Professor Name,Interests,h-index,Abstracts,Link,Home_page
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:AvfA0Oy_GE0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Code-mixing is the phenomenon of using more than one language in a sentence. It is a very frequently observed pattern of communication on social media platforms. Flexibility to use multiple languages in one text message might help to communicate efficiently with the target audience. But, it adds to the challenge of processing and understanding natural language to a much larger extent. This paper presents a parallel corpus of the 13,738 code-mixed English-Hindi sentences and their corresponding translation in English. The translations of sentences are done manually by the annotators. We are releasing the parallel corpus to facilitate future research opportunities in code-mixed machine translation. The annotated corpus is available at https://doi.org/10.5281/zenodo.3605597.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:_xSYboBqXhAC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Text generation is a highly active area of research in the computational linguistic community. The evaluation of the generated text is a challenging task and multiple theories and metrics have been proposed over the years. Unfortunately, text generation and evaluation are relatively understudied due to the scarcity of high-quality resources in code-mixed languages where the words and phrases from multiple languages are mixed in a single utterance of text and speech. To address this challenge, we present a corpus (HinGE) for a widely popular code-mixed language Hinglish (code-mixing of Hindi and English languages). HinGE has Hinglish sentences generated by humans as well as two rule-based algorithms corresponding to the parallel Hindi-English sentences. In addition, we demonstrate the inefficacy of widely-used evaluation metrics on the code-mixed data. The HinGE dataset will facilitate the progress of natural language generation research in code-mixed languages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:SdhP9T11ey4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Projection of changes in extreme indices of climate variables such as temperature and precipitation are critical to assess the potential impacts of climate change on human-made and natural systems, including critical infrastructures and ecosystems. While impact assessment and adaptation planning rely on high-resolution projections (typically in the order of a few kilometers), state-of-the-art Earth System Models (ESMs) are available at spatial resolutions of few hundreds of kilometers. Current solutions to obtain high-resolution projections of ESMs include downscaling approaches that consider the information at a coarse-scale to make predictions at local scales. Complex and non-linear interdependence among local climate variables (e.g., temperature and precipitation) and large-scale predictors (e.g., pressure fields) motivate the use of neural network-based super-resolution architectures. In this work, we present …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:uWQEDVKXjbEC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Understanding the current research trends, problems, and their innovative solutions remains a bottleneck due to the ever-increasing volume of scientific articles. In this paper, we propose NLPExplorer, a completely automatic portal for indexing, searching, and visualizing Natural Language Processing (NLP) research volume. NLPExplorer presents interesting insights from papers, authors, venues, and topics. In contrast to previous topic modelling based approaches, we manually curate five course-grained non-exclusive topical categories namely Linguistic Target (Syntax, Discourse, etc.), Tasks (Tagging, Summarization, etc.), Approaches (unsupervised, supervised, etc.), Languages (English, Chinese, etc.) and Dataset types (news, clinical notes, etc.). Some of the novel features include a list of young popular authors, popular URLs and datasets, list of topically diverse papers and recent popular papers …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:D03iK_w7-QYC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Digital advancement in scholarly repositories has led to the emergence of a large number of open access predatory publishers that charge high article processing fees from authors but fail to provide necessary editorial and publishing services. Identifying and blacklisting such publishers has remained a research challenge due to the highly volatile scholarly publishing ecosystem. This paper presents a data-driven approach to study how potential predatory publishers are evolving and bypassing several regularity constraints. We empirically show the close resemblance of predatory publishers against reputed publishing groups. In addition to verifying standard constraints, we also propose distinctive signals gathered from network-centric properties to understand this evolving ecosystem better. To facilitate reproducible research, we shall make all the codes and the processed dataset available in the public …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:fPk4N6BV_jEC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Code-mixing is a frequent communication style among multilingual speakers where they mix words and phrases from two different languages in the same utterance of text or speech. Identifying and filtering code-mixed text is a challenging task due to its co-existence with monolingual and noisy text. Over the years, several code-mixing metrics have been extensively used to identify and validate code-mixed text quality. This paper demonstrates several inherent limitations of code-mixing metrics with examples from the already existing datasets that are popularly used across various experiments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:eMMeJKvmdy0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Abstract—India is an agro-based economy and proper information about agricultural practices is the key to optimal agricultural growth and output. In order to answer the queries of the farmer, we have build an agricultural chatbot based on the dataset from Kisan Call Center. This system is robust enough to answer queries related to weather, market rates, plant protection and government schemes. This system is available 24* 7, can be accessed through any electronic device and the information is delivered with the ease of understanding. The system is based on a sentence embedding model which gives an accuracy of 56%. After eliminating synonyms and incorporating entity extraction, the accuracy jumps to 86%. With such a system, farmers can progress towards easier information about farming related practices and hence a better agricultural output. The job of the Call Center workforce would be made easier and the hard work of various such workers can be redirected to a better goal.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:P5F9QuxV20EC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"We present CL Scholar, the ACL Anthology knowledge graph miner to facilitate high-quality search and exploration of current research progress in the computational linguistics community. In contrast to previous works, periodically crawling, indexing and processing of new incoming articles is completely automated in the current system. CL Scholar utilizes both textual and network information for knowledge graph construction. As an additional novel initiative, CL Scholar supports more than 1200 scholarly natural language queries along with standard keyword-based search on constructed knowledge graph. It answers binary, statistical and list based natural language queries. The current system is deployed at http://cnerg.iitkgp.ac.in/aclakg. We also provide REST API support along with bulk download facility. Our code and data are available at https://github.com/CLScholar.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:ZHo1McVdvXMC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Code-mixing is the phenomenon of using multiple languages in the same utterance of a text or speech. It is a frequently used pattern of communication on various platforms such as social media sites, online gaming, product reviews, etc. Sentiment analysis of the monolingual text is a well-studied task. Code-mixing adds to the challenge of analyzing the sentiment of the text due to the non-standard writing style. We present a candidate sentence generation and selection based approach on top of the Bi-LSTM based neural classifier to classify the Hinglish code-mixed text into one of the three sentiment classes positive, negative, or neutral. The proposed approach shows an improvement in the system performance as compared to the Bi-LSTM based neural classifier. The results present an opportunity to understand various other nuances of code-mixing in the textual data, such as humor-detection, intent classification, etc.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:1sJd4Hv_s6UC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"A leaderboard is a tabular presentation of performance scores of the best competing techniques that address a specific scientific problem. Manually maintained leaderboards take time to emerge, which induces a latency in performance discovery and meaningful comparison. This can delay dissemination of best practices to non-experts and practitioners. Regarding papers as proxies for techniques, we present a new system to automatically discover and maintain leaderboards in the form of partial orders between papers, based on performance reported therein. In principle, a leaderboard depends on the task, data set, other experimental settings, and the choice of performance metrics. Often there are also tradeoffs between different metrics. Thus, leaderboard discovery is not just a matter of accurately extracting performance numbers and comparing them. In fact, the levels of noise and uncertainty around …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:UebtZRa9Y70C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Information Extraction (IE) from the tables present in scientific articles is challenging due to complicated tabular representations and complex embedded text. This paper presents TabLeX, a large-scale benchmark dataset comprising table images generated from scientific articles. TabLeX consists of two subsets, one for table structure extraction and the other for table content extraction. Each table image is accompanied by its corresponding LaTeX source code. To facilitate the development of robust table IE tools, TabLeX contains images in different aspect ratios and in a variety of fonts. Our analysis sheds light on the shortcomings of current state-of-the-art table extraction models and shows that they fail on even simple table images. Towards the end, we experiment with a transformer-based existing baseline to report performance scores. In contrast to the static benchmarks, we plan to augment this dataset …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:Mojj43d5GZwC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"In this shared task, we seek the participating teams to investigate the factors influencing the quality of the code-mixed text generation systems. We synthetically generate code-mixed Hinglish sentences using two distinct approaches and employ human annotators to rate the generation quality. We propose two subtasks, quality rating prediction and annotators' disagreement prediction of the synthetic Hinglish dataset. The proposed subtasks will put forward the reasoning and explanation of the factors influencing the quality and human perception of the code-mixed text.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:WqliGbK-hY8C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"The distinction between sciences is becoming increasingly more artificial – an approach from one area can be easily applied to the other. More exciting research nowadays is happening perhaps at the interfaces of disciplines like Physics, Mathematics and Computer Science. How do these interfaces emerge and interact? For instance, is there a specific pattern in which these fields cite each other? In this article, we investigate a collection of more than 1.2 million papers from three different scientific disciplines – Physics, Mathematics, and Computer Science. We show how over a timescale the citation patterns from the core science fields (Physics, Mathematics) to the applied and fast-growing field of Computer Science have drastically increased. Further, we observe how certain subfields in these disciplines are shrinking while others are becoming tremendously popular. For instance, an intriguing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&citation_for_view=U2NUj90AAAAJ:a0OBvERweLwC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Code-mixing is a phenomenon of mixing words and phrases from two or more languages in a single utterance of speech and text. Due to the high linguistic diversity, code-mixing presents several challenges in evaluating standard natural language generation (NLG) tasks. Various widely popular metrics perform poorly with the code-mixed NLG tasks. To address this challenge, we present a metric independent evaluation pipeline MIPE that significantly improves the correlation between evaluation metrics and human judgments on the generated code-mixed text. As a use case, we demonstrate the performance of MIPE on the machine-generated Hinglish (code-mixing of Hindi and English languages) sentences from the HinGE corpus. We can extend the proposed evaluation strategy to other code-mixed language pairs, NLG tasks, and evaluation metrics with minimal to no effort.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:eq2jaN3J8jMC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Tables present important information concisely in many scientific documents. Visual features like mathematical symbols, equations, and spanning cells make structure and content extraction from tables embedded in research documents difficult. This paper discusses the dataset, tasks, participants’ methods, and results of the ICDAR 2021 Competition on Scientific Table Image Recognition to LaTeX. Specifically, the task of the competition is to convert a tabula r image to its corresponding  source code. We proposed two subtasks. In Subtask 1, we ask the participants to reconstruct the  structure code from an image. In Subtask 2, we ask the participants to reconstruct the  content code from an image. This report describes the datasets and ground truth specification, details the performance evaluation metrics used, presents the final results, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:9vf0nzSNQJEC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Extensive literature demonstrates how the copying of references (links) can lead to the emergence of various structural properties (e.g., power-law degree distribution and bipartite cores) in bibliographic and other similar directed networks. However, it is also well known that the copying process is incapable of mimicking the number of directed triangles in such networks; neither does it have the power to explain the obsolescence of older papers. In this paper, we propose RefOrCite, a new model that allows for copying of both the references from (i.e., out-neighbors of) as well as the citations to (i.e., in-neighbors of) an existing node. In contrast, the standard copying model (CP) only copies references. While retaining its spirit, RefOrCite differs from the Forest Fire (FF) model in ways that makes RefOrCite amenable to mean-field analysis for degree distribution, triangle count, and densification. Empirically, RefOrCite …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:f2IySw72cVMC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"The task of learning a sentiment classification model that adapts well to any target domain, different from the source domain, is a challenging problem. Majority of the existing approaches focus on learning a common representation by leveraging both source and target data during training. In this paper, we introduce a two-stage training procedure that leverages weakly supervised datasets for developing simple lift-and-shift-based predictive models without being exposed to the target domain during the training phase. Experimental results show that transfer with weak supervision from a source domain to various target domains provides performance very close to that obtained via supervised training on the target domain itself.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:abG-DnoFyZgC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Air pollution is a global challenge for cities across the globe. Understanding the public perception of air pollution can help policymakers engage better with the public and appropriately introduce policies. Accurate public perception can also help people to identify the health risks of air pollution and act accordingly. Unfortunately, current techniques for determining perception are not scalable: it involves surveying few hundred people with questionnaire-based surveys. Using the advances in natural language processing (NLP), we propose a more scalable solution called Vartalaap to gauge public perception of air pollution via the microblogging social network Twitter. We curated a dataset of more than 1.2M tweets discussing Delhi-specific air pollution. We find that (unfortunately) the public is supportive of unproven mitigation strategies to reduce pollution, thus risking their health due to a false sense of security. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:WA5NYHcadZ8C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"WhatsApp Messenger is one of the most popular channels for spreading information with a current reach of more than 180 countries and 2 billion people. Its widespread usage has made it one of the most popular media for information propagation among the masses during any socially engaging event. In the recent past, several countries have witnessed its effectiveness and influence in political and social campaigns. We observe a high surge in information and propaganda flow during election campaigning. In this paper, we explore a high-quality large-scale user-generated dataset curated from WhatsApp comprising of 281 groups, 31,078 unique users, and 223,404 messages shared before, during, and after the Indian General Elections 2019, encompassing all major Indian political parties and leaders. In addition to the raw noisy user-generated data, we present a fine-grained annotated dataset of 3,848 messages that will be useful to understand the various dimensions of WhatsApp political campaigning. We present several complementary insights into the investigative and sensational news stories from the same period. Exploratory data analysis and experiments showcase several exciting results and future research opportunities. To facilitate reproducible research, we make the anonymized datasets available in the public domain.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:eflP2zaiRacC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"This tutorial will elaborate on various available resources for the natural language generation (NLG) tasks in code-mixed languages. We will also discuss the adaptability, limitations, and challenges with various evaluation metrics for the code-mixed NLG. In addition, we will put forward a set of open research questions pertaining to the tasks, resources, experiments, and metrics for the code-mixed NLG.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:hkOj_22Ku90C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Comparing research papers is a conventional method to demonstrate progress in experimental research. We present COMPARE, a taxonomy and a dataset of comparison discussions in peer reviews of research papers in the domain of experimental deep learning. From a thorough observation of a large set of review sentences, we build a taxonomy of categories in comparison discussions and present a detailed annotation scheme to analyze this. Overall, we annotate 117 reviews covering 1,800 sentences. We experiment with various methods to identify comparison sentences in peer reviews and report a maximum F1 Score of 0.49. We also pretrain two language models specifically on ML, NLP, and CV paper abstracts and reviews to learn informative representations of peer reviews. The annotated dataset and the pretrained models are available at https://github.com/shruti-singh/COMPARE.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:ZuybSZzF8UAC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Relational databases are prevalent in handling large and complex databases; however, writing the SQL queries can be a tedious task for databases. Recent studies for automating the task of translating natural language text to SQL query are not robust to queries having multi-table dependencies. Also, considering the lack of such research in scientific domain, we introduce ACL-SQL, a dataset with complex queries depending on up to five tables and benchmark the dataset on a simple approach. Evaluation shows that our approach is reasonably precise and can be adopted for practical applications. The dataset and codes are available at https://github.com/rohitshantarampatil/sql-nlp.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:5ugPr518TE4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"The entire world is engulfed in the fight against the COVID-19 pandemic, leading to a significant surge in research experiments, government policies, and social media discussions. A multi-modal information access and data visualization platform can play a critical role in supporting research aimed at understanding and developing preventive measures for the pandemic. In this paper, we present a multi-faceted AI-based search and visualization engine, CovidExplorer. Our system aims to help researchers understand current state-of-the-art COVID-19 research, identify research articles relevant to their domain, and visualize real-time trends and statistics of COVID-19 cases. In contrast to other existing systems, CovidExplorer also brings in India-specific topical discussions on social media to study different aspects of COVID-19. The system, demo video, and the datasets are available at http://covidexplorer.in.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:u9iWguZQMMsC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"High solicitation for publishing a paper in scientific journals has led to the emergence of a large number of open-access predatory publishers. They fail to provide a rigorous peer-review process, thereby diluting the quality of research work and charge high article processing fees. Identification of such publishers has remained a challenge due to the vast diversity of the scholarly publishing ecosystem. Earlier works utilises only the objective features such as metadata. In this work, we aim to explore the possibility of identifying predatory behaviour through text-based features. We propose PredCheck, a four-step classificaton pipeline. The first classifier identifies the subject of the paper using TF-IDF vectors. Based on the subject of the paper, the Doc2Vec embeddings of the text are found. These embeddings are then fed into a Naive Bayes classifier that identifies the text to be predatory or non-predatory. Our pipeline …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:dshw04ExmUIC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Research and innovation is an important agenda for any company to remain competitive in the market. The relationship between innovation and revenue is a key metric for companies to decide on the amount to be invested for future research. Two important parameters to evaluate innovation are the quantity and quality of scientific papers and patents. Our work studies the relationship between innovation and patenting activities for several Fortune 500 companies over a period of time. We perform a comprehensive study of the patent citation dataset available in the Reed Technology Index collected from the US Patent Office. We observe several interesting relations between parameters like the number of (i) patent applications, (ii) patent grants, (iii) patent citations and Fortune 500 ranks of companies. We also study the trends of these parameters varying over the years and derive causal explanations for these with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:bFI3QPDXJZMC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Network modeling is a challenging task due to non-trivial evolution dynamics. We introduce multiple-selection-procedure with ‘N’ possible growth mechanisms (MSP-N). In MSP-N, an incoming node chooses a single option among N available options to link to pre-existing nodes. Some of the potential options, in case of social networks, can be standard preferential or random attachment and node aging or fitness. In this paper, we discuss a specific case, MSP-2, and shows its efficacy in reconstructing several non-trivial characteristic properties of social networks, including networks with power-law degree distribution, power-law with an exponential decay (exponential cut-off), and exponential degree distributions. We evaluate the proposed evolution mechanism over two real-world networks and observe that the generated networks highly resembles the degree distribution of the real-world networks. Besides, several other network properties such as high clustering and triangle count, low spectral radius, and community structure, of the generated networks are significantly closer to the real-world networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:pyW8ca7W8N0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Tsunamis, power blackouts, and distribution systems failure drastically affect the networked infrastructure systems which further affect a countries economy. Moreover, if these systems reach critical thresholds, they may experience disproportionate losses in the system’s functionality. Here we propose an approach to identify the critical thresholds and observe the presence of warning regions for real-world transportation systems. While attack tolerance of networked systems has been intensively studied for the disruptions originating from a single point of failure, there have been instances where real-world systems are subject to concurrent disruptions at multiple locations. We determine the entire robustness characteristics of transportation networks of disparate architecture subject to disruptions of varying sizes. Using United States Airspace Airport network and Indian Railways Network data, and synthetic networks as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:UHK10RUVsp4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Multilingualism refers to the high degree of proficiency in two or more languages in the written and oral communication modes. It often results in language mixing, a.k.a. code-mixing, when a multilingual speaker switches between multiple languages in a single utterance of a text or speech. This paper discusses the current state of the NLP research, limitations, and foreseeable pitfalls in addressing five real-world applications for social good crisis management, healthcare, political campaigning, fake news, and hate speech for multilingual societies. We also propose futuristic datasets, models, and tools that can significantly advance the current research in multilingual NLP applications for the societal good. As a representative example, we consider English-Hindi code-mixing but draw similar inferences for other language pairs",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:tkaPQYYpVKoC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"A reverse dictionary is a tool that solves the Tip-of-the-Tongue problem by predicting the target word given a meaning or description. This paper proposes a modified Continuous Bag-Of-Words (CBOW) model inspired by the Recurrent Neural Network (RNN), to implement a reverse dictionary. The model possesses the merits of both the CBOW model and RNN while stripping away the complexity associated with RNN. We evaluate the model by measuring accuracy based on the top-2 predictions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:V3AGJWp-ZtQC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Complex systems have been successfully modeled as networks exhibiting the varying extent of randomness and nonrandomness. Network scientists contemplate randomness as one of the most desirable characteristics for real complex systems’ efficient performance. However, the current methodologies for randomness (or nonrandomness) quantification are nontrivial. In this article, we empirically showcase severe limitations associated with the state-of-the-art graph spectral-based quantification approaches. Addressing these limitations led to the proposal of a novel spectrum-based methodology that leverages configuration models as a reference network to quantify the nonrandomness in a given candidate network. Besides, we derive mathematical formulations for demonstrating the dependence of nonrandomness on three structural properties: modularity, clustering, and the highest degree node’s growth rate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:K3LRdlH-MEoC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Language models are increasingly becoming popular in AI-powered scientific IR systems. This paper evaluates popular scientific language models in handling (i) short-query texts and (ii) textual neighbors. Our experiments showcase the inability to retrieve relevant documents for a short-query text even under the most relaxed conditions. Additionally, we leverage textual neighbors, generated by small perturbations to the original text, to demonstrate that not all perturbations lead to close neighbors in the embedding space. Further, an exhaustive categorization yields several classes of orthographically and semantically related, partially related, and completely unrelated neighbors. Retrieval performance turns out to be more influenced by the surface form rather than the semantics of the text.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:W5xh706n7nkC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Several studies in the fields of Artificial Intelligence and Natural Language Processing have been conducted on Music Synthesis. However, due to the limited availability of structured datasets, the field of Indian Classical Music remains unexplored. Additionally, the considerable influence of western music in the past decade has adversely affected the market and demand for Indian Classical Music. In this work, we propose a model to generate music for Indian Classical Music, specifically Carnatic Music, by leveraging the structured nature of Indian Carnatic Music. We build a dataset of Classical Indian Music with paired lyrics and melody to map melody with notes to extract features. Generative Adversarial Networks (GANs) are proven to be very effective for music generation in several research works. We experiment with GANs and Auto Encoder (Variational AE and Conditional VAE) on classical lyrics. The curated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:JQOojiI6XY0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Automatic code synthesis from natural language descriptions is a challenging task. We witness massive progress in developing code generation systems for domain-specific languages (DSLs) employing sequence-to-sequence deep learning techniques in the recent past. In this paper, we specifically experiment with \textsc{AlgoLisp} DSL-based generative models and showcase the existence of significant dataset bias through different classes of adversarial examples. We also experiment with two variants of Transformer-based models that outperform all existing \textsc{AlgoLisp} DSL-based code generation baselines. Consistent with the current state-of-the-art systems, our proposed models, too, achieve poor performance under adversarial settings. Therefore, we propose several dataset augmentation techniques to reduce bias and showcase their efficacy using robust experimentation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:dTyEYWd-f8wC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"We present TweeNLP, a one-stop portal that organizes Twitter's natural language processing (NLP) data and builds a visualization and exploration platform. It curates 19,395 tweets (as of April 2021) from various NLP conferences and general NLP discussions. It supports multiple features such as TweetExplorer to explore tweets by topics, visualize insights from Twitter activity throughout the organization cycle of conferences, discover popular research papers and researchers. It also builds a timeline of conference and workshop submission deadlines. We envision TweeNLP to function as a collective memory unit for the NLP community by integrating the tweets pertaining to research papers with the NLPExplorer scientific literature search engine. The current system is hosted at http://nlpexplorer.org/twitter/CFP .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:JoZmwDi-zQgC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Recommendation Systems are widely deployed for all kinds of services across various websites to enhance user experience. However, existing systems do not make efficient use of text data associated with products and users, available as reviews and blogs to relate them better. Many recent works have tried to improve the accuracy of rating prediction. However, very few works have attempted to justify the reason for a particular recommendation. Explaining the recommendation would help in gaining the trust of the user, and lend the system human-like credibility. In this paper, we propose a model that can recommend movies and generate a reasoning text to help the user understand why a film was recommended to them. We use three parallel neural networks with an enhanced BERT Embedding for Aspect Based Sentiment Analysis (ABSA) to predict rating. The Seq2Seq transformer model is used to generate the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:kRWSkSYxWN8C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Understanding the topical evolution in industrial innovation is a challenging problem. With the advancement in the digital repositories in the form of patent documents, it is becoming increasingly more feasible to understand the innovation secrets - 'catchphrases' - of organizations. However, searching and understanding this enormous textual information is a natural bottleneck. In this paper, we propose an unsupervised method for the extraction of catchphrases from the abstracts of patents granted by the U.S. Patent and Trademark Office over the years. Our proposed system achieves substantial improvement, both in terms of precision and recall, against state-of-the-art techniques. As a second objective, we conduct an extensive empirical study to understand the temporal evolution of the catchphrases across various organizations. We also show how the overall innovation evolution in the form of introduction of newer …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:CHSYGLWDkRkC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"We introduce an AI-enabled portal that presents an excellent visualization of Mahatma Gandhi's life events by constructing temporal and spatial social networks from the Gandhian literature. Applying an ensemble of methods drawn from NLTK, Polyglot and Spacy we extract the key persons and places that find mentions in Gandhi's written works. We visualize these entities and connections between them based on co-mentions within the same time frame as networks in an interactive web portal. The nodes in the network, when clicked, fire search queries about the entity and all the information about the entity presented in the corresponding book from which the network is constructed, are retrieved and presented back on the portal. Overall, this system can be used as a digital and user-friendly resource to study Gandhian literature.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:EUQCXRtRnyEC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"A biography of a person is the detailed description of several life events including his education, work, relationships and death. Wikipedia, the free web-based encyclopedia, consists of millions of manually curated biographies of eminent politicians, film and sports personalities, etc. However, manual curation efforts, even though efficient, suffers from significant delays. In this work, we propose an automatic biography generation framework BioGen. BioGen generates a short collection of biographical sentences clustered into multiple events of life. Evaluation results show that biographies generated by BioGen are significantly closer to manually written biographies in Wikipedia. A working model of this framework is available at nlpbiogen.herokuapp.com/home/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:cFHS6HbyZ2cC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"The multi-sentential long sequence textual data unfolds several interesting research directions pertaining to natural language processing and generation. Though we observe several high-quality long-sequence datasets for English and other monolingual languages, there is no significant effort in building such resources for code-mixed languages such as Hinglish (code-mixing of Hindi-English). In this paper, we propose a novel task of identifying multi-sentential code-mixed text (MCT) from multilingual articles. As a use case, we leverage multilingual articles from two different data sources and build a first-of-its-kind multi-sentential code-mixed Hinglish dataset i.e., MUTANT. We propose a token-level language-aware pipeline and extend the existing metrics measuring the degree of code-mixing to a multi-sentential framework and automatically identify MCT in the multilingual articles. The MUTANT dataset comprises 67k articles with 85k identified Hinglish MCTs. To facilitate future research, we make the publicly available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:BUYA1_V_uYcC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Scientific documents contain tables that list important information in a concise fashion. Structure and content extraction from tables embedded within PDF research documents is a very challenging task due to the existence of visual features like spanning cells and content features like mathematical symbols and equations. Most existing table structure identification methods tend to ignore these academic writing features. In this paper, we adapt the transformer-based language modeling paradigm for scientific table structure and content extraction. Specifically, the proposed model converts a tabular image to its corresponding LaTeX source code. Overall, we outperform the current state-of-the-art baselines and achieve an exact match accuracy of 70.35 and 49.69% on table structure and content extraction, respectively. Further analysis demonstrates that the proposed models efficiently identify the number of rows and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:ipzZ9siozwsC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Stock market investors debate and heavily discuss stock ideas, investing strategies, news and market movements on social media platforms. The discussions are significantly longer in length and require extensive domain expertise for understanding. In this paper, we curate such discussions and construct a first-of-its-kind of abstractive summarization dataset. Our curated dataset consists of 7888 Reddit posts and manually constructed summaries for 400 posts. We robustly evaluate the summaries and conduct experiments on SOTA summarization tools to showcase their limitations. We plan to make the dataset publicly available. The sample dataset is available here: https://dhyeyjani. github. io/RSMC",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:7T2F9Uy0os0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Computers are devices that execute precise instructions provided to them using various programming languages. However, the idea of delivering instructions to a computer through natural language could vastly simplify the act of programming as a specific task. Generating code from high-level descriptions for a given program is a significantly challenging task and has been an active area of research in the natural language processing domain. In this paper, we present a novel feedback-based deep learning approach for synthesizing code from human-specified descriptions. Inspired by the dual-learning mechanism, our framework uses a feedback loss to produce more consistent and robust predictions. We show how our approach fares empirically on standard code generation datasets and achieves state-of-the-art results on the NAPS (Natural Program Synthesis) dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:uLbwQdceFCQC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Nowadays, researchers have moved to platforms like Twitter to spread information about their ideas and empirical evidence. Recent studies have shown that social media affects the scientific impact of a paper. However, these studies only utilize the tweet counts to represent Twitter activity. In this paper, we propose TweetPap, a large-scale dataset that introduces temporal information of citation/tweets and the metadata of the tweets to quantify and understand the discourse of scientific papers on social media. The dataset is publicly available at https://github.com/lingo-iitgn/TweetPap.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:_B80troHkn4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"The increasing use of dialogue agents makes it extremely desirable for them to understand and acknowledge the implied emotions to respond like humans with empathy. Chatbots using traditional techniques analyze emotions based on the context and meaning of the text and lack the understanding of emotions expressed through face. Emojis representing facial expressions present a promising way to express emotions. However, none of the AI systems utilizes emojis for empathetic conversation generation. We propose, SentEmojiBot, based on the SentEmoji dataset, to generate empathetic conversations with a combination of emojis and text. Evaluation metrics show that the BERT-based model outperforms the vanilla transformer model. A user study indicates that the dialogues generated by our model were understandable and adding emojis improved empathetic traits in conversations by 9.8%",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:PELIpwtuRlgC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"In this work, we propose to construct a Genealogical Tree of research papers. A Genealogy tree of research papers is a tree-like structure that captures information diffusion (transfer of genes) from parent papers to its citations (children). The nodes in the tree denote papers, and the edges represent the information passed from one generation to the other. A genealogy tree can be leveraged to understand better any research topic’s lineage and any specific paper’s influence",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:1qzjygNMrQYC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:J-pR_7NvFogC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Network structures in a wide array of systems such as social networks, transportation, power and water distribution infrastructures, and biological and ecological systems can exhibit critical thresholds or tipping points beyond which there are disproportionate losses in the system functionality. There is growing concern over tipping points and failure tolerance of such systems as tipping points can lead to an abrupt loss of intended functionality and possibly non-recoverable states. While attack tolerance of networked systems has been intensively studied for the disruptions originating from a single point of failure, there have been instances where real-world systems are subject to simultaneous or sudden onset of concurrent disruption at multiple locations. Using open-source data from the United States Airspace Airport network and Indian Railways Network, and random networks as prototype class of systems, we study their responses to synthetic attack strategies of varying sizes. For both types of networks, we observe the presence of warning regions, which serve as a precursor to the tipping point. Further, we observe the statistically significant relationships between network robustness and size of simultaneous distribution, which generalizes to the networks with different topological attributes for random failures and targeted attacks. We show that our approach can determine the entire robustness characteristics of networks of disparate architecture subject to disruptions of varying sizes. Our approach can serve as a paradigm to understand the tipping point in real-world systems, and the principle can be extended to other disciplines to address critical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:OU6Ihb5iCvQC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Automatic scientific keyphrase extraction is a challenging problem facilitating several downstream scholarly tasks like search, recommendation, and ranking. In this paper, we introduce SEAL, a scholarly tool for automatic keyphrase extraction and classification. The keyphrase extraction module comprises two-stage neural architecture composed of Bidirectional Long Short-Term Memory cells augmented with Conditional Random Fields. The classification module comprises of a Random Forest classifier. We extensively experiment to showcase the robustness of the system. We evaluate multiple state-of-the-art baselines and show a significant improvement. The current system is hosted at http://lingo.iitgn.ac.in:5000/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:b0M2c_1WBrUC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Song lyrics convey a meaningful story in a creative manner with complex rhythmic patterns. Researchers have been successful in generating and analyisng lyrics for poetry and songs in English and Chinese. But there are no works which explore the Hindi language datasets. Given the popularity of Hindi songs across the world and the ambiguous nature of romanized Hindi script, we propose Bollyrics, an automatic lyric generator for romanized Hindi songs. We propose simple techniques to capture rhyming patterns before and during the model training process in Hindi language. The dataset and codes are available publicly at https://github.com/lingo-iitgn/Bollyrics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:xtRiw3GOFMkC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Understanding scholarly articles is a key ingredient of impressive research recipe. Scholarly articles keep the scientific community up to date with the current research and development results and ideas. With the tremendous advancement in Internet infrastructure, we are witnessing an ongoing explosion in scholarly information that is generated. In this thesis, we attempt to introduce, study and solve some of the challenges emanating from scholarly volume overload. In particular, we look into three different dimensions:(i) metadata, structure, bibliography and experimental performance extraction from scholarly articles,(ii) designing network-assisted aging growth models for evolving citation networks with novel proposal of temporal summaries, and (iii) leveraging textual and network information to design long-term scientific impact prediction frameworks. While the first objective is related to the curation of scientific …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:t6usbXjVLHcC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:nb7KW1ujOQ8C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"Recent advancements in Internet and Mobile infrastructure have resulted in the development of faster and efficient platforms of communication. These platforms include speech, facial and text-based conversational mediums. Majority of these are text-based messaging platforms. Development of Chatbots that automatically understand latent emotions in the textual message is a challenging task. In this paper, we present an automatic emotion detection system that aims to detect the emotion of a person textually conversing with a chatbot. We explore deep learning techniques such as CNN and LSTM based neural networks and outperformed the baseline score by 14%. The trained model and code are kept in public domain.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:dfsIfKJdRG4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:p2g8aNsByqUC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,"With the exponential growth of research volume in the recent decades, academic entities like articles, authors, venues, organisations, fields etc. have evolved qualitatively and quantitatively. The scientific community has always been demanding for better algorithms, metrics and features for ranking and categorization of academic entities leading to one of the interesting and well researched problem of understanding and estimating the popularity of these academic entities. We study several interesting factors that influence the popularity of research articles. Specifically, we utilize information generated immediately after the publication to estimate its long-term popularity. This generated information includes both network-based and content-based information. We also propose the first plausible network-driven models for obsolescence in the context of research paper citations, based on a natural notion of relay-linking. Our model is based on a surprising inversion or undoing of triangle completion, where an old node relays a citation to a younger follower in its immediate vicinity. We show that our proposed models remarkably better fit with real bibliographic data. We also demonstrate the development of ConfAssist which is a novel conflict resolution framework that can assist experts to resolve conflicts in deciding whether a conference is a top-tier or not by expressing how (dis) similar the conference is to other well accepted top-tier/non top-tier conferences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&citation_for_view=U2NUj90AAAAJ:kzcrU_BdoSEC,http://mayank4490.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"India loses 35% of the annual crop yield due to plant diseases. Early detection of plant diseases remains difficult due to the lack of lab infrastructure and expertise. In this paper, we explore the possibility of computer vision approaches for scalable and early plant disease detection. The lack of availability of sufficiently large-scale non-lab data set remains a major challenge for enabling vision based plant disease detection. Against this background, we present PlantDoc: a dataset for visual plant disease detection. Our dataset contains 2,598 data points in total across 13 plant species and up to 17 classes of diseases, involving approximately 300 human hours of effort in annotating internet scraped images. To show the efficacy of our dataset, we learn 3 models for the task of plant disease classification. Our results show that modelling using our dataset can increase the classification accuracy by up to 31%. We believe …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&citation_for_view=rFGzHlIAAAAJ:0KyAp5RtaNEC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Non-intrusive load monitoring (NILM) or energy disaggregation is the task of separating the household energy measured at the aggregate level into constituent appliances. In 2014, the NILM toolkit (NILMTK) was introduced in an effort towards making NILM research reproducible. Despite serving as the reference library for data set parsers and reference benchmark algorithm implementations, few publications presenting algorithmic contributions within the field went on to contribute implementations back to the toolkit. This paper describes two significant contributions to the NILM community in an effort towards reproducible state-of-the-art research: i) a rewrite of the disaggregation API and a new experiment API which lower the barrier to entry for algorithm developers and simplify the definition of algorithm comparison experiments, and ii) the release of NILMTK-contrib; a new repository containing NILMTK-compatible …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&citation_for_view=rFGzHlIAAAAJ:uJ-U7cs_P_0C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Many modern machine learning algorithms have a large number of hyperparameters. To effectively use these algorithms, we need to pick good hyperparameter values. In this article, we talk about Bayesian Optimization, a suite of techniques often used to tune hyperparameters. More generally, Bayesian Optimization can be used to optimize any black-box function.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&citation_for_view=rFGzHlIAAAAJ:epqYDVWIO7EC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Non-intrusive load monitoring (NILM) or energy disaggregation refers to the task of estimating the appliance power consumption given the aggregate power consumption readings. Recent state-of-the-art neural networks based methods are computation and memory intensive, and thus not suitable to run on ""edge devices"". Recent research has proposed various methods to compress neural networks without significantly impacting accuracy. In this work, we study different neural network compression schemes and their efficacy on the state-of-the-art neural network NILM method. We additionally propose a multi-task learning-based architecture to compress models further. We perform an extensive evaluation of these techniques on two publicly available datasets and find that we can reduce the memory and compute footprint by a factor of up to 100 without significantly impacting predictive performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&citation_for_view=rFGzHlIAAAAJ:EYYDruWGBe4C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Buildings across the world contribute about one-third of the total energy consumption. Studies report that anomalies in energy consumption caused by faults and abnormal appliance usage waste up to 20% of energy in buildings. Recent works leverage smart meter data to find such anomalies; however, such works do not identify the appliance causing the anomaly. Moreover, most of these works are not real-time and report the anomaly at the end of the day. In this paper, we propose a technique named Rimor that addresses these limitations. Rimor predicts the energy consumption of a home using historical energy data and contextual information and flags an anomaly when the actual energy consumption deviates significantly from the predicted consumption. Further, it identifies anomalous appliance(s) by using easy-to-collect appliance power ratings. We evaluated it on four real-world energy datasets containing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&citation_for_view=rFGzHlIAAAAJ:-_dYPAW6P2MC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Homes constitute roughly one-third of the total energy usage worldwide. Providing an energy breakdown–energy consumption per appliance, can help save up to 15% energy. Given the vast differences in energy consumption patterns across different regions, existing energy breakdown solutions require instrumentation and model training for each geographical region, which is prohibitively expensive and limits the scalability. In this paper, we propose a novel region independent energy breakdown model via statistical transfer learning. Our key intuition is that the heterogeneity in homes and weather across different regions most significantly impacts the energy consumption across regions; and if we can factor out such heterogeneity, we can learn region independent models or the homogeneous energy breakdown components for each individual appliance. Thus, the model learnt in one region can be transferred to another region. We evaluate our approach on two US cities having distinct weather from a publicly available dataset. We find that our approach gives better energy breakdown estimates requiring the least amount of instrumented homes from the target region, when compared to the state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&citation_for_view=rFGzHlIAAAAJ:tKAzc9rXhukC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Residential buildings constitute roughly one-fourth of the total energy use across the globe. Numerous studies have shown that providing an energy breakdown increases residents' awareness of energy use and can help save up to 15% energy. A significant amount of prior work has looked into source-separation techniques collectively called non-intrusive load monitoring (NILM), and most prior NILM research has leveraged high-frequency household aggregate data for energy breakdown. However, in practice most smart meters only sample hourly or once every 15 minutes, and existing NILM techniques show poor performance at such a low sampling rate.
In this paper, we propose a TreeCNN model for energy breakdown on low frequency data. There are three key insights behind the design of our model: i) households consume energy with regular temporal patterns, which can be well captured by filters learned …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&citation_for_view=rFGzHlIAAAAJ:fEOibwPWpKIC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Non-intrusive load monitoring (NILM) or energy disaggregation involves separating the household energy measured at the aggregate level into constituent appliances. The NILM toolkit (NILMTK) was introduced in 2014 towards making NILM research reproducible. NILMTK has served as the reference library for data set parsers and reference benchmark algorithm implementations. However, few publications presenting algorithmic contributions within the field went on to contribute implementations back to the toolkit. This work presents a demonstration of a new version of NILMTK [2] which has a rewrite of the disaggregation API and a new experiment API which lower the barrier to entry for algorithm developers and simplify the definition of algorithm comparison experiments. This demo also marks the release of NILMTK-contrib: a new repository containing NILMTK-compatible implementations of 3 benchmarks and 9 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:nrtMV_XWKgEC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Air pollution is a global problem and severely impacts human health. Fine-grained air quality (AQ) monitoring is important in mitigating air pollution. However, existing AQ station deployments are sparse. Conventional interpolation techniques fail to learn the complex AQ phenomena. Physics-based models require domain knowledge and pollution source data for AQ modeling. In this work, we propose a Gaussian processes based approach for estimating AQ. The important features of our approach are: a) a non-stationary (NS) kernel to allow input depended smoothness of fit; b) a Hamming distance-based kernel for categorical features; and c) a locally periodic kernel to capture temporal periodicity. We leverage batch-wise training to scale our approach to a large amount of data. Our approach outperforms the conventional baselines and a state-of-the-art neural attention-based approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:TIZ-Mc8IlK0C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Non-intrusive load monitoring (NILM) involves separating the household aggregate energy consumption into constituent appliances. In 2014, a toolkit called NILMTK was released towards making NILM reproducible. Subsequently, in 2019, an improved version called NILMTK-contrib, focused on experiments and ease of adding new algorithms was released. Since then, there have been significant advances in neural networks for various applications, and in the NILM domain. In this paper, we implement five recent neural network architectures for NILM in NILMTK-contrib and benchmark against existing algorithms. Further, in this paper, we also implement a dataset parser for a publicly available dataset called IDEAL containing 255 homes with 39 homes having appliance data. We find that the new algorithms are comparable or better than the state-of-the-art over a subset of the appliances.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:tYavs44e6CUC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Research shows that providing an appliance-wise energy breakdown can help users save up to 15% of their energy bills. Non-intrusive load monitoring (NILM) or energy disaggregation is the task of estimating the household energy measured at the aggregate level for each constituent appliances in the household. The problem was first was introduced in the 1980s by Hart. Over the past three decades, NILM has been an extensively researched topic by researchers. NILMTK was introduced in 2014 to the NILM community in order to motivate reproducible research. Even after the introduction of the NILMTK toolkit to the community, there has been a little contribution of recent state-of-the-art algorithms back to the toolkit. In this paper, we propose a new disaggregation API, which further simplifies the process for the rapid comparison of different state-of-the-art algorithms across a wide range of datasets and algorithms. We also propose a new rewrite for writing the new disaggregation algorithms for NILMTK, which is similar to Scikitlearn. We demonstrate the power of the new API by conducting various complex experiments using the API.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:uWiczbcajpAC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Air pollution is a global challenge for cities across the globe. Understanding the public perception of air pollution can help policymakers engage better with the public and appropriately introduce policies. Accurate public perception can also help people to identify the health risks of air pollution and act accordingly. Unfortunately, current techniques for determining perception are not scalable: it involves surveying few hundred people with questionnaire-based surveys. Using the advances in natural language processing (NLP), we propose a more scalable solution called Vartalaap to gauge public perception of air pollution via the microblogging social network Twitter. We curated a dataset of more than 1.2M tweets discussing Delhi-specific air pollution. We find that (unfortunately) the public is supportive of unproven mitigation strategies to reduce pollution, thus risking their health due to a false sense of security. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:g3aElNc5_aQC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"In this notes paper, we present an open problem to the Buildsys community: energy data super-resolution, referring to the task of estimating the power consumption of a home at a higher resolution given the low-resolution power consumption. Super-resolution is especially useful when the smart meters collect data at a very low-sampling rate owing to a plethora of issues such as bandwidth, pricing, old hardware, among others. The problem is motivated by the success of image super resolution in the computer vision community. In this paper, we formally introduce the problem and present baseline methods and the algorithms we used to ""solve"" this problem. We evaluate the performance of the algorithms on a real-world dataset and discuss the results. We also discuss what makes this problem hard and why a trivial baseline is hard to beat.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:vbGhcppDl1QC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Sensing is central to the SenSys and related communities. However, fine-grained spatial sensing remains a challenge despite recent advancements, owing to cost, maintenance, among other factors. Thus, estimating the sensed phenomenon at unmonitored locations and strategically installing sensors is of prime importance. In this work, we introduce Polire - an open-source tool that provides a suite of algorithms for spatial interpolation and near-field passive sensor placements. We replicate two existing papers on these two tasks to show the efficacy of Polire. We believe that Polire is an essential step towards lowering entry barriers towards sensing and scientific reproducibility.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:ILKRHgRFtOwC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Given the pandemic and the high air pollution in large parts of the world, masks have become ubiquitous. In this poster, we present our vision and work-in-progress (WIP) towards leveraging the ubiquity of masks for health sensing and persuasion. We envision masks to monitor health-related parameters such as i) temperature; ii) lung activity, among others. We also envision that retrofitting masks with sensors and display to show localized pollution can create awareness about air pollution. In this WIP, we present a smart mask, Naqaab1, that measures forced vital capacity (FVC) of the lung using a retrofitted microphone. We evaluated the measured lung parameter on eight persons using an Incentive Spirometer2 and found that our smart mask accurately measures incentive lung capacity. Naqaab also measures pollution exposure and indicates via different LED colours. We envision using such a system for eco …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:4MWp96NkSFoC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Deep learning-based innovations, particularly GANs, have recently shown great success in fashion modelling for various use cases such as pose and face generation. A famous work, FashionGAN[1], can generate images with modified clothing as per natural language description and uses the DeepFashion dataset, which primarily contains clothing styles of the Western countries. Currently, no dataset caters to Indian style and clothing. Hence, we present a dataset of 12k images and descriptions pertaining to the Indian culture as well as a baseline approach with this work. Deep learning-based innovations in the Indian Fashion context are a relatively new area of research, and we hope our work will be a starting point for other researchers. Code and Dataset: https://github.com/ronakkaoshik42/Generative_fashion",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:hMsQuOkrut0C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"According to the World Health Organisation (WHO), 235 million people suffer from respiratory illnesses which causes four million deaths annually. Regular lung health monitoring can lead to prognoses about deteriorating lung health conditions. This article presents our system SpiroMask that retrofits a microphone in consumer-grade masks (N95 and cloth masks) for continuous lung health monitoring. We evaluate our approach on 48 participants (including 14 with lung health issues) and find that we can estimate parameters such as lung volume and respiration rate within the approved error range by the American Thoracic Society (ATS). Further, we show that our approach is robust to sensor placement inside the mask.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:kuK5TVdYjLIC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Respiration rate is a vital sign to predict cardiac arrest, apnea, dyspnea and lung ailments. Past research has largely focused on sensing respiration rate in a controlled environment with participants at rest. But disease prognosis requires continuous everyday-life monitoring of respiration rate. In this work, we demonstrate how CO2 sensor placed inside N95 mask can detect respiration rate during motion as well as rest with a better or comparable performance compared to previous work. Our system weighs 16 grams, runs uninterrupted for 2 hours, generalises across participants, does not require any learning algorithm and is reproducible.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:M7yex6snE4oC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"COVID-19 has severely impacted millions of lives around the world. In this note, we explore the impact of COVID-19 on the electricity consumption of 93 households across two tier-2 cities in India. Given the work from home restrictions, we would expect electricity consumption to increase as people spend more time at home. Contrary to the expectations, we found that electricity consumption decreased during the lockdown as compared to previous years. On further follow-up with households, we found several reasons for decreased usage: i) inability to get air conditioners serviced due to movement restriction, ii) advisories on minimising AC usage, and iii) reducing energy to compensate for reduced income.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:L7CI7m0gUJcC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Residential homes constitute roughly one-fourth of the total energy usage worldwide. Providing appliance-level energy breakdown has been shown to induce positive behavioral changes that can reduce energy consumption by 15%. Existing approaches for energy breakdown either require hardware installation in every target home or demand a large set of energy sensor data available for model training. However, very few homes in the world have installed sub-meters (sensors measuring individual appliance energy); and the cost of retrofitting a home with extensive sub-metering eats into the funds available for energy saving retrofits. As a result, strategically deploying sensing hardware to maximize the reconstruction accuracy of sub-metered readings in non-instrumented homes while minimizing deployment costs becomes necessary and promising. In this work, we develop an active learning solution based on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:j8SEvjWlNXcC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Non-intrusive load monitoring (NILM) refers to the task of disaggregating total household power consumption into the constituent appliances. In recent years, various neural network (NN) based approaches have emerged as state-of-the-art for NILM. In conventional settings, NN(s) provide point estimates for appliance power. In this paper, we explore the question - can we learn models that tell when they are unsure? Or, in other words, can we learn models that provide uncertainty estimates? We explore recent advances in uncertainty for NN(s), evaluate 14 model variants on the publicly available REDD dataset, and find that our models can accurately estimate uncertainty without compromising on traditional metrics. We also find that different appliances in their different states have varying performance of uncertainty. We also propose ""recalibration"" methods and find they can improve the uncertainty estimation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:k8Z6L05lTy4C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"In this paper, we present novel variations of an earlier approach called homogeneous clustering algorithm for reducing dataset size. The intuition behind the approaches proposed in this paper is to partition the dataset into homogeneous clusters and select some images which contribute significantly to the accuracy. Selected images are the proper subset of the training data and thus are human-readable. We propose four variations upon the baseline algorithm-RHC. The intuition behind the first approach, RHCKON, is that the boundary points contribute significantly towards the representation of clusters. It involves selecting k farthest and one nearest neighbour of the centroid of the clusters. In the following two approaches (KONCW and CWKC), we introduce the concept of cluster weights. They are based on the fact that larger clusters contribute more than smaller sized clusters. The final variation is GHCIDR which selects points based on the geometrical aspect of data distribution. We performed the experiments on two deep learning models- Fully Connected Networks (FCN) and VGG1. We experimented with the four variants on three datasets- MNIST, CIFAR10, and Fashion-MNIST. We found that GHCIDR gave the best accuracy of 99.35%, 81.10%, and 91.66% and a training data reduction of 87.27%, 32.34%, and 76.80% on MNIST, CIFAR10, and Fashion-MNIST respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:lmc2jWPfTJgC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Air pollution killed 1.67M people in India in 2019. Previous work has shown that accurate public perception can help people identify the health risks of air pollution and act accordingly. News media influence how the public defines a social problem. However, news media analysis on air pollution has been on a small scale and regional. In this work, we gauge print news media response to air pollution in India on a larger scale. We curated a dataset of 17.4K news articles on air pollution from two leading English daily newspapers spanning 11 years. We performed exploratory data analysis and topic modeling to reveal the news media response to air pollution. Our study shows that, although air pollution is a year-long problem in India, the news media limelight on the issue is periodic (temporal bias). News media prefer to focus on the air pollution issue of metropolitan cities rather than the cities which are worst hit by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:MLfJN-KU85MC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"The development of the fashion industry has increased the demand for customised and meticulously designed clothes. This poses a challenge to fashion designers who need to create novel clothing designs based on the requirements specified by the customers. This work presents a generative adversarial network (GAN) based text-to-image synthesis model for fabricating intricate Indian apparel designs. We introduce an architecture that strategically combines multiple trained GAN models for a streamlined text-to-image generation. Existing fashion datasets with elaborate image descriptions cater to western fashion only. We have extracted traditional Indian images like kurtis, kurtas, etc., and then combined with an existing dataset to create an Indian Fashion dataset of around 16000 images with their corresponding text descriptions. On carrying out elaborate testing on our dataset we have achieved good visual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:gsN89kCJA0AC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Ambient fine particulate (PM2.5) is the most significant risk factor for premature death, shortening life expectancy at birth by 1.5 to 1.9 years [2]. 91% of the world's population lives in areas where air pollution exceeds safety limits1. 99% of the people in countries like India, Pakistan, Nepal, and Bangladesh experience ambient exposures of PM2.5 exceeding 75 μg/m3 to 100 μg/m3 [3]. My Ph.D. thesis will be on understanding the perception of air pollution among people using social media data. I also intend to develop a wearable air pollution exposure monitor and design an air pollution visualisation tool to reduce the entry barrier for air pollution research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:ML0RJ9NH7IQC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"91% of the world's population lives in areas where air pollution exceeds safety limits1. Research has focused on monitoring ambient air pollution, but individual exposure to air pollution is not equal to ambient and is thus important to measure. Our work (in progress) measures individual exposures of different categories of people on an academic campus. We highlight some anecdotal findings and surprising insights from monitoring, such as a) Indoor CO2 concentration of 1.8 times higher than the permissible limit. Over 10 times the WHO limit of PM2.5 exposure during b) construction-related activities, and c) cooking (despite the use of exhaust). We also found that during transit, the PM2.5 exposure is at least two times higher than indoor. Our current work though in progress, already shows important findings affecting different people associated with an academic campus. In the future, we plan to do a more exhaustive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:Z5m8FVwuT1cC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Motivation: Recent years have seen a decline in air quality across the planet, with studies suggesting that a significant proportion of global population has reduced life expectancy by up to 4 years [1, 2, 5]. To tackle this increasing growth in air pollution and its adverse effects, governments across the world have set up air quality monitoring stations that measure concentrations of various pollutants like NO2, SO2 and PM2. 5, of which PM2. 5 especially has significant health impact and is used for measuring air quality. One major issue with the deployment of these stations is the massive cost involved. Owing to the high installation and maintenance costs, the spatial resolution of air quality monitoring is generally poor. In this current work, we propose active learning methods to choose the next location to install an air quality monitor, motivated by sparse spatial air quality monitoring and expensive sensing equipment …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:EkHepimYqZsC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Air pollution kills around 7 million people annually, and approximately 2.4 billion people are exposed to hazardous air pollution. Accurate, fine-grained air quality (AQ) monitoring is essential to control and reduce pollution. However, AQ station deployment is sparse, and thus air quality inference for unmonitored locations is crucial. Conventional interpolation methods fail to learn the complex AQ phenomena. This work demonstrates that Deep Gaussian Process models (DGPs) are a promising model for the task of AQ inference. We implement Doubly Stochastic Variational Inference, a DGP algorithm, and show that it performs comparably to the state-of-the-art models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:oNZyr7d5Mn4C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Non-intrusive load monitoring (NILM) or energy disaggregation aims to break down total household energy consumption into constituent appliances. Prior work has shown that providing an energy breakdown can help people save up to 15\% of energy. In recent years, deep neural networks (deep NNs) have made remarkable progress in the domain of NILM. In this paper, we demonstrate the performance of Gaussian Processes (GPs) for NILM. We choose GPs due to three main reasons: i) GPs inherently model uncertainty; ii) equivalence between infinite NNs and GPs; iii) by appropriately designing the kernel we can incorporate domain expertise. We explore and present the challenges of applying our GP approaches to NILM.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:WZBGuue-350C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Gaussian processes are Bayesian non-parametric models used in many areas. In this work, we propose a Non-stationary Heteroscedastic Gaussian process model which can be learned with gradient-based techniques. We demonstrate the interpretability of the proposed model by separating the overall uncertainty into aleatoric (irreducible) and epistemic (model) uncertainty. We illustrate the usability of derived epistemic uncertainty on active learning problems. We demonstrate the efficacy of our model with various ablations on multiple datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:kz9GbA2Ns4gC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"The computational resources required to train a model have been increasing since the inception of deep networks. Training neural networks on massive datasets have become a challenging and time-consuming task. So, there arises a need to reduce the dataset without compromising the accuracy. In this paper, we present novel variations of an earlier approach called reduction through homogeneous clustering for reducing dataset size. The proposed methods are based on the idea of partitioning the dataset into homogeneous clusters and selecting images that contribute significantly to the accuracy. We propose two variations: Geometrical Homogeneous Clustering for Image Data Reduction (GHCIDR) and Merged-GHCIDR upon the baseline algorithm - Reduction through Homogeneous Clustering (RHC) to achieve better accuracy and training time. The intuition behind GHCIDR involves selecting data points by cluster weights and geometrical distribution of the training set. Merged-GHCIDR involves merging clusters having the same labels using complete linkage clustering. We used three deep learning models- Fully Connected Networks (FCN), VGG1, and VGG16. We experimented with the two variants on four datasets- MNIST, CIFAR10, Fashion-MNIST, and Tiny-Imagenet. Merged-GHCIDR with the same percentage reduction as RHC showed an increase of 2.8%, 8.9%, 7.6% and 3.5% accuracy on MNIST, Fashion-MNIST, CIFAR10, and Tiny-Imagenet, respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:LI9QrySNdTsC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"In India, residential power consumption accounts for a quarter of the country’s total consumption. With increasing disposable income and living standards and indeed warming conditions, demand for cooling through the use of air conditioners, is expected to rise and with it the peak demand. There is a new opportunity to manage the growth of this demand by first identifying the contribution of various end-uses to peak demand and supporting uptake of energy efficient equipment and influencing behavior concerning the use of cooling equipment. The information that is currently available from conventional meters and the frequency of collection is not sufficient to enable such analyses. With the help of high-frequency data from smart meters, electricity utilities can identify customers driving the peak demand and respond suitably. We demonstrate this with the help of data from 93 smart meters deployed in a sample of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:tuHXwOkdijsC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:b1wdh0AR-JQC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Large scale campus deployments in the past have resulted in energy conservation measures, data validation, and software architectures. Inspired by the success and learnings from such previous deployments, we present our work on deployment involving sensing various aspect of campus sustainability like water, electricity, solar produce, air quality, and parking lot occupancy. Our full deployment spanned more 171 days. We used 469 sensors, collecting a maximum of 190 MB of data daily. We discuss the deployment challenges and the learnings obtained from them. We address the data collection challenges by providing best practices measures and provide insights from the installation of wireless radio communication modules. Our deployment can act as a reconnaissance guide for campus deployment, especially in developing countries.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:p__nRnzSRKYC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Recent years have seen a decline in air quality across the planet, with studies suggesting that air pollution is a significant cause of death. Governments have set up large scale air quality monitoring stations to aid them in formulating policies for air quality. However, these air quality stations are expensive to install, and have thus been often sparsely deployed. Motivated by sparse air quality monitoring and the expensive cost of air quality monitoring stations, we propose an active learning based solution to recommend locations to install air quality monitoring stations. We use a Gaussian Processes based approach for this purpose, motivated by their ability to encode prior knowledge using custom kernels. We demonstrate via extensive experimentation that our proposed approach outperforms several baselines on a publicly available dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:vDijr-p_gm4C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Motivation Studies have shown that consumers of electricity can save up 15% of their bills when provided with a detailed appliance wise feedback [1]. Energy super-resolution refers to estimating energy usage at a higher-sampling rate from the lower sampling rate. We mainly focus on predicting the hourly reading of a home, using the daily usage (which can be noted down by the users from the meter). This predicted usage can be used by the consumers to identify the times of the day, which are contributing more to electricity usage and help them optimize their usage. This is analogous to image superresolution, where the zooming out factor equals 24. Problem definition",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:zLWjf1WUPmwC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Motivation: Air pollution is measured by the amount of PM2. 5 the air contains. These are fine particles with a diameter less than 2.5 micrometres that can penetrate deep into the lungs and trigger severe respiratory diseases. The concentration of PM2. 5 in the air can be measured using ground-based monitoring stations, but there is a considerable deficit in the number of stations required for reliable measurements as air quality varies spatially and temporally across a given region. Given the non-trivial costs of installing and maintaining ground-based PM2. 5 sensors, previous research has looked at using satellite retrievals for estimating PM2. 5 data from visual features.
Problem Statement: The goal is to predict PM2. 5 from aerosol optical thickness (AOT), which is a measure of how much light is attenuated by the aerosols (eg haze, smoke particles, desert dust) as it passes the atmosphere. Previous studies have …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:ipzZ9siozwsC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",20,"Motivation From 2010 to 2040, the world’s total energy requirement will increase by 56%[1]. Solar energy is among the largest sources of renewable energy in the world. At the current rate, by 2050, solar energy will contribute approximately 20% of the total energy requirement in the world [2]. One of the drawbacks with solar energy is its high dependence on various meteorological conditions such as temperature, humidity, cloud cover; due to which the produced energy is highly volatile and intermittent. Accurately forecasting solar energy production is an important step towards reducing reliance on non-renewable resources.
Problem Statement Our aim is to accurately forecast the solar produce yt+ K, K timestamps in the future given historical solar produce {y1, y2,..., yt} and historical and forecasted meteorological data,{M1, M2,..., Mt,.., Mt+ K}, where M∈ Rd corresponding to d meteo-",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&citation_for_view=rFGzHlIAAAAJ:uc_IGeMz5qoC,https://nipunbatra.github.io/
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Social media conversations unfold based on complex interactions between users, topics and time. While recent models have been proposed to capture network strengths between users, users' topical preferences and temporal patterns between posting and response times, interaction patterns between topics has not been studied. We propose the Hidden Markov Hawkes Process (HMHP) that incorporates topical Markov Chains within Hawkes processes to jointly model topical interactions along with user-user and user-topic patterns. We propose a Gibbs sampling algorithm for HMHP that jointly infers the network strengths, diffusion paths, the topics of the posts as well as the topic-topic interactions. We show using experiments on real and semi-synthetic data that HMHP is able to generalize better and recover the network strengths, topics and diffusion paths more accurately than state-of-the-art baselines. More …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:43LB_KcVqeAC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"We study the effect of norm based regularization on the size of coresets for regression problems. Specifically, given a matrix with and a vector and , we analyze the size of coresets for regularized versions of regression of the form . Prior work has shown that for ridge regression (where ) we can obtain a coreset that is smaller than the coreset for the unregularized counterpart ie least squares regression\cite {avron2017sharper}. We show that when , no coreset for regularized regression can have size smaller than the optimal coreset of the unregularized version. The well known lasso problem falls under this category and hence does not allow a coreset smaller than the one for least squares regression. We propose a modified version of the lasso problem and obtain for it a coreset of size smaller than the least square regression. We empirically show that the modified version of lasso also induces sparsity in solution, similar to the original lasso. We also obtain smaller coresets for regression with regularization. We extend our methods to multi response regularized regression. Finally, we empirically demonstrate the coreset performance for the modified lasso and the regression with regularization.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:bFuYayV9R1gC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"The classic Mallows model is a widely-used tool to realize distributions on per-mutations. Motivated by common practical situations, in this paper, we generalize Mallows to model distributions on top-k lists by using a suitable distance measure between top-k lists. Unlike many earlier works, our model is both analytically tractable and computationally efficient. We demonstrate this by studying two basic problems in this model, namely, sampling and reconstruction, from both algorithmic and experimental points of view.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:uoeYKOKFegwC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Factorizing tensors has recently become an important optimization module in a number of machine learning pipelines, especially in latent variable models. We show how to do this efficiently in the streaming setting. Given a set of vectors, each in , we present algorithms to select a sublinear number of these vectors as coreset, while guaranteeing that the CP decomposition of the -moment tensor of the coreset approximates the corresponding decomposition of the -moment tensor computed from the full data. We introduce two novel algorithmic techniques: online filtering and kernelization. Using these two, we present four algorithms that achieve different tradeoffs of coreset size, update time and working space, beating or matching various state of the art algorithms. In the case of matrices (2-ordered tensor), our online row sampling algorithm guarantees relative error spectral approximation. We show applications of our algorithms in learning single topic modeling.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:0qX8s2k1IRwC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Named entity disambiguation (NED) is a central problem in information extraction. The goal is to link entities in a knowledge graph (KG) to their mention spans in unstructured text. Each distinct mention span (like John Smith, Jordan or Apache) represents a multi-class classification task. NED can therefore be modeled as a multitask problem with tens of millions of tasks for realistic KGs. We initiate an investigation into neural representations, network architectures, and training protocols for multitask NED. Specifically, we propose a task-sensitive representation learning framework that learns mention dependent representations, followed by a common classifier. Parameter learning in our framework can be decomposed into solving multiple smaller problems involving overlapping groups of tasks. We prove bounds for excess risk, which provide additional insight into the problem of multi-task representation learning. While remaining practical in terms of training memory and time requirements, our approach outperforms recent strong baselines, on four benchmark data sets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:S0CDQJw8Yr4C,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Many modern applications of AI such as web search, mobile browsing, image processing, and natural language processing rely on finding similar items from a large database of complex objects. Due to the very large scale of data involved (e.g., users’ queries from commercial search engines), computing such near or nearest neighbors is a non-trivial task, as the computational cost grows significantly with the number of items. To address this challenge, we adopt Locality Sensitive Hashing (a.k.a, LSH) methods and evaluate four variants in a distributed computing environment (specifically, Hadoop). We identify several optimizations which improve performance, suitable for deployment in very large scale settings. The experimental results demonstrate our variants of LSH achieve the robust performance with better recall compared with “vanilla” LSH, even when using the same amount of space.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:plAW456RD7MC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Random projection (RP) is a powerful dimension reduction technique widely used in analysis of high dimensional data. We demonstrate how this technique can be used to improve the computational efficiency of gravitational wave searches from compact binaries of neutron stars or black holes. Improvements in low-frequency response and bandwidth due to detector hardware upgrades pose a data analysis challenge in the advanced LIGO era as they result in increased redundancy in template databases and longer templates due to a higher number of signal cycles in band. The RP-based methods presented here address both these issues within the same broad framework. We first use RP for an efficient, singular value decomposition-inspired template matrix factorization and develop a geometric intuition for why this approach works. We then use RP to calculate approximate time-domain correlations in a lower …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:Wqn_fehR_TUC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Curriculum learning is a training strategy that sorts the training examples by some measure of their difficulty and gradually exposes them to the learner to improve the network performance. Motivated by our insights from implicit curriculum ordering, we first introduce a simple curriculum learning strategy that uses statistical measures such as standard deviation and entropy values to score the difficulty of data points for real image classification tasks. We empirically show its improvements in performance with convolutional and fully-connected neural networks on multiple real image datasets. We also propose and study the performance of a dynamic curriculum learning algorithm. Our dynamic curriculum algorithm tries to reduce the distance between the network weight and an optimal weight at any training step by greedily sampling examples with gradients that are directed towards the optimal weight. Further, we use our algorithms to discuss why curriculum learning is helpful.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:lL5f5cZgq8MC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Low-latency gravitational wave search pipelines such as GstLAL take advantage of low-rank factorization of the template matrix via singular value decomposition (SVD). With unprecedented improvements in detector bandwidth and sensitivity in advanced-LIGO and Virgo detectors, one expects several orders of magnitude increase in the size of template banks. This poses a formidable computational challenge in factorizing huge template matrices. Previously, [in Kulkarni et al. [6]], we introduced the idea of random projection (RP)-based matrix factorization as a computationally viable alternative to SVD, applicable for large template banks. This follow-up paper demonstrates the application of a block-wise randomized matrix factorization (RMF) algorithm for computing low-rank factorizations at a preset average fractional loss of SNR. This new scheme is shown to be more efficient in the context of the LLOID framework of the GstLAL search pipeline. Further, it is well-known that for huge template banks, the total computational cost of the search is dominated by reconstructing the detection statistic compared to that of filtering the data. However, optimizing the reconstruction cost has not been addressed satisfactorily so far in the available literature. We show that it is possible to approximately reconstruct the time-series of the matched-filter detection statistic at a fraction of the total cost using the matching pursuit algorithm. Combining the two algorithms presented in this paper can handle online searches involving large template banks more efficiently. We have analyzed the total computational cost in detail and offer various tips for optimally applying the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:xEMdJR0kL_sC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"We present algorithms that create coresets in an online setting for clustering problems according to a wide subset of Bregman divergences. Notably, our coresets have a small additive error, similar in magnitude to the lightweight coresets Bachem et. al. 2018, and take update time for every incoming point where is dimension of the point. Our first algorithm gives online coresets of size for -clusterings according to any -similar Bregman divergence. We further extend this algorithm to show existence of a non-parametric coresets, where the coreset size is independent of , the number of clusters, for the same subclass of Bregman divergences. Our non-parametric coresets are larger by a factor of ( is number of points) and have similar (small) additive guarantee. At the same time our coresets also function as lightweight coresets for non-parametric versions of the Bregman clustering like DP-Means. While these coresets provide additive error guarantees, they are also significantly smaller (scaling with as opposed to for points in $\~R^d$) than the (relative-error) coresets obtained in Bachem et. al. 2015 for DP-Means. While our non-parametric coresets are existential, we give an algorithmic version under certain assumptions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:qt-6tCTBDsQC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Introduction: Adnexal torsion contributes to 2.7-7.4% of all gynaecological emergencies and delayed or misdiagnosis results in loss of ovarian function. Diagnosis is not straight forward, both clinically and radiologically, and it can be confused with a number of other surgical and gynaecological emergencies. Aim: The aim of the present study was to correctly identify ovarian torsion among different cyst accidents, its overall incidence, the types of surgery involved and the histopathological diagnoses of the twisted adnexal masses in a prospective observation over two years. Materials and Methods: The clinical scoring was used in one group (n= 14) and its reliability was assessed in correct identification of adnexal torsion by comparing with another group without the scoring (n= 12). This scoring was developed in an Institute in Paris in (2000-04) using logistic regression model to select a combination of five best …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:QlnOKEPDpKwC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"A real-valued set function is (additively) approximately submodular if it satisfies the submodularity conditions with an additive error. Approximate submodularity arises in many settings, especially in machine learning, where the function evaluation might not be exact. In this paper we study how close such approximately submodular functions are to truly submodular functions. We show that an approximately submodular function defined on a ground set of n elements is O (n 2) pointwise-close to a submodular function. This result also provides an algorithmic tool that can be used to adapt existing submodular optimization algorithms to approximately submodular functions. To complement, we show an Ω (n) lower bound on the distance to submodularity. These results stand in contrast to the case of approximate modularity, where the distance to modularity is a constant, and approximate convexity, where the distance to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:yeKNu01O_4gC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Infectious or contagious diseases can be transmitted from one person to another through social contact networks. In today’s interconnected global society, such contagion processes can cause global public health hazards, as exemplified by the ongoing Covid-19 pandemic. It is therefore of great practical relevance to investigate the network transmission of contagious diseases from the perspective of statistical inference. An important and widely studied boundary condition for contagion processes over networks is the so-called epidemic threshold. The epidemic threshold plays a key role in determining whether a pathogen introduced into a social contact network will cause an epidemic or die out. In this paper, we investigate epidemic thresholds from the perspective of statistical network inference. We identify two major challenges that are caused by high computational and sampling complexity of the epidemic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:wE8AsS3ykUMC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"In this paper we present coresets for Fair Regression with Statistical Parity (SP) constraints and for Individually Fair Clustering. Due to the fairness constraints, the classical coreset definition is not enough for these problems. We first define coresets for both the problems. We show that to obtain such coresets, it is sufficient to sample points based on the probabilities dependent on combination of sensitivity score and a carefully chosen term according to the fairness constraints. We give provable guarantees with relative error in preserving the cost and a small additive error in preserving fairness constraints for both problems. Since our coresets are much smaller in size as compared to n, the number of points, they can give huge benefits in computational costs (from polynomial to polylogarithmic in n), especially when n≫ d, where d is the input dimension. We support our theoretical claims with experimental evaluations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:YXPZ0dOdYS4C,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"We present algorithms that create coresets in an online setting for clustering problems based on a wide subset of Bregman divergences. Notably, our coresets have a small additive error, similar in magnitude to the gap between expected and empirical loss (Bachem et. al. 2017), and take update time for every incoming point where is the dimension of the point. Our first algorithm gives online coresets of size for -clusterings according to any -similar Bregman divergence. We further extend this algorithm to show the existence of non-parametric coresets, where the coreset size is independent of , the number of clusters, for the same subclass of Bregman divergences. Our non-parametric coresets also function as coresets for non-parametric versions of the Bregman clustering like DP-Means. While these coresets provide additive error guarantees, they are significantly smaller for high dimensional data than the (relative-error) coresets obtained in (Bachem et. al 2015) for DP-Means--- for the input of size our coresets grow as while being independent of as opposed to for points in $\~R^d$ (Bachem et. al 2015). We also present experiments to compare the performance of our algorithms with other sampling techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:b8m_4JuPjscC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"We address the problem of modeling bursty diffusion of text-based events over a social network of user nodes. The purpose is to recover, disentangle and analyze overlapping social conversations from the perspective of user-topic preferences, user-user connection strengths and, importantly, topic transitions. For this, we propose a Dual-Network Hawkes Process (DNHP), which executes over a graph whose nodes are user-topic pairs, and closeness of nodes is captured using topic-topic, a user-user, and user-topic interactions. No existing Hawkes Process model captures such multiple interactions simultaneously. Additionally, unlike existing Hawkes Process based models, where event times are generated first, and event topics are conditioned on the event times, the DNHP is more faithful to the underlying social process by making the event times depend on interacting (user, topic) pairs. We develop a Gibbs …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:pcWPcJyQGiUC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"We address the problem of large scale real-time classification of content posted on social networks, along with the need to rapidly identify novel spam types. Obtaining manual labels for user-generated content using editorial labeling and taxonomy development lags compared to the rate at which new content type needs to be classified. We propose a class of hierarchical clustering algorithms that can be used both for efficient and scalable real-time multiclass classification as well as in detecting new anomalies in user-generated content. Our methods have low query time, linear space usage, and come with theoretical guarantees with respect to a specific hierarchical clustering cost function (Dasgupta, 2016). We compare our solutions against a range of classification techniques and demonstrate excellent empirical performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:KYgttONoxcsC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Guanine nucleotide binding proteins are characterized by a structurally and mechanistically conserved GTP-binding domain, indispensable for binding GTP. The G domain comprises of five adjacent consensus motifs called G boxes, which are separated by amino acid spacers of different lengths. Several G proteins, discovered over time, are characterized by diverse function and sequence. This sequence diversity is also observed in the G box motifs (specifically the G5 box) as well as the inter-G box spacer length. The Spacers and Mismatch Algorithm (SMA) introduced in this study, can predict G-domains in a given G protein sequence, based on user-specified constraints for approximate G-box patterns and inter-box gaps in each G protein family. The SMA parameters can be customized as more G proteins are discovered and characterized structurally. Family-specific G box motifs including the less characterized G5 motif as well as G domain boundaries were predicted with higher precision. Overall, our analysis suggests the possible classification of G protein families based on family-specific G box sequences and lengths of inter-G box spacers.
Significance Statement
It is difficult to define the boundaries of a G domain as well as predict G boxes and important GTP-binding residues of a G protein, if structural information is not available. Sequence alignment and phylogenetic methods are often unsuccessful, given the sequence diversity across G protein families. SMA is a unique method which uses approximate pattern matching as well as inter-motif separation constraints to predict the locations of G-boxes. It is able to predict all G boxes including …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:f13iAvnbnnYC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Near isometric orthogonal embeddings to lower dimensions are a fundamental tool in data science and machine learning. In this paper, we present the construction of such embeddings that minimizes the maximum distortion for a given set of points. We formulate the problem as a non convex constrained optimization problem. We first construct a primal relaxation and then use the theory of Lagrange duality to create a dual relaxation. We also suggest a polynomial time algorithm based on the theory of convex optimization to solve the dual relaxation provably. We provide a theoretical upper bound on the approximation guarantees for our algorithm, which depends only on the spectral properties of the dataset. We experimentally demonstrate the superiority of our algorithm compared to baselines in terms of the scalability and the ability to achieve lower distortion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:dj1AAMDQi3QC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"With its rising fatality rates, oral cancer is one of the most concerning public health issues. To reduce disease-related mortality and morbidity, advancements in screening and detection are critical. Finding specific biomarkers is one of the most successful approaches for screening, diagnosing, and staging this dreadful disease. In this study differentially expressed genes associated with oral cancer were analyzed using RNASeq to find the potential biomarkers. Functional enrichment of upregulated genes found that 253 genes were present in the plasma membrane. Three clusters were formed using KMean Clustering from the PPI networks, and highly connected hub genes were identified from each cluster. Eventually, expression and survival analyses of hub genes were performed using The Cancer Genome Atlas (TCGA) database targeting Head and Neck Squamous Cell Carcinoma. Among those genes, expression levels of eight genes SLC2A1, ITGA6, LAMC2, COL1A2, COL1A1, TNC, THY1, and CD276 have significantly changed in Head and Neck Squamous cell carcinoma. There are reports that suggest these genes were significantly dysregulated in Oral Squamous cell carcinoma and can be explored further as potential biomarkers for margin clearance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:TuM7UPshZo8C,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Aims
To assess whether chemotherapy response score (CRS) is associated with surgical end-result in interval debulking surgery (IDS) for tubo-ovarian cancer patients and determine its prognostic significance.
Background
CRS is a histopathological three-tier score for assessing tumour regression in omentectomy specimens after neoadjuvant chemotherapy (NACT), and original study concluded that prognostically, CRS is more important than completeness of cytoreduction (CC) in IDS. This has not been proved by other validation studies. There is a conflict in evidence regarding significance of improvement of overall survival (OS) with CRS-3 in available literature. Evidence of association of CRS with radiological and biochemical (CA-125 decline) response is lacking and conflicting.
Methods
Patients who underwent …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:WsFh9Szeq2wC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"In this paper, we show that for a fixed k, there is an NC algorithm that separates the graphs of rank-width at most k from those with rank-width at least 3 k+ 1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:Q_E8KsG3g9MC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Increased bandwidth and improved sensitivity at low frequencies in the advanced LIGO/Virgo detectors have led to a vast increase in the number of templates against which data is cross correlated. It has also resulted in longer template waveforms. Both of these effects have amplified the computational cost of the gravitational wave (GW) searches from compact binary systems by several orders of magnitude. In a seminal work, Hanna, Canon et al. have validated the use of the singular value decomposition (SVD) method to deal with a large number of templates. However, performing SVD on large matrices in situ has severe memory and logistical challenges. Random matrix factorization is an efficient technique for low-rank approximation of such large template matrices, where the templates are randomly projected into a much lower dimensional space. The basis vectors in the projected space are obtained by QR …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:pYRxIbzCxX0C,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",30,"Compact-binary coalescences are an important class of sources for the advanced-LIGO detectors. Improved sensitivity at low frequencies and increased bandwidth of the advanced-LIGO and Virgo detectors has resulted in a vast increase in the number of templates to cover the deemed parameter space covering target mass and spin ranges. Further, it has also led to longer template waveforms used for matched-filtering based searches. These in-turns amplify the computational cost of the gravitational wave searches by several orders of magnitude. Random matrix factorization is an efficient technique for the low-rank approximation of a given large template matrix by projecting the template waveforms into a much lower dimensional space. We report the application of such a technique to reduce the high computational costs of adv-LIGO CBC searches. We demonstrate that one can efficiently factorize large template …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&citation_for_view=plJC8R0AAAAJ:kiex5tMzGo8C,http://sites.google.com/site/anirbandasgupta
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"The Coalitional Manipulation problem has been studied extensively in the literature for many voting rules. However, most studies have focused on the complete information setting, wherein the manipulators know the votes of the non-manipulators. While this assumption is reasonable for purposes of showing intractability, it is unrealistic for algorithmic considerations. In most real-world scenarios, it is impractical to assume that the manipulators to have accurate knowledge of all the other votes. In this work, we investigate manipulation with incomplete information. In our framework, the manipulators know a partial order for each voter that is consistent with the true preference of that voter. In this setting, we formulate three natural computational notions of manipulation, namely weak, opportunistic, and strong manipulation. We say that an extension of a partial order is viable if there exists a manipulative vote for that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&citation_for_view=XFgieDYAAAAJ:iH-uZ7U-co4C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"The notion of robustness in the context of committee elections was introduced by Bredereck et al. [SAGT 2018] [2] to capture the impact of small changes in the input preference orders, depending on the voting rules used. They show that for certain voting rules, such as Chamberlin-Courant, checking if an election instance is robust, even to the extent of a small constant, is computationally hard. More specifically, it is NP-hard to determine if one swap in any of the votes can change the set of winning committees with respect to the Chamberlin-Courant voting rule. Further, the problem is also -hard when parameterized by the size of the committee, k. We complement this result by suggesting an algorithm that is in with respect to k. We also show that on nearly-structured profiles, the problem of robustness remains NP-hard. We also address the case of approval ballots, where we show a hardness result …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:M3NEmzRMIkIC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"Consider a graph and a coloring c of vertices with colors from . A vertex v is said to be happy with respect to c if for all neighbors u of v. Further, an edge (u, v) is happy if . Given a partial coloring c of V, the Maximum Happy Vertex (Edge) problem asks for a total coloring of V extending c to all vertices of V that maximizes the number of happy vertices (edges). Both problems are known to be NP-hard in general even when , and is polynomially solvable when . In [IWOCA 2016] it was shown that both problems are polynomially solvable on trees, and for arbitrary k, it was shown that MHE is NP-hard on planar graphs and is parameterized by the number of precolored vertices and branchwidth.
We continue the study of this problem from a parameterized perspective. Our focus is on both structural and standard parameterizations. To begin with, we establish that the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:ZHo1McVdvXMC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"Approval voting provides an opportunity for the agents to make a comment about every candidate, without incurring the overhead of determining a full ranking on the entire set of candidates. This makes approval voting a natural choice for many practical applications. In this work, we focus on the use of approval voting for selecting a committee in scenarios where we can have few outrageous voters whom we call outliers. More specifically, we study the computational complexity of the committee selection problem for commonly used approval-based voting rules in the presence of outliers. Our first result shows that outliers render the committee selection problem intractable for approval, net approval, and minisum approval voting rules. We next study the parameterized complexity of this problem with five natural parameters, namely the target score, the size of the committee (and its dual parameter namely the number of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:JV2RwH3_ST0C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We study the parameterized complexity of the Optimal Defense and Optimal Attack problems in voting. In both the problems, the input is a set of voter groups (every voter group is a district consisting of a set of votes) and two integers k a and k d corresponding to respectively the number of voter groups the attacker can attack and the number of voter groups the defender can defend. A voter group gets removed from the election if it is attacked but not defended. In the Optimal Defense problem, we want to know if it is possible for the defender to commit to a strategy of defending at most k d voter groups such that, no matter which k a voter groups the attacker attacks, the outcome of the election does not change. In the Optimal Attack problem, we want to know if it is possible for the attacker to commit to a strategy of attacking k a voter groups such that, no matter which k d voter groups the defender defends, the outcome of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:2P1L_qKh6hAC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We study the question of finding a set of at most k edges, whose removal makes the input n-vertex graph a disjoint union of s-clubs (graphs of diameter s). Komusiewicz and Uhlmann [DAM 2012] showed that Cluster Edge Deletion (ie, for the case of 1-clubs (cliques)), cannot be solved in time 2 o (k) n O (1) unless the Exponential Time Hypothesis (ETH) fails. But, Fomin et al.[JCSS 2014] showed that if the number of cliques in the output graph is restricted to d, then the problem (d-Cluster Edge Deletion) can be solved in time O (2 O (d k)+ m+ n). We show that assuming ETH, there is no algorithm solving 2-Club Cluster Edge Deletion in time 2 o (k) n O (1). Further, we show that the same lower bound holds in the case of s-Club d-Cluster Edge Deletion for any s≥ 2 and d≥ 2.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:QIV2ME_5wuYC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"The Chamberlin-Courant and Monroe rules are fundamental and well-studied rules in the literature of multi-winner elections. The problem of determining if there exists a committee of size k that has a Chamberlin-Courant (respectively, Monroe) score of at most r is known to be NP-complete. We consider the following natural problems in this setting: a) given a committee S of size k as input, is it an optimal k-sized committee, and b) given a candidate c and a committee size k, does there exist an optimal k-sized committee that contains c? In this work, we resolve the complexity of both problems for the Chamberlin-Courant and Monroe voting rules in the settings of rankings as well as approval ballots. We show that verifying if a given committee is optimal is coNP-complete whilst the latter problem is complete for . We also demonstrate efficient algorithms for the second problem when the input consists of single-peaked rankings. Our contribution fills an essential gap in the literature for these important multi-winner rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:a0OBvERweLwC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We consider the problem of matching reconfiguration, where we are given two matchings and in a graph G and the goal is to determine if there exists a sequence of matchings , such that , all consecutive matchings differ by exactly two edges (specifically, any matching is obtained from the previous one by the addition and deletion of one edge), and . It is known that the existence of such a sequence can be determined in polynomial time [5].
We extend the study of reconfiguring matchings to account for the length of the reconfiguration sequence. We show that checking if we can reconfigure to in at most steps is NP-hard, even when the graph is unweighted, bipartite, and the maximum degree is four, and the matchings and are maximum matchings. We propose two simple algorithmic approaches, one of which improves on the brute-force running time …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:GnPB-g6toBAC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"Given a set R of red points and a set B of blue points in the plane, the Red-Blue point separation problem asks if there are at most k lines that separate R from B, that is, each cell induced by the lines of the solution is either empty or monochromatic (containing points of only one color). A common variant of the problem is when the lines are required to be axis-parallel. The problem is known to be NP-complete for both scenarios, and W[1]-hard parameterized by k in the former setting and FPT in the latter. We demonstrate a polynomial-time algorithm for the special case when the points lie on a circle. Further, we also demonstrate the W-hardness of a related problem in the axis-parallel setting, where the question is if there are p horizontal and q vertical lines that separate R from B. The hardness here is shown in the parameter p.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:f2IySw72cVMC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"The colorful components framework is motivated by applications emerging from computational biology. A vertex-colored graph G is said to be colorful if every color appears exactly once. The general goal is to remove a collection of edges from an undirected vertex-colored graph G such that in the resulting graph H all the connected components are colorful. We want H to optimize an appropriate objective function. Two natural functions involve deleting the smallest number of edges (which we refer to as Colorful Components) and maximizing the number of edges in the transitive closure of the remaining components (which we refer to as MEC).
These problems are well-studied from the point of view of classical complexity, approximation algorithms, and parameterized algorithms. We complement and improve on some of the results in the literature concerning MEC and Colorful Components. In the context …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:O3NaXMp0MMsC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"Imbalance is a classical graph layout problem with several applications, particularly in graph drawing. The imbalance of a layout σ is determined by how well-balanced the neighbors of the vertices are in σ. In the present work, we study the problem of Imbalance parameterized by the twin cover of a graph. We show that Imbalance is XP parameterized by twin cover, and FPT when parameterized by the twin cover and the size of the largest clique outside the twin cover. In contrast, we introduce a notion of succinct representations of graphs in terms of their twin cover and demonstrate that Imbalance is NP-hard in the setting of succinct representations, even for graphs that have a twin cover of size one.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:pyW8ca7W8N0C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We consider the problem of distributing a collection of indivisible objects among agents in a manner that satisfies some desirable notions of fairness and efficiency. We allow agents to “share” goods in order to achieve efficiency and fairness goals which may be otherwise impossible to attain. In this context, our goal is to find allocations that minimize the “amount of sharing”. We follow up on recent work demonstrating that finding fair allocations with minimum sharing is tractable when valuations are non-degenerate, a notion which captures scenarios that are “far from identical”. This result holds for any fixed number of agents. We show that the usefulness of non-degeneracy does not scale to the setting of many agents. In particular, we demonstrate that the problem of finding fractionally Pareto optimal and envy-free allocations is NP-complete even for instances with constant degeneracy and no sharing. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:EUQCXRtRnyEC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We consider the minimum power spanning tree (MPST) problem with general and unit demands from a parameterized perspective. The case of unit demands is equivalent to the problem of finding a spanning tree with the smallest possible vertex cover (MCST). We show that MPST is W[1]-hard when parameterized by the vertex cover of the input graph, and is W[2]-hard when parameterized by the solution size—the latter holds even in the case of unit demands. For the special case of unit demands, however, we demonstrate an FPT algorithm when parameterized by treewidth. In the context of kernelization, we show that even MCST is unlikely to admit a polynomial kernel under standard complexity-theoretic assumptions when parameterized by the vertex cover of the input graph.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:yD5IFk8b50cC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We address the parameterized complexity of Max Colorable Induced Subgraph on perfect graphs. The problem asks for a maximum sized q-colorable induced subgraph of an input graph G. Yannakakis and Gavril (Inf Process Lett 24:133–137, 1987) showed that this problem is NP-complete even on split graphs if q is part of input, but gave an algorithm on chordal graphs. We first observe that the problem is W[2]-hard when parameterized by q, even on split graphs. However, when parameterized by , the number of vertices in the solution, we give two fixed-parameter tractable algorithms.
The first algorithm runs in time where t is the number of maximal independent sets of the input graph.
The second algorithm runs in time on graph classes where the maximum independent set of an induced subgraph can be found in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:SeFeTyx0c_EC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We consider a natural variant of the well-known Feedback Vertex Set problem, namely the problem of deleting a small subset of vertices or edges to a full binary tree. This version of the problem is motivated by real-world scenarios that are best modeled by full binary trees. We establish that both the edge and vertex deletion variants of the problem are -hard. This stands in contrast to the fact that deleting edges to obtain a forest or a tree is equivalent to the problem of finding a minimum cost spanning tree, which can be solved in polynomial time. We also establish that both problems are by the standard parameter.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:dfsIfKJdRG4C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We introduce a generalization of ""Solo Chess"", a single-player variant of the game that can be played on chess.com. The standard version of the game is played on a regular 8 x 8 chessboard by a single player, with only white pieces, using the following rules: every move must capture a piece, no piece may capture more than 2 times, and if there is a King on the board, it must be the final piece. The goal is to clear the board, i.e, make a sequence of captures after which only one piece is left. We generalize this game to unbounded boards with pieces, each of which have a given number of captures that they are permitted to make. We show that Generalized Solo Chess is NP-complete, even when it is played by only rooks that have at most two captures remaining. It also turns out to be NP-complete even when every piece is a queen with exactly two captures remaining in the initial configuration. In contrast, we show that solvable instances of Generalized Solo Chess can be completely characterized when the game is: a) played by rooks on a one-dimensional board, and b) played by pawns with two captures left on a 2D board. Inspired by Generalized Solo Chess, we also introduce the Graph Capture Game, which involves clearing a graph of tokens via captures along edges. This game subsumes Generalized Solo Chess played by knights. We show that the Graph Capture Game is NP-complete for undirected graphs and DAGs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:UxriW0iASnsC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"Topological features of polymer chains have been used as the key controlling mechanism for the physicochemical properties of hyperbranched polymers (HPs) and, therefore, provide a significant impetus to determine their branching characteristics. Single monomer methodology (SMM) involving ABm step polymerization has been one of the routes to synthesize both compact and segmented HPs. Here, we explore Catalan and half-Catalan numbers in the context of ABm step polymerization to deduce the structural information of HPs. Our approach harnesses the concepts of combinatorics and graph theory to calculate the exact numbers of isomeric, branched and linear, structures of polymer chains. We also demonstrate that the extent of branching of a polymer chain can be measured via pathwidth and establish its bounds as a function of its length. We believe that our findings can be leveraged to design and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:1sJd4Hv_s6UC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We study fair resource allocation under a connectedness constraint wherein a set of indivisible items are arranged on a path and only connected subsets of items may be allocated to the agents. An allocation is deemed fair if it satisfies equitability up to one good (EQ1), which requires that agents' utilities are approximately equal. We show that achieving EQ1 in conjunction with well-studied measures of economic efficiency (such as Pareto optimality, non-wastefulness, maximum egalitarian or utilitarian welfare) is computationally hard even for binary additive valuations. On the algorithmic side, we show that by relaxing the efficiency requirement, a connected EQ1 allocation can be computed in polynomial time for any given ordering of agents, even for general monotone valuations. Interestingly, the allocation computed by our algorithm has the highest egalitarian welfare among all allocations consistent with the given ordering. On the other hand, if efficiency is required, then tractability can still be achieved for binary additive valuations with interval structure. On our way, we strengthen some of the existing results in the literature for other fairness notions such as envy-freeness up to one good (EF1), and also provide novel results for negatively-valued items or chores.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:abG-DnoFyZgC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"In a vertex-colored graph, an edge is happy if its endpoints have the same color. Similarly, a vertex is happy if all its incident edges are happy. Motivated by the computation of homophily in social networks, we consider the algorithmic aspects of the following Maximum Happy Edges (k-MHE) problem: given a partially k-colored graph G and an integer ℓ, find an extended full k-coloring of G making at least ℓ edges happy. When we want to make ℓ vertices happy on the same input, the problem is known as Maximum Happy Vertices (k-MHV). We perform an extensive study into the complexity of the problems, particularly from a parameterized viewpoint. For every k≥ 3, we prove both problems can be solved in time 2 n n O (1). Moreover, by combining this result with a linear vertex kernel of size (k+ ℓ) for k-MHE, we show that the edge-variant can be solved in time 2 ℓ n O (1). In contrast, we prove that the vertex-variant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:bFI3QPDXJZMC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"The Firefighting problem is defined as follows. At time t= 0, a fire breaks out at a vertex of a graph. At each time step t≥ 1, a firefighter permanently defends (protects) an unburned vertex, and the fire then spreads to all undefended neighbors from the vertices on fire. This process stops when the fire cannot spread anymore. The goal is to find a sequence of vertices for the firefighter that maximizes the number of saved (non burned) vertices. The Firefighting problem turns out to be NP-hard even when restricted to bipartite graphs or trees of maximum degree three. We study the parameterized complexity of the Firefighting problem for various structural parameterizations. All our parameters measure the distance to a graph class (in terms of vertex deletion) on which the Firefighting problem admits a polynomial-time algorithm. To begin with, we show that the problem is W [1]-hard when parameterized by the size of a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:lSLTfruPkqcC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We consider variants and generalizations of the dominating set problem on special classes of graphs, specifically, graphs that are a small distance from a tractable class. Here, our focus is mainly on the problems of domination and efficient domination (a variant where we want every vertex to be dominated uniquely) and their respective generalizations to -distance domination.
We consider graphs which are at most vertices away from the following classes: edgless graphs, cluster graphs, split graphs, and complements of bipartite graphs. For the newly introduced parameter CBDS, we show that Dominating Set is W[2]-hard , while in contrast, is FPT for . For this parameter, Efficient Dominating Set turns out to be FPT as well. We generalize known results for Dominating Set parameterized by CVD to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:4OULZ7Gr8RgC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"Two Dots is a popular single-player puzzle video game for iOS and Android. A level of this game consists of a grid of colored dots. The player connects two or more adjacent dots, removing them from the grid and causing the remaining dots to fall, as if influenced by gravity. One special move, which is frequently a game-changer, consists of connecting a cycle of dots: this removes all the dots of the given color from the grid. The goal is to remove a certain number of dots of each color using a limited number of moves. The computational complexity of Two Dots has already been addressed in [Misra, FUN 2016], where it has been shown that the general version of the problem is NP-complete. Unfortunately, the known reductions produce Two Dots levels having both a large number of colors and many columns. This does not completely match the spirit of the game, where, on the one hand, only few colors are allowed, and on the other hand, the grid of the game has only a constant number of columns. In this paper, we partially fill this gap by assessing the computational complexity of Two Dots instances having a small number of colors or columns. More precisely, we show that Two Dots is hard even for instances involving only 3 colors or 2 columns. As a contrast, we also prove that the problem can be solved in polynomial-time on single-column instances with a constant number of goals.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:u_35RYKgDlwC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"The Eternal Vertex Cover problem is a dynamic variant of the vertex cover problem. We have a two player game in which guards are placed on some vertices of a graph. In every move, one player (the attacker) attacks an edge. In response to the attack, the second player (the defender) moves some of the guards along the edges of the graph in such a manner that at least one guard moves along the attacked edge. If such a movement is not possible, then the attacker wins. If the defender can defend the graph against an infinite sequence of attacks, then the defender wins.
The minimum number of guards with which the defender has a winning strategy is called the eternal vertex cover number of the graph G. On general graphs, the computational problem of determining the minimum eternal vertex cover number is -hard and admits a 2-approximation algorithm and an exponential kernel. The complexity of the problem …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:OU6Ihb5iCvQC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:p2g8aNsByqUC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"In this paper, we study the Shortest Color Spanning t-Intervals problem, and related generalizations, namely Smallest Color Spanning t-Squares and Smallest Color Spanning t-Circles. The generic setting is the following: we are given n points in the plane (or on a line), each colored with one of k colors. For each color i we also have a demand s i. Given a budget t, we are required to find at most t objects (for example, intervals, squares, circles, etc.) that cover at least s i points of color i. Typically, the goal is to minimize the maximum perimeter or area. We provide exact algorithms for these problems for the cases of intervals, circles and squares, generalizing several known results. In the case of intervals, we provide a comprehensive understanding of the complexity landscape of the problem after taking several natural parameters into account. Given that the problem turns out to be W [1]-hard parameterized by the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:blknAaTinKkC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We consider the problem of protecting and manipulating elections by recounting and changing ballots, respectively. Our setting involves a plurality-based election held across multiple districts, and the problem formulations are based on the model proposed recently by [Elkind et al., IJCAI 2019]. It turns out that both of the manipulation and protection problems are NP-complete even in fairly simple settings. We study these problems from a parameterized perspective with the goal of establishing a more detailed complexity landscape. The parameters we consider include the number voters, and the budgets of the attacker and the defender. While we observe fixed-parameter tractability when parameterizing by number of voters, our main contribution is a demonstration of parameterized hardness when working with the budgets of the attacker and the defender.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:D03iK_w7-QYC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"An edge Hamiltonian path of a graph is a permutation of its edge set where every pair of consecutive edges have a vertex in common. Unlike the seemingly related problem of finding an Eulerian walk, the edge Hamiltonian path is known to be a -hard problem, even on fairly restricted classes of graphs. We introduce a natural optimization variant of the notion of an edge Hamiltonian path, which seeks the longest sequence of distinct edges with the property that every consecutive pair of them has a vertex in common. We call such a sequence of edges an edge-linked path, and study the parameterized complexity of the problem of finding edge-linked paths with at least k edges. We show that the problem is FPT when parameterized by k, and unlikely to admit a polynomial kernel even on connected graphs.
On the other hand, we show that the problem admits a Turing kernel of polynomial size. To the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:fPk4N6BV_jEC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:tS2w5q8j5-wC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"The game of rendezvous with adversaries is a game on a graph played by two players: Facilitator and Divider. Facilitator has two agents and Divider has a team of agents. While the initial positions of Facilitator's agents are fixed, Divider gets to select the initial positions of his agents. Then, they take turns to move their agents to adjacent vertices (or stay put) with Facilitator's goal to bring both her agents at same vertex and Divider's goal to prevent it. The computational question of interest is to determine if Facilitator has a winning strategy against Divider with agents. Fomin, Golovach, and Thilikos [WG, 2021] introduced this game and proved that it is PSPACE-hard and co-W[2]-hard parameterized by the number of agents. This hardness naturally motivates the structural parameterization of the problem. The authors proved that it admits an FPT algorithm when parameterized by the modular width and the number of allowed rounds. However, they left open the complexity of the problem from the perspective of other structural parameters. In particular, they explicitly asked whether the problem admits an FPT or XP-algorithm with respect to the treewidth of the input graph. We answer this question in the negative and show that Rendezvous is co-NP-hard even for graphs of constant treewidth. Further, we show that the problem is co-W[1]-hard when parameterized by the feedback vertex set number and the number of agents, and is unlikely to admit a polynomial kernel when parameterized by the vertex cover number and the number of agents. Complementing these hardness results, we show that the Rendezvous is FPT when parameterized by both …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:738O_yMBCRsC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,التقسيم الثلاثي للحديث عند أهل السنّة (أبناء العامّة). أدعية لدفع السحر والعين. أصحاب الفيل أصحاب السبت أصحاب الرس أصحاب الأيكة أصحاب الأعراف أصحاب الأخدود التشققات والندب على ثمار الفلفل الطلاق اسس الحياة المشتركة بين الزوجين نـشـوء سـوق العـمـلات الأوربـيـة Euro Dollar Market والعوامـل المساعـدة لتطويـر التمـويـل الدولـي الطفل والحاجة الى الحرية تـشكـيـل دعائـم النـظام الاقتـصادي العـالـمي الخطر الكامن في عدم الإجابة عن أسئلة الطفل,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:l7t_Zn2s7bgC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,The maximum leaf number l (G) of a graph G is the largest number of tree leaves in any of its spanning trees.(The corresponding smallest number of leaves is known as the minimum leaf number.),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:SP6oXDckpogC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"Number sequences, like Fibonacci, Fermat, Markov, Euler, Bernoulli, etc., have been popular in exemplifying a variety of scientific phenomena. Here, we explore the Catalan numbers in the context of ABm step polymerisation and develop a framework to derive its alternative closed form expression. Our approach harnesses the concepts of combinatorics and graph theory, in conjunction with kinetics of AB2 polymerisation to obtain the chain length distribution that directly gives the closed-form expression of Catalan number expressed as a bivariate distribution function. Furthermore, we validate our expression by comparing first 5000 Catalan numbers obtained from its traditional closed-form. As an offshoot, we discuss “pathwidth”, a construct used in graph theory, as a better metrics for describing topology of polymer chains. The framework developed in this work can be extended to ABm step polymerisation and thus, facilitates topological characterisation of hyperbranched polymers (HPs) that ultimately, dictates their structure-property relationships.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:dshw04ExmUIC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"The b-Exact Multicover problem takes a universe U of n elements, a family of m subsets of U, a function and a positive integer k, and decides whether there exists a subfamily(set cover) of size at most k such that each element u ∈ U is covered by exactly dem(u) sets of . The b-Exact Coverage problem also takes the same input and decides whether there is a subfamily such that there are at least k elements that satisfy the following property: u ∈ U is covered by exactly dem(u) sets of . Both these problems are known to be NP-complete. In the parameterized setting, when parameterized by k, b-Exact Multicover is W[1]-hard even when b = 1. While b-Exact Coverage is FPT under the same parameter, it is known to not admit a polynomial kernel under standard complexity-theoretic assumptions, even when b = 1. In this paper, we investigate these two problems under the assumption that every …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:xtRiw3GOFMkC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"We study the computational complexity of finding fair allocations of indivisible goods in the setting where a social network on the agents is given. Notions of fairness in this context are “localized”, that is, agents are only concerned about the bundles allocated to their neighbors, rather than every other agent in the system. We comprehensively address the computational complexity of finding locally envy-free and Pareto efficient allocations in the setting where the agents have binary valuations for the goods and the underlying social network is modeled by an undirected graph. We study the problem in the framework of parameterized complexity.
We show that the problem is computationally intractable even in fairly restricted scenarios, for instance, even when the underlying graph is a path. We show NP-hardness for settings where the graph has only two distinct valuations among the agents. We demonstrate W …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:P5F9QuxV20EC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"Eternal Vertex Cover problem is a dynamic variant of the vertex cover problem. We have a two player game in which guards are placed on some vertices of a graph. In every move, one player (the attacker) attacks an edge. In response to the attack, the second player (defender) moves the guards along the edges of the graph in such a manner that at least one guard moves along the attacked edge. If such a movement is not possible, then the attacker wins. If the defender can defend the graph against an infinite sequence of attacks, then the defender wins. The minimum number of guards with which the defender has a winning strategy is called the Eternal Vertex Cover Number of the graph G. On general graphs, the computational problem of determining the minimum eternal vertex cover number is NP-hard and admits a 2-approximation algorithm and an exponential kernel. The complexity of the problem on bipartite graphs is open, as is the question of whether the problem admits a polynomial kernel. We settle both these questions by showing that Eternal Vertex Cover is NP-hard and does not admit a polynomial compression even on bipartite graphs of diameter six. This result also holds for split graphs. We also show that the problem admits a polynomial time algorithm on the class of cobipartite graphs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:KxtntwgDAa4C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"The game of rendezvous with adversaries is a game on a graph played by two players: Facilitator and Divider. Facilitator has two agents and Divider has a team of k ≥ 1 agents. While the initial positions of Facilitator’s agents are fixed, Divider gets to select the initial positions of his agents. Then, they take turns to move their agents to adjacent vertices (or stay put) with Facilitator’s goal to bring both her agents at same vertex and Divider’s goal to prevent it. The computational question of interest is to determine if Facilitator has a winning strategy against Divider with k agents. Fomin, Golovach, and Thilikos [WG, 2021] introduced this game and proved that it is PSPACE-hard and co-W[2]-hard parameterized by the number of agents. This hardness naturally motivates the structural parameterization of the problem. The authors proved that it admits an FPT algorithm when parameterized by the modular width and the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:vRqMK49ujn8C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"In the past few decades, the utility of hyperbranched polymers in coatings, drug and gene delivery, additives etc. has provided significant impetus to design molecular architectures with a broad range of physicochemical properties. One of the methods to synthesize these branched polymers is via step polymerization using-type multifunctional monomer. Here, we use combinatorics within the framework of graph theory to obtain structural information about branched polymers. Specifically, we establish one-to-one correspondence between polymer chains and tree data structures and develop various metrics to calculate the exact quantities of isomorphic/non-isomorphic and branched/linear polymer chains. Further, we use the traditional kinetic models to validate our findings. Our approach can be harnessed not only to determine the exact quantity of the hyperbranched polymers formed during synthesis but also be …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:CHSYGLWDkRkC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"This Special Issue contains eleven articles—surveys and research papers—that represent fresh and ambitious new directions in the area of Parameterized Complexity. They provide ground-breaking research at the frontiers of knowledge, and they contribute to bridging the gap between theory and practice. The scope and impact of the field continues to increase. Promising avenues and new research challenges are highlighted in this Special Issue.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:_xSYboBqXhAC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",19,"Consider a fixed voting rule. In the Possible President problem, we are given an election where the candidates are partitioned into parties, and the problem is to determine if, given a party, it is possible for every party to nominate a candidate such that the nominee from is a winner of the election that is obtained by restricting the votes to the nominated candidates. In previous work on this problem, proposed by [10], it was established that Possible President is NP-hard even when the voting rule is Plurality and the election is restricted to single-peaked votes. In this contribution, we initiate a study of the parameterized complexity of the problem. Our main result is that for a natural choice of parameter (namely the number of parties), the problem is W [2]-hard in general but is FPT on the 1D-Euclidean domain. On the other hand, if we parameterize by the size of the largest party, we encounter para-NP-hardness even on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&citation_for_view=XFgieDYAAAAJ:cFHS6HbyZ2cC,http://www.neeldhara.com/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Traditional 3D Convolutional Neural Networks (CNNs) are computationally expensive, memory intensive, prone to overfit, and most importantly, there is a need to improve their feature learning capabilities. To address these issues, we propose Rectified Local Phase Volume (ReLPV) block, an efficient alternative to the standard 3D convolutional layer. The ReLPV block extracts the phase in a 3D local neighborhood (eg, 3x3x3) of each position of the input map to obtain the feature maps. The phase is extracted by computing 3D Short Term Fourier Transform (STFT) at multiple fixed low frequency points in the 3D local neighborhood of each position. These feature maps at different frequency points are then linearly combined after passing them through an activation function. The ReLPV block provides significant parameter savings of at least, 3^ 3 to 13^ 3 times compared to the standard 3D convolutional layer with the filter sizes 3x3x3 to 13x13x13, respectively. We show that the feature learning capabilities of the ReLPV block are significantly better than the standard 3D convolutional layer. Furthermore, it produces consistently better results across different 3D data representations. We achieve state-of-the-art accuracy on the volumetric ModelNet10 and ModelNet40 datasets while utilizing only 11% parameters of the current state-of-the-art. We also improve the state-of-the-art on the UCF-101 split-1 action recognition dataset by 5.68%(when trained from scratch) while using only 15% of the parameters of the state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:HIFyuExEbWQC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Human pose estimation is a well-known problem in computer vision to locate joint positions. Existing datasets for learning of poses are observed to be not challenging enough in terms of pose diversity, object occlusion and view points. This makes the pose annotation process relatively simple and restricts the application of the models that have been trained on them. To handle more variety in human poses, we propose the concept of fine-grained hierarchical pose classification, in which we formulate the pose estimation as a classification task, and propose a dataset, Yoga-82, for large-scale yoga pose recognition with 82 classes. Yoga-82 consists of complex poses where fine annotations may not be possible. To resolve this, we provide hierarchical labels for yoga poses based on the body configuration of the pose. The dataset contains a three-level hierarchy including body positions, variations in body positions, and the actual pose names. We present the classification accuracy of the state-of-the-art convolutional neural network architectures on Yoga-82. We also present several hierarchical variants of DenseNet in order to utilize the hierarchical labels.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:mlAyqtXpCwEC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"High dynamic range (HDR) image generation from a single exposure low dynamic range (LDR) image has been made possible due to the recent advances in Deep Learning. Various feed-forward Convolutional Neural Networks (CNNs) have been proposed for learning LDR to HDR representations. To better utilize the power of CNNs, we exploit the idea of feedback, where the initial low level features are guided by the high level features using a hidden state of a Recurrent Neural Network. Unlike a single forward pass in a conventional feed-forward network, the reconstruction from LDR to HDR in a feedback network is learned over multiple iterations. This enables us to create a coarse-to-fine representation, leading to an improved reconstruction at every iteration. Various advantages over standard feed-forward networks include early reconstruction ability and better reconstruction quality with fewer network …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:umqufdRvDiIC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Recognizing facial expressions is one of the central problems in computer vision. Temporal image sequences have useful spatio-temporal features for recognizing expressions. In this paper, we propose a new 3D Convolution Neural Network (CNN) that can be trained end-to-end for facial expression recognition on temporal image sequences without using facial landmarks. More specifically, a novel 3D convolutional layer that we call Local Binary Volume (LBV) layer is proposed. The LBV layer, when used with our newly proposed LBVCNN network, achieve comparable results compared to state-of-the-art landmark-based or without landmark-based models on image sequences from CK+, Oulu-CASIA, and UNBC McMaster shoulder pain datasets. Furthermore, our LBV layer reduces the number of trainable parameters by a significant amount when compared to a conventional 3D convolutional layer. As a matter of fact, when compared to a 3x3x3 conventional 3D convolutional layer, the LBV layer uses 27 times less trainable parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:cWzG1nlazyYC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Techniques to learn hash codes which can store and retrieve large dimensional multimedia data efficiently have attracted broad research interests in the recent years. With rapid explosion of newly emerged concepts and online data, existing supervised hashing algorithms suffer from the problem of scarcity of ground truth annotations due to the high cost of obtaining manual annotations. Therefore, we propose an algorithm to learn a hash function from training images belonging to ‘seen’ classes which can efficiently encode images of ‘unseen’ classes to binary codes. Specifically, we project the image features from visual space and semantic features from semantic space into a common Hamming subspace. Earlier works to generate hash codes have tried to relax the discrete constraints on hash codes and solve the continuous optimization problem. However, it often leads to quantization errors. In this work, we use …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:ILKRHgRFtOwC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Competitive diving is a well recognized aquatic sport in which a person dives from a platform or a springboard into the water. Based on the acrobatics performed during the dive, diving is classified into a finite set of action classes which are standardized by FINA. In this work, we propose an attention guided LSTM-based neural network architecture for the task of diving classification. The network takes the frames of a diving video as input and determines its class. We evaluate the performance of the proposed model on a recently introduced competitive diving dataset, Diving48. It contains over 18000 video clips which covers 48 classes of diving. The proposed model outperforms the classification accuracy of the state-of-the-art models in both 2D and 3D frameworks by 11.54% and 4.24%, respectively. We show that the network is able to localize the diver in the video frames during the dive without being trained with such a supervision.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:dBIO0h50nwkC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,We propose an algorithm to detect approximate reflection symmetry present in a set of volumetrically distributed points belonging to ℝ d containing a distorted reflection symmetry pattern. We pose the problem of detecting approximate reflection symmetry as the problem of establishing correspondences between the points which are reflections of each other and we determine the reflection symmetry transformation. We formulate an optimization framework in which the problem of establishing the correspondences amounts to solving a linear assignment problem and the problem of determining the reflection symmetry transformation amounts to solving an optimization problem on a smooth Riemannian product manifold. The proposed approach estimates the symmetry from the geometry of the points and is descriptor independent. We evaluate the performance of the proposed approach on the standard benchmark …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:HbR8gkJAVGIC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Conventional 3D convolutional neural networks (CNNs) are computationally expensive, memory intensive, prone to overfitting, and most importantly, there is a need to improve their feature learning capabilities. To address these issues, we propose spatio-temporal short-term Fourier transform (STFT) blocks, a new class of convolutional blocks that can serve as an alternative to the 3D convolutional layer and its variants in 3D CNNs. An STFT block consists of non-trainable convolution layers that capture spatially and/or temporally local Fourier information using an STFT kernel at multiple low frequency points, followed by a set of trainable linear weights for learning channel correlations. The STFT blocks significantly reduce the space-time complexity in 3D CNNs. In general, they use 3.5 to 4.5 times less parameters and 1.5 to 1.8 times less computational costs when compared to the state-of-the-art methods. Furthermore …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:PaBasH6fAo0C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Many real-world solutions for image restoration are learning-free and based on handcrafted image priors such as self-similarity. Recently, deep-learning methods that use training data have achieved state-of-the-art results in various image restoration tasks (e.g., super-resolution and inpainting). Ulyanov et al. bridge the gap between these two families of methods (CVPR 18). They have shown that learning-free methods perform close to the state-of-the-art learning-based methods (approximately 1 PSNR). Their approach benefits from the encoder-decoder network. In this paper, we propose a framework based on the multi-level extensions of the encoder-decoder network, to investigate interesting aspects of the relationship between image restoration and network construction independent of learning. Our framework allows various network structures by modifying the following network components: skip links …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:mNrWkgRL2YcC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Reflection symmetry is a very commonly occurring feature in both natural and man-made objects, which helps in understanding objects better and makes them visually pleasing. Detection of reflection symmetry is a fundamental problem in the field of computer vision and computer graphics which aids in understanding and representing reflective symmetric objects. In this work, we attempt the problem of detecting the 3D global reflection symmetry of a 3D object represented as a point cloud. The main challenge is to handle outliers, missing parts, and perturbations from the perfect reflection symmetry. We propose a descriptor-free approach, in which, we pose the problem of reflection symmetry detection as an optimization problem and provide a closed-form solution. We show that the proposed method achieves state-of-the-art performance on the standard dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:DUooU5lO8OsC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Display of images on different display devices having varied size and aspect ratio requires one to resize them. Many attempts have been made to perform content‐aware image retargeting while generating an image compatible with a target display size. Seam carving is one of the image retargeting operators which alters the size of an image by removing least energy pixels. However, it requires high computational time in order to perform retargeting. In this study, the authors accelerate the naive seam carving process by removal or insertion of multiple pixel wide batch seam in a single iteration rather than a single pixel wide seam. Along with the energy of pixels to be removed, inserted energy after the removal of a batch seam is also minimised in order to prevent the inclusion of false edges. The width of a batch seam is a critical factor which is made adaptive during the retargeting process to preserve the energy of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&citation_for_view=3YWptB8AAAAJ:k8Z6L05lTy4C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"In computer vision and graphics, various types of symmetries are extensively studied since symmetry present in objects is a fundamental cue for understanding the shape and the structure of objects. In this work, we detect the intrinsic reflective symmetry in triangle meshes where we have to find the intrinsically symmetric point for each point of the shape. We establish correspondences between functions defined on the shapes by extending the functional map framework and then recover the point-to-point correspondences. Previous approaches using the functional map for this task find the functional correspondences matrix by solving a non-linear optimization problem which makes them slow. In this work, we propose a closed form solution for this matrix which makes our approach faster. We find the closed-form solution based on our following results. If the given shape is intrinsically symmetric, then the shortest length geodesic between two intrinsically symmetric points is also intrinsically symmetric. If an eigenfunction of the Laplace-Beltrami operator for the given shape is an even (odd) function, then its restriction on the shortest length geodesic between two intrinsically symmetric points is also an even (odd) function. The sign of a low-frequency eigenfunction is the same on the neighboring points. Our method is invariant to the ordering of the eigenfunctions and has the least time complexity. We achieve the best performance on the SCAPE dataset and comparable performance with the state-of-the-art methods on the TOSCA dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:foquWX3nUaYC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Recently, there is a vast interest in developing methods which are independent of the training samples such as deep image prior, zero-shot learning, and internal learning. The methods above are based on the common goal of maximizing image features learning from a single image despite inherent technical diversity. In this work, we bridge the gap between the various unsupervised approaches above and propose a general framework for image restoration and image retargeting. We use contextual feature learning and internal learning to improvise the structure similarity between the source and the target images. We perform image resize application in the following setups: classical image resize using super-resolution, a challenging image resize where the low-resolution image contains noise, and content-aware image resize using image retargeting. We also provide comparisons to the relevant state-of-the-art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:OTTXONDVkokC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"This paper addresses the problem of unsupervised object localization in an image. Unlike previous supervised and weakly supervised algorithms that require bounding box or image level annotations for training classifiers, we propose a simple yet effective technique for localization using iterative spectral clustering. This iterative spectral clustering approach along with appropriate cluster selection strategy in each iteration naturally helps in searching of object region in the image. In order to estimate the final localization window, we group the proposals obtained from the iterative spectral clustering step based on the perceptual similarity, and average the coordinates of the proposals from the top scoring groups. We benchmark our algorithm on challenging datasets like Object Discovery and PASCAL VOC 2007, achieving an average CorLoc percentage of 51% and 35% respectively which is comparable to various …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:kuK5TVdYjLIC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"In this paper, we propose Rectified Local Phase Unit (ReLPU), which is an efficient and trainable convolutional layer that utilizes phase information computed locally in a window for every pixel location of the input image. The ReLPU layer is based on applying the Rectified Linear Unit (ReLU) activation function on the local phase information extracted by computing the local Fourier transform of the input image at multiple low frequency points. The ReLPU layer, when used at the top of the segmentation network U-Net, is observed to improve the performance of the baseline U-Net model. We demonstrate this using the task of segmenting blood vessels in fundus images of two standard datasets, DRIVE and STARE, achieving state-of-the-art results. An important feature of the ReLPU layer is that it is trainable which allows it to choose the best frequency points for computing local Fourier transform and to selectively give …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:xtoqd-5pKcoC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Reflection symmetry is one of the most commonly occurring and prominent visual attributes present in the real world. With an increase in the display devices of different sizes and aspect ratios, the images captured from the real world need to be resized to fit to the display device. In this paper, we propose a novel image retargeting approach which preserves the reflection symmetry present in the image during the image retargeting process. We detect the symmetry region present in the image using symmetry axis detection and object proposals. We propose a novel framework for finding an optimized reflected seam for the least energy seam defined by the seam carving approach. The symmetry axis and the symmetric object are preserved by adding or removing a seam and its reflected counterpart together. We show better preservation of symmetry axis, preservation of shape of the symmetric object, and quality of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:PoWvk5oyLR8C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Recently, there is a vast interest in developing image feature learning methods that are independent of the training data, such as deep image prior, InGAN, SinGAN, and DCIL. These methods are unsupervised and are used to perform low-level vision tasks such as image restoration, image editing, and image synthesis. In this work, we proposed a new training data-independent framework, called Deep Contextual Features Learning (DeepCFL), to perform image synthesis and image restoration based on the semantics of the input image. The contextual features are simply the high dimensional vectors representing the semantics of the given image. DeepCFL is a single image GAN framework that learns the distribution of the context vectors from the input image. We show the performance of contextual learning in various challenging scenarios: outpainting, inpainting, and restoration of randomly removed pixels. DeepCFL is applicable when the input source image and the generated target image are not aligned. We illustrate image synthesis using DeepCFL for the task of image resizing.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:fbc8zXXH2BUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Autonomous assembly of objects is an essential task in robotics and 3D computer vision. It has been studied extensively in robotics as a problem of motion planning, actuator control and obstacle avoidance. However, the task of developing a generalized framework for assembly robust to structural variants remains relatively unexplored. In this work, we tackle this problem using a recurrent graph learning framework considering inter-part relations and the progressive update of the part pose. Our network can learn more plausible predictions of shape structure by accounting for priorly assembled parts. Compared to the current state-of-the-art, our network yields up to 10% improvement in part accuracy and up to 15% improvement in connectivity accuracy on the PartNet dataset. Moreover, our resulting latent space facilitates exciting applications such as shape recovery from the point-cloud components. We conduct extensive experiments to justify our design choices and demonstrate the effectiveness of the proposed framework.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:buQ7SEKw-1sC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"In this paper, we propose a new convolutional layer called Depthwise-STFT Separable layer that can serve as an alternative to the standard depthwise separable convolutional layer. The construction of the proposed layer is inspired by the fact that the Fourier coefficients can accurately represent important features such as edges in an image. It utilizes the Fourier coefficients computed (channelwise) in the 2D local neighborhood (e.g., 3 × 3) of each position of the input map to obtain the feature maps. The Fourier coefficients are computed using 2D Short Term Fourier Transform (STFT) at multiple fixed low frequency points in the 2D local neighborhood at each position. These feature maps at different frequency points are then linearly combined using trainable pointwise (1 × 1) convolutions. We show that the proposed layer outperforms the standard depthwise separable layer based models on the CIFAR-10 and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:a9-T7VOCCH8C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"A scene can be divided into two parts: static and dynamic. The parts of the scene which do not admit any motion are static regions, while moving objects correspond to dynamic regions. In this work, we tackle the challenging task of identifying dynamic objects present in the CrowdCam images. Our approach exploits the coherency present in the natural images and utilizes the epipolar geometry present between a pair of images to achieve this objective. It does not require a dynamic object to be present in all the given images. We show that the proposed approach obtains state-of-the-art accuracy on standard datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:FPJr55Dyh1AC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Deep neural networks have enormous representational power which leads them to overfit on most datasets. Thus, regularizing them is important in order to reduce overfitting and enhance their generalization capabilities. Recently, channel shuffle operation has been introduced for mixing channels in group convolutions in resource efficient networks in order to reduce memory and computations. This paper studies the operation of channel shuffle as a regularization technique in deep convolutional networks. We show that while random shuffling of channels during training drastically reduce their performance, however, randomly shuffling small patches between channels significantly improves their performance. The patches to be shuffled are picked from the same spatial locations in the feature maps such that a patch, when transferred from one channel to another, acts as structured noise for the later channel. We call this method ""ShuffleBlock"". The proposed ShuffleBlock module is easy to implement and improves the performance of several baseline networks on the task of image classification on CIFAR and ImageNet datasets. It also achieves comparable and in many cases better performance than many other regularization methods. We provide several ablation studies on selecting various hyperparameters of the ShuffleBlock module and propose a new scheduling method that further enhances its performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:cK4Rrx0J3m0C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Photometric stereo is a method to obtain surface normals of an object using its images captured under varying illumination directions. The existing deep learning-based methods require multiple images of an object captured using complex image acquisition systems. In this work, we propose a deep learning framework to perform three tasks jointly: (i) lighting estimation, (ii) image relighting, and (iii) surface normal estimation, all from a single input image of an object with non-Lambertian surface and general reflectance. The network explicitly segregates global geometric features and local lighting-specific features of the object from a single image. The local features resemble attached shadows, shadings, and specular highlights, providing valuable lighting estimation and relighting cues. The global features capture the lighting-independent geometric attributes that effectively guide the surface normal estimation. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:U4n9YNQMCAIC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"While recent learning-based methods have been observed to be superior for several vision-related applications, their potential in generating artistic effects has not been explored much. One such exciting application is Shadow Art-a unique form of sculptural art that produces artistic effects through 2D shadows cast by a 3D sculpture. In this work, we revisit shadow art using differentiable rendering-based optimization frameworks to obtain the 3D sculpture from a set of shadow (binary) images and their corresponding projection information. Specifically, we discuss shape optimization through voxel as well as mesh-based differentiable renderers. Our choice of using differentiable rendering for generating shadow art sculptures can be attributed to its ability to learn the underlying 3D geometry solely from image data, thus reducing the dependence on 3D ground truth. The qualitative and quantitative results demonstrate the potential of the proposed framework in generating complex 3D sculptures that transcend the ones seen in contemporary art pieces using just a set of shadow images as input. Further, we demonstrate the generation of 3D sculptures to cast shadows of faces, animated movie characters, and the applicability of the proposed framework to sketch-based 3D reconstruction of the underlying shapes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:BJbdYPG6LGMC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"The prime goal of digital imaging techniques is to reproduce the realistic appearance of a scene. Low Dynamic Range (LDR) cameras are incapable of representing the wide dynamic range of the real-world scene. The captured images turn out to be either too dark (underexposed) or too bright (overexposed). Specifically, saturation in overexposed regions makes the task of reconstructing a High Dynamic Range (HDR) image from single LDR image challenging. In this paper, we propose a deep learning based approach to recover details in the saturated areas while reconstructing the HDR image. We formulate this problem as an image-to-image (I2I) translation task. To this end, we present a novel conditional GAN (cGAN) based framework trained in an end-to-end fashion over the HDR-REAL and HDR-SYNTH datasets. Our framework uses an overexposed mask obtained from a pre-trained segmentation model to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:wMgC3FpKEyYC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"One of the major challenges of style transfer is the appropriate image features supervision between the output image and the input images (style and content). An efficient strategy would be to define an object map between the objects of the style and the content images. However, such a mapping is not well established when there are semantic objects of different types and numbers in the style and the content images. It also leads to content mismatch in the style transfer output, which could reduce the visual quality of the results. We propose an object-based style transfer approach, called DeepObjStyle, for the style supervision in the training data-independent framework. DeepObjStyle preserves the semantics of the objects and achieves better style transfer in the challenging scenario when the style and the content images have a mismatch of image features. We also perform style transfer of images containing a word cloud to demonstrate that DeepObjStyle enables an appropriate image features supervision. We validate the results using quantitative comparisons and user studies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:u-coK7KVo8oC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Consider a set of images of a scene captured from multiple views with some missing regions in each image. In this work, we propose a convolutional neural network (CNN) architecture which fills the missing regions in one image using the information present in the remaining images. The network takes the set of images and their corresponding binary maps as inputs and generates an image with the completed missing regions. The binary map indicates the missing regions present in the corresponding image. The network is trained using an adversarial approach and is observed to generate sharp output images qualitatively. We evaluate the performance of the proposed approach on the dataset extracted from the standard dataset, MVS-Synth.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:QYdC8u9Cj1oC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"The process of rendering high dynamic range (HDR) images to be viewed on conventional displays is called tone mapping. However, tone mapping introduces distortions in the final image which may lead to visual displeasure. To quantify these distortions, we introduce a novel no-reference quality assessment technique for these tone mapped images. This technique is composed of two stages. In the first stage, we employ a convolutional neural network (CNN) to generate quality aware maps (also known as distortion maps) from tone mapped images by training it with the ground truth distortion maps. In the second stage, we model the normalized image and distortion maps using an Asymmetric Generalized Gaussian Distribution (AGGD). The parameters of the AGGD model are then used to estimate the quality score using support vector regression (SVR). We show that the proposed technique delivers competitive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:YohjEiUPhakC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Reflection symmetry is ubiquitous in nature and plays an important role in object detection and recognition tasks. Most of the existing methods for symmetry detection extract and describe each keypoint using a descriptor and a mirrored descriptor. Two keypoints are said to be mirror symmetric key-points if the original descriptor of one keypoint and the mirrored descriptor of the other keypoint are similar. However, these methods suffer from the following issue. The background pixels around the mirror symmetric pixels lying on the boundary of an object can be different. Therefore, their descriptors can be different. However, the boundary of a symmetric object is a major component of global reflection symmetry. We exploit the estimated boundary of the object and describe a boundary pixel using only the estimated normal of the boundary segment around the pixel. We embed the symmetry axes in a graph as cliques to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:Dip1O2bNi0gC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Content-aware image retargeting methods address the resizing of an image to be displayed on devices having different aspect ratios and resolutions. Seam carving method is an effective image retargeting method which suffers from high computational complexity. It requires one to find one-pixel wide minimum energy path in either vertical or horizontal direction, called seam, to reduce the image size by one pixel. In this paper, we propose an acceleration of the seam carving method by expanding the width of the seam making it multiple-pixel wide seam carving. The two types of energies: one corresponding to the pixels to be removed and another corresponding to the pixels across the multiple-pixel wide seam, increase as the width of the seam increases. In order to prevent the increase in these energies, we make the width of the seam adaptive as a function of the number of iterations. We find the width of a seam …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:lmc2jWPfTJgC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"The resizing of stereo images while preserving salient content and geometric consistency between the image pair is an essential problem to be addressed for 3D visualization. Existing stereo image retargeting techniques are observed to be incurring salient object deformation. In this paper, we formulate a seam carving method to perform stereo image retargeting using graph-cuts having node size as the number of pixels in one of the stereo images. We define the object map with depth ordering of each object from the camera. The seams are allowed to pass along the object-object occlusion boundary at depth discontinuity in order to prevent salient object deformation. We propose adaptive occlusion boundary weights as a function of an object area to be occluded to preserve small objects. The seam passing through object-object occlusion boundary in one image may not follow the exact boundary in the other …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:PVjk1bu6vJQC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Consider a set of n images of a dynamic scene captured using multiple hand-held devices. The order in which these images are captured is unknown. For n images, there can be n! possible arrangements, which makes this problem extremely challenging. In this work, we address the problem of sequencing such a set of unordered images in its temporal order. We propose an LSTM-based deep neural network which addresses this problem in an end-to-end manner. The network takes the set of images as input and outputs their order of capture. We formulate the problem as a sequence-to-sequence mapping task, in which each image is mapped to its position in the ordered sequence. We do not provide any other information to the network apart from the input images. We show that the proposed approach obtains the state-of-the-art results on the standard dataset. Further, we show through experimental results that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:tuHXwOkdijsC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"In this paper, we present a Fast Motion Deblurring-Conditional Generative Adversarial Network (FMD-cGAN) that helps in blind motion deblurring of a single image. FMD-cGAN delivers impressive structural similarity and visual appearance after deblurring an image. Like other deep neural network architectures, GANs also suffer from large model size (parameters) and computations. It is not easy to deploy the model on resource constraint devices such as mobile and robotics. With the help of MobileNet  based architecture that consists of depthwise separable convolution, we reduce the model size and inference time, without losing the quality of the images. More specifically, we reduce the model size by 3–60x compare to the nearest competitor. The resulting compressed Deblurring cGAN faster than its closest competitors and even qualitative and quantitative results outperform various recently proposed state-of-the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:jL-93Qbq4QoC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Graph convolutional networks (GCNs) have achieved impressive performance in learning from graph-structured data. Although GCN and its variants have shown promising results, they continue to remain shallow as their performance drops with an increasing number of layers - a problem popularly known as oversmoothing. This work introduces a simple yet effective idea of feature gating over graph convolution layers to facilitate deeper graph neural networks and address oversmoothing. The proposed feature gating is easy to implement without changing the underlying network architecture and is broadly applicable to GCN and almost any of its variants. Further, we demonstrate the use of feature gating in assigning importance to node features and the nodes for the node classification task. Quantitative analysis on real-world datasets shows that feature gating paves the way for constructing deeper GCNs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:v1_lew4L6wgC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"3D point cloud completion problem deals with completing the shape from partial points. The problem finds its application in many vision-related applications. Here, structure plays an important role. Most of the existing approaches either do not consider structural information or consider structure at the decoder only. For maintaining the structure, it is also necessary to maintain the position of the available 3D points. However, most of the approaches lack the aspect of maintaining the available structural position. In this paper, we propose to employ stacked auto-encoder in conjunction a with shared Multi-Layer Perceptron (MLP). MLP converts each 3D point into a feature vector and the stacked auto-encoder helps in maintaining the available structural position of the input points. Further, it explores the redundancy present in the feature vector. It aids to incorporate coarse to fine scale information that further helps in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:F1b5ZUV5XREC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Traditional 3D convolutions are computationally expensive, memory intensive, and due to large number of parameters, they often tend to overfit. On the other hand, 2D CNNs are less computationally expensive and less memory intensive than 3D CNNs and have shown remarkable results in applications like image classification and object recognition. However, in previous works, it has been observed that they are inferior to 3D CNNs when applied on a spatio-temporal input. In this work, we propose a convolutional block which extracts the spatial information by performing a 2D convolution and extracts the temporal information by exploiting temporal differences, i.e., the change in the spatial information at different time instances, using simple operations of shift, subtract and add without utilizing any trainable parameters. The proposed convolutional block has same number of parameters as of a 2D convolution kernel of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:NyGDZy8z5eUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"In this work, we address the problem of extracting high dimensional, soft semantic feature descriptors for every pixel in an image using a deep learning framework. Existing methods rely on a metric learning objective called multi-class N-pair loss, which requires pairwise comparison of positive examples (same class pixels) to all negative examples (different class pixels). Computing this loss for all possible pixel pairs in an image leads to a high computational bottleneck. We show that this huge computational overhead can be reduced by learning this metric based on superpixels. This also conserves the global semantic context of the image, which is lost in pixel-wise computation because of the sampling to reduce comparisons. We design an end-to-end trainable network with a loss function and give a detailed comparison of two feature extraction methods: pixel-based and superpixel-based. We also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:sJsF-0ZLhtgC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"DiversePatel, DiptibenaspectRaman, Shanmuganathan ratios of display devices require adaptation of the image content to be displayed on them. Image retargeting pertains to changing the size of an image to adapt to the aspect ratio and spatial resolution of the display device. This is achieved while preserving the salient or important information and thereby reducing visible artifacts in the retargeted image. Seam carving techniques remove or insert least energy seams, one pixel wide paths from top to bottom or left to right of an image, iteratively in order to achieve the target display size. These techniques highly depend on an energy measure of a pixel in an image. Here, we propose a novel technique of defining energy of a pixel, also known as significance map, using object proposal boxes with the probability of objects being present. Object proposal boxes are modeled using the Gaussian kernels. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:4X0JR2_MtJMC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Deep neural networks have enormous representational power which has lead them to overfit on most datasets. Thus, regularizing them is important in order to reduce overfitting and to enhance their generalization capability. This paper studies the operation of channel patch shuffle as a regularization technique in deep convolutional networks. We propose a novel regularization technique called ShuffieBlock where we show that randomly shuffling small patches or blocks between channels significantly improves their performance. The patches to be shuffled are picked from the same spatial locations in the feature maps such that a patch, when transferred from one channel to another, acts as a structured noise for the later channel. The ShuffieBlock module is easy to implement and improves the performance of several baseline networks for the task of image classification on CIFAR and ImageNet datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:LdasjJ6CEcoC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Estimating 3D surface normals through photometric stereo has been of great interest in computer vision research. Despite the success of existing traditional and deep learning-based methods, it is still challenging due to: (i) the requirement of three or more differently illuminated images, (ii) the inability to model unknown general reflectance, and (iii) the requirement of accurate 3D ground truth surface normals and known lighting information for training. In this work, we attempt to address an under-explored problem of photometric stereo using just two differently illuminated images, referred to as the PS2 problem. It is an intermediate case between a single image-based reconstruction method like Shape from Shading (SfS) and the traditional Photometric Stereo (PS), which requires three or more images. We propose an inverse rendering-based deep learning framework, called DeepPS2, that jointly performs surface …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:j7_hQOaDUrUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"We consider the generic deep image enhancement problem where an input image is transformed into a perceptually better-looking image. The methods mostly fall into two categories: training with prior examples methods and training with no-prior examples methods. Recently, Deep Internal Learning solutions to image enhancement in training with no-prior examples setup are gaining attention. We perform image enhancement using a deep internal learning framework. Our Deep Internal Learning for Image Enhancement framework (DILIE) enhances content features and style features and preserves semantics in the enhanced image. To validate the results, we use structure similarity and perceptual error, which is efficient in measuring the unrealistic deformation present in the images. We show that DILIE framework outputs good quality images for hazy and noisy image enhancement tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:ODE9OILHJdcC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,Point cloud is one of the widely used techniques for representing and storing 3D geometric data. In the past several methods have been proposed for processing point clouds. Methods such as PointNet and FoldingNet have shown promising results for tasks like 3D shape classification and segmentation. This work proposes a tree-structured autoencoder framework to generate robust embeddings of point clouds by utilizing hierarchical information using graph convolution. We perform multiple experiments to assess the quality of embeddings generated by the proposed encoder architecture and visualize the t-SNE map to highlight its ability to distinguish between different object classes. We further demonstrate the applicability of the proposed framework in applications like: 3D point cloud completion and Single image-based 3D reconstruction.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:uDGL6kOW6j0C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"The camera sensors often fail to capture all the brightness intensities present in the visible spectrum of light. This is due to the limited dynamic range of the sensor elements. When bright light falls on a camera sensor, it is not appropriately measured. The recorded brightness values that fall outside the sensor’s dynamic range are stored as the minimum or maximum value depending on the bit-depth of the sensor. This results in a loss of information and undesirable artifacts in the form of blown-out areas, referred to as over- and under-exposed regions. In this study, we propose to detect these areas in an image using deep learning tools. Our approach uses semantic segmentation to mark the under, over, and correctly exposed regions in the image. We have created a new dataset containing 4928 images to train and test the performance of the model using a pre-trained state-of-the-art model architecture and re …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:Bg7qf7VwUHIC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Consider a set of images of a scene consisting of moving objects captured using a hand-held camera. In this work, we propose an algorithm which takes this set of multi-view images as input, detects the dynamic objects present in the scene, and replaces them with the static regions which are being occluded by them. The proposed algorithm scans the reference image in the row-major order at the pixel level and classifies each pixel as static or dynamic. During the scan, when a pixel is classified as dynamic, the proposed algorithm replaces that pixel value with the corresponding pixel value of the static region which is being occluded by that dynamic region. We show that we achieve artifact-free removal of dynamic objects in multi-view images of several real-world scenes. To the best of our knowledge, we propose the first method which simultaneously detects and removes the dynamic objects present in multi-view images.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:IUKN3-7HHlwC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"In the past years, there have been several attempts for the task of object localization in an image. However, most of the algorithms for object localization have been either supervised or weakly supervised. The work presented in this paper is based on the localization of a single object instance, in an image, in a fully unsupervised manner. Initially, from the input image, object proposals are generated where the proposal score for each of these proposals is calculated using a saliency map. Next, a graph by the GIST feature similarity between each pair of proposals is constructed. Density-based spatial clustering of applications with noise (DBSCAN) is used to make clusters of proposals based on GIST similarity, which eventually helps us in the final localization of the object. The setup is evaluated on two challenging benchmark datasets - PASCAL VOC 2007 dataset and object discovery dataset. The performance of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:VaXvl8Fpj5cC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Over-segmentation of an image into superpixels has become a useful tool for solving various problems in image processing and computer vision. Reflection symmetry is quite prevalent in both natural and man-made objects and is an essential cue in understanding and grouping the objects in natural scenes. Existing algorithms for estimating superpixels do not preserve the reflection symmetry of an object which leads to different sizes and shapes of superpixels across the symmetry axis. In this work, we propose an algorithm to over-segment an image through the propagation of reflection symmetry evident at the pixel level to superpixel boundaries. In order to achieve this goal, we first find the reflection symmetry in the image and represent it by a set of pairs of pixels which are mirror reflections of each other. We partition the image into superpixels while preserving this reflection symmetry through an iterative algorithm. We compare the proposed method with state-of-the-art superpixel generation methods and show the effectiveness in preserving the size and shape of superpixel boundaries across the reflection symmetry axes. We also present two applications, symmetry axes detection and unsupervised symmetric object segmentation, to illustrate the effectiveness of the proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:tYavs44e6CUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,"Reconstructing images using brain signals of imagined visuals may provide an augmented vision to the disabled, leading to the advancement of Brain-Computer Interface (BCI) technology. The recent progress in deep learning has boosted the study area of synthesizing images from brain signals using Generative Adversarial Networks (GAN). In this work, we have proposed a framework for synthesizing the images from the brain activity recorded by an electroencephalogram (EEG) using small-size EEG datasets. This brain activity is recorded from the subject's head scalp using EEG when they ask to visualize certain classes of Objects and English characters. We use a contrastive learning method in the proposed framework to extract features from EEG signals and synthesize the images from extracted features using conditional GAN. We modify the loss function to train the GAN, which enables it to synthesize 128x128 images using a small number of images. Further, we conduct ablation studies and experiments to show the effectiveness of our proposed framework over other state-of-the-art methods using the small EEG dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&citation_for_view=3YWptB8AAAAJ:1taIhTC69MYC,http://people.iitgn.ac.in/~shanmuga/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"We present , a new formal verification framework for the symbolic security analysis of cryptographic protocol code written in the programming language. Unlike automated symbolic provers, our framework accounts for advanced protocol features like unbounded loops and mutable recursive data structures, as well as low-level implementation details like protocol state machines and message formats, which are often at the root of real-world attacks. Our work extends a long line of research on using dependent type systems for this task, but takes a fundamentally new approach by explicitly modeling the global trace-based semantics within the framework, hence bridging the gap between trace-based and type-based protocol analyses. This approach enables us to uniformly, precisely, and soundly model, for the first time using dependent types, long-lived mutable protocol state, equational theories, fine-grained dynamic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:0EnyYjriUFMC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"The Noise protocol framework defines a succinct notation and execution framework for a large class of 59+ secure channel protocols, some of which are used in popular applications such as WhatsApp and WireGuard. We present a verified implementation of a Noise protocol compiler that takes any Noise protocol, and produces an optimized C implementation with extensive correctness and security guarantees. To this end, we formalize the complete Noise stack in F*, from the low-level cryptographic library to a high-level API. We write our compiler also in F*, prove that it meets our formal specification once and for all, and then specialize it on-demand for any given Noise protocol, relying on a novel technique called hybrid embedding. We thus establish functional correctness, memory safety and a form of side-channel resistance for the generated C code for each Noise protocol. We propagate these guarantees to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:_kc_bZDykSQC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"The ACME certificate issuance and management protocol, standardized as IETF RFC 8555, is an essential element of the web public key infrastructure (PKI). It has been used by Let's Encrypt and other certification authorities to issue over a billion certificates, and a majority of HTTPS connections are now secured with certificates issued through ACME. Despite its importance, however, the security of ACME has not been studied at the same level of depth as other protocol standards like TLS 1.3 or OAuth. Prior formal analyses of ACME only considered the cryptographic core of early draft versions of ACME, ignoring many security-critical low-level details that play a major role in the 100 page RFC, such as recursive data structures, long-running sessions with asynchronous sub-protocols, and the issuance for certificates that cover multiple domains.
We present the first in-depth formal security analysis of the ACME …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:KlAtU1dfN6UC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"Information flow type systems enforce the security property of noninterference by detecting unauthorized data flows at compile-time. However, they require precise type annotations, making them difficult to use in practice as much of the legacy infrastructure is written in untyped or dynamically-typed languages. Gradual typing seamlessly integrates static and dynamic typing, providing the best of both approaches, and has been applied to information flow control, where information flow monitors are derived from gradual security types. Prior work on gradual information flow typing uncovered tensions between noninterference and the dynamic gradual guarantee- the property that less precise security type annotations in a program should not cause more runtime errors.This paper re-examines the connection between gradual information flow types and information flow monitors to identify the root cause of the tension …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:8k81kl-MbHgC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:M3ejUd6NZC8C,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"is a recently proposed formal verification framework for the symbolic security analysis of cryptographic protocol code written in the programming language. Unlike automated symbolic provers, accounts for advanced protocol features like unbounded loops and mutable recursive data structures as well as low-level implementation details like protocol state machines and message formats, which are often at the root of real-world attacks. Protocols modeled in can be executed, and hence, tested, and they can even interoperate with real-world counterparts. extends a long line of research on using dependent type systems but takes a fundamentally new approach by explicitly modeling the global trace-based semantics within the framework, hence bridging the gap between trace-based and type-based protocol analyses. With this, one can uniformly, precisely, and soundly model, for the first time using …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:Zph67rFs4hoC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"Home automation rules that allow users to connect smart home devices using trigger-action programs (TAP) can interact in subtle and unexpected ways. Determining whether these rules are free of undesirable behavior is challenging; so researchers have developed tools to analyze rules and assist users. However, it is unclear whether users need such tools, and what help they need from such tools. To answer this question, we performed a user study where half of the participants were given our custom analysis tool SafeTAP and the other half were not. We found that users are not good at finding issues in their TAP rules, despite perceiving such tasks as easy. The user study also indicates that users would like to check their rules every time they make rule changes. Therefore, we designed a novel incremental symbolic model checking (SMC) algorithm, which extends the basic SMC algorithm of SafeTAP. SafeTAPΔ only performs analysis caused by the addition or removal of rules and reports only new violations that have not already been reported to the user. We evaluate the performance of SafeTAPΔ and show that incremental checking on average improves the performance by 6X when adding new rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:MXK_kJrjxJIC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"Database-backed applications rely on inlined policy checks to process users' private and confidential data in a policy-compliant manner as traditional database access control mechanisms cannot enforce complex policies. However, application bugs due to missed checks are common in such applications, which result in data breaches. While separating policy from code is a natural solution, many data protection policies specify restrictions based on the context in which data is accessed and how the data is used. Enforcing these restrictions automatically presents significant challenges, as the information needed to determine context requires a tight coupling between policy enforcement and an application's implementation.
We present Estrela, a framework for enforcing contextual and granular data access policies. Working from the observation that API endpoints can be associated with salient contextual information …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:ufrVoPGSRksC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"To prevent applications from leaking users' private data to attackers, researchers have developed runtime information flow control (IFC) mechanisms. Most existing approaches are either based on taint tracking or multi-execution, and the same technique is used to protect the entire application. However, today's applications are typically composed of multiple components from heterogenous and unequally trusted sources. The goal of this paper is to develop a framework to enable the flexible composition of IFC enforcement mechanisms. More concretely, we focus on reactive programs, which is an abstract model for event-driven programs including web and mobile applications. We formalize the semantics of existing IFC enforcement mechanisms with well-defined interfaces for composition, define knowledge-based security guarantees that can precisely quantify the effect of implicit leaks from taint tracking, and prove …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:qxL8FJ1GzNcC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"Information flow control (IFC) has been extensively studied as an approach to mitigate information leaks in applications. A vast majority of existing work in this area is based on static analysis. However, some applications, especially on the Web, are developed using dynamic languages like JavaScript where static analyses for IFC do not scale well. As a result, there has been a growing interest in recent years to develop dynamic or runtime information flow analysis techniques. In spite of the advances in the field, runtime information flow analysis has not been at the helm of information flow security, one of the reasons being that the analysis techniques and the security property related to them (non-interference) over-approximate information flows (particularly implicit flows), generating many false positives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:5nxA0vEk-isC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"Information flow type systems enforce the security property of noninterference by detecting unauthorized data flows at compile-time. However, they require precise type annotations, making them difficult to use in practice as much of the legacy infrastructure is written in untyped or dynamically-typed languages. Gradual typing seamlessly integrates static and dynamic typing, providing the best of both approaches, and has been applied to information flow control, where information flow monitors are derived from gradual security types. Prior work on gradual information flow typing uncovered tensions between noninterference and the dynamic gradual guarantee -- the property that less precise security type annotations in a program should not cause more runtime errors. This paper re-examines the connection between gradual information flow types and information flow monitors to identify the root cause of the tension between the gradual guarantees and noninterference. We develop runtime semantics for a simple imperative language with gradual information flow types that provides both noninterference and gradual guarantees. We leverage a proof technique developed for FlowML and reduce noninterference proofs to preservation proofs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:_FxGoFyzp5QC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"The Noise protocol framework defines a succinct notation and execution framework for a large class of 59+ secure channel protocols, some of which are used in popular applications such as WhatsApp and WireGuard. We present a verified implementation of a Noise protocol compiler that takes any Noise protocol, and produces an optimized C implementation with extensive correctness and security guarantees. To this end, we formalize the complete Noise stack in F*, from the low-level cryptographic library to a high-level API. We write our compiler also in F*, prove that it meets our formal specification once and for all, and then specialize it on-demand for any given Noise protocol, relying on a novel technique called hybrid embedding. We thusa establish functional correctness, memory safety and a form of side-channel resistance for the generated C code for each Noise protocol. We propagate these guarantees to the high-level API, using defensive dynamic checks to prevent incorrect uses of the protocol. Finally, we formally state and prove the security of our Noise code, by building on a symbolic model of cryptography in F*, and formally link high-level API security goals stated in terms of security levels to low-level cryptographic guarantees. Ours are the first comprehensive verification results for a protocol compiler that targets C code and the first verified implementations of any Noise protocol. We evaluate our framework by generating implementations for all 59 Noise protocols and by comparing the size, performance, and security of our verified code against other (unverified) implementations and prior security analyses of Noise.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&citation_for_view=qJavKW4AAAAJ:aqlVkmm33-oC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"DY* is a recently proposed formal verification framework for the symbolic security analysis of cryptographic protocol code written in the F* programming language. Unlike automated symbolic provers, DY* accounts for advanced protocol features like unbounded loops and mutable recursive data structures as well as low-level implementation details like protocol state machines and message formats, which are often at the root of real-world attacks. Protocols modeled in DY* can be executed, and hence, tested, and they can even interoperate with real-world counterparts. DY* extends a long line of research on using dependent type systems but takes a fundamentally new approach by explicitly modeling the global trace-based semantics within the framework, hence bridging the gap between trace-based and type-based protocol analyses. With this, one can uniformly, precisely, and soundly model, for the first time using dependent types, long-lived mutable protocol state, equational theories, fine-grained dynamic corruption, and trace-based security properties like forward secrecy and post-compromise security. In this paper, we provide a tutorial-style introduction to DY*: We illustrate how to model and prove the security of the ISO-DH protocol, a simple key exchange protocol based on Diffie-Hellman.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&cstart=20&pagesize=80&citation_for_view=qJavKW4AAAAJ:YOwf2qJgpHMC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",7,"The risk posed by high-profile data breaches has raised the stakes for adhering to data access policies for many organizations, but the complexity of both the policies themselves and the applications that must obey them raises significant challenges. To mitigate this risk, fine-grained audit of access to private data has become common practice, but this is a costly, time-consuming, and error-prone process.We propose an approach for automating much of the work required for fine-grained audit of private data access. Starting from the assumption that the auditor does not have an explicit, formal description of the correct policy, but is able to decide whether a given policy fragment is partially correct, our approach gradually infers a policy from audit log entries. When the auditor determines that a proposed policy fragment is appropriate, it is added to the system's mechanized policy, and future log entries to which the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&cstart=20&pagesize=80&citation_for_view=qJavKW4AAAAJ:hqOjcs7Dif8C,http://people.iitgn.ac.in/~abhishek/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",14,"Greybox fuzzing is an automated test-input generation technique that aims to uncover program errors by searching for bug-inducing inputs using a fitness-guided search process. Existing fuzzing approaches are primarily coverage-based. That is, they regard a test input that covers a new region of code as being fit to be retained. However, a vulnerability at a program location may not get exhibited in every execution that happens to visit to this program location; only certain program executions that lead to the location may expose the vulnerability. In this paper, we introduce a unified fitness metric called headroom, which can be used within greybox fuzzers, and which is explicitly oriented towards searching for test inputs that come closer to exposing vulnerabilities.
We have implemented our approach by enhancing AFL, which is a production quality fuzzing tool. We have instantiated our approach to detecting buffer …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&citation_for_view=fZq9W2cAAAAJ:IWHjjKOFINEC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",14,"Object sensitivity analysis is a well-known form of context-sensitive points-to analysis. This analysis is parameterized by a bound on the names of symbolic objects associated with each allocation site. In this paper, we propose a novel approach based on object sensitivity analysis that takes as input a set of client queries, and tries to answer them using an initial round of inexpensive object sensitivity analysis that uses a low object-name length bound at all allocation sites. For the queries that are answered unsatisfactorily, the approach then pin points ""bad"" points-to facts, which are the ones that are responsible for the imprecision. It then employs a form of program slicing to identify allocation sites that are potentially causing these bad points-to facts to be generated. The approach then runs object sensitivity analysis once again, this time using longer names for just these allocation sites, with the objective of resolving …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&citation_for_view=fZq9W2cAAAAJ:9ZlFYXVOiuMC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",14,"The synthesis of maximally-permissive controllers in infinite-state systems has many practical applications. Such controllers directly correspond to maximal winning strategies in logically specified infinite-state two-player games. In this paper, we introduce a tool called GenSys which is a fixed-point engine for computing maximal winning strategies for players in infinite-state safety games. A key feature of GenSys is that it leverages the capabilities of existing off-the-shelf solvers to implement its fixed point engine. GenSys outperforms state-of-the-art tools in this space by a significant margin. Our tool has solved some of the challenging problems in this space, is scalable, and also synthesizes compact controllers. These controllers are comparatively small in size and easier to comprehend. GenSys is freely available for use and is available under an open-source license.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&cstart=20&pagesize=80&citation_for_view=fZq9W2cAAAAJ:L8Ckcad2t8MC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",14,"Buffer-overruns are a prevalent vulnerability in software libraries and applications. Fuzz testing is one of the effective techniques to detect vulnerabilities in general. Greybox fuzzers such as AFL automatically generate a sequence of test inputs for a given program using a fitness-guided search process. A recently proposed approach in the literature introduced a buffer-overrun specific fitness metric called ""headroom"", which tracks how close each generated test input comes to exposing the vulnerabilities. That approach showed good initial promise, but is somewhat imprecise and expensive due to its reliance on conservative points-to analysis. Inspired by the approach above, in this paper we propose a new ground-up approach for detecting buffer-overrun vulnerabilities. This approach uses an extended version of ASAN (Address Sanitizer) that runs in parallel with the fuzzer, and reports back to the fuzzer test inputs that happen to come closer to exposing buffer-overrun vulnerabilities. The ASAN-style instrumentation is precise as it has no dependence on points-to analysis. We describe in this paper our approach, as well as an implementation and evaluation of the approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&cstart=20&pagesize=80&citation_for_view=fZq9W2cAAAAJ:TQgYirikUcIC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",14,"In this work we describe a novel approach for modeling, analysis and verification of database-accessing applications that use the ORM (Object Relational Mapping) paradigm. Rather than directly analyze ORM code to check specific properties, our approach infers a general-purpose relational algebra summary of each controller in the application. This summary can then be fed into any off-the-shelf relational algebra solver to check for properties or specifications given by a developer. The summaries can also aid program understanding, and may have other applications. We have implemented our approach as a prototype tool that works for 'Spring' based MVC applications. A preliminary evaluation reveals that the approach is efficient, and gives good results while checking a set of properties given by human subjects.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&cstart=20&pagesize=80&citation_for_view=fZq9W2cAAAAJ:HDshCWvjkbEC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",14,"Asynchronous message-passing systems are employed frequently to implement distributed mechanisms, protocols, and processes. This paper addresses the problem of precise data flow analysis for such systems. To obtain good precision, data flow analysis needs to somehow skip execution paths that read more messages than the number of messages sent so far in the path, as such paths are infeasible at run time. Existing data flow analysis techniques do elide a subset of such infeasible paths, but have the restriction that they admit only finite abstract analysis domains. In this paper we propose a generalization of these approaches to admit infinite abstract analysis domains, as such domains are commonly used in practice to obtain high precision. We have implemented our approach, and have analyzed its performance on a set of 14 benchmarks. On these benchmarks our tool obtains significantly higher precision compared to a baseline approach that does not elide any infeasible paths and to another baseline that elides infeasible paths but admits only finite abstract domains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&cstart=20&pagesize=80&citation_for_view=fZq9W2cAAAAJ:7PzlFSSx8tAC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",14,"Innovations in Software Engineering Conference (ISEC) is the flagship annual conference of iSoft, which is an arm of ACM India and serves as the India chapter of ACM SIGSOFT. The 13th edition of ISEC is to be held at IIITDM Jabalpur during the period February 27-29 2020, and will hold a PhD Symposium. The objective of the PhD Symposium is to provide for a forum for junior as well senior level PhD students working in the field of software engineering to present their work in a friendly setting, to get feedback on their direction from experts, to present posters about their work to the ISEC attendees, and to interact and network with each other. This report summarizes the motivation for this symposium and the plan for the event, and lists the full set of accepted submissions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&cstart=20&pagesize=80&citation_for_view=fZq9W2cAAAAJ:hC7cP41nSMkC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",14,"Verifying whether a procedure is observationally pure (that is, it always returns the same result for the same input argument) is challenging when the procedure uses mutable (private) global variables, e.g., for memoization, and when the procedure is recursive.
We present a deductive verification approach for this problem. Our approach encodes the procedure’s code as a logical formula, with recursive calls being modeled using a mathematical function symbol assuming that the procedure is observationally pure. Then, a theorem prover is invoked to check whether this logical formula agrees with the function symbol referred to above in terms of input-output behavior for all arguments. We prove the soundness of this approach.
We then present a conservative approximation of the first approach that reduces the verification problem to one of checking whether a quantifier-free formula is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&cstart=20&pagesize=80&citation_for_view=fZq9W2cAAAAJ:hFOr9nPyWt4C,http://www.csa.iisc.ernet.in/~raghavan/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"TD (0) is one of the most commonly used algorithms in reinforcement learning. Despite this, there is no existing finite sample analysis for TD (0) with function approximation, even for the linear case. Our work is the first to provide such results. Existing convergence rates for Temporal Difference (TD) methods apply only to somewhat modified versions, eg, projected variants or ones where stepsizes depend on unknown problem parameters. Our analyses obviate these artificial alterations by exploiting strong properties of TD (0). We provide convergence rates both in expectation and with high-probability. The two are obtained via different approaches that use relatively unknown, recently developed stochastic approximation techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:ZHo1McVdvXMC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"Two-timescale Stochastic Approximation (SA) algorithms are widely used in Reinforcement Learning (RL). Their iterates have two parts that are updated using distinct stepsizes. In this work, we develop a novel recipe for their finite sample analysis. Using this, we provide a concentration bound, which is the first such result for a two-timescale SA. The type of bound we obtain is known as “lock-in probability”. We also introduce a new projection scheme, in which the time between successive projections increases exponentially. This scheme allows one to elegantly transform a lock-in probability into a convergence rate result for projected two-timescale SA. From this latter result, we then extract key insights on stepsize selection. As an application, we finally obtain convergence rates for the projected two-timescale RL algorithms GTD (0), GTD2, and TDC.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:pqnbT2bcN3wC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"Given an ordinary differential equation (ODE) and its perturbation, the Alekseev formula expresses the solutions of the latter in terms related to the former. By exploiting this formula and a new concentration inequality for martingale-differences, we develop a novel approach for analyzing nonlinear stochastic approximation (SA). This approach is useful for studying a SA’s behavior close to a locally asymptotically stable equilibrium (LASE) of its limiting ODE; this LASE need not be the limiting ODE’s only attractor. As an application, we obtain a new concentration bound for nonlinear SA. That is, given ϵ > and that the current iterate is in a neighborhood of a LASE, we provide an estimate for (i) the time required to hit the ϵ-ball of this LASE, and (ii) the probability that after this time the iterates are indeed within this ϵ-ball and stay there thereafter. The latter estimate can also be viewed as the “lock-in” probability …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:M05iB0D1s5AC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"Policy evaluation in reinforcement learning is often conducted using two-timescale stochastic approximation, which results in various gradient temporal difference methods such as GTD (0), GTD2, and TDC. Here, we provide convergence rate bounds for this suite of algorithms. Algorithms such as these have two iterates, θ n and w n, which are updated using two distinct stepsize sequences, α n and β n, respectively. Assuming α n= n− α and β n= n− β with 1> α> β> 0, we show that, with high probability, the two iterates converge to their respective solutions θ* and w* at rates given by∥ θ n-θ*∥= Õ (n− α/2) and∥ w n-w*∥= Õ (n− β/2); here, Õ hides logarithmic terms. Via comparable lower bounds, we show that these bounds are, in fact, tight. To the best of our knowledge, ours is the first finite-time analysis which achieves these rates. While it was known that the two timescale components decouple asymptotically, our results depict this phenomenon more explicitly by showing that it in fact happens from some finite time onwards. Lastly, compared to existing works, our result applies to a broader family of stepsizes, including non-square summable ones.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:dfsIfKJdRG4C,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"A weighted complex is a simplicial complex of dimension in which each face is assigned a real-valued weight. We derive three key results here concerning persistence diagrams and minimal spanning acycles (MSAs) of such complexes. First, we establish an equivalence between the MSA face-weights and \emph{death times} in the persistence diagram. Next, we show a novel stability result for the MSA face-weights which, due to our first result, also holds true for the death and birth times, separately. Our final result concerns a perturbation of a mean-field model of randomly weighted complexes. The face weights here are perturbation of some i.i.d. distribution while all the lower-dimensional faces have a weight of . If the perturbations decay sufficiently quickly, we show that suitably scaled extremal nearest face-weights, face-weights of the MSA, and the associated death times converge to an inhomogeneous Poisson point process. This result completely characterizes the extremal points of persistence diagrams and MSAs. The point process convergence and the asymptotic equivalence of three point processes are new for any weighted random complex model, including even the non-perturbed case. Lastly, as a consequence of our stability result, we show that Frieze's limit for random minimal spanning trees and the recent extension to random MSAs by Hino and Kanazawa also hold in suitable noisy settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:g5m5HwL7SMYC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"A search engine maintains local copies of different web pages to provide quick search results. This local cache is kept up-to-date by a web crawler that frequently visits these different pages to track changes in them. Ideally, the local copy should be updated as soon as a page changes on the web. However, finite bandwidth availability and server restrictions limit how frequently different pages can be crawled. This brings forth the following optimization problem: maximize the freshness of the local cache subject to the crawling frequencies being within prescribed bounds. While tractable algorithms do exist to solve this problem, these either assume the knowledge of exact page change rates or use inefficient methods such as MLE for estimating the same. We address this issue here.
We provide three novel schemes for online estimation of page change rates, all of which have extremely low running times per iteration …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:SeFeTyx0c_EC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"For providing quick and accurate results, a search engine maintains a local snapshot of the entire web. And, to keep this local cache fresh, it employs a crawler for tracking changes across various web pages. However, finite bandwidth availability and server restrictions impose some constraints on the crawling frequency. Consequently, the ideal crawling rates are the ones that maximise the freshness of the local cache and also respect the above constraints.
Azar et al. [2] recently proposed a tractable algorithm to solve this optimisation problem. However, they assume the knowledge of the exact page change rates, which is unrealistic in practice. We address this issue here. Specifically, we provide two novel schemes for online estimation of page change rates. Both schemes only need partial information about the page change process, i.e., they only need to know if the page has changed or not since the last crawled …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:cFHS6HbyZ2cC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"The topological study of existing random simplicial complexes is non-trivial and has led to several seminal works. However, the applicability of such studies is limited since a single parameter usually governs the randomness in these models. With this in mind, we focus here on the topology of the recently proposed multi-parameter random simplicial complex. In particular, we introduce a dynamic variant of this model and look at how its topology evolves. In this dynamic setup, the temporal evolution of simplices is determined by stationary and possibly non-Markovian processes with a renewal structure. Special cases of this setup include the dynamic versions of the clique complex and the Linial–Meshulam complex. Our key result concerns the regime where the face-count of a particular dimension dominates. We show that the Betti number corresponding to this dimension and the Euler characteristic satisfy a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:4OULZ7Gr8RgC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"Random field excursions is an increasingly vital topic within data analysis in medicine, cosmology, materials science, etc. This work is the first detailed study of their Betti numbers in the so-called `sparse' regime. Specifically, we consider a piecewise constant Gaussian field whose covariance function is positive and satisfies some local, boundedness, and decay rate conditions. We model its excursion set via a Cech complex. For Betti numbers of this complex, we then prove various limit theorems as the window size and the excursion level together grow to infinity. Our results include asymptotic mean and variance estimates, a vanishing to non-vanishing phase transition with a precise estimate of the transition threshold, and a weak law in the non-vanishing regime. We further obtain a Poisson approximation and a central limit theorem close to the transition threshold. Our proofs combine extreme value theory and combinatorial topology tools.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:70eg2SAEIzsC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:UxriW0iASnsC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"In Multi-Agent Reinforcement Learning (MARL), multiple agents interact with a common environment, as also with each other, for solving a shared problem in sequential decision-making. It has wide-ranging applications in gaming, robotics, finance, communication, etc. In this work, we derive a novel law of iterated logarithm for a family of distributed nonlinear stochastic approximation schemes that is useful in MARL. In particular, our result describes the convergence rate on almost every sample path where the algorithm converges. This result is the first of its kind in the distributed setup and provides deeper insights than the existing ones, which only discuss convergence rates in the expected or the CLT sense. Importantly, our result holds under significantly weaker assumptions: neither the gossip matrix needs to be doubly stochastic nor the stepsizes square summable. As an application, we show that, for the stepsize with the distributed TD (0) algorithm with linear function approximation has a convergence rate of as; for the type stepsize, the same is as These decay rates do not depend on the graph depicting the interactions among the different agents.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:abG-DnoFyZgC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"Frieze showed that the expected weight of the minimum spanning tree (MST) of the uniformly weighted graph converges to . Recently, this result was extended to a uniformly weighted simplicial complex, where the role of the MST is played by its higher-dimensional analogue -- the Minimum Spanning Acycle (MSA). In this work, we go beyond and look at the histogram of the weights in this random MSA -- both in the bulk and in the extremes. In particular, we focus on the `incomplete' setting, where one has access only to a fraction of the potential face weights. Our first result is that the empirical distribution of the MSA weights asymptotically converges to a measure based on the shadow -- the complement of graph components in higher dimensions. As far as we know, this result is the first to explore the connection between the MSA weights and the shadow. Our second result is that the extremal weights converge to an inhomogeneous Poisson point process. A interesting consequence of our two results is that we can also state the distribution of the death times in the persistence diagram corresponding to the above weighted complex, a result of interest in applied topology.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:pyW8ca7W8N0C,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:NhqRSupF_l8C,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"We consider the measurement model where and, hence, are random variables and is an a priori known tall matrix. At each time instance, a sample of one of 's coordinates is available, and the goal is to estimate via these samples. However, the challenge is that a small but unknown subset of 's coordinates are controlled by adversaries with infinite power: they can return any real number each time they are queried for a sample. For such an adversarial setting, we propose the first asynchronous online algorithm that converges to almost surely. We prove this result using a novel differential inclusion based two-timescale analysis. Two key highlights of our proof include: (a) the use of a novel Lyapunov function for showing that is the unique global attractor for our algorithm's limiting dynamics, and (b) the use of martingale and stopping time theory to show that our algorithm's iterates are almost surely bounded.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:738O_yMBCRsC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"Despite the popularity of policy gradient methods, they are known to suffer from large variance and high sample complexity. To mitigate this, we introduce SoftTreeMax -- a generalization of softmax that takes planning into account. In SoftTreeMax, we extend the traditional logits with the multi-step discounted cumulative reward, topped with the logits of future states. We consider two variants of SoftTreeMax, one for cumulative reward and one for exponentiated reward. For both, we analyze the gradient variance and reveal for the first time the role of a tree expansion policy in mitigating this variance. We prove that the resulting variance decays exponentially with the planning horizon as a function of the expansion policy. Specifically, we show that the closer the resulting state transitions are to uniform, the faster the decay. In a practical implementation, we utilize a parallelized GPU-based simulator for fast and efficient tree search. Our differentiable tree-based policy leverages all gradients at the tree leaves in each environment step instead of the traditional single-sample-based gradient. We then show in simulation how the variance of the gradient is reduced by three orders of magnitude, leading to better sample complexity compared to the standard policy gradient. On Atari, SoftTreeMax demonstrates up to 5x better performance in a faster run time compared to distributed PPO. Lastly, we demonstrate that high reward correlates with lower variance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:XiSMed-E-HIC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,"Evolution Strategy (ES) is a powerful black-box optimization technique based on the idea of natural evolution. In each of its iterations, a key step entails ranking candidate solutions based on some fitness score. For an ES method in Reinforcement Learning (RL), this ranking step requires evaluating multiple policies. This is presently done via on-policy approaches: each policy's score is estimated by interacting several times with the environment using that policy. This leads to a lot of wasteful interactions since, once the ranking is done, only the data associated with the top-ranked policies is used for subsequent learning. To improve sample efficiency, we propose a novel off-policy alternative for ranking, based on a local approximation for the fitness function. We demonstrate our idea in the context of a state-of-the-art ES method called the Augmented Random Search (ARS). Simulations in MuJoCo tasks show that, compared to the original ARS, our off-policy variant has similar running times for reaching reward thresholds but needs only around 70% as much data. It also outperforms the recent Trust Region ES. We believe our ideas should be extendable to other ES methods as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&citation_for_view=X5zV3s8AAAAJ:OU6Ihb5iCvQC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&cstart=20&pagesize=80&citation_for_view=X5zV3s8AAAAJ:xtRiw3GOFMkC,https://sites.google.com/site/gugancth/
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"In topological data analysis and visualization, topological descriptors such as persistence diagrams, merge trees, contour trees, Reeb graphs, and Morse–Smale complexes play an essential role in capturing the shape of scalar field data. We present a state‐of‐the‐art report on scalar field comparison using topological descriptors. We provide a taxonomy of existing approaches based on visualization tasks associated with three categories of data: single fields, time‐varying fields, and ensembles. These tasks include symmetry detection, periodicity detection, key event/feature detection, feature tracking, clustering, and structure statistics. Our main contributions include the formulation of a set of desirable mathematical and computational properties of comparative measures, and the classification of visualization tasks and applications that are enabled by these measures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:qYOp8iumCsAC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Analyzing depressions plays an important role in meteorology, especially in the study of cyclones. In particular, the study of the temporal evolution of cyclones requires a robust depression tracking framework. To cope with this demand we propose a pipeline for the exploration of cyclones and their temporal evolution. This entails a generic framework for their identification and tracking. The fact that depressions and cyclones are not well-defined objects and their shape and size characteristics change over time makes this task especially challenging. Our method combines the robustness of topological approaches and the detailed tracking information from optical flow analysis. At first cyclones are identified within each time step based on well-established topological concepts. Then candidate tracks are computed from an optical flow field. These tracks are clustered within a moving time window to distill dominant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:qSd0DAb9jMoC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Topological structures such as the merge tree provide an abstract and succinct representation of scalar fields. They facilitate effective visualization and interactive exploration of feature-rich data. A merge tree captures the topology of sub-level and super-level sets in a scalar field. Estimating the similarity between merge trees is an important problem with applications to feature-directed visualization of time-varying data. We present an approach based on tree edit distance to compare merge trees. The comparison measure satisfies metric properties, it can be computed efficiently, and the cost model for the edit operations is both intuitive and captures well-known properties of merge trees. Experimental results on time-varying scalar fields, 3D cryo electron microscopy data, shape data, and various synthetic datasets show the utility of the edit distance towards a feature-driven analysis of scalar fields.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:ZYsTHYU9jrMC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,The study of electronic transitions within a molecule connected to the absorption or emission of light is a common task in the process of the design of new materials. The transitions are complex quantum mechanical processes and a detailed analysis requires a breakdown of these processes into components that can be interpreted via characteristic chemical properties. We approach these tasks by providing a detailed analysis of the electron density field. This entails methods to quantify and visualize electron localization and transfer from molecular subgroups combining spatial and abstract representations. The core of our method uses geometric segmentation of the electronic density field coupled with a graph‐theoretic formulation of charge transfer between molecular subgroups. The design of the methods has been guided by the goal of providing a generic and objective analysis following fundamental concepts …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:T_0gP6tLVL0C,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"A wide range of data that appear in scientific experiments and simulations are multivariate or multifield in nature, consisting of multiple scalar fields. Topological feature search of such data aims to reveal important properties useful to the domain scientists. It has been shown in recent works that a single scalar field is insufficient to capture many important topological features in the data, instead one needs to consider topological relationships between multiple scalar fields. In the current paper, we propose a novel method of finding similarity between two multifield data by comparing their respective fiber component distributions. Given a time-varying multifield data, the method computes a metric plot for each pair of histograms at consecutive time stamps to understand the topological changes in the data over time. We validate the method using real and synthetic data. The effectiveness of the proposed method is shown by its ability to capture important topological features that are not always possible to detect using the individual component scalar fields.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:k8to_Y4Q4_EC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Comparative analysis of scalar fields is an important problem with various applications including feature-directed visualization and feature tracking in time-varying data. Comparing topological structures that are abstract and succinct representations of the scalar fields lead to faster and meaningful comparison. While there are many distance or similarity measures to compare topological structures in a global context, there are no known measures for comparing topological structures locally. While the global measures have many applications, they do not directly lend themselves to fine-grained analysis across multiple scales. We define a local variant of the tree edit distance and apply it towards local comparative analysis of merge trees with support for finer analysis. We also present experimental results on time-varying scalar fields, 3D cryo-electron microscopy data, and other synthetic data sets to show the utility of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:WgvcDLhf7hwC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Electronic transitions in molecules due to absorption or emission of light is a complex quantum mechanical process. Their study plays an important role in the design of novel materials. A common yet challenging task in the study is to determine the nature of those electronic transitions, i.e. which subgroups of the molecule are involved in the transition by donating or accepting electrons, followed by an investigation of the variation in the donor-acceptor behavior for different transitions or conformations of the molecules. In this paper, we present a novel approach towards the study of electronic transitions based on the visual analysis of a bivariate field, namely the electron density in the hole and particle Natural Transition Orbital (NTO). The visual analysis focuses on the continuous scatter plots (CSPs) of the bivariate field linked to their spatial domain. The method supports selections in the CSP visualized as fiber …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:4uoR24qA-WYC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"The Morse-Smale complex is a well studied topological structure that represents the gradient flow behavior of a scalar function. It supports multi-scale topological analysis and visualization of large scientific data. Its computation poses significant algorithmic challenges when considering large scale data and increased feature complexity. Several parallel algorithms have been proposed towards the fast computation of the 3D Morse-Smale complex. The non-trivial structure of the saddle-saddle connections are not amenable to parallel computation. This paper describes a fine grained parallel method for computing the Morse-Smale complex that is implemented on a GPU. The saddle-saddle reachability is first determined via a transformation into a sequence of vector operations followed by the path traversal, which is achieved via a sequence of matrix operations. Computational experiments show that the method …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:sYWwZaPVD1oC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"The alpha complex, a subset of the Delaunay triangulation, has been extensively used as the underlying representation for biomolecular structures. We propose a GPU-based parallel algorithm for the computation of the alpha complex, which exploits the knowledge of typical spatial distribution and sizes of atoms in a biomolecule. Unlike existing methods, this algorithm does not require prior construction of the Delaunay triangulation. The algorithm computes the alpha complex in two stages. The first stage proceeds in a bottom-up fashion and computes a superset of the edges, triangles, and tetrahedra belonging to the alpha complex. The false positives from this estimation stage are removed in a subsequent pruning stage to obtain the correct alpha complex. Computational experiments on several biomolecules demonstrate the superior performance of the algorithm, up to a factor of 50 when compared to existing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:SgM-ki2adj0C,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"We present a pipeline for the interactive visual analysis and exploration of molecular electronic transition ensembles. Each ensemble member is specified by a molecular configuration, the charge transfer between two molecular states, and a set of physical properties. The pipeline is targeted towards theoretical chemists, supporting them in comparing and characterizing electronic transitions by combining automatic and interactive visual analysis. A quantitative feature vector characterizing the electron charge transfer serves as the basis for hierarchical clustering as well as for the visual representations. The interface for the visual exploration consists of four components. A dendrogram provides an overview of the ensemble. It is augmented with a level of detail glyph for each cluster. A scatterplot using dimensionality reduction provides a second visualization, highlighting ensemble outliers. Parallel coordinates show …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:VBDT71xRUdcC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Topology driven methods for analysis of scalar fields often begin with an exploration of an abstract topological structure such as the merge tree. Such abstractions are hard to interpret and time-consuming, particularly for feature-rich data. Current visualization schemes often place less emphasis on enriching user experience, human perception, or interaction. In this work, we aim to bridge that gap by utilizing treemaps towards effective topological analysis. We present mergemaps, a treemap based interactive design, to better understand merge trees. To aid the perceptual understanding of large merge trees, we provide fusing and diffusing operations to reduce its hierarchical size while preserving topological features. We show multiple examples where our design leads to easy interpretations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:EsrhoZGmrkoC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Topological methods for data analysis have proven to be useful in multiple contexts ranging from exploring molecular surfaces to understanding cyclones. While abstract topological representations are powerful, they are still yet to gain widespread popularity, because their interpretation requires background in algebraic topology and Morse theory. To this extent, multiple attempts have been made to provide user interfaces that convey topological information in an intuitive manner. In this work, we aim at improving the understanding of a topological abstraction called merge tree.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:e0LTWoPxLYMC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Topology based analysis and feature tracking is a well studied area. In this work, we focus exclusively on a dataset called the von Kármán street, and apply topology-based methods to understand its vortices. For this analysis, we adapt the recently proposed edit distance between merge trees. We discern several interesting results. One, we observe spatial periodicity between the vortices, alternating every half-cycle. Two, we observe a distinct difference in spatial probability of vortex regions during a half-cycle. Further, we compare the accuracy of our spatial probability with an off-the-shelf machine learning approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:w0odbtu79TwC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,The contour tree represents the topology of level sets of a scalar function. Nodes of the tree correspond to critical level sets and arcs of the tree represent a collection of topologically equivalent level sets connecting two critical level sets. The augmented contour tree contains degree-2 nodes on the arcs that represent regular level sets. The degree-2 nodes correspond to regular points of the scalar function and other critical points that do not affect the number of level set components. The augmented contour tree is significantly larger in size and requires more effort to compute when compared to the contour tree. Applications of the contour tree to data exploration and visualization require the augmented contour tree. Current approaches propose algorithms to compute the contour tree and the augmented contour tree from scratch. Precomputing and storing the large augmented contour tree will not be necessary if the …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:4tNoA7Af41QC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"The Morse-Smale complex is a well studied topological structure that represents the gradient flow behavior between critical points of a scalar function. It supports multi-scale topological analysis and visualization of feature-rich scientific data. Several parallel algorithms have been proposed towards the fast computation of the 3D Morse-Smale complex. Its computation continues to pose significant algorithmic challenges. In particular, the non-trivial structure of the connections between the saddle critical points are not amenable to parallel computation. This paper describes a fine grained parallel algorithm for computing the Morse-Smale complex and a GPU implementation (gMSC). The algorithm first determines the saddle-saddle reachability via a transformation into a sequence of vector operations, and next computes the paths between saddles by transforming it into a sequence of matrix operations. Computational …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:DwFgw5hZUzMC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"A new method for identifying Rossby wave packets (RWPs) using 6-hourly data from the ERA-Interim is presented. The method operates entirely in the spatial domain and relies on the geometric and topological properties of the meridional wind field to identify RWPs. The method represents RWPs as nodes and edges of a dual graph instead of the more common envelope representation. This novel representation allows access to both RWP phase and amplitude information. Local maxima and minima of the meridional wind field are collected into groups. Each group, called a υ -max cluster or υ -min cluster of the meridional wind field, represents a potential wave component. Nodes of the dual graph represent a υ -max cluster or υ -min cluster. Alternating υ -max clusters and υ -min clusters are linked by edges of the dual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:-fu4zM_6qcIC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"The extremum graph is a succinct representation of the Morse decomposition of a scalar field. It has increasingly become a useful data structure that supports topological feature‐directed visualization of 2D/3D scalar fields, and enables dimensionality reduction together with exploratory analysis of high‐dimensional scalar fields. Current methods that employ the extremum graph compute it either using a simple sequential algorithm for computing the Morse decomposition or by computing the more detailed Morse–Smale complex. Both approaches are typically limited to two and three‐dimensional scalar fields. We describe a GPU–CPU hybrid parallel algorithm for computing the extremum graph of scalar fields in all dimensions. The proposed shared memory algorithm utilizes both fine‐grained parallelism and task parallelism to achieve efficiency. An open source software library, tachyon, that implements the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:djft3U1LymYC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Electronic transitions in molecules due to the absorption or emission of light is a complex quantum mechanical process. Their study plays an important role in the design of novel materials. A common yet challenging task in the study is to determine the nature of electronic transitions, namely which subgroups of the molecule are involved in the transition by donating or accepting electrons, followed by an investigation of the variation in the donor-acceptor behavior for different transitions or conformations of the molecules. In this paper, we present a novel approach for the analysis of a bivariate field and show its applicability to the study of electronic transitions. This approach is based on two novel operators, the continuous scatterplot (CSP) lens operator and the CSP peel operator, that enable effective visual analysis of bivariate fields. Both operators can be applied independently or together to facilitate analysis. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:0urtJCGzaFQC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Isosurfaces are an important tool for analysis and visualization of univariate scalar fields. Earlier works have demonstrated the presence of interesting isosurfaces at isovalues close to critical values. This motivated the development of efficient methods for computing individual components of isosurfaces restricted to a region of interest. Generalization of isosurfaces to fiber surfaces and critical points to Jacobi sets has resulted in new approaches for analyzing bivariate scalar fields. Unlike isosurfaces, there exists no output sensitive method for computing fiber surfaces. Existing methods traverse through all the tetrahedra in the domain. In this paper, we propose the use of the Jacobi set to identify fiber surface components of interest and present an output sensitive approach for its computation. The Jacobi edges are used to initiate the search towards seed tetrahedra that contain the fiber surface, thereby reducing the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:w5CyTnyFq80C,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"This article presents a robust Morse theory-based framework for segmenting 3D X-ray computed tomography image (CT) and computing the fabric, relative arrangement of particles, of granular ensembles. The framework includes an algorithm for computing the segmentation, a data structure for storing the segmentation and representing both individual particles and the connectivity network, and visualizations of topological descriptors of the CT image that enable interactive exploration. The Morse theory-based framework produces superior quality segmentation of a granular ensemble as compared to prior approaches based on the watershed transform. The accuracy of the connectivity network also improves. Further, the framework supports the efficient computation of various distribution statistics on the segmentation and the connectivity network. Such a comprehensive characterization and quantification of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:puFLaqDw8dcC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"The Bay of Bengal (BoB) fosters several monsoon depressions and cyclones, playing a crucial role in the Asian summer and winter monsoons. The capacity of the bay to remain warm and energize such weather systems is attributed to its strong vertical stratification sustained by the large freshwater input into the bay. River runoff and rainfall into the northern bay in contrast to the high salinity water intrusion in the south creates a strong north–south salinity gradient. Here, we present a visual analysis tool to trace the path of the high salinity core (HSC) entering into the BoB from the Arabian Sea. We introduce two feature definitions that represent the movement and shape of the HSC, and algorithms to track their evolution over time. The two feature representations, namely fronts and skeletons, are based on geometric and topological analysis of the HSC. The method is validated via comparison with well established …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:ibZ2AwG9z6wC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Topological Data Analysis has become, over the last few years, an established framework for the extraction and analysis of subtle structural patterns in complex data. It has been successfully applied in a variety of application fields, including quantum chemistry, astrophysics, fluid dynamics, combustion, material sciences, biology, and data science. In particular, the genericity, efficiency, and robustness of topological methods have made them particularly well suited for the multi-scale, interactive analysis and visualization of the structural information of data.
Despite their rising mainstream popularity, topological methods still face a number of challenges, including, for instance efficient computational methods for large-scale time-varying data, the characterization of noise and uncertainty, or the support of novel emerging data types such as ensemble data or high-dimensional point clouds.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:mS4qin7VKjkC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"In time-varying scientific datasets, the temporal evolution of interesting topological features is commonly displayed and explored using isosurfaces and tracking graphs. However, the visual representation of such tracking graphs supports only few interactive capabilities. Further, they capture information at a high level that requires specification of carefully chosen parameter values. To bridge this gap, we propose persistenceBundles, a flexible visualization metaphor that utilizes a hierarchical edge-bundling approach for visualizing tracked features using persistence hierarchies, and implicitly allows for intuitive interaction schemes. We demonstrate the effectiveness of our approach using the viscous finger dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:PklR0melJeUC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"A new method for identifying Rossby wave packets (RWPs) using 6-hourly data from the ERA-Interim is presented. The method operates entirely in the spatial domain and relies on the geometric and topological properties of the meridional wind field to identify RWPs. The method represents RWPs as nodes and edges of a dual graph instead of the more common envelope representation. This novel representation allows access to both RWP phase and amplitude information. Local maxima and minima of the meridional wind field are collected into groups. Each group, called a υ-max cluster or υ-min cluster of the meridional wind field, represents a potential wave component. Nodes of the dual graph represent a υ-max cluster or υ-min cluster. Alternating υ-max clusters and υ-min clusters are linked by edges of the dual graph, called the RWP association graph. Amplitude and discrete gradient-based filtering applied on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:R6EwkKsDylYC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"Critical weather applications such as cyclone tracking require online visualization simultaneously performed with the simulations so that the scientists can provide real-time guidance to decision makers. However, resource constraints such as slow networks can hinder online remote visualization. In this work, we have developed an adaptive framework for efficient online remote visualization of critical weather applications. We present three algorithms, namely, most-recent, auto-clustering and adaptive, for reducing lag between the simulation and visualization times. Using experiments with different network configurations, we find that the adaptive algorithm strikes a good balance in providing reduced lags and visualizing most representative frames, with up to 72% smaller lag than auto-clustering, and 37% more representative than most-recent for slow networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:uWy0R8PweswC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",27,"This report documents the program and the outcomes of Dagstuhl Seminar 19212"" Topology, Computation and Data Analysis"". The seminar brought together researchers with mathematical and computational backgrounds in addressing emerging directions within computational topology for data analysis in practice. This seminar was designed to be a followup event after a very successful Dagstuhl Seminar (17292; July 2017). The list of topics and participants were updated to keep the discussions diverse, refreshing, and engaging. This seminar facilitated close interactions among the attendees with the aim of accelerating the convergence between mathematical and computational thinking in the development of theories and scalable algorithms for data analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&citation_for_view=yePyztMAAAAJ:bbjcffOLshcC,https://www.csa.iisc.ac.in/~vijayn
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"Attributed network embedding has received much interest from the research community as most of the networks come with some content in each node, which is also known as node attributes. Existing attributed network approaches work well when the network is consistent in structure and attributes, and nodes behave as expected. But real world networks often have anomalous nodes. Typically these outliers, being relatively unexplainable, affect the embeddings of other nodes in the network. Thus all the downstream network mining tasks fail miserably in the presence of such outliers. Hence an integrated approach to detect anomalies and reduce their overall effect on the network embedding is required.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&citation_for_view=VQZTmpcAAAAJ:sA9dB-pw3HoC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"The topic of identifying objects that stand out from the norm in a data set is an exciting one in the field of data mining. Detecting such objects, known as outliers, is important for many applications such as fraud detection, network analysis, etc. Given the significance of outlier detection in real life scenarios, we chose to focus on this challenging research topic in this book. Contents of this book are mainly derived from the research work carried out towards Ph. D. thesis of the first author at Indian Institute of Science (IISc), Bangalore, under the supervision of the co-authors. The book itself is the outcome of the recommendation made by Prof. Lakhmi C. Jain, University of Canberra, suggesting us to produce a monograph based on our understanding of this research area.
The first part of the book touches upon the significant aspects of the problem that are useful in carrying out further research on related issues. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:Wq2b2clWBLsC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"Attributed network embedding is the task to learn a lower dimensional vector representation of the nodes of an attributed network, which can be used further for downstream network mining tasks. Nodes in a network exhibit community structure and most of the network embedding algorithms work well when the nodes, along with their attributes, adhere to the community structure of the network. But real life networks come with community outlier nodes, which deviate significantly in terms of their link structure or attribute similarities from the other nodes of the community they belong to. These outlier nodes, if not processed carefully, can even affect the embeddings of the other nodes in the network. Thus, a node embedding framework for dealing with both the link structure and attributes in the presence of outliers in an unsupervised setting is practically important. In this work, we propose a deep unsupervised …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:RJOyoaXV5v8C,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"Analysis and visualization of an information network can be facilitated better using an appropriate embedding of the network. Network embedding learns a compact low-dimensional vector representation for each node of the network, and uses this lower dimensional representation for different network analysis tasks. Only the structure of the network is considered by a majority of the current embedding algorithms. However, some content is associated with each node, in most of the practical applications, which can help to understand the underlying semantics of the network. It is not straightforward to integrate the content of each node in the current state-of-the-art network embedding methods. In this paper, we propose a nonnegative matrix factorization based optimization framework, namely FSCNMF which considers both the network structure and the content of the nodes while learning a lower dimensional representation of each node in the network. Our approach systematically regularizes structure based on content and vice versa to exploit the consistency between the structure and content to the best possible extent. We further extend the basic FSCNMF to an advanced method, namely FSCNMF++ to capture the higher order proximities in the network. We conduct experiments on real world information networks for different types of machine learning applications such as node clustering, visualization, and multi-class classification. The results show that our method can represent the network significantly better than the state-of-the-art algorithms and improve the performance across all the applications that we consider.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:HhcuHIWmDEUC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"In the past, hybrid recommender systems have shown the power of exploiting relationships amongst objects which directly or indirectly effect the recommendation task. However, the effect of all relations is not equal, and choosing their right balance for a recommendation problem at hand is non-trivial. We model these interactions using a Heterogeneous Information Network, and propose a systematic framework for learning their influence weights for a given recommendation task. Further, we address the issue of redundant results, which is very much prevalent in recommender systems. To alleviate redundancy in recommendations we use Vertex Reinforced Random Walk (a non-Markovian random walk) over a heterogeneous graph. It works by boosting the transitions to the influential nodes, while simultaneously shrinking the weights of others. This helps in discouraging recommendation of multiple influential nodes …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:pAkWuXOU-OoC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"Network representation learning and node classification in graphs got significant attention due to the invent of different types graph neural networks. Graph convolution network (GCN) is a popular semi-supervised technique which aggregates attributes within the neighborhood of each node. Conventional GCNs can be applied to simple graphs where each edge connects only two nodes. But many modern days applications need to model high order relationships in a graph. Hypergraphs are effective data types to handle such complex relationships. In this paper, we propose a novel technique to apply graph convolution on hypergraphs with variable hyperedge sizes. We use the classical concept of line graph of a hypergraph for the first time in the hypergraph learning literature. Then we propose to use graph convolution on the line graph of a hypergraph. Experimental analysis on multiple real world network datasets shows the merit of our approach compared to state-of-the-arts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:eAlLMO4JVmQC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"Network representation learning has traditionally been used to find lower dimensional vector representations of the nodes in a network. However, there are very important edge driven mining tasks of interest to the classical network analysis community, which have mostly been unexplored in the network embedding space. For applications such as link prediction in homogeneous networks, vector representation (i.e., embedding) of an edge is derived heuristically just by using simple aggregations of the embeddings of the end vertices of the edge. Clearly, this method of deriving edge embedding is suboptimal and there is a need for a dedicated unsupervised approach for embedding edges by leveraging edge properties of the network. Towards this end, we propose a novel concept of converting a network to its weighted line graph which is ideally suited to find the embedding of edges of the original network. We further derive a novel algorithm to embed the line graph, by introducing the concept of collective homophily. To the best of our knowledge, this is the first direct unsupervised approach for edge embedding in homogeneous information networks, without relying on the node embeddings. We validate the edge embeddings on three downstream edge mining tasks. Our proposed optimization framework for edge embedding also generates a set of node embeddings, which are not just the aggregation of edges. Further experimental analysis shows the connection of our framework to the concept of node centrality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:eGYfIraVYiQC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"While graphs capture pairwise relations between entities, hypergraphs deal with higher-order ones, thereby ensuring losslessness. However, in hyperlink (i.e., higher-order link) prediction, where hyperlinks and non-hyperlinks are treated as “positive” and “negative” classes respectively, hypergraphs suffer from the problem of extreme class imbalance. Given this context, “negative sampling”—under-sampling the negative class of non-hyperlinks—becomes mandatory for performing hyperlink prediction. No prior work on hyperlink prediction deals with this problem. In this work, which is the first of its kind, we deal with this problem in the context of hyperlink prediction. More specifically, we leverage graph sampling techniques for sampling non-hyperlinks in hyperlink prediction. Our analysis clearly establishes the effect of random sampling, which is the norm in both link- as well as hyperlink-prediction. Further …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:AYInfyleIOsC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"This chapter deals with a brief introduction to deep learning. We deal with the perceptron classifier and its training. We then deal with feedforward networks and the multilayer perceptron (MLP). Training MLP using the well-known backpropagation algorithm is examined. An introduction to convolutional neural networks (CNNs), recurrent neural networks (RNNs), Long Short-TermMemory (LSTM), and autoencoders is provided.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:unp9ATQDT5gC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"Network representation learning (also known as Graph embedding) is a technique to map the nodes of a network to a lower dimensional vector space. Random walk based representation techniques are found to be efficient as they can easily preserve different orders of proximities between the nodes in the embedding space. Most of the social networks now-a-days have some content (or attributes) associated with each node. These attributes can provide complementary information along with the link structure of the network. But in a real life network, the information carried by the link structure and that by the attributes vary significantly over the nodes. Most of the existing unsupervised attributed network embedding algorithms do not distinguish between the link structure and the attributes of a node depending on their informativeness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:T_ojBgVMvoEC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"This book deals with network representation learning. It deals with embedding nodes, edges, subgraphs and graphs. There is a growing interest in understanding complex systems in different domains including health, education, agriculture and transportation. Such complex systems are analyzed by modeling, using networks that are aptly called complex networks. Networks are becoming ubiquitous as they can represent many real-world relational data, for instance, information networks, molecular structures, telecommunication networks and protein–protein interaction networks. Analysis of these networks provides advantages in many fields such as recommendation (recommending friends in a social network), biological field (deducing connections between proteins for treating new diseases) and community detection (grouping users of a social network according to their interests) by leveraging the latent information of networks. An active and important area of current interest is to come out with algorithms that learn features by embedding nodes or (sub) graphs into a vector space. These tasks come under the broad umbrella of representation learning. A representation learning model learns a mapping function that transforms the graphs' structure information to a low-/high-dimension vector space maintaining all the relevant properties.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:YB4bud6kWLwC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"Measuring influence, through centrality measures, has been a center-piece of research in the analysis of complex social networks, such as finding coherent communities (clusters) and locating trend setters (prototypes) in viral marketing. Even though there exists a few axiomatic frameworks associated with some specific forms of influence measures in the literature, these formal frameworks are not generic in nature in terms of characterizing the space of influence measures for complex social networks. To address this research gap, we propose a generic axiomatic framework, in this paper, to capture most of the key intrinsic properties of any influence measure in networks. We further analyze certain popular centrality measures using this framework. Interestingly, our analysis reveals that none of the centrality measures considered satisfies all the desirable axioms. We finally conclude this paper by stating an appealing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:SIv7DqKytYAC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",34,"Social recommendation systems typically combine extra information like a social network with the user-item interaction network in order to alleviate data sparsity issues. This also helps in making more accurate and personalized recommendations. However, most of the existing systems work under the assumption that all socially connected users have equal influence on each other in a social network, which is not true in practice. Further, estimating the quantum of influence that exists among entities in a user-item interaction network is essential when only implicit ratings are available. This has been ignored even in many recent state-of-the-art models such as SAMN (Social Attentional Memory Network) and DeepSoR (Deep neural network model on Social Relations). Many a time, capturing a complex relationship between the entities (users/items) is essential to boost the performance of a recommendation system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&citation_for_view=VQZTmpcAAAAJ:YlPif8NxrbYC,https://www.csa.iisc.ac.in/~mnm/
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Neural mechanisms of attention are extensively studied in the neocortex; comparatively little is known about how subcortical regions contribute to attention. The superior colliculus (SC) is an evolutionarily conserved, subcortical (midbrain) structure that has been implicated in controlling visuospatial attention. Yet how the SC contributes mechanistically to attention remains unknown. We investigated the role of the SC in attention, combining model-based psychophysics, diffusion imaging, and tractography in human participants. Specifically, we asked whether the SC contributes to enhancing sensitivity (d′) to attended information, or whether it contributes to biasing choices (criteria) in favor of attended information. We tested human participants on a multialternative change detection task, with endogenous spatial cueing, and quantified sensitivity and bias with a recently developed multidimensional signal detection …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&citation_for_view=5ij8Y9YAAAAJ:ZeXyd9-uunAC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Endogenous cueing of attention enhances sensory processing of the attended stimulus (perceptual sensitivity) and prioritizes information from the attended location for guiding behavioral decisions (spatial choice bias). Here, we test whether sensitivity and bias effects of endogenous spatial attention are under the control of common or distinct mechanisms. Human observers performed a multialternative visuospatial attention task with probabilistic spatial cues. Observers’ behavioral choices were analyzed with a recently developed multidimensional signal detection model (the m-ADC model). The model effectively decoupled the effects of spatial cueing on sensitivity from those on spatial bias and revealed striking dissociations between them. Sensitivity was highest at the cued location and not significantly different among uncued locations, suggesting a spotlight-like allocation of sensory resources at the cued …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&citation_for_view=5ij8Y9YAAAAJ:IWHjjKOFINEC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Diffusion imaging and tractography enable mapping structural connections in the human brain, in-vivo. Linear Fascicle Evaluation (LiFE) is a state-of-the-art approach for pruning spurious connections in the estimated structural connectome, by optimizing its fit to the measured diffusion data. Yet, LiFE imposes heavy demands on computing time, precluding its use in analyses of large connectome databases. Here, we introduce a GPU-based implementation of LiFE that achieves 50-100x speedups over conventional CPU-based implementations for connectome sizes of up to several million fibers. Briefly, the algorithm accelerates generalized matrix multiplications on a compressed tensor through efficient GPU kernels, while ensuring favorable memory access patterns. Leveraging these speedups, we advance LiFE’s algorithm by imposing a regularization constraint on estimated fiber weights during connectome pruning. Our regularized, accelerated, LiFE algorithm (“ReAl-LiFE”) estimates sparser connectomes that also provide more accurate fits to the underlying diffusion signal. We demonstrate the utility of our approach by classifying pathological signatures of structural connectivity in patients with Alzheimer’s Disease (AD). We estimated million fiber whole-brain connectomes, followed by pruning with ReAl-LiFE, for 90 individuals (45 AD patients and 45 healthy controls). Linear classifiers, based on support vector machines, achieved over 80% accuracy in classifying AD patients from healthy controls based on their ReAl-LiFE pruned structural connectomes alone. Moreover, classification based on the ReAl-LiFE pruned connectome outperformed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&citation_for_view=5ij8Y9YAAAAJ:4DMP91E08xMC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Attention can be directed endogenously, based on task-relevant goals, or captured exogenously, by salient stimuli. While recent studies have shown that endogenous attention can facilitate behavior through dissociable sensitivity (sensory) and choice bias (decisional) mechanisms, it is unknown if exogenous attention also operates through dissociable sensitivity and bias mechanisms. We tested human participants on a multialternative change detection task with exogenous attention cues, which preceded or followed change events in close temporal proximity. Analyzing participants’ behavior with a multidimensional signal detection model revealed clear dissociations between exogenous cueing effects on sensitivity and bias. While sensitivity was, overall, lower at the cued location compared to other locations, bias was highest at the cued location. With an appropriately designed post-cue control condition, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&citation_for_view=5ij8Y9YAAAAJ:L8Ckcad2t8MC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Deep networks often make confident, yet, incorrect, predictions when tested with outlier data that is far removed from their training distributions. Likelihoods computed by deep generative models (DGMs) are a candidate metric for outlier detection with unlabeled data. Yet, previous studies have shown that DGM likelihoods are unreliable and can be easily biased by simple transformations to input data. Here, we examine outlier detection with variational autoencoders (VAEs), among the simplest of DGMs. We propose novel analytical and algorithmic approaches to ameliorate key biases with VAE likelihoods. Our bias corrections are sample-specific, computationally inexpensive, and readily computed for various decoder visible distributions. Next, we show that a well-known image pre-processing technique--contrast stretching--extends the effectiveness of bias correction to further improve outlier detection. Our approach achieves state-of-the-art accuracies with nine grayscale and natural image datasets, and demonstrates significant advantages--both with speed and performance--over four recent, competing approaches. In summary, lightweight remedies suffice to achieve robust outlier detection with VAEs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:RHpTSmoSYBkC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Flexible functional interactions among brain regions mediate critical cognitive functions. Such interactions can be measured using functional magnetic resonance imaging (fMRI) data either with instantaneous (zero-lag) or lag-based (time-lagged) functional connectivity. Because the fMRI hemodynamic response is slow, and is sampled at a timescale (seconds) several orders of magnitude slower than the underlying neural dynamics (milliseconds), simulation studies have shown that lag-based fMRI functional connectivity, measured with approaches like Granger–Geweke causality (GC), provides spurious and unreliable estimates of underlying neural interactions. Experimental verification of this claim is challenging because neural ground truth connectivity is often unavailable concurrently with fMRI recordings. Here we demonstrate that, despite these widely held caveats, GC networks estimated from fMRI …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:7PzlFSSx8tAC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Selective attention produces systematic effects on neural states. It is unclear whether, conversely, momentary fluctuations in neural states have behavioral significance for attention. We investigated this question in the human brain with a cognitive brain-machine interface (cBMI) for tracking electrophysiological steady-state visually evoked potentials (SSVEPs) in real-time. Discrimination accuracy (d’) was significantly higher when target stimuli were triggered at high, versus low, SSVEP power states. Target and distractor SSVEP power was uncorrelated across the hemifields, and target d’ was unaffected by distractor SSVEP power states. Next, we trained participants on an auditory neurofeedback paradigm to generate biased, cross-hemispheric competitive interactions between target and distractor SSVEPs. The strongest behavioral effects emerged when competitive SSVEP dynamics unfolded at a timescale …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:M3NEmzRMIkIC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"We present a biologically inspired recurrent neural network (RNN) that efficiently detects changes in natural images. The model features sparse, topographic connectivity (st-RNN), closely modeled on the circuit architecture of a “midbrain attention network.” We deployed the st-RNN in a challenging change blindness task, in which changes must be detected in a discontinuous sequence of images. Compared with a conventional RNN, the st-RNN learned 9x faster and achieved state-of-the-art performance with 15x fewer connections. An analysis of low-dimensional dynamics revealed putative circuit mechanisms, including a critical role for a global inhibitory (GI) motif, for successful change detection. The model reproduced key experimental phenomena, including midbrain neurons' sensitivity to dynamic stimuli, neural signatures of stimulus competition, as well as hallmark behavioral effects of midbrain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:k_IJM867U9cC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Despite possessing the capacity for selective attention, we often fail to notice the obvious. We investigated participants’ (n = 39) failures to detect salient changes in a change blindness experiment. Surprisingly, change detection success varied by over two-fold across participants. These variations could not be readily explained by differences in scan paths or fixated visual features. Yet, two simple gaze metrics–mean duration of fixations and the variance of saccade amplitudes–systematically predicted change detection success. We explored the mechanistic underpinnings of these results with a neurally-constrained model based on the Bayesian framework of sequential probability ratio testing, with a posterior odds-ratio rule for shifting gaze. The model’s gaze strategies and success rates closely mimicked human data. Moreover, the model outperformed a state-of-the-art deep neural network (DeepGaze II) with predicting human gaze patterns in this change blindness task. Our mechanistic model reveals putative rational observer search strategies for change detection during change blindness, with critical real-world implications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:dhFuZR0502QC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Functional magnetic resonance imaging (fMRI) enables measuring human brain activity, in vivo. Yet, the fMRI hemodynamic response unfolds over very slow timescales (< 0.1-1 Hz), orders of magnitude slower than millisecond timescales of neural spiking. It is unclear, therefore, if slow dynamics as measured with fMRI are relevant for cognitive function. We investigated this question with a novel application of Gaussian Process Factor Analysis (GPFA) and machine learning to fMRI data. We analyzed slowly sampled (1.4 Hz) fMRI data from 1000 healthy human participants (Human Connectome Project database), and applied GPFA to reduce dimensionality and extract smooth latent dynamics. GPFA dimensions with slow (< 1 Hz) characteristic timescales identified, with high accuracy (> 95%), the specific task that each subject was performing inside the fMRI scanner. Moreover, functional connectivity between slow GPFA latents accurately predicted inter-individual differences in behavioral scores across a range of cognitive tasks. Finally, infra-slow (< 0.1 Hz) latent dynamics predicted CDR (Clinical Dementia Rating) scores of individual patients, and identified patients with mild cognitive impairment (MCI) who would progress to develop Alzheimer’s dementia (AD). Slow and infra-slow brain dynamics may be relevant for understanding the neural basis of cognitive function, in health and disease.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:qUcmZB5y_30C,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:GnPB-g6toBAC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Even before the eyes move, visual sensitivity improves at the target of the planned eye movement. Yet, it is unknown if such ""presaccadic"" benefits are merely sensory, or also influence decisional processes. We teased apart these contributions with signal detection theory, and discovered a surprising absence of presaccadic benefits in visual change detection tasks. Participants planned and executed saccades while concurrently detecting and localizing either orientation or contrast changes. Spatial choice bias reliably improved presaccadically but, surprisingly, without a concomitant increase in perceptual sensitivity. Additional investigation with an orientation estimation task, and a Bayesian ""variable precision"" model, revealed that sensory precision increased at the saccade target, but only for the most recent of two successive stimuli. Moreover, the recent stimulus perceptually biased feature estimates of the prior stimulus, rendering accurate change detection even more challenging. Our results uncover novel perceptual and decisional mechanisms that mediate presaccadic change detection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:NMxIlDl6LWMC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Visual working memory (WM) is known to exhibit attractor dynamics, wherein mnemonic representations drift toward discrete, stable attractor states [1, 2]. Maintenance in WM is also accompanied by specific patterns of synchronization and desynchronization in parieto-occipital alpha-band (8-12 Hz) oscillations [3]. Yet, the link between alpha desynchronization and attractor dynamics in WM remains unexplored. We tested n= 24 human participants on a visual WM task involving delayed (~ 2500 ms) reporting of a retro-cued grating’s orientation. Although grating orientations were uniformly distributed across trials, participants’ orientation reports systematically favored the nearest diagonal orientations and were biased away from cardinal orientations, indicating stable and unstable fixed points (attractors) at these orientations, respectively. We investigated the behavioral and neural correlates of these attractor dynamics …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:blknAaTinKkC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Reliable outlier detection is critical for real-world applications of deep learning models. Likelihoods produced by deep generative models, although extensively studied, have been largely dismissed as being impractical for outlier detection. For one, deep generative model likelihoods are readily biased by low-level input statistics. Second, many recent solutions for correcting these biases are computationally expensive or do not generalize well to complex, natural datasets. Here, we explore outlier detection with a state-of-the-art deep autoregressive model: PixelCNN++. We show that biases in PixelCNN++ likelihoods arise primarily from predictions based on local dependencies. We propose two families of bijective transformations that we term ""shaking"" and ""stirring"", which ameliorate low-level biases and isolate the contribution of long-range dependencies to the PixelCNN++ likelihood. These transformations are computationally inexpensive and readily applied at evaluation time. We evaluate our approaches extensively with five grayscale and six natural image datasets and show that they achieve or exceed state-of-the-art outlier detection performance. In sum, lightweight remedies suffice to achieve robust outlier detection on images with deep generative models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:TFP_iSt0sucC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Diffusion magnetic resonance imaging and tractography enable the estimation of anatomical connectivity in the human brain, in vivo. Yet, without ground-truth validation, different tractography algorithms can yield widely varying connectivity estimates. Although streamline pruning techniques mitigate this challenge, slow compute times preclude their use in big-data applications. We present ‘Regularized, Accelerated, Linear Fascicle Evaluation’ (ReAl-LiFE), a GPU-based implementation of a state-of-the-art streamline pruning algorithm (LiFE), which achieves >100× speedups over previous CPU-based implementations. Leveraging these speedups, we overcome key limitations with LiFE’s algorithm to generate sparser and more accurate connectomes. We showcase ReAl-LiFE’s ability to estimate connections with superlative test–retest reliability, while outperforming competing approaches. Moreover, we predicted …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:j3f4tGmQtD8C,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Deep networks often make confident, yet incorrect, predictions when tested with outlier data that is far removed from their training distributions. Likelihoods computed by deep generative models are a candidate metric for outlier detection with unlabeled data. Yet, previous studies have shown that such likelihoods are unreliable and can be easily biased by simple transformations to input data. Here, we examine outlier detection with variational autoencoders (VAEs), among the simplest class of deep generative models. First, we show that a theoreticallygrounded correction readily ameliorates a key bias with VAE likelihood estimates. The bias correction is model-free, sample-specific, and accurately computed with the Bernoulli and continuous Bernoulli visible distributions. Second, we show that a well-known preprocessing technique, contrast normalization, extends the effectiveness of bias correction to natural image datasets. Third, we show that the variance of the likelihoods computed over an ensemble of VAEs also enables robust outlier detection. We perform a comprehensive evaluation of our remedies with nine (grayscale and natural) image datasets, and demonstrate significant advantages, in terms of both speed and accuracy, over four other state-of-the-art methods. Our lightweight remedies are biologically inspired and may serve to achieve efficient outlier detection with many types of deep generative models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:BqipwSGYUEgC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:e5wmG9Sq2KIC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"We thank Friedrich et al.(1) for their keen interest in our study (2) and for highlighting additional examples of asymmetries in visually guided behavior and brain connectivity across several vertebrate classes. The superior colliculus (SC), or its nonmammalian homolog, the optic tectum (OT), is, indeed, an evolutionarily conserved vertebrate midbrain structure (3, 4). The SC/OT is spatiotopically organized and multilayered and exhibits strong anatomical and functional homology across vertebrates (3, 5). Superficial layers of the SC/OT receive visual inputs, whereas intermediate layers receive multisensory inputs (3, 5). SC/OT intermediate layers also receive inputs from the forebrain (3). For example, in nonhuman primates, SC/OT intermediate layers receive inputs from frontal and parietal cortex, including the frontal eye field and lateral intraparietal area (5). Similarly, in birds, gazerelated forebrain areas project to the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:TQgYirikUcIC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,"Brain processes occur at various timescales, ranging from milliseconds (neurons) to minutes and hours (behavior). Characterizing functional coupling among brain regions at these diverse timescales is key to understanding how the brain produces behavior. Here, we apply instantaneous and lag-based measures of conditional linear dependence, based on Granger-Geweke causality (GC), to infer network connections at distinct timescales from functional magnetic resonance imaging (fMRI) data. Due to the slow sampling rate of fMRI, it is widely held that GC produces spurious and unreliable estimates of functional connectivity when applied to fMRI data. We challenge this claim with simulations and a novel machine learning approach. First, we show, with simulated fMRI data, that instantaneous and lag-based GC identify distinct timescales and complementary patterns of functional connectivity. Next, we analyze …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:YFjsv_pBGBYC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&cstart=20&pagesize=80&citation_for_view=5ij8Y9YAAAAJ:hMod-77fHWUC,http://cns.iisc.ac.in/sridhar
Jayant Haritsa,['Database Systems'],38,"Methods, systems, and computer program products for securely processing range predicates on cloud databases are provided herein. A computer-implemented method includes separately encrypting a set of plain text data using two or more encryption functions, thereby producing an encrypted domain comprising at least two distinct groups of encrypted data items; converting a range query over plain text data items into a query over at least one of the distinct groups of encrypted data items; and combining results from the query over the distinct groups of encrypted data items, thereby generating a final encrypted result to the range query.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&cstart=20&pagesize=80&citation_for_view=dc626ewAAAAJ:_FM0Bhl9EiAC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],38,"A core requirement of database engine testing is the ability to create synthetic versions of the customer’s data warehouse at the vendor site. A rich body of work exists on synthetic database regeneration, but suffers critical limitations with regard to:(a) maintaining statistical fidelity to the client’s query processing, and/or (b) scaling to large data volumes. In this paper, we present HYDRA, a workload-dependent database regenerator that leverages a declarative approach to data regeneration to assure volumetric similarity, a crucial aspect of statistical fidelity, and materially improves on the prior art by adding scale, dynamism and functionality. Specifically, Hydra uses an optimized linear programming (LP) formulation based on a novel regionpartitioning approach. This spatial strategy drastically reduces the LP complexity, enabling it to handle query workloads on which contemporary techniques fail. Second, Hydra …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&cstart=20&pagesize=80&citation_for_view=dc626ewAAAAJ:NXb4pA-qfm4C,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],38,"A core requirement of database engine testing is the ability to create synthetic versions of the customer's data warehouse at the vendor site. Prior work on synthetic data regeneration suffers from critical limitations with regard to (a) scaling to large data volumes, (b) handling complex query workloads, and (c) producing data on demand. In this demo, we present HYDRA, a workload-dependent dynamic data regenerator, that materially addresses these limitations. It introduces the concept of dynamic regeneration by constructing a minuscule memory-resident database summary that can on-the-fly regenerate databases of arbitrary size during query execution. Further, since the data is generated in memory, the velocity of generation can be closely regulated. Finally, to complement dynamic regeneration, Hydra also ensures that the process of summary construction is data-scale-free.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&cstart=20&pagesize=80&citation_for_view=dc626ewAAAAJ:mlAyqtXpCwEC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],38,"We investigate a new query reverse-engineering problem of unmasking SQL queries hidden within database applications. The diverse use-cases for this problem range from resurrecting legacy code to query rewriting. As a first step in addressing the unmasking challenge, we present UNMASQUE, an active-learning extraction algorithm that can expose a basal class of hidden warehouse queries. A special feature of our design is that the extraction is non-invasive wrt the application, examining only the results obtained from repeated executions on databases derived with a combination of data mutation and data generation techniques. Further, potent optimizations are incorporated to minimize the extraction overheads. A detailed evaluation over applications hosting hidden SQL queries, or their imperative versions, demonstrates that UNMASQUE correctly and efficiently extracts these queries.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&cstart=20&pagesize=80&citation_for_view=dc626ewAAAAJ:lvd772isFD0C,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],38,"We investigate a new query reverse-engineering problem of unmasking SQL queries hidden within database applications. The diverse use-cases for this problem range from resurrecting legacy code to query rewriting. As a first step in addressing the unmasking challenge, we present UNMASQUE, an active-learning extraction algorithm that can expose a basal class of hidden warehouse queries. A special feature of our design is that the extraction is non-invasive wrt the application, examining only the results obtained from repeated executions on databases derived with a combination of data mutation and data generation techniques. Further, potent optimizations, such as table minimization and sampling, are incorporated to reduce extraction overheads. A detailed evaluation over applications hosting hidden SQL queries, or their imperative versions, demonstrates that UNMASQUE correctly and efficiently extracts these queries.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&cstart=20&pagesize=80&citation_for_view=dc626ewAAAAJ:Aul-kAQHnToC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],38,"Given a database instance and a populated result, query reverse-engineering attempts to identify candidate SQL queries that produce this result on the instance. A variant of this problem arises when a ground-truth is additionally available, but hidden within an opaque database application. In this demo, we present UN-MASQUE, an extraction algorithm that is capable of precisely identifying a substantive class of such hidden queries. A hallmark of its design is that the extraction is completely non-invasive to the application. Specifically, it only examines the results obtained from application executions on databases derived with a combination of data mutation and data generation techniques, thereby achieving platform-independence. Further, potent optimizations, such as database size reduction to a few rows, are incorporated to minimize the extraction overheads. The demo showcases these features on both …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&cstart=20&pagesize=80&citation_for_view=dc626ewAAAAJ:Ehil0879vHcC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],38,"A popular approach to hosting Keyword Search Systems (KWS) on relational DBMS platforms is to employ the Candidate Network framework. The quality of a Candidate Network-based search is critically dependent on the scoring function used to rank the relevant answers. In this paper, we first demonstrate, through detailed empirical and conceptual analysis studies, that the Labrador scoring function provides the best user relevance among contemporary Candidate Network scoring functions.
Efficiently incorporating the Labrador function, however, is rendered difficult due to its Result Set Dependent (RSD) characteristic, wherein the distribution of keywords in the query results influences the ranking. To address this RSD challenge ►We investigate two mechanisms ►(a) a simple wrapper approach that leverages existing RDBMS functionalities through an SQL wrapper ►And (b) a more sophisticated operator …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&cstart=20&pagesize=80&citation_for_view=dc626ewAAAAJ:3htObqc8RwsC,http://dsl.cds.iisc.ac.in/~haritsa
Bhavana Kanukurthi,['Cryptography'],10,"Non-malleable codes (NMCs), introduced by Dziembowski, Pietrzak and Wichs (ITCS 2010), provide a powerful guarantee in scenarios where the classical notion of error-correcting codes cannot provide any guarantee: a decoded message is either the same or completely independent of the underlying message, regardless of the number of errors introduced into the codeword. Informally, NMCs are defined with respect to a family of tampering functions and guarantee that any tampered codeword decodes either to the same message or to an independent message, so long as it is tampered using a function . One of the well-studied tampering families for NMCs is the t-split-state family, where the adversary tampers each of the t“states” of a codeword, arbitrarily but independently. Cheraghchi and Guruswami (TCC 2014) obtain a rate-1 non-malleable code for the case where with n being the codeword length and, in (ITCS 2014), show an upper …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&citation_for_view=QYNU5jMAAAAJ:YsMSGLbcyi4C,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,"Non-malleable Codes (NMCs), introduced by Dziembowski, Peitrzak and Wichs (ITCS 2010), serve the purpose of preventing “related tampering” of encoded messages. The most popular tampering model considered is the 2-split-state model where a codeword consists of 2 states, each of which can be tampered independently. While NMCs in the 2-split state model provide the strongest security guarantee, despite much research in the area we only know how to build them with poor rate ( , where n is the codeword length). However, in many applications of NMCs one only needs to be able to encode randomness i.e., security is not required to hold for arbitrary, adversarially chosen messages. For example, in applications of NMCs to tamper-resilient security, the messages that are encoded are typically randomly generated secret keys. To exploit this, in this work, we introduce the notion of “Non-malleable …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&citation_for_view=QYNU5jMAAAAJ:eQOLeE2rZwMC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,"Non-malleable Codes give us the following property: their codewords cannot be tampered into codewords of related messages. Privacy Amplification allows parties to convert their weak shared secret into a fully hidden, uniformly distributed secret key, while communicating on a fully tamperable public channel. In this work, we show how to construct a constant round privacy amplification protocol from any augmented split-state non-malleable code. Existentially, this gives us another primitive (in addition to optimal non-malleable extractors) whose optimal construction would solve the long-standing open problem of building constant round privacy amplification with optimal entropy loss and min-entropy requirement. Instantiating our code with the current best known NMC gives us an 8-round privacy amplification protocol with entropy loss and min-entropy requirement , where is the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&citation_for_view=QYNU5jMAAAAJ:ufrVoPGSRksC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,"At ITCS 2010, Dziembowski, Pietrzak, and Wichs introduced Non-malleable Codes (NMCs) which protect against tampering of a codeword of a given message into the codeword of a related message. A well-studied model of tampering is the 2-split-state model where the codeword consists of two independently tamperable states. As with standard error-correcting codes, it is of great importance to build codes with high rates.
Following a long line of work, Aggarwal and Obremski (FOCS 2020) showed the first constant rate non-malleable code in the 2−split state model; however, this constant was a minuscule 10−6! In this work, we build a Non-malleable Code with rate 1/3. This nearly matches the rate 1/2 lower bound for this model due to Cheraghchi and Guruswami (ITCS 2014). Our construction is simple, requiring just an inner-product extractor, a seeded extractor, and an affine-evasive function.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&citation_for_view=QYNU5jMAAAAJ:UebtZRa9Y70C,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&citation_for_view=QYNU5jMAAAAJ:5nxA0vEk-isC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,"We introduce Adaptive Extractors, which unlike traditional randomness extractors, guarantee security even when an adversary obtains leakage on the source after observing the extractor output. We make a compelling case for the study of such extractors by demonstrating their use in obtaining adaptive leakage in secret sharing schemes.
Specifically, at FOCS 2020, Chattopadhyay, Goodman, Goyal, Kumar, Li, Meka, Zuckerman, built an adaptively secure leakage resilient secret sharing scheme (LRSS) with both rate and leakage rate being , where is the number of parties. In this work, we build an adaptively secure LRSS that offers an interesting trade-off between rate, leakage rate, and the total number of shares from which an adversary can obtain leakage. As a special case, when considering t-out-of-n secret sharing schemes for threshold (constant ), we build a scheme with a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&citation_for_view=QYNU5jMAAAAJ:LkGwnXOMwfcC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,"Sealed bid auctions are used to allocate a resource among a set of interested parties. Traditionally, auctions need the presence of a trusted auctioneer to whom the bidders provide their private bid values. Existence of such a trusted party is not an assumption easily realized in practice. Generic secure computation protocols can be used to remove a trusted party. However, generic techniques result in inefficient protocols, and typically do not provide fairness -- that is, a corrupt party can learn the output and abort the protocol thereby preventing other parties from learning the output.
At CRYPTO 2009, Miltersen, Nielsen and Triandopoulos~\citeC:MilNieTri09, introduced the problem of building auctions that are secure against rational bidders. Such parties are modeled as self-interested agents who care more about maximizing their utility than about learning information about bids of other agents. To realize this, they …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&citation_for_view=QYNU5jMAAAAJ:0EnyYjriUFMC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,"Non-malleable secret sharing (NMSS) schemes, introduced by Goyal and Kumar (STOC 2018), ensure that a secret can be distributed into shares (for some ), such that any (a parameter ) shares can be reconstructed to recover the secret , any shares doesn't leak information about and even if the shares that are used for reconstruction are tampered, it is guaranteed that the reconstruction of these tampered shares will either result in the original or something independent of . Since their introduction, non-malleable secret sharing schemes sparked a very impressive line of research. In this work, we introduce a feature of local reconstructability in NMSS, which allows reconstruction of any portion of a secret by reading just a few locations of the shares. This is a useful feature, especially when the secret is long or when the shares are stored in a distributed manner on a communication network. In this work, we give a compiler that takes in any non-malleable secret sharing scheme and compiles it into a locally reconstructable non-malleable secret sharing scheme. To secret share a message consisting of blocks of length each, our scheme would only require reading bits (in addition to a few more bits, whose quantity is independent of and ) from each party's share (of a reconstruction set) to locally reconstruct a single block of the message. We show an application of our locally reconstructable non-malleable secret sharing scheme to a computational non-malleable secure message transmission scheme in the pre-processing model, with an improved communication complexity, when transmitting multiple …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&citation_for_view=QYNU5jMAAAAJ:roLk4NBRz8UC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,"Leakage resilient secret sharing (LRSS) allows a dealer to share a secret amongst n parties such that any authorized subset of the parties can recover the secret from their shares, while an adversary that obtains shares of any unauthorized subset of parties along with bounded leakage from the other shares learns no information about the secret. Non-malleable secret sharing (NMSS) provides a guarantee that even shares that are tampered by an adversary will reconstruct to either the original message or something independent of it.
The most important parameter of LRSS and NMSS schemes is the size of each share. For LRSS, in the local leakage model (i.e., when the leakage functions on each share are independent of each other and bounded), Srinivasan and Vasudevan (CRYPTO 2019), gave a scheme for threshold access structures with share size of approximately , where is the number of bits of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&citation_for_view=QYNU5jMAAAAJ:hqOjcs7Dif8C,http://drona.csa.iisc.ernet.in/~bhavana/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"This paper presents our method for enabling a UAV quadrotor, equipped with a monocular camera, to autonomously avoid collisions with obstacles in unstructured and unknown indoor environments. When compared to obstacle avoidance in ground vehicular robots, UAV navigation brings in additional challenges because the UAV motion is no more constrained to a well-defined indoor ground or street environment. Unlike ground vehicular robots, a UAV has to navigate across more types of obstacles - for e.g., objects like decorative items, furnishings, ceiling fans, sign-boards, tree branches, etc., are also potential obstacles for a UAV. Thus, methods of obstacle avoidance developed for ground robots are clearly inadequate for UAV navigation. Current control methods using monocular images for UAV obstacle avoidance are heavily dependent on environment information. These controllers do not fully retain and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&citation_for_view=cj3fJJsbjAoC:fbc8zXXH2BUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"Reinforcement learning (RL) methods learn optimal decisions in the presence of a stationary environment. However, the stationary assumption on the environment is very restrictive. In many real world problems like traffic signal control, robotic applications, etc., one often encounters situations with non-stationary environments, and in these scenarios, RL methods yield sub-optimal decisions. In this paper, we thus consider the problem of developing RL methods that obtain optimal decisions in a non-stationary environment. The goal of this problem is to maximize the long-term discounted reward accrued when the underlying model of the environment changes over time. To achieve this, we first adapt a change point algorithm to detect change in the statistics of the environment and then develop an RL algorithm that maximizes the long-run reward accrued. We illustrate that our change point method detects change in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&citation_for_view=cj3fJJsbjAoC:WC9gN4BGCRcC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"We present for the first time an asymptotic convergence analysis of two time-scale stochastic approximation driven by “controlled” Markov noise. In particular, the faster and slower recursions have nonadditive controlled Markov noise components in addition to martingale difference noise. We analyze the asymptotic behavior of our framework by relating it to limiting differential inclusions in both time scales that are defined in terms of the ergodic occupation measures associated with the controlled Markov processes. Finally, we present a solution to the off-policy convergence problem for temporal-difference learning with linear function approximation, using our results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&citation_for_view=cj3fJJsbjAoC:tH6gc1N1XXoC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"In this work, we provide a simulation framework to perform systematic studies on the effects of spinal joint compliance and actuation on bounding performance of a 16-DOF quadruped spined robot Stoch 2. Fast quadrupedal locomotion with active spine is an extremely hard problem, and involves a complex coordination between the various degrees of freedom. Therefore, past attempts at addressing this problem have not seen much success. Deep-Reinforcement Learning seems to be a promising approach, after its recent success in a variety of robot platforms, and the goal of this paper is to use this approach to realize the aforementioned behaviors. With this learning framework, the robot reached a bounding speed of 2.1m /s with a maximum Froude number of 2. Simulation results also show that use of active spine, indeed, increased the stride length, improved the cost of transport, and also reduced the natural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:jgBuDB5drN8C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"We are interested in understanding stability (almost sure boundedness) of stochastic approximation algorithms (SAs) driven by a “controlled Markov” process. Analyzing this class of algorithms is important, since many reinforcement learning (RL) algorithms can be cast as SAs driven by a “controlled Markov” process. In this paper, we present easily verifiable sufficient conditions for stability and convergence of SAs driven by a “controlled Markov” process. Many RL applications involve continuous state spaces. While our analysis readily ensures stability for such continuous state applications, traditional analyses do not. As compared to literature, our analysis presents a two-fold generalization: 1) the Markov process may evolve in a continuous state space and 2) the process need not be ergodic under any given stationary policy. Temporal difference (TD) learning is an important policy evaluation method in RL. The theory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:9Nmd_mFXekcC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the “Stoch”. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:Aul-kAQHnToC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"In this paper, we present a complete description of the hardware design and control architecture of our custom built quadruped robot, called the Stoch. Our goal is to realize a robust, modular, and a reliable quadrupedal platform, using which various locomotion behaviors are explored. This platform enables us to explore different research problems in legged locomotion, which use both traditional and learning based techniques. We discuss the merits and limitations of the platform in terms of exploitation of available behaviours, fast rapid prototyping, reproduction and repair. Towards the end, we will demonstrate trotting, bounding behaviors, and preliminary results in turning. In addition, we will also show various gait transitions i.e., trot-to-turn and trot-to-bound behaviors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:AHdEip9mkN0C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"We consider the problem of tracking an intruder using a network of wireless sensors. For tracking the intruder at each instant, the optimal number and the right configuration of sensors has to be powered. As powering the sensors consumes energy, there is a trade off between accurately tracking the position of the intruder at each instant and the energy consumption of sensors. This problem has been formulated in the framework of partially observable Markov decision process (POMDP). Even for the state-of-the-art algorithm in the literature, the curse of dimensionality renders the problem intractable. In this letter, we formulate the intrusion detection (ID) problem with a suitable state-action space in the framework of POMDP and develop a reinforcement learning algorithm utilizing the upper confidence tree search method to solve the ID problem. Through simulations, we show that our algorithm performs and scales …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:9c2xU6iGI7YC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"Recently, a dynamic adaptive queue management with random dropping (AQMRD) scheme has been developed to capture the time-dependent variation of average queue size by incorporating the rate of change of average queue size as a parameter. A major issue with AQMRD is the choice of parameters. In this paper, a novel online stochastic approximation based optimization scheme is proposed to dynamically tune the parameters of AQMRD and which is also applicable for other active queue management (AQM) algorithms. Our optimization scheme significantly improves the throughput, average queue size, and loss-rate in relation to other AQM schemes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:mlAyqtXpCwEC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"In this paper we study the asymptotic behaviour of stochastic approximation schemes with set-valued drift function and non-additive iterate-dependent Markov noise. We show that a linearly interpolated trajectory of such a recursion is an asymptotic pseudotrajectory for the flow of a limiting differential inclusion obtained by averaging the set-valued drift function of the recursion w.r.t. the stationary distributions of the Markov noise. The limit set theorem by Benaim is then used to characterize the limit sets of the recursion in terms of the dynamics of the limiting differential inclusion. We then state two variants of the Markov noise assumption under which the analysis of the recursion is similar to the one presented in this paper. Scenarios where our recursion naturally appears are presented as applications. These include controlled stochastic approximation, subgradient descent, approximate drift problem and analysis of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:M7yex6snE4oC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"In this work, we consider the problem of computing optimal actions for Reinforcement Learning (RL) agents in a co-operative setting, where the objective is to optimize a common goal. However, in many real-life applications, in addition to optimizing the goal, the agents are required to satisfy certain constraints specified on their actions. Under this setting, the objective of the agents is to not only learn the actions that optimize the common objective but also meet the specified constraints. In recent times, the Actor-Critic algorithm with an attention mechanism has been successfully applied to obtain optimal actions for RL agents in multi-agent environments. In this work, we extend this algorithm to the constrained multi-agent RL setting. The idea here is that optimizing the common goal and satisfying the constraints may require different modes of attention. By incorporating different attention modes, the agents can select useful information required for optimizing the objective and satisfying the constraints separately, thereby yielding better actions. Through experiments on benchmark multi-agent environments, we show the effectiveness of our proposed algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:MAUkC_7iAq8C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"In this paper, with a view toward fast deployment of locomotion gaits in low-cost hardware, we use a linear policy for realizing end-foot trajectories in the quadruped robot, Stoch 2. In particular, the parameters of the end-foot trajectories are shaped via a linear feedback policy that takes the torso orientation and the terrain slope as inputs. The corresponding desired joint angles are obtained via an inverse kinematics solver and tracked via a PID control law. Augmented Random Search, a model-free and a gradient-free learning algorithm is used to train this linear policy. Simulation results show that the resulting walking is robust to terrain slope variations and external pushes. This methodology is not only computationally light-weight but also uses minimal sensing and actuation capabilities in the robot, thereby justifying the approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:-7ulzOJl1JYC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"In cooperative stochastic games multiple agents work towards learning joint optimal actions in an unknown environment to achieve a common goal. In many real-world applications, however, constraints are often imposed on the actions that can be jointly taken by the agents. In such scenarios the agents aim to learn joint actions to achieve a common goal (minimizing a specified cost function) while meeting the given constraints (specified via certain penalty functions). In this paper, we consider the relaxation of the constrained optimization problem by constructing the Lagrangian of the cost and penalty functions. We propose a nested actor-critic solution approach to solve this relaxed problem. In this approach, an actor-critic scheme is employed to improve the policy for a given Lagrange parameter update on a faster timescale as in the classical actor-critic architecture. A meta actor-critic scheme using this faster timescale policy updates is then employed to improve the Lagrange parameters on the slower timescale. Utilizing the proposed nested actor-critic schemes, we develop three Nested Actor-Critic (N-AC) algorithms. Through experiments on constrained cooperative tasks, we show the effectiveness of the proposed algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:lgwcVrK6X84C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"In this paper, we provide two new stable online algorithms for the problem of prediction in reinforcement learning, i.e., estimating the value function of a model-free Markov reward process using the linear function approximation architecture and with memory and computation costs scaling quadratically in the size of the feature set. The algorithms employ the multi-timescale stochastic approximation variant of the very popular cross entropy optimization method which is a model based search method to find the global optimum of a real-valued function. A proof of convergence of the algorithms using the ODE method is provided. We supplement our theoretical results with experimental comparisons. The algorithms achieve good performance fairly consistently on many RL benchmark problems with regards to computational efficiency, accuracy and stability.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:LhH-TYMQEocC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"Zeroth Order Bayesian Optimization (ZOBO) methods optimize an unknown function based on its black-box evaluations at the query locations. Unlike most optimization procedures, ZOBO methods fail to utilize gradient information even when it is available. On the other hand, First Order Bayesian Optimization (FOBO) methods exploit the available gradient information to arrive at better solutions faster. However, the existing FOBO methods do not utilize a crucial information that the gradient is zero at the optima. Further, the inherent sequential nature of the FOBO methods incur high computational cost limiting their wide applicability. To alleviate the aforementioned difficulties of FOBO methods, we propose a relaxed statistical model to leverage the gradient information that directly searches for points where gradient vanishes. To accomplish this, we develop novel acquisition algorithms that search for global …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:AXkvAH5U_nMC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"An appealing feature of cloud computing is elasticity, that allows shrinking or expanding the resources allocated to an application in order to adjust to workload variations. The resource provisioning algorithm must also adhere to the performance requirements specified in the Service Level Agreement between the cloud provider and the client who runs the application. While the use of Reinforcement learning algorithms such as Q-learning has been proposed already to address this problem, those suffer from slow convergence and scalability issues. In this paper, we explore methods for overcoming such challenges and ensuring effective resource utilization. Preliminary experiments on CloudSim platform demonstrate the superiority of some of these methods over static, threshold-based and other reinforcement learning based allocation schemes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:v1_lew4L6wgC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"In this paper, we analyze the behavior of stochastic approximation schemes with set-valued maps in the absence of a stability guarantee. We prove that after a large number of iterations, if the stochastic approximation process enters the domain of attraction of an attracting set, it gets locked into the attracting set with high probability. We demonstrate that the above-mentioned result is an effective instrument for analyzing stochastic approximation schemes in the absence of a stability guarantee, by using it to obtain an alternate criterion for convergence in the presence of a locally attracting set for the mean field and by using it to show that a feedback mechanism, which involves resetting the iterates at regular time intervals, stabilizes the scheme when the mean field possesses a globally attracting set, thereby guaranteeing convergence. The results in this paper build on the works of Borkar, Andrieu et al., and Chen et al …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:HtEfBTGE9r8C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",33,"Asynchronous stochastic approximations (SAs) are an important class of model-free algorithms, tools, and techniques that are popular in multiagent and distributed control scenarios. To counter Bellman's curse of dimensionality, such algorithms are coupled with function approximations. Although the learning/control problem becomes more tractable, function approximations affect stability and convergence. In this article, we present verifiable sufficient conditions for stability and convergence of asynchronous SAs with biased approximation errors. The theory developed herein is used to analyze policy gradient methods and noisy value iteration schemes. Specifically, we analyze the asynchronous approximate counterparts of the policy gradient (A2PG) and value iteration (A2VI) schemes. It is shown that the stability of these algorithms is unaffected by biased approximation errors, provided that they are asymptotically …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&citation_for_view=cj3fJJsbjAoC:fFSKOagxvKUC,https://www.csa.iisc.ac.in/~shalabh/
Vinod Ganapathy,['Security and Privacy'],30,"Machine learning models are increasingly being deployed in practice. Machine Learning as a Service (MLaaS) providers expose such models to queries by third-party developers through application programming interfaces (APIs). Prior work has developed model extraction attacks, in which an attacker extracts an approximation of an MLaaS model by making black-box queries to it. We design ActiveThief–a model extraction framework for deep neural networks that makes use of active learning techniques and unannotated public datasets to perform model extraction. It does not expect strong domain knowledge or access to annotated data on the part of the attacker. We demonstrate that (1) it is possible to use ActiveThief to extract deep classifiers trained on a variety of datasets from image and text domains, while querying the model with as few as 10-30% of samples from public datasets,(2) the resulting model exhibits a higher transferability success rate of adversarial examples than prior work, and (3) the attack evades detection by the state-of-the-art model extraction detection method, PRADA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&citation_for_view=wrzZzwYAAAAJ:V3AGJWp-ZtQC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"In FaaS workflows, a set of functions implement application logic by interacting and exchanging data among themselves. Contemporary FaaS platforms execute each function of a workflow in separate containers. When functions in a workflow interact, the resulting latency slows execution. Faastlane minimizes function interaction latency by striving to execute functions of a workflow as threads within a single process of a container instance, which eases data sharing via simple load/store instructions. For FaaS workflows that operate on sensitive data, Faastlane provides lightweight thread-level isolation domains using Intel Memory Protection Keys (MPK). While threads ease sharing, implementations of languages such as Python and Node. js (widely used in FaaS applications) disallow concurrent execution of threads. Faastlane dynamically identifies opportunities for parallelism in FaaS workflows and fork processes (instead of threads) or spawns new container instances to concurrently execute parallel functions of a workflow. We implemented Faastlane atop Apache OpenWhisk and show that it accelerates workflow instances by up to 15×, and reduces function interaction latency by up to 99.95% compared to OpenWhisk.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:Y5dfb0dijaUC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"We present Privaros, a framework to enforce privacy policies on drones. Privaros is designed for commercial delivery drones, such as the ones that will likely be used by Amazon Prime Air. Such drones visit various host airspaces, each of which may have different privacy requirements. Privaros uses mandatory access control to enforce the policies of these hosts on guest delivery drones. Privaros is tailored for ROS, a middleware popular in many drone platforms. This paper presents the design and implementation of Privaros's policy-enforcement mechanisms, describes how policies are specified, and shows that policy specification can be integrated with India's Digital Sky portal. Our evaluation shows that a drone running Privaros can robustly enforce various privacy policies specified by hosts, and that its core mechanisms only marginally increase communication latency and power consumption.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:bnK-pcrLprsC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"The Intel Security Guard Extensions (SGX) architecture enables the abstraction of enclaved execution, using which an application can protect its code and data from powerful adversaries, including system software that executes with the highest processor privilege. While the Intel SGX architecture exports an ISA with low-level instructions that enable applications to create enclaves, the task of writing applications using this ISA has been left to the software community.
We consider the problem of porting legacy applications to SGX enclaves. In the approximately four years to date since the Intel SGX became commercially available, the community has developed three different models to port applications to enclaves---the library OS, the library wrapper, and the instruction wrapper models.
In this paper, we conduct an empirical evaluation of the merits and costs of each model. We report on our attempt to port a handful …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:olpn-zPbct0C,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"Commercial and end-user drones come equipped with a wide array of sensors. Unregulated use of such drones in public airspaces poses a serious threat to the privacy of citizens. We make the case for restricted spaces for drones, which are geographic areas for which a host can specify its privacy policies. Guest drones must prove to the host that they are in compliance with the host's policies before entering the restricted space. We then make the case for an information-flow control-based policy enforcement framework on drones, and sketch the design of a prototype framework atop the Robot Operating System (ROS).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:D_sINldO8mEC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"Many security and forensic analyses rely on the ability to fetch memory snapshots from a target machine. To date, the security community has relied on virtualization, external hardware or trusted hardware to obtain such snapshots. These techniques either sacrifice snapshot consistency or degrade the performance of applications executing atop the target. We present SnipSnap, a new snapshot acquisition system based on on-package DRAM technologies that offers snapshot consistency without excessively hurting the performance of the target's applications. We realize SnipSnap and evaluate its benefits using careful hardware emulation and software simulation, and report our results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:K3LRdlH-MEoC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"GPUs are now commonly available in most modern computing platforms. They are increasingly being adopted in cloud platforms and data centers due to their immense computing capability. In response to this growth in usage, manufacturers continuously try to improve GPU hardware by adding new features. However, this increase in usage and the addition of utility-improving features can create new, unexpected attack channels. In this paper, we show that two such features-unified virtual memory (UVM) and multi-process service (MPS)-primarily introduced to improve the programmability and efficiency of GPU kernels have an unexpected consequence-that of creating a novel covert-timing channel via the GPU's translation lookaside buffer (TLB) hierarchy. To enable this covert channel, we first perform experiments to understand the characteristics of TLBs present on a GPU. The use of UVM allows fine-grained …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:eMMeJKvmdy0C,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"Intel’s SGX architecture offers clients of public cloud computing platforms the ability to create hardware-protected enclaves whose contents are protected from privileged system software. However, SGX relies on system software for enclave memory management. In a sequence of recent papers, researchers have demonstrated that this reliance allows a malicious OS/hypervisor to snoop on the page addresses being accessed from within an enclave via various channels. This page address stream can then be used to infer secrets if the enclave’s page access pattern depends upon the secret and this constitutes an important class of side-channels.
We propose SGXL, a hardware-software co-designed system that significantly increases the difficulty of any page address-based side-channels through the use of large pages. A large page maps address ranges at a much larger granularity than the default page size (at …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:HE397vMXCloC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"This paper concerns the Hyperledger Fabric permissioned blockchain system. This system is in popular use in several enterprise settings, where each participating corporate entity may have sensitive business-related data whose confidentiality it wishes to protect. Fabric provides the channel abstraction that ensures that channel data (e.g., data stored in that channel's ledger, or data transmitted via the network to members of that channel) are only accessible to members of that channel. Unfortunately, as we show in this paper, the channel abstraction only offers data protection under the implicit assumption that all system components in the permissioned blockchain are trustworthy. This assumption may not hold in the presence of compromised container nodes, on which several blockchain-related components execute, or malicious business users inside any one of the participating corporate entities. Under such …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:N5tVd3kTz84C,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"As e-commerce companies begin to consider using delivery drones for customer fulfillment, there are growing concerns around citizen privacy. Drones are equipped with cameras, and the video feed from these cameras is often required as part of routine navigation, be it for semi autonomous or fully-autonomous drones. Footage of ground-based citizens may be captured in this video feed, thereby leading to privacy concerns. This paper presents Privadome, a system that implements the vision of a virtual privacy dome centered around the citizen. Privadome is designed to be integrated with city-scale regulatory authorities that oversee delivery drone operations and realizes this vision through two components, PD-MPC and PD-ROS. PD-MPC allows citizens equipped with a mobile device to identify drones that have captured their footage. It uses secure two-party computation to achieve this goal without compromising the privacy of the citizen's location. PD-ROS allows the citizen to communicate with such drones and obtain an audit trail showing how the drone uses their footage and determine if privacy-preserving steps are taken to sanitize the footage. An experimental evaluation of Privadome using our prototype implementations of PD-MPC and PD-ROS shows that the system scales to near-term city-scale delivery drone deployments (hundreds of drones). We show that with PD-MPC the mobile data usage on the citizen's mobile device is comparable to that of routine activities on the device, such as streaming videos. We also show that the workflow of PD-ROS consumes a modest amount of additional CPU resources and power on our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:PELIpwtuRlgC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"A method for preventing a side channel attack by executing an enclave on a remote computing device. The method comprises configuring the enclave based on configuration parameters defined by a computing device. A page created in first enclave cache memory in the remote computing device and adding virtual page address information and page security attributes corresponding to the page in a second enclave cache memory, and an encrypted log entry is created in a protected memory of the remote computing device. The enclave is initiated by comparing the log entry and a second hash key generated by the remote computing device. A new page of pre-defined size is dynamically added to the first enclave cache memory after initiation of the enclave. The enclave is executed based on a successful validation of a size of the page created in first enclave cache memory to be equal to the pre-defined page size.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:AXPGKjj_ei8C,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"On public cloud computing platforms, cloud providers own and administer the system software (eg, the BIOS, the OS, and/or the hypervisor) that manages the computing infrastructure. A malicious actor can leverage this system software to compromise the integrity and confidentiality of data and code of the clients of public computing infrastructures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:t6usbXjVLHcC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],30,"We were fortunate to receive financial support for the conference from Sonata Software, IISc Bangalore, and Microsoft Research India. We are thankful to Omprakash Subbarao (Sonata Software), Y. Narahari (IISc Bangalore), and the team of Chiranjib Bhattacharyya (IISc Bangalore), Sriram Rajamani, Satish Sangameswaran, and Christina Gould-Sandhu (Microsoft Research India) for providing financial sponsorship. We also appreciate the support of Springer, in particular Alfred Hofmann and Anna Kramer, in publishing the proceedings as well as the monetary support for the conference. We would also like to acknowledge EasyChair for their conference management system, which was freely used to manage the process of paper submissions and reviews.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&cstart=20&pagesize=80&citation_for_view=wrzZzwYAAAAJ:BrmTIyaxlBUC,http://www.csa.iisc.ac.in/~vg
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"The knapsack problem is one of the classical problems in combinatorial optimization: Given a set of items, each specified by its size and profit, the goal is to find a maximum profit packing into a knapsack of bounded capacity. In the online setting, items are revealed one by one and the decision, if the current item is packed or discarded forever, must be done immediately and irrevocably upon arrival. We study the online variant in the random order model where the input sequence is a uniform random permutation of the item set. We develop a randomized (1/6.65)-competitive algorithm for this problem, outperforming the current best algorithm of competitive ratio 1/8.06 (Kesselheim et al. in SIAM J Comput 47(5):1939–1964, 2018). Our algorithm is based on two new insights: We introduce a novel algorithmic approach that employs two given algorithms, optimized for restricted item classes, sequentially on the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&citation_for_view=yRsbV0AAAAAJ:LO7wyVUgiFcC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the knapsack problem with group fairness constraints. The input of the problem consists of a knapsack of bounded capacity and a set of items, each item belongs to a particular category and has and associated weight and value. The goal of this problem is to select a subset of items such that all categories are fairly represented, the total weight of the selected items does not exceed the capacity of the knapsack,and the total value is maximized. We study the fairness parameters such as the bounds on the total value of items from each category, the total weight of items from each category, and the total number of items from each category. We give approximation algorithms for these problems. These fairness notions could also be extended to the min-knapsack problem. The fair knapsack problems encompass various important problems, such as participatory budgeting, fair budget allocation, advertising.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&citation_for_view=yRsbV0AAAAAJ:DJbcl8HfkQkC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"In the Strip Packing problem, we are given a vertical half-strip [0, W]×[0,+∞) and a collection of open rectangles of width at most W. Our goal is to find an axis-aligned (non-overlapping) packing of such rectangles into the strip such that the maximum height OPT spanned by the packing is as small as possible. Strip Packing generalizes classical well-studied problems such as Makespan Minimization on identical machines (when rectangle widths are identical) and Bin Packing (when rectangle heights are identical). It has applications in manufacturing, scheduling and energy consumption in smart grids among others. It is NP-hard to approximate this problem within a factor (3/2-ε) for any constant ε> 0 by a simple reduction from the Partition problem. The current best approximation factor for Strip Packing is (5/3+ ε) by Harren et al.[Computational Geometry'14], and it is achieved with a fairly complex algorithm and analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&citation_for_view=yRsbV0AAAAAJ:cWzG1nlazyYC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"Guillotine separability of rectangles has recently gained prominence in combinatorial optimization, computational geometry, and combinatorics. Consider a given large stock unit (say glass or wood) and we need to cut out a set of required rectangles from it. Many cutting technologies allow only end-to-end cuts called guillotine cuts. Guillotine cuts occur in stages. Each stage consists of either only vertical cuts or only horizontal cuts. In k-stage packing, the number of cuts to obtain each rectangle from the initial packing is at most k (plus an additional trimming step to separate the rectangle itself from a waste area). Pach and Tardos [Pach and Tardos, 2000] studied the following question: Given a set of n axis-parallel rectangles (in the weighted case, each rectangle has an associated weight), cut out as many rectangles (resp. weight) as possible using a sequence of guillotine cuts. They provide a guillotine cutting sequence that recovers 1/(2 log n)-fraction of rectangles (resp. weights). Abed et al.[Fidaa Abed et al., 2015] claimed that a guillotine cutting sequence can recover a constant fraction for axis-parallel squares. They also conjectured that for any set of rectangles, there exists a sequence of axis-parallel guillotine cuts that recovers a constant fraction of rectangles. This conjecture, if true, would yield a combinatorial O (1)-approximation for Maximum Independent Set of Rectangles (MISR), a long-standing open problem. We show the conjecture is not true, if we only allow o (log log n) stages (resp. o (log n/log log n)-stages for the weighted case). On the positive side, we show a simple O (n log n)-time 2-stage cut sequence that recovers 1/(1+ log n …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&citation_for_view=yRsbV0AAAAAJ:HtS1dXgVpQUC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"In the \textsc{2-Dimensional Knapsack} problem (2DK) we are given a square knapsack and a collection of rectangular items with integer sizes and profits. Our goal is to find the most profitable subset of items that can be packed non-overlappingly into the knapsack. The currently best known polynomial-time approximation factor for 2DK is and there is a -approximation algorithm if we are allowed to rotate items by 90 degrees~{[}G\'alvez et al., FOCS 2017{]}. In this paper, we give -approximation algorithms in polynomial time for both cases, assuming that all input data are {integers polynomially bounded in }. G\'alvez et al.'s algorithm for 2DK partitions the knapsack into a constant number of rectangular regions plus \emph{one} L-shaped region and packs items into those {in a structured way}. We generalize this approach by allowing up to a \emph{constant} number of {\emph{more general}} regions that can have the shape of an L, a U, a Z, a spiral, and more, and therefore obtain an improved approximation ratio. {In particular, we present an algorithm that computes the essentially optimal structured packing into these regions. }",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&citation_for_view=yRsbV0AAAAAJ:8xutWZnSdmoC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We present a approximation algorithm for the matching augmentation problem (MAP): given a multi-graph with edges of cost either zero or one such that the edges of cost zero form a matching, find a 2-edge connected spanning subgraph (2-ECSS) of minimum cost. We first present a reduction of any given MAP instance to a collection of well-structured MAP instances such that the approximation guarantee is preserved. Then we present a approximation algorithm for a well-structured MAP instance. The algorithm starts with a min-cost 2-edge cover and then applies ear-augmentation steps. We analyze the cost of the ear-augmentations using an approach similar to the one proposed by Vempala and Vetta for the (unweighted) min-size 2-ECSS problem (in: Jansen and Khuller (eds.) Approximation Algorithms for Combinatorial Optimization, Third International Workshop, APPROX 2000, Proceedings, LNCS 1913 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&citation_for_view=yRsbV0AAAAAJ:bnK-pcrLprsC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the Maximum Independent Set of Rectangles (MISR) problem, where we are given a set of axis-parallel rectangles in the plane and the goal is to select a subset of non-overlapping rectangles of maximum cardinality. In a recent breakthrough, Mitchell [46] obtained the first constant-factor approximation algorithm for MISR. His algorithm achieves an approximation ratio of 10 and it is based on a dynamic program that intuitively recursively partitions the input plane into special polygons called corner-clipped rectangles (CCRs), without intersecting certain special horizontal line segments called fences.
In this paper, we present a 3-approximation algorithm for MISR which is also based on a recursive partitioning scheme. First, we use a partition into a class of axis-parallel polygons with constant complexity each that are more general than CCRs. This allows us to provide an arguably simpler analysis and at the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&citation_for_view=yRsbV0AAAAAJ:fbc8zXXH2BUC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"In two-dimensional geometric knapsack problem, we are given a set of n axis-aligned rectangular items and an axis-aligned square-shaped knapsack. Each item has integral width, integral height and an associated integral profit. The goal is to find a (non-overlapping axis-aligned) packing of a maximum profit subset of rectangles into the knapsack. A well-studied and frequently used constraint in practice is to allow only packings that are guillotine separable, i.e., every rectangle in the packing can be obtained by recursively applying a sequence of edge-to-edge axis-parallel cuts that do not intersect any item of the solution. In this paper we study approximation algorithms for the geometric knapsack problem under guillotine cut constraints. We present polynomial time (1 + {\epsilon})-approximation algorithms for the cases with and without allowing rotations by 90 degrees, assuming that all input numeric data are polynomially bounded in n. In comparison, the best-known approximation factor for this setting is 3 + {\epsilon} [Jansen-Zhang, SODA 2004], even in the cardinality case where all items have the same profit. Our main technical contribution is a structural lemma which shows that any guillotine packing can be converted into another structured guillotine packing with almost the same profit. In this packing, each item is completely contained in one of a constant number of boxes and L-shaped regions, inside which the items are placed by a simple greedy routine. In particular, we provide a clean sufficient condition when such a packing obeys the guillotine cut constraints which might be useful for other settings where these constraints are imposed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&citation_for_view=yRsbV0AAAAAJ:nZcligLrVowC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"Best Fit is a well known online algorithm for the bin packing problem, where a collection of one-dimensional items has to be packed into a minimum number of unit-sized bins. In a seminal work, Kenyon [SODA 1996] introduced the (asymptotic) random order ratio as an alternative performance measure for online algorithms. Here, an adversary specifies the items, but the order of arrival is drawn uniformly at random. Kenyon’s result establishes lower and upper bounds of 1.08 and 1.5, respectively, for the random order ratio of Best Fit. Although this type of analysis model became increasingly popular in the field of online algorithms, no progress has been made for the Best Fit algorithm after the result of Kenyon. We study the random order ratio of Best Fit and tighten the long-standing gap by establishing an improved lower bound of 1.10. For the case where all items are larger than 1/3, we show that the random …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&citation_for_view=yRsbV0AAAAAJ:bKqednn6t2AC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the Maximum Independent Set of Rectangles (MISR) problem, where we are given a set of axis-parallel rectangles in the plane and the goal is to select a subset of non-overlapping rectangles of maximum cardinality. In a recent breakthrough, Mitchell [2021] obtained the first constant-factor approximation algorithm for MISR. His algorithm achieves an approximation ratio of 10 and it is based on a dynamic program that intuitively recursively partitions the input plane into special polygons called corner-clipped rectangles (CCRs), without intersecting certain special horizontal line segments called fences. In this paper, we present a -approximation algorithm for MISR which is also based on a recursive partitioning scheme. First, we use a partition into a class of axis-parallel polygons with constant complexity each that are more general than CCRs. This allows us to provide an arguably simpler analysis and at the same time already improves the approximation ratio to 6. Then, using a more elaborate charging scheme and a recursive partitioning into general axis-parallel polygons with constant complexity, we improve our approximation ratio to . In particular, we construct a recursive partitioning based on more general fences which can be sequences of up to line segments each. This partitioning routine and our other new ideas may be useful for future work towards a PTAS for MISR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:ALROH1vI_8AC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study Nonpreemptive Peak Demand Minimization (NPDM) problem, where we are given a set of jobs, specified by their processing times and energy requirements. The goal is to schedule all jobs within a fixed time period such that the peak load (the maximum total energy requirement at any time) is minimized. This problem has recently received significant attention due to its relevance in smart-grids. Theoretically, the problem is related to the classical strip packing problem (SP). In SP, a given set of axis-aligned rectangles must be packed into a fixed-width strip, such that the height of the strip is minimized. NPDM can be modeled as strip packing with slicing and stacking constraint: each rectangle may be cut vertically into multiple slices and the slices may be packed into the strip as individual pieces. The stacking constraint forbids solutions where two slices of the same rectangle are intersected by the same vertical line. Nonpreemption enforces the slices to be placed in contiguous horizontal locations (but may be placed at different vertical locations). We obtain a -approximation algorithm for the problem. We also provide an asymptotic efficient polynomial-time approximation scheme (AEPTAS) which generates a schedule for almost all jobs with energy consumption . The remaining jobs fit into a thin container of height . The previous best for NPDM was 2.7 approximation based on FFDH [Ranjan et al. 2015]. One of our key ideas is providing several new lower bounds on the optimal solution of a geometric packing, which could be useful in other related problems. These lower bounds help us to obtain approximative solutions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:u-coK7KVo8oC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the Stochastic Multi-armed Bandit problem under bounded arm-memory. In this setting, the arms arrive in a stream, and the number of arms that can be stored in the memory at any time, is bounded. The decision-maker can only pull arms that are present in the memory. We address the problem from the perspective of two standard objectives: 1) regret minimization, and 2) best-arm identification. For regret minimization, we settle an important open question by showing an almost tight guarantee. We show cumulative regret in expectation for single-pass algorithms for arm-memory size of , where is the number of arms. For best-arm identification, we provide an -PAC algorithm with arm memory size of and optimal sample complexity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:BJbdYPG6LGMC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study a generalization of the knapsack problem with geometric and vector constraints. The input is a set of rectangular items, each with an associated profit and nonnegative weights (-dimensional vector), and a square knapsack. The goal is to find a non-overlapping axis-parallel packing of a subset of items into the given knapsack such that the vector constraints are not violated, i.e., the sum of weights of all the packed items in any of the dimensions does not exceed one. We consider two variants of the problem: the items are not allowed to be rotated, items can be rotated by 90 degrees. We give a -approximation algorithm for this problem (both versions). In the process, we also study a variant of the maximum generalized assignment problem (Max-GAP), called Vector-Max-GAP, and design a PTAS for it.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:F9fV5C73w3QC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"In Two-dimensional Bin Packing (2BP), we are given n rectangles as input and our goal is to find an axis-aligned nonoverlapping packing of these rectangles into the minimum number of unit square bins. 2BP admits no APTAS and the current best approximation ratio is 1.406 by Bansal and Khan (ACM-SIAM symposium on discrete algorithms (SODA), pp 13–25, 2014. https://doi.org/10.1137/1.9781611973402.2). A well-studied variant of 2BP is Guillotine Two-dimensional Bin Packing (G2BP), where rectangles must be packed in such a way that every rectangle in the packing can be obtained by applying a sequence of end-to-end axis-parallel cuts, also called guillotine cuts. Bansal et al. (Symposium on foundations of computer science (FOCS). IEEE, pp 657–666, 2005. https://doi.org/10.1109/SFCS.2005.10) gave an APTAS for G2BP. Let be the smallest constant such that for every set I of items, the number of bins in the optimal solution to G2BP for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:ZzlSgRqYykMC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the two-dimensional geometric knapsack problem, in which we are given a set of n axis-aligned rectangular items, each one with an associated profit, and an axis-aligned square knapsack. The goal is to find a (non-overlapping) packing of a maximum profit subset of items inside the knapsack (without rotating items). The best-known polynomial-time approximation factor for this problem (even just in the cardinality case) is 2+ε [Jansen and Zhang, SODA 2004]. In this article we present a polynomial-time 17/9+ε < 1.89-approximation, which improves to 558/325+ε < 1.72 in the cardinality case.
Prior results pack items into a constant number of rectangular containers that are filled via greedy strategies. We deviate from this setting and show that there exists a large profit solution where items are packed into a constant number of containers plus one L-shaped region at the boundary of the knapsack containing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:artPoR2Yc-kC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the generalized multidimensional bin packing problem (GVBP) that generalizes both geometric packing and vector packing. Here, we are given rectangular items where the item has width , height , and nonnegative weights . Our goal is to get an axis-parallel non-overlapping packing of the items into square bins so that for all , the sum of the weight of items in each bin is at most 1. This is a natural problem arising in logistics, resource allocation, and scheduling. Despite being well studied in practice, surprisingly, approximation algorithms for this problem have rarely been explored. We first obtain two simple algorithms for GVBP having asymptotic approximation ratios and . We then extend the Round-and-Approx (R&A) framework [Bansal-Khan, SODA'14] to wider classes of algorithms, and show how it can be adapted to GVBP. Using more sophisticated techniques, we obtain better approximation algorithms for GVBP, and we get further improvement by combining them with the R&A framework. This gives us an asymptotic approximation ratio of for GVBP, which improves to for the special case of . We obtain further improvement when the items are allowed to be rotated. We also present algorithms for a generalization of GVBP where the items are high dimensional cuboids.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:5icHVeHT4IsC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study fair and efficient allocation of divisible goods, in an online manner, among n agents. The goods arrive online in a sequence of T time periods. The agents' values for a good are revealed only after its arrival, and the online algorithm needs to fractionally allocate the good, immediately and irrevocably, among the agents. Towards a unifying treatment of fairness and economic efficiency objectives, we develop an algorithmic framework for finding online allocations to maximize the generalized mean of the values received by the agents. In particular, working with the assumption that each agent's value for the grand bundle of goods is appropriately scaled, we address online maximization of p-mean welfare. Parameterized by an exponent term p in (-infty, 1], these means encapsulate a range of welfare functions, including social welfare (p= 1), egalitarian welfare (p to-infty), and Nash social welfare (p to 0). We present a simple algorithmic template that takes a threshold as input and, with judicious choices for this threshold, leads to both universal and tailored competitive guarantees. First, we show that one can compute online a single allocation that O (sqrt (n) log n)-approximates the optimal p-mean welfare for all p<= 1. The existence of such a universal allocation is interesting in and of itself. Moreover, this universal guarantee achieves essentially tight competitive ratios for specific values of p. Next, we obtain improved competitive ratios for different ranges of p by executing our algorithm with p-specific thresholds, eg, we provide O (log^ 3 n)-competitive ratio for all p in (-1/(log 2n), 1). We complement our positive results by establishing lower …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:tH6gc1N1XXoC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the d-dimensional hypercube knapsack problem where we are given a set of d-dimensional hypercubes with associated profits, and a knapsack which is a unit d-dimensional hypercube. The goal is to find an axis-aligned non-overlapping packing of a subset of hypercubes such that the profit of the packed hypercubes is maximized. For this problem, Harren (ICALP'06) gave an algorithm with an approximation ratio of (1+1/2^d+epsilon). For d=2, Jansen and Solis-Oba (IPCO'08) showed that the problem admits a polynomial-time approximation scheme (PTAS); Heydrich and Wiese (SODA'17) further improved the running time and gave an efficient polynomial-time approximation scheme (EPTAS). Both the results use structural properties of 2-D packing, which do not generalize to higher dimensions. For d>2, it remains open to obtain a PTAS, and in fact, there has been no improvement since Harren's result. We settle the problem by providing a PTAS. Our main technical contribution is a structural lemma which shows that any packing of hypercubes can be converted into another structured packing such that a high profitable subset of hypercubes is packed into a constant number of special hypercuboids, called V-Boxes and N-Boxes. As a side result, we give an almost optimal algorithm for a variant of the strip packing problem in higher dimensions. This might have applications for other multidimensional geometric packing problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:AHdEip9mkN0C,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"In the Strip Packing problem (SP), we are given a vertical half-strip and a set of axis-aligned rectangles of width at most . The goal is to find a non-overlapping packing of all rectangles into the strip such that the height of the packing is minimized. A well-studied and frequently used practical constraint is to allow only those packings that are guillotine separable, i.e., every rectangle in the packing can be obtained by recursively applying a sequence of edge-to-edge axis-parallel cuts (guillotine cuts) that do not intersect any item of the solution. In this paper, we study approximation algorithms for the Guillotine Strip Packing problem (GSP), i.e., the Strip Packing problem where we require additionally that the packing needs to be guillotine separable. This problem generalizes the classical Bin Packing problem and also makespan minimization on identical machines, and thus it is already strongly NP-hard. Moreover, due to a reduction from the Partition problem, it is NP-hard to obtain a polynomial-time -approximation algorithm for GSP for any (exactly as Strip Packing). We provide a matching polynomial time -approximation algorithm for GSP. Furthermore, we present a pseudo-polynomial time -approximation algorithm for GSP. This is surprising as it is NP-hard to obtain a -approximation algorithm for (general) Strip Packing in pseudo-polynomial time. Thus, our results essentially settle the approximability of GSP for both the polynomial and the pseudo-polynomial settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:F1b5ZUV5XREC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We extend the notion of regret with a welfarist perspective. Focussing on the classic multi-armed bandit (MAB) framework, the current work quantifies the performance of bandit algorithms by applying a fundamental welfare function, namely the Nash social welfare (NSW) function. This corresponds to equating algorithm's performance to the geometric mean of its expected rewards and leads us to the study of Nash regret, defined as the difference between the -- a priori unknown -- optimal mean (among the arms) and the algorithm's performance. Since NSW is known to satisfy fairness axioms, our approach complements the utilitarian considerations of average (cumulative) regret, wherein the algorithm is evaluated via the arithmetic mean of its expected rewards. This work develops an algorithm that, given the horizon of play , achieves a Nash regret of , here denotes the number of arms in the MAB instance. Since, for any algorithm, the Nash regret is at least as much as its average regret (the AM-GM inequality), the known lower bound on average regret holds for Nash regret as well. Therefore, our Nash regret guarantee is essentially tight. In addition, we develop an anytime algorithm with a Nash regret guarantee of .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:otzGkya1bYkC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the online bin packing problem under two stochastic settings. In the bin packing problem, we are given n items with sizes in (0,1] and the goal is to pack them into the minimum number of unit-sized bins. First, we study bin packing under the i.i.d. model, where item sizes are sampled independently and identically from a distribution in (0,1]. Both the distribution and the total number of items are unknown. The items arrive one by one and their sizes are revealed upon their arrival and they must be packed immediately and irrevocably in bins of size 1. We provide a simple meta-algorithm that takes an offline -asymptotic approximation algorithm and provides a polynomial-time -competitive algorithm for online bin packing under the i.i.d. model, where >0 is a small constant. Using the AFPTAS for offline bin packing, we thus provide a linear time -competitive algorithm for online bin packing under i.i.d. model, thus settling the problem. We then study the random-order model, where an adversary specifies the items, but the order of arrival of items is drawn uniformly at random from the set of all permutations of the items. Kenyon's seminal result [SODA'96] showed that the Best-Fit algorithm has a competitive ratio of at most 3/2 in the random-order model, and conjectured the ratio to be around 1.15. However, it has been a long-standing open problem to break the barrier of 3/2 even for special cases. Recently, Albers et al. [Algorithmica'21] showed an improvement to 5/4 competitive ratio in the special case when all the item sizes are greater than 1/3. For this special case, we settle the analysis by showing that Best-Fit has a competitive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:uDGL6kOW6j0C,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"Set cover and hitting set are fundamental problems in combinatorial optimization which are well-studied in the offline, online, and dynamic settings. We study the geometric versions of these problems and present new online and dynamic algorithms for them. In the online version of set cover (resp. hitting set), sets (resp.~ points) are give points (resp.~ sets) arrive online, one-by-one. In the dynamic versions, points (resp. sets) can arrive as well as depart. Our goal is to maintain a set cover (resp. hitting set), minimizing the size of the computed solution. For online set cover for (axis-parallel) squares of arbitrary sizes, we present a tight -competitive algorithm. In the same setting for hitting set, we provide a tight -competitive algorithm, assuming that all points have integral coordinates in . No online algorithm had been known for either of these settings, not even for unit squares (apart from the known online algorithms for arbitrary set systems). For both dynamic set cover and hitting set with -dimensional hyperrectangles, we obtain -approximation algorithms with worst-case update time. This partially answers an open question posed by Chan et al. [SODA'22]. Previously, no dynamic algorithms with polylogarithmic update time were known even in the setting of squares (for either of these problems). Our main technical contributions are an \emph{extended quad-tree }approach and a \emph{frequency reduction} technique that reduces geometric set cover instances to instances of general set cover with bounded frequency.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:zCSUwVk65WsC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:43bX7VzcjpAC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"Ranking algorithms find extensive usage in diverse areas such as web search, employment, college admission, voting, etc. The related rank aggregation problem deals with combining multiple rankings into a single aggregate ranking. However, algorithms for both these problems might be biased against some individuals or groups due to implicit prejudice or marginalization in the historical data. We study ranking and rank aggregation problems from a fairness or diversity perspective, where the candidates (to be ranked) may belong to different groups and each group should have a fair representation in the final ranking. We allow the designer to set the parameters that define fair representation. These parameters specify the allowed range of the number of candidates from a particular group in the top- positions of the ranking. Given any ranking, we provide a fast and exact algorithm for finding the closest fair ranking for the Kendall tau metric under {\em strong fairness}, ie, when the final ranking is fair for all values of . We also provide an exact algorithm for finding the closest fair ranking for the Ulam metric under strong fairness when there are only number of groups. Our algorithms are simple, fast, and might be extendable to other relevant metrics. We also give a novel meta-algorithm for the general rank aggregation problem under the fairness framework. Surprisingly, this meta-algorithm works for any generalized mean objective (including center and median problems) and any fairness criteria. As a byproduct, we obtain 3-approximation algorithms for both center and median problems, under both Kendall tau and Ulam metrics. Furthermore, using …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:jgBuDB5drN8C,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the Improving Multi-Armed Bandit (IMAB) problem, where the reward obtained from an arm increases with the number of pulls it receives. This model provides an elegant abstraction for many real-world problems in domains such as education and employment, where decisions about the distribution of opportunities can affect the future capabilities of communities and the disparity between them. A decision-maker in such settings must consider the impact of her decisions on future rewards in addition to the standard objective of maximizing her cumulative reward at any time. In many of these applications, the time horizon is unknown to the decision-maker beforehand, which motivates the study of the IMAB problem in the technically more challenging horizon-unaware setting. We study the tension that arises between two seemingly conflicting objectives in the horizon-unaware setting: a) maximizing the cumulative reward at any time based on current rewards of the arms, and b) ensuring that arms with better long-term rewards get sufficient opportunities even if they initially have low rewards. We show that, surprisingly, the two objectives are aligned with each other in this setting. Our main contribution is an anytime algorithm for the IMAB problem that achieves the best possible cumulative reward while ensuring that the arms reach their true potential given sufficient time. Our algorithm mitigates the initial disparity due to lack of opportunity and continues pulling an arm till it stops improving. We prove the optimality of our algorithm by showing that a) any algorithm for the IMAB problem, no matter how utilitarian, must suffer policy regret and  …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:ubry08Y2EpUC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study the fair allocation of indivisible goods among agents with identical, additive valuations but individual budget constraints. Here, the indivisible goods--each with a specific size and value--need to be allocated such that the bundle assigned to each agent is of total size at most the agent's budget. Since envy-free allocations do not necessarily exist in the indivisible goods context, compelling relaxations--in particular, the notion of envy-freeness up to goods (EFk)--have received significant attention in recent years. In an EFk allocation, each agent prefers its own bundle over that of any other agent, up to the removal of goods, and the agents have similarly bounded envy against the charity (which corresponds to the set of all unallocated goods). Recently, Wu et al. (2021) showed that an allocation that satisfies the budget constraints and maximizes the Nash social welfare is -approximately EF1. However, the computation (or even existence) of exact EFk allocations remained an intriguing open problem. We make notable progress towards this by proposing a simple, greedy, polynomial-time algorithm that computes EF2 allocations under budget constraints. Our algorithmic result implies the universal existence of EF2 allocations in this fair division context. The analysis of the algorithm exploits intricate structural properties of envy-freeness. Interestingly, the same algorithm also provides EF1 guarantees for important special cases. Specifically, we settle the existence of EF1 allocations for instances in which: (i) the value of each good is proportional to its size, (ii) all goods have the same size, or (iii) all the goods have the same value. Our EF2 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:1lhNe0rCu4AC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study rectangle stabbing problems in which we are given n axis-aligned rectangles in the plane that we want to stab, i.e., we want to select line segments such that for each given rectangle there is a line segment that intersects two opposite edges of it. In the horizontal rectangle stabbing problem (Stabbing), the goal is to find a set of horizontal line segments of minimum total length such that all rectangles are stabbed. In general rectangle stabbing problem, also known as horizontal-vertical stabbing problem (HV-Stabbing), the goal is to find a set of rectilinear (i.e., either vertical or horizontal) line segments of minimum total length such that all rectangles are stabbed. Both variants are NP-hard. Chan, van Dijk, Fleszar, Spoerhase, and Wolff initiated the study of these problems by providing O(1)-approximation algorithms. Recently, Eisenbrand, Gallato, Svensson, and Venzin have presented a QPTAS and a polynomial-time 8 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:vDZJ-YLwNdEC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"We study ROUND-UFP and ROUND-SAP, two generalizations of the classical BIN PACKING problem that correspond to the unsplittable flow problem on a path (UFP) and the storage allocation problem (SAP), respectively. We are given a path with capacities on its edges and a set of tasks where for each task we are given a demand and a subpath. In ROUND-UFP, the goal is to find a packing of all tasks into a minimum number of copies (rounds) of the given path such that for each copy, the total demand of tasks on any edge does not exceed the capacity of the respective edge. In ROUND-SAP, the tasks are considered to be rectangles and the goal is to find a non-overlapping packing of these rectangles into a minimum number of rounds such that all rectangles lie completely below the capacity profile of the edges. We show that in contrast to BIN PACKING, both the problems do not admit an asymptotic polynomial-time approximation scheme (APTAS), even when all edge capacities are equal. However, for this setting, we obtain asymptotic -approximations for both problems. For the general case, we obtain an -approximation algorithm and an -approximation under -resource augmentation for both problems. For the intermediate setting of the no bottleneck assumption (i.e., the maximum task demand is at most the minimum edge capacity), we obtain absolute - and asymptotic -approximation algorithms for ROUND-UFP and ROUND-SAP, respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:LgRImbQfgY4C,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",15,"In the 2-Dimensional Knapsack problem (2DK) we are given a square knapsack and a collection of n rectangular items with integer sizes and profits. Our goal is to find the most profitable subset of items that can be packed non-overlappingly into the knapsack. The currently best known polynomial-time approximation factor for 2DK is 17/9 + Îµ < 1.89 and there is a (3/2 + Îµ)-approximation algorithm if we are allowed to rotate items by 90 degrees GÃ¡lvez et al., FOCS 2017. In this paper, we give (4/3 + Îµ)-approximation algorithms in polynomial time for both cases, assuming that all input data are integers polynomially bounded in n. GÃ¡lvez et al.'s algorithm for 2DK partitions the knapsack into a constant number of rectangular regions plus one L-shaped region and packs items into those in a structured way. We generalize this approach by allowing up to a constant number of more general regions that can have the shape of an L, a U, a Z, a spiral, and more, and therefore obtain an improved approximation ratio. In particular, we present an algorithm that computes the essentially optimal structured packing into these regions. Â© Waldo GÃ¡lvez, Fabrizio Grandoni, Arindam Khan, Diego RamÃrez-Romero, and Andreas Wiese; licensed under Creative Commons License CC-BY 4.0 37th International Symposium on Computational Geometry (SoCG 2021).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&citation_for_view=yRsbV0AAAAAJ:gKiMpY-AVTkC,https://www.csa.iisc.ac.in/~arindamkhan/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"This letter presents a new notion of input-to-state safe control barrier functions (ISSf-CBFs), which ensure safety of nonlinear dynamical systems under input disturbances. Similar to how safety conditions are specified in terms of forward invariance of a set, input-to-state safety conditions are specified in terms of forward invariance of a slightly larger set. In this context, invariance of the larger set implies that the states stay either inside or very close to the smaller safe set; and this closeness is bounded by the magnitude of the disturbances. The main contribution of the letter is the methodology used for obtaining a valid ISSf-CBF, given a control barrier function. The associated universal control law will also be provided. Towards the end, we will study unified quadratic programs that combine control Lyapunov functions and ISSf-CBFs in order to obtain a single control law that ensures both safety and stability in systems …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&citation_for_view=is0x16gAAAAJ:SdhP9T11ey4C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"This paper presents the meta-algorithmic approach used to realize multi-contact walking on the humanoid robot, DURUS. This systematic methodology begins by decomposing human walking into a sequence of distinct events (e.g. heel-strike, toe-strike, and toe push-off). These events are converted into an alternating sequence of domains and guards, resulting in a hybrid system model of the locomotion. Through the use of a direct collocation based optimization framework, a walking gait is generated for the hybrid system model emulating human-like multi-contact walking behaviors – additional constraints are iteratively added and shaped from experimental evaluation to reflect the machine’s practical limitations. The synthesized gait is analyzed directly on hardware wherein feedback regulators are introduced which stabilize the walking gait, e.g., modulating foot placement. The end result is an energyoptimized …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&citation_for_view=is0x16gAAAAJ:eMMeJKvmdy0C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Over the decades, kinematic controllers have proven to be practically useful for applications like set-point and trajectory tracking in robotic systems. To this end, we formulate a novel safety-critical paradigm by extending the methodology of control barrier functions (CBFs) to kinematic equations governing robotic systems. We demonstrate a purely kinematic implementation of a velocity-based CBF, and subsequently introduce a formulation that guarantees safety at the level of dynamics. This is achieved through a new form of CBFs that incorporate kinetic energy with the classical forms, thereby minimizing model dependence and conservativeness. The approach is then extended to underactuated systems. This method and the purely kinematic implementation are demonstrated in simulation on two robotic platforms: a 6-DOF robotic manipulator, and a cart-pole system.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&citation_for_view=is0x16gAAAAJ:W5xh706n7nkC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this work, we provide a simulation framework to perform systematic studies on the effects of spinal joint compliance and actuation on bounding performance of a 16-DOF quadruped spined robot Stoch 2. Fast quadrupedal locomotion with active spine is an extremely hard problem, and involves a complex coordination between the various degrees of freedom. Therefore, past attempts at addressing this problem have not seen much success. Deep-Reinforcement Learning seems to be a promising approach, after its recent success in a variety of robot platforms, and the goal of this paper is to use this approach to realize the aforementioned behaviors. With this learning framework, the robot reached a bounding speed of 2.1m /s with a maximum Froude number of 2. Simulation results also show that use of active spine, indeed, increased the stride length, improved the cost of transport, and also reduced the natural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&citation_for_view=is0x16gAAAAJ:ZuybSZzF8UAC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the “Stoch”. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&citation_for_view=is0x16gAAAAJ:VL0QpB8kHFEC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"We establish stability results for PD tracking control laws in bipedal walking robots. Stability of PD control laws for continuous robotic systems is an established result, and we extend this for hybrid robotic systems, an alternating sequence of continuous and discrete events. Bipedal robots have the leg-swing as the continuous event, and the foot-strike as the discrete event. In addition, bipeds largely have underactuations due to the interactions between feet and ground. For each continuous event, we establish that the convergence rate of the tracking error can be regulated via appropriate tuning of the PD gains; and for each discrete event, we establish that this convergence rate sufficiently overcomes the nonlinear impacts by assumptions on the hybrid zero dynamics. The main contributions are (1) Extension of the stability results of PD control laws for underactuated robotic systems, and (2) Exponential ultimate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&citation_for_view=is0x16gAAAAJ:hkOj_22Ku90C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this paper, we present a complete description of the hardware design and control architecture of our custom built quadruped robot, called the Stoch. Our goal is to realize a robust, modular, and a reliable quadrupedal platform, using which various locomotion behaviors are explored. This platform enables us to explore different research problems in legged locomotion, which use both traditional and learning based techniques. We discuss the merits and limitations of the platform in terms of exploitation of available behaviours, fast rapid prototyping, reproduction and repair. Towards the end, we will demonstrate trotting, bounding behaviors, and preliminary results in turning. In addition, we will also show various gait transitions i.e., trot-to-turn and trot-to-bound behaviors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&citation_for_view=is0x16gAAAAJ:N5tVd3kTz84C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"This paper analyzes the input to state stability properties of controllers which stabilize hybrid periodic orbits. Systems that are input to state stable tend to be robust to modeling and sensing uncertainties. The main contribution of this paper is in the construction of control Lyapunov functions that do not just stabilize, but also input to state stabilize a given hybrid system. Bipedal robotic walking, which can be naturally modeled as a hybrid system, is analyzed under this class of controllers. Specifically, we will select a class of controllers via rapidly exponentially stabilizing control Lyapunov functions that stabilize bipedal robotic walking; typically modeled as hybrid periodic orbits. We will show with simulation results that given the control Lyapunov functions and the associated set of stabilizing controllers, there exist input to state stabilizing control Lyapunov functions and the associated set of controllers that input to state …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&citation_for_view=is0x16gAAAAJ:ye4kPcJQO24C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Industrial robot manipulators are not able to match the precision and speed with which humans are able to execute contact rich tasks even to this day. Therefore, as a means to overcome this gap, we demonstrate generative methods for imitating a peg-in-hole insertion task in a 6-DOF robot manipulator. In particular, generative adversarial imitation learning (GAIL) is used to successfully achieve this task with a peg-hole clearance on the Yaskawa GP8 industrial robot. Experimental results show that the policy successfully learns within 20 episodes from a handful of human expert demonstrations on the robot (i.e., < 10 tele-operated robot demonstrations). The insertion time improves from > 20 seconds (which also includes failed insertions) to < 15 seconds, thereby validating the effectiveness of this approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:UHK10RUVsp4C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"To realize robotic systems in real-world settings, e.g., in restaurants, it will be necessary to achieve dynamic manipulation of nontrivial objects. In this context, this letter discusses methodologies used to realize trajectories in a robotic arm platform, specifically, applied to flipping burgers as an example of nonprehensile object manipulation. Flipping of burgers involves a series of tasks-going to the burger location, scooping, picking up, and flipping. Since the goal is to obtain these trajectories in a reasonably fast manner, we employ direct collocation based multisegmented trajectory optimization. We will first describe the problem setup, and then describe the constraints, decision variables employed, and then, to conclude, we will demonstrate these behaviors in a 6-DOF robot experimentally.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:LjlpjdlvIbIC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this paper, with a view toward fast deployment of locomotion gaits in low-cost hardware, we use a linear policy for realizing end-foot trajectories in the quadruped robot, Stoch 2. In particular, the parameters of the end-foot trajectories are shaped via a linear feedback policy that takes the torso orientation and the terrain slope as inputs. The corresponding desired joint angles are obtained via an inverse kinematics solver and tracked via a PID control law. Augmented Random Search, a model-free and a gradient-free learning algorithm is used to train this linear policy. Simulation results show that the resulting walking is robust to terrain slope variations and external pushes. This methodology is not only computationally light-weight but also uses minimal sensing and actuation capabilities in the robot, thereby justifying the approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:NJ774b8OgUMC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this work, we demonstrate robust walking in the bipedal robot Digit on uneven terrains by just learning a single linear policy. In particular, we propose a new control pipeline, wherein the high-level trajectory modulator shapes the end-foot ellipsoidal trajectories, and the low-level gait controller regulates the torso and ankle orientation. The foot-trajectory modulator uses a linear policy and the regulator uses a linear PD control law. As opposed to neural network based policies, the proposed linear policy has only 13 learnable parameters, thereby not only guaranteeing sample efficient learning but also enabling simplicity and interpretability of the policy. This is achieved with no loss of performance on challenging terrains like slopes, stairs and outdoor landscapes. We first demonstrate robust walking in the custom simulation environment, MuJoCo, and then directly transfer to hardware with no modification of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:evX43VCCuoAC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"This letter addresses the problem of formally guaranteeing the stability of interconnected systems with local controllers with a view toward stabilizing quadrupeds viewed as coupled bipeds. In particular, we present a novel framework that views general rigid-body systems as a collection of lower-dimensional systems that are coupled via reaction forces. Stabilizing the corresponding coupled control system can thus be addressed by stabilizing each subsystem coupled through the passive dynamics. The main results of the letter are stability conditions that guarantee convergence for each control subsystem by formulating coupled control Lyapunov functions (CCLFs) using the notion of input-to-state stability (ISS). This theoretical result is illustrated via a simple cart-pole example, where exponential stability is obtained. Next, building on previous results where an 18-DOF quadrupedal robot is decomposed into two …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:tzM49s52ZIMC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this paper, with a view toward deployment of light-weight control frameworks for bipedal walking robots, we realize end-foot trajectories that are shaped by a single linear feedback policy. We learn this policy via a model-free and a gradient free learning algorithm, Augmented Random Search (ARS), in the two robot platforms Rabbit and Digit. Our contributions are two-fold: a) By using torso and support plane orientation as inputs, we achieve robust walking on slopes of upto 20° in simulation. b) We demonstrate additional behaviors like walking backwards, stepping-in-place, and recovery from external pushes of upto 120 N. The end-result is a robust and a fast feedback control law for bipedal walking on terrains with varying slopes. Towards the end, we also provide preliminary results of hardware transfer to Digit.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:2KloaMYe4IUC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this paper, we explore a specific form of deep reinforcement learning (D-RL) technique for quadrupedal walking—trajectory based policy search via deep policy networks. Existing approaches determine optimal policies for each time step, whereas we propose to determine an optimal policy for each walking step. We justify our approach based on the fact that animals including humans use “low” dimensional trajectories at the joint level to realize walking. We will construct these trajectories by using Bézier polynomials, with the coefficients being determined by a parameterized policy. In order to maintain smoothness of the trajectories during step transitions, hybrid invariance conditions are also applied. The action is computed at the beginning of every step, and a linear PD control law is applied to track at the individual joints. After each step, reward is computed, which is then used to update the new policy …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:dQ2og3OwTAUC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this letter, we study stability properties of Proportional-Derivative (PD) controlled underactuated robotic systems for trajectory tracking applications. Stability of PD control laws for fully actuated systems is an established result, and we extend it for the class of underactuated robotic systems. We will first show some well known examples where PD tracking control laws do not yield tracking; some of which can even lead to instability. We will then show that for a subclass of robotic systems, PD tracking control laws, indeed, yield desirable tracking guarantees. We will show that for a specified time interval, and for sufficiently large enough PD gains (input saturations permitting), local boundedness of the tracking error can be guaranteed. In addition, for a class of systems with the kinetic symmetry property, stronger conditions like convergence to desirable bounds can be guaranteed. This class is not restrictive and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:JQOojiI6XY0C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this paper, with a view toward fast deployment of learned locomotion gaits in low-cost hardware, we generate a library of walking trajectories, namely, forward trot, backward trot, side-step, and turn in our custom-built quadruped robot, Stoch 2, using reinforcement learning. There are existing approaches that determine optimal policies for each time step, whereas we determine an optimal policy, in the form of end-foot trajectories, for each half walking step i.e., swing phase and stance phase. The way-points for the foot trajectories are obtained from a linear policy, i.e., a linear function of the states of the robot, and cubic splines are used to interpolate between these points. Augmented Random Search, a model-free and gradient-free learning algorithm is used to learn the policy in simulation. This learned policy is then deployed on hardware, yielding a trajectory in every half walking step. Different locomotion patterns are learned in simulation by enforcing a preconfigured phase shift between the trajectories of different legs. The transition from one gait to another is achieved by using a low-pass filter for the phase, and the sim-to-real transfer is improved by a linear transformation of the states obtained through regression.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:PR6Y55bgFSsC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this paper, inspired by Proportional-Derivative (PD) control laws, we present a class of Control Lyapunov Function (CLF) based Quadratic Programs (QPs) for robotic systems. Proportional-Derivative (PD) control laws are independent of the robot model, however, they fail to incorporate physical constraints, such as torque saturation. On the other hand, most optimization based control design approaches ensure satisfaction of the physical constraints, but they are sensitive to errors in the robot model. The PD based Quadratic Programs (PD-QPs), presented in this paper, are a first step towards bridging this gap between the PD and the optimization based controllers to bring the best of both together. We derive two versions of PD-QPs: model-based and model-free. Furthermore, for tracking time-varying trajectories, we establish asymptotic stability for the model-based PD-QP, and ultimate boundedness for the model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:1yQoGdGgb4wC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Robots that must operate in novel environments and collaborate with humans must be capable of acquiring new knowledge from human experts during operation. We propose teaching a robot novel objects it has not encountered before by pointing a hand at the new object of interest. An end-to-end neural network is used to attend to the novel object of interest indicated by the pointing hand and then to localize the object in new scenes. In order to attend to the novel object indicated by the pointing hand, we propose a spatial attention modulation mechanism that learns to focus on the highlighted object while ignoring the other objects in the scene. We show that a robot arm can manipulate novel objects that are highlighted by pointing a hand at them. We also evaluate the performance of the proposed architecture on a synthetic dataset constructed using emojis and on a real-world dataset of common objects.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:kzcrU_BdoSEC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"With the research into development of quadruped robots picking up pace, learning based techniques are being explored for developing locomotion controllers for such robots. A key problem is to generate leg trajectories for continuously varying target linear and angular velocities, in a stable manner. In this paper, we propose a two pronged approach to address this problem. First, multiple simpler policies are trained to generate trajectories for a discrete set of target velocities and turning radius. These policies are then augmented using a higher level neural network for handling the transition between the learned trajectories. Specifically, we develop a neural network based filter that takes in target velocity, radius and transforms them into new commands that enable smooth transitions to the new trajectory. This transformation is achieved by learning from expert demonstrations. An application of this is the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:uLbwQdceFCQC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Model Predictive Control (MPC) is a popular approach used for motion planning in dynamical systems. Given a finite horizon cost, we seek an optimal control law subject to safety constraints. However, in the presence of obstacles, existing MPC formulations are often slow and may lead to infeasibility. We propose a real-time implementable MPC formulation using control barrier functions (CBF) and successive convexification. We represent the non-convex obstacle avoidance constraints using CBFs that ensure that a feasible solution always exists. We then reformulate the non-convex optimal control problem using successive convexification to enable the use of computationally-efficient conic solvers. Our approach enables controller synthesis at real-time, which is difficult with existing approaches that rely on nonlinear solvers. We demonstrate the method in simulation, where we navigate a UAV to a target while …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:fEOibwPWpKIC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Control barrier function (CBF) based Quadratic Programs (QPs) were introduced in early 2014 as a means to guarantee safety in affine control systems in conjunction with stability/tracking. However, due to the presence of modelbased terms, they fail to provide guarantees under model perturbations. Therefore, in this paper, we propose a new class of CBFs for robotic systems that augment kinetic energy with the traditional forms. We show that with torque limits permitting, and with the kinematic models accurately known, forward invariance of safe sets generated by kinematic constraints (position and velocity) can be guaranteed. The proposed methodology is motivated by the control Lyapunov function (CLF) based QPs that use the kinetic energy function. By the property of CBF-QPs, we show that the pointwise min-norm control laws obtained are feasible and Lipschitz continuous, and can be derived analytically via the KKT conditions. In order to include stability with safety, we also augment CLF based constraints in the CBF-QPs to realize a unified control law that allows tracking with safety irrespective of the inertial parameters of the robot. We will demonstrate the robustness of this class of CBF-QPs in two robotic platforms: a 1-DOF and a 2-DOF manipulator, by scaling the masses by up to 100, and then simulating the resulting dynamics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:_Ybze24A_UAC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Bipedal robots are a prime example of systems which exhibit highly nonlinear dynamics, underactuation, and undergo complex dissipative impacts. This paper discusses methods used to overcome a wide variety of uncertainties, with the end result being stable bipedal walking. The principal contribution of this paper is to establish sufficiency conditions for yielding input to state stable (ISS) hybrid periodic orbits, i.e., stable walking gaits under model-based and phase-based uncertainties. In particular, it will be shown formally that exponential input to state stabilization (e-ISS) of the continuous dynamics, and hybrid invariance conditions are enough to realize stable walking in the 23-DOF bipedal robot DURUS. This main result will be supported through successful and sustained walking of the bipedal robot DURUS in a laboratory environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:9vf0nzSNQJEC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Recent works in Reinforcement Learning (RL) combine model-free (Mf)-RL algorithms with model-based (Mb)-RL approaches to get the best from both: asymptotic performance of Mf-RL and high sample-efficiency of Mb-RL. Inspired by these works, we propose a hierarchical framework that integrates online learning for the Mb-trajectory optimization with off-policy methods for the Mf-RL. In particular, two loops are proposed, where the Dynamic Mirror Descent based Model Predictive Control (DMD-MPC) is used as the inner loop Mb-RL to obtain an optimal sequence of actions. These actions are in turn used to significantly accelerate the outer loop Mf-RL. We show that our formulation is generic for a broad class of MPC based policies and objectives, and includes some of the well-known Mb-Mf approaches. We finally introduce a new algorithm: Mirror-Descent Model Predictive RL (M-DeMoRL), which uses Cross …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:-_dYPAW6P2MC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Inverse Kinematics of bipedal humanoid robots remains a challenging problem in the domain of robotics and computation, due to high order non-linearity and computation involved in Inverse Kinematics solutions. Also, there are many constraints involved with the various joint parameters which makes their analysis even more complex. Through this paper, we attempt to solve the Inverse Kinematics problem of a bipedal humanoid robot, Cassie, using Radial Basis Function (RBF) Networks. Our method can also be applied to other higher degrees of freedom serial manipulators. Our simulation analyses the results based on size of datasets, data distribution and network parameters. We have considered datasets of size 300k and 1 million, single and multiple hidden layers, equal and random data distribution, different number of neurons in layers and different training functions. We achieve our target of limiting the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:35r97b3x0nAC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Existing architectures for imitation learning using image-to-action policy networks perform poorly when presented with an input image containing multiple instances of the object of interest, especially when the number of expert demonstrations available for training are limited. We show that end-to-end policy networks can be trained in a sample efficient manner by (a) appending the feature map output of the vision layers with an embedding that can indicate instance preference or take advantage of an implicit preference present in the expert demonstrations, and (b) employing an autoregressive action generator network for the control layers. The proposed architecture for localization has improved accuracy and sample efficiency and can generalize to the presence of more instances of objects than seen during training. When used for end-to-end imitation learning to perform reach, push, and pick-and-place tasks on a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:Fu2w8maKXqMC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Unmanned aerial vehicles (UAVs), specifically quadrotors, have revolutionized various industries with their maneuverability and versatility, but their safe operation in dynamic environments heavily relies on effective collision avoidance techniques. This paper introduces a novel technique for safely navigating a quadrotor along a desired route while avoiding kinematic obstacles. The proposed approach employs control barrier functions and utilizes collision cones to ensure that the quadrotor's velocity and the obstacle's velocity always point away from each other. In particular, we propose a new constraint formulation that ensures that the relative velocity between the quadrotor and the obstacle always avoids a cone of vectors that may lead to a collision. By showing that the proposed constraint is a valid control barrier function (CBFs) for quadrotors, we are able to leverage on its real-time implementation via Quadratic Programs (QPs), called the CBF-QPs. We validate the effectiveness of the proposed CBF-QPs by demonstrating collision avoidance with moving obstacles under multiple scenarios. This is shown in the pybullet simulator.Furthermore we compare the proposed approach with CBF-QPs shown in literature, especially the well-known higher order CBF-QPs (HO-CBF-QPs), where in we show that it is more conservative compared to the proposed approach. This comparison also shown in simulation in detail.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:yB1At4FlUx8C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Cooperative control involves developing control strategies for individual robots that guarantee synchronized behavior of the states of all the robots in a team in some prescribed sense. In this work, we present a novel controller that achieves formation control for a group of differential-drive robots. First, we propose a nonlinear feedback control law that guarantees stable tracking of a reference trajectory for a single robot without exceeding the velocity limits of the robot. Using Lyapunov analysis, we obtain the necessary conditions on the control parameters and establish ultimate boundedness on error terms. Next, we formulate the formation control problem as a trajectory tracking problem for the multi-robot system and solve it using the proposed controller. Additionally, we provide constraints on formation size for given reference trajectory which ensures smooth turning of multi-robot formation without exceeding …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:9Nmd_mFXekcC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Evolution Strategy (ES) is a powerful black-box optimization technique based on the idea of natural evolution. In each of its iterations, a key step entails ranking candidate solutions based on some fitness score. For an ES method in Reinforcement Learning (RL), this ranking step requires evaluating multiple policies. This is presently done via on-policy approaches: each policy's score is estimated by interacting several times with the environment using that policy. This leads to a lot of wasteful interactions since, once the ranking is done, only the data associated with the top-ranked policies is used for subsequent learning. To improve sample efficiency, we propose a novel off-policy alternative for ranking, based on a local approximation for the fitness function. We demonstrate our idea in the context of a state-of-the-art ES method called the Augmented Random Search (ARS). Simulations in MuJoCo tasks show that, compared to the original ARS, our off-policy variant has similar running times for reaching reward thresholds but needs only around 70% as much data. It also outperforms the recent Trust Region ES. We believe our ideas should be extendable to other ES methods as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:t7zJ5fGR-2UC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"In this paper, we show how to realize robust safety-critical control laws for robotic manipulators with a large number of inequality constraints (>100). In particular, we use control barrier functions (CBFs) formulated via the kinetic energy terms to represent constraints like joint position and velocity limits, both in configuration and task space. By using the kinetic energy terms, we can realize model-free constraints in a quadratic program (QP), which can be solved in real-time, thereby demonstrating fast computation time despite the presence of large constraints. We will consider two types of CBFs, the reciprocal and the zeroing type, and integrate with Control Lyapunov Function (CLF) based constraints to yield a multi-objective QP. Further, we will provide feasibility and continuity guarantees, thereby yielding a continuous, robust and a safe control law for a broad class of robotic systems. Towards the end, we will …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:z_wVstp3MssC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"The use of internet-connected devices, especially small multi-rotor Unmanned Aerial Vehicles (UAVs), in scientific data gathering and applications is quite widespread. But due to limited intervention capability, the UAVs alone fail to automate agricultural tasks completely. Thereby, we propose a centralized framework capable of handling a heterogeneous mixture of UAVs and UGVs to cater to the needs of automating agriculture efficiently. The framework’s core is a novel heuristic decision module that creates new tasks by visually analyzing the farm and solves a vehicle routing problem to allocate it to agents optimally. It is also equipped with supporting modules to monitor their operation and, in case of failures, help them recover autonomously based on the task and agent assessment. The framework is used in three significant agricultural applications, namely yield prediction and drought stress detection in a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:uJ-U7cs_P_0C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",19,"Imitation learning is a data-driven approach to acquiring skills that relies on expert demonstrations to learn a policy that maps observations to actions. When performing demonstrations, experts are not always consistent and might accomplish the same task in slightly different ways. In this paper, we demonstrate inherent stochasticity in demonstrations collected for tasks including line following with a remote-controlled car and manipulation tasks including reaching, pushing, and picking and placing an object. We model stochasticity in the data distribution using autoregressive action generation, generative adversarial nets, and variational prediction and compare the performance of these approaches. We find that accounting for stochasticity in the expert data leads to substantial improvement in the success rate of task completion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&citation_for_view=is0x16gAAAAJ:tKAzc9rXhukC,http://shishirny.com/
Shirish Shevade,['Machine Learning'],21,"Machine learning models are increasingly being deployed in practice. Machine Learning as a Service (MLaaS) providers expose such models to queries by third-party developers through application programming interfaces (APIs). Prior work has developed model extraction attacks, in which an attacker extracts an approximation of an MLaaS model by making black-box queries to it. We design ActiveThief–a model extraction framework for deep neural networks that makes use of active learning techniques and unannotated public datasets to perform model extraction. It does not expect strong domain knowledge or access to annotated data on the part of the attacker. We demonstrate that (1) it is possible to use ActiveThief to extract deep classifiers trained on a variety of datasets from image and text domains, while querying the model with as few as 10-30% of samples from public datasets,(2) the resulting model exhibits a higher transferability success rate of adversarial examples than prior work, and (3) the attack evades detection by the state-of-the-art model extraction detection method, PRADA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&citation_for_view=HOIpJSwAAAAJ:3s1wT3WcHBgC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Novice programmers often struggle with the formal syntax of programming languages. In the traditional classroom setting, they can make progress with the help of real time feedback from their instructors which is often impossible to get in the massive open online course (MOOC) setting. Syntactic error repair techniques have huge potential to assist them at scale. Towards this, we design a novel programming language correction framework amenable to reinforcement learning. The framework allows an agent to mimic human actions for text navigation and editing. We demonstrate that the agent can be trained through self-exploration directly from the raw input, that is, program text itself, without either supervision or any prior knowledge of the formal syntax of the programming language. We evaluate our technique on a publicly available dataset containing 6975 erroneous C programs with typographic errors, written by students during an introductory programming course. Our technique fixes 1699 (24. 4%) programs completely and 1310 (18. 8%) program partially, outperforming DeepFix, a state-of-the-art syntactic error repair technique, which uses a fully supervised neural machine translation approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&citation_for_view=HOIpJSwAAAAJ:70eg2SAEIzsC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Novice programmers often struggle with the formal syntax of programming languages. To assist them, we design a novel programming language correction framework amenable to reinforcement learning. The framework allows an agent to mimic human actions for text navigation and editing. We demonstrate that the agent can be trained through self-exploration directly from the raw input, that is, program text itself, without any knowledge of the formal syntax of the programming language. We leverage expert demonstrations for one tenth of the training data to accelerate training. The proposed technique is evaluated on 6975 erroneous C programs with typographic errors, written by students during an introductory programming course. Our technique fixes 14% more programs and 29% more compiler error messages relative to those fixed by a state-of-the-art tool, DeepFix, which uses a fully supervised neural machine translation approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:J_g5lzvAfSwC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Machine learning models trained on confidential datasets are increasingly being deployed for profit. Machine Learning as a Service (MLaaS) has made such models easily accessible to end-users. Prior work has developed model extraction attacks, in which an adversary extracts an approximation of MLaaS models by making black-box queries to it. However, none of these works is able to satisfy all the three essential criteria for practical model extraction: (1) the ability to work on deep learning models, (2) the non-requirement of domain knowledge and (3) the ability to work with a limited query budget. We design a model extraction framework that makes use of active learning and large public datasets to satisfy them. We demonstrate that it is possible to use this framework to steal deep classifiers trained on a variety of datasets from image and text domains. By querying a model via black-box access for its top prediction, our framework improves performance on an average over a uniform noise baseline by 4.70x for image tasks and 2.11x for text tasks respectively, while using only 30% (30,000 samples) of the public dataset at its disposal.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:M05iB0D1s5AC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Providing feedback is an integral part of teaching. Most open online courses on programming make use of automated grading systems to support programming assignments and give real-time feedback. These systems usually rely on test results to quantify the programs' functional correctness. They return failing tests to the students as feedback. However, students may find it difficult to debug their programs if they receive no hints about where the bug is and how to fix it. In this work, we present NeuralBugLocator, a deep learning based technique, that can localize the bugs in a faulty program with respect to a failing test, without even running the program. At the heart of our technique is a novel tree convolutional neural network which is trained to predict whether a program passes or fails a given test. To localize the bugs, we analyze the trained network using a state-of-the-art neural prediction attribution technique and see which lines of the programs make it predict the test outcomes. Our experiments show that NeuralBugLocator is generally more accurate than two state-of-the-art program-spectrum based and one syntactic difference based bug-localization baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:SeFeTyx0c_EC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Explainable Recommendations provide the reasons behind why an item is recommended to a user, which often leads to increased user satisfaction and persuasiveness. An intuitive way to explain recommendations is by generating a synthetic personalized natural language review for a user-item pair. Although there exist some approaches in the literature that explain recommendations by generating reviews, the quality of the reviews is questionable. Besides, these methods usually take considerable time to train the underlying language model responsible for generating the text. In this work, we propose ReXPlug, an end-to-end framework with a plug and play way of explaining recommendations. ReXPlug predicts accurate ratings as well as exploits Plug and Play Language Model to generate high-quality reviews. We train a simple sentiment classifier for controlling a pre-trained language model for the generation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:pyW8ca7W8N0C,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Research on the task of Reading Comprehension style Question Answering (RCQA) has gained momentum in recent years due to the emergence of human annotated datasets and associated leaderboards, for example CoQA, HotpotQA, SQuAD, TriviaQA, etc. While state-of-the-art has advanced considerably, there is still ample opportunity to advance it further on some important variants of the RCQA task. In this paper, we propose a novel deep neural architecture, called TAP (Translucent Answer Prediction), to identify answers and evidence (in the form of supporting facts) in an RCQA task requiring multi-hop reasoning. TAP comprises two loosely coupled networks–Local and Global Interaction eXtractor (LoGIX) and Answer Predictor (AP). LoGIX predicts supporting facts, whereas AP consumes these predicted supporting facts to predict the answer span. The novel design of LoGIX is inspired by two key design desiderata–local context and global interaction–that we identified by analyzing examples of multi-hop RCQA task. The loose coupling between LoGIX and the AP reveals the set of sentences used by the AP in predicting an answer. Therefore, answer predictions of TAP can be interpreted in a translucent manner. TAP offers state-of-the-art performance on the HotpotQA (Yang et al. 2018) dataset–an apt dataset for multi-hop RCQA task–as it occupies Rank-1 on its leaderboard (https://hotpotqa. github. io/) at the time of submission.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:4OULZ7Gr8RgC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Social recommendation systems typically combine extra information like a social network with the user-item interaction network in order to alleviate data sparsity issues. This also helps in making more accurate and personalized recommendations. However, most of the existing systems work under the assumption that all socially connected users have equal influence on each other in a social network, which is not true in practice. Further, estimating the quantum of influence that exists among entities in a user-item interaction network is essential when only implicit ratings are available. This has been ignored even in many recent state-of-the-art models such as SAMN (Social Attentional Memory Network) and DeepSoR (Deep neural network model on Social Relations). Many a time, capturing a complex relationship between the entities (users/items) is essential to boost the performance of a recommendation system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:HoB7MX3m0LUC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Natural language processing for program synthesis has been widely researched. In this work, we focus on generating Bash commands from natural language invocations with explanations. We propose a novel transformer based solution by utilizing Bash Abstract Syntax Trees and manual pages. Our method incorporates tree structure information in the transformer architecture and provides explanations for its predictions via alignment matrices between user invocation and manual page text. Our method performs on par with the state of the art performance on Natural Language Context to Command task and performs better than fine-tuned T5 and Seq2Seq models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:bFI3QPDXJZMC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Bundle recommendation – recommending a group of products in place of individual products to customers is gaining attention day by day. It presents two interesting challenges – (1) how to personalize and recommend existing bundles to users, and (2) how to generate personalized novel bundles targeting specific users. Recently, few models have been proposed for modeling the bundle recommendation problem. However, they have the following shortcomings. First, they do not consider the higher-order relationships amongst the entities (users, items and bundles). Second, they do not model the relative influence of items present in the bundles, which is crucial in defining such bundles. In this work, we propose GRAM-SMOT – a graph attention-based framework to address the above challenges. Further, we define a loss function based on the metric-learning approach to learn the embeddings of entities …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:cFHS6HbyZ2cC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Machine-Learning-as-a-Service providers expose machine learning (ML) models through application programming interfaces (APIs) to developers. Recent work has shown that attackers can exploit these APIs to extract good approximations of such ML models, by querying them with samples of their choosing. We propose VarDetect, a stateful monitor that tracks the distribution of queries made by users of such a service, to detect model extraction attacks. Harnessing the latent distributions learned by a modified variational autoencoder, VarDetect robustly separates three types of attacker samples from benign samples, and successfully raises an alarm for each. Further, with VarDetect deployed as an automated defense mechanism, the extracted substitute models are found to exhibit poor performance and transferability, as intended. Finally, we demonstrate that even adaptive attackers with prior knowledge of the deployment of VarDetect, are detected by it.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:D03iK_w7-QYC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Providing feedback is an integral part of teaching. Most open online courses on programming make use of automated grading systems to support programming assignments and give real-time feedback. These systems usually rely on test results to quantify the programs' functional correctness. They return failing tests to the students as feedback. However, students may find it difficult to debug their programs if they receive no hints about where the bug is and how to fix it. In this work, we present the first deep learning based technique that can localize bugs in a faulty program w.r.t. a failing test, without even running the program. At the heart of our technique is a novel tree convolutional neural network which is trained to predict whether a program passes or fails a given test. To localize the bugs, we analyze the trained network using a state-of-the-art neural prediction attribution technique and see which lines of the programs make it predict the test outcomes. Our experiments show that the proposed technique is generally more accurate than two state-of-the-art program-spectrum based and one syntactic difference based bug-localization baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:g5m5HwL7SMYC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Cross-Domain Collaborative Filtering (CDCF) mitigates data sparsity and cold-start issues present in conventional recommendation systems by exploiting and transferring knowledge from related domains. Leveraging user-generated tags (e.g. ancient-literature, military-history) for bridging the related domains is becoming a popular way for enhancing personalized recommendations. However, existing tag based models bridge the domains based on common tags between domains and their co-occurrence frequencies. This results in capturing the syntax similarities between the tags and ignoring the semantic similarities between them. In this work, to address these, we propose TagEmbedSVD, a tag-based CDCF model to cross-domain setting. TagEmbedSVD makes use of the pre-trained word embeddings (word2vec) for tags to enhance personalized recommendations in the cross-domain setting. Empirical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:ZHo1McVdvXMC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Cross-Domain Collaborative Filtering (CDCF) provides a way to alleviate data sparsity and cold-start problems present in recommendation systems by exploiting the knowledge from related domains. Existing CDCF models are either based on matrix factorization or deep neural networks. Independent use of either of the techniques in isolation may result in suboptimal performance for the prediction task. Also, most of the existing models face challenges particularly in handling diversity between domains and learning complex non-linear relationships that exist amongst entities (users/items) within and across domains. In this work, we propose an end-to-end neural network model – NeuCDCF, to address these challenges in a cross-domain setting. More importantly, NeuCDCF is based on a wide and deep framework and learns the representations jointly using both matrix factorization and deep neural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:pqnbT2bcN3wC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Exploiting heterogeneous information networks (HIN) to top-N recommendation has been shown to alleviate the data sparsity problem present in recommendation systems. This requires careful effort in extracting relevant knowledge from HIN. However, existing models in this setting have the following shortcomings. Mainly, they are not end-to-end, which puts the burden on the system to first learn similarity or commuting matrix offline using some manually selected meta-paths before we train for the top-N recommendation objective. Further, they do not attentively extract user-specific information from HIN, which is essential for personalization. To address these challenges, we propose an end-to-end neural network model – GAMMA (Graph and Multi-view Memory Attention mechanism). We aim to replace the offline meta-path based similarity or commuting matrix computation with a graph attention …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:u_35RYKgDlwC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"The personalized list continuation (PLC) task is to curate the next items to user-generated lists (ordered sequence of items) in a personalized way. The main challenge in this task is understanding the ternary relationships among the interacting entities (users, items, and lists) that the existing works do not consider. Further, they do not take into account the multi-hop relationships among entities of the same type. In addition, capturing the sequential information amongst the items already present in the list also plays a vital role in determining the next relevant items that get curated.In this work, we propose HyperTeNet - a self-attention hypergraph and Transformer-based neural network architecture for the personalized list continuation task to address the challenges mentioned above. We use graph convolutions to learn the multi-hop relationship among the entities of the same type and leverage a self-attention-based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:_xSYboBqXhAC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Cross-Domain Collaborative Filtering (CDCF) provides a way to alleviate data sparsity and cold-start problems present in recommendation systems by exploiting the knowledge from related domains. Existing CDCF models are either based on matrix factorization or deep neural networks. Either of the techniques in isolation may result in suboptimal performance for the prediction task. Also, most of the existing models face challenges particularly in handling diversity between domains and learning complex non-linear relationships that exist amongst entities (users/items) within and across domains. In this work, we propose an end-to-end neural network model -- NeuCDCF, to address these challenges in a cross-domain setting. More importantly, NeuCDCF follows a wide and deep framework and it learns the representations combinedly from both matrix factorization and deep neural networks. We perform experiments on four real-world datasets and demonstrate that our model performs better than state-of-the-art CDCF models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:1sJd4Hv_s6UC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Bash is a Unix command language used for interacting with the Operating System. Recent works on natural language to Bash translation have made significant advances, but none of the previous methods utilize the problem’s inherent structure. We identify this structure andpropose a Segmented Invocation Transformer (SIT) that utilizes the information from the constituency parse tree of the natural language text. Our method is motivated by the alignment between segments in the natural language text and Bash command components. Incorporating the structure in the modelling improves the performance of the model. Since such systems must be universally accessible, we benchmark the inference times on a CPU rather than a GPU. We observe a 1.8 x improvement in the inference time and a 5x reduction in model parameters. Attribution analysis using Integrated Gradients reveals that the proposed method can capture the problem structure.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:b0M2c_1WBrUC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Multi-label classification has attracted much interest due to its wide applicability. Modeling label interactions and investigating their impact on classifier quality are crucial aspects of multi-label classification. In this paper, we propose a multi-structure SVM (called MSSVM) which allows the user to hypothesize multiple label interaction structures and helps to identify their importance in improving generalization performance. We design an efficient optimization algorithm to solve the proposed MSSVM. Extensive empirical evaluation provides fresh and interesting insights into the following questions: (a) How do label interactions affect multiple performance metrics typically used in multi-label classification? (b) Do higher order label interactions significantly impact a given performance metric for a particular dataset? (c) Can we make useful suggestions on the label interaction structure? and (d) Is it always …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:lSLTfruPkqcC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"In this work, we propose an automated method to identify semantic bugs in student programs, called ATAS, which builds upon the recent advances in both symbolic execution and active learning. Symbolic execution is a program analysis technique which can generate test cases through symbolic constraint solving. Our method makes use of a reference implementation of the task as its sole input. We compare our method with a symbolic execution-based baseline on 6 programming tasks retrieved from CodeForces comprising a total of 23 K student submissions. We show an average improvement of over 2.5x over the baseline in terms of runtime (thus making it more suitable for online evaluation), without a significant degradation in evaluation accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:RYcK_YlVTxYC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"During software development, developers need answers to queries about semantic aspects of code. Even though extractive question-answering using neural approaches has been studied widely in natural languages, the problem of answering semantic queries over code using neural networks has not yet been explored. This is mainly because there is no existing dataset with extractive question and answer pairs over code involving complex concepts and long chains of reasoning. We bridge this gap by building a new, curated dataset called CodeQueries, and proposing a neural question-answering methodology over code. We build upon state-of-the-art pre-trained models of code to predict answer and supporting-fact spans. Given a query and code, only some of the code may be relevant to answer the query. We first experiment under an ideal setting where only the relevant code is given to the model and show that our models do well. We then experiment under three pragmatic considerations: (1) scaling to large-size code, (2) learning from a limited number of examples and (3) robustness to minor syntax errors in code. Our results show that while a neural model can be resilient to minor syntax errors in code, increasing size of code, presence of code that is not relevant to the query, and reduced number of training examples limit the model performance. We are releasing our data and models to facilitate future work on the proposed problem of answering semantic queries over code.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:NhqRSupF_l8C,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Community detection is a well-studied problem in machine learning and recommendation systems literature. In this paper, we study a novel variant of this problem where we assign predefined fashion communities to users in an Ecommerce ecosystem for downstream tasks. We model our problem as a link prediction task in knowledge graphs with multiple types of edges and multiple types of nodes depicting the intricate Ecommerce ecosystems. We employ Relational Graph Convolutional Networks (R-GCN) on top of this knowledge graph to determine whether a user should be assigned to a given community or not. We conduct empirical experiments on two real-world datasets from a leading fashion retailer. Our experiments demonstrate that the proposed graph-based approach performs significantly better than the non-graph-based baseline, indicating that higher order methods like GCN can improve the task of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:EUQCXRtRnyEC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"Stochastic multi-armed bandit (MAB) mechanisms are widely used in sponsored search auctions, crowdsourcing, online procurement, etc. Existing stochastic MAB mechanisms with a deterministic payment rule, proposed in the literature, necessarily suffer a regret of Ω(T2/3), where T is the number of time steps. This happens because the existing mechanisms consider the worst case scenario where the means of the agents’ stochastic rewards are separated by a very small amount that depends on T. We make, and, exploit the crucial observation that in most scenarios, the separation between the agents’ rewards is rarely a function of T. Moreover, in the case that the rewards of the arms are arbitrarily close, the regret contributed by such sub-optimal arms is minimal. Our idea is to allow the center to indicate the resolution, Δ, with which the agents must be distinguished. This immediately leads us to introduce the notion of Δ …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:a0OBvERweLwC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],21,"The personalized list continuation (PLC) task is to curate the next items to user-generated lists (ordered sequence of items) in a personalized way. The main challenge in this task is understanding the ternary relationships among the interacting entities (users, items, and lists) that the existing works do not consider. Further, they do not take into account the multi-hop relationships among entities of the same type. In addition, capturing the sequential information amongst the items already present in the list also plays a vital role in determining the next relevant items that get curated. In this work, we propose HyperTeNet -- a self-attention hypergraph and Transformer-based neural network architecture for the personalized list continuation task to address the challenges mentioned above. We use graph convolutions to learn the multi-hop relationship among the entities of the same type and leverage a self-attention-based hypergraph neural network to learn the ternary relationships among the interacting entities via hyperlink prediction in a 3-uniform hypergraph. Further, the entity embeddings are shared with a Transformer-based architecture and are learned through an alternating optimization procedure. As a result, this network also learns the sequential information needed to curate the next items to be added to the list. Experimental results demonstrate that HyperTeNet significantly outperforms the other state-of-the-art models on real-world datasets. Our implementation and datasets are available at https://github.com/mvijaikumar/HyperTeNet.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&citation_for_view=HOIpJSwAAAAJ:f2IySw72cVMC,http://drona.csa.iisc.ac.in/~shirish/
Chaya Ganesh,['Cryptography'],13,"The two most common ways to design non-interactive zero-knowledge (NIZK) proofs are based on Sigma protocols and QAP-based SNARKs. The former is highly efficient for proving algebraic statements while the latter is superior for arithmetic representations.
   Motivated by applications such as privacy-preserving credentials and privacy-preserving audits in cryptocurrencies, we study the design of NIZKs for composite statements that compose algebraic and arithmetic statements in arbitrary ways. Specifically, we provide a framework for proving statements that consist of ANDs, ORs and function compositions of a mix of algebraic and arithmetic components. This allows us to explore the full spectrum of trade-offs between proof size, prover cost, and CRS size/generation cost. This leads to proofs for statements of the form: knowledge of x such that for some public y where the prover’s …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:Tyk-4Ss8FVUC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Proof-of-stake (PoS) protocols are emerging as one of the most promising alternative to the wasteful proof-of-work (PoW) protocols for consensus in Blockchains (or distributed ledgers). However, current PoS protocols inherently disclose both the identity and the wealth of the stakeholders, and thus seem incompatible with privacy-preserving cryptocurrencies (such as ZCash, Monero, etc.). In this paper we initiate the formal study for PoS protocols with privacy properties. Our results include:
1.
A (theoretical) feasibility result showing that it is possible to construct a general class of private PoS (PPoS) protocols; and to add privacy to a wide class of PoS protocols,
2.
A privacy-preserving version of a popular PoS protocol, Ouroboros Praos …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:W7OEmFMy1HYC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"In this paper we provide a formal treatment of proof of replicated storage, a novel cryptographic primitive recently proposed in the context of a novel cryptocurrency, namely Filecoin.
In a nutshell, proofs of replicated storage is a solution to the following problem: A user stores a file m on n different servers to ensure that the file will be available even if some of the servers fail. Using proof of retrievability, the user could check that every server is indeed storing the file. However, what if the servers collude and, in order to save on resources, decide to only store one copy of the file? A proof of replicated storage guarantees that, unless the (potentially colluding) servers are indeed reserving the space necessary to store n copies of the file, the user will not accept the proofs. While some candidate proofs of replicated storage have already been proposed, their soundness relies on timing assumptions i.e., the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:Y0pCki6q_DkC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"The lack of privacy in the first generation of cryptocurrencies such as Bitcoin, Ethereum, etc. is a well known problem in cryptocurrency research. To overcome this problem, several new cryptocurrencies were designed to guarantee transaction privacy and anonymity for their users (examples include ZCash, Monero, etc.).
However, the anonymity provided by such systems appears to be fundamentally problematic in current business and legislation settings: banks and other financial institutions must follow rules such as “Know Your Customer” (KYC), “Anti Money Laundering” (AML), etc. It is also well known that the (alleged or real) anonymity guarantees provided by cryptocurrencies have attracted ill-intentioned individuals to this space, who look at cryptocurrencies as a way of facilitating illegal activities (tax-evasion, ransom-ware, trading of illegal substances, etc.).
The fact that current cryptocurrencies do not comply …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:_FxGoFyzp5QC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Zero-knowledge (ZK) protocols are undoubtedly among the central primitives in cryptography, lending their power to numerous applications such as secure computation, voting, auctions, and anonymous credentials to name a few. The study of efficient ZK protocols for non-algebraic statements has seen rapid progress in recent times, relying on secure computation techniques. The primary contribution of this work lies in constructing efficient UC-secure constant round ZK protocols from garbled circuits that are secure against adaptive corruptions, with communication linear in the size of the statement. We begin by showing that the practically efficient ZK protocol of Jawurek et al. (CCS 2013) is adaptively secure when the underlying oblivious transfer (OT) satisfies a mild adaptive security guarantee. We gain adaptive security with little to no overhead over the static case. A conditional verification technique is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:zYLM7Y9cAGgC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"We present a framework that allows to certify the fairness degree of a model based on an interactive and privacy-preserving test. The framework verifies any trained model, regardless of its training process and architecture. Thus, it allows us to evaluate any deep learning model on multiple fairness definitions empirically. We tackle two scenarios, where either the test data is privately available only to the tester or is publicly known in advance, even to the model creator. We investigate the soundness of the proposed approach using theoretical analysis and present statistical guarantees for the interactive test. Finally, we provide a cryptographic technique to automate fairness testing and certified inference with only black-box access to the model at hand while hiding the participants' sensitive data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:Se3iqnhoufwC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Succinct non-interactive arguments of knowledge (SNARKs) enable non-interactive efficient verification of NP computations and admit short proofs. However, all current SNARK constructions assume that the statements to be proven can be efficiently represented as either Boolean or arithmetic circuits over finite fields. For most constructions, the choice of the prime field is limited by the existence of groups of matching order for which secure bilinear maps exist. In this work we overcome such restrictions and enable verifying computations over rings. We construct the first designated-verifier SNARK for statements which are represented as circuits over a broader kind of commutative rings, namely those containing big enough exceptional sets. Exceptional sets consist of elements such that their pairwise differences are invertible. Our contribution is threefold: We first introduce Quadratic Ring Programs (QRPs) as a characterization of NP where the arithmetic is over a ring. Second, inspired by the framework in Gennaro, Gentry, Parno and Raykova (EUROCRYPT 2013), we design SNARKs over rings in a modular way. We generalize pre-existent assumptions employed in field-restricted SNARKs to encoding schemes over rings. As our encoding notion is generic in the choice of the ring, it is amenable to different settings. Finally, we propose two applications for our SNARKs. Our first application is verifiable computation over encrypted data, specifically for evaluations of Ring-LWE-based homomorphic encryption schemes. In the second one, we use Rinocchio to naturally prove statements about circuits over eg , which closely matches real-life …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:LkGwnXOMwfcC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Bulletproofs (Bünz et al. IEEE S&P 2018) are a celebrated ZK proof system that allows for short and efficient proofs, and have been implemented and deployed in several real-world systems.
In practice, they are most often implemented in their non-interactive version obtained using the Fiat-Shamir transform, despite the lack of a formal proof of security for this setting.
Prior to this work, there was no evidence that malleability attacks were not possible against Fiat-Shamir Bulletproofs. Malleability attacks can lead to very severe vulnerabilities, as they allow an adversary to forge proofs re-using or modifying parts of the proofs provided by the honest parties.
In this paper, we show for the first time that Bulletproofs (or any other similar multi-round proof system satisfying some form of weak unique response property) achieve simulation-extractability in the algebraic group model.
This implies that Fiat-Shamir Bulletproofs are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:hqOjcs7Dif8C,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"The problems of Byzantine Broadcast (BB) and Byzantine Agreement (BA) are of interest to both the distributed computing and cryptography communities. Extension protocols for these primitives have been introduced to handle long messages efficiently at the cost of small number of single-bit broadcasts, referred to as seed broadcasts. While the communication optimality has remained the most sought-after property of an extension protocol in the literature, we prioritize both communication and round optimality in this work. In a setting with n parties and a static adversary controlling at most t parties in Byzantine fashion, we present BB and BA extension protocols with $$t<n$$ t < n , $$t < n/2$$ t < n / 2 and $$t<n/3$$ t < …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:qjMakFHDy7sC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"We show that three popular universal zero-knowledge SNARKs (Plonk, Sonic, and Marlin) are updatable SRS simulation extractable NIZKs and signatures of knowledge (SoK) out-of-the-box avoiding any compilation overhead.
Towards this we generalize results for the Fiat–Shamir (FS) transformation, which turns interactive protocols into signature schemes, non-interactive proof systems, or SoK in the random oracle model (ROM). The security of the transformation relies on rewinding to extract the secret key or the witness, even in the presence of signing queries for signatures and simulation queries for proof systems and SoK, respectively. We build on this line of work and analyze multi-round FS for arguments with a structured reference string (SRS). The combination of ROM and SRS, while redundant in theory, is the model of choice for the most efficient practical systems to date. We also consider the case where …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:8k81kl-MbHgC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Standardized digital signature schemes (eg, Rivest-Shamir-Adleman (RSA), Digital Signature Algorithm (DSA), Elliptical Curve Digital Signature Algorithm (EC-DSA), etc.) may be employed to prove authenticity of a message containing credentials. Proving possession of valid credentials may be performed using a combination of garbled circuits with message authentication codes (MACs) and proof of knowledge protocols (eg, Sigma protocol, Schnorr protocol, etc.). Such techniques may allow proving entities to prove possession of valid credentials using standardized signature schemes without revealing those credentials directly to a verifying entity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:IjCSPb-OGe4C,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"We study interactive proof systems (IPSes) in a strong adversarial setting where the machines of honest parties might be corrupted and under control of the adversary. Our aim is to answer the following, seemingly paradoxical, questions:•
Can Peggy convince Vic of the veracity of an NP statement, without leaking any information about the witness even in case Vic is malicious and Peggy does not trust her computer?
•
Can we avoid that Peggy fools Vic into accepting false statements, even if Peggy is malicious and Vic does not trust her computer?
At EUROCRYPT 2015, Mironov and Stephens-Davidowitz introduced cryptographic reverse firewalls (RFs) as an attractive approach to tackling such questions. Intuitively, a RF for Peggy/Vic is an external party that sits between Peggy/Vic and the outside world and whose scope is to sanitize Peggy's/Vic's incoming and outgoing messages in the face of subversion of her/his …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:eQOLeE2rZwMC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"We construct polynomial commitment schemes with constant sized evaluation proofs and logarithmic verification time in the transparent setting. To the best of our knowledge, this is the first result achieving this combination of properties. Our starting point is a transparent inner product commitment scheme with constant-sized proofs and linear verification. We build on this to construct a polynomial commitment scheme with constant size evaluation proofs and logarithmic (in the degree of the polynomial) verification time. Our constructions make use of groups of unknown order instantiated by class groups. We prove security of our construction in the Generic Group Model (GGM). Using our polynomial commitment scheme to compile an information-theoretic proof system yields Dew--a transparent and constant-sized zkSNARK (Zero-knowledge Succinct Non-interactive ARguments of Knowledge) with logarithmic verification. Finally, we show how to recover the result of DARK (Bünz et al., Eurocrypt 2020). DARK presented a succinct transparent polynomial commitment scheme with logarithmic proof size and verification. However, it was recently discovered to have a gap in its security proof (Block et al, CRYPTO 2021). We recover its extractability based on our polynomial commitment construction, thus obtaining a transparent polynomial commitment scheme with logarithmic proof size and verification under the same assumptions as DARK, but with a prover time that is quadratic.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:0EnyYjriUFMC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"We advance the state-of-the art for zero-knowledge commit-and-prove SNARKs (CP-SNARKs). CP-SNARKs are an important class of SNARKs which, using commitments as “glue”, allow to efficiently combine proof systems—e.g., general-purpose SNARKs (an efficient way to prove statements about circuits) and -protocols (an efficient way to prove statements about group operations). Thus, CP-SNARKs allow to efficiently provide zero-knowledge proofs for composite statements such as for some hash-function H.
Our main contribution is providing the first construction of CP-SNARKs where the proof size is succinct in the number of commitments.
We achieve our result by providing a general technique to compile Algebraic Holographic Proofs (AHP) (an underlying abstraction used in many modern SNARKs) with special “decomposition” properties into an efficient CP-SNARK. We then show that some of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:roLk4NBRz8UC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Method, System, and Computer Program Product for Determining Solvency of a Digital Asset Exchange Download PDF",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:ufrVoPGSRksC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"We study Multi-party computation (MPC) in the setting of subversion, where the adversary tampers with the machines of honest parties. Our goal is to construct actively secure MPC protocols where parties are corrupted adaptively by an adversary (as in the standard adaptive security setting), and in addition, honest parties’ machines are compromised.
The idea of reverse firewalls (RF) was introduced at EUROCRYPT’15 by Mironov and Stephens-Davidowitz as an approach to protecting protocols against corruption of honest parties’ devices. Intuitively, an RF for a party is an external entity that sits between and the outside world and whose scope is to sanitize ’s incoming and outgoing messages in the face of subversion of their computer. Mironov and Stephens-Davidowitz constructed a protocol for passively-secure two-party computation. At CRYPTO’20, Chakraborty, Dziembowski and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&citation_for_view=b_NnjeQAAAAJ:UebtZRa9Y70C,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Bulletproofs (Bünz et al. IEEE S&P 2018) are a celebrated ZK proof system that allows for short and efficient proofs, and have been implemented and deployed in several real-world systems. In practice, they are most often implemented in their non-interactive version obtained using the Fiat-Shamir transform. A security proof for this setting is necessary for ruling out malleability attacks. These attacks can lead to very severe vulnerabilities, as they allow an adversary to forge proofs re-using or modifying parts of the proofs provided by the honest parties. An earlier version of this work (Ganesh et al. EUROCRYPT 2022) provided evidence for non-malleability of Fiat-Shamir Bulletproofs. This was done by proving simulation-extractability, which implies non-malleability, in the algebraic group model. In this work, we generalize the former result and prove simulation extractability in the programmable random oracle model, removing the need for the algebraic group model. Along the way, we establish a generic chain of reductions for Fiat-Shamir-transformed multi-round public-coin proofs to be simulation-extractable in the (programmable) random oracle model, which may be of independent interest.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&citation_for_view=b_NnjeQAAAAJ:YOwf2qJgpHMC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"In proof-of-work based cryptocurrencies, miners invest computing power to maintain a distributed ledger. One known drawback of such a consensus protocol is its immense energy consumption. To prevent this waste of energy various consensus mechanism such as proof-of-space or proof-of-stake have been proposed. In proof-of-stake, block creators are selected based on the amounts of currency they stake instead of their expanded computing power.
In this work we study Virtual ASICs–a generalization of proof-of-stake. Virtual ASICs are essentially a virtualized version of proof-of-work. Miners can buy on-chain virtual mining machines which can be powered by virtual electricity. Similar to their physical counterparts, each powered virtual ASIC has a certain chance to win the right to create the next block. In the boundary case where virtual electricity is free, the protocol corresponds to proof-of-stake using an ASIC …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&citation_for_view=b_NnjeQAAAAJ:WF5omc3nYNoC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"The celebrated result by Gentry and Wichs established a theoretical barrier for succinct non-interactive arguments (SNARGs), showing that for (expressive enough) hard-on-average languages we must assume non-falsifiable assumptions. We further investigate those barriers by showing new negative and positive results related to extractability and to the preprocessing model. 1. We first ask the question “are there further barriers to SNARGs that are knowledge-sound (SNARKs) and with a black-box extractor?”. We show it is impossible to have such SNARKs in the standard model. This separates SNARKs in the random oracle model (which can have black-box extraction) and those in the standard model. 2. We find positive results regarding the same question in the non-adaptive setting. Under the existence of SNARGs (without extractability) and from standard assumptions, it is possible to build SNARKs with black-box extractability for a non-trivial subset of NP. 3. On the other hand, we show that (under some mild assumptions) all NP languages cannot have SNARKs with black-box extractability even in the non-adaptive setting. 4. The Gentry-Wichs result does not account for the preprocessing model, under which fall several efficient constructions. We show that also in the preprocessing model it is impossible to construct SNARGs that rely on falsifiable assumptions in a black-box way. Along the way, we identify a class of non-trivial languages, which we dub “trapdoor languages”, that bypass some of these impossibility results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&citation_for_view=b_NnjeQAAAAJ:5nxA0vEk-isC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Zero-knowledge Succinct Non-interactive ARguments of Knowledge (zkSNARKs) are becoming an increasingly fundamental tool in many real-world applications where the proof compactness is of the utmost importance, including blockchains. A proof of security for SNARKs in the Universal Composability (UC) framework (Canetti, FOCS’01) would rule out devastating malleability attacks. To retain security of SNARKs in the UC model, one must show their simulation-extractability such that the knowledge extractor is both black-box and straight-line, which would imply that proofs generated by honest provers are non-malleable. However, existing simulation-extractability results on SNARKs either lack some of these properties, or alternatively have to sacrifice witness succinctness to prove UC security.
In this paper, we provide a compiler lifting any simulation-extractable NIZKAoK into a UC-secure one in the global …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&citation_for_view=b_NnjeQAAAAJ:Zph67rFs4hoC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Sealed bid auctions are used to allocate a resource among a set of interested parties. Traditionally, auctions need the presence of a trusted auctioneer to whom the bidders provide their private bid values. Existence of such a trusted party is not an assumption easily realized in practice. Generic secure computation protocols can be used to remove a trusted party. However, generic techniques result in inefficient protocols, and typically do not provide fairness -- that is, a corrupt party can learn the output and abort the protocol thereby preventing other parties from learning the output.
At CRYPTO 2009, Miltersen, Nielsen and Triandopoulos~\citeC:MilNieTri09, introduced the problem of building auctions that are secure against rational bidders. Such parties are modeled as self-interested agents who care more about maximizing their utility than about learning information about bids of other agents. To realize this, they …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&citation_for_view=b_NnjeQAAAAJ:kNdYIx-mwKoC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"In current blockchain systems, full nodes that perform all of the available functionalities need to store the entire blockchain. In addition to the blockchain, full nodes also store a blockchain-summary, called the state, which is used to efficiently verify transactions. With the size of popular blockchains and their states growing rapidly, full nodes require massive storage resources in order to keep up with the scaling. This leads to a tug-of-war between scaling and decentralization since fewer entities can afford expensive resources. We present hybrid nodes for proof-of-work (PoW) cryptocurrencies which can validate transactions, validate blocks, validate states, mine, select the main chain, bootstrap new hybrid nodes, and verify payment proofs. With the use of a protocol called trimming, hybrid nodes only retain polylogarithmic number of blocks in the chain length in order to represent the proof-of-work of the blockchain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&citation_for_view=b_NnjeQAAAAJ:3fE2CSJIrl8C,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"In the setting of subversion, an adversary tampers with the machines of the honest parties thus leaking the honest parties’ secrets through the protocol transcript. The work of Mironov and Stephens-Davidowitz (EUROCRYPT’15) introduced the idea of reverse firewalls (RF) to protect against tampering of honest parties’ machines. All known constructions in the RF framework rely on the malleability of the underlying operations in order for the RF to rerandomize/sanitize the transcript. RFs are thus limited to protocols that offer some structure, and hence based on public-key operations. In this work, we initiate the study of efficient Multiparty Computation (MPC) protocols in the presence of tampering. In this regard,
We construct the first Oblivious Transfer (OT) extension protocol in the RF setting. We obtain maliciously-secure OTs using public key operations and inexpensive symmetric key operations, where is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&citation_for_view=b_NnjeQAAAAJ:KlAtU1dfN6UC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"We give an efficient construction of a computational non-interactive witness indistinguishable (NIWI) proof in the plain model, and investigate notions of extraction for NIZKs for algebraic languages. Our starting point is the recent work of Couteau and Hartmann (CRYPTO 2020) who developed a new framework (CH framework) for constructing non-interactive zero-knowledge proofs and arguments under falsifiable assumptions for a large class of languages called algebraic languages. In this paper, we construct an efficient NIWI proof in the plain model for algebraic languages based on the CH framework. In the plain model, our NIWI construction is more efficient for algebraic languages than state-of-the-art Groth-Ostrovsky-Sahai (GOS) NIWI (JACM 2012). Next, we explore knowledge soundness of NIZK systems in the CH framework. We define a notion of strong f-extractability, and show that the CH proof system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&citation_for_view=b_NnjeQAAAAJ:MXK_kJrjxJIC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,"Traditional notions of secure multiparty computation (MPC) allow mutually distrusting parties to jointly compute a function over their private inputs, but typically do not specify how these inputs are chosen. Motivated by real-world applications where corrupt inputs could adversely impact privacy and operational legitimacy, we consider a notion of authenticated MPC where the inputs are authenticated, eg, signed using a digital signature by some trusted authority. We propose a generic and efficient compiler that transforms any linear secret sharing based MPC protocol into one with input authentication. Our compiler incurs significantly lower computational costs and competitive communication overheads when compared to the best existing solutions, while entirely avoiding the (potentially expensive) protocol-specific techniques and pre-processing requirements that are inherent to these solutions. For -party MPC protocols with abort security where each party has inputs, our compiler incurs communication overall and a computational overhead of group exponentiations per party (the corresponding overheads for the most efficient existing solution are and ). Finally, for a corruption threshold , our compiler preserves the stronger identifiable abort security of the underlying MPC protocol. No existing solution for authenticated MPC achieves this regardless of the corruption threshold. Along the way, we make several technical contributions that are of independent interest. This includes the notion of distributed proofs of knowledge and concrete realizations of the same for several relations of interest, such as proving …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&citation_for_view=b_NnjeQAAAAJ:ULOm3_A8WrAC,https://www.csa.iisc.ac.in/~chaya/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"An algebraic branching program (ABP) A can be modelled as a product expression X1amp;middot; X2… Xd, where X1 and Xd are 1 × w and w × 1 matrices, respectively, and every other Xk is a w × w matrix; the entries of these matrices are linear forms in m variables over a field F (which we assume to be either Q or a field of characteristic poly(m)). The polynomial computed by A is the entry of the 1 × 1 matrix obtained from the product ∏k=1d Xk. We say A is a full rank ABP if the w2(d − 2) + 2w linear forms occurring in the matrices X1, X2, …, Xd are F-linearly independent. Our main result is a randomized reconstruction algorithm for full rank ABPs: Given blackbox access to an m-variate polynomial f of degree at most m, the algorithm outputs a full rank ABP computing f if such an ABP exists, or outputs “no full rank ABP exists” (with high probability). The running time of the algorithm is polynomial in m and β, where β is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&citation_for_view=xJrC-GMAAAAJ:ULOm3_A8WrAC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"A homogeneous depth three circuit C computes a polynomial f = T1 + T2 + ... + Ts, where each Ti is a product of d linear forms in n variables over some underlying field F. Given black-box access to f, can we efficiently reconstruct (i.e. proper learn) a homogeneous depth three circuit computing f? Learning various subclasses of circuits is natural and interesting from both theoretical and practical standpoints and in particular, properly learning homogeneous depth three circuits efficiently is stated as an open problem in a work by Klivans and Shpilka (COLT 2003) and is well-studied. Unfortunately, there is substantial amount of evidence to show that this is a hard problem in the worst case. We give a (randomized) poly(n,d,s)-time algorithm to reconstruct non-degenerate homogeneous depth three circuits for n = Ω(d2) (with some additional mild requirements on s and the characteristic of F). We call a circuit C as non …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&citation_for_view=xJrC-GMAAAAJ:Wp0gIr-vW9MC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"A matrix X is called a linear matrix if its entries are affine forms, i.e., degree one polynomials in n variables. What is a minimal-sized representation of a given matrix F as a product of linear matrices? Finding such a minimal representation is closely related to finding an optimal way to compute a given polynomial via an algebraic branching program. Here we devise an efficient algorithm for an average-case version of this problem. Specifically, given and blackbox access to the w2 entries of a matrix product , where each is a linear matrix over a given finite field , we wish to recover a factorization , where every is also a linear matrix over (or a small extension of ). We show that when the input F is sampled from a distribution defined by choosing random linear matrices over independently and taking their product and and , then an equivalent factorization …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&citation_for_view=xJrC-GMAAAAJ:M3ejUd6NZC8C,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"We develop algorithms for writing a polynomial as sums of powers of low degree polynomials in the non-degenerate case. This problem generalizes symmetric tensor decomposition which is widely studied, having many applications in machine learning. Our algorithm for this more general problem allows us to solve the moment problem for mixtures of zero-mean Gaussians in the nondegenerate case. Our algorithm is based on a scheme for obtaining a learning algorithm for an arithmetic circuit model from lower bound for the same model, provided certain non-degeneracy conditions hold. The scheme reduces the learning problem to the problem of decomposing two vector spaces under the action of a set of linear operators, where the spaces and the operators are derived from the input circuit and the complexity measure used in a typical lower bound proof. The non-degeneracy conditions are certain restrictions on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:mVmsd5A6BfQC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"The orbit of an n-variate polynomial f (𝐱) over a field 𝔽 is the set {f (A𝐱+ 𝐛): A∈ GL (n, 𝔽) and 𝐛∈ 𝔽ⁿ}. In this paper, we initiate the study of explicit hitting sets for the orbits of polynomials computable by several natural and well-studied circuit classes and polynomial families. In particular, we give quasi-polynomial time hitting sets for the orbits of:",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:aqlVkmm33-oC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"The determinant polynomial Det_n (x) of degree n is the determinant of anxn matrix of formal variables. A polynomial f is equivalent to Det_n (x) over a field F if there exists a A in GL (n^ 2, F) such that f= Det_n (A* x). Determinant equivalence test over F is the following algorithmic task: Given black-box access to af in F [x], check if f is equivalent to Det_n (x) over F, and if so then output a transformation matrix A in GL (n^ 2, F). In (Kayal, STOC 2012), a randomized polynomial time determinant equivalence test was given over F= C. But, to our knowledge, the complexity of the problem over finite fields and over Q was not well understood. In this work, we give a randomized poly (n, log| F|) time determinant equivalence test over finite fields F (under mild restrictions on the characteristic and size of F). Over Q, we give an efficient randomized reduction from factoring square-free integers to determinant equivalence test for quadratic forms (ie the n= 2 case), assuming GRH. This shows that designing a polynomial-time determinant equivalence test over Q is a challenging task. Nevertheless, we show that determinant equivalence test over Q is decidable: For bounded n, there is a randomized polynomial-time determinant equivalence test over Q with access to an oracle for integer factoring. Moreover, for any n, there is a randomized polynomial-time algorithm that takes input black-box access to af in Q [x] and if f is equivalent to Det_n over Q then it returns a A in GL (n^ 2, L) such that f= Det_n (A* x), where L is an extension field of Q and [L: Q]<= n. The above algorithms over finite fields and over Q are obtained by giving a polynomial-time randomized reduction …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:dhFuZR0502QC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"We show an Ω̃ (n^ 2.5) lower bound for general depth four arithmetic circuits computing an explicit n-variate degree-Θ (n) multilinear polynomial over any field of characteristic zero. To our knowledge, and as stated in the survey [Amir Shpilka and Amir Yehudayoff, 2010], no super-quadratic lower bound was known for depth four circuits over fields of characteristic≠ 2 before this work. The previous best lower bound is Ω̃ (n^ 1.5)[Abhijat Sharma, 2017], which is a slight quantitative improvement over the roughly Ω (n^ 1.33) bound obtained by invoking the super-linear lower bound for constant depth circuits in [Ran Raz, 2010; Victor Shoup and Roman Smolensky, 1997].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:qxL8FJ1GzNcC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"Consider a homogeneous degree d polynomial f= T₁+⋯+ T_s, T_i= g_i (𝓁_ {i, 1},…, 𝓁_ {i, m}) where g_i’s are homogeneous m-variate degree d polynomials and 𝓁_ {i, j}’s are linear polynomials in n variables. We design a (randomized) learning algorithm that given black-box access to f, computes black-boxes for the T_i’s. The running time of the algorithm is poly (n, m, d, s) and the algorithm works under some non-degeneracy conditions on the linear forms and the g_i’s, and some additional technical assumptions n≥(md) ², s≤ n^{d/4}. The non-degeneracy conditions on 𝓁_ {i, j}’s constitute non-membership in a variety, and hence are satisfied when the coefficients of 𝓁_ {i, j}’s are chosen uniformly and randomly from a large enough set. The conditions on g_i’s are satisfied for random polynomials and also for natural polynomials common in the study of arithmetic complexity like determinant, permanent, elementary symmetric polynomial, iterated matrix multiplication. A particularly appealing algorithmic corollary is the following: Given black-box access to an f= Det_r (L^(1))+…+ Det_r (L^(s)), where L^(k)=(𝓁_ {i, j}^(k)) _ {i, j} with 𝓁_ {i, j}^(k)’s being linear forms in n variables chosen randomly, there is an algorithm which in time poly (n, r) outputs matrices (M^(k)) _k of linear forms st there exists a permutation π:[s]→[s] with Det_r (M^(k))= Det_r (L^(π (k))).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:IWHjjKOFINEC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"Equivalence testing for a polynomial family {g_m} over a field F is the following problem: Given black-box access to an n-variate polynomial f(x), where n is the number of variables in g_m, check if there exists an A in GL(n,F) such that f(x) = g_m(Ax). If yes, then output such an A. The complexity of equivalence testing has been studied for a number of important polynomial families, including the determinant (Det) and the two popular variants of the iterated matrix multiplication polynomial: IMM_{w,d} (the (1,1) entry of the product of d many w w symbolic matrices) and Tr-IMM_{w,d} (the trace of the product of d many w w symbolic matrices). The families Det, IMM and Tr-IMM are VBP-complete, and so, in this sense, they have the same complexity. But, do they have the same equivalence testing complexity? We show that the answer is 'yes' for Det and Tr-IMM (modulo the use of randomness). The result is obtained by connecting the two problems via another well-studied problem called the full matrix algebra isomorphism problem (FMAI). In particular, we prove the following: 1. Testing equivalence of polynomials to Tr-IMM_{w,d}, for d 3 and w 2, is randomized polynomial-time Turing reducible to testing equivalence of polynomials to Det_w, the determinant of the w w matrix of formal variables. (Here, d need not be a constant.) 2. FMAI is randomized polynomial-time Turing reducible to equivalence testing (in fact, to tensor isomorphism testing) for the family of matrix multiplication tensors {Tr-IMM_{w,3}}. These in conjunction with the randomized poly-time reduction from determinant equivalence testing to FMAI [Garg,Gupta,Kayal,Saha19], imply that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:4DMP91E08xMC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"In a Nisan-Wigderson design polynomial (in short, a design polynomial), every pair of monomials share a few common variables. A useful example of such a polynomial, introduced in [Neeraj Kayal et al., 2014], is the following: NW_ {d, k}({x})= sum_ {h in F_d [z], deg (h)<= k}{prod_ {i= 0}^{d-1}{x_ {i, h (i)}}}, where d is a prime, F_d is the finite field with d elements, and k<< d. The degree of the gcd of every pair of monomials in NW_ {d, k} is at most k. For concreteness, we fix k= ceil [sqrt {d}]. The family of polynomials NW:={NW_ {d, k}: d is a prime} and close variants of it have been used as hard explicit polynomial families in several recent arithmetic circuit lower bound proofs. But, unlike the permanent, very little is known about the various structural and algorithmic/complexity aspects of NW beyond the fact that NW in VNP. Is NW_ {d, k} characterized by its symmetries? Is it circuit-testable, ie, given a circuit C can we check efficiently if C computes NW_ {d, k}? What is the complexity of equivalence test for NW, ie, given black-box access to af in F [{x}], can we check efficiently if there exists an invertible linear transformation A such that f= NW_ {d, k}(A*{x})? Characterization of polynomials by their symmetries plays a central role in the geometric complexity theory program. Here, we answer the first two questions and partially answer the third. We show that NW_ {d, k} is characterized by its group of symmetries over C, but not over R. We also show that NW_ {d, k} is characterized by circuit identities which implies that NW_ {d, k} is circuit-testable in randomized polynomial time. As another application of this characterization, we obtain the"" flip theorem"" for NW …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:9ZlFYXVOiuMC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"How many operations are needed to compute a given polynomial f(x1; x2; : : : ; xn)? Answering questions of this form naturally leads us on a search for clever algorithmic techniques to reduce the number of operations required. Simultaneously, it also leads us towards the complementary task of finding techniques and paradigms for proving lower bounds on the minimum number of operations required. In this survey we describe one such paradigm for obtaining lower bounds.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:4TOpqqG69KYC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"We study the polynomial equivalence problem for orbits of read-once arithmetic formulas (ROFs). Readonce formulas have received considerable attention in both algebraic and Boolean complexity and have served as a testbed for developing effective tools and techniques for analyzing circuits. Two n-variate polynomials f, g∈ F [x] are equivalent, denoted as f∼ g, if there is an A∈ GL (n, F) such that f= g (Ax). The orbit of f is the set of all polynomials equivalent to f. We investigate the complexity of the following two natural problems on ROFs:
• Equivalence test for ROFs: Given black-box access to f, check if it is in the orbit of an ROF. If yes, output an ROF C and an A∈ GL (n, F) such that f= C (Ax).• Polynomial equivalence for orbits of ROFs: Given black-box access to f and g in the orbits of two",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:hFOr9nPyWt4C,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",18,"We prove super-polynomial lower bounds for low-depth arithmetic circuits using the shifted partials measure [Gupta-Kamath-Kayal-Saptharishi, CCC 2013], [Kayal, ECCC 2012] and the affine projections of partials measure [Garg-Kayal-Saha, FOCS 2020], [Kayal-Nair-Saha, STACS 2016]. The recent breakthrough work of Limaye, Srinivasan and Tavenas [FOCS 2021] proved these lower bounds by proving lower bounds for low-depth set-multilinear circuits. An interesting aspect of our proof is that it does not require conversion of a circuit to a set-multilinear circuit, nor does it involve a random restriction. We are able to upper bound the measures for homogeneous formulas directly, without going via set-multilinearity. Our lower bounds hold for the iterated matrix multiplication as well as the Nisan-Wigderson design polynomials. We also define a subclass of homogeneous formulas which we call unique parse tree (UPT) formulas, and prove superpolynomial lower bounds for these. This generalizes the superpolynomial lower bounds for regular formulas in [Kayal-Saha-Saptharishi, STOC 2014], [Fournier-Limaye-Malod-Srinivasan, STOC 2014].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&cstart=20&pagesize=80&citation_for_view=xJrC-GMAAAAJ:-f6ydRqryjwC,https://drona.csa.iisc.ac.in/~chandan/
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR aims to address software fragmentation, improve compilation for heterogeneous hardware, significantly reduce the cost of building domain specific compilers, and aid in connecting existing compilers together. MLIR facilitates the design and implementation of code generators, translators and optimizers at different levels of abstraction and also across application domains, hardware targets and execution environments. The contribution of this work includes (1) discussion of MLIR as a research artifact, built for extension and evolution, and identifying the challenges and opportunities posed by this novel design point in design, semantics, optimization specification, system, and engineering. (2) evaluation of MLIR as a generalized infrastructure that reduces the cost of building compilers-describing diverse use-cases to show research and educational opportunities for future programming languages, compilers, execution environments, and computer architecture. The paper also presents the rationale for MLIR, its original design principles, structures and semantics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&citation_for_view=cwo0elIAAAAJ:zA6iFVUQeVQC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR addresses software fragmentation, compilation for heterogeneous hardware, significantly reducing the cost of building domain specific compilers, and connecting existing compilers together. MLIR facilitates the design and implementation of code generators, translators and optimizers at different levels of abstraction and across application domains, hardware targets and execution environments. The contribution of this work includes (1) discussion of MLIR as a research artifact, built for extension and evolution, while identifying the challenges and opportunities posed by this novel design, semantics, optimization specification, system, and engineering. (2) evaluation of MLIR as a generalized infrastructure that reduces the cost of building compilers-describing diverse use-cases to show research and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&citation_for_view=cwo0elIAAAAJ:pyW8ca7W8N0C,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"Effective models for fusion of loop nests continue to remain a challenge in both general-purpose and domain-specific language (DSL) compilers. The difficulty often arises from the combinatorial explosion of grouping choices and their interaction with parallelism and locality. This paper presents a new fusion algorithm for high-performance domain-specific compilers for image processing pipelines. The fusion algorithm is driven by dynamic programming and explores spaces of fusion possibilities not covered by previous approaches, and is driven by a cost function more concrete and precise in capturing optimization criteria than prior approaches. The fusion model is particularly tailored to the transformation and optimization sequence applied by PolyMage and Halide, two recent DSLs for image processing pipelines. Our model-driven technique when implemented in PolyMage provides significant improvements (up …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:J_g5lzvAfSwC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"This article is primarily meant to present an early case study on using MLIR, a new compiler intermediate representation infrastructure, for high-performance code generation. Aspects of MLIR covered in particular include memrefs, the affine dialect, and polyhedral utilities and pass infrastructure surrounding those. This article is also aimed at showing the role compiler infrastructure could play in generating code that is competitive with highly tuned manually developed libraries, albeit in a more modular, reusable, and automatable way.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:fPk4N6BV_jEC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"State-of-the-art algorithms used in automatic polyhedral transformation for parallelization and locality optimization typically rely on Integer Linear Programming (ILP). This poses a scalability issue when scaling to tens or hundreds of statements, and may be disconcerting in production compiler settings. In this work, we consider relaxing integrality in the ILP formulation of the Pluto algorithm, a popular algorithm used to find good affine transformations. We show that the rational solutions obtained from the relaxed LP formulation can easily be scaled to valid integral ones to obtain desired solutions, although with some caveats. We first present formal results connecting the solution of the relaxed LP to the original Pluto ILP. We then show that there are difficulties in realizing the above theoretical results in practice, and propose an alternate approach to overcome those while still leveraging linear programming. Our new …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:35N4QoGY0k4C,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"Though CNNs are highly parallel workloads, in the absence of efficient on-chip memory reuse techniques, an accelerator for them quickly becomes memory bound. In this paper, we propose a CNN accelerator design for inference that is able to exploit all forms of reuse available to minimize off-chip memory access while increasing utilization of available resources. The proposed design is composed of cores, each of which contains a one-dimensional array of processing elements. These cores can exploit different types of reuse available in CNN layers of varying shapes without requiring any reconfiguration; in particular, our design minimizes underutilization due to problem sizes that are not perfect multiples of the underlying hardware array dimensions. A major obstacle in the adoption of FPGAs as a platform for CNN inference is the difficulty to program these devices using hardware description languages. Our end goal is to also address this, and we develop preliminary software support via a codesign in order to leverage the accelerator through TensorFlow, a dominant high-level programming model. Our framework takes care of tiling and scheduling of neural network layers and generates necessary low-level commands to execute the CNN. Experimental evaluation on a real system with a PCI-express based Xilinx VC709 board demonstrates the effectiveness of our approach. As a result of an effective interconnection, the design maintains a high frequency when we scale the number of PEs. The sustained performance overall is a good fraction of the accelerator's theoretical peak performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:3s1wT3WcHBgC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"The state-of-the-art in high-performance deep learning today is primarily driven by manually developed libraries optimized and highly tuned by expert programmers using low-level abstractions with significant effort. This effort is often repeated for similar hardware and future ones. In this work, we pursue and evaluate the more modular and reusable approach of using compiler IR infrastructure to generate libraries by encoding all the required optimizations as a sequence of transformations and customized passes on an IR. We believe that until the recent introduction of MLIR (Multi-level intermediate representation), it had been hard to represent and transform computation at various levels of abstraction within a single IR.
Using the MLIR infrastructure, we build a transformation and lowering pipeline to automatically generate near-peak performance code for matrix-matrix multiplication (matmul) as well as matmul fused …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:bFI3QPDXJZMC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"Polyhedral auto-transformation frameworks are known to find efficient loop transformations that maximize locality and parallelism and minimize synchronization. While complex loop transformations are routinely modeled in these frameworks, they tend to rely on ad hoc heuristics for loop fusion. Although there exist multiple loop fusion models with cost functions to maximize locality and parallelism, these models involve separate optimization steps rather than seamlessly integrating with other loop transformations like loop permutation, scaling, and shifting. Incorporating parallelism-preserving loop fusion heuristics into existing affine transformation frameworks like Pluto, LLVM-Polly, PPCG, and PoCC requires solving a large number of Integer Linear Programming formulations, which increase auto-transformation times significantly.
In this work, we incorporate polynomial time loop fusion heuristics into the Pluto-lp-dfp …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:4OULZ7Gr8RgC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"The emergence of machine learning, image and audio processing on edge devices has motivated research towards power efficient custom hardware accelerators. Though FPGAs are an ideal target for energy efficient custom accelerators, the difficulty of hardware design and the lack of vendor agnostic, standardized hardware compilation infrastructure has hindered their adoption. This paper introduces HIR, an MLIR-based intermediate representation (IR) to describe hardware accelerator designs. HIR combines high level language features, such as loops and multi-dimensional tensors, with programmer defined explicit scheduling, to provide a high-level IR suitable for DSL compiler pipelines without compromising control over the micro-architecture of the accelerator. HIR's explicit schedules allow it to express fine-grained, synchronization-free parallelism and optimizations such as retiming and pipelining. Built as a dialect in MLIR, it draws from best IR practices learnt from communities like those of LLVM. While offering rich optimization opportunities and a high level abstraction, HIR enables sharing of optimizations, utilities and passes with software compiler infrastructure. Our implementation shows that the code generation time of the HIR code generator is on average 1112x lower than that of Xilinx Vivado HLS on a range of kernels without a compromise on the quality of the generated hardware. We believe that these are significant steps forward in the design of IRs for hardware synthesis and in equipping domain-specific languages with a productive and performing compilation path to custom hardware acceleration.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:yD5IFk8b50cC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"Unlike CPUs and GPUs, it is possible to use custom fixed-point data types, specified as a tuple (α, β), on FPGAs. The parameters α and β denote the number of integral and fractional bitwidths respectively. The power and area savings while performing arithmetic operations on fixed-point data types are well known to be significant over using floating-point data types.
In this paper, we propose a hybrid approach involving interval analysis and SMT solvers, for estimating integral bitwidths at different compute stages, in an image processing pipeline, specified using a domain-specific language (DSL) such as PolyMage. The DSL specification facilitates the compiler analysis to infer the underlying computational structure with ease. We also propose a simple and practical profile-driven greedy heuristic search technique for fractional bitwidth analysis. Using the Horn-Schunck Optical Flow benchmark program, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:u_35RYKgDlwC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"Loop tiling for locality is an important transformation for general-purpose and domain-specific compilation as it allows programs to exploit the benefits of deep memory hierarchies. Most code generation tools with the infrastructure to perform automatic tiling of loop nests rely on auto-tuning to find good tile sizes. Tile size selection models proposed in the literature either fall back to modeling complex non-linear optimization problems or tackle a narrow class of inputs. Hence, a fast and generic tile size selection model is desirable for it to be adopted into compiler infrastructures like those of GCC, LLVM, or MLIR.
In this paper, we propose a new, fast and lightweight tile size selection model that considers temporal and spatial reuse along dimensions of a loop nest. For an n-dimensional loop nest, we determine the tile sizes by calculating the zeros of a polynomial in a single variable of degree at most n. Our tile size …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:a0OBvERweLwC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"Effective models for fusion of loop nests continue to remain a challenge in both general-purpose and domain-specific language (DSL) compilers. The difficulty often arises from the combinatorial explosion of grouping choices and their interaction with parallelism and locality. This article presents a new fusion algorithm for high-performance domain-specific compilers for image processing pipelines. The fusion algorithm is driven by dynamic programming and explores spaces of fusion possibilities not covered by previous approaches, and it is also driven by a cost function more concrete and precise in capturing optimization criteria than prior approaches. The fusion model is particularly tailored to the transformation and optimization sequence applied by PolyMage and Halide, two recent DSLs for image processing pipelines. Our model-driven technique when implemented in PolyMage provides significant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:dfsIfKJdRG4C,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"Sparse matrix-vector multiplication (SpMV) operations are commonly used in various scientific and engineering applications. The performance of the SpMV operation often depends on exploiting regularity patterns in the matrix. Various representations and optimization techniques have been proposed to minimize the memory bandwidth bottleneck arising from the irregular memory access pattern involved. Among recent representation techniques, tensor decomposition is a popular one used for very large but sparse matrices. Post sparse-tensor decomposition, the new representation involves indirect accesses, making it more challenging to optimize for massive parallelism, such as on GPUs.
Computational neuroscience algorithms often involve sparse datasets while still performing long running computations on them. The Linear Fascicle Evaluation (LiFE) application is a popular neuroscience algorithm used for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:ZHo1McVdvXMC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"Decision tree ensembles are among the most commonly used machine learning models. These models are used in a wide range of applications and are deployed at scale. Decision tree ensemble inference is usually performed with libraries such as XGBoost, LightGBM, and Sklearn. These libraries incorporate a fixed set of optimizations for the hardware targets they support. However, maintaining these optimizations is prohibitively expensive with the evolution of hardware. Further, they do not specialize the inference code to the model being used, leaving significant performance on the table. This paper presents TREEBEARD, an optimizing compiler that progressively lowers the inference computation to optimized CPU code through multiple intermediate abstractions. By applying model-specific optimizations at the higher levels, tree walk optimizations at the middle level, and machine-specific optimizations lower …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:P5F9QuxV20EC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"Polyhedral compilers can perform complex loop optimizations that improve parallelism and cache behaviour of loops in the input program. These transformations result in significant performance gains on modern processors which have large compute power and deep memory hierarchies. The paper, ""Polyhedral Auto-transformation with No Integer Linear Programming"", identifies issues that adversely affect scalability of polyhedral transformation frameworks; in particular the Pluto algorithm. The construction and solving of a complex Integer Linear Programming (ILP) problem increases the time taken by a polyhedral compiler significantly. The paper presents two orthogonal ideas, which together overcome the scalability issues in the affine scheduling problem. It first relaxes the ILP to a Linear Programming (LP) problem, thereby solving a cheaper algorithm. To overcome the sub-optimalities that arise due to this relaxation, the affine scheduling problem is decomposed into following three components: (1) Fusion and dimension matching, (2) Loop scaling and shifting, and (3) Loop skewing. This new auto-transformation framework, pluto-lp-dfp, significantly improves the time taken by the Pluto algorithm without sacrificing performance of the generated code. This report first provides proofs for the theoretical claims made in the paper surrounding relaxed LP formulation of the Pluto algorithm. The second part of the report describes an approach to find good loop fusion (or distribution) and loop permutations that enable tileability. This short report serves as the supplementary material for the paper.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:vV6vV6tmYwMC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",33,"The power and area savings while performing arithmetic operations on fixed-point data type are well known to be significant over using floating-point data type. PolyMage-HLS stores data at each stage of a pipeline using a fixed-point data type (α, β) where α and β denote the number of integral and fractional bits. The integral bitwidth (α) requirement at a pipeline stage can be inferred from its range. In this paper, we first propose an interval-arithmetic based range analysis algorithm to estimate the number of bits required to store the integral part of the data at each stage of an image processing pipeline. The analysis algorithm uses the homogeneity of pixel signals at each stage to cluster them and perform a combined range analysis. Secondly, we propose a software architecture for easily deploying any kind of interval/affine arithmetic based range analyses in the DSL compiler. Thirdly, we show that interval/affine arithmetic based techniques fail to take into account correlated computations across stages and hence could lead to poor range estimates. These errors in range estimates accumulate across stages, especially for iterative programs, such as Horn-Schunck Optical Flow, resulting in estimates nearly unusable in practice. Then, we propose a new range analysis technique using Satisfiability Modulo Theory (SMT) solvers, and show that the range estimates obtained through it are very close to the lower bounds obtained through profile-driven analysis. Finally, for estimating fractional bitwidth (β) requirement at each stage of the pipeline, we propose a simple and practical heuristic search algorithm, which makes very few profile passes, as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&cstart=20&pagesize=80&citation_for_view=cwo0elIAAAAJ:EUQCXRtRnyEC,https://www.csa.iisc.ac.in/~udayb
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Secure Multi-party Computation (MPC) allows a set of mutually distrusting parties to jointly evaluate a function on their private inputs while maintaining input privacy. In this work, we improve semi-honest secure two-party computation (2PC) over rings, with a focus on the efficiency of the online phase.
We propose an efficient mixed-protocol framework, outperforming the state-of-the-art 2PC framework of ABY. Moreover, we extend our techniques to multiinput multiplication gates without inflating the online communication, ie, it remains independent of the fan-in. Along the way, we construct efficient protocols for several primitives such as scalar product, matrix multiplication, comparison, maxpool, and equality testing. The online communication of our scalar product is two ring elements irrespective of the vector dimension, which is a feature achieved for the first time in the 2PC literature. The practicality of our new set of protocols is showcased with four applications: i) AES S-box, ii) Circuit-based Private Set Intersection, iii) Biometric Matching, and iv) Privacypreserving Machine Learning (PPML). Most notably, for PPML, we implement and benchmark training and inference of Logistic Regression and Neural Networks over LAN and WAN networks. For training, we improve online runtime (both for LAN and WAN) over SecureML (Mohassel et al., IEEE S&P’17) in the range 1.5×–6.1×, while for inference, the improvements are in the range of 2.5×–754.3×.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&citation_for_view=RG6kKh8AAAAJ:sSrBHYA8nusC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Machine learning tools have illustrated their potential in many significant sectors such as healthcare and finance, to aide in deriving useful inferences. The sensitive and confidential nature of the data, in such sectors, raise natural concerns for the privacy of data. This motivated the area of Privacy-preserving Machine Learning (PPML) where privacy of the data is guaranteed. Typically, ML techniques require large computing power, which leads clients with limited infrastructure to rely on the method of Secure Outsourced Computation (SOC). In SOC setting, the computation is outsourced to a set of specialized and powerful cloud servers and the service is availed on a pay-per-use basis. In this work, we explore PPML techniques in the SOC setting for widely used ML algorithms-- Linear Regression, Logistic Regression, and Neural Networks. We propose BLAZE, a blazing fast PPML framework in the three server setting tolerating one malicious corruption over a ring (\Z{\ell}). BLAZE achieves the stronger security guarantee of fairness (all honest servers get the output whenever the corrupt server obtains the same). Leveraging an input-independent preprocessing phase, BLAZE has a fast input-dependent online phase relying on efficient PPML primitives such as: (i) A dot product protocol for which the communication in the online phase is independent of the vector size, the first of its kind in the three server setting; (ii) A method for truncation that shuns evaluating expensive circuit for Ripple Carry Adders (RCA) and achieves a constant round complexity. This improves over the truncation method of ABY3 (Mohassel et al., CCS 2018) that uses RCA and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&citation_for_view=RG6kKh8AAAAJ:l7t_Zn2s7bgC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Privacy-preserving machine learning (PPML) via Secure Multi-party Computation (MPC) has gained momentum in the recent past. Assuming a minimal network of pair-wise private channels, we propose an efficient four-party PPML framework over rings $\Z {\ell} $, FLASH, the first of its kind in the regime of PPML framework, that achieves the strongest security notion of Guaranteed Output Delivery (all parties obtain the output irrespective of adversary's behaviour). The state of the art ML frameworks such as ABY3 by {\em Mohassel et. al}(ACM CCS'18) and SecureNN by {\em Wagh et. al}(PETS'19) operate in the setting of parties with one malicious corruption but achieve the {\em weaker} security guarantee of {\em abort}. We demonstrate PPML with real-time efficiency, using the following custom-made tools that overcome the limitations of the aforementioned state-of-the-art--(a){\em dot product}, which is independent of the vector size unlike the state-of-the-art ABY3, SecureNN and ASTRA by {\em Chaudhari et. al}(ACM CCSW'19), all of which have linear dependence on the vector size.(b){\em Truncation}, which is constant round and free of circuits like Ripple Carry Adder (RCA), unlike ABY3 which uses these circuits and has round complexity of the order of depth of these circuits. We then exhibit the application of our FLASH framework in the secure server-aided prediction of vital algorithms--Linear Regression, Logistic Regression, Deep Neural Networks, and Binarized Neural Networks. We substantiate our theoretical claims through improvement in benchmarks of the aforementioned algorithms when compared with the current best framework ABY3 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&citation_for_view=RG6kKh8AAAAJ:K3LRdlH-MEoC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"The concrete efficiency of secure computation has been the focus of many recent works. In this work, we present concretely-efficient protocols for secure 3-party computation (3PC) over a ring of integers modulo 2ℓ tolerating one corruption, both with semi-honest and malicious security. Owing to the fact that computation over ring emulates computation over the real-world system architectures, secure computation over ring has gained momentum of late.
Cast in the offline-online paradigm, our constructions present the most efficient online phase in concrete terms. In the semi-honest setting, our protocol requires communication of 2 ring elements per multiplication gate during the online phase. In the malicious setting, our protocol requires communication of 4 elements per multiplication gate during the online phase, beating the state-of-the-art protocol by 5 elements. Realized with both the security notions of selective …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&citation_for_view=RG6kKh8AAAAJ:XiSMed-E-HIC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Performing machine learning (ML) computation on private data while maintaining data privacy, aka Privacy-preserving Machine Learning (PPML), is an emergent field of research. Recently, PPML has seen a visible shift towards the adoption of the Secure Outsourced Computation (SOC) paradigm due to the heavy computation that it entails. In the SOC paradigm, computation is outsourced to a set of powerful and specially equipped servers that provide service on a pay-per-use basis. In this work, we propose SWIFT, a robust PPML framework for a range of ML algorithms in SOC setting, that guarantees output delivery to the users irrespective of any adversarial behaviour. Robustness, a highly desirable feature, evokes user participation without the fear of denial of service. At the heart of our framework lies a highly-efficient, maliciously-secure, three-party computation (3PC) over rings that provides guaranteed output delivery (GOD) in the honestmajority setting. To the best of our knowledge, SWIFT is the first robust and efficient PPML framework in the 3PC setting. SWIFT is as fast as (and is strictly better in some cases than) the best-known 3PC framework BLAZE (Patra et al. NDSS’20), which only achieves fairness. We extend our 3PC framework for four parties (4PC). In this regime, SWIFT is as fast as the best known fair 4PC framework Trident (Chaudhari et al. NDSS’20) and twice faster than the best-known robust 4PC framework FLASH (Byali et al. PETS’20). We demonstrate our framework’s practical relevance by benchmarking popular ML algorithms such as Logistic Regression and deep Neural Networks such as VGG16 and LeNet, both over …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&citation_for_view=RG6kKh8AAAAJ:vRqMK49ujn8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"We settle the exact round complexity of three-party computation (3PC) in honest-majority setting, for a range of security notions such as selective abort, unanimous abort, fairness and guaranteed output delivery. Selective abort security, the weakest in the lot, allows the corrupt parties to selectively deprive some of the honest parties of the output. In the mildly stronger version of unanimous abort, either all or none of the honest parties receive the output. Fairness implies that the corrupted parties receive their output only if all honest parties receive output and lastly, the strongest notion of guaranteed output delivery implies that the corrupted parties cannot prevent honest parties from receiving their output. It is a folklore that the implication holds from the guaranteed output delivery to fairness to unanimous abort to selective abort. We focus on two network settings– pairwise-private channels without and with a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&citation_for_view=RG6kKh8AAAAJ:_Re3VWB3Y0AC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Secure Multi-Party Computation (MPC) with small number of parties is an interesting area of research, primarily due to its ability to model most real-life MPC applications and the simplicity and efficiency of the resulting protocols. In this work, we present efficient, constant-round 3-party (3PC) and 4-party (4PC) protocols in the honest-majority setting that achieve strong security notions of fairness (corrupted parties receive their output only if all honest parties receive output) and guaranteed output delivery (corrupted parties cannot prevent honest parties from receiving their output). Being constant-round, our constructions are suitable for Internet-like high-latency networks and are built from garbled circuits (GC). Assuming the minimal model of pairwise-private channels, we present two protocols that involve computation and communication of a single GC-- (a) a 4-round 3PC with fairness, (b) a 5-round 4PC with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:OU6Ihb5iCvQC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Mixing arithmetic and boolean circuits to perform privacy-preserving machine learning has become increasingly popular. Towards this, we propose a framework for the case of four parties with at most one active corruption called Tetrad. Tetrad works over rings and supports two levels of security, fairness and robustness. The fair multiplication protocol costs 5 ring elements, improving over the state-of-the-art Trident (Chaudhari et al. NDSS'20). A key feature of Tetrad is that robustness comes for free over fair protocols. Other highlights across the two variants include (a) probabilistic truncation without overhead, (b) multi-input multiplication protocols, and (c) conversion protocols to switch between the computational domains, along with a tailor-made garbled circuit approach. Benchmarking of Tetrad for both training and inference is conducted over deep neural networks such as LeNet and VGG16. We found that Tetrad is up to 4 times faster in ML training and up to 5 times faster in ML inference. Tetrad is also lightweight in terms of deployment cost, costing up to 6 times less than Trident.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:LPZeul_q3PIC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Oblivious Transfer (OT) is one of the most fundamental cryptographic primitives with wide-spread application in general secure multi-party computation (MPC) as well as in a number of tailored and special-purpose problems of interest such as private set intersection (PSI), private information retrieval (PIR), contract signing to name a few. Often the instantiations of OT require prohibitive communication and computation complexity. OT extension protocols are introduced to compute a very large number of OTs referred to as extended OTs at the cost of a small number of OTs referred to as seed OTs. We present a fast OT extension protocol for small secrets in the active setting. Our protocol when used to produce 1-out-of-n OTs outperforms all the known actively secure OT extensions. Our protocol is built on the semi-honest secure extension protocol of Kolesnikov and Kumaresan of CRYPTO'13 (referred to as KK13 protocol henceforth) which is the best known OT extension for short secrets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:zA6iFVUQeVQC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Zero-knowledge (ZK) protocols are undoubtedly among the central primitives in cryptography, lending their power to numerous applications such as secure computation, voting, auctions, and anonymous credentials to name a few. The study of efficient ZK protocols for non-algebraic statements has seen rapid progress in recent times, relying on secure computation techniques. The primary contribution of this work lies in constructing efficient UC-secure constant round ZK protocols from garbled circuits that are secure against adaptive corruptions, with communication linear in the size of the statement. We begin by showing that the practically efficient ZK protocol of Jawurek et al. (CCS 2013) is adaptively secure when the underlying oblivious transfer (OT) satisfies a mild adaptive security guarantee. We gain adaptive security with little to no overhead over the static case. A conditional verification technique is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:NhqRSupF_l8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Perfectly-secure verifiable secret sharing (VSS) and multi-party computation (MPC) protocols in asynchronous network tolerate only at most one-fourth of corruption, while their counterparts in synchronous network sustain against at most one-third corruption. Moreover property-wise, synchronous protocols provide much stronger guarantees than the asynchronous counterparts. Taking note of the fact that asynchronous network is more realistic on one hand and on the other, synchrony of a network has positive impact on several aspects of distributed protocols including properties and fault-tolerance, we explore the power of hybrid networks that combines best of both the worlds by supporting a few synchronous rounds at the onset of a protocol execution, before turning to asynchronous mode. In hybrid networks, we investigate various feasibility questions pertaining to protocols giving guarantees attainable in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:nb7KW1ujOQ8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Verifiable Secret-Sharing (VSS) is a fundamental primitive in secure distributed computing. It is used as a building block in several distributed computing tasks, such as Byzantine agreement and secure multi-party computation. In this article, we consider VSS schemes with perfect security, tolerating computationally unbounded adversaries. We comprehensively survey the existing perfectly secure VSS schemes in three different communication settings, namely, synchronous, asynchronous, and hybrid setting and provide full details of the existing schemes in these settings. The aim of this survey is to provide a clear knowledge and foundation to researchers who are interested in knowing and extending the state-of-the-art perfectly secure VSS schemes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:5Ul4iDaHHb8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"The problems of Byzantine Broadcast (BB) and Byzantine Agreement (BA) are of interest to both the distributed computing and cryptography communities. Extension protocols for these primitives have been introduced to handle long messages efficiently at the cost of small number of single-bit broadcasts, referred to as seed broadcasts. While the communication optimality has remained the most sought-after property of an extension protocol in the literature, we prioritize both communication and round optimality in this work. In a setting with n parties and a static adversary controlling at most t parties in Byzantine fashion, we present BB and BA extension protocols with $$t<n$$ t < n , $$t < n/2$$ t < n / 2 and $$t<n/3$$ t < …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:cFHS6HbyZ2cC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Secure Multi-party Computation (MPC) with small population and honest majority has drawn focus specifically due to customization in techniques and resulting efficiency that the constructions can offer. In this work, we investigate a wide range of security notions in the five-party setting, tolerating two active corruptions. Being constant-round, our protocols are best suited for real-time, high latency networks such as the Internet. In a minimal setting of pairwise-private channels, we present efficient instantiations with unanimous abort (where either all honest parties obtain the output or none of them do) and fairness (where the adversary obtains its output only if all honest parties also receive it). With the presence of an additional broadcast channel (known to be necessary), we present a construction with guaranteed output delivery (where any adversarial behaviour cannot prevent the honest parties from receiving the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:Tiz5es2fbqcC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"In STOC 1988, Ben-Or, Goldwasser, and Wigderson (BGW) established an important milestone in the fields of cryptography and distributed computing by showing that every functionality can be computed with perfect (information-theoretic and error-free) security at the presence of an active (aka Byzantine) rushing adversary that controls up to n/3 of the parties. We study the round complexity of general secure multiparty computation in the BGW model. Our main result shows that every functionality can be realized in only four rounds of interaction, and that some functionalities cannot be computed in three rounds. This completely settles the round-complexity of perfect actively-secure optimally-resilient MPC, resolving a long line of research. Our lower-bound is based on a novel round-reduction technique that allows us to lift existing three-round lower-bounds for verifiable secret sharing to four-round lower-bounds for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:08ZZubdj9fEC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"The problem of Byzantine Agreement (BA) is of interest to both the distributed computing and cryptography communities. Following well-known results from distributed computing literature, the BA problem in the asynchronous network setting encounters inevitable non-termination issues. The impasse is overcome via randomization that allows construction of BA protocols in two flavors of termination guarantee—with overwhelming probability and with probability one. The latter type, termed as almost-surely terminating BA, is the main focus of this article. An eluding problem in the domain of almost-surely terminating BA is achieving a constant expected running time. Our primary contribution in this work makes significant progress in this direction.
In a setting with n parties and an adversary with unbounded computing power controlling at most t parties in a Byzantine fashion, we present two almost-surely terminating …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:tOudhMTPpwUC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Two of the most sought-after properties of Multi-party Computation (MPC) protocols are fairness and guaranteed output delivery (GOD), the latter also referred to as robustness. Achieving both, however, brings in the necessary requirement of malicious-minority. In a generalised adversarial setting where the adversary is allowed to corrupt both actively and passively, the necessary bound for a n-party fair or robust protocol turns out to be , where denote the threshold for active and passive corruption with the latter subsuming the former. Subsuming the malicious-minority as a boundary special case, this setting, denoted as dynamic corruption, opens up a range of possible corruption scenarios for the adversary. While dynamic corruption includes the entire range of thresholds for starting from to , the boundary corruption restricts the adversary only to the boundary cases of  …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:WbkHhVStYXYC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"The problem of Byzantine Agreement (BA) is of interest to both distributed computing and cryptography community. Following well-known results from the distributed computing literature, BA problem in the asynchronous network setting encounters inevitable non-termination issues. The impasse is overcome via randomization that allows construction of BA protocols in two flavours of termination guarantee - with overwhelming probability and with probability one. The latter type termed as almost-surely terminating BAs are the focus of this paper. An eluding problem in the domain of almost-surely terminating BAs is achieving a constant expected running time. Our work makes progress in this direction.
In a setting with n parties and an adversary with unbounded computing power controlling at most t parties in Byzantine fashion, we present two asynchronous almost-surely terminating BA protocols:
With the optimal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:KxtntwgDAa4C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Secure Multi-party Computation (MPC) allows to securely compute on private data. To make MPC practical, logic synthesis can be used to automatically translate a description of the function to be computed securely into optimized and error-free boolean circuits. The work of Demmler et al. (CCS'15) used industry-grade hardware synthesis tools (DC, Yosys) to generate depth-optimized circuits for MPC. To evaluate their optimized circuits, they used the ABY framework (Demmler et al., NDSS'15) for secure two-party computation. The recent ABY2.0 framework (Patra et al., USENIX Security'21) presented round-efficient constructions using multi-input AND gates and improved over ABY by at least 6× in online communication. In this work, we propose SynCirc, an efficient hardware synthesis framework designed for MPC applications. Our framework is based on Verilog and the open-source tool Yosys-ABC. It provides …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:D_sINldO8mEC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"We introduce the problem of Verifiable Relation Sharing (VRS) where a client (prover) wishes to share a vector of secret data items among k servers (the verifiers) while proving in zero-knowledge that the shared data satisfies some properties. This combined task of sharing and proving generalizes notions like verifiable secret sharing and zero-knowledge proofs over secret-shared data. We study VRS from a theoretical perspective and focus on its round complexity.
As our main contribution, we show that every efficiently-computable relation can be realized by a VRS with an optimal round complexity of two rounds where the first round is input-independent (offline round). The protocol achieves full UC-security against an active adversary that is allowed to corrupt any t-subset of the parties that may include the client together with some of the verifiers. For a small (logarithmic) number of parties, we achieve an optimal resiliency …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:HE397vMXCloC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"We give constructions of three-round secure multiparty computation (MPC) protocols for general functions that make black-box use of a two-round oblivious transfer (OT). For the case of semi-honest adversaries, we make use of a two-round, semi-honest secure OT in the plain model. This resolves the round-complexity of black-box (semi-honest) MPC protocols from minimal assumptions and answers an open question of Applebaum et al. (ITCS 2020). For the case of malicious adversaries, we make use of a two-round maliciously-secure OT in the common random/reference string model that satisfies a (mild) variant of adaptive security for the receiver.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:VOx2b1Wkg3QC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"We study information-theoretic secure multiparty protocols that achieve full security, including guaranteed output delivery, at the presence of an active adversary that corrupts a constant fraction of the parties. It is known that 2 rounds are insufficient for such protocols even when the adversary corrupts only two parties (Gennaro, Ishai, Kushilevitz, and Rabin; Crypto 2002), and that perfect protocols can be implemented in 3 rounds as long as the adversary corrupts less than a quarter of the parties (Applebaum, Brakerski, and Tsabary; Eurocrypt, 2019). Furthermore, it was recently shown that the quarter threshold is tight for any 3-round perfectly-secure protocol (Applebaum, Kachlon, and Patra; FOCS 2020). Nevertheless, one may still hope to achieve a better-than-quarter threshold at the expense of allowing some negligible correctness errors and/or statistical deviations in the security.
Our main results …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:geHnlv5EZngC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"The growing volumes of data being collected and its analysis to provide better services are creating worries about digital privacy. To address privacy concerns and give practical solutions, the literature has relied on secure multiparty computation. However, recent research has mostly focused on the small-party honest-majority setting of up to four parties, noting efficiency concerns. In this work, we extend the strategies to support a larger number of participants in an honest-majority setting with efficiency at the center stage. Cast in the preprocessing paradigm, our semi-honest protocol improves the online complexity of the decade-old state-of-the-art protocol of Damg\aa rd and Nielson (CRYPTO'07). In addition to having an improved online communication cost, we can shut down almost half of the parties in the online phase, thereby saving up to 50% in the system's operational costs. Our maliciously secure protocol also enjoys similar benefits and requires only half of the parties, except for one-time verification, towards the end. To showcase the practicality of the designed protocols, we benchmark popular applications such as deep neural networks, graph neural networks, genome sequence matching, and biometric matching using prototype implementations. Our improved protocols aid in bringing up to 60-80% savings in monetary cost over prior work.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:AXPGKjj_ei8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"This book focuses on multi-party computation (MPC) protocols in the passive corruption model (also known as the semi-honest or honest-but-curious model). The authors present seminal possibility and feasibility results in this model and includes formal security proofs. Even though the passive corruption model may seem very weak, achieving security against such a benign form of adversary turns out to be non-trivial and demands sophisticated and highly advanced techniques. MPC is a fundamental concept, both in cryptography as well as distributed computing. On a very high level, an MPC protocol allows a set of mutually-distrusting parties with their private inputs to jointly and securely perform any computation on their inputs. Examples of such computation include, but not limited to, privacy-preserving data mining; secure e-auction; private set-intersection; and privacy-preserving machine learning. MPC protocols emulate the role of an imaginary, centralized trusted third party (TTP) that collects the inputs of the parties, performs the desired computation, and publishes the result. Due to its powerful abstraction, the MPC problem has been widely studied over the last four decades.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:Fu2w8maKXqMC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Traditional zero-knowledge protocols have been studied and optimized for the setting where a single prover holds the complete witness and tries to convince a verifier about a predicate on the witness, without revealing any additional information to the verifier. In this work, we study the notion of distributed-prover zero knowledge (DPZK) for arbitrary predicates where the witness is shared among multiple mutually distrusting provers and they want to convince a verifier that their shares together satisfy the predicate. We make the following contributions to the notion of distributed proof generation:(i) we propose a new MPC-style security definition to capture the adversarial settings possible for different collusion models between the provers and the verifier,(ii) we discuss new efficiency parameters for distributed proof generation such as the number of rounds of interaction and the amount of communication among the provers, and (iii) we propose a compiler that realizes distributed proof generation from the zero-knowledge protocols in the Interactive Oracle Proofs (IOP) paradigm. Our compiler can be used to obtain DPZK from arbitrary IOP protocols, but the concrete efficiency overheads are substantial in general. To this end, we contribute (iv) a new zero-knowledge IOP which can be compiled into an efficient DPZK protocol. The -DPZK protocol , with provers and one verifier, admits proof size with a communication complexity of , where is the number of gates in the arithmetic circuit representing the predicate and is the number of wires that depends on inputs from two or more parties. Significantly …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:1qzjygNMrQYC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Fault-tolerant distributed consensus is a fundamental problem in secure distributed computing. In this work, we consider the problem of distributed consensus in directed graphs tolerating crash failures. Tseng and Vaidya (PODC’15) presented necessary and sufficient condition for the existence of consensus protocols in directed graphs. We improve the round and communication complexity of their protocol. Moreover, we prove that our protocol requires the optimal number of communication rounds, required by any protocol belonging to a restricted class of crash-tolerant consensus protocols in directed graphs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:dshw04ExmUIC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Broadcast is an essential primitive for secure computation. We focus in this paper on optimal resilience (i.e., when the number of corrupted parties t is less than a third of the computing parties n), and with no setup or cryptographic assumptions.
While broadcast with worst case t rounds is impossible, it has been shown [Feldman and Micali STOC’88, Katz and Koo CRYPTO’06] how to construct protocols with expected constant number of rounds in the private channel model. However, those constructions have large communication complexity, specifically expected number of bits transmitted for broadcasting a message of length L. This leads to a significant communication blowup in secure computation protocols in this setting.
In this paper, we substantially improve the communication complexity of broadcast in constant expected time. Specifically, the expected communication complexity of our protocol is . For …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:ye4kPcJQO24C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"We study the round complexity of secure multiparty computation (MPC) in the challenging model where full security, including guaranteed output delivery, should be achieved at the presence of an active rushing adversary who corrupts up to half of parties. It is known that 2 rounds are insufficient in this model (Gennaro et al. Crypto 2002), and that 3 round protocols can achieve computational security under public-key assumptions (Gordon et al. Crypto 2015; Ananth et al. Crypto 2018; and Badrinarayanan et al. Asiacrypt 2020). However, despite much effort, it is unknown whether public-key assumptions are inherently needed for such protocols, and whether one can achieve similar results with security against computationally-unbounded adversaries.
In this paper, we use Minicrypt-type assumptions to realize 3-round MPC with full and active security. Our protocols come in two flavors: for a small (logarithmic) number of parties n …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:8AbLer7MMksC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",25,"Consider the problem of securely identifying τ-heavy hitters, where given a set of client inputs, the goal is to identify those inputs which are held by at least τ clients in a privacy-preserving manner. Towards this, we design a novel system Vogue, whose key highlight in comparison to prior works, is that it ensures complete privacy and does not leak any information other than the heavy hitters. In doing so, Vogue aims to achieve as efficient a solution as possible. To showcase these efficiency improvements, we benchmark our solution and observe that it requires around 14 minutes to compute the heavy hitters for τ= 900 on 256-bit inputs when considering 400K clients. This is in contrast to the state of the art solution that requires over an hour for the same. In addition to the static input setting described above, Vogue also accounts for streaming inputs and provides a protocol that outperforms the state-of-the-art therein. The efficiency improvements witnessed while computing heavy hitters in both, the static and streaming input settings, are attributed to our new secure stable compaction protocol, whose round complexity is independent of the size of the input array to be compacted",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&citation_for_view=RG6kKh8AAAAJ:tKAzc9rXhukC,https://www.csa.iisc.ac.in/~arpita/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Recent studies on commercial hardware demonstrated that irregular GPU applications can bottleneck on virtual-to-physical address translations. In this work, we explore ways to reduce address translation overheads for such applications. We discover that the order of servicing GPU's address translation requests (specifically, page table walks) plays a key role in determining the amount of translation overhead experienced by an application. We find that different SIMD instructions executed by an application require vastly different amounts of work to service their address translation needs, primarily depending upon the number of distinct pages they access. We show that better forward progress is achieved by prioritizing translation requests from the instructions that require less work to service their address translation needs. Further, in the GPU's Single-Instruction-Multiple-Thread (SIMT) execution paradigm, all …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&citation_for_view=pL5B4ywAAAAJ:QIV2ME_5wuYC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"The described embodiments include a computing device with two or more translation lookaside buffers (TLB). During operation, the computing device updates an entry in the TLB based on a virtual address to physical address translation and metadata from a page table entry that were acquired during a page table walk. The computing device then computes, based on a lease length expression, a lease length for the entry in the TLB. Next, the computing device sets, for the entry in the TLB, a lease value to the lease length, wherein the lease value represents a time until a lease for the entry in the TLB expires, wherein the entry in the TLB is invalid when the associated lease has expired. The computing device then uses the lease value to control operations that are allowed to be performed using information from the entry in the TLB.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&citation_for_view=pL5B4ywAAAAJ:k_IJM867U9cC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"In FaaS workflows, a set of functions implement application logic by interacting and exchanging data among themselves. Contemporary FaaS platforms execute each function of a workflow in separate containers. When functions in a workflow interact, the resulting latency slows execution. Faastlane minimizes function interaction latency by striving to execute functions of a workflow as threads within a single process of a container instance, which eases data sharing via simple load/store instructions. For FaaS workflows that operate on sensitive data, Faastlane provides lightweight thread-level isolation domains using Intel Memory Protection Keys (MPK). While threads ease sharing, implementations of languages such as Python and Node. js (widely used in FaaS applications) disallow concurrent execution of threads. Faastlane dynamically identifies opportunities for parallelism in FaaS workflows and fork processes (instead of threads) or spawns new container instances to concurrently execute parallel functions of a workflow. We implemented Faastlane atop Apache OpenWhisk and show that it accelerates workflow instances by up to 15×, and reduces function interaction latency by up to 99.95% compared to OpenWhisk.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&citation_for_view=pL5B4ywAAAAJ:lSLTfruPkqcC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"A method and processing apparatus for accelerating program processing is provided that includes a plurality of processors configured to process a plurality of tasks of a program and a controller. The controller is configured to determine, from the plurality of tasks being processed by the plurality of processors, a task being processed on a first processor to be a lagging task causing a delay in execution of one or more other tasks of the plurality of tasks. The controller is further configured to provide the determined lagging task to a second processor to be executed by the second processor to accelerate execution of the lagging task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&citation_for_view=pL5B4ywAAAAJ:qxL8FJ1GzNcC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"GPUs are becoming first-class compute citizens and increasingly support programmability-enhancing features such as shared virtual memory and hardware cache coherence. This enables them to run a wider variety of programs. However, a key aspect of general-purpose programming where GPUs still have room for improvement is the ability to invoke system calls. We explore how to directly invoke system calls from GPUs. We examine how system calls can be integrated with GPGPU programming models, where thousands of threads are organized in a hierarchy of execution groups. To answer questions on GPU system call usage and efficiency, we implement Genesys, a generic GPU system call interface for Linux. Numerous architectural and OS issues are considered and subtle changes to Linux are necessary, as the existing kernel assumes that only CPUs invoke system calls. We assess the performance of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&citation_for_view=pL5B4ywAAAAJ:e5wmG9Sq2KIC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Recent studies on commercial hardware demonstrated that irregular GPU workloads could bottleneck on virtual-to-physical address translations. GPU's single-instruction multiple-thread (SIMT) execution can generate many concurrent memory accesses, all of which require address translation before accesses can complete. Unfortunately, many of these address translation requests often miss in the TLB, generating many concurrent page table walks. In this work, we investigate how to reduce address translation overheads for such applications. We observe that many of these concurrent page walk requests, while irregular from the perspective of a single GPU wavefront, still fall on neighboring virtual page addresses. The address mappings for these neighboring pages are typically stored in the same 64-byte cache line. Since cache lines are the smallest granularity of memory access, the page table walker implicitly …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&citation_for_view=pL5B4ywAAAAJ:-f6ydRqryjwC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"GPUs are becoming first-class compute citizens and increasingly support programmability-enhancing features such as shared virtual memory and hardware cache coherence. This enables them to run a wider variety of programs. However, a key aspect of general-purpose programming where GPUs still have room for improvement is the ability to invoke system calls. We explore how to directly invoke system calls from GPUs. We examine how system calls can be integrated with GPGPU programming models, where thousands of threads are organized in a hierarchy of execution groups. To answer questions on GPU system call usage and efficiency, we implement Genesys, a generic GPU system call interface for Linux. Numerous architectural and OS issues are considered and subtle changes to Linux are necessary, as the existing kernel assumes that only CPUs invoke system calls. We assess the performance of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&citation_for_view=pL5B4ywAAAAJ:hFOr9nPyWt4C,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:TQgYirikUcIC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"An operating system (OS) of a processing system having a plurality of processor cores determines a cost associated with different mechanisms for performing a translation lookaside buffer (TLB) shootdown in response to, for example, a virtual address being remapped to a new physical address, and selects a TLB shootdown mechanism to purge outdated or invalid address translations from the TLB based on the determined cost. In some embodiments, the OS selects an inter-processor interrupt (IPI) as the TLB shootdown mechanism if the cost associated with sending an IPI is less than a threshold cost. In some embodiments, the OS compares the cost of using an IPI as the TLB shootdown mechanism versus the cost of sending a hardware broadcast to all processor cores of the processing system as the shootdown mechanism and selects the shootdown mechanism having the lower cost.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:JV2RwH3_ST0C,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Memory is becoming increasingly heterogeneous with the emergence of disparate memory technologies ranging from non-volatile memories like PCM, STT-RAM, and memristors to 3D-stacked memories like HBM. In such systems, data is of ten migrated across memory regions backed by different technologies for better overall performance. An effective migration mechanism is a prerequisite in such systems.
Prior works on OS-directed page migration have focused on what data to migrate and/or on when to migrate. In this work, we demonstrate the need to investigate another dimension -- how much to migrate. Specifically, we show that the amount of data migrated in a single migration operation (called ""migration granularity"") is vital to the overall performance. Through analysis on real hardware, we further show that different applications benefit from different migration granularities, owing to their distinct memory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:L8Ckcad2t8MC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,A processing apparatus is provided that includes NVRAM and one or more processors configured to process a first set and a second set of instructions according to a hierarchical processing scope and process a scoped persistence barrier residing in the program after the first instruction set and before the second instruction set. The barrier includes an instruction to cause first data to persist in the NVRAM before second data persists in the NVRAM. The first data results from execution of each of the first set of instructions processed according to the one hierarchical processing scope. The second data results from execution of each of the second set of instructions processed according to the one hierarchical processing scope. The processing apparatus also includes a controller configured to cause the first data to persist in the NVRAM before the second data persists in the NVRAM based on the scoped persistence …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:maZDTaKrznsC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Increasing heterogeneity in the memory system mandates careful data placement to hide the non-uniform memory access (NUMA) effects on applications. However, NUMA optimizations have predominantly focused on application data in the past decades, largely ignoring the placement of kernel data structures due to their small memory footprint; this is evident in typical OS designs that pin kernel objects in memory. In this paper, we show that careful placement of kernel data structures is gaining importance in the context of page-tables: sub-optimal placement of page-tables causes severe slowdown (up to 3.1x) on virtualized NUMA servers.
In response, we present vMitosis -- a system for explicit management of two-level page-tables, i.e., the guest and extended page-tables, on virtualized NUMA servers. vMitosis enables faster address translation by migrating and replicating page-tables. It supports two prevalent …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:NaGl4SEjCO4C,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"GPU (Graphics Processing Unit) architecture has evolved to accelerate parts of a single application at a time. Consequently, several aspects of its architecture, particularly the virtual memory, have embraced a shared-mostly design. This implicitly assumes that a single application and, thus, one address space is resident in the GPU at a time. However, recent trends, e.g., deployment of GPUs in the cloud, necessitate efficient multi-tenancy. Multi-tenancy is needed for sharing the physical resources of a large server-class GPU across multiple concurrent tenants (applications) for resource consolidation while ensuring fairness among the tenants.We first quantify how different components of GPU's virtual memory can impede multi-tenancy. We show that shared page walkers are a key bottleneck under multi-tenancy. We, therefore, propose dynamic page walk stealing that enables soft partitioning of the shared pool of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:O3NaXMp0MMsC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Intel and AMD processors have long supported more than one large page sizes – 1GB and 2MB, to reduce address translation overheads for applications with large memory footprints. However, previous works on large pages have primarily focused on 2MB pages, partly due to a lack of evidence on the usefulness of 1GB pages to real-world applications. Consequently, micro-architectural resources devoted to 1GB pages have gone underutilized for a decade.
We quantitatively demonstrate where 1GB pages can be valuable, especially when employed in conjunction with 2MB pages. Unfortunately, the lack of application-transparent dynamic allocation of 1GB pages is to blame for the under-utilization of 1GB pages on today’s systems. Toward this, we design and implement Trident in Linux to fully harness micro-architectural resources devoted for all page sizes in the current x86 hardware by transparently allocating …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:vV6vV6tmYwMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"The last level TLB (LLT) and the last level cache (LLC) play a critical role in the overall performance of memory-intensive applications. While management of LLC content has received significant attention, the same may not be true for LLT. In this work, we first explore the well-known concept of dead blocks in caches for TLBs. We find that dead pages are fairly common in the LLT. Different from dead blocks in LLCs, dead pages in LLTs are most often dead-on-arrival, i.e., they produce zero hits in the TLB. We design a storage-efficient dead page predictor that works with a fraction of storage compared to typical dead block predictors. This is important since an LLT itself requires only a few KBs of storage compared to MBs in LLC. We then leverage the dead page information to guide a simple dead block predictor in LLC. This is driven by the observation that dead blocks are often concentrated within dead pages. In …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:ns9cj8rnVeAC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"The described embodiments include a computing device with two or more types of processors and a memory that is shared between the two or more types of processors. The computing device performs operations for handling cache coherency between the two or more types of processors. During operation, the computing device sets a cache coherency indicator in metadata in a page table entry in a page table, the page table entry information about a page of data that is stored in the memory. The computing device then uses the cache coherency indicator to determine operations to be performed when accessing data in the page of data in the memory. For example, the computing device can use the coherency indicator to determine whether a coherency operation is to be performed when a processor of a given type accesses data in the page of data in the memory.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:R3hNpaxXUhUC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"The described embodiments include a computing device with two or more types of processors and a memory that is shared between the two or more types of processors. The computing device performs operations for handling cache coherency between the two or more types of processors. During operation, the computing device sets a cache coherency indicator in metadata in a page table entry in a page table, the page table entry information about a page of data that is stored in the memory. The computing device then uses the cache coherency indicator to determine operations to be performed when accessing data in the page of data in the memory. For example, the computing device can use the coherency indicator to determine whether a coherency operation is to be performed when a processor of a given type accesses data in the page of data in the memory.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:4DMP91E08xMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"GPUs have emerged as a key computing platform for an ever-growing range of applications. Unlike traditional bulk-synchronous GPU programs, many emerging GPU-accelerated applications, such as graph processing, have irregular interaction among the concurrent threads. Consequently, they need complex synchronization. To enable both high performance and adequate synchronization, GPU vendors have introduced scoped synchronization operations that allow a programmer to synchronize within a subset of concurrent threads (a.k. a., scope) that she deems adequate. Scoped-synchronization avoids the performance overhead of synchronization across thousands of GPU threads while ensuring correctness when used appropriately. This flexibility, however, could be a new source of incorrect synchronization where a race can occur due to insufficient scope of the synchronization operation, and not due to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:hMod-77fHWUC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Heterogeneous systems combine general-purpose CPUs with domain-specific accelerators like GPUs. Recent heterogeneous system designs have enabled GPUs to request OS services, but the domain-specific nature of accelerators means that they must rely on the CPUs to handle these requests. Such system service requests can unintentionally harm the performance of unrelated CPU applications. Tests on a real heterogeneous processor demonstrate that GPU system service requests can degrade contemporaneous CPU application performance by up to 44% and can reduce energy efficiency by limiting CPU sleep time. The reliance on busy CPU cores to perform the system services can also slow down GPU work by up to 18%. This new form of interference is found only in accelerator-rich heterogeneous designs and may be exacerbated in future systems with more accelerators. We explore mitigation strategies from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:IWHjjKOFINEC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Two key trends in computing are evident --- emergence of GPU as a first-class compute element and emergence of byte-addressable nonvolatile memory technologies (NVRAM) as DRAM-supplement. GPUs and NVRAMs are likely to coexist in future systems. However, previous works have either focused on GPUs or on NVRAMs, in isolation. In this work, we investigate the enhancements necessary for a GPU to efficiently and correctly manipulate NVRAM-resident persistent data structures.
Specifically, we find that previously proposed CPU-centric persist barriers fall short for GPUs. We thus introduce the concept of scoped persist barriers that aligns with the hierarchical programming framework of GPUs. Scoped persist barriers enable GPU programmers to express which execution group (a.k.a., scope) a given persist barrier applies to. We demonstrate that: 1 use of narrower scope than algorithmically-required can …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:Wp0gIr-vW9MC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"The GPU is a key computing platform for many application domains. While the new non-volatile memory technology has brought the promise of byte-addressable persistence (a.k.a., persistent memory, or PM) to CPU applications, the same, unfortunately, is beyond the reach of GPU programs.
We take three key steps toward enabling GPU programs to access PM directly. First, enable direct access to PM from within a GPU kernel without needing to modify the hardware. Next, we demonstrate three classes of GPU-accelerated applications that benefit from PM. In the process, we create a workload suite with nine such applications. We then create a GPU library, written in CUDA, to support logging, checkpointing, and primitives for native persistence for programmers to easily leverage PM.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:ldfaerwXgEUC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Techniques described herein improve processor performance in situations where a large number of system service requests are being received from other devices. More specifically, upon detecting that certain operating conditions that indicate a processor slowdown are present, the processor performs one or more system service adjustment techniques. These techniques include throttling (reducing the rate of handling) of such requests, coalescing (grouping multiple requests into a single group) the requests, disabling microarchitctural structures (such as caches or branch prediction units) or updates to those structures, and prefetching data for or pre-performing these requests. Each of these adjustment techniques helps to reduce the number of and/or workload associated with servicing requests for system services.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:7PzlFSSx8tAC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"GPUs are now commonly available in most modern computing platforms. They are increasingly being adopted in cloud platforms and data centers due to their immense computing capability. In response to this growth in usage, manufacturers continuously try to improve GPU hardware by adding new features. However, this increase in usage and the addition of utility-improving features can create new, unexpected attack channels. In this paper, we show that two such features-unified virtual memory (UVM) and multi-process service (MPS)-primarily introduced to improve the programmability and efficiency of GPU kernels have an unexpected consequence-that of creating a novel covert-timing channel via the GPU's translation lookaside buffer (TLB) hierarchy. To enable this covert channel, we first perform experiments to understand the characteristics of TLBs present on a GPU. The use of UVM allows fine-grained …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:RYcK_YlVTxYC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:qUcmZB5y_30C,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Newer use cases of GPU (Graphics Processing Unit) computing, e.g., graph analytics, look less like traditional bulk-synchronous GPU programs. To cater to the needs of emerging applications with semantically richer and finer grain sharing patterns, GPU vendors have been introducing advanced programming features, e.g., scoped synchronization and independent thread scheduling. While these features can speed up many applications and enable newer use cases, they can also introduce subtle synchronization errors if used incorrectly.
We present iGUARD, a runtime software tool to detect races in GPU programs due to incorrect use of such advanced features. A key need for a race detector to be practical is to accurately detect races at reasonable overheads. We thus perform the race detection on the GPU itself without relying on the CPU. The GPU's parallelism helps speed up race detection by 15x over a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:2P1L_qKh6hAC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:mB3voiENLucC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Systems, apparatuses, and methods for enforcing processor quality of service guarantees when servicing system service requests (SSRs) are disclosed. A system includes a first processor executing an operating system and a second processor executing an application which generates SSRs for the first processor to service. The first processor monitors the number of cycles spent servicing SSRs over a previous time interval, and if this number of cycles is above a threshold, the first processor starts delaying the servicing of subsequent SSRs. In one implementation, if the previous delay was non-zero, the first processor increases the delay used in the servicing of subsequent SSRs. If the number of cycles is less than or equal to the threshold, then the first processor services SSRs without delay. As the delay is increased, the second processor begins to stall and its SSR generation rate falls, reducing the load on the first …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:M3NEmzRMIkIC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Intel’s SGX architecture offers clients of public cloud computing platforms the ability to create hardware-protected enclaves whose contents are protected from privileged system software. However, SGX relies on system software for enclave memory management. In a sequence of recent papers, researchers have demonstrated that this reliance allows a malicious OS/hypervisor to snoop on the page addresses being accessed from within an enclave via various channels. This page address stream can then be used to infer secrets if the enclave’s page access pattern depends upon the secret and this constitutes an important class of side-channels.
We propose SGXL, a hardware-software co-designed system that significantly increases the difficulty of any page address-based side-channels through the use of large pages. A large page maps address ranges at a much larger granularity than the default page size (at …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:RGFaLdJalmkC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,A processing apparatus is provided that includes NVRAM and one or more processors configured to process a first set and a second set of instructions according to a hierarchical processing scope and process a scoped persistence barrier residing in the program after the first instruction set and before the second instruction set. The barrier includes an instruction to cause first data to persist in the NVRAM before second data persists in the NVRAM. The first data results from execution of each of the first set of instructions processed according to the one hierarchical processing scope. The second data results from execution of each of the second set of instructions processed according to the one hierarchical processing scope. The processing apparatus also includes a controller configured to cause the first data to persist in the NVRAM before the second data persists in the NVRAM based on the scoped persistence …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:mVmsd5A6BfQC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"A data processing system includes a memory, a group of input/output (I/O) devices, an input/output memory management unit (IOMMU). The IOMMU is connected to the memory and adapted to allocate a hardware resource from among a group of hardware resources to receive an address translation request for a memory access from an I/O device. The IOMMU detects address translation requests from the plurality of I/O devices. The IOMMU reorders the address translation requests such that an order of dispatching an address translation request is based on a policy associated with the I/O device that is requesting the memory access. The IOMMU selectively allocates a hardware resource to the input/output device, based on the policy that is associated with the I/O device in response to the reordering.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:blknAaTinKkC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"An operating system has many memory management goals including reducing memory access latency, and reducing memory footprint. These goals can conflict with each other when independent subsystems optimize them in silos. In this work, we report one such conflict that appears between memory de-duplication and NUMA (non-uniform memory access) management. Linux's memory de-duplication subsystem, namely KSM, is NUMA unaware. Consequently, while de-duplicating pages across NUMA nodes, it can place de-duplicated pages in a manner that can lead to significant performance variations, unfairness, and subvert process priority. Toward this, we introduce NUMA-aware KSM, a.k.a., nuKSM, that makes judicious decisions about the placement of de-duplicated pages to reduce the impact of NUMA, unfairness, and avoid priority subversion. Independent of the NUMA effects, we observed that KSM …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:70eg2SAEIzsC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"The present disclosure is directed to techniques for migrating data between heterogeneous memories in a computing system. More specifically, the techniques involve migrating data between a memory having better access characteristics (eg, lower latency but greater capacity) and a memory having worse access characteristics (eg, higher latency but lower capacity). Migrations occur with a variable migration granularity. A migration granularity specifies a number of memory pages, having virtual addresses that are contiguous in virtual address space, that are migrated in a single migration operation. A history-based technique that adjusts migration granularity based on the history of memory utilization by an application is provided. A profiling-based technique that adjusts migration granularity based on a profiling operation is also provided.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:hC7cP41nSMkC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,A method and apparatus for performing inter-lane power management includes de-energizing one or more execution lanes upon a determination that the one or more execution lanes are to be predicated. Energy from the predicated execution lanes is redistributed to one or more active execution lanes.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:4JMBOYKVnBMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,A method and apparatus for performing inter-lane power management includes de-energizing one or more execution lanes upon a determination that the one or more execution lanes are to be predicated. Energy from the predicated execution lanes is redistributed to one or more active execution lanes.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:Zph67rFs4hoC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,A processing apparatus is provided that includes NVRAM and one or more processors configured to process a first set and a second set of instructions according to a hierarchical processing scope and process a scoped persistence barrier residing in the program after the first instruction set and before the second instruction set. The barrier includes an instruction to cause first data to persist in the NVRAM before second data persists in the NVRAM. The first data results from execution of each of the first set of instructions processed according to the one hierarchical processing scope. The second data results from execution of each of the second set of instructions processed according to the one hierarchical processing scope. The processing apparatus also includes a controller configured to cause the first data to persist in the NVRAM before the second data persists in the NVRAM based on the scoped persistence …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:isC4tDSrTZIC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"While the implications of persistent memory (PM) on CPU hardware and software are well-explored, the same is not true for GPUs (Graphics Processing Units). A recent work, GPM, demonstrated how GPU programs can benefit from the fine-grain persistence of PM. However, in the absence of a persistency model, one cannot reason about the correctness of PM-aware GPU programs. Persistency models define the order in which writes to PM are persisted. We explore persistency models for GPUs.
We explore persistency models for GPUs. We demonstrate that CPU persistency models fall short for GPUs. We qualitatively and quantitatively argue that GPU persistency models should support scopes and buffering of writes to PM to leverage parallelism while adapting to higher NVM latencies. We formally specify a GPU persistency model that supports both scopes and buffers. We detail how GPU architecture can …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:SeFeTyx0c_EC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Secure Two-party Computation (2PC) allows two parties to compute any function on their private inputs without revealing their inputs in the clear to each other. Since 2PC is known to have notoriously high overheads, one of the most popular computation models is that of 2PC with a trusted dealer, where a trusted dealer provides correlated randomness (independent of any input) to both parties during a preprocessing phase. Recent works construct efficient 2PC protocols in this model based on the cryptographic technique of function secret sharing (FSS). We build an end-to-end system Orca to accelerate the computation of FSS-based 2PC protocols with GPUs. Next, we observe that the main performance bottleneck in such accelerated protocols is in storage (due to the large amount of correlated randomness), and we design new FSS-based 2PC cryptographic protocols for several key functionalities in ML which reduce storage by up to . Compared to prior state-of-the-art on secure training accelerated with GPUs in the same computation model (Piranha, Usenix Security 2022), we show that Orca has higher accuracy, lesser communication, and is faster on CIFAR-10.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:ZHo1McVdvXMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Multi-Chip Module (MCM) designs have emerged as a key technique to scale up a GPU’s compute capabilities in the face of slowing transistor technology. However, the disaggregated nature of MCM GPUs with many chiplets connected via in-package interconnects leads to non-uniformity. We explore the implications of MCM’s non-uniformity on the GPU’s virtual memory. We quantitatively demonstrate that an MCM-aware virtual memory system should aim to 1 leverage aggregate TLB capacity across chiplets while limiting accesses to L2 TLB on remote chiplets, 2 reduce accesses to page table entries resident on a remote chiplet’s memory during page walks. We propose MCM-aware GPU virtual memory (MGvm) that leverages static analysis techniques, previously used for thread and data placement, to map virtual addresses to chiplets and to place the page tables. At runtime, MGvm balances its objective of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:HoB7MX3m0LUC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Systems, apparatuses, and methods for enforcing processor quality of service guarantees when servicing system service requests (SSRs) are disclosed. A system includes a first processor executing an operating system and a second processor executing an application which generates SSRs for the first processor to service. The first processor monitors the number of cycles spent servicing SSRs over a previous time interval, and if this number of cycles is above a threshold, the first processor starts delaying the servicing of subsequent SSRs. In one implementation, if the previous delay was non-zero, the first processor increases the delay used in the servicing of subsequent SSRs. If the number of cycles is less than or equal to the threshold, then the first processor services SSRs without delay. As the delay is increased, the second processor begins to stall and its SSR generation rate falls, reducing the load on the first …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:pqnbT2bcN3wC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Various messaging systems and methods are disclosed for meeting invitation management. In one aspect, a method of messaging is provided that includes generating a message to invite one or more invitees to a meeting. The message includes an assertion to suppress an auto-responder of the one or more invitees. The message is sent to the one or more invitees. The assertion suppresses the auto-responder of the one or more invitees.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:ZeXyd9-uunAC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"A method for preventing a side channel attack by executing an enclave on a remote computing device. The method comprises configuring the enclave based on configuration parameters defined by a computing device. A page created in first enclave cache memory in the remote computing device and adding virtual page address information and page security attributes corresponding to the page in a second enclave cache memory, and an encrypted log entry is created in a protected memory of the remote computing device. The enclave is initiated by comparing the log entry and a second hash key generated by the remote computing device. A new page of pre-defined size is dynamically added to the first enclave cache memory after initiation of the enclave. The enclave is executed based on a successful validation of a size of the page created in first enclave cache memory to be equal to the pre-defined page size.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:J_g5lzvAfSwC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Large pages are commonly deployed to reduce address translation overheads for big-memory workloads. Modern x86-64 processors from Intel and AMD support two large page sizes -- 1GB and 2MB. However, previous works on large pages have primarily focused on 2MB pages, partly due to lack of substantial evidence on the profitability of 1GB pages to real-world applications. We argue that in fact, inadequate system software support is responsible for a decade of underutilized hardware support for 1GB pages. Through extensive experimentation on a real system, we demonstrate that 1GB pages can improve performance over 2MB pages, and when used in tandem with 2MB pages for an important set of applications; the support for the latter is crucial but missing in current systems. Our design and implementation of \trident{} in Linux fully exploit hardware supported large pages by dynamically and transparently allocating 1GB, 2MB, and 4KB pages as deemed suitable. \trident{} speeds up eight memory-intensive applications by {}, on average, over Linux's use of 2MB pages. We also propose \tridentpv{}, an extension to \trident{} that effectively virtualizes 1GB pages via copy-less promotion and compaction in the guest OS. Overall, this paper shows that even GB-sized pages have considerable practical significance with adequate software enablement, in turn motivating architects to continue investing/innovating in large pages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:YFjsv_pBGBYC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Large pages are commonly deployed to reduce address translation overheads for big-memory workloads. Modern x86-64 processors from Intel and AMD support two large page sizes--1GB and 2MB. However, previous works on large pages have primarily focused on 2MB pages, partly due to lack of substantial evidence on the profitability of 1GB pages to real-world applications. We argue that in fact, inadequate system software support is responsible for a decade of underutilized hardware support for 1GB pages. Through extensive experimentation on a real system, we demonstrate that 1GB pages can improve performance over 2MB pages, and when used in tandem with 2MB pages for an important set of applications; the support for the latter is crucial but missing in current systems. Our design and implementation of\trident {} in Linux fully exploit hardware supported large pages by dynamically and transparently …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:BqipwSGYUEgC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"On public cloud computing platforms, cloud providers own and administer the system software (eg, the BIOS, the OS, and/or the hypervisor) that manages the computing infrastructure. A malicious actor can leverage this system software to compromise the integrity and confidentiality of data and code of the clients of public computing infrastructures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:NMxIlDl6LWMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"A data processing system includes a memory and an input output memory management unit that is connected to the memory. The input output memory management unit is adapted to receive batches of address translation requests. The input output memory management unit has instructions that identify, from among the batches of address translation requests, a later batch having a lower number of memory access requests than an earlier batch, and selectively schedules access to a page table walker for each address translation request of a batch.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:TFP_iSt0sucC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Cluster manager functional blocks perform operations for migrating pages in portions in corresponding migration clusters. During operation, each cluster manager keeps an access record that includes information indicating accesses of pages in the portions in the corresponding migration cluster. Based on the access record and one or more migration policies, each cluster manager migrates pages between the portions in the corresponding migration cluster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:bEWYMUwI8FkC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"Cluster manager functional blocks perform operations for migrating pages in portions in corresponding migration clusters. During operation, each cluster manager keeps an access record that includes information indicating accesses of pages in the portions in the corresponding migration cluster. Based on the access record and one or more migration policies, each cluster manager migrates pages between the portions in the corresponding migration cluster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:dhFuZR0502QC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"The described embodiments include a computing device with two or more translation lookaside buffers (TLB) that performs operations for handling entries in the TLBs. During operation, the computing device maintains lease values for entries in the TLBs, the lease values representing times until leases for the entries expire, wherein a given entry in the TLB is invalid when the associated lease has expired. The computing device uses the lease value to control operations that are allowed to be performed using information from the entries in the TLBs. In addition, the computing device maintains, in a page table, longest lease values for page table entries indicating when corresponding longest leases for entries in TLBs expire. The longest lease values are used to determine when and if a TLB shootdown is to be performed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:HDshCWvjkbEC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",20,"The described embodiments include a computing device with two or more translation lookaside buffers (TLB) that performs operations for handling entries in the TLBs. During operation, the computing device maintains lease values for entries in the TLBs, the lease values representing times until leases for the entries expire, wherein a given entry in the TLB is invalid when the associated lease has expired. The computing device uses the lease value to control operations that are allowed to be performed using information from the entries in the TLBs. In addition, the computing device maintains, in a page table, longest lease values for page table entries indicating when corresponding longest leases for entries in TLBs expire. The longest lease values are used to determine when and if a TLB shootdown is to be performed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&citation_for_view=pL5B4ywAAAAJ:_kc_bZDykSQC,http://www.csa.iisc.ac.in/~arkapravab/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of allocating a set of indivisible goods among a set of agents in a fair and efficient manner. An allocation is said to be fair if it is envy-free up to one good (EF1), which means that each agent prefers its own bundle over the bundle of any other agent up to the removal of one good. In addition, an allocation is deemed efficient if it satisfies Pareto efficiency. While each of these well-studied properties is easy to achieve separately, achieving them together is far from obvious. Recently, Caragiannis et al. (2016) established the surprising result that when agents have additive valuations for the goods, there always exists an allocation that simultaneously satisfies these two seemingly incompatible properties. Specifically, they showed that an allocation that maximizes the Nash social welfare objective is both EF1 and Pareto efficient. However, the problem of maximizing Nash social welfare is NP-hard. As …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&citation_for_view=HcGQSKIAAAAJ:-f6ydRqryjwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We consider the problem of allocating indivisible goods fairly among n agents who have additive and submodular valuations for the goods. Our fairness guarantees are in terms of the maximin share, which is defined to be the maximum value that an agent can ensure for herself, if she were to partition the goods into n bundles, and then receive a minimum valued bundle. Since maximin fair allocations (i.e., allocations in which each agent gets at least her maximin share) do not always exist, prior work has focused on approximation results that aim to find allocations in which the value of the bundle allocated to each agent is (multiplicatively) as close to her maximin share as possible. In particular, Procaccia and Wang (2014) along with Amanatidis et al. (2015) have shown that under additive valuations, a 2/3-approximate maximin fair allocation always exists and can be found in polynomial time. We complement these …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&citation_for_view=HcGQSKIAAAAJ:qUcmZB5y_30C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We consider the problem of fairly allocating indivisible goods, among agents, under cardinality constraints and additive valuations. In this setting, we are given a partition of the entire set of goods—ie, the goods are categorized—and a limit is specified on the number of goods that can be allocated from each category to any agent. The objective here is to find a fair allocation in which the subset of goods assigned to any agent satisfies the given cardinality constraints. This problem naturally captures a number of resource-allocation applications, and is a generalization of the well-studied (unconstrained) fair division problem.
The two central notions of fairness, in the context of fair division of indivisible goods, are envy freeness up to one good (EF1) and (approximate) maximin share guarantee (MMS). We show that the existence and algorithmic guarantees established for these solution concepts in the unconstrained setting can essentially be achieved under cardinality constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&citation_for_view=HcGQSKIAAAAJ:_Qo2XoVZTnwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of fairly allocating a set of indivisible goods among agents with additive valuations. The extent of fairness of an allocation is measured by its Nash social welfare, which is the geometric mean of the valuations of the agents for their bundles. While the problem of maximizing Nash social welfare is known to be APX-hard in general, we study the effectiveness of simple, greedy algorithms in solving this problem in two interesting special cases. First, we show that a simple, greedy algorithm provides a 1.061-approximation guarantee when agents have identical valuations, even though the problem of maximizing Nash social welfare remains NP-hard for this setting. Second, we show that when agents have binary valuations over the goods, an exact solution (i.e., a Nash optimal allocation) can be found in polynomial time via a greedy algorithm. Our results in the binary setting extend to provide novel, exact algorithms for optimizing Nash social welfare under concave valuations. Notably, for the above mentioned scenarios, our techniques provide a simple alternative to several of the existing, more sophisticated techniques for this problem such as constructing equilibria of Fisher markets or using real stable polynomials.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&citation_for_view=HcGQSKIAAAAJ:HDshCWvjkbEC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of allocating indivisible goods among n agents in a fair manner. For this problem, maximin share (MMS) is a well-studied solution concept which provides a fairness threshold. Specifically, maximin share is defined as the minimum utility that an agent can guarantee for herself when asked to partition the set of goods into n bundles such that the remaining (n-1) agents pick their bundles adversarially. An allocation is deemed to be fair if every agent gets a bundle whose valuation is at least her maximin share. Even though maximin shares provide a natural benchmark for fairness, it has its own drawbacks and, in particular, it is not sufficient to rule out unsatisfactory allocations. Motivated by these considerations, in this work we define a stronger notion of fairness, called groupwise maximin share guarantee (GMMS). In GMMS, we require that the maximin share guarantee is achieved not just with respect to the grand bundle, but also among all the subgroups of agents. Hence, this solution concept strengthens MMS and provides an ex-post fairness guarantee. We show that in specific settings, GMMS allocations always exist. We also establish the existence of approximate GMMS allocations under additive valuations, and develop a polynomial-time algorithm to find such allocations. Moreover, we establish a scale of fairness wherein we show that GMMS implies approximate envy freeness. Finally, we empirically demonstrate the existence of GMMS allocations in a large set of randomly generated instances. For the same set of instances, we additionally show that our algorithm achieves an approximation factor better than the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&citation_for_view=HcGQSKIAAAAJ:hFOr9nPyWt4C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study Fisher markets that admit equilibria wherein each good is integrally assigned to some agent. While strong existence and computational guarantees are known for equilibria of Fisher markets with additive valuations (Eisenberg and Gale 1959; Orlin 2010), such equilibria, in general, assign goods fractionally to agents. Hence, Fisher markets are not directly applicable in the context of indivisible goods. In this work we show that one can always bypass this hurdle and, up to a bounded change in agents’ budgets, obtain markets that admit an integral equilibrium. We refer to such markets as pure markets and show that, for any given Fisher market (with additive valuations), one can efficiently compute a “near-by,” pure market with an accompanying integral equilibrium.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&citation_for_view=HcGQSKIAAAAJ:j3f4tGmQtD8C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"In the allocation of resources to a set of agents, how do fairness guarantees impact social welfare? A quantitative measure of this impact is the price of fairness, which measures the worst-case loss of social welfare due to fairness constraints. While initially studied for divisible goods, recent work on the price of fairness also studies the setting of indivisible goods.
In this paper, we resolve the price of two well-studied fairness notions in the context of indivisible goods: envy-freeness up to one good () and approximate maximin share (). For both and we show, via different techniques, that the price of fairness is , where n is the number of agents. From previous work, it follows that these guarantees are tight. We, in fact, obtain the price-of-fairness results via efficient algorithms. For our bound holds for additive valuations, whereas for , it holds for the more general class of subadditive valuations …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&citation_for_view=HcGQSKIAAAAJ:35N4QoGY0k4C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We develop polynomial-time algorithms for the fair and efficient allocation of indivisible goods among agents that have subadditive valuations over the goods. We first consider the Nash social welfare as our objective and design a polynomial-time algorithm that, in the value oracle model, finds an -approximation to the Nash optimal allocation. Subadditive valuations include XOS (fractionally subadditive) and submodular valuations as special cases. Our result, even for the special case of submodular valuations, improves upon the previously best known -approximation ratio of Garg et al. (2020). More generally, we study maximization of -mean welfare. The -mean welfare is parameterized by an exponent term and encompasses a range of welfare functions, such as social welfare (), Nash social welfare (), and egalitarian welfare (). We give an algorithm that, for subadditive valuations and any given , computes (in the value oracle model and in polynomial time) an allocation with -mean welfare at least times the optimal. Further, we show that our approximation guarantees are essentially tight for XOS and, hence, subadditive valuations. We adapt a result of Dobzinski et al. (2010) to show that, under XOS valuations, an approximation for the -mean welfare for any (including the Nash social welfare) requires exponentially many value queries; here, is any fixed constant.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&citation_for_view=HcGQSKIAAAAJ:NaGl4SEjCO4C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study fair division of indivisible goods in a single-parameter environment. In particular, we develop truthful social welfare maximizing mechanisms for fairly allocating indivisible goods. Our fairness guarantees are in terms of solution concepts which are tailored to address allocation of indivisible goods and, hence, provide an appropriate framework for fair division of goods. This work specifically considers fairness in terms of envy freeness up to one good (EF1), maximin share guarantee (MMS), and Nash social welfare (NSW). Our first result shows that (in a single-parameter environment) the problem of maximizing welfare, subject to the constraint that the allocation of the indivisible goods is EF1, admits a polynomial-time, 1/2-approximate, truthful auction. We further prove that this problem is NP-Hard and, hence, an approximation is warranted. This hardness result also complements prior works which show that an arbitrary EF1 allocation can be computed efficiently. We also establish a bi-criteria approximation guarantee for the problem of maximizing social welfare under MMS constraints. In particular, we develop a truthful auction which efficiently finds an allocation wherein each agent gets a bundle of value at least times her maximin share and the welfare of the computed allocation is at least the optimal, here is a fixed constant. We complement this result by showing that maximizing welfare is computationally hard even if one aims to only satisfy the MMS constraint approximately.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:TFP_iSt0sucC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"The classic cake-cutting problem provides a model for addressing fair and efficient allocation of a divisible, heterogeneous resource (metaphorically, the cake) among agents with distinct preferences. Focusing on a standard formulation of cake cutting, in which each agent must receive a contiguous piece of the cake, this work establishes algorithmic and hardness results for multiple fairness/efficiency measures.
First, we consider the well-studied notion of envy-freeness and develop an efficient algorithm that finds a cake division (with connected pieces) wherein the envy is multiplicatively within a factor of . The same algorithm in fact achieves an approximation ratio of for the problem of finding cake divisions with as large a Nash social welfare () as possible. is another standard measure of fairness and this work also establishes a connection between envy-freeness and : approximately envy-free cake divisions (with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:hMod-77fHWUC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study fair and economically efficient allocation of indivisible goods among agents whose valuations are rank functions of matroids. Such valuations constitute a well-studied class of submodular functions (i.e., they exhibit a diminishing returns property) and model preferences in several resource-allocation settings. We prove that, for matroid-rank valuations, a social welfare-maximizing allocation that gives each agent her maximin share always exists. Furthermore, such an allocation can be computed in polynomial time. We establish similar existential and algorithmic results for the pairwise maximin share guarantee as well. To complement these results, we show that if the agents have binary XOS valuations or weighted-rank valuations, then maximin fair allocations are not guaranteed to exist. Both of these valuation classes are immediate generalizations of matroid-rank functions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:70eg2SAEIzsC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"In the classic maximum coverage problem, we are given subsets of a universe [n] along with an integer k and the objective is to find a subset of size k that maximizes . It is well-known that the greedy algorithm for this problem achieves an approximation ratio of and there is a matching inapproximability result. We note that in the maximum coverage problem if an element is covered by several sets, it is still counted only once. By contrast, if we change the problem and count each element e as many times as it is covered, then we obtain a linear objective function, , which can be easily maximized under a cardinality constraint.
We study the maximum -multi-coverage problem which naturally interpolates between these two extremes. In this problem, an element can be counted up to times but no more; hence, we consider maximizing the function , subject to the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:M3NEmzRMIkIC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"In the maximum coverage problem, we are given subsets of a universe along with an integer and the objective is to find a subset of size that maximizes . It is a classic result that the greedy algorithm for this problem achieves an optimal approximation ratio of . In this work we consider a generalization of this problem wherein an element can contribute by an amount that depends on the number of times it is covered. Given a concave, nondecreasing function , we define , where . The standard maximum coverage problem corresponds to taking . For any such , we provide an efficient algorithm that achieves an approximation ratio equal to the Poisson concavity ratio of , defined by . Complementing this approximation guarantee, we establish a matching NP-hardness result when grows in a sublinear way. As special cases, we improve the result of [Barman et al., IPCO, 2020] about maximum multi-coverage, that was based on the unique games conjecture, and we recover the result of [Dudycz et al., IJCAI, 2020] on multi-winner approval-based voting for geometrically dominant rules. Our result goes beyond these special cases and we illustrate it with applications to distributed resource allocation problems, welfare maximization problems and approval-based voting for general rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:vV6vV6tmYwMC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"This work develops algorithmic results for the classic cake-cutting problem in which a divisible, heterogeneous resource (modeled as a cake) needs to be partitioned among agents with distinct preferences. We focus on a standard formulation of cake cutting wherein each agent must receive a contiguous piece of the cake. While multiple hardness results exist in this setup for finding fair/efficient cake divisions, we show that, if the value densities of the agents satisfy the monotone likelihood ratio property(MLRP), then strong algorithmic results hold for various notions of fairness and economic efficiency.
Addressing cake-cutting instances with MLRP, first we develop an algorithm that finds cake divisions (with connected pieces) that are envy-free, up to an arbitrary precision. The time complexity of our algorithm is polynomial in the number of agents and the bit complexity of an underlying Lipschitz constant. We obtain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:J_g5lzvAfSwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We consider the problem of allocating a set of indivisible goods among a group of homogeneous agents under matroid constraints and additive valuations, in a fair manner. We propose a novel algorithm that computes a fair allocation for instances with additive and identical valuations, even under matroid constraints. Our result provides a computational anchor to the existential result of the fairness notion, called EF1 (envy-free up to one good) by Biswas and Barman in this setting. We further provide examples to show that the fairness notions stronger than EF1 does not always exist in this setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:blknAaTinKkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"Sparsity is a basic property of real vectors that is exploited in a wide variety of machine learning applications. In this work, we describe property testing algorithms for sparsity that observe a low-dimensional projec-tion of the input. We consider two settings. In the first setting, we test sparsity with respect to an unknown basis: given input vectors whose concatenation as columns forms , does for matrices and such that each column of is -sparse, or is “far” from having such a decomposition? In the second setting, we test sparsity with respect to a known basis: for a fixed design ma-trix , given input vector , is for some -sparse vector or is “far” from having such a decomposition? We analyze our algorithms using tools from high-dimensional geometry and probability.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:R3hNpaxXUhUC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of allocating indivisible goods among strategic agents. We focus on settings wherein monetary transfers are not available and each agent's private valuation is a submodular function with binary marginals, ie, the agents' valuations are matroid-rank functions. In this setup, we establish a notable dichotomy between two of the most well-studied fairness notions in discrete fair division; specifically, between envy-freeness up to one good (EF1) and maximin shares (MMS). First, we show that a known Pareto-efficient mechanism is group strategy-proof for finding EF1 allocations, under matroid-rank valuations. The group strategy-proofness guarantee strengthens an existing result that establishes truthfulness (individually for each agent) in the same context. Our result also generalizes prior work from binary additive valuations to the matroid-rank case. Next, we establish that an analogous positive result cannot be achieved for MMS, even when considering truthfulness on an individual level. Specifically, we prove that, for matroid-rank valuations, there does not exist a truthful mechanism that is index oblivious, Pareto efficient, and maximin fair. For establishing our results, we develop a characterization of truthful mechanisms for matroid-rank functions. This characterization in fact holds for a broader class of valuations (specifically, holds for binary XOS functions) and might be of independent interest.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:g5m5HwL7SMYC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of allocating indivisible goods among agents that have an identical subadditive valuation over the goods. The extent of fairness and efficiency of allocations is measured by the generalized means of the values that the allocations generate among the agents. Parameterized by an exponent term , generalized-mean welfares encompass multiple well-studied objectives, such as social welfare, Nash social welfare, and egalitarian welfare. We establish that, under identical subadditive valuations and in the demand oracle model, one can efficiently find a single allocation that approximates the optimal generalized-mean welfare---to within a factor of ---uniformly for all . Hence, by way of a constant-factor approximation algorithm, we obtain novel results for maximizing Nash social welfare and egalitarian welfare for identical subadditive valuations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:RGFaLdJalmkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of fair rent division that entails splitting the rent and allocating the rooms of an apartment among agents in a fair manner (i.e., under the imposed rents, no agent has a strictly stronger preference for any other agent’s room). The utility functions specify the cardinal preferences of the agents for the rooms for every possible room rent. Although envy-free solutions are guaranteed to exist under reasonably general utility functions, efficient algorithms for finding them were known only for quasilinear utilities. This work addresses this notable gap and develops a fully polynomial-time approximation scheme for fair rent division with minimal assumptions on the utility functions. Envy-free solutions correspond to equilibria of a two-sided matching market with monetary transfers; hence, this work also provides efficient algorithms for finding approximate equilibria in such markets. We complement the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:RHpTSmoSYBkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of allocating indivisible goods among agents in a fair and economically efficient manner. In this context, the Nash social welfare—defined as the geometric mean of agents’ valuations for their assigned bundles—stands as a fundamental measure that quantifies the extent of fairness of an allocation. Focusing on instances in which the agents’ valuations have binary marginals, we develop essentially tight results for (approximately) maximizing Nash social welfare under two of the most general classes of complement-free valuations, i.e., under binary and binary subadditive valuations.
For binary valuations, we develop a polynomial-time algorithm that finds a constant-factor (specifically ) approximation for the optimal Nash social welfare, in the standard value-oracle model. The allocations computed by our algorithm also achieve constant-factor approximation for social welfare and the groupwise …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:ldfaerwXgEUC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"In the allocation of resources to a set of agents, how do fairness guarantees impact the social welfare? A quantitative measure of this impact is the price of fairness, which measures the worst-case loss of social welfare due to fairness constraints. While initially studied for divisible goods, recent work on the price of fairness also studies the setting of indivisible goods. In this paper, we resolve the price of two well-studied fairness notions for the allocation of indivisible goods: envy-freeness up to one good (EF1), and approximate maximin share (MMS). For both EF1 and 1/2-MMS guarantees, we show, via different techniques, that the price of fairness is O (",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:lSLTfruPkqcC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study classic fair-division problems in a partial information setting. This paper respectively addresses fair division of rent, cake, and indivisible goods among agents with cardinal preferences. We will show that, for all of these settings and under appropriate valuations, a fair (or an approximately fair) division among n agents can be efficiently computed using only the valuations of n− 1 agents. The nth (secretive) agent can make an arbitrary selection after the division has been proposed and, irrespective of her choice, the computed division will admit an overall fair allocation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:iH-uZ7U-co4C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study fair and efficient allocation of divisible goods, in an online manner, among n agents. The goods arrive online in a sequence of T time periods. The agents' values for a good are revealed only after its arrival, and the online algorithm needs to fractionally allocate the good, immediately and irrevocably, among the agents. Towards a unifying treatment of fairness and economic efficiency objectives, we develop an algorithmic framework for finding online allocations to maximize the generalized mean of the values received by the agents. In particular, working with the assumption that each agent's value for the grand bundle of goods is appropriately scaled, we address online maximization of p-mean welfare. Parameterized by an exponent term p in (-infty, 1], these means encapsulate a range of welfare functions, including social welfare (p= 1), egalitarian welfare (p to-infty), and Nash social welfare (p to 0). We present a simple algorithmic template that takes a threshold as input and, with judicious choices for this threshold, leads to both universal and tailored competitive guarantees. First, we show that one can compute online a single allocation that O (sqrt (n) log n)-approximates the optimal p-mean welfare for all p<= 1. The existence of such a universal allocation is interesting in and of itself. Moreover, this universal guarantee achieves essentially tight competitive ratios for specific values of p. Next, we obtain improved competitive ratios for different ranges of p by executing our algorithm with p-specific thresholds, eg, we provide O (log^ 3 n)-competitive ratio for all p in (-1/(log 2n), 1). We complement our positive results by establishing lower …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:M05iB0D1s5AC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of allocating indivisible goods among agents with the objective of maximizing Nash social welfare (NSW). This welfare function is defined as the geometric mean of the agents' valuations and, hence, it strikes a balance between the extremes of social welfare (arithmetic mean) and egalitarian welfare (max-min value). Nash social welfare has been extensively studied in recent years for various valuation classes. In particular, a notable negative result is known when the agents' valuations are complement-free and are specified via value queries: for XOS valuations, one necessarily requires exponentially many value queries to find any sublinear (in ) approximation for NSW. Indeed, this lower bound implies that stronger query models are needed for finding better approximations. Towards this, we utilize demand oracles and XOS oracles; both of these query models are standard and have been used in prior work on social welfare maximization with XOS valuations. We develop the first sublinear approximation algorithm for maximizing Nash social welfare under XOS valuations, specified via demand and XOS oracles. Hence, this work breaks the -approximation barrier for NSW maximization under XOS valuations. We obtain this result by developing a novel connection between NSW and social welfare under a capped version of the agents' valuations. In addition to this insight, which might be of independent interest, this work relies on an intricate combination of multiple technical ideas, including the use of repeated matchings and the discrete moving knife method. In addition, we partially complement the algorithmic result by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:u_35RYKgDlwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We consider prediction with expert advice when the loss vectors are assumed to lie in a set described by the sum of atomic norm balls. We derive a regret bound for a general version of the online mirror descent (OMD) algorithm that uses a combination of regularizers, each adapted to the constituent atomic norms. The general result recovers standard OMD regret bounds, and yields regret bounds for new structured settings where the loss vectors are (i) noisy versions of vectors from a low-dimensional subspace,(ii) sparse vectors corrupted with noise, and (iii) sparse perturbations of low-rank vectors. For the problem of online learning with structured losses, we also show lower bounds on regret in terms of rank and sparsity of the loss vectors, which implies lower bounds for the above additive loss settings as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:hC7cP41nSMkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of allocating indivisible goods among agents in a fair manner. While envy-free allocations of indivisible goods are not guaranteed to exist, envy-freeness can be achieved by additionally providing some subsidy to the agents. These subsidies can be alternatively viewed as a divisible good (money) that is fractionally assigned among the agents to realize an envy-free outcome. In this setup, we bound the subsidy required to attain envy-freeness among agents with dichotomous valuations, i.e., among agents whose marginal value for any good is either zero or one. We prove that, under dichotomous valuations, there exists an allocation that achieves envy-freeness with a per-agent subsidy of either or . Furthermore, such an envy-free solution can be computed efficiently in the standard value-oracle model. Notably, our results hold for general dichotomous valuations and, in particular, do not require the (dichotomous) valuations to be additive, submodular, or even subadditive. Also, our subsidy bounds are tight and provide a linear (in the number of agents) factor improvement over the bounds known for general monotone valuations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:a0OBvERweLwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"Agriculture has become a high-risk profession towards climate change and weather variability, which have direct impact on farmers’ socio-economic condition, and at the same time has to face challenge to provide food security for ever increasing population. So, there is a need to study the different aspects of climate smart agriculture and the present study is an attempt to assess the adoption consistency of farmers about CSA practices and factors likely to influence thereon. The adopters of overall selected practices were 79.85 per cent. The adoption consistency for overall selected CSA practices was of medium level for majority of respondents (58.25%). The LMR model showed that adoption consistency was expressed variation by selected explanatory variables with 23 per cent (R2= 0.23).‘Age’(X1),‘dependency ratio of family’(X3),‘proportion of low land’(X4),‘market accessibility’(X7) and ‘cropping intensity’(X9) were found to have positive and significant influence on adoption consistency. In order to increase adoption consistency, extension agencies, both in public and private sectors, should put forward strategic effort to make farmers aware of climate change and its impact on food production. Regular extension and technology backstopping is very important for increasing adoption consistency of farmers. The different stakeholders (both public and private) in input and output chains should work in convergence mode as a common entity so that farmers get necessary environment for adoption of technologies",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:3s1wT3WcHBgC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the problem of dividing indivisible chores among agents whose costs (for the chores) are supermodular set functions with binary marginals. Such functions capture complementarity among chores, i.e., they constitute an expressive class wherein the marginal disutility of each chore is either one or zero, and the marginals increase with respect to supersets. In this setting, we study the broad landscape of finding fair and efficient chore allocations. In particular, we establish the existence of EF1 and Pareto efficient chore allocations, MMS-fair and Pareto efficient allocations, and Lorenz dominating chore allocations. Furthermore, we develop polynomial-time algorithms--in the value oracle model--for computing the chore allocations for each of these fairness and efficiency criteria. Complementing these existential and algorithmic results, we show that in this chore division setting, the aforementioned fairness notions, namely EF1, MMS, and Lorenz domination are incomparable: an allocation that satisfies any one of these notions does not necessarily satisfy the others. Additionally, we study EFX chore division. In contrast to the above-mentioned positive results, we show that, for binary supermodular costs, Pareto efficient allocations that are even approximately EFX do not exist, for any arbitrarily small approximation constant. Focusing on EFX fairness alone, when the cost functions are identical we present an algorithm (Add-and-Fix) that computes an EFX allocation. For binary marginals, we show that Add-and-Fix runs in polynomial time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:CHSYGLWDkRkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We extend the notion of regret with a welfarist perspective. Focussing on the classic multi-armed bandit (MAB) framework, the current work quantifies the performance of bandit algorithms by applying a fundamental welfare function, namely the Nash social welfare (NSW) function. This corresponds to equating algorithm's performance to the geometric mean of its expected rewards and leads us to the study of Nash regret, defined as the difference between the -- a priori unknown -- optimal mean (among the arms) and the algorithm's performance. Since NSW is known to satisfy fairness axioms, our approach complements the utilitarian considerations of average (cumulative) regret, wherein the algorithm is evaluated via the arithmetic mean of its expected rewards. This work develops an algorithm that, given the horizon of play , achieves a Nash regret of , here denotes the number of arms in the MAB instance. Since, for any algorithm, the Nash regret is at least as much as its average regret (the AM-GM inequality), the known lower bound on average regret holds for Nash regret as well. Therefore, our Nash regret guarantee is essentially tight. In addition, we develop an anytime algorithm with a Nash regret guarantee of .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:pyW8ca7W8N0C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We revisit the connection between bargaining and equilibrium in exchange economies, and study its algorithmic implications. We consider bargaining outcomes to be allocations that cannot be blocked (i.e., profitably re-traded) by coalitions of small size and show that these allocations must be approximate Walrasian equilibria. Our results imply that deciding whether an allocation is approximately Walrasian can be done in polynomial time, even in economies for which finding an equilibrium is known to be computationally hard.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:JV2RwH3_ST0C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study coverage problems in which, for a set of agents and a given threshold T, the goal is to select T subsets (of the agents) that, while satisfying combinatorial constraints, achieve fair and efficient coverage among the agents. In this setting, the valuation of each agent is equated to the number of selected subsets that contain it, plus one. The current work utilizes the Nash social welfare function to quantify the extent of fairness and collective efficiency. We develop a polynomial-time \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\left( 18 + o(1) \right) $$\end{document}-approximation algorithm for maximizing Nash social welfare in coverage instances. Our algorithm applies to all instances …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:bFI3QPDXJZMC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"Cake cutting is a classic model for studying fair division of a heterogeneous, divisible resource among agents with individual preferences. Addressing cake division under a typical requirement that each agent must receive a connected piece of the cake, we develop approximation algorithms for finding envy-free (fair) cake divisions. In particular, this work improves the state-of-the-art additive approximation bound for this fundamental problem. Our results hold for general cake division instances in which the agents' valuations satisfy basic assumptions and are normalized (to have value for the cake). Furthermore, the developed algorithms execute in polynomial time under the standard Robertson-Webb query model. Prior work has shown that one can efficiently compute a cake division (with connected pieces) in which the additive envy of any agent is at most . An efficient algorithm is also known for finding connected cake divisions that are (almost) -multiplicatively envy-free. Improving the additive approximation guarantee and maintaining the multiplicative one, we develop a polynomial-time algorithm that computes a connected cake division that is both -additively envy-free and -multiplicatively envy-free. Our algorithm is based on the ideas of interval growing and envy-cycle-elimination. In addition, we study cake division instances in which the number of distinct valuations across the agents is parametrically bounded. We show that such cake division instances admit a fully polynomial-time approximation scheme for connected envy-free cake division.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:abG-DnoFyZgC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study the fair allocation of indivisible goods among agents with identical, additive valuations but individual budget constraints. Here, the indivisible goods--each with a specific size and value--need to be allocated such that the bundle assigned to each agent is of total size at most the agent's budget. Since envy-free allocations do not necessarily exist in the indivisible goods context, compelling relaxations--in particular, the notion of envy-freeness up to goods (EFk)--have received significant attention in recent years. In an EFk allocation, each agent prefers its own bundle over that of any other agent, up to the removal of goods, and the agents have similarly bounded envy against the charity (which corresponds to the set of all unallocated goods). Recently, Wu et al. (2021) showed that an allocation that satisfies the budget constraints and maximizes the Nash social welfare is -approximately EF1. However, the computation (or even existence) of exact EFk allocations remained an intriguing open problem. We make notable progress towards this by proposing a simple, greedy, polynomial-time algorithm that computes EF2 allocations under budget constraints. Our algorithmic result implies the universal existence of EF2 allocations in this fair division context. The analysis of the algorithm exploits intricate structural properties of envy-freeness. Interestingly, the same algorithm also provides EF1 guarantees for important special cases. Specifically, we settle the existence of EF1 allocations for instances in which: (i) the value of each good is proportional to its size, (ii) all goods have the same size, or (iii) all the goods have the same value. Our EF2 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:b0M2c_1WBrUC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study Markov Decision Processes (MDP) wherein states correspond to causal graphs that stochastically generate rewards. In this setup, the learner's goal is to identify atomic interventions that lead to high rewards by intervening on variables at each state. Generalizing the recent causal-bandit framework, the current work develops (simple) regret minimization guarantees for two-stage causal MDPs, with parallel causal graph at each state. We propose an algorithm that achieves an instance dependent regret bound. A key feature of our algorithm is that it utilizes convex optimization to address the exploration problem. We identify classes of instances wherein our regret guarantee is essentially tight, and experimentally validate our theoretical results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:yD5IFk8b50cC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"This paper studies a multi-armed bandit (MAB) version of the range-searching problem. In its basic form, range searching considers as input a set of points (on the real line) and a collection of (real) intervals. Here, with each specified point, we have an associated weight, and the problem objective is to find a maximum-weight point within every given interval. The current work addresses range searching with stochastic weights: each point corresponds to an arm (that admits sample access) and the point's weight is the (unknown) mean of the underlying distribution. In this MAB setup, we develop sample-efficient algorithms that find, with high probability, near-optimal arms within the given intervals, i.e., we obtain PAC (probably approximately correct) guarantees. We also provide an algorithm for a generalization wherein the weight of each point is a multi-dimensional vector. The sample complexities of our algorithms depend, in particular, on the size of the optimal hitting set of the given intervals. Finally, we establish lower bounds proving that the obtained sample complexities are essentially tight. Our results highlight the significance of geometric constructs -- specifically, hitting sets -- in our MAB setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:2P1L_qKh6hAC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"In critical decision-making scenarios, optimizing accuracy can lead to a biased classifier, hence past work recommends enforcing group-based fairness metrics in addition to maximizing accuracy. However, doing so exposes the classifier to another kind of bias called infra-marginality. This refers to individual-level bias where some individuals/subgroups can be worse off than under simply optimizing for accuracy. For instance, a classifier implementing race-based parity may significantly disadvantage women of the advantaged race. To quantify this bias, we propose a general notion of -infra-marginality that can be used to evaluate the extent of this bias. We prove theoretically that, unlike other fairness metrics, infra-marginality does not have a trade-off with accuracy: high accuracy directly leads to low infra-marginality. This observation is confirmed through empirical analysis on multiple simulated and real-world datasets. Further, we find that maximizing group fairness often increases infra-marginality, suggesting the consideration of both group-level fairness and individual-level infra-marginality. However, measuring infra-marginality requires knowledge of the true distribution of individual-level outcomes correctly and explicitly. We propose a practical method to measure infra-marginality, and a simple algorithm to maximize group-wise accuracy and avoid infra-marginality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:NMxIlDl6LWMC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"The classic cake-cutting problem provides a model for addressing fair and efficient allocation of a divisible, heterogeneous resource (metaphorically, the cake) among agents with distinct preferences. Focusing on a standard formulation of cake cutting, in which each agent must receive a contiguous piece of the cake, this work establishes algorithmic and hardness results for multiple fairness/efficiency measures. First, we consider the well-studied notion of envy-freeness and develop an efficient algorithm that finds a cake division (with connected pieces) wherein the envy is multiplicatively within a factor of . The same algorithm in fact achieves an approximation ratio of for the problem of finding cake divisions with as large a Nash social welfare (NSW) as possible. NSW is another standard measure of fairness and this work also establishes a connection between envy-freeness and NSW: approximately envy-free cake divisions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:RYcK_YlVTxYC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We study classic fair-division problems in a partial information setting. This paper respectively addresses fair division of rent, cake, and indivisible goods among agents with cardinal preferences. We will show that, for all of these settings and under appropriate valuations, a fair (or an approximately fair) division among n agents can be efficiently computed using only the valuations of n-1 agents. The nth (secretive) agent can make an arbitrary selection after the division has been proposed and, irrespective of her choice, the computed division will admit an overall fair allocation. For the rent-division setting we prove that the (well-behaved) utilities of n-1 agents suffice to find a rent division among n rooms such that, for every possible room selection of the secretive agent, there exists an allocation (of the remaining n-1 rooms among the n-1 agents) which ensures overall envy freeness (fairness). We complement this …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:O3NaXMp0MMsC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],22,"We consider the problem of fairly allocating indivisible goods, among agents, under cardinality constraints and additive valuations. In this setting, we are given a partition of the entire set of goods---i.e., the goods are categorized---and a limit is specified on the number of goods that can be allocated from each category to any agent. The objective here is to find a fair allocation in which the subset of goods assigned to any agent satisfies the given cardinality constraints. This problem naturally captures a number of resource-allocation applications, and is a generalization of the well-studied (unconstrained) fair division problem. The two central notions of fairness, in the context of fair division of indivisible goods, are envy freeness up to one good (EF1) and the (approximate) maximin share guarantee (MMS). We show that the existence and algorithmic guarantees established for these solution concepts in the unconstrained setting can essentially be achieved under cardinality constraints. Specifically, we develop efficient algorithms which compute EF1 and approximately MMS allocations in the constrained setting. Furthermore, focusing on the case wherein all the agents have the same additive valuation, we establish that EF1 allocations exist and can be computed efficiently even under laminar matroid constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&citation_for_view=HcGQSKIAAAAJ:TQgYirikUcIC,https://www.csa.iisc.ac.in/~barman/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Whereas people learn many different types of knowledge from diverse experiences over many years, and become better learners over time, most current machine learning systems are much more narrow, learning just a single function or data model based on statistical analysis of a single data set. We suggest that people learn better than computers precisely because of this difference, and we suggest a key direction for machine learning research is to develop software architectures that enable intelligent agents to also learn many types of knowledge, continuously over many years, and to become better learners over time. In this paper we define more precisely this never-ending learning paradigm for machine learning, and we present one case study: the Never-Ending Language Learner (NELL), which achieves a number of the desired properties of a never-ending learner. NELL has been learning to read the Web …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:a2necdfpwlEC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Graph Convolutional Networks (GCNs) have recently been shown to be quite successful in modeling graph-structured data. However, the primary focus has been on handling simple undirected graphs. Multi-relational graphs are a more general and prevalent form of graphs where each edge has a label and direction associated with it. Most of the existing approaches to handle such graphs suffer from over-parameterization and are restricted to learning representations of nodes only. In this paper, we propose CompGCN, a novel Graph Convolutional framework which jointly embeds both nodes and relations in a relational graph. CompGCN leverages a variety of entity-relation composition operations from Knowledge Graph Embedding techniques and scales with the number of relations. It also generalizes several of the existing multi-relational GCN methods. We evaluate our proposed method on multiple tasks such as node classification, link prediction, and graph classification, and achieve demonstrably superior results. We make the source code of CompGCN available to foster reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:WIXB4To3Tx4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Knowledge Graphs (KG) are multi-relational graphs consisting of entities as nodes and relations among them as typed edges. Goal of the Question Answering over KG (KGQA) task is to answer natural language queries posed over the KG. Multi-hop KGQA requires reasoning over multiple edges of the KG to arrive at the right answer. KGs are often incomplete with many missing links, posing additional challenges for KGQA, especially for multi-hop KGQA. Recent research on multi-hop KGQA has attempted to handle KG sparsity using relevant external text, which isn’t always readily available. In a separate line of research, KG embedding methods have been proposed to reduce KG sparsity by performing missing link prediction. Such KG embedding methods, even though highly relevant, have not been explored for multi-hop KGQA so far. We fill this gap in this paper and propose EmbedKGQA. EmbedKGQA is particularly effective in performing multi-hop KGQA over sparse KGs. EmbedKGQA also relaxes the requirement of answer selection from a pre-specified neighborhood, a sub-optimal constraint enforced by previous multi-hop KGQA methods. Through extensive experiments on multiple benchmark datasets, we demonstrate EmbedKGQA’s effectiveness over other state-of-the-art baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:N6_Y7JlWxwsC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Knowledge Graph (KG) embedding has emerged as an active area of research resulting in the development of several KG embedding methods. Relational facts in KG often show temporal dynamics, eg, the fact (Cristiano Ronaldo, playsFor, Manchester United) is valid only from 2003 to 2009. Most of the existing KG embedding methods ignore this temporal dimension while learning embeddings of the KG elements. In this paper, we propose HyTE, a temporally aware KG embedding method which explicitly incorporates time in the entity-relation space by associating each timestamp with a corresponding hyperplane. HyTE not only performs KG inference using temporal guidance, but also predicts temporal scopes for relational facts with missing time annotations. Through extensive experimentation on temporal datasets extracted from real-world KGs, we demonstrate the effectiveness of our model over both traditional as well as temporal KG embedding methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:wuD5JclIwkYC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"In many real-world network datasets such as co-authorship, co-citation, email communication, etc., relationships are complex and go beyond pairwise. Hypergraphs provide a flexible and natural modeling tool to model such complex relationships. The obvious existence of such complex relationships in many real-world networks naturaly motivates the problem of learning with hypergraphs. A popular learning paradigm is hypergraph-based semi-supervised learning (SSL) where the goal is to assign labels to initially unlabeled vertices in a hypergraph. Motivated by the fact that a graph convolutional network (GCN) has been effective for graph-based SSL, we propose HyperGCN, a novel GCN for SSL on attributed hypergraphs. Additionally, we show how HyperGCN can be used as a learning-based approach for combinatorial optimisation on NP-hard hypergraph problems. We demonstrate HyperGCN's effectiveness through detailed experimentation on real-world hypergraphs. We have made HyperGCN's source code available to foster reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:gmHTDCtJMcoC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Distantly-supervised Relation Extraction (RE) methods train an extractor by automatically aligning relation instances in a Knowledge Base (KB) with unstructured text. In addition to relation instances, KBs often contain other relevant side information, such as aliases of relations (e.g., founded and co-founded are aliases for the relation founderOfCompany). RE models usually ignore such readily available side information. In this paper, we propose RESIDE, a distantly-supervised neural relation extraction method which utilizes additional side information from KBs for improved relation extraction. It uses entity type and relation alias information for imposing soft constraints while predicting relations. RESIDE employs Graph Convolution Networks (GCN) to encode syntactic information from text and improves performance even when limited side information is available. Through extensive experiments on benchmark datasets, we demonstrate RESIDE's effectiveness. We have made RESIDE's source code available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:G36d5HCDkJYC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Most existing knowledge graphs suffer from incompleteness, which can be alleviated by inferring missing links based on known facts. One popular way to accomplish this is to generate low-dimensional embeddings of entities and relations, and use these to make inferences. ConvE, a recently proposed approach, applies convolutional filters on 2D reshapings of entity and relation embeddings in order to capture rich interactions between their components. However, the number of interactions that ConvE can capture is limited. In this paper, we analyze how increasing the number of these interactions affects link prediction performance, and utilize our observations to propose InteractE. InteractE is based on three key ideas–feature permutation, a novel feature reshaping, and circular convolution. Through extensive experiments, we find that InteractE outperforms state-of-the-art convolutional link prediction baselines on FB15k-237. Further, InteractE achieves an MRR score that is 9%, 7.5%, and 23% better than ConvE on the FB15k-237, WN18RR and YAGO3-10 datasets respectively. The results validate our central hypothesis–that increasing feature interaction is beneficial to link prediction performance. We make the source code of InteractE available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:8RAEygVn5_EC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Graph Neural Networks (GNN) have been shown to work effectively for modeling graph structured data to solve tasks such as node classification, link prediction and graph classification. There has been some recent progress in defining the notion of pooling in graphs whereby the model tries to generate a graph level representation by downsampling and summarizing the information present in the nodes. Existing pooling methods either fail to effectively capture the graph substructure or do not easily scale to large graphs. In this work, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and differentiable pooling method that addresses the limitations of previous graph pooling architectures. ASAP utilizes a novel self-attention network along with a modified GNN formulation to capture the importance of each node in a given graph. It also learns a sparse soft cluster assignment for nodes at each layer to effectively pool the subgraphs to form the pooled graph. Through extensive experiments on multiple datasets and theoretical analysis, we motivate our choice of the components used in ASAP. Our experimental results show that combining existing GNN architectures with ASAP leads to state-of-the-art results on multiple graph classification benchmarks. ASAP has an average improvement of 4%, compared to current sparse hierarchical state-of-the-art method. We make the source code of ASAP available to encourage reproducible research 1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:C-Rn0OCouf8C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report the performance of several existing methods using our protocol. The reproducible code has been made publicly available",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&citation_for_view=CIZwXAcAAAAJ:kO05sadLmrgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Relation extraction is the problem of classifying the relationship between two entities in a given sentence. Distant Supervision (DS) is a popular technique for developing relation extractors starting with limited supervision. We note that most of the sentences in the distant supervision relation extraction setting are very long and may benefit from word attention for better sentence representation. Our contributions in this paper are threefold. Firstly, we propose two novel word attention models for distantly- supervised relation extraction: (1) a Bi-directional Gated Recurrent Unit (Bi-GRU) based word attention model (BGWA), (2) an entity-centric attention model (EA), and (3) a combination model which combines multiple complementary models using weighted voting method for improved relation extraction. Secondly, we introduce GDS, a new distant supervision dataset for relation extraction. GDS removes test data noise present in all previous distant- supervision benchmark datasets, making credible automatic evaluation possible. Thirdly, through extensive experiments on multiple real-world datasets, we demonstrate the effectiveness of the proposed methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:qCpRzq7zkD8C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Word Sense Disambiguation (WSD) is a long-standing but open problem in Natural Language Processing (NLP). WSD corpora are typically small in size, owing to an expensive annotation process. Current supervised WSD methods treat senses as discrete labels and also resort to predicting the Most-Frequent-Sense (MFS) for words unseen during training. This leads to poor performance on rare and unseen senses. To overcome this challenge, we propose Extended WSD Incorporating Sense Embeddings (EWISE), a supervised model to perform WSD by predicting over a continuous sense embedding space as opposed to a discrete label space. This allows EWISE to generalize over both seen and unseen senses, thus achieving generalized zero-shot learning. To obtain target sense embeddings, EWISE utilizes sense definitions. EWISE learns a novel sentence encoder for sense definitions by using WordNet relations and also ConvE, a recently proposed knowledge graph embedding method. We also compare EWISE against other sentence encoders pretrained on large corpora to generate definition embeddings. EWISE achieves new state-of-the-art WSD performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:ojlX30-wUrgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"India is a multilingual society with 1369 rationalized languages and dialects being spoken across the country (INDIA, 2011). Of these, the 22 scheduled languages have a staggering total of 1.17 billion speakers and 121 languages have more than 10,000 speakers (INDIA, 2011). India also has the second largest (and an ever growing) digital footprint (Statista, 2020). Despite this, today's state-of-the-art multilingual systems perform suboptimally on Indian (IN) languages. This can be explained by the fact that multilingual language models (LMs) are often trained on 100+ languages together, leading to a small representation of IN languages in their vocabulary and training data. Multilingual LMs are substantially less effective in resource-lean scenarios (Wu and Dredze, 2020; Lauscher et al., 2020), as limited data doesn't help capture the various nuances of a language. One also commonly observes IN language text transliterated to Latin or code-mixed with English, especially in informal settings (for example, on social media platforms) (Rijhwani et al., 2017). This phenomenon is not adequately handled by current state-of-the-art multilingual LMs. To address the aforementioned gaps, we propose MuRIL, a multilingual LM specifically built for IN languages. MuRIL is trained on significantly large amounts of IN text corpora only. We explicitly augment monolingual text corpora with both translated and transliterated document pairs, that serve as supervised cross-lingual signals in training. MuRIL significantly outperforms multilingual BERT (mBERT) on all tasks in the challenging cross-lingual XTREME benchmark (Hu et al., 2020). We also present results …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:GiYFt9mpioMC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Visual Question Answering (VQA) has emerged as an important problem spanning Computer Vision, Natural Language Processing and Artificial Intelligence (AI). In conventional VQA, one may ask questions about an image which can be answered purely based on its content. For example, given an image with people in it, a typical VQA question may inquire about the number of people in the image. More recently, there is growing interest in answering questions which require commonsense knowledge involving common nouns (eg, cats, dogs, microphones) present in the image. In spite of this progress, the important problem of answering questions requiring world knowledge about named entities (eg, Barack Obama, White House, United Nations) in the image has not been addressed in prior research. We address this gap in this paper, and introduce KVQA–the first dataset for the task of (world) knowledge-aware VQA. KVQA consists of 183K question-answer pairs involving more than 18K named entities and 24K images. Questions in this dataset require multi-entity, multi-relation, and multi-hop reasoning over large Knowledge Graphs (KG) to arrive at an answer. To the best of our knowledge, KVQA is the largest dataset for exploring VQA over KG. Further, we also provide baseline performances using state-of-the-art methods on KVQA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:wGzT3bKASkAC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"The recent growth in the popularity and success of deep learning models on NLP classification tasks has accompanied the need for generating some form of natural language explanation of the predicted labels. Such generated natural language (NL) explanations are expected to be faithful, i.e., they should correlate well with the model's internal decision making. In this work, we focus on the task of natural language inference (NLI) and address the following question: can we build NLI systems which produce labels with high accuracy, while also generating faithful explanations of its decisions? We propose Natural-language Inference over Label-specific Explanations (NILE), a novel NLI method which utilizes auto-generated label-specific NL explanations to produce labels along with its faithful explanation. We demonstrate NILE's effectiveness over previously reported methods through automated and human evaluation of the produced labels and explanations. Our evaluation of NILE also supports the claim that accurate systems capable of providing testable explanations of their decisions can be designed. We discuss the faithfulness of NILE's explanations in terms of sensitivity of the decisions to the corresponding explanations. We argue that explicit evaluation of faithfulness, in addition to label and explanation accuracy, is an important step in evaluating model's explanations. Further, we demonstrate that task-specific probes are necessary to establish such sensitivity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:oldoQiaHq2UC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Word embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings. SynGCN utilizes the dependency context of a word without increasing the vocabulary size. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both models available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:eFf2swCANGcC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Open Information Extraction (OpenIE) methods extract (noun phrase, relation phrase, noun phrase) triples from text, resulting in the construction of large Open Knowledge Bases (Open KBs). The noun phrases (NPs) and relation phrases in such Open KBs are not canonicalized, leading to the storage of redundant and ambiguous facts. Recent research has posed canonicalization of Open KBs as clustering over manually-defined feature spaces. Manual feature engineering is expensive and often sub-optimal. In order to overcome this challenge, we propose Canonicalization using Embeddings and Side Information (CESI) -- a novel approach which performs canonicalization over learned embeddings of Open KBs. CESI extends recent advances in KB embedding by incorporating relevant NP and relation phrase side information in a principled manner. Through extensive experiments on multiple real-world datasets …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:CMvovTBb2okC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Inducing diversity in the task of paraphrasing is an important problem in NLP with applications in data augmentation and conversational agents. Previous paraphrasing approaches have mainly focused on the issue of generating semantically similar paraphrases while paying little attention towards diversity. In fact, most of the methods rely solely on top-k beam search sequences to obtain a set of paraphrases. The resulting set, however, contains many structurally similar sentences. In this work, we focus on the task of obtaining highly diverse paraphrases while not compromising on paraphrasing quality. We provide a novel formulation of the problem in terms of monotone submodular function maximization, specifically targeted towards the task of paraphrasing. Additionally, we demonstrate the effectiveness of our method for data augmentation on multiple tasks such as intent classification and paraphrase recognition. In order to drive further research, we have made the source code available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:S2WlVNSe3u4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Document date is essential for many important tasks, such as document retrieval, summarization, event detection, etc. While existing approaches for these tasks assume accurate knowledge of the document date, this is not always available, especially for arbitrary documents from the Web. Document Dating is a challenging problem which requires inference over the temporal structure of the document. Prior document dating systems have largely relied on handcrafted features while ignoring such document internal structures. In this paper, we propose NeuralDater, a Graph Convolutional Network (GCN) based document dating approach which jointly exploits syntactic and temporal graph structures of document in a principled way. To the best of our knowledge, this is the first application of deep learning for the problem of document dating. Through extensive experiments on real-world datasets, we find that NeuralDater significantly outperforms state-of-the-art baseline by 19% absolute (45% relative) accuracy points.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:Nw_I7GeUguwC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by providing temporal scopes (start and end times) on each edge in the KG. While Question Answering over KG (KGQA) has received some attention from the research community, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored area. Lack of broad coverage datasets has been another factor limiting progress in this area. We address this challenge by presenting CRONQUESTIONS, the largest known Temporal KGQA dataset, clearly stratified into buckets of structural complexity. CRONQUESTIONS expands the only known previous dataset by a factor of 340x. We find that various state-of-the-art KGQA methods fall far short of the desired performance on this new dataset. In response, we also propose CRONKGQA, a transformer-based solution that exploits recent advances in Temporal KG embeddings, and achieves performance superior to all baselines, with an increase of 120% in accuracy over the next best performing method. Through extensive experiments, we give detailed insights into the workings of CRONKGQA, as well as situations where significant further improvements appear possible. In addition to the dataset, we have released our code as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:Nnq8S6OXqDYC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Given a sentence (e.g., “I like mangoes”) and a constraint (e.g., sentiment flip), the goal of controlled text generation is to produce a sentence that adapts the input sentence to meet the requirements of the constraint (e.g., “I hate mangoes”). Going beyond such simple constraints, recent work has started exploring the incorporation of complex syntactic-guidance as constraints in the task of controlled paraphrase generation. In these methods, syntactic-guidance is sourced from a separate exemplar sentence. However, these prior works have only utilized limited syntactic information available in the parse tree of the exemplar sentence. We address this limitation in the paper and propose Syntax Guided Controlled Paraphraser (SGCP), an end-to-end framework for syntactic paraphrase generation. We find …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:5LPo_wSKItgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Entity Linking (EL) systems aim to automatically map mentions of an entity in text to the corresponding entity in a Knowledge Graph (KG). Degree of connectivity of an entity in the KG directly affects an EL system’s ability to correctly link mentions in text to the entity in KG. This causes many EL systems to perform well for entities well connected to other entities in KG, bringing into focus the role of KG density in EL. In this paper, we propose Entity Linking using Densified Knowledge Graphs (ELDEN). ELDEN is an EL system which first densifies the KG with co-occurrence statistics from a large text corpus, and then uses the densified KG to train entity embeddings. Entity similarity measured using these trained entity embeddings result in improved EL. ELDEN outperforms state-of-the-art EL system on benchmark datasets. Due to such densification, ELDEN performs well for sparsely connected entities in the KG too. ELDEN’s approach is simple, yet effective. We have made ELDEN’s code and data publicly available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:hefNtdE4IMkC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Knowledge Graph (KG) embedding has emerged as a very active area of research over the last few years, resulting in the development of several embedding methods. These KG embedding methods represent KG entities and relations as vectors in a high-dimensional space. Despite this popularity and effectiveness of KG embeddings in various tasks (eg, link prediction), geometric understanding of such embeddings (ie, arrangement of entity and relation vectors in vector space) is unexplored–we fill this gap in the paper. We initiate a study to analyze the geometry of KG embeddings and correlate it with task performance and other hyperparameters. To the best of our knowledge, this is the first study of its kind. Through extensive experiments on real-world datasets, we discover several insights. For example, we find that there are sharp differences between the geometry of embeddings learnt by different classes of KG embeddings methods. We hope that this initial study will inspire other follow-up research on this important but unexplored problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:Oo1CbQkBAzEC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Blind estimation of local (per-residue) and global (for the whole structure) accuracies in protein structure models is an essential step in many protein modeling applications. With the recent developments in deep-learning, single-model quality assessment methods have been also advanced, primarily through the use of 2D and 3D convolutional deep neural networks. Here we explore an alternative approach and train a graph convolutional network with nodes representing protein atoms and edges connecting spatially adjacent atom pairs on the dataset Rosetta-300k which contains a set of 300k conformations from 2,897 proteins. We show that our proposed architecture, ProteinGCN, is capable of predicting both local and global accuracies in protein models at state-of-the-art levels. Further, the number of free parameters in ProteinGCN is almost 1-2 orders of magnitude smaller compared to the 3D convolutional networks proposed earlier. We provide the source code of our work to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:i91s68tWr-MC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Predicting properties of nodes in a graph is an important problem with applications in a variety of domains. Graph-based Semi Supervised Learning (SSL) methods aim to address this problem by labeling a small subset of the nodes as seeds, and then utilizing the graph structure to predict label scores for the rest of the nodes in the graph. Recently, Graph Convolutional Networks (GCNs) have achieved impressive performance on the graph-based SSL task. In addition to label scores, it is also desirable to have confidence scores associated with them. Unfortunately, confidence estimation in the context of GCN has not been previously explored. We fill this important gap in this paper and propose ConfGCN, which estimates labels scores along with their confidences jointly in GCN-based setting. ConfGCN uses these estimated confidences to determine the influence of one node on another during neighborhood aggregation, thereby acquiring anisotropic capabilities. Through extensive analysis and experiments on standard benchmarks, we find that ConfGCN is able to outperform state-of-the-art baselines. We have made ConfGCN’s source code available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:3vbIHxFL9FgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Developing accurate, transferable and computationally inexpensive machine learning models can rapidly accelerate the discovery and development of new materials. Some of the major challenges involved in developing such models are, (i) limited availability of materials data as compared to other fields, (ii) lack of universal descriptor of materials to predict its various properties. The limited availability of materials data can be addressed through transfer learning, while the generic representation was recently addressed by Xie and Grossman [1], where they developed a crystal graph convolutional neural network (CGCNN) that provides a unified representation of crystals. In this work, we develop a new model (MT-CGCNN) by integrating CGCNN with transfer learning based on multi-task (MT) learning. We demonstrate the effectiveness of MT-CGCNN by simultaneous prediction of various material properties such as Formation Energy, Band Gap and Fermi Energy for a wide range of inorganic crystals (46774 materials). MT-CGCNN is able to reduce the test error when employed on correlated properties by upto 8%. The model prediction has lower test error compared to CGCNN, even when the training data is reduced by 10%. We also demonstrate our model's better performance through prediction of end user scenario related to metal/non-metal classification. These results encourage further development of machine learning approaches which leverage multi-task learning to address the aforementioned challenges in the discovery of new materials. We make MT-CGCNN's source code available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:T8_be82Iz5gC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Link prediction insimple graphs is a fundamental problem in which new links between vertices are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among vertices that go beyond pairwise associations. For example, in a chemical reaction, relationship among the reactants and products is inherently higher-order. Additionally, there is a need to represent the direction from reactants to products. Hypergraphs provide a natural way to represent such complex higher-order relationships. Graph Convolutional Network (GCN) has recently emerged as a powerful deep learning-based approach for link prediction over simple graphs. However, their suitability for link prediction in hypergraphs is underexplored -- we fill this gap in this paper and propose Neural Hyperlink Predictor (NHP). NHP adapts GCNs for link prediction in hypergraphs …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:adHtZc2wMuEC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Low rank tensor completion is a well studied problem and has applications in various fields. However, in many real world applications the data is dynamic, i.e., new data arrives at different time intervals. As a result, the tensors used to represent the data grow in size. Besides the tensors, in many real world scenarios, side information is also available in the form of matrices which also grow in size with time. The problem of predicting missing values in the dynamically growing tensor is called dynamic tensor completion. Most of the previous work in dynamic tensor completion make an assumption that the tensor grows only in one mode. To the best of our Knowledge, there is no previous work which incorporates side information with dynamic tensor completion. We bridge this gap in this paper by proposing a dynamic tensor completion framework called Side Information infused Incremental Tensor Analysis (SIITA …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:rqnDXT1GswoC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Open Information Extraction (OpenIE) methods are effective at extracting (noun phrase, relation phrase, noun phrase) triples from text, eg,(Barack Obama, took birth in, Honolulu). Organization of such triples in the form of a graph with noun phrases (NPs) as nodes and relation phrases (RPs) as edges results in the construction of Open Knowledge Graphs (OpenKGs). In order to use such OpenKGs in downstream tasks, it is often desirable to learn embeddings of the NPs and RPs present in the graph. Even though several Knowledge Graph (KG) embedding methods have been recently proposed, all of those methods have targeted Ontological KGs, as opposed to OpenKGs. Straightforward application of existing Ontological KG embedding methods to OpenKGs is challenging, as unlike Ontological KGs, OpenKGs are not canonicalized, ie, a real-world entity may be represented using multiple nodes in the OpenKG, with each node corresponding to a different NP referring to the entity. For example, nodes with labels Barack Obama, Obama, and President Obama may refer to the same real-world entity Barack Obama. Even though canonicalization of OpenKGs has received some attention lately, output of such methods has not been used to improve OpenKG embed-dings. We fill this gap in the paper and propose Canonicalization-infused Representations (CaRe) for OpenKGs. Through extensive experiments, we observe that CaRe enables existing models to adapt to the challenges in OpenKGs and achieve substantial improvements for the link prediction task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:1EqfMoDn7-AC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Generalized canonical correlation analysis (GCCA) integrates information from data samples that are acquired at multiple feature spaces (or `views') to produce low-dimensional representations-which is an extension of classical two-view CCA. Since the 1960s, (G)CCA has attracted much attention in statistics, machine learning, and data mining because of its importance in data analytics. Despite these efforts, the existing GCCA algorithms have serious complexity issues. The memory and computational complexities of the existing algorithms usually grow as a quadratic and cubic function of the problem dimension (the number of samples / features), respectively-e.g., handling views with ≈1,000 features using such algorithms already occupies ≈10 6 memory and the periteration complexity is ≈10 9 flops-which makes it hard to push these methods much further. To circumvent such difficulties, we first propose a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:Gpwnp1kGG20C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"The ability to learn from limited data, or few-shot learning, is a desirable and often critical requirement for NLP systems. While many existing methods do poorly at learning from a handful of examples, large pretrained language models have recently been shown to be efficient few-shot learners. One approach to few-shot learning, which does not require finetuning of model parameters, is to augment the language model's input with priming text which is typically constructed using task specific descriptions and examples. In this work, we further explore priming-based few-shot learning, with focus on using examples as prompts. We show that presenting examples in the right order is key for generalization. We introduce PERO (Prompting with Examples in the Right Order), where we formulate few-shot learning as search over the set of permutations of the training examples. We show that PERO can learn to generalize efficiently using as few as 10 examples, in contrast to existing approaches. While the newline token is a natural choice for separating the examples in the prompt, we show that learning a new separator token can potentially provide further gains in performance. We demonstrate the effectiveness of the proposed method on the tasks of sentiment classification, natural language inference and fact retrieval. Finally, we analyze the learned prompts to reveal novel insights, including the idea that two training examples in the right order alone can provide competitive performance for sentiment classification and natural language inference.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:GJVTs2krol4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Simple weighted averaging of word vectors often yields effective representations for sentences which outperform sophisticated seq2seq neural models in many tasks. While it is desirable to use the same method to represent documents as well, unfortunately, the effectiveness is lost when representing long documents involving multiple sentences. One of the key reasons is that a longer document is likely to contain words from many different topics; hence, creating a single vector while ignoring all the topical structure is unlikely to yield an effective document representation. This problem is less acute in single sentences and other short text fragments where the presence of a single topic is most likely. To alleviate this problem, we present P-SIF, a partitioned word averaging model to represent long documents. P-SIF retains the simplicity of simple weighted word averaging while taking a document's topical structure into account. In particular, P-SIF learns topic-specific vectors from a document and finally concatenates them all to represent the overall document. We provide theoretical justifications on the correctness of P-SIF. Through a comprehensive set of experiments, we demonstrate P-SIF's effectiveness compared to simple weighted averaging and many other baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:NU-BerS4NX4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"This tutorial aims to introduce recent advances in graph-based deep learning techniques such as Graph Convolutional Networks (GCNs) for Natural Language Processing (NLP). It provides a brief introduction to deep learning methods on non-Euclidean domains such as graphs and justifies their relevance in NLP. It then covers recent advances in applying graph-based deep learning methods for various NLP tasks, such as semantic role labeling, machine translation, relationship extraction, and many more.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:M0j1y4EgrScC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Robots that can manipulate objects in unstructured environments and collaborate with humans can benefit immensely by understanding natural language. We propose a pipelined architecture of two stages to perform spatial reasoning on the text input. All the objects in the scene are first localized, and then the instruction for the robot in natural language and the localized co-ordinates are mapped to the start and end co-ordinates corresponding to the locations where the robot must pick up and place the object respectively. We show that representing the localized objects by quantizing their positions to a binary grid is preferable to representing them as a list of 2D co-ordinates. We also show that attention improves generalization and can overcome biases in the dataset. The proposed method is used to pick-and-place playing cards using a robot arm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:LWqeokA2EBkC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Efficient representation of text documents is an important building block in many NLP tasks. Research on long text categorization has shown that simple weighted averaging of word vectors for sentence representation often outperforms more sophisticated neural models. Recently proposed Sparse Composite Document Vector (SCDV) (Mekala et. al, 2017) extends this approach from sentences to documents using soft clustering over word vectors. However, SCDV disregards the multi-sense nature of words, and it also suffers from the curse of higher dimensionality. In this work, we address these shortcomings and propose SCDV-MS. SCDV-MS utilizes multi-sense word embeddings and learns a lower dimensional manifold. Through extensive experiments on multiple real-world datasets, we show that SCDV-MS embeddings outperform previous state-of-the-art embeddings on multi-class and multi-label text categorization tasks. Furthermore, SCDV-MS embeddings are more efficient than SCDV in terms of time and space complexity on textual classification tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:VnuxuLaQPLMC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"What is the relationship between sentence representations learned by deep recurrent models against those encoded by the brain? Is there any correspondence between hidden layers of these recurrent models and brain regions when processing sentences? Can these deep models be used to synthesize brain data which can then be utilized in other extrinsic tasks? We investigate these questions using sentences with simple syntax and semantics (e.g., The bone was eaten by the dog.). We consider multiple neural network architectures, including recently proposed ELMo and BERT. We use magnetoencephalography (MEG) brain recording data collected from human subjects when they were reading these simple sentences. Overall, we find that BERT's activations correlate the best with MEG brain data. We also find that the deep network representation can be used to generate brain data from new sentences to augment existing brain data. To the best of our knowledge, this is the first work showing that the MEG brain recording when reading a word in a sentence can be used to distinguish earlier words in the sentence. Our exploration is also the first to use deep neural network representations to generate synthetic brain data and to show that it helps in improving subsequent stimuli decoding task accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:sJK75vZXtG0C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Recent research in multilingual language models (LM) has demonstrated their ability to effectively handle multiple languages in a single model. This holds promise for low web-resource languages (LRL) as multilingual models can enable transfer of supervision from high resource languages to LRLs. However, incorporating a new language in an LM still remains a challenge, particularly for languages with limited corpora and in unseen scripts. In this paper we argue that relatedness among languages in a language family may be exploited to overcome some of the corpora limitations of LRLs, and propose RelateLM. We focus on Indian languages, and exploit relatedness along two dimensions: (1) script (since many Indic scripts originated from the Brahmic script), and (2) sentence structure. RelateLM uses transliteration to convert the unseen script of limited LRL text into the script of a Related Prominent Language (RPL) (Hindi in our case). While exploiting similar sentence structures, RelateLM utilizes readily available bilingual dictionaries to pseudo translate RPL text into LRL corpora. Experiments on multiple real-world benchmark datasets provide validation to our hypothesis that using a related language as pivot, along with transliteration and pseudo translation based data augmentation, can be an effective way to adapt LMs for LRLs, rather than direct training or pivoting through English.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:WMtz-WDmgKQC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Semi-supervised learning on graph structured data has received significant attention with the recent introduction of Graph Convolution Networks (GCN). While traditional methods have focused on optimizing a loss augmented with Laplacian regularization framework, GCNs perform an implicit Laplacian type regularization to capture local graph structure. In this work, we propose Lovasz Convolutional Network (LCNs) which are capable of incorporating global graph properties. LCNs achieve this by utilizing Lovasz’s orthonormal embeddings of the nodes. We analyse local and global properties of graphs and demonstrate settings where LCNs tend to work better than GCNs. We validate the proposed method on standard random graph models such as stochastic block models (SBM) and certain community structure based graphs where LCNs outperform GCNs and learn more intuitive embeddings. We also perform extensive binary and multi-class classification experiments on real world datasets to demonstrate LCN’s effectiveness. In addition to simple graphs, we also demonstrate the use of LCNs on hyper-graphs by identifying settings where they are expected to work better than GCNs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:j5aT6aphRxQC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Link prediction in simple graphs is a fundamental problem in which new links between nodes are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among nodes which go beyond pairwise associations. For example, in a chemical reaction, relationship among the reactants and products is inherently higher-order. Additionally, there is need to represent the direction from reactants to products. Hypergraphs provide a natural way to represent such complex higher-order relationships. Even though Graph Convolutional Networks (GCN) have recently emerged as a powerful deep learning-based approach for link prediction over simple graphs, their suitability for link prediction in hypergraphs is unexplored -- we fill this gap in this paper and propose Neural Hyperlink Predictor (NHP). NHP adapts GCNs for link prediction in hypergraphs. We propose two variants of NHP --NHP-U and NHP-D -- for link prediction over undirected and directed hypergraphs, respectively. To the best of our knowledge, NHP-D is the first method for link prediction over directed hypergraphs. Through extensive experiments on multiple real-world datasets, we show NHP's effectiveness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:rFyVMFCKTwsC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"While recent work on multilingual language models has demonstrated their capacity for cross-lingual zero-shot transfer on downstream tasks, there is a lack of consensus in the community as to what shared properties between languages enable such transfer. Analyses involving pairs of natural languages are often inconclusive and contradictory since languages simultaneously differ in many linguistic aspects. In this paper, we perform a large-scale empirical study to isolate the effects of various linguistic properties by measuring zero-shot transfer between four diverse natural languages and their counterparts constructed by modifying aspects such as the script, word order, and syntax. Among other things, our experiments show that the absence of sub-word overlap significantly affects zero-shot transfer when languages differ in their word order, and there is a strong correlation between transfer performance and word embedding alignment between languages (e.g., R=0.94 on the task of NLI). Our results call for focus in multilingual models on explicitly improving word embedding alignment between languages rather than relying on its implicit emergence.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:IHkkN1K1AlAC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",47,"Knowledge of the creation date of documents facilitates several tasks such as summarization, event extraction, temporally focused information extraction etc. Unfortunately, for most of the documents on the Web, the time-stamp metadata is either missing or can't be trusted. Thus, predicting creation time from document content itself is an important task. In this paper, we propose Attentive Deep Document Dater (AD3), an attention-based neural document dating system which utilizes both context and temporal information in documents in a flexible and principled manner. We perform extensive experimentation on multiple real-world datasets to demonstrate the effectiveness of AD3 over neural and non-neural baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&citation_for_view=CIZwXAcAAAAJ:17ZO-CJnx_8C,https://parthatalukdar.github.io/
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"For every event occurring in the real world, most often a sound is associated with the corresponding visual scene. Humans possess an inherent ability to automatically map the audio content with visual scenes leading to an effortless and enhanced understanding of the underlying event. This triggers an interesting question: Can this natural correspondence between video and audio, which has been diminutively explored so far, be learned by a machine and modeled jointly to localize the sound source in a visual scene? In this paper, we propose a novel algorithm that addresses the problem of localizing sound source in unconstrained videos, which uses efficient fusion and attention mechanisms. Two novel blocks namely, Audio Visual Fusion Block (AVFB) and Segment-Wise Attention Block (SWAB) have been developed for this purpose. Quantitative and qualitative evaluations show that it is feasible to use the same algorithm with minor modifications to serve the purpose of sound localization using three different types of learning: supervised, weakly supervised and unsupervised. A novel Audio Visual Triplet Gram Matrix Loss (AVTGML) has been proposed as a loss function to learn the localization in an unsupervised way. Our empirical evaluations demonstrate a significant increase in performance over the existing state-of-the-art methods, serving as a testimony to the superiority of our proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&citation_for_view=nqDmEHUAAAAJ:9LpHyFPp1DQC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Learning based on convolutional neural networks (CNNs) or deep learning has been a major research area with applications in face recognition (FR). Under degraded conditions, performance of FR algorithms severely degrade. The work presented in this paper has three contributions. First, it proposes a transfer-CNN architecture of deep learning tailor-made for domain adaptation (DA), to overcome the difference in feature distributions between the gallery and probe samples. The proposed architecture consists of three units: base convolution (BCM), transfer (TM) and linear (LM) modules. Secondly, a novel 3-stage algorithm for Mutually Exclusive Training (3-MET) based on stochastic gradient descent, has been proposed. The initial stage of 3-MET involves updating the parameters of the BCM and LM units using samples from gallery. The second stage involves updating the parameters of TM, to bridge the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&citation_for_view=nqDmEHUAAAAJ:CdxZDUztZiMC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Humans possess an innate capability of recognizing objects and their corresponding parts and confine their attention to that location in a visual scene where the object is spatially present. Recently, efforts to train machines to mimic this ability of humans in the form of weakly supervised object localization, using training labels only at the image-level, have garnered a lot of attention. Nonetheless, one of the well-known problems that most of the existing methods suffer from is localizing only the most discriminative part of an object. Such methods provide very little or no focus on other pertinent parts of the object. In this paper, we propose a novel way of scrupulously localizing objects using training with labels as for the entire image by mining information from complementary regions in an image. Primarily, we adapt to regional dropout at complementary spatial locations to create two intermediate images. With the help of a novel Channel-wise Assisted Attention Module (CAAM) coupled with a Spatial Self-Attention Module (SSAM), we parallely train our model to leverage the information from complementary image regions for excellent localization. Finally, we fuse the attention maps generated by the two classifiers using our Attention-based Fusion Loss. Several experimental studies manifest the superior performance of our proposed approach. Our method demonstrates a significant increase in localization performance over the existing state-of-the-art methods on CUB-200-2011 and ILSVRC 2016 datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&citation_for_view=nqDmEHUAAAAJ:_mQi-xiA4oYC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Scene Parsing is an important cog for modern autonomous driving systems. Most of the works in semantic segmentation pertains to day-time scenes with favourable weather and illumination conditions. In this paper, we propose a novel deep architecture, NiSeNet, that performs semantic segmentation of night scenes using a domain mapping approach of synthetic to real data. It is a dual-channel network, where we designed a Real channel using DeepLabV3+ coupled with an MSE loss to preserve the spatial information. In addition, we used an Adaptive channel reducing the domain gap between synthetic and real night images, which also complements the failures of Real channel output. Apart from the dual channel, we introduced a novel fusion scheme to fuse the outputs of two channels. In addition to that, we compiled a new dataset Urban Night Driving Dataset (UNDD); it consists of 7125 unlabelled day and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:orDZ08hpP44C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Most Face Recognition (FR) systems provide acceptable performances under controlled environments, but fail to perform well when subjected to severe degradations. The major bottle-neck occurs due to severe degradation in the image quality captured by surveillance cameras, compared to the high-quality mug-shot images used for training. In this work, we propose a deep network based on a generative adversarial network (GAN), termed LR-GAN, which helps to reconstruct realistic mugshot images from low-resolution probe samples. These synthesized but realistic (in quality) face images facilitate superior matching performance for FR. The main contribution of the paper is in the adversarial training procedure of LR-GAN to optimize a “multi-scale reconstruction loss”, based on Multi-Scale Structural Similarity Index (MS-SSIM), patch-wise mean-squared error (PMSE), modified Jensen–Shannon Divergence (JSD …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:-nhnvRiOwuoC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Human recognition in a multi‐biometric system is performed by combining biometric clues from different sources (multiple sensors, units, algorithms, samples and modalities) at different levels (sensor, feature, score, rank and decision level). Low computational complexity and adequate data for fusion make the score‐level fusion a preferable option over other levels of fusion. However, incompatibility issue prevails at this level as scores obtained from different uni‐biometric systems are disparate in nature. This disparity can be resolved by using score normalisation before fusion. This study first analysed the effect of generalised extreme value distribution‐based score normalisation technique on different fusion techniques and then proposes an efficient score fusion technique based on Dezert–Smarandache theory (DSmT). A unique blend of belief assignment and decision‐making methods in the DSmT framework is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:jU7OWUQzBzMC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Certain facial parts are salient (unique) in appearance, which substantially contribute to the holistic recognition of a subject. Occlusion of these salient parts deteriorates the performance of face recognition algorithms. In this paper, we propose a generative model to reconstruct the missing parts of the face which are under occlusion. The proposed generative model (SD-GAN) reconstructs a face preserving the illumination variation and identity of the face. A novel adversarial training algorithm has been designed for a bimodal mutually exclusive Generative Adversarial Network (GAN) model, for faster convergence. A novel adversarial ""structural"" loss function is also proposed, comprising of two components: a holistic and a local loss, characterized by SSIM and patch-wise MSE. Ablation studies on real and synthetically occluded face datasets reveal that our proposed technique outperforms the competing methods by a considerable margin, even for boosting the performance of Face Recognition.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:T8_be82Iz5gC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Face Recognition using convolutional neural networks have achieved considerable success in constrained environments in the recent past. However, the performance of these methods deteriorates in case of mismatch of training and test distributions, under classroom/surveillance scenarios. These test (probe) samples suffer from degradations such as noise, poor illumination, pose variations, occlusion, low-resolution (LR), blur as well as aliasing, when compared to the crisp, rich training (gallery) set, comprising mostly of high-resolution (HR) mugshot images captured in laboratory settings. To cope with this scenario, we propose a novel dual deep-shallow channeled generative adversarial network (D2SC-GAN) which performs supervised domain adaptation (DA) by mapping LR degraded probe samples to their corresponding HR gallery-like counterparts to perform closed-set face recognition. D2SC-GAN uses a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:kO05sadLmrgC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Facial make‐up changes the appearance of a person and significantly degrades the performance of automated face verification (FV) systems. Here, the authors propose the design of an end‐to‐end siamese convolutional neural network (SCNN) that simultaneously replicates the facial make‐up of a subject using its target image (under facial make‐up) on a query face image and verifies the identity of the query face sample either with or without make‐up. The SCNN model is designed using loss functions to deal with the variations due to make‐up. The proposed architecture can reciprocate the make‐up at appropriate locations of the face without any human interventions. Rigorous experimentations on four benchmark facial make‐up datasets reveal the efficiency of their proposed model. Ablation studies show improvement of 4% for genuine acceptance rate at 0.1% false acceptance rate and reduction of equal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:1yWc8FF-_SYC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Pose-Invariant Face Recognition (PIFR) has been a serious challenge in the general field of face recognition (FR). The performance of face recognition algorithms deteriorate due to various degradations such as pose, illuminaton, occlusions, blur, noise, aliasing, etc. In this paper, we deal with the problem of 3D pose variation of a face. for that we design and propose PosIX Generative Adversarial Network (PosIX-GAN) that has been trained to generate a set of nice (high quality) face images with 9 different pose variations, when provided with a face image in any arbitrary pose as input. The discriminator of the GAN has also been trained to perform the task of face recognition along with the job of discriminating between real and generated (fake) images. Results when evaluated using two benchmark datasets, reveal the superior performance of PosIX-GAN over state-of-the-art shallow as well as deep learning methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:mWEH9CqjF64C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"This paper proposes a novel network architecture for video frame prediction based on Graph Convolutional Neural Networks (GCNN). Most recent methods often fail in situations where multiple close-by objects at different scales move in random directions with variable speeds. We overcome this by modeling the scene as a space-time graph with intermediate features from the pixels (or a local region) as vertices and the relationships among them as edges. Our main contribution lies within posing the frame generation problem with our proposed space-time graph, which enables the network to learn the spatial as well as temporal inter-pixel relationships independent of each other, thus making the system invariant to velocity differences among the moving objects present in the scene. Moreover, we also propose a novel directional attention mechanism for the graph based model to efficiently learn a significance score …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:_tF6a-HnqWAC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Context is an important aspect for accurate saliency detection. However, the question of how to formally model image context within saliency detection frameworks is still an open problem. Recent saliency detection models designed using complex Deep Neural Networks to extract robust features, however often fail to select the right contextual features. These methods generally utilize physical attributes of objects for generating final saliency maps, but ignores scene contextual information. In this paper, we overcome such limitation using (i) a proposed novel end-to-end framework with a Contextual Unit (CTU) module that models the scene contextual information to give efficient saliency maps with the help of Convolutional GRU (Conv-GRU). This is the first work reported so far that utilizes Conv-GRU to generate image saliency maps. In addition, (ii) we propose a novel way of using the Conv-GRU that helps to refine …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:7VEv-pLvLSsC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Generative models aiming to generate content from noise have achieved high-fidelity synthesis for image data. However, obtaining comparable performance in the field of unconditional video generation still remains challenging. In this work, we propose a recurrent GAN architecture to model the high-dimensional video data distribution. Recurrent networks by design are able to generate complex, long sequences in an autoregressive fashion. However, the standard LSTM unit for videos (ConvLSTM) is not ideally suited for the task of unconditional video generation. Therefore, we propose a simple yet effective LSTM variant called as TransConv LSTM (TC-LSTM) by modulating the conventional ConvLSTM to have a transpose convolutional structure in input-to-state transitions. This enables the network to model both spatial and temporal relationships across layers simultaneously inside the TC-LSTM unit. TC-LSTM unit acts as a building block of our generator. Extensive quantitative and qualitative analysis shows that RV-GAN outperforms state-of-the-art methods by a significant margin on Moving MNIST, MUG, Weizmann and UCF101 datasets. Additionally, owing to the recurrent structure, our method is able to generate high-quality videos, up to 2 times longer (32 frames) than training videos at inference time. Further analysis confirms that the proposed architecture is generic and can be easily adapted to other tasks like class-conditional video synthesis and text-to-video synthesis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:IHkkN1K1AlAC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Predicting future frames of a video sequence has been a problem of high interest in the field of Computer Vision as it caters to a multitude of applications. The ability to predict, anticipate and reason about future events is the essence of intelligence and one of the main goals of decision-making systems such as human-machine interaction, robot navigation and autonomous driving. However, the challenge lies in the ambiguous nature of the problem as there may be multiple future sequences possible for the same input video shot. A naively designed model averages multiple possible futures into a single blurry prediction. Recently, two distinct approaches have attempted to address this problem as: (a) use of latent variable models that represent underlying stochasticity and (b) adversarially trained models that aim to produce sharper images. A latent variable model often struggles to produce realistic results, while an adversarially trained model underutilizes latent variables and thus fails to produce diverse predictions. These methods have revealed complementary strengths and weaknesses. Combining the two approaches produces predictions that appear more realistic and better cover the range of plausible futures. This forms the basis and objective of study in this project work. In this paper, we proposed a novel multi-scale architecture combining both approaches. We validate our proposed model through a series of experiments and empirical evaluations on Moving MNIST, UCF101, and Penn Action datasets. Our method outperforms the results obtained using the baseline methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:N6_Y7JlWxwsC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"This paper presents feature reconstruction based approach using Generative Adversarial Networks (GAN) to solve the problem of predicting future frames from natural video scenes. Recent GAN based methods often generate blurry outcomes and fail miserably in case of long-range prediction. Our proposed method incorporates an intermediate feature generating GAN to minimize the disparity between the ground truth and predicted outputs. For this, we propose two novel objective functions: (a) Locally Guided Gram Loss (LGGL) and (b) Multi-Scale Correlation Loss (MSCL) to further enhance the quality of the predicted frames. LGGL aides the feature generating GAN to maximize the similarity between the intermediate features of the ground-truth and the network output by constructing Gram matrices from locally extracted patches over several levels of the generator. MSCL incorporates a correlation based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:m92CDrhVnKEC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"This paper proposes a feature reconstruction based approach using pixel-graph and Generative Adversarial Networks (GAN) for solving the problem of synthesizing future frames from video scenes. Recent methods of frame synthesis often generate blurry outcomes in case of long-range prediction and scenes involving multiple objects moving at different velocities due to their holistic approach. Our proposed method introduces a novel pixel-graph based context aggregation layer (PixGraph) which efficiently captures long range dependencies. PixGraph incorporates a weighting scheme through which the internal features of each pixel (or a group of neighboring pixels) can be modeled independently of the others, thus handling the issue of separate objects moving in different directions and with very dissimilar speed. We also introduce a novel objective function, the Locally Guided Gram Loss (LGGL), which aides the GAN based model to maximize the similarity between the intermediate features of the ground-truth and the network output by constructing Gram matrices from locally extracted patches over several levels of the generator. Our proposed model is end-to-end trainable and exhibits superior performance compared to the state-of-the-art on four realworld benchmark video datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:69ZgNCALVd0C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Image Stitching is a hard task to solve in the presence of large parallax in the images. Specifically, for a sequence of frames from unconstrained videos which are considerably shaky, recent works fail to align such a sequence of images accurately. The proposed method “GreenWarps” aims to accurately align frames/images with large parallax. The method consists of two novel stages, namely, Prewarping and Diffeomorphic Mesh warping. The first stage warps unaligned image to the reference image using Green Coordinates. The second stage of the model refines the alignment by using a demon-based diffeomorphic warping method for mesh deformation termed “DiffeoMeshes”. The warping is performed using Green Coordinates in both the stages without the assumption of any motion model. The combination of the two stages provide accurate alignment of the images. Experiments were performed on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:NZNkWSpQBv0C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Most of the visual scene understanding tasks in the field of computer vision involve the identification of the objects present in the scene. Image regions like hideouts, turns, and other obscured regions of the scene also contain crucial information, for specific surveillance tasks. In this work, we propose an intelligent visual aid for the identification of such locations in an image, which has either the potential to create an imminent threat from an adversary or appear as the target zones needing further investigation to identify concealed objects. Covert places (CGL) for hiding behind an occluding object are concealed 3D locations, not usually detectable from the viewpoint (camera). Hence, this involves delineating specific image regions around the outer boundary of the projections of the occluding objects, as places to be accessed around the potential hideouts. CGL detection finds applications in military counter …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:htyGaKyDgHMC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Learning based on convolutional neural networks (CNNs) or deep learning has been a major research area with applications in face recognition (FR). However, performances of algorithms designed for FR are unsatisfactory when surveillance conditions severely degrade the test probes. The work presented in this paper has three contributions. First, it proposes a novel adaptive-CNN architecture of deep learning refurbished for domain adaptation (DA), to overcome the difference in feature distributions between the gallery and probe samples. The proposed architecture consists of three components: feature (FM), adaptive (AM) and classification (CM) modules. Secondly, a novel 2-stage algorithm for Mutually Exclusive Training (2-MET) based on stochastic gradient descent, has been proposed. The final stage of training in 2-MET freezes the layers of the FM and CM, while updating (tuning) only the parameters of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:DkZNVXde3BIC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"There is a need in modern neuroscience for accurate and automated image processing techniques for analyzing the large volume of neuroanatomical imaging data. Even at light microscopic levels, imaging mouse brains produces individual data volumes in the TerraByte range. A fundamental task involves the detection and quantification of objects of a given type, eg neuronal nuclei or somata, in brain scan dataset. Traditionally this quantification has been performed by human visual inspection with high accuracy, that is not scalable. When modern automated CNN and SVM-based methods are used to solve this classification problem, they achieve accuracy levels that range between 85–92%. However, higher rates of precision and recall that are close to that of human performance are necessary. In this paper, we describe an unsupervised, iterative algorithm, which provides a high performance for a specific problem of detecting Green Fluorescent Protein labeled nuclei in 2D scans of mouse brains. The algorithm judiciously combines classical computer vision techniques and is focused on the complex problem of decomposing strong overlapped objects of interest. Our proposed technique uses feature detection methods on ridge lines over distance transformation of the image and an arc based iterative spatial-filling method to solve the problem. We demonstrate our results on mouse brain dataset of Gigabyte resolution and compare it with manual annotation of the brains. Our results show that an aptly designed CV algorithm with classical feature extractors when tailored to this problem of interest achieves near-ideal human-like performance …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:wvYxNZNCP7wC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",19,"Image Stitching is a hard task to solve in the presence of large parallax in video frames. In many cases, video frames shot using hand-held cameras have low resolution, blur and large parallax errors. Most recent works fail to align such a sequence of images accurately. The proposed method aims to accurately align image frames, by employing a novel demon-based, edge-preserving diffeomorphic registration for image stitching, termed as “DiffeoWarps”. The first stage aligns the images globally using a mesh-based perspective (homography) transformation. At the second stage, an alternating method of minimization of correspondence energy and TV-regularization improves the alignment. The “diffeowarped” images are then blended to obtain good quality stitched results. We experimented on two standard datasets as well as on a dataset comprising of 10 sets of images/frames collected from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&citation_for_view=nqDmEHUAAAAJ:1DsIQWDZLl8C,http://www.cse.iitm.ac.in/~sdas
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"First responders, a critical lifeline of any society, often find themselves in precarious situations. The ability to track them real-time in unknown indoor environments, would significantly contributes to the success of their mission as well as their safety. In this work, we present the design, implementation and evaluation of TrackIO—a system capable of accurately localizing and tracking mobile responders realtime in large indoor environments. TrackIO leverages the mobile virtual infrastructure offered by unmanned aerial vehicles (UAVs), coupled with the balanced penetration-accuracy tradeoff offered by ultra-wideband (UWB), to accomplish this objective directly from outside, without relying on access to any indoor infrastructure. Towards a practical system, TrackIO incorporates four novel mechanisms in its design that address key challenges to enable tracking responders (i) who are mobile with potentially non-uniform velocities (eg during turns),(ii) deep indoors with challenged reachability,(iii) in real-time even for a large network, and (iv) with high accuracy even when impacted by UAV’s position error. TrackIO’s real-world performance reveals that it can track static nodes with a median accuracy of about 1–1.5 m and mobile (even running) nodes with a median accuracy of 2–2.5 m in large buildings in real-time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&citation_for_view=xKrkM1EAAAAJ:5ugPr518TE4C,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"We envision a flexible, dynamic airborne LTE infrastructure built upon Unmanned Autonomous Vehicles (UAVs) that will provide on-demand, on-time, network access, anywhere. In this paper, we design, implement and evaluate SkyRAN, a self-organizing UAV-based LTE RAN (Radio Access Network) that is a key component of this UAV LTE infrastructure network. SkyRAN determines the UAV's operating position in 3D airspace so as to optimize connectivity to all the UEs on the ground. It realizes this by overcoming various challenges in constructing and maintaining radio environment maps to UEs that guide the UAV's position in real-time. SkyRAN is designed to be scalable in that it can be quickly deployed to provide efficient connectivity even over a larger area. It is adaptive in that it reacts to changes in the terrain and UE mobility, to maximize LTE coverage performance while minimizing operating overhead. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&citation_for_view=xKrkM1EAAAAJ:V3AGJWp-ZtQC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"We use a crowdsourcing approach for RF spectrum patrolling, where heterogeneous, low-cost spectrum sensors are deployed widely and are tasked with detecting unauthorized transmissions in a collaborative fashion while consuming only a limited amount of resources. We pose this as a collaborative signal detection problem where the individual sensor's detection performance may vary widely based on their respective hardware or software configurations, but are hard to model using traditional approaches. Still an optimal subset of sensors and their configurations must be chosen to maximize the overall detection performance subject to given resource (cost) limitations. We present the challenges of this problem in crowdsourced settings and present a set of methods to address them. The proposed methods use data-driven approaches to model individual sensors and develops mechanisms for sensor selection …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&citation_for_view=xKrkM1EAAAAJ:J-pR_7NvFogC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"Un-manned aerial vehicle (UAVs) have the potential to change the landscape of wide-area wireless connectivity by bringing them to areas where connectivity was sparing or non-existent (e.g. rural areas) or has been compromised due to disasters. While Google's Project Loon and Facebook's Project Aquila are examples of high-altitude, long-endurance UAV-based connectivity efforts in this direction, the telecom operators (e.g. AT&T and Verizon) have been exploring low-altitude UAV-based LTE solutions for on-demand deployments. Understandably, these projects are in their early stages and face formidable challenges in their realization and deployment. The goal of this document is to expose the reader to both the challenges as well as the potential offered by these unconventional connectivity solutions. We aim to explore the end-to-end design of such UAV-based connectivity networks particularly in the context of low-altitude UAV networks providing LTE connectivity. Specifically, we aim to highlight the challenges that span across multiple layers (access, core network, and backhaul) in an inter-twined manner as well as the richness and complexity of the design space itself. To help interested readers navigate this complex design space towards a solution, we also articulate the overview of one such end-to-end design, namely SkyLiTE-- a self-organizing network of low-altitude UAVs that provide optimized LTE connectivity in a desired region.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&citation_for_view=xKrkM1EAAAAJ:mvPsJ3kp5DgC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"We use a crowdsourcing approach for RF spectrum patrolling, where heterogeneous, low-cost spectrum sensors are deployed widely and are tasked with detecting unauthorized transmissions while consuming only a limited amount of resources. We pose this as a signal detection problem where the individual sensor's detection performance may vary widely based on their respective hardware or software configurations, but are hard to model using traditional approaches. Still an optimal subset of sensors and their configurations must be chosen to maximize the overall detection performance subject to given resource (cost) limitations. We present the challenges of this problem in crowdsourced settings and propose a set of methods to address them. These methods use data-driven approaches to model individual sensors and exploit mechanisms for sensor selection and fusion while accounting for their correlated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:WA5NYHcadZ8C,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"Shared spectrum systems is an emerging paradigm to improve spectrum utilization and thus address the unabated increase in mobile data consumption. The paradigm allows the “unused” spectrum bands of licensed Primary Users (PUs) to be shared with Secondary Users (SUs), without causing any harmful interference to the PUs. Allocation of spectrum to the SUs is done based on spectrum availability at the SUs' locations; such allocation of spectrum is greatly facilitated by spectrum occupancy maps. In this work, we address the problem of creating spectrum occupancy maps from spectrum occupancy data over a large number of instants, in the challenging scenario of dynamically (temporally) changing spectrum occupancy due to intermittent transmission of primary users. The problem is particularly challenging when the available occupancy data is very sparse spatially, i.e., only very few locations report sensing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:t6usbXjVLHcC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:_B80troHkn4C,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"Aspects of the present disclosure describe systems, methods, and structures infrastructure-free RF tracking in dynamic indoor environments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:Y5dfb0dijaUC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"Promising solutions exist today that can accurately track mobile entities indoor using visual inertial odometry in favorable visual conditions, or by leveraging fine-grained ranging (RF, ultrasonic, IR, etc.) to reference anchors. However, they are unable to directly cater to ""dynamic"" indoor environments (e.g. first responder scenarios, multi-player AR/VR gaming in everyday spaces, etc.) that are devoid of such favorable conditions. Indeed, we show that the need for ""infrastructure-free"", and robustness to ""node mobility"" and ""visual conditions"" in such environments, motivates a robust RF-based approach along with the need to address a novel and challenging variant of its infrastructure-free (i.e. peer-to-peer) localization problem that is latency-bounded - accurate tracking of mobile entities imposes a latency budget that not only affects the solution computation but also the collection of peer-to-peer ranges themselves. In this work, we present the design and deployment of DynoLoc that addresses this latency-bounded infrastructure-free RF localization problem. To this end, DynoLoc unravels the fundamental tradeoff between latency and localization accuracy and incorporates design elements that judiciously leverage the available ranging resources to adaptively estimate the joint topology of nodes, coupled with robust algorithm that maximizes the localization accuracy even in the face of practical environmental artifacts (wireless connectivity and multipath, node mobility, etc.). This allows DynoLoc to track (every second) a network of few tens of mobile entities even at speeds of 1-2 m/s with median accuracies under 1-2 m (compared to 5m+ with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:JoZmwDi-zQgC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"A computer-implemented method, system, and computer program product are provided for positioning an unmanned autonomous vehicle (UAV) in a long term evolution radio access network. The method includes acquiring, by a processor-device, a position of the UAV with a global position system. The method also includes determining, by the processor-device, physical distances from the UAV to each of a plurality of user equipment (UE) responsive to a time-of-flight from the UAV to each of the plurality of UE. The method additionally includes generating, by the processor-device, radio environment maps for each of the plurality of UE with signal-to-noise ratios (SNR) from each of the plurality of UEs to the UAV. The method further includes selecting, by the processor-device, a determined position for the UAV as a position with a minimum SNR in the REMs. The method also includes commanding the UAV to move to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:olpn-zPbct0C,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"A system for implementing a wireless communication network is provided. The system includes a plurality of unmanned aerial vehicles (UAVs) forming a wireless multi-hop mesh network constituting a backhaul. A given one of the UAVs includes a radio access network (RAN) agent configured to determine at least one UAV configuration for optimized coverage of one or more user equipment (UE) devices in a terrestrial zone, a haul agent configured to coordinate an optimization of the backhaul based at least in part on the at least one UAV configuration determined by the RAN agent, and a core agent configured to implement a distributed core architecture among the plurality of UAVs. The system further includes a controller configured to control the plurality of UAVs based on information received from at least one of the agents.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:bnK-pcrLprsC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"Methods and systems for localization within an environment include determining a topology estimate of nodes located in a dynamic indoor environment, based on distances measured between the nodes. Rigid k-core sub-graphs of the topology estimate are generated to determine relative localizations of the nodes. Relative localizations are transformed into absolute localizations to generate a map of positions of the nodes within the environment. A feature of the map is deployed to a device in the environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:PELIpwtuRlgC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"With the emergence of next generation networks, Network Traffic Classification (NTC) has seen greater importance in network management and security. Recently, Channel State Information (CSI) based WiFi sensing techniques have shown their potential for NTC applications [1], [2] as a privacy-preserving yet effective tool. As CSI could be prone to interference, this paper examines the performance of CSI-based NTC models under interference-induced adversarial attacks. Specifically, the impact of spectral allocation of the interference, underlying interfering network traffic type, and physical location of the interference are studied and quantified. We conducted experiments using off-the-shelf devices to test the NTC performance, with and without the adversarial interference attack of ping, buffered video streaming, and live video streaming network traffics. Subsequently, we found that spectral allocation of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:dTyEYWd-f8wC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"Systems and methods for localizing and tracking mobile objects are provided. A method includes determining an initial location of a node in a multi-hop network based on multi-lateration from an unmanned aerial vehicle. The method also includes applying an adaptive aperture to address a non-uniform velocity of the node based on the turn and a velocity vector. A determination whether localization for the node can be implemented using first hop nodes in the multi-hop network is made. In response to a determination that localization cannot be implemented using the first hop nodes, inertial sensor measurements associated with the node are accessed and the inertial sensor measurements are integrated with the adaptive aperture to improve localization accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:Mojj43d5GZwC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,"An example method of operating a network may include determining whether a flow is to be added to the network based on: a flow type of the flow, a link condition of the flow, and for each possible combination of flow type and link condition out of multiple flow types and multiple link conditions, the number of flows currently carried on the network that correspond to the respective combination.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:tkaPQYYpVKoC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",15,Systems and methods for localizing and tracking mobile objects are provided. The method includes determining an initial location of a node based on multi-lateration from an unmanned aerial vehicle and determining a velocity vector associated with the node based on multi-lateration. The method also includes detecting when the node turns. An adaptive aperture is applied to address a non-uniform velocity of the node based on the turn and the velocity vector.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&cstart=20&pagesize=80&citation_for_view=xKrkM1EAAAAJ:eMMeJKvmdy0C,https://www.cse.iitm.ac.in/~ayon/
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Cache timing attacks are a serious threat to the security of computing systems. It permits sensitive information, such as cryptographic keys, to leak across virtual machines and even to remote servers. Encrypted Address Cache, proposed by CEASER - a best paper candidate at MICRO 2018 - is a promising countermeasure that stymies the timing channel by employing cryptography to randomize the cache address space. The author claims strong security guarantees by providing randomization both spatially (randomizing every address) and temporally (changing the encryption key periodically). In this letter, we point out a serious flaw in their encryption approach that undermines the proposed security guarantees. Specifically, we show that the proposed Low-Latency Block Cipher, used for encryption in CEASER, is composed of only linear functions which neutralizes the spatial and temporal randomization. Thus, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&citation_for_view=ctxSQrwAAAAJ:DJbcl8HfkQkC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"The power consumption of a microprocessor is a huge channel for information leakage. While the most popular exploitation of this channel is to recover cryptographic keys from embedded devices, other applications such as mobile app fingerprinting, reverse engineering of firmware, and password recovery are growing threats. Countermeasures proposed so far are tuned to specific applications, such as crypto-implementations. They are not scalable to the large number and variety of applications that typically run on a general purpose microprocessor.In this paper, we investigate the design of a microprocessor, called PARAM with increased resistance to power based sidechannel attacks. To design PARAM, we start with identifying the most leaking modules in an open-source RISC V processor. We evaluate the leakage in these modules and then add suitable countermeasures. The countermeasures depend on the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&citation_for_view=ctxSQrwAAAAJ:LhH-TYMQEocC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Owing to the failure of Dennard’s scaling, the past decade has seen a steep growth of prominent new paradigms leveraging opportunities in computer architecture. Two technologies of interest are Posit and RISC-V. Posit was introduced in mid-2017 as a viable alternative to IEEE-754, and RISC-V provides a commercial-grade open source Instruction Set Architecture (ISA). In this article, we bring these two technologies together and propose a Configurable Posit Enabled RISC-V Core called PERI.
The article provides insights on how the Single-Precision Floating Point (“F”) extension of RISC-V can be leveraged to support posit arithmetic. We also present the implementation details of a parameterized and feature-complete posit Floating Point Unit (FPU). The configurability and the parameterization features of this unit generate optimal hardware, which caters to the accuracy and energy/area tradeoffs imposed by the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&citation_for_view=ctxSQrwAAAAJ:a3BOlSfXSfwC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Power side-channel attacks pose a serious threat to the security of embedded devices. Most available countermeasures have significant overheads resulting in the application not meeting its requirements of low-power, high-performance and small area. We propose an algorithm called Karna 11 Karna, much like Achilles from Greek mythology, was born with a shield that protected him from attacks. Similarly, Our proposed scheme, Karna protects the design from power side-channel attacks in the manufacturing phase or in other words the chip is manufactured(born) with a shield. that can be incorporated in the Electronic Design Automation (EDA) flow, in order to significantly improve the side-channel security of the device, without impacting the other device characteristics. Karna does not add additional logic but rather achieves this by first identifying vulnerable gates in the design and then reconfiguring these gates …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&citation_for_view=ctxSQrwAAAAJ:cWzG1nlazyYC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Spectrum Sharing Data Falsification (SSDF) attacks can cause heavy performance degradation to Cognitive Radio (CR) based Internet of Battlefield Things (IoBT) networks. The challenge in such networks is to handle this security problem real time, in addition to spectrum sharing. This requires a robust CR architecture and protocol that can provide integrity of the spectrum sensing data being shared between Secondary Users (SUs) for collaborative spectrum decisions in protocols like PROLEMus. We propose one such protocol called Proactive Blockchain based Spectrum Sharing (ProBLeSS) protocol which leverages a blockchain to provide security against SSDF attacks in CR-IoBT networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&citation_for_view=ctxSQrwAAAAJ:yFnVuubrUp4C,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Most cipher implementations are vulnerable to a class of cryptanalytic attacks known as fault injection attacks. To reveal the secret key, these attacks make use of faults induced at specific locations during the execution of the cipher. Countermeasures for fault injection attacks require these vulnerable locations in the implementation to be first identified and then protected. However, both these steps are difficult and error-prone and, hence, it requires considerable expertise to design efficient countermeasures. Incorrect or insufficient application of the countermeasures would cause the implementation to remain vulnerable, while inefficient application of the countermeasures could lead to significant performance penalties to achieve the desired fault-attack resistance. In this paper, we present a novel framework called SAFARI for automatically synthesizing fault-attack resistant implementations of block ciphers. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:WJVC3Jt7v1AC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"In this era of IoT devices, security is very often traded off for smaller device footprint and low power consumption. Considering the exponentially growing security threats of IoT and cyber-physical systems, it is important that these devices have built-in features that enhance security. In this paper, we present Shakti-MS, a lightweight RISC-V processor with built-in support for both temporal and spatial memory protection. At run time, Shakti-MS can detect and stymie memory misuse in C and C++ programs, with minimum runtime overheads. The solution uses a novel implementation of fat-pointers to efficiently detect misuse of pointers at runtime. Our proposal is to use stack-based cookies for crafting fat-pointers instead of having object-based identifiers. We store the fat-pointer on the stack, which eliminates the use of shadow memory space, or any table to store the pointer metadata. This reduces the storage overheads …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:IUKN3-7HHlwC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"An important aspect of malware design is to be able to evade detection. This is increasingly difficult to achieve with powerful runtime detection techniques based on behavioural and heuristic analysis. In this paper, we propose D-TIME, a new distributed threadless independent malware execution framework to evade runtime detection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:dBIO0h50nwkC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Online detection of cyber-attacks on IoT devices is extremely difficult due to the limited battery and computational power available in these devices. An alternate approach is to shrink the attack surface in order to reduce the threat of attack. This would require that the device undergo more stringent security tests before deployment. Formal verification is a promising tool that can be used to not only detect potential vulnerabilities but also provide guarantees of security. This chapter reviews several security issues that plague IoT devices such as functional correctness of implementations, programming bugs, side-channel analysis, and hardware Trojans. In each of these cases, we discuss state-of-the-art mechanisms that use formal verification tools to detect the vulnerability much before the device is deployed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:6ZxmRoH8BuwC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Fault attacks are potent physical attacks on crypto-devices. A single fault injected during encryption can reveal the cipher's secret key. In a hardware realization of an encryption algorithm, only a tiny fraction of the gates is exploitable by such an attack. Finding these vulnerable gates has been a manual and tedious task requiring considerable expertise. In this paper, we propose SOLOMON, the first automatic fault attack vulnerability detection framework for hardware designs. Given a cipher implementation, either at RTL or gate-level, SOLOMON uses formal methods to map vulnerable regions in the cipher algorithm to specific locations in the hardware thus enabling targeted countermeasures to be deployed with much lesser overheads. We demonstrate the efficacy of the SOLOMON framework using three ciphers: AES, CLEFIA, and Simon.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:mNrWkgRL2YcC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Formally bounding side-channel leakage is important to bridge the gap between theory and practice in cryptography. However, bounding side-channel leakages is difficult because leakage in a cryptosystem could be from several sources. Moreover, the amount of leakage from a source may vary depending on the implementation of the cipher and the form of attack. To formally analyze the security of a cryptosystem, it is therefore essential to consider each source of leakage independently. This paper considers data prefetching, which is used in most modern day cache memories to reduce miss penalty. We build a framework that would help computer architects theoretically gauge the impact of a data prefetcher in time-driven cache attacks early in the design phase. The framework computes leakage due to the prefetcher using a metric that is based on the Kullback–Leibler transformation. We use the framework to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:_FM0Bhl9EiAC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Composite fields are used for implementing the advanced encryption standard (AES) SBox when compact and side-channel resistant constructions are required. The prior art has investigated efficient implementations of such SBoxes for application specific integrated circuit (ASIC) platforms. On field programmable gate arrays (FPGAs); however, due to the considerably different structure compared with ASICs, these implementations perform poorly. In this letter, we revisit composite field AES SBox implementations for FPGAs. We show how design choices and optimizations can be made to better suit the granular look-up tables that are present in modern FPGAs. We investigate 2880 SBox constructions and show that about half of them are better than the state-of-the-art composite field implementation. Our best SBox implementation is 18% smaller compared with the state-of-the-art implementation on an FPGA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:mlAyqtXpCwEC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Illegal memory accesses are a serious security vulnerability that have been exploited on numerous occasions. In this letter, we present Gandalf, a compiler assisted hardware extension for the OpenRISC processor that thwarts all forms of memory-based attacks. We associate lightweight capabilities to all program variables, which are checked at run time by the hardware. Gandalf is transparent to the user and does not require significant OS modifications. Moreover, it achieves locality and incurs minimal overheads in the hardware. We demonstrate these features with a customized Linux kernel executing SPEC2006 benchmarks. To the best of our knowledge, this is the first work to demonstrate a complete solution for hardware-based memory protection schemes for embedded platforms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:NXb4pA-qfm4C,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Fault injection attacks are one of the most powerful forms of cryptanalytic attacks on ciphers. A single, precisely injected fault during the execution of a cipher like the AES, can completely reveal the key within a few milliseconds. Software implementations of ciphers, therefore, need to be thoroughly evaluated for such attacks. In recent years, automated tools have been developed to perform these evaluations. These tools either work on the cipher algorithm or on their implementations. Tools that work at the algorithm level can provide a comprehensive assessment of fault attack vulnerability for different fault attacks and with different fault models. Their application is, however, restricted because every realization of the cipher has unique vulnerabilities. On the other hand, tools that work on cipher implementations have a much wider application but are often restricted by the range of fault attacks and the number of fault models they can evaluate.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:bKqednn6t2AC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"The IT infrastructure of large organizations consists of devices and software services purchased from multiple vendors. The problem of measuring the quality of service (QoS) of each of these vendor devices (and services) is challenging since the vendors may tamper with the measurements for monetary benefits or saving debugging efforts. Existing solutions for QoS measurement in trusted environments cannot be extended for this problem since the vendors can easily circumvent them. Solutions borrowed from other areas such as client-server QoS measurement do not help either since they incur unreasonable storage and network overheads, or require extensive modifications to the packet headers. In this paper, we propose the Measuring Tape scheme, comprised of (1) a novel data structure called evidence Bloom filter (e-BF) that can be deployed at the vendor devices (and services), and (2) unique querying …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:IRz6iEL74y4C,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Illegal use of memory pointers is a serious security vulnerability. A large number of malwares exploit the spatial and temporal nature of these vulnerabilities to subvert execution or glean sensitive data from an application. Recent countermeasures attach metadata to memory pointers, which define the pointer’s capabilities. The metadata is used by the hardware to validate pointer-based memory accesses. However, recent works have considerable overheads. Further, the pointer validation is decoupled from the actual memory access. We show that this could open up vulnerabilities in multithreaded applications and introduce new vulnerabilities due to speculation in out-of-order processors.
In this article, we demonstrate that the overheads can be reduced considerably by efficient metadata management. We show that the hardware can be designed in a manner that would remain safe in multithreaded applications …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:HIFyuExEbWQC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Decentralized exchange markets leveraging blockchain have been proposed recently to provide open and equal access to traders, improve transparency and avoid single-point-of-compromise of centralized exchanges. However, they compromise on the privacy of traders with respect to their asset ownership, account balance, order details and their identity. In this paper, we present Rialto, a fully decentralized privacy-preserving exchange marketplace with support for matching trade orders, on-chain settlement and market price discovery. Rialto provides order rate and account balance confidentiality and unlinkability between traders and their trade orders, while retaining the desirable properties of a traditional marketplace like front-running resilience and market fairness. We define formal security notions of the marketplace. We perform a detailed evaluation of our solution, demonstrate that it scales well and is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:ZzlSgRqYykMC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"The emergence of distributed manufacturing ecosystems for electronic hardware involving untrusted parties has given rise to diverse trust issues. In particular, IP piracy, overproduction, and hardware Trojan attacks pose significant threats to digital design manufacturers. Watermarking has been one of the solutions employed by the semiconductor industry to overcome many of the trust issues. However, current watermarking techniques have low coverage, incur hardware overheads, and are vulnerable to removal or tampering attacks. Additionally, these watermarks cannot detect Trojan implantation attacks where an adversary alters a design for malicious purposes. We address these issues in our framework called SIGNED: Secure Lightweight Watermarking Scheme for Digital Designs. SIGNED relies on a challenge-response protocol based interrogation scheme for generating the watermark. SIGNED identifies sensitive regions in the target netlist and samples them to form a compact signature that is representative of the functional and structural characteristics of a design. We show that this signature can be used to simultaneously verify, in a robust manner, the provenance of a design, as well as any malicious alterations to it at any stage during design process. We evaluate SIGNED on the ISCAS85 and ITC benchmark circuits and obtain a detection accuracy of 87.61\% even for modifications as low as 5-gates. We further demonstrate that SIGNED can benefit from integration with a logic locking solution, where it can achieve increased protection against removal/tempering attacks and incurs lower overhead through judicious reuse of the locking …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:r_AWSJRzSzQC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"A powerful cache timing attack cannot only determine the secret key of a cryptographic cipher accurately but also do so quickly. Cache timing attacks that utilize the shared L1 cache memory are known to have these two characteristics. On the other hand, attacks using the shared last-level cache (LLC) memory are not always successful in obtaining the secret key, and they take considerably longer than an L1 cache attack. This paper leverages the fact that all LLC attacks run on multi-core CPUs, facilitating the attack programs to be parallelized. We show how parallelization can be used to reduce the runtime and improve the attack’s success making it at par with L1 cache attacks. We then propose a new methodology for LLC cache attacks, by which an attacker can maximize the attack success for a given time frame. The only additional requirement is learning about the target system’s runtime behavior, which …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:_5tno0g5mFcC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Bloom filter (BF), when used by an online application, experiences monotonically increasing false-positive errors. The decay of stale elements can control false-positives. Existing mechanisms for decay require unreasonable storage and computation. Inexpensive methods reset the BF periodically, resulting in inconsistent guarantees and performance issues in the underlying computing system. In this article, we propose Fading Bloom filter (FadingBF), which can provide inexpensive yet safe decay of elements. FadingBF neither requires additional storage nor computation to achieve this but instead exploits the underlying storage medium’s intrinsic properties, i.e., DRAM capacitor characteristics. We realize FadingBF by implementing the BF on a DRAM memory module with its periodic refresh disabled . Consequently, the capacitors holding the data elements that are not accessed frequently will predictably lose …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:yqoGN6RLRZoC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Blockchains are known to provide verifiable tamper-resistant trails of accepted transactions. This guarantee comes at the considerable cost of storage and computational power, thereby restricting its application. Current research has focused on alternatives such as proof of reputation, proof of stake, and proof of elapsed-time to reduce the computational burden on the blockchain participants. Orthogonal to this effort, we focus on a specific set of applications that cannot commit much storage space and computational resources, but require only reasonable guarantees on the validity of transactions. To this end, we introduce blockchain design alternatives, collectively called ApproxBC, that can provide proof of transactions with provable confidence bounds. Consequently, ApproxBC can considerably reduce the computation and storage resources required, making them suitable for resource-constrained Internet of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:XvxMoLDsR5gC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"An in-depth analysis of the impact of malware across multiple layers of cyber-connected systems is crucial for confronting evolving cyber-attacks. Gleaning such insights requires executing malware samples in analysis frameworks and observing their run-time characteristics. However, the evasive nature of malware, its dependence on real-world conditions, Internet connectivity, and short-lived remote servers to reveal its behavior, and the catastrophic consequences of its execution, pose significant challenges in collecting its real-world run-time behavior in analysis environments.
In this context, we propose JUGAAD, a malware behavior-as-a-service to meet the demands for the safe execution of malware. Such a service enables the users to submit malware hashes or programs and retrieve their precise and comprehensive real-world run-time characteristics. Unlike prior services that analyze malware and present …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:gKiMpY-AVTkC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Cryptography hardware are highly vulnerable to a class of side-channel attacks known as Differential Fault Analysis (DFA). These attacks exploit fault induced errors to compromise secret keys from ciphers within a few seconds. A bias in the error probabilities strengthens the attack considerably. It abets in bypassing countermeasures and is also the basis of powerful attack variants like the Differential Fault Intensity Analysis (DFIA) and Statistical Ineffective Fault Analysis (SIFA). In this paper, we make two significant contributions. First, we identify the correlation between fault induced errors and gatelevel parameters like the threshold voltage, gate size, and . We show how these parameters can influence the bias in the error probabilities. Then, we propose an algorithm, called Avatar, that carefully tunes gate-level parameters to strengthen the redundancy countermeasures against DFA, DFIA, and SIFA attacks …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:nVrZBo8bIpAC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Micro-architectural attacks use information leaked through shared resources to break hardware-enforced isolation. These attacks have been used to steal private information ranging from cryptographic keys to privileged Operating System (OS) data in devices ranging from mobile phones to cloud servers. Most existing software countermeasures either have unacceptable overheads or considerable false positives. Further, they are designed for specific attacks and cannot readily adapt to new variants. In this paper, we propose a framework called LEASH, which works from the OS scheduler to stymie micro-architectural attacks with minimal overheads, negligible impact of false positives, and is capable of handling a wide range of attacks. LEASH works by starving maliciously behaving threads at runtime, providing insufficient time and resources to carry out an attack. The CPU allocation for a falsely flagged thread found to be benign is boosted to minimize overheads. To demonstrate the framework, we modify Linux's Completely Fair Scheduler with LEASH and evaluate it with seven micro-architectural attacks ranging from Meltdown and Rowhammer to a TLB covert channel. The runtime overheads are evaluated with a range of real-world applications and found to be less than 1% on average.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:OP4eGU-M3BUC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"A malware goes through multiple stages in its life-cycle at the target machine before mounting its expected attack. The entire life-cycle can span anywhere from a few weeks to several months. The network communications during the initial phase could be the earliest indicators of a malware infection. While prior works have leveraged network traffic, none have focused on the temporal analysis of how early can the malware be detected. The main challenges here are the difficulty in differentiating benign-looking malware communications in the early stages of the malware life-cycle. In our quest to build an early warning system, we analyze malware communications to identify such early indicators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:9c2xU6iGI7YC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"The emergence of distributed manufacturing ecosystems for electronic hardware involving untrusted parties has led to diverse trust issues. In particular, Intellectual Property (IP) piracy, reverse engineering, and overproduction pose significant threats to integrated circuits (IC) manufacturers. Watermarking has been one of the solutions employed by the semiconductor industry to overcome many of the trust issues. However, existing watermarking techniques often suffer from one or more of the following deficiencies: (1) low structural coverage, (2) applicability to specific design abstraction level (e.g., gate or layout), (3) high design overhead, and (4) vulnerabilities to removal or tampering attacks. We address these deficiencies by introducing a new watermarking scheme, called SIGNED : S ignature I nsertion through challen G e respo N se in E lectronic D esign. SIGNED  relies on a challenge-response protocol …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:Bg7qf7VwUHIC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Artificial Intelligence techniques on malware run-time behavior have emerged as a promising tool in the arms race against sophisticated and stealthy cyber-attacks. While data of malware run-time features are critical for research and benchmark comparisons, unfortunately, there is a dearth of real-world datasets due to multiple challenges to their collection. The evasive nature of malware, its dependence on connected real-world conditions to execute, and its potential repercussions pose significant challenges for executing malware in laboratory settings. Consequently, prior open datasets rely on isolated virtual sandboxes to run malware, resulting in data that is not representative of malware behavior in the wild.
This paper presents RaDaR, an open real-world dataset for run-time behavioral analysis of Windows malware. RaDaR is collected by executing malware on a real-world testbed with Internet connectivity and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:vDZJ-YLwNdEC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Power side-channel attacks are potent security threats that exploit the power consumption patterns of an electronic device to glean sensitive information ranging from secret keys and passwords to web-browsing activity. While pre-Silicon tools promise early detection of side-channel leakage at the design stage, they require several hours of simulation time. In this paper, we present an analytical framework called FORTIFY that estimates the power side-channel vulnerability of digital circuit designs at signal-level granularity, given the RTL or gate-level netlist of the design, at least 100 times faster than contemporary works. We demonstrate the correctness of FORTIFY by comparing it with a recent simulation-based side-channel leakage analysis framework. We also test its scalability by evaluating FORTIFY on an open-source System-on-Chip.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:gVv57TyPmFsC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"In recent years several hardware enforced pointer protection schemes have been proposed. The most notable amongst them is the Intel MPX, which can identify spatial violations at run time. Recently, it is shown that Intel MPX is vulnerable to a potent attack called Meltdown, which exploits the processor’s transient behavior during speculative execution.In this paper, we show that there is a fundamental design flaw in Intel MPX and all other hardware enforced pointer protection schemes that we surveyed, making all of them vulnerable to Meltdown. We then suggest a design strategy called MSMPX, that provides hardware enforced pointer protection, while at the same time being immune to Meltdown. We compare the hardware overheads on an OpenRISC processor and the performance overheads with respect to Intel MPX.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:ODE9OILHJdcC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Hardware performance counters (HPCs) are present in most modern processors and provide an interface to user-level processes to monitor their performance in terms of the number of micro-architectural events, executed during the process execution. In this paper, we analyze the leakage from these HPC events and present a new micro-architectural side-channel attack that observes the number of instruction counts during the execution of an encryption algorithm as side-channel information to recover the secret key. This paper explores the fact that the instruction counts can act as a side channel and then describes the instruction profiling attack (IPA) methodology with the help of two block ciphers, namely AES and CLEFIA, on Intel and AMD processors. We follow the principles of profiled instruction attacks and show that the proposed attack is more potent than the well-known cache timing attacks in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:DUooU5lO8OsC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"The weakest link in cryptosystems is quite often due to the implementation rather than the mathematical underpinnings. A vast majority of attacks in the recent past have targeted programming flaws and bugs to break security systems. Due to the complexity, empirically verifying such systems is practically impossible, while manual verification as well as testing do not provide adequate guarantees.
In this article, we leverage model checking techniques to prove the functional correctness of an elliptic curve cryptography (ECC) library with respect to its formal specification. We demonstrate how the huge state space of the C library can be aptly verified using a hierarchical assume-guarantee verification strategy. To test the scalability of this approach, we verify the correctness of five MST-specified elliptic curve implementations. We also verify the newer curve25519 elliptic curve, which is finding multiple applications, due …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:umqufdRvDiIC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Fault attacks are a potent class of physical attacks that exploit a fault njected during device operation to steal secret keys from a cryptographic device. The success of a fault attack depends intricately on (a) the cryptographic properties of the cipher,(b) the program structure, and (c) the underlying hardware architecture. While there are several tools that automate the process of fault attack evaluation, none of them consider all three influencing aspects.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:LgRImbQfgY4C,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Malware programs are diverse, with varying objectives, functionalities, and threat levels ranging from mere pop-ups to financial losses. Consequently, their run-time footprints across the system differ, impacting the optimal data source (Network, Operating system (OS), Hardware) and features that are instrumental to malware detection. Further, the variations in threat levels of malware classes affect the user requirements for detection. Thus, the optimal tuple of <data-source, features, user-requirements> is different for each malware class, impacting the state-of-the-art detection solutions that are agnostic to these subtle differences. This paper presents SUNDEW, a framework to detect malware classes using their optimal tuple of <data-source, features, user-requirements>. SUNDEW uses an ensemble of specialized predictors, each trained with a particular data source (network, OS, and hardware) and tuned for features and requirements of a specific class. While the specialized ensemble with a holistic view across the system improves detection, aggregating the independent conflicting inferences from the different predictors is challenging. SUNDEW resolves such conflicts with a hierarchical aggregation considering the threat-level, noise in the data sources, and prior domain knowledge. We evaluate SUNDEW on a real-world dataset of over 10,000 malware samples from 8 classes. It achieves an F1-Score of one for most classes, with an average of 0.93 and a limited performance overhead of 1.5%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:BJbdYPG6LGMC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"In this paper, we propose a novel class of speculative attacks, called Timed Speculative Attacks (TSA), that does not depend on the state changes in the cache memory. Instead, it makes use of the timing differences that occur due to store-to-load forwarding. We propose two attack strategies - Fill-and-Forward utilizing correctly speculated loads, and Fill-and-Misdirect using mis-speculated load instructions. While Fill-and-Forward exploits the shared store buffers in a multi-threaded CPU core, the Fill-and-Misdirect approach exploits the influence of rolled back mis-speculated loads on subsequent instructions. As case studies, we demonstrate a covert channel using Fill-and-Forward and key recovery attacks on OpenSSL AES and Romulus-N Authenticated Encryption with Associated Data scheme using Fill-and-Misdirect approach. Finally, we show that TSA is able to subvert popular cache-based countermeasures for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:tH6gc1N1XXoC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:5icHVeHT4IsC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"Cryptocurrencies are rapidly finding wide application in areas such as Real Time Gross Settlements and Payments Systems. Ripple is a cryptocurrency that has gained prominence with banks and payment providers. It solves the Byzantine General’s Problem with it’s Ripple Protocol Consensus Algorithm (RPCA), where each server maintains a list of servers, called Unique Node List (UNL) that represents the network for the server, and will not collectively defraud it. The server believes that the network has come to a consensus when members of the UNL come to a consensus on a transaction.
In this paper we improve Ripple to achieve better speed, security, last mile connectivity and ease of use. We implement guidelines and automated systems for building and maintaining UNLs for resilience, robustness, improved security, and efficient information propagation. We enhance the system so as to ensure that each server receives information from across the whole network rather than just from the UNL members. We also introduce the paradigm of UNL overlap as a function of information propagation and the trust a server assigns to its own UNL. Our design not only reduces vulnerabilities such as eclipse attacks, but also makes it easier to identify malicious behaviour and entities attempting to fraudulently Double Spend or stall the system. We provide experimental evidence of the benefits of our approach over the current Ripple scheme. We observe≥ 4.97 x and 98.22 x in speedup and success rate for information propagation respectively, and≥ 3.16 x and 51.70 x in speedup and success rate in consensus.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:yMeIxYmEMEAC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",21,"The Conference on Security, Privacy, and Applied Cryptography Engineering 2018 (SPACE 2018), was held during December 15–19, 2018, at the Indian Institute of Technology Kanpur, India. This annual event is devoted to various aspects of security, privacy, applied cryptography, and cryptographic engineering. This is a challenging field, requiring expertise from diverse domains, ranging from mathematics to solid-state circuit design.
This year we received 34 submissions from 11 different countries. The submissions were evaluated based on their significance, novelty, technical quality, and relevance to the SPACE conference. The submissions were reviewed in a double-blind mode by at least three members of the 36-member Program Committee. The Program Committee was aided by 22 additional reviewers. The Program Committee meetings were held electronically, with intensive discussions. After an extensive review process, 12 papers were accepted for presentation at the conference, for an acceptance rate of 35.29%. The program also included six invited talks and five tutorials on several aspects of applied cryptology, delivered by world-renowned researchers: Nasour Bagheri, Shivam Bhasin, Jo Van Bulck, Shay Gueron, Avi Mendelson, Mridul Nandi, Abhik Roychoudhury, Sandeep Shukla, Vanessa Teague, and Eran Toch. We sincerely thank the invited speakers for accepting our invitations in spite of their busy schedules. Like its previous editions, SPACE 2018 was organized in co-operation with the International Association for Cryptologic Research (IACR). We are thankful to the Indian Institute of Technology Kanpur for being the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&citation_for_view=ctxSQrwAAAAJ:OTTXONDVkokC,http://cse.iitm.ac.in/~chester
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Distributed graph analytics systems for CPUs, like D-Galois and Gemini, and for GPUs, like D-IrGL and Lux, use a bulk-synchronous parallel (BSP) programming and execution model. BSP permits bulk-communication and uses large messages which are supported efficiently by current message transport layers, but bulk-synchronization can exacerbate the performance impact of load imbalance because a round cannot be completed until every host has completed that round. Asynchronous distributed graph analytics systems circumvent this problem by permitting hosts to make progress at their own pace, but existing systems either use global locks and send small messages or send large messages but do not support general partitioning policies such as vertex-cuts. Consequently, they perform substantially worse than bulk-synchronous systems. Moreover, none of their programming or execution models can be …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&citation_for_view=kbgu7ccAAAAJ:r0BpntZqJG4C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"There are relatively few studies of distributed GPU graph analytics systems in the literature and they are limited in scope since they deal with small data-sets, consider only a few applications, and do not consider the interplay between partitioning policies and optimizations for computation and communication.In this paper, we present the first detailed analysis of graph analytics applications for massive real-world datasets on a distributed multi-GPU platform and the first analysis of strong scaling of smaller real-world datasets. We use D-IrGL, the state-of-the-art distributed GPU graph analytical framework, in our study. Our evaluation shows that (1) the Cartesian vertex-cut partitioning policy is critical to scale computation out on GPUs even at a small scale, (2) static load imbalance is a key factor in performance since memory is limited on GPUs, (3) device-host communication is a significant portion of execution time and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&citation_for_view=kbgu7ccAAAAJ:blknAaTinKkC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"The precision of heap analyses determines the precision of several associated optimizations, and has been a prominent area in compiler research. It has been shown that context-sensitive heap analyses are more precise than the insensitive ones, but their scalability continues to be a cause of concern. Though the value-contexts approach improves the scalability of classical call-string based context-sensitive analyses, it still does not scale well for several popular whole-program heap analyses. In this paper, we propose a three-stage analysis approach that lets us scale complex whole-program value-contexts based heap analyses for large programs, without losing their precision.
Our approach is based on a novel idea of level-summarized relevant value-contexts (LSRV-contexts), which take into account an important observation that we do not need to compare the complete value-contexts at each call-site. Our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&citation_for_view=kbgu7ccAAAAJ:HDshCWvjkbEC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Existing precise context-sensitive heap analyses do not scale well for large OO programs. Further, identifying the right context abstraction becomes quite intriguing as two of the most popular categories of context abstractions (call-site- and object-sensitive) lead to theoretically incomparable precision. In this paper, we address this problem by first doing a detailed comparative study (in terms of precision and efficiency) of the existing approaches, both with and without heap cloning. In addition, we propose novel context abstractions that lead to a new sweet-spot in the arena.
We first enhance the precision of level-summarized relevant value (LSRV) contexts (a highly scalable abstraction with precision matching that of call-site-sensitivity) using heap cloning. Then, motivated by the resultant scalability, we propose the idea of mixing various context abstractions, and add the advantages of k-object-sensitive analyses to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&citation_for_view=kbgu7ccAAAAJ:JV2RwH3_ST0C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"This paper presents a Tensor Transposition Library for GPUs (TTLG). A distinguishing feature of TTLG is that it also includes a performance prediction model, which can be used by higher level optimizers that use tensor transposition. For example, tensor contractions are often implemented by using the TTGT (Transpose-Transpose-GEMM-Transpose) approach - transpose input tensors to a suitable layout and then use high-performance matrix multiplication followed by transposition of the result. The performance model is also used internally by TTLG for choosing among alternative kernels and/or slicing/blocking parameters for the transposition. TTLG is compared with current state-of-the-art alternatives for GPUs. Comparable or better transposition times for the ""repeated-use"" scenario and considerably better ""single-use"" performance are observed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&citation_for_view=kbgu7ccAAAAJ:hC7cP41nSMkC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Languages like Java and C# follow a two-step process of compilation: static compilation and just-in-time (JIT) compilation. As the time spent in JIT compilation gets added to the execution-time of the application, JIT compilers typically sacrifice the precision of program analyses for efficiency. The alternative of performing the analysis for the whole program statically ignores the analysis of libraries (available only at runtime), and thereby generates imprecise results. To address these issues, in this article, we propose a two-step (static+JIT) analysis framework called precise-yet-efficient (PYE) that helps generate precise analysis-results at runtime at a very low cost.
PYE achieves the twin objectives of precision and performance during JIT compilation by using a two-pronged approach: (i) It performs expensive analyses during static compilation, while accounting for the unavailability of the runtime libraries by generating …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:4JMBOYKVnBMC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Many program-analysis based tools require precise points-to/alias information only for some program variables. To meet this requirement efficiently, there have been many works on demand-driven analyses that perform only the work necessary to compute the points-to or alias information on the requested variables (queries). However, these demand-driven analyses can be very expensive when applied on large systems where the number of queries can be significant. Such a blow-up in analysis time is unacceptable in cases where scalability with real-time constraints is crucial; for example, when program analysis tools are plugged into an IDE (Integrated Development Environment). In this paper, we propose schemes to improve the scalability of demand-driven analyses without compromising on precision. Our work is based on novel ideas for eliminating irrelevant and redundant data-flow paths for the given …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:bEWYMUwI8FkC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Refactoring is a program transformation that restructures existing code without altering its behaviour and is a key practice in popular software design movements, such as Agile. Identification of potential refactoring opportunities is an important step in the refactoring process. In large systems, manual identification of useful refactoring opportunities requires a lot of effort and time. Hence, there is a need for automatic identification of refactoring opportunities. However, this problem has not been addressed well for many non-trivial refactorings. Two such non-trivial, yet popular refactorings are “Replace Type Code with Subclass” (SC) and “Replace Type Code with State” (ST) refactorings. In this paper, we present new approaches to identify SC and ST refactoring opportunities.
Our proposed approach is based around the notion of control-fields. A control-field is a field of a class that exposes the different underlying …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:-f6ydRqryjwC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Graph algorithms are widely used in various applications. Their programmability and performance have garnered a lot of interest among the researchers. Being able to run these graph analytics programs on distributed systems is an important requirement. Green-Marl is a popular Domain Specific Language (DSL) for coding graph algorithms and is known for its simplicity. However, the existing Green-Marl compiler for distributed systems (Green-Marl to Pregel) can only compile limited types of Green-Marl programs (in Pregel canonical form). This severely restricts the types of parallel Green-Marl programs that can be executed on distributed systems. We present DisGCo, the first compiler to translate any general Green-Marl program to equivalent MPI program that can run on distributed systems.
Translating Green-Marl programs to MPI (SPMD/MPMD style of computation, distributed memory) presents many other …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:YFjsv_pBGBYC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"May-Happen-in-Parallel (MHP) analysis forms the basis for many problems of program analysis and program understanding. MHP analysis can also be used by IDEs (integrated-development-environments) to help programmers to refactor parallel-programs, identify racy programs, understand which parts of the program run in parallel, and so on. Since the code keeps changing in the IDE, re-computing the MHP information after every change can be an expensive affair. In this manuscript, we propose a novel scheme to perform incremental MHP analysis (on the fly) of programs written in task parallel languages like X10 to keep the MHP information up to date, in an IDE environment.
The key insight of our proposed approach to maintain the MHP information up to date is that we need not rebuild (from scratch) every data structure related to MHP information, after each modification (addition or deletion of statements) in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:M3NEmzRMIkIC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Load-balancing among the threads of a GPU for graph analytics workloads is difficult because of the irregular nature of graph applications and the high variability in vertex degrees, particularly in power-law graphs. We describe a novel load balancing scheme to address this problem. Our scheme is implemented in the IrGL compiler to allow users to generate efficient load balanced code for a GPU from high-level sequential programs. We evaluated several graph analytics applications on up to 16 distributed GPUs using IrGL to compile the code and the Gluon substrate for inter-GPU communication. Our experiments show that this scheme can achieve an average speed-up of 2.2x on inputs that suffer from severe load imbalance problems when previous state-of-the-art load-balancing schemes are used.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:TFP_iSt0sucC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Graph coloring is a widely studied problem that is used in a variety of applications, such as task scheduling, register allocation, eigenvalue computations, social network analysis, and so on. Many of the modern day applications deal with large graphs (with millions of vertices and edges) and researchers have exploited the parallelism provided by multi-core systems to efficiently color such large graphs. GPUs provide a promising parallel infrastructure to run large applications. In this paper, we present new schemes to efficiently color large graphs on GPUs.
We extend the algorithm of Rokos et al. [21] to efficiently color graphs using GPUs. Their approach has to continually resolve conflicts for color assignment. We present a data driven variation of their algorithm and use an improved scheme for conflict resolution. We also propose two optimizations for our algorithm to reduce both the execution time and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:j3f4tGmQtD8C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"X10 is a partitioned global address space (PGAS) programming language that supports the notion of places; a place consists of some data and some lightweight tasks called activities. Each activity runs at a place and may invoke a place-change operation (using the at-construct) to synchronously perform some computation at another place. These place-change operations need to copy all the required data from the current place to the remote place. However, identifying the required data during each place-change operation is a non-trivial task, especially in the context of irregular applications (like graph applications) that contain large amounts of cross-referencing objects - not all of those objects may be actually required, at the remote place. In this paper, we present a new optimization AT-Opt that minimizes the amount of data serialized and communicated during place-change operations.
AT-Opt uses a novel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:hFOr9nPyWt4C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Task-parallel languages such as X10 implement dynamic lightweight task-parallel execution model, where programmers are encouraged to express the ideal parallelism in the program. Prior work has used loop chunking to extract useful parallelism from ideal. Traditional loop chunking techniques assume that iterations in the loop are of similar workload, or the behavior of the first few iterations can be used to predict the load in later iterations. However, in loops with non-uniform work distribution, such assumptions do not hold. This problem becomes more complicated in the presence of atomic blocks (critical sections).
In this paper, we propose a new optimization called deep-chunking that uses a mixed compile-time and runtime technique to chunk the iterations of the parallel-for-loops, based on the runtime workload of each iteration. We propose a parallel algorithm that is executed by individual threads to efficiently …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:hMod-77fHWUC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Many modern task‐parallel languages allow the programmer to synchronize tasks using high‐level constructs like barriers, clocks, and phasers. While these high‐level synchronization primitives help the programmer express the program logic in a convenient manner, they also have their associated overheads. In this paper, we identify the sources of some of these overheads for task‐parallel languages like X10 that support lock‐step synchronization, and propose a mechanism to reduce these overheads.
We first propose three desirable properties that an efficient runtime (for task‐parallel languages like X10, HJ, Chapel, and so on) should satisfy, to minimize the overheads during lock‐step synchronization. We use these properties to derive a scheme to called uClocks to improve the efficiency of X10 clocks; uClocks consists of an extension to X10 clocks and two related runtime optimizations. We prove that uClocks …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:RHpTSmoSYBkC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"OpenMP uses the efficient ‘team of workers’ model, where workers are given chunks of tasks (iterations of a parallel-for-loop, or sections in a parallel-sections block) to execute, and worker (not tasks) can be synchronized using barriers. Thus, OpenMP restricts the invocation of barriers in these tasks; as otherwise, the behavior of the program would be dependent on the number of runtime workers. To address such a restriction which can adversely impact programmability and readability, Aloor and Nandivada proposed UW-OpenMP by taking inspiration from the more intuitive interaction of tasks and barriers in newer task parallel languages like X10, HJ, Chapel and so on. UW-OpenMP gives the programmer an impression that each parallel task is executed by a unique worker, and importantly these parallel tasks can be synchronized using a barrier construct. Though UW-OpenMP is a useful extension of OpenMP …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:R3hNpaxXUhUC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Mainstream compilers perform a multitude of analyses and optimizations on the given input program. Each analysis pass may generate a program-abstraction. Each optimization pass is typically composed of multiple alternating phases of inspection of program-abstractions and transformations of the program. Upon transformation of a program, the program-abstractions generated by various analysis passes may become inconsistent with the program's modified state. Consequently, the downstream transformations may be considered unsafe until the relevant program-abstractions are stabilized, i.e., the program-abstractions are made consistent with the modified program. In general, the existing compiler frameworks do not perform automated stabilization of the program-abstractions and instead leave it to the optimization writer to deal with the complex task of identifying the relevant program-abstractions to stabilize, the points where the stabilization is to be performed, and the exact procedure of stabilization. Similarly, adding new analyses becomes a challenge as one has to understand which all existing optimizations may impact the newly added program-abstractions. In this paper, we address these challenges by providing the design and implementation of a novel generalized compiler-design framework called Homeostasis. Homeostasis can be used to guarantee the trigger of automated stabilization of relevant program-abstractions under every possible transformation of the program. Interestingly, Homeostasis provides such guarantees not only for the existing optimization passes but also for any future optimizations that may be added to the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:BqipwSGYUEgC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"X10 is a partitioned global address space programming language that supports the notion of places; a place consists of some data and some lightweight tasks called activities. Each activity runs at a place and may invoke a place-change operation (using the at-construct) to synchronously perform some computation at another place. These place-change operations can be very expensive, as they need to copy all the required data from the current place to the remote place. However, identifying the necessary number of place-change operations and the required data during each place-change operation are non-trivial tasks, especially in the context of irregular applications (like graph applications) that contain complex code with large amounts of cross-referencing objects—not all of those objects may be actually required, at the remote place. In this article, we present AT-Com, a scheme to optimize X10 code with place …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:iH-uZ7U-co4C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"IMOP follows the object-oriented visitor design pattern, and has been written in Java. The parser and certain fundamental visitors of the Abstract Syntax Tree (ASTs), Control Flow Graphs (CFGs), etc., have been written using JavaCC/JTB. This report looks into the design and key features of IMOP, along with an appropriate level of implementation detail, wherever required. 1",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:maZDTaKrznsC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",13,"Modern languages like Java and C# follow a two-step process for compilation and execution: the input program is statically compiled to an intermediate language (for example, Bytecode for Java and CIL for C#), which is then executed on a possibly remote virtual machine (for example, JVM and .NET). Many virtual machines (Alpern et al. 2005; Paleczny et al. 2001) use inbuilt just-in-time (JIT) compiler (s) to generate optimized assembly code that can be directly executed on the hardware.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&cstart=20&pagesize=80&citation_for_view=kbgu7ccAAAAJ:e5wmG9Sq2KIC,http://www.cse.iitm.ac.in/~krishna
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"Algebraic effects and their handlers have been steadily gaining attention as a programming language feature for composably expressing user-defined computational effects. While several prototype implementations of languages incorporating algebraic effects exist, Multicore OCaml incorporates effect handlers as the primary means of expressing concurrency in the language. In this paper, we make the observation that effect handlers can elegantly express particularly difficult programs that combine system programming and concurrency without compromising performance. Our experimental results on a highly concurrent and scalable web server demonstrate that effect handlers perform on par with highly optimised monadic concurrency libraries, while retaining the simplicity of direct-style code.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&citation_for_view=Kc2cHqYAAAAJ:EkHepimYqZsC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"The language Eff is an OCaml-like language serving as a prototype implementation of the theory of algebraic effects, intended for experimentation with algebraic effects on a large scale. We present the embedding of Eff into OCaml, using the library of delimited continuations or the multicore OCaml branch. We demonstrate the correctness of the embedding denotationally, relying on the tagless-final-style interpreter-based denotational semantics, including the novel, direct denotational semantics of multi-prompt delimited control. The embedding is systematic, lightweight, performant and supports even higher-order, 'dynamic' effects with their polymorphism. OCaml thus may be regarded as another implementation of Eff, broadening the scope and appeal of that language.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&citation_for_view=Kc2cHqYAAAAJ:yB1At4FlUx8C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"We propose a new semantics for shared-memory parallel programs that gives strong guarantees even in the presence of data races. Our local data race freedom property guarantees that all data-race-free portions of programs exhibit sequential semantics. We provide a straightforward operational semantics and an equivalent axiomatic model, and evaluate an implementation for the OCaml programming language. Our evaluation demonstrates that it is possible to balance a comprehensible memory model with a reasonable (no overhead on x86, ~0.6% on ARM) sequential performance trade-off in a mainstream programming language.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&citation_for_view=Kc2cHqYAAAAJ:4MWp96NkSFoC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"High-level data types are often associated with semantic invariants that must be preserved by any correct implementation. While having implementations enforce strong guarantees such as linearizability or serializability can often be used to prevent invariant violations in concurrent settings, such mechanisms are impractical in geo-distributed replicated environments, the platform of choice for many scalable Web services. To achieve high-availability essential to this domain, these environments admit various forms of weak consistency that do not guarantee all replicas have a consistent view of an application's state. Consequently, they often admit difficult-to-understand anomalous behaviors that violate a data type's invariants, but which are extremely challenging, even for experts, to understand and debug.
In this paper, we propose a novel programming framework for replicated data types (RDTs) equipped with an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&citation_for_view=Kc2cHqYAAAAJ:vbGhcppDl1QC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"Programming geo-replicated distributed systems is challenging given the complexity of reasoning about different evolving states on different replicas. Existing approaches to this problem impose significant burden on application developers to consider the effect of how operations performed on one replica are witnessed and applied on others. To alleviate these challenges, we present a fundamentally different approach to programming in the presence of replicated state. Our insight is based on the use of invertible relational specifications of an inductively-defined data type as a mechanism to capture salient aspects of the data type relevant to how its different instances can be safely merged in a replicated environment. Importantly, because these specifications only address a data type's (static) structural properties, their formulation does not require exposing low-level system-level details concerning asynchrony …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&citation_for_view=Kc2cHqYAAAAJ:ILKRHgRFtOwC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"Effect handlers have been gathering momentum as a mechanism for modular programming with user-defined effects. Effect handlers allow for non-local control flow mechanisms such as generators, async/await, lightweight threads and coroutines to be composably expressed. We present a design and evaluate a full-fledged efficient implementation of effect handlers for OCaml, an industrial-strength multi-paradigm programming language. Our implementation strives to maintain the backwards compatibility and performance profile of existing OCaml code. Retrofitting effect handlers onto OCaml is challenging since OCaml does not currently have any non-local control flow mechanisms other than exceptions. Our implementation of effect handlers for OCaml: (i) imposes a mean 1% overhead on a comprehensive macro benchmark suite that does not use effect handlers; (ii) remains compatible with program analysis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&citation_for_view=Kc2cHqYAAAAJ:kz9GbA2Ns4gC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"OCaml is an industrial-strength, multi-paradigm programming language, widely used in industry and academia. OCaml is also one of the few modern managed system programming languages to lack support for shared memory parallel programming. This paper describes the design, a full-fledged implementation and evaluation of a mostly-concurrent garbage collector (GC) for the multicore extension of the OCaml programming language. Given that we propose to add parallelism to a widely used programming language with millions of lines of existing code, we face the challenge of maintaining backwards compatibility--not just in terms of the language features but also the performance of single-threaded code running with the new GC. To this end, the paper presents a series of novel techniques and demonstrates that the new GC strikes a balance between performance and feature backwards compatibility for sequential programs and scales admirably on modern multicore processors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&citation_for_view=Kc2cHqYAAAAJ:-FonjvnnhkoC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"Programmers regularly use distributed version control systems (DVCS) such as Git to facilitate collaborative software development. The primary purpose of a DVCS is to maintain integrity of source code in the presence of concurrent, possibly conflicting edits from collaborators. In addition to safely merging concurrent non-conflicting edits, a DVCS extensively tracks source code provenance to help programmers contextualize and resolve conflicts. Provenance also facilitates debugging by letting programmers see diffs between versions and quickly find those edits that introduced the offending conflict (eg, via git blame).
In this paper, we posit that analogous workflows to collaborative software development also arise in distributed software execution; we argue that the characteristics that make a DVCS an ideal fit for the former also make it an ideal fit for the latter. Building on this observation, we propose a distributed programming model, called carmot that views distributed shared state as an entity evolving in time, manifested as a sequence of persistent versions, and relies on an explicitly defined merge semantics to reconcile concurrent conflicting versions. We show examples demonstrating how carmot simplifies distributed programming, while also enabling novel workflows integral to modern applications such as blockchains. We also describe a prototype implementation of carmot that we use to evaluate its practicality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&cstart=20&pagesize=80&citation_for_view=Kc2cHqYAAAAJ:L7CI7m0gUJcC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"Replicated data types (RDTs) are data structures that permit concurrent modification of multiple, potentially geo-distributed, replicas without coordination between them. RDTs are designed in such a way that conflicting operations are eventually deterministically reconciled ensuring convergence. Constructing correct RDTs remains a difficult endeavour due to the complexity of reasoning about independently evolving states of the replicas. With the focus on the correctness of RDTs (and rightly so), existing approaches to RDTs are less efficient compared to their sequential counterparts in terms of the time and space complexity of local operations. This is unfortunate since RDTs are often used in a local-first setting where the local operations far outweigh remote communication.
This paper presents PEEPUL, a pragmatic approach to building and verifying efficient RDTs. To make reasoning about correctness easier, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&cstart=20&pagesize=80&citation_for_view=Kc2cHqYAAAAJ:HbR8gkJAVGIC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"Programming loosely connected distributed applications is a challenging endeavour. Loosely connected distributed applications such as geo-distributed stores and intermittently reachable IoT devices cannot afford to coordinate among all of the replicas in order to ensure data consistency due to prohibitive latency costs and the impossibility of coordination if availability is to be ensured. Thus, the state of the replicas evolves independently, making it difficult to develop correct applications. Existing solutions to this problem limit the data types that can be used in these applications, which neither offer the ability to compose them to construct more complex data types nor offer transactions.
In this paper, we describe Banyan, a distributed programming model for developing loosely connected distributed applications. Data types in Banyan are equipped with a three-way merge function à la Git to handle …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&cstart=20&pagesize=80&citation_for_view=Kc2cHqYAAAAJ:e_rmSamDkqQC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"Languages like C\#, C++, or JavaScript support complex control flow statements like exception handling, iterators (yield), and even asynchrony (async/await) through special extensions. For exceptions, the runtime needs to be extended with exception handling stack frames. For iterators and asynchrony, the situation is more involved, as the compiler needs to turn regular code into stack restoring state machines. Furthermore, these features need to interact as expected, eg finally blocks must not be forgotten in the state machines for iterators. And all of this work needs to be done again for the next control flow abstraction that comes along. Or we can use algebraic effect handlers! This single mechanism generalizes all the control flow abstractions listed above and more, composes freely, has simple operational semantics, and can be efficiently compiled, since there is just one mechanism that needs to be supported well. Handlers allow programmers to keep the code in direct-style, which is easy to reason about, and empower library writers to implement various high-level abstractions without special extensions. The idea of algebraic effects handlers has already been experimented with in the form of small research languages and libraries in several mainstream languages, including OCaml, Haskell, Clojure, and Scala. The next step, and the aim of this seminar, is to seriously consider adoption by mainstream languages including both functional languages such as OCaml or Haskell, as well as languages like JavaScript and the JVM and .NET ecosystems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&cstart=20&pagesize=80&citation_for_view=Kc2cHqYAAAAJ:TIZ-Mc8IlK0C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"Bug-free concurrent programs are hard to write due to non-determinism arising out of concurrency and program inputs. Since concurrency bugs typically manifest under specific inputs and thread schedules, conventional testing methodologies for concurrent programs like stress testing and random testing, which explore random schedules, have a strong chance of missing buggy schedules.
In this paper, we introduce a novel technique that combines property-based testing with mutation-based, grey box fuzzer, applied to event-driven OCaml programs. We have implemented this technique in ConFuzz, a directed concurrency bug-finding tool for event-driven OCaml programs. Using ConFuzz, programmers specify high-level program properties as assertions in the concurrent program. ConFuzz uses the popular greybox fuzzer AFL to generate inputs as well as concurrent schedules to maximise the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&cstart=20&pagesize=80&citation_for_view=Kc2cHqYAAAAJ:k8Z6L05lTy4C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,"Digital infrastructure in modern urban environments is currently very Internet-centric, and involves transmitting data to physically remote environments. The cost for this is data insecurity, high response latency and unpredictable reliability of services. In this paper, we lay out a software architecture that inverts the current model by building an operating system designed to securely connect physical spaces with extremely low latency, high bandwidth local-area computation capabilities and service discovery. We describe our early prototype design OSMOSE, which is based on unikernels and a distributed store.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&cstart=20&pagesize=80&citation_for_view=Kc2cHqYAAAAJ:URolC5Kub84C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&cstart=20&pagesize=80&citation_for_view=Kc2cHqYAAAAJ:SpbeaW3--B0C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",16,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&cstart=20&pagesize=80&citation_for_view=Kc2cHqYAAAAJ:AvfA0Oy_GE0C,https://kcsrk.info/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",7,"While a number of weak consistency mechanisms have been developed in recent years to improve performance and ensure availability in distributed, replicated systems, ensuring correctness of transactional applications running on top of such systems remains a difficult and important problem. Serializability is a well-understood correctness criterion for transactional programs; understanding whether applications are serializable when executed in a weakly-consistent environment, however remains a challenging exercise. In this work, we combine the dependency graph-based characterization of serializability and the framework of abstract executions to develop a fully automated approach for statically finding bounded serializability violations under \emph{any} weak consistency model. We reduce the problem of serializability to satisfiability of a formula in First-Order Logic, which allows us to harness the power of existing SMT solvers. We provide rules to automatically construct the FOL encoding from programs written in SQL (allowing loops and conditionals) and the consistency specification written as a formula in FOL. In addition to detecting bounded serializability violations, we also provide two orthogonal schemes to reason about unbounded executions by providing sufficient conditions (in the form of FOL formulae) whose satisfiability would imply the absence of anomalies in any arbitrary execution. We have applied the proposed technique on TPC-C, a real world database program with complex application logic, and were able to discover anomalies under Parallel Snapshot Isolation, and verify serializability for unbounded executions under …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&citation_for_view=KiT5oNUAAAAJ:Tyk-4Ss8FVUC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",7,"Relational database applications are notoriously difficult to test and debug. Concurrent execution of database transactions may violate complex structural invariants that constraint how changes to the contents of one (shared) table affect the contents of another. Simplifying the underlying concurrency model is one way to ameliorate the difficulty of understanding how concurrent accesses and updates can affect database state with respect to these sophisticated properties. Enforcing serializable execution of all transactions achieves this simplification, but it comes at a significant price in performance, especially at scale, where database state is often replicated to improve latency and availability.
To address these challenges, this paper presents a novel testing framework for detecting serializability violations in (SQL) database-backed Java applications executing on weakly-consistent storage systems. We manifest our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&citation_for_view=KiT5oNUAAAAJ:YsMSGLbcyi4C,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",7,"Maintaining multiple replicas of data is crucial to achieving scalability, availability and low latency in distributed applications. Conflict-free Replicated Data Types (CRDTs) are important building blocks in this domain because they are designed to operate correctly under the myriad behaviors possible in a weakly-consistent distributed setting. Because of the possibility of concurrent updates to the same object at different replicas, and the absence of any ordering guarantees on these updates, convergence is an important correctness criterion for CRDTs. This property asserts that two replicas which receive the same set of updates (in any order) must nonetheless converge to the same state. One way to prove that operations on a CRDT converge is to show that they commute since commutative actions by definition behave the same regardless of the order in which they execute. In this paper, we present a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&citation_for_view=KiT5oNUAAAAJ:W7OEmFMy1HYC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",7,"Serializability is a well-understood concurrency control mechanism that eases reasoning about highly-concurrent database programs. Unfortunately, enforcing serializability has a high performance cost, especially on geographically distributed database clusters. Consequently, many databases allow programmers to choose when a transaction must be executed under serializability, with the expectation that transactions would only be so marked when necessary to avoid serious concurrency bugs. However, this is a significant burden to impose on developers, requiring them to (a) reason about subtle concurrent interactions among potentially interfering transactions, (b) determine when such interactions would violate desired invariants, and (c) then identify the minimum number of transactions whose executions should be serialized to prevent these violations. To mitigate this burden, this paper presents a sound fully …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&citation_for_view=KiT5oNUAAAAJ:WF5omc3nYNoC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",7,"Geo-replicated systems provide a number of desirable properties such as globally low latency, high availability, scalability, and built-in fault tolerance. Unfortunately, programming correct applications on top of such systems has proven to be very challenging, in large part because of the weak consistency guarantees they offer. These complexities are exacerbated when we try to adapt existing highly-performant concurrent libraries developed for shared-memory environments to this setting. The use of these libraries, developed with performance and scalability in mind, is highly desirable. But, identifying a suitable notion of correctness to check their validity under a weakly consistent execution model has not been well-studied, in large part because it is problematic to naïvely transplant criteria such as linearizability that has a useful interpretation in a shared-memory context to a distributed one where the cost of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&citation_for_view=KiT5oNUAAAAJ:eQOLeE2rZwMC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",7,"Replicated data types (RDTs) are data structures that permit concurrent modification of multiple, potentially geo-distributed, replicas without coordination between them. RDTs are designed in such a way that conflicting operations are eventually deterministically reconciled ensuring convergence. Constructing correct RDTs remains a difficult endeavour due to the complexity of reasoning about independently evolving states of the replicas. With the focus on the correctness of RDTs (and rightly so), existing approaches to RDTs are less efficient compared to their sequential counterparts in terms of the time and space complexity of local operations. This is unfortunate since RDTs are often used in a local-first setting where the local operations far outweigh remote communication.
This paper presents PEEPUL, a pragmatic approach to building and verifying efficient RDTs. To make reasoning about correctness easier, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&citation_for_view=KiT5oNUAAAAJ:ufrVoPGSRksC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",7,"Distributed protocols are generally parametric and can be executed on a system with any number of nodes, and hence proving their correctness becomes an infinite state verification problem. The most popular approach for verifying distributed protocols is to find an inductive invariant which is strong enough to prove the required safety property. However, finding inductive invariants is known to be notoriously hard, and is especially harder in the context of distributed protocols which are quite complex due to their asynchronous nature. In this work, we investigate an orthogonal cut-off based approach to verifying distributed protocols which sidesteps the problem of finding an inductive invariant, and instead reduces checking correctness to a finite state verification problem. The main idea is to find a finite, fixed protocol instance called the cutoff instance, such that if the cutoff instance is safe, then any protocol instance would also be safe. Previous cutoff based approaches have only been applied to a restricted class of protocols and specifications. We formalize the cutoff approach in the context of a general protocol modeling language (RML), and identify sufficient conditions which can be efficiently encoded in SMT to check whether a given protocol instance is a cutoff instance. Further, we propose a simple static analysis-based algorithm to automatically synthesize a cut-off instance. We have applied our approach successfully on a number of complex distributed protocols, providing the first known cut-off results for many of them.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&citation_for_view=KiT5oNUAAAAJ:roLk4NBRz8UC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",7,We propose a framework to automate and mechanize simulation-based proofs of cutoffs for parameterized verification of distributed protocols. We propose a strategy to derive the simulation relation given the cutoff instance and encode the correctness of the simulation relation as a formula in first-order logic. We have successfully applied our approach on a number of distributed protocols.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&citation_for_view=KiT5oNUAAAAJ:_FxGoFyzp5QC,http://kartiknagar.github.io/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Zero shot learning in Image Classification refers to the setting where images from some novel classes are absent in the training data but other information such as natural language descriptions or attribute vectors of the classes are available. This setting is important in the real world since one may not be able to obtain images of all the possible classes at training. While previous approaches have tried to model the relationship between the class attribute space and the image space via some kind of a transfer function in order to model the image space correspondingly to an unseen class, we take a different approach and try to generate the samples from the given attributes, using a conditional variational autoencoder, and use the generated samples for classification of the unseen classes. By extensive testing on four benchmark datasets, we show that our model outperforms the state of the art, particularly in the more realistic generalized setting, where the training classes can also appear at the test time along with the novel classes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&citation_for_view=mB9AZSAAAAAJ:u9iWguZQMMsC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Sketch-based image retrieval (SBIR) is the task of retrieving images from a natural image database that correspond to a given hand-drawn sketch. Ideally, an SBIR model should learn to associate components in the sketch (say, feet, tail, etc.) with the corresponding components in the image. However, current evaluation methods simply focus only on coarse-grained evaluation where the focus is on retrieving images which belong to the same class as the sketch but not necessarily having the same components as in the sketch. As a result, existing methods simply learn to associate sketches with classes seen during training and hence fail to generalize to unseen classes. In this paper, we propose a new bench mark for zero-shot SBIR where the model is evaluated on novel classes that are not seen during training. We show through extensive experiments that existing models for SBIR which are trained in a discriminative setting learn only class specific mappings and fail to generalize to the proposed zero-shot setting. To circumvent this, we propose a generative approach for the SBIR task by proposing deep conditional generative models which take the sketch as an input and fill the missing information stochastically. Experiments on this new benchmark created from the"" Sketchy"" dataset, which is a large-scale database of sketch-photo pairs demonstrate that the performance of these generative models is significantly better than several state-of-the-art approaches in the proposed zero-shot framework of the coarse-grained SBIR task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&citation_for_view=mB9AZSAAAAAJ:z_wVstp3MssC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"We present a generative framework for zero-shot action recognition where some of the possible action classes do not occur in the training data. Our approach is based on modeling each action class using a probability distribution whose parameters are functions of the attribute vector representing that action class. In particular, we assume that the distribution parameters for any action class in the visual space can be expressed as a linear combination of a set of basis vectors where the combination weights are given by the attributes of the action class. These basis vectors can be learned solely using labeled data from the known (i.e., previously seen) action classes, and can then be used to predict the parameters of the probability distributions of unseen action classes. We consider two settings: (1) Inductive setting, where we use only the labeled examples of the seen action classes to predict the unseen action class …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&citation_for_view=mB9AZSAAAAAJ:5Ul4iDaHHb8C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Person re-identification (Re-ID) is an important real-world surveillance problem that entails associating a person's identity over a network of cameras. Video-based Re-ID approaches have gained significant attention recently since a video, and not just an image, is often available. In this work, we propose a novel Co-segmentation inspired video Re-ID deep architecture and formulate a Co-segmentation based Attention Module (COSAM) that activates a common set of salient features across multiple frames of a video via mutual consensus in an unsupervised manner. As opposed to most of the prior work, our approach is able to attend to person accessories along with the person. Our plug-and-play and interpretable COSAM module applied on two deep architectures (ResNet50, SE-ResNet50) outperform the state-of-the-art methods on three benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&citation_for_view=mB9AZSAAAAAJ:nrtMV_XWKgEC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Recent studies have shown that current VQA models are heavily biased on the language priors in the train set to answer the question, irrespective of the image. E.g., overwhelmingly answer “what sport is” as “tennis” or “what color banana” as “yellow.” This behavior restricts them from real-world application scenarios. In this work, we propose a novel model-agnostic question encoder, Visually-Grounded Question Encoder (VGQE), for VQA that reduces this effect. VGQE utilizes both visual and language modalities equally while encoding the question. Hence the question representation itself gets sufficient visual-grounding, and thus reduces the dependency of the model on the language priors. We demonstrate the effect of VGQE on three recent VQA models and achieve state-of-the-art results on the bias-sensitive split of the VQAv2 dataset; VQA-CPv2. Further, unlike the existing bias-reduction techniques, on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:EYYDruWGBe4C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Conventional approaches to Sketch-Based Image Retrieval (SBIR) assume that the data of all the classes are available during training. The assumption may not always be practical since the data of a few classes may be unavailable, or the classes may not appear at the time of training. Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) relaxes this constraint and allows the algorithm to handle previously unseen classes during the test. This paper proposes a generative approach based on the Stacked Adversarial Network (SAN) and the advantage of Siamese Network (SN) for ZS-SBIR. While SAN generates a high-quality sample, SN learns a better distance metric compared to that of the nearest neighbor search. The capability of the generative model to synthesize image features based on the sketch reduces the SBIR problem to that of an image-to-image retrieval problem. We evaluate the efficacy of our proposed approach on TU-Berlin, and Sketchy database in both standard ZSL and generalized ZSL setting. The proposed method yields a significant improvement in standard ZSL as well as in a more challenging generalized ZSL setting (GZSL) for SBIR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:Z5m8FVwuT1cC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Practical autonomous driving systems face two crucial challenges: memory constraints and domain gap issues. In this paper, we present a novel approach to learn domain adaptive knowledge in models with limited memory, thus bestowing the model with the ability to deal with these issues in a comprehensive manner. We term this as"" Domain Adaptive Knowledge Distillation"" and address the same in the context of unsupervised domain-adaptive semantic segmentation by proposing a multi-level distillation strategy to effectively distil knowledge at different levels. Further, we introduce a novel cross entropy loss that leverages pseudo labels from the teacher. These pseudo teacher labels play a multifaceted role towards:(i) knowledge distillation from the teacher network to the student network & (ii) serving as a proxy for the ground truth for target domain images, where the problem is completely unsupervised. We introduce four paradigms for distilling domain adaptive knowledge and carry out extensive experiments and ablation studies on real-to-real as well as synthetic-to-real scenarios. Our experiments demonstrate the profound success of our proposed method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:b1wdh0AR-JQC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Attention models are widely used in Vision-language (V-L) tasks to perform the visual-textual correlation. Humans perform such a correlation with a strong linguistic understanding of the visual world. However, even the best performing attention model in V-L tasks lacks such a high-level linguistic understanding, thus creating a semantic gap between the modalities. In this paper, we propose an attention mechanism - Linguistically-aware Attention (LAT) - that leverages object attributes obtained from generic object detectors along with pre-trained language models to reduce this semantic gap. LAT represents visual and textual modalities in a common linguistically-rich space, thus providing linguistic awareness to the attention process. We apply and demonstrate the effectiveness of LAT in three V-L tasks: Counting-VQA, VQA, and Image captioning. In Counting-VQA, we propose a novel counting-specific VQA model to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:ILKRHgRFtOwC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:S16KYo8Pm5AC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"This paper explores an efficient solution for Space-time Super-Resolution, aiming to generate High-resolution Slow-motion videos from Low Resolution and Low Frame rate videos. A simplistic solution is the sequential running of Video Super Resolution and Video Frame interpolation models. However, this type of solutions are memory inefficient, have high inference time, and could not make the proper use of space-time relation property. To this extent, we first interpolate in LR space using quadratic modeling. Input LR frames are super-resolved using a state-of-the-art Video Super-Resolution method. Flowmaps and blending mask which are used to synthesize LR interpolated frame is reused in HR space using bilinear upsampling. This leads to a coarse estimate of HR intermediate frame which often contains artifacts along motion boundaries. We use a refinement network to improve the quality of HR intermediate frame via residual learning. Our model is lightweight and performs better than current state-of-the-art models in REDS STSR Validation set.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:MLfJN-KU85MC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"The task of matching image patches is a fundamental problem in computer vision. When sufficiently textured patches are normalized up to similarity transformation, a simple Normalized Cross Correlation (NCC) of corresponding patches will give a high value. In practice, using it on patches per se may not perform well due to the noisy variations of pixel intensities. A more prudent approach will be to apply it to the abstract features extracted by a deep convolutional network. We study the applicability of an NCC based convolutional network for the task of Patch Matching. Further, there may be cases where the network may fail due to insufficient textures. In those cases, a simple pixel difference based method will be beneficial. To this end, we propose to improve the two basic architectures, Siamese networks and Central-Surround stream networks, using robust matching layers for learning the similarities of patches …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:eJXPG6dFmWUC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"The goal of video captioning is to generate captions for a video by understanding visual and temporal cues. A general video captioning model consists of an Encoder-Decoder framework where Encoder generally captures the visual and temporal information while the decoder generates captions. Recent works have incorporated object-level information into the Encoder by a pretrained off-the-shelf object detector, significantly improving performance. However, using an object detector comes with the following downsides: 1) object detectors may not exhaustively capture all the object categories. 2) In a realistic setting, the performance may be influenced by the domain gap between the object detector and the visual-captioning dataset. To remedy this, we argue that using an external object detector could be eliminated if the model is equipped with the capability of automatically finding salient regions. To achieve this, we propose a novel architecture that learns to attend to salient regions such as objects, persons automatically using a co-segmentation inspired attention module. Then, we utilize a novel salient region interaction module to promote information propagation between salient regions of adjacent frames. Further, we incorporate this salient region-level information into the model using knowledge distillation. We evaluate our model on two benchmark datasets MSR-VTT and MSVD, and show that our model achieves competitive performance without using any object detector.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:WZBGuue-350C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Deblurring is the task of restoring a blurred image to a sharp one, retrieving the information lost due to the blur. In blind deblurring we have no information regarding the blur kernel. As deblurring can be considered as an image to image translation task, deep learning based solutions, including the ones which use GAN (Generative Adversarial Network), have been proven effective for deblurring. Most of them have an encoder-decoder structure. Our objective is to try different GAN structures and improve its performance through various modifications to the existing structure for supervised deblurring. In supervised deblurring we have pairs of blurred and their corresponding sharp images, while in the unsupervised case we have a set of blurred and sharp images but their is no correspondence between them. Modifications to the structures is done to improve the global perception of the model. As blur is non-uniform in nature, for deblurring we require global information of the entire image, whereas convolution used in CNN is able to provide only local perception. Deep models can be used to improve global perception but due to large number of parameters it becomes difficult for it to converge and inference time increases, to solve this we propose the use of attention module (non-local block) which was previously used in language translation and other image to image translation tasks in deblurring. Use of residual connection also improves the performance of deblurring as features from the lower layers are added to the upper layers of the model. It has been found that classical losses like L1, L2, and perceptual loss also help in training of GANs when …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:t7zJ5fGR-2UC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Matching deformable objects using their shapes are an important problem in computer vision since shape is perhaps the most distinguishable characteristic of an object. The problem is difficult due to many factors such as intra-class variations, local deformations, articulations, viewpoint changes and missed and extraneous contour portions due to errors in shape extraction. While small local deformations have been handled in the literature by allowing some leeway in the matching of individual contour points via methods such as Chamfer distance and Hausdorff distance, handling more severe deformations and articulations has been done by applying local geometric corrections such as similarity or affine. However, determining which portions of the shape should be used for the geometric corrections is very hard, although some methods have been tried. In this paper, we address this problem by an efficient …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:u_35RYKgDlwC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"A sub-problem of paramount importance in super-resolution is the generation of an upsampled image (or frame) that is ‘sharp’. In deblurring, the core problem itself is of removing the blur, and it is equivalent to the problem of generating a ‘sharper’ version of the given image. This sharpness in the generated image comes by accurately predicting the high-frequency details (commonly referred to as fine-details) such as object edges. Thus high-frequency prediction is a vital sub-problem in super-resolution and a core problem in deblurring. To generate a sharp upsampled or deblurred image, this paper proposes a multi-stage neural network architecture ‘HFR-Net’ that works on the principle of ‘explicit refinement and fusion of high-frequency details’. To implement this principle, HFR-Net is trained with a novel 2-phase progressive–retrogressive training method. In addition to the training method, this paper also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:p__nRnzSRKYC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"In the information retrieval task, sketch-based image retrieval (SBIR) has drawn significant attention owing to the ease with which sketches can be drawn. The existing deep learning methods for the SBIR are very unrealistic in the real scenario, and its performance reduces drastically for unseen class test examples. Recently, Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) has drawn a lot of attention due to its ability to retrieve the novel/unseen class images at test time. These methods try to project sketch features into the image domain by learning a distribution conditioned on the sketch. We propose a new framework for ZS-SBIR that models joint distribution between the sketch and image domain using a generative adversarial network. The joint distribution modeling ability of our generative model helps to reduce the domain gap between the sketches and images. Our framework helps to synthesize the novel class image features using sketch features. The generative ability of our model for the unseen/novel classes, conditioned on sketch feature, allows it to perform well on the seen as well as unseen class sketches. We conduct extensive experiments on two widely used SBIR benchmark datasets-Sketchy and Tu-Berlin and obtain significant improvement over the existing state-of-the-art. We will release the code publicly for reproducibility of results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:uc_IGeMz5qoC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Video frame interpolation aims to synthesize one or multiple frames between two consecutive frames in a video. It has a wide range of applications including slow-motion video generation, video compression and developing video codecs. Some older works tackled this problem by assuming per-pixel linear motion between video frames. However, objects often follow a non-linear motion pattern in the real domain and some recent methods attempt to model per-pixel motion by non-linear models (eg, quadratic). A quadratic model can also be inaccurate, especially in the case of motion discontinuities over time (ie sudden jerks) and occlusions, where some of the flow information may be invalid or inaccurate. In our paper, we propose to approximate the per-pixel motion using a space-time convolution network that is able to adaptively select the motion model to be used. Specifically, we are able to softly switch between a linear and a quadratic model. Towards this end, we use an end-to-end 3D CNN encoder-decoder architecture over bidirectional optical flows and occlusion maps to estimate the non-linear motion model of each pixel. Further, a motion refinement module is employed to refine the non-linear motion and the interpolated frames are estimated by a simple warping of the neighboring frames with the estimated per-pixel motion. We show that our method outperforms state-of-the-art algorithms on four datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:e_rmSamDkqQC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Divide and Conquer is a well-established approach in the literature that has efficiently solved a variety of problems. However, it is yet to be explored in full in solving image super-resolution. To predict a sharp up-sampled image, this work proposes a divide and conquer approach based wide and deep network (WDN) that divides the 4x up-sampling problem into 32 disjoint subproblems that can be solved simultaneously and independently of each other. Half of these subproblems deal with predicting the overall features of the high-resolution image, while the remaining are exclusively for predicting the finer details. Additionally, a technique that is found to be more effective in calibrating the pixel intensities has been proposed. Results obtained on multiple datasets demonstrate the improved performance of the proposed wide and deep network over state-of-the-art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:ML0RJ9NH7IQC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Deep Convolutional Neural Networks have shown drastic improvements in the performance of various Computer Vision tasks. However, shape classification is a problem that has not seen state-of-the-art results using CNNs. The problem is due to lack of large amounts of data to learn to handle multiple variations such as noise, pose variations, part articulations and affine deformations present in the shapes. In this paper, we introduce a new technique for augmenting 2D shape data that uses part articulations. This utilizes a novel articulation cut detection method to determine putative shape parts. Standard off-the-shelf CNN models trained with our novel data augmentation technique on standard 2D shape datasets yielded significant improvements over the state-of-the-art in most experiments and our data augmentation approach has the potential to be extended to other problems such as Image Classification and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:BrmTIyaxlBUC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"A video super-resolution technique is expected to generate asharp'upsampled video. The sharpness in the generated video comes from the precise prediction of the high-frequency details (eg object edges). Thus high-frequency prediction becomes a vital sub-problem of the super-resolution task. To generate a sharp-upsampled video, this paper proposes an upsampling network architectureHFR-Net'that works on the principle ofexplicit refinement and fusion of high-frequency details'. To implement this principle and to train HFR-Net, a novel technique named 2-phase progressive-retrogressive training is being proposed. Additionally, a method called dual motion warping is also being introduced to preprocess the videos that have varying motion intensities (slow and fast). Results on multiple video datasets demonstrate the improved performance of our approach over the current state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:4MWp96NkSFoC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Video-based computer vision tasks can benefit from estimation of the salient regions and interactions between those regions. Traditionally, this has been done by identifying the object regions in the images by utilizing pre-trained models to perform object detection, object segmentation and/or object pose estimation. Although using pre-trained models is a viable approach, it has several limitations in the need for an exhaustive annotation of object categories, a possible domain gap between datasets and a bias that is typically present in pre-trained models. In this work, we propose to utilize the common rationale that a sequence of video frames capture a set of common objects and interactions between them, thus a notion of co-segmentation between the video frame features may equip the model with the ability to automatically focus on task-specific salient regions and improve the underlying task’s performance in an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:oNZyr7d5Mn4C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Generalizing beyond the experiences has a significant role in developing robust and practical machine learning systems. It has been shown that current Visual Question Answering (VQA) models are over-dependent on the language-priors (spurious correlations between question-types and their most frequent answers) from the train set and pose poor performance on Out-of-Distribution (OOD) test sets. This conduct negatively affects the robustness of VQA models and restricts them from being utilized in real-world situations. This paper shows that the sequence model architecture used in the question-encoder has a significant role in the OOD performance of VQA models. To demonstrate this, we performed a detailed analysis of various existing RNN-based and Transformer-based question-encoders, and along, we proposed a novel Graph attention network (GAT)-based question-encoder. Our study found that a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:HbR8gkJAVGIC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"The human face is one of the predominant means of person recognition. Human faces are affected by many factors i.e. time, attributes, weather, and other subject-specific variations. Although face aging has been studied in the past, the impact of the aforesaid factors, especially, the effect of attributes on the aging process were unexplored. In this paper, we propose a novel holistic “Face Age progression With Attribute Manipulation” (FAWAM) model that generates face images at different ages while simultaneously varying attributes and other subject specific characteristics. We address the task in a bottom-up manner, considering both age and attributes submodules. For face aging, we use an attribute-conscious face aging model with a pyramidal generative adversarial network that can model age-specific facial changes while maintaining intrinsic subject specific characteristics. For facial attribute manipulation, the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:LI9QrySNdTsC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Acoustic imaging systems dominate in underwater imaging due to their unique ability to illuminate objects on the seabed, even in dark or turbid water conditions. These systems mounted on an autonomous underwater vehicle (AUV) are being used for a variety of civilian and military applications. Mine detection and classification is a predominant application. The raw images captured using these systems are usually noisy and poor in their resolution. Consequently, methods to enhance sonar images are necessary to aid further processing and classification of these acquired scenes. Inspired by the developments in the field of deep learning in different areas of computer vision, this study explores efficient deep neural networks for acoustic image super resolution. The study is performed on a custom-made sonar image dataset to handle the deficiency of public datasets in the domain. We employ a Generative …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:i2xiXl-TujoC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Divide and conquer is an established algorithm design paradigm that has proven itself to solve a variety of problems efficiently. However, it is yet to be fully explored in solving problems with a neural network, particularly the problem of image super-resolution. In this work, we propose an approach to divide the problem of image super-resolution into multiple subproblems and then solve/conquer them with the help of a neural network. Unlike a typical deep neural network, we design an alternate network architecture that is much wider (along with being deeper) than existing networks and is specially designed to implement the divide-and-conquer design paradigm with a neural network. Additionally, a technique to calibrate the intensities of feature map pixels is being introduced. Extensive experimentation on five datasets reveals that our approach towards the problem and the proposed architecture generate better …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:TIZ-Mc8IlK0C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Recognizing a person's face images with intentional/unintentional disguising effects such as make-up, plastic surgery, artificial wearables (hats, eye-glasses) is a challenging task. We propose a Feature EnsemBle Network (FEBNet) for recognizing Disguised Faces in the Wild (DFW). FEBNet encompasses multiple base networks (SE-ResNet50, Inception-ResNet-V1) pretrained on large-scale face recognition datasets (MS-Celeb-1M, VGGFace2) and fine-tuned on DFW training dataset. During the fine-tuning phase, we propose to use two novel objective functions, namely, 1) Category loss, 2) Impersonator Triplet loss along with two prevalent objective functions: Identity loss, Inter-person Triplet loss. To further improve the performance, we apply a state-of-the-art re-ranking strategy as a post-processing step. Extensive ablation studies and evaluation results show that FEBNet significantly outperforms the baseline models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:yB1At4FlUx8C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Sketch-based image retrieval (SBIR) is the task of retrieving images from a natural image database that correspond to a given hand-drawn sketch. Ideally, an SBIR model should learn to associate components in the sketch (say, feet, tail, etc.) with the corresponding components in the image having similar shape characteristics. However, current evaluation methods simply focus only on coarse-grained evaluation where the focus is on retrieving images which belong to the same class as the sketch but not necessarily having the same shape characteristics as in the sketch. As a result, existing methods simply learn to associate sketches with classes seen during training and hence fail to generalize to unseen classes. In this paper, we propose a new benchmark for zero-shot SBIR where the model is evaluated in novel classes that are not seen during training. We show through extensive experiments that existing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:xtoqd-5pKcoC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Acoustic imaging sonar systems are widely used for long-range underwater surveillance in various civilian and military applications. They provide 2-D images of underwater objects, even in turbid water conditions where optical underwater imaging systems fail. Achieving high accuracy in automatic deep learning based underwater image classification remains an open problem due to insufficient data availability, poor image resolution, low signal-to-noise ratio surroundings, etc. In this study, we conduct a comparative analysis of different advanced deep learning approaches, i.e., transfer learning and few-shot learning, to address the problem of automatic object classification in sonar images, using a few samples of data. Specifically, two metric learning-based approaches, i.e., siamese network and triplet network as well as library-based approaches, are studied under the few-shot learning paradigm. Extensive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:q3CdL3IzO_QC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"The present disclosure relates to semiconductor structures and, more particularly, to devices with slotted active regions and methods of manufacture. The method includes: forming a mandrel on top of a diffusion region comprising a diffusion material; forming a first material over the mandrel and the diffusion region; removing the mandrel to form multiple spacers each having a thickness; depositing a second material over the spacers and the diffusion material; and forming slots in the diffusion region by removing a portion of the second material over the diffusion region and the underlying diffusion material.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:Dip1O2bNi0gC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Generalizing beyond the experiences has a significant role in developing practical AI systems. It has been shown that current Visual Question Answering (VQA) models are over-dependent on the language-priors (spurious correlations between question-types and their most frequent answers) from the train set and pose poor performance on Out-of-Distribution (OOD) test sets. This conduct limits their generalizability and restricts them from being utilized in real-world situations. This paper shows that the sequence model architecture used in the question-encoder has a significant role in the generalizability of VQA models. To demonstrate this, we performed a detailed analysis of various existing RNN-based and Transformer-based question-encoders, and along, we proposed a novel Graph attention network (GAT)-based question-encoder. Our study found that a better choice of sequence model in the question-encoder improves the generalizability of VQA models even without using any additional relatively complex bias-mitigation approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:k8Z6L05lTy4C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",31,"Representation learning from 3D point clouds is challenging due to their inherent nature of permutation invariance and irregular distribution in space. Existing deep learning methods follow a hierarchical feature extraction paradigm in which high-level abstract features are derived from low-level features. However, they fail to exploit different granularity of information due to the limited interaction between these features. To this end, we propose Multi-Abstraction Refinement Network (MARNet) that ensures an effective exchange of information between multi-level features to gain local and global contextual cues while effectively preserving them till the final layer. We empirically show the effectiveness of MARNet in terms of state-of-the-art results on two challenging tasks: Shape classification and Coarse-to-fine grained semantic segmentation. MARNet significantly improves the classification performance by 2% over the baseline and outperforms the state-of-the-art methods on semantic segmentation task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&citation_for_view=mB9AZSAAAAAJ:gsN89kCJA0AC,http://sites.google.com/view/anurag-mittal/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"Conditional Value-at-Risk (CVaR) is a popular risk measure for modelling losses in the case of a rare but extreme event. We consider the problem of estimating CVaR from i.i.d. samples of an unbounded random variable, which is either sub-Gaussian or sub-exponential. We derive a novel one-sided concentration bound for a natural sample-based CVaR estimator in this setting. Our bound relies on a concentration result for a quantile-based estimator for Value-at-Risk (VaR), which may be of independent interest.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&citation_for_view=Q1YXWpoAAAAJ:jU7OWUQzBzMC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"Known finite-sample concentration bounds for the Wasserstein distance between the empirical and true distribution of a random variable are used to derive a two-sided concentration bound for the error between the true conditional value-at-risk (CVaR) of a (possibly unbounded) random variable and a standard estimate of its CVaR computed from an iid sample. The bound applies under fairly general assumptions on the random variable, and improves upon previous bounds which were either one sided, or applied only to bounded random variables. Specializations of the bound to sub-Gaussian and sub-exponential random variables are also derived. A similar procedure is followed to derive concentration bounds for the error between the true and estimated Cumulative Prospect Theory (CPT) value of a random variable, in cases where the random variable is bounded or sub-Gaussian. These bounds are shown to match a known bound in the bounded case, and improve upon the known bound in the sub-Gaussian case. The usefulness of the bounds is illustrated through an algorithm, and corresponding regret bound for a stochastic bandit problem, where the underlying risk measure to be optimized is CVaR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&citation_for_view=Q1YXWpoAAAAJ:yxmsSjX2EkcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"Cumulative prospect theory (CPT) is a popular approach for modeling human preferences. It is based on probabilistic distortions and generalizes the expected utility theory. We bring the CPT to a stochastic optimization framework and propose algorithms for both estimation and optimization of CPT-value objectives. We propose an empirical distribution function-based scheme to estimate the CPT value, and then, use this scheme in the inner loop of a CPT-value optimization procedure. We propose both gradient based as well as gradient-free CPT-value optimization algorithms that are based on two well-known simulation optimization ideas: simultaneous perturbation stochastic approximation and model-based parameter search, respectively. We provide theoretical convergence guarantees for all the proposed algorithms and also illustrate the potential of CPT-based criteria in a traffic signal control application.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&citation_for_view=Q1YXWpoAAAAJ:7wO8s98CvbsC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"Conditional Value-at-Risk (CVaR) is a widely used risk metric in applications such as finance. We derive concentration bounds for CVaR estimates, considering separately the cases of sub-Gaussian, light-tailed and heavy-tailed distributions. For the sub-Gaussian and light-tailed cases, we use a classical CVaR estimator based on the empirical distribution constructed from the samples. For heavy-tailed random variables, we assume a mild ‘bounded moment’condition, and derive a concentration bound for a truncation-based estimator. Our concentration bounds exhibit exponential decay in the sample size, and are tighter than those available in the literature for the above distribution classes. To demonstrate the applicability of our concentration results, we consider the CVaR optimization problem in a multi-armed bandit setting. Specifically, we address the best CVaR-arm identification problem under a fixed budget. Using our CVaR concentration results, we derive an upperbound on the probability of incorrect arm identification.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&citation_for_view=Q1YXWpoAAAAJ:Ade32sEp0pkC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"The classic objective in a reinforcement learning (RL) problem is to find a policy that minimizes, in expectation, a long-run objective such as the infinite-horizon cumulative discounted or long-run average cost. In many practical applications, optimizing the expected value alone is not sufficient, and it may be necessary to include a risk measure in the optimization process, either in the objective or as a constraint. Various risk measures have been proposed in the literature, eg, variance, exponential utility, percentile performance, chance constraints, value at risk (quantile), conditional value-at-risk, coherent risk measure, prospect theory and its later enhancement, cumulative prospect theory. In this article, we focus on the combination of risk criteria and reinforcement learning in a constrained optimization framework, ie, a setting where the goal to find a policy that optimizes the usual objective of infinite-horizon discounted …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&citation_for_view=Q1YXWpoAAAAJ:jFemdcug13IC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"The classic objective in a reinforcement learning (RL) problem is to find a policy that minimizes, in expectation, a long-run objective such as the infinite-horizon discounted or long-run average cost. In many practical applications, optimizing the expected value alone is not sufficient, and it may be necessary to include a risk measure in the optimization process, either as the objective or as a constraint. Various risk measures have been proposed in the literature, eg, mean-variance tradeoff, exponential utility, the percentile performance, value at risk, conditional value at risk, prospect theory and its later enhancement, cumulative prospect theory. In this article, we focus on the combination of risk criteria and reinforcement learning in a constrained optimization framework, ie, a setting where the goal to find a policy that optimizes the usual objective of infinite-horizon discounted/average cost, while ensuring that an explicit risk constraint is satisfied. We introduce the risk-constrained RL framework, cover popular risk measures based on variance, conditional value-at-risk and cumulative prospect theory, and present a template for a risk-sensitive RL algorithm. We survey some of our recent work on this topic, covering problems encompassing discounted cost, average cost, and stochastic shortest path settings, together with the aforementioned risk measures in a constrained framework. This non-exhaustive survey is aimed at giving a flavor of the challenges involved in solving a risk-sensitive RL problem, and outlining some potential future research directions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&citation_for_view=Q1YXWpoAAAAJ:MAUkC_7iAq8C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"Traditional multi-armed bandit problems are geared towards finding the arm with the highest expected value--an objective that is risk-neutral. In several practical applications, eg, finance, a risk-sensitive objective is to control the worst-case losses and Conditional Value-at-Risk (CVaR) is a popular risk measure for modelling the aforementioned objective. We consider the CVaR optimization problem in a best-arm identification framework under a fixed budget. First, we derive a novel two-sided concentration bound for a well-known CVaR estimator using empirical distribution function, assuming that the underlying distribution is unbounded, but either sub-Gaussian or light-tailed. This bound may be of independent interest. Second, we adapt the well-known successive rejects algorithm to incorporate a CVaR-based criterion and derive an upper-bound on the probability of incorrect identification of our proposed algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&citation_for_view=Q1YXWpoAAAAJ:WC9gN4BGCRcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"We consider the problem of estimating a spectral risk measure (SRM) from iid samples, and propose a novel method that is based on numerical integration. We show that our SRM estimate concentrates exponentially, when the underlying distribution has bounded support. Further, we also consider the case when the underlying distribution satisfies an exponential moment bound, which includes sub-Gaussian and subexponential distributions. For these distributions, we derive a concentration bound for our estimation scheme. We validate the theoretical findings on a synthetic setup, and in a vehicular traffic routing application.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:q-HalDI95KYC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"We propose a stochastic approximation (SA) based method with randomization of samples for policy evaluation using the least squares temporal difference (LSTD) algorithm. Our proposed scheme is equivalent to running regular temporal difference learning with linear function approximation, albeit with samples picked uniformly from a given dataset. Our method results in an O(d) improvement in complexity in comparison to LSTD, where d is the dimension of the data. We provide non-asymptotic bounds for our proposed method, both in high probability and in expectation, under the assumption that the matrix underlying the LSTD solution is positive definite. The latter assumption can be easily satisfied for the pathwise LSTD variant proposed by Lazaric (J Mach Learn Res 13:3041–3074, 2012). Moreover, we also establish that using our method in place of LSTD does not impact the rate of convergence of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:SjuI4pbJlxcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"This paper presents a unified approach based on Wasserstein distance to derive concentration bounds for empirical estimates for two broad classes of risk measures defined in the paper. The classes of risk measures introduced include as special cases well known risk measures from the finance literature such as conditional value at risk (CVaR), optimized certainty equivalent risk, spectral risk measures, utility-based shortfall risk, cumulative prospect theory (CPT) value, rank dependent expected utility and distorted risk measures. Two estimation schemes are considered, one for each class of risk measures. One estimation scheme involves applying the risk measure to the empirical distribution function formed from a collection of i.i.d. samples of the random variable (r.v.), while the second scheme involves applying the same procedure to a truncated sample. The bounds provided apply to three popular classes of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:-jrNzM816MMC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"We introduce deterministic perturbation (DP) schemes for the recently proposed random directions stochastic approximation, and propose new first-order and second-order algorithms. In the latter case, these are the first second-order algorithms to incorporate DPs. We show that the gradient and/or Hessian estimates in the resulting algorithms with DPs are asymptotically unbiased, so that the algorithms are provably convergent. Furthermore, we derive convergence rates to establish the superiority of the first-order and second-order algorithms, for the special case of a convex and quadratic optimization problem, respectively. Numerical experiments are used to validate the theoretical results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:-mN3Mh-tlDkC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"The objective in a traditional reinforcement learning (RL) problem is to find a policy that optimizes the expected value of a performance metric such as the infinite-horizon cumulative discounted or long-run average cost/reward. In practice, optimizing the expected value alone may not be satisfactory, in that it may be desirable to incorporate the notion of risk into the optimization problem formulation, either in the objective or as a constraint. Various risk measures have been proposed in the literature, eg, exponential utility, variance, percentile performance, chance constraints, value at risk (quantile), conditional value-at-risk, prospect theory and its later enhancement, cumulative prospect theory.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:HGTzPopzzJcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"While the objective in traditional multi-armed bandit problems is to find the arm with the highest mean, in many settings, finding an arm that best captures information about other arms is of interest. This objective, however, requires learning the underlying correlation structure and not just the means. Sensors placement for industrial surveillance and cellular network monitoring are a few applications, where the underlying correlation structure plays an important role. Motivated by such applications, we formulate the correlated bandit problem, where the objective is to find the arm with the lowest mean-squared error (MSE) in estimating all the arms. To this end, we derive first an MSE estimator based on sample variances/covariances and show that our estimator exponentially concentrates around the true MSE. Under a best-arm identification framework, we propose a successive rejects type algorithm and provide bounds on the probability of error in identifying the best arm. Using minimax theory, we also derive fundamental performance limits for the correlated bandit problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:LPtt_HFRSbwC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"In several applications such as clinical trials and financial portfolio optimization, the expected value (or the average reward) does not satisfactorily capture the merits of a drug or a portfolio. In such applications, risk plays a crucial role, and a risk-aware performance measure is preferable, so as to capture losses in the case of adverse events. This survey aims to consolidate and summarise the existing research on risk measures, specifically in the context of multi-armed bandits. We review various risk measures of interest, and comment on their properties. Next, we review existing concentration inequalities for various risk measures. Then, we proceed to defining risk-aware bandit problems, We consider algorithms for the regret minimization setting, where the exploration-exploitation trade-off manifests, as well as the best-arm identification setting, which is a pure exploration problem -- both in the context of risk-sensitive measures. We conclude by commenting on persisting challenges and fertile areas for future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:jE2MZjpN3IcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"Let µk denote the expected value of the stochastic rewards from arm k, for k= 1,..., K. The optimal arm is one that has the highest expected value, ie, µ∗= maxk= 1,..., K µk. The goal of the bandit algorithm is to maximize Sn=∑ n t= 1 Xt. Notice that Sn is a random variable (rv) and hence, has a distribution. So, a natural objective is to design an algorithm that maximizes E (Sn).
The framework outlined above captures “exploration-exploitation dilemma”. To elaborate, in any round the bandit algorithm can choose to either explore by pulling an arm to estimate its mean reward, or exploit by pulling an arm that has the highest estimated mean reward. Notice that the rewards are stochastic, ie, each arm has a reward distribution with a mean and certain spread. Since the bandit algorithm does not know the arms’ reward distributions, it has to estimate the mean rewards though sampling and the sampling has to be adaptive, ie, in any round, based on the samples obtained so far, the bandit algorithm has to adaptively decide which arm to pull next. A bandit algorithm that explores too often would end with a lower expected value for the total reward Sn. On the other hand, an algorithm that does not sample the individual arms enough number of times to be confident about their mean rewards would end up pulling a sub-optimal excessively in the exploit stage and this would again lead to a low Sn in expectation. Thus, the",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:WC23djZS0W4C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"We introduce biased gradient oracles to capture a setting where the function measurements have an estimation error that can be controlled through a batch size parameter. Our proposed oracles are appealing in several practical contexts, for instance, risk measure estimation from a batch of independent and identically distributed (i.i.d.) samples, or simulation optimization, where the function measurements are ‘biased’ due to computational constraints. In either case, increasing the batch size reduces the estimation error. We highlight the applicability of our biased gradient oracles in a risk-sensitive reinforcement learning setting. In the stochastic non-convex optimization context, we analyze a variant of the randomized stochastic gradient (RSG) algorithm with a biased gradient oracle. We quantify the convergence rate of this algorithm by deriving non-asymptotic bounds on its performance. Next, in the stochastic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:Dem6FJhTUoYC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"We propose two policy gradient algorithms for solving the problem of control in an off-policy reinforcement learning (RL) context. Both algorithms incorporate a smoothed functional (SF) based gradient estimation scheme. The first algorithm is a straightforward combination of importance sampling-based off-policy evaluation with SF-based gradient estimation. The second algorithm, inspired by the stochastic variance-reduced gradient (SVRG) algorithm, incorporates variance reduction in the update iteration. For both algorithms, we derive non-asymptotic bounds that establish convergence to an approximate stationary point. From these results, we infer that the first algorithm converges at a rate that is comparable to the well-known REINFORCE algorithm in an off-policy RL context, while the second algorithm exhibits an improved rate of convergence.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:AXkvAH5U_nMC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"We present in this paper a family of generalized simultaneous perturbation stochastic approximation (G-SPSA) estimators that estimate the gradient of the objective using noisy function measurements, but where the number of function measurements and the form of the gradient estimator is guided by the desired estimator bias. In particular, estimators with more function measurements are seen to result in lower bias. We provide an analysis of convergence of generalized SPSA, and point to possible future directions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:PyEswDtIyv0C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"The classic objective in a reinforcement learning (RL) problem is to find a policy that minimizes, in expectation, a long-run cost objective such as the infinite horizon discounted or average cost. In many practical applications, optimizing the expected value alone is not sufficient and it may be necessary to include a risk measure in the optimization process either as the objective or a constraint. Various risk measures have been proposed in the literature, e.g., mean-variance tradeoff, exponential utility, the percentile performance, value at risk, conditional value at risk, prospect theory and its later enhancement, cumulative prospect theory. In this two-part article, we are primarily concerned with the combination of risk criteria and reinforcement learning in a constrained optimization framework, i.e., a setting where the goal to find a policy that minimizes the usual objective of infinite horizon discounted/average cost, while …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:prdVHNxh-e8C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"Known finite-sample concentration bounds for the Wasserstein distance between the empirical and true distribution of a random variable are used to derive a two-sided concentration bound for the error between the true conditional value-at-risk (CVaR) of a (possibly unbounded) random variable and a standard estimate of its CVaR computed from an iid sample. The bound applies under fairly general assumptions on the random variable, and improves upon previous bounds which were either one sided, or applied only to bounded random variables. Specializations of the bound to sub-Gaussian and sub-exponential random variables are also derived. A similar procedure is followed to derive concentration bounds for the error between the true and estimated Cumulative Prospect Theory (CPT) value of a random variable, in cases where the random variable is bounded or sub-Gaussian. These bounds are shown to match a known bound in the bounded case, and improve upon the known bound in the sub-Gaussian case. The usefulness of the bounds is illustrated through an algorithm, and corresponding regret bound for a stochastic bandit problem, where the underlying risk measure to be optimized is CVaR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:DBa1UEJaJKAC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm, when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal O (1/t) rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation, and show that this variant fares favourably in problems with ill-conditioned features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:QyXJ3EUuO1IC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm, when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyze a variant of TD that incorporates regularization. From our finite time analysis, we conclude that the regularized version of TD is useful for problems with ill-conditioned features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:U_HPUtbDl20C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"Utility-Based Shortfall Risk (UBSR) is a risk metric that is increasingly popular in financial applications, owing to certain desirable properties that it enjoys. We consider the problem of estimating UBSR in a recursive setting, where samples from the underlying loss distribution are available one-at-a-time. We cast the UBSR estimation problem as a root finding problem, and propose stochastic approximation-based estimations schemes. We derive non-asymptotic bounds on the estimation error in the number of samples. We also consider the problem of UBSR optimization within a parameterized class of random variables. We propose a stochastic gradient descent based algorithm for UBSR optimization, and derive non-asymptotic bounds on its convergence.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:NDuN12AVoxsC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:1Ye0OR6EYb4C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,"Traditional multi-armed bandit problems are geared towards finding the arm with the highest expected value – an objective that is risk-neutral. In several practical applications, e.g., finance, a risk-sensitive objective is to control the worst-case losses and Conditional Value-at-Risk (CVaR) is a popular risk measure for modeling the aforementioned objective. We consider the CVaR optimization problem in a best-arm identification framework under a fixed budget. First, we derive a novel two-sided concentration bound for a well-known CVaR estimator using empirical distribution function, assuming that the underlying distribution is unbounded, but light-tailed. This bound may be of independent interest. Second, we adapt the well-known successive rejects algorithm to incorporate a CVaRbased criterion and derive an upper-bound on the probability of incorrect identification of our proposed algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&citation_for_view=Q1YXWpoAAAAJ:rHJHxKgnXwkC,http://cse.iitm.ac.in/~prashla/
Shweta Agrawal,['Cryptography'],25,"Constructing indistinguishability obfuscation (iO iO) 17 is a central open question in cryptography. We provide new methods to make progress towards this goal. Our contributions may be summarized as follows: 1. Bootstrapping. In a recent work, Lin and Tessaro 71 (LT) show that iO iO may be constructed using (i) Functional Encryption (FE FE) for polynomials of degree L,(ii) Pseudorandom Generators (PRG PRG) with blockwise locality L and polynomial expansion, and (iii) Learning With Errors (LWE LWE). Since there exist constructions of FE FE for quadratic polynomials from standard assumptions on bilinear maps 16, 68, the ideal scenario would be to set L= 2 L= 2, yielding iO iO from widely believed assumptions Unfortunately, it was shown soon after 18, 73 that PRG PRG with block locality 2 and the expansion factor required by the LT construction, concretely\varOmega (n ⋅ 2^ b (3+ ϵ)) Ω (n· 2 b (3+ ϵ …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&citation_for_view=uLkJ5_4AAAAJ:k_IJM867U9cC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Boneh, Waters and Zhandry (CRYPTO 2014) used multilinear maps to provide a solution to the long-standing problem of public-key broadcast encryption (BE) where all parameters in the system are small. In this work, we improve their result by providing a solution that uses only bilinear maps and Learning With Errors (LWE). Our scheme is fully collusion-resistant against any number of colluders, and can be generalized to an identity-based broadcast system with short parameters. Thus, we reclaim the problem of optimal broadcast encryption from the land of “Obfustopia”.
Our main technical contribution is a ciphertext policy attribute based encryption (CP-ABE) scheme which achieves special efficiency properties – its ciphertext size, secret key size, and public key size are all independent of the size of the circuits supported by the scheme. We show that this special CP-ABE scheme implies BE with optimal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&citation_for_view=uLkJ5_4AAAAJ:lSLTfruPkqcC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Candidates of Indistinguishability Obfuscation () can be categorized as “direct” or “bootstrapping based”. Direct constructions rely on high degree multilinear maps [28, 29] and provide heuristic guarantees, while bootstrapping based constructions [2, 7, 33, 36, 38, 39] rely, in the best case, on bilinear maps as well as new variants of the Learning With Errors () assumption and pseudorandom generators. Recent times have seen exciting progress in the construction of indistinguishability obfuscation () from bilinear maps (along with other assumptions) [2, 7, 33, 38].
As a notable exception, a recent work by Agrawal [2] provided a construction for without using any maps. This work identified a new primitive, called Noisy Linear Functional Encryption () that provably suffices for and gave a direct construction of from new assumptions on lattices. While a preliminary cryptanalysis for the new assumptions was …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:vV6vV6tmYwMC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Constructing Attribute Based Encryption (ABE) [56] for uniform models of computation from standard assumptions, is an important problem, about which very little is known. The only known ABE schemes in this setting that (i) avoid reliance on multilinear maps or indistinguishability obfuscation, (ii) support unbounded length inputs and (iii) permit unbounded key requests to the adversary in the security game, are by Waters from Crypto, 2012 [57] and its variants. Waters provided the first ABE for Deterministic Finite Automata (DFA) satisfying the above properties, from a parametrized or “q-type” assumption over bilinear maps. Generalizing this construction to Nondeterministic Finite Automata (NFA) was left as an explicit open problem in the same work, and has seen no progress to date. Constructions from other assumptions such as more standard pairing based assumptions, or lattice based assumptions has also proved …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:ns9cj8rnVeAC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Inner product functional encryption () [1] is a popular primitive which enables inner product computations on encrypted data. In , the ciphertext is associated with a vector $$\varvec{x}$$, the secret key is associated with a vector $$\varvec{y}$$ and decryption reveals the inner product $$\langle \varvec{x},\varvec{y}\rangle $$. Previously, it was known how to achieve adaptive indistinguishability () based security for from the , and assumptions [8]. However, in the stronger simulation () based security game, it was only known how to support a restricted adversary that makes all its key requests either before or after seeing the challenge ciphertext, but not both. In more detail, Wee [46] showed that the -based scheme of Agrawal et al. (Crypto 2016) achieves semi-adaptive simulation-based security, where the adversary must make all its key requests after seeing the challenge ciphertext. On the other hand, O’Neill showed that all -secure  …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:RYcK_YlVTxYC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Text and image analysis are playing very important role in healthcare and medical domain. The whole clinical process is getting affected positively by text and image processing. Many datasets, algorithms, models and tools are available for extracting useful information and for applying natural language processing, machine learning and deep learning algorithms. But there exist many challenges in healthcare data for successful implementation of text and image based machine learning models, which include: (i) storage and retrieval of high resolution images, (ii) scarcity of data (iii) dataset generation and validation, (iv) appropriate algorithms and models for extracting hidden information from images and texts, (v) use of modern concepts like deep neural networks, recurrent neural network, (vi) data wrangling and (vii) processing capacity of processors. This chapter will: (i) establish a background for the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:pqnbT2bcN3wC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Consider sources that supply sensitive data to an aggregator. Standard encryption only hides the data from eavesdroppers, but using specialized encryption one can hope to hide the data (to the extent possible) from the aggregator itself. For flexibility and security, we envision schemes that allow sources to supply encrypted data, such that at any point a dynamically-chosen subset of sources can allow an agreed-upon joint function of their data to be computed by the aggregator. A primitive called multi-input functional encryption (MIFE), due to Goldwasser et al.(EUROCRYPT 2014), comes close, but has two main limitations:",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:maZDTaKrznsC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Blind signatures are a fundamental cryptographic primitive with numerous practical applications. While there exist many practical blind signatures from number-theoretic assumptions, the situation is far less satisfactory from post-quantum assumptions. In this work, we provide the first overall practical, lattice-based blind signature, supporting an unbounded number of signature queries and additionally enjoying optimal round complexity. We provide a detailed estimate of parameters achieved -- we obtain a signature of size slightly above 45KB, for a core-SVP hardness of 109 bits. The run-times of the signer, user and verifier are also very small.
Our scheme relies on the Gentry, Peikert and Vaikuntanathan signature [STOC'08] and non-interactive zero-knowledge proofs for linear relations with small unknowns, which are significantly more efficient than their general purpose counterparts. Its security stems from a new …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:ZHo1McVdvXMC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"We construct the first multi-input functional encryption (MIFE) scheme for quadratic functions from pairings. Our construction supports polynomial number of users, where user i, for , encrypts input to obtain ciphertext , the key generator provides a key for vector and decryption, given and , recovers and nothing else. We achieve indistinguishability-based (selective) security against unbounded collusions under the standard bilateral matrix Diffie-Hellman assumption. All previous MIFE schemes either support only inner products (linear functions) or rely on strong cryptographic assumptions such as indistinguishability obfuscation or multi-linear maps.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:3s1wT3WcHBgC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"We construct Indistinguishability Obfuscation () and Functional Encryption () schemes in the Turing machine model from the minimal assumption of compact for circuits (). Our constructions overcome the barrier of sub-exponential loss incurred by all prior work. Our contributions are:
1.
We construct in the Turing machine model from the same assumptions as required in the circuit model, namely, sub-exponentially secure for circuits. The previous best constructions [6, 41] require sub-exponentially secure for circuits, which in turn requires sub-exponentially secure for circuits [5, 15].
2.
We provide a new construction of single input for Turing machines with unbounded length inputs and optimal parameters from polynomially secure, compact for circuits. The previously best known …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:mB3voiENLucC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Broadcast Encryption with optimal parameters was a long-standing problem, whose first solution was provided in an elegant work by Boneh, Waters and Zhandry [BWZ14]. However, this work relied on multilinear maps of logarithmic degree, which is not considered a standard assumption. Recently, Agrawal and Yamada [AY20] improved this state of affairs by providing the first construction of optimal broadcast encryption from Bilinear Maps and Learning With Errors (LWE). However, their proof of security was in the generic bilinear group model. In this work, we improve upon their result by providing a new construction and proof in the standard model. In more detail, we rely on the Learning With Errors (LWE) assumption and the Knowledge of OrthogonALity Assumption (KOALA) [BW19] on bilinear groups.
Our construction combines three building blocks: a (computational) nearly linear secret sharing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:70eg2SAEIzsC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Constructing indistinguishability obfuscation (iO)[BGI+ 01] is a central open question in cryptography. We provide new methods to make progress towards this goal. Our contributions may be summarized as follows: 1.{\textbf Bootstrapping}. In a recent work, Lin and Tessaro [LT17](LT) show that iO may be constructed using i) Functional Encryption (FE) for polynomials of degree , ii) Pseudorandom Generators (PRG) with blockwise locality and polynomial expansion, and iii) Learning With Errors (LWE). Since there exist constructions of FE for quadratic polynomials from standard assumptions on bilinear maps [Lin17, BCFG17], the ideal scenario would be to set , yielding iO from widely believed assumptions. Unfortunately, it was shown soon after [LV17, BBKK17] that PRG with block locality and the expansion factor required by the LT construction, concretely , where is the input length and is the block length, do not exist. In the worst case, these lower bounds rule out 2-block local PRG with stretch . While [LV17, BBKK17] provided strong negative evidence for constructing iO based on bilinear maps, they could not rule out the possibility completely; a tantalizing gap has remained. Given the current state of lower bounds, the existence of 2 block local PRG with expansion factor remains open, although this stretch does not suffice for the LT bootstrapping, and is hence unclear to be relevant for iO. In this work, we improve the state of affairs as follows.(a) Weakening requirements on PRGs: In this work, we show that the narrow window of expansion factors left open by lower bounds do suffice for iO. We show a new method to construct FE for from i) FE for degree L polynomials, ii) PRGs of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:-f6ydRqryjwC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Blind signatures have numerous applications in privacy-preserving technologies. While there exist many practical blind signatures from number-theoretic assumptions, the situation is far less satisfactory from post-quantum assumptions. In this work, we make advances towards making lattice-based blind signatures practical. We introduce two round-optimal constructions in the random oracle model, and provide guidance towards their concrete realization as well as efficiency estimates.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:dfsIfKJdRG4C,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Waters [Crypto, 2012] provided the first attribute based encryption scheme ABE for Deterministic Finite Automata (DFA) from a parametrized or “q-type” assumption over bilinear maps. Obtaining a construction from static assumptions has been elusive, despite much progress in the area of ABE.
In this work, we construct the first attribute based encryption scheme for DFA from static assumptions on pairings, namely, the assumption. Our scheme supports unbounded length inputs, unbounded length machines and unbounded key requests. In more detail, secret keys in our construction are associated with a DFA M of unbounded length, ciphertexts are associated with a tuple where is a public attribute of unbounded length and is a secret message bit, and decryption recovers if and only if .
Our techniques are at least as interesting as our final result. We present a simple compiler that combines constructions of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:GnPB-g6toBAC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"We initiate the study of multi-party functional encryption ( which unifies and abstracts out various notions of functional encryption which support distributed ciphertexts or secret keys, such as multi-input FE, multi-client FE, decentralized multi-client FE, multi-authority FE, dynamic decentralized FE, adhoc multi-input FE and such others. Using our framework, we identify several gaps in the literature and provide some constructions to fill these:
1. Multi-Authority with Inner Product Computation. The recent work of Abdalla et al. (ASIACRYPT’20) constructed a novel “composition” of Attribute Based Encryption () and Inner Product Functional Encryption (), namely functional encryption schemes that combine the access control functionality of attribute based encryption with the possibility of performing linear operations on the encrypted data. In this work, we extend the access control component to support the much more challenging multi-authority …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:2P1L_qKh6hAC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"We define and construct Deniable Fully Homomorphic Encryption based on the Learning With Errors (LWE) polynomial hardness assumption. Deniable FHE enables storing encrypted data in the cloud to be processed securely without decryption, maintaining deniability of the encrypted data, as well the prevention of vote-buying in electronic voting schemes where encrypted votes can be tallied without decryption.
Our constructions achieve compactness independently of the level of deniability- both the size of the public key and the size of the ciphertexts are bounded by a fixed polynomial, independent of the detection probability achieved by the scheme. This is in contrast to all previous constructions of deniable encryption schemes (even without requiring homomorphisms) which are based on polynomial hardness assumptions, originating with the seminal work of Canetti, Dwork, Naor and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:4OULZ7Gr8RgC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"The classic work of Gorbunov, Vaikuntanathan and Wee (CRYPTO 2012) and follow-ups provided constructions of bounded collusion Functional Encryption (FE) for circuits from mild assumptions. In this work, we improve the state of affairs for bounded collusion FE in several ways:
1.
New Security Notion. We introduce the notion of dynamic bounded collusion FE, where the declaration of collusion bound is delayed to the time of encryption. This enables the encryptor to dynamically choose the collusion bound for different ciphertexts depending on their individual level of sensitivity. Hence, the ciphertext size grows linearly with its own collusion bound and the public key size is independent of collusion bound. In contrast, all prior constructions have public key and ciphertext size that grow at least linearly with a fixed bound Q …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:u_35RYKgDlwC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"The celebrated work of Gorbunov, Vaikuntanathan and Wee [GVW13] provided the first key policy attribute based encryption scheme (ABE) for circuits from the Learning With Errors (LWE) assumption. However, the arguably more natural ciphertext policy variant has remained elusive, and is a central primitive not yet known from LWE.
In this work, we construct the first symmetric key ciphertext policy attribute based encryption scheme (CP-ABE) for all polynomial sized circuits from the learning with errors (LWE) assumption. In more detail, the ciphertext for a message m is labelled with an access control policy f, secret keys are labelled with public attributes from the domain of f and decryption succeeds to yield the hidden message m if and only if . The size of our public and secret key do not depend on the size of the circuits supported by the scheme – this enables our construction to support circuits …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:ldfaerwXgEUC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Can a sender encode a pair of messages jointly, and send their encoding over (say) a binary erasure channel, so that the receiver can decode exactly one of the two messages and the sender does not know which one?
Garg et al. (Crypto 2015) showed that this is information-theoretically impossible. We show how to circumvent this impossibility by assuming that the receiver is computationally bounded, settling for an inverse-polynomial security error (which is provably necessary), and relying on ideal obfuscation. Our solution creates a “computational anti-correlation” between the events of receiving and receiving by exploiting the anti-concentration of the binomial distribution.
The ideal obfuscation primitive in our construction can either be directly realized using (stateless) tamper-proof hardware, yielding an unconditional result, or heuristically instantiated in the plain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:fPk4N6BV_jEC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"We introduce the notion of public key encryption with secure key leasing (PKE-SKL). Our notion supports the leasing of decryption keys so that a leased key achieves the decryption functionality but comes with the guarantee that if the quantum decryption key returned by a user passes a validity test, then the user has lost the ability to decrypt. Our notion is similar in spirit to the notion of secure software leasing (SSL) introduced by Ananth and La Placa (Eurocrypt 2021) but captures significantly more general adversarial strategies. (In more detail, our adversary is not restricted to use an honest evaluation algorithm to run pirated software.) Our results can be summarized as follows:
Definitions: We introduce the definition of PKE with secure key leasing and formalize a security notion that we call indistinguishability against key leasing attacks (IND-KLA security). We also define a one-wayness notion for PKE-SKL that we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:b0M2c_1WBrUC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Motivated by several new and natural applications, we initiate the study of multi-input predicate encryption () and further develop multi-input attribute based encryption (). Our contributions are:
Formalizing Security: We provide definitions for and in the symmetric key setting and formalize security in the standard indistinguishability (IND) paradigm, against unbounded collusions.
Two-input  for  from  and Pairings: We provide the first constructions for two-input key-policy for from and pairings. Our construction leverages a surprising connection between techniques recently developed by Agrawal and Yamada (Eurocrypt, 2020) in the context of succinct single-input ciphertext-policy, to the seemingly unrelated problem of two-input key-policy. Similarly to Agrawal-Yamada, our construction is proven secure in the bilinear generic group model. By leveraging inner product functional encryption and using (a variant of) the KOALA knowledge assumption, we obtain a construction in the standard model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:f2IySw72cVMC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Threshold signature schemes enable distribution of the signature issuing capability to multiple users, to mitigate the threat of signing key compromise. Though a classic primitive, these signatures have witnessed a surge of interest in recent times due to relevance to modern applications like blockchains and cryptocurrencies. In this work, we study round-optimal threshold signatures in the post-quantum regime and improve the only known lattice-based construction by Boneh et al [CRYPTO’18] as follows:• Efficiency. We reduce the amount of noise flooding used in the construction from down to , where is the bound on the number of generated signatures and is the security parameter. By using lattice hardness assumptions over polynomial rings, this allows to decrease the signature bit-lengths from to~ , bringing them significantly closer to practice. Our improvement relies on a careful analysis using Rényi divergence rather than statistical distance in the security proof.• Instantiation. The construction of Boneh et al requires a standard signature scheme to be evaluated homomorphically. To instantiate this, we provide a homomorphism-friendly variant of Lyubashevsky’s signature [EUROCRYPT’12] which achieves low circuit depth by being “rejection-free” and uses an optimal, moderate noise flooding of , matching the above.• Towards Adaptive Security. The construction of Boneh et al satisfies only selective security, where all the corrupted parties must be announced before any signing query is made. We improve this in two ways: in the Random Oracle Model, we obtain partial adaptivity where signing queries can be made …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:D03iK_w7-QYC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Garg et al. (Crypto 2015) initiated the study of cryptographic protocols over noisy channels in the non-interactive setting, namely when only one party speaks. A major question left open by this work is the completeness of finite channels, whose input and output alphabets do not grow with the desired level of security. In this work, we address this question by obtaining the following results:
1.
Completeness of Bit-ROT with Inverse Polynomial Error. We show that bit-ROT (i.e., Randomized Oblivious Transfer channel, where each of the two messages is a single bit) can be used to realize general randomized functionalities with inverse polynomial error. Towards this, we provide a construction of string-ROT from bit-ROT with inverse polynomial error.
2.
No Finite Channel is Complete with Negligible …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:M05iB0D1s5AC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"In TCC 2013, Boyen suggested the first lattice based construction of attribute based encryption () for the circuit class . Unfortunately, soon after, a flaw was found in the security proof of the scheme. However, it remained unclear whether the scheme is actually insecure, and if so, whether it can be repaired. Meanwhile, the construction has been heavily cited and continues to be extensively studied due to its technical novelty. In particular, this is the first lattice based which uses linear secret sharing schemes (LSSS) as a crucial tool to enforce access control. In this work, we show that the scheme is in fact insecure,if the scheme is instantiated by the linear secret sharing scheme specified in the paper. To do so, we provide a polynomial-time attack that completely breaks the security of the scheme. We suggest a route to fix the security of the scheme, via the notion of admissible LSSS and instantiate these for the class …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:rO6llkc54NcC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"The Learning with Errors (LWE) problem has been extensively studied in cryptography due to its strong hardness guarantees, efficiency and expressiveness in constructing advanced cryptographic primitives. In this work, we show that using polar codes in conjunction with LWE-based encryption yields several advantages. To begin, we demonstrate the obvious improvements in the efficiency or rate of information transmission in the LWE-based scheme by leveraging polar coding (with no change in the cryptographic security guarantee). Next, we integrate wiretap polar coding with LWE-based encryption to ensure provable semantic security over a wiretap channel in addition to cryptographic security based on the hardness of LWE. To the best of our knowledge this is the first wiretap code to have cryptographic security guarantees as well. Finally, we study the security of the private key used in LWE-based encryption …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:hFOr9nPyWt4C,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Multi-input functional encryption, MIFE, is a powerful generalization of functional encryption that allows computation on encrypted data coming from multiple different data sources. In a recent work, Agrawal, Goyal, and Tomida (CRYPTO 2021) constructed MIFE for the class of quadratic functions. This was the first MIFE construction from bilinear maps that went beyond inner product computation. We advance the state-of-the-art in MIFE, and propose new constructions with stronger security and broader functionality.
Stronger Security: In the typical formulation of MIFE security, an attacker is allowed to either corrupt all or none of the users who can encrypt the data. In this work, we study MIFE security in a stronger and more natural model where we allow an attacker to corrupt any subset of the users, instead of only permitting all-or-nothing corruption. We formalize the model by providing each user a unique encryption …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:bFI3QPDXJZMC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"A trace and revoke () scheme is an user traitor tracing scheme which additionally enables the encryptor to specify a list of revoked users so that these users can no longer decrypt ciphertexts. The``holy grail''of this line of work is a construction which resists unbounded collusions, achieves ciphertext, public and secret key sizes independent (ignoring logarithmic dependencies) of and , and is based on polynomial hardness assumptions. In this work we make the following contributions: 1. Public Trace Setting: We provide a construction which (i) achieves optimal parameters,(ii) supports embedding identities (from an exponential space) in user secret keys,(iii) relies on polynomial hardness assumptions, namely compact functional encryption () and a key-policy attribute based encryption () with special efficiency properties constructed by Boneh et al.(Eurocrypt 2014) from Learning With Errors (), and (iv) enjoys adaptive security with respect to the revocation list. The previous best known construction by Nishimaki, Wichs and Zhandry (Eurocrypt 2016) which achieved optimal parameters and embedded identities, relied on indistinguishability obfuscation, which is considered an inherently subexponential assumption and achieved only selective security with respect to the revocation list. 2. Secret Trace Setting: We provide the first construction with optimal ciphertext, public and secret key sizes and embedded identities from any assumption outside Obfustopia. In detail, our construction relies on Lockable Obfuscation which can be constructed using (Goyal, Koppula, Waters and Wichs, Zirdelis, Focs 2017) and two schemes:(i) the key-policy scheme with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:_xSYboBqXhAC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"The recent work of Agrawal et al. [Crypto ’21] and Goyal et al. [Eurocrypt ’22] concurrently introduced the notion of dynamic bounded collusion security for functional encryption (FE) and showed a construction satisfying the notion from identity based encryption (IBE). Agrawal et al. [Crypto ’21] further extended it to FE for Turing machines in non-adaptive simulation setting from the sub-exponential learining with errors assumption (). Concurrently, the work of Goyal et al. [Asiacrypt ’21] constructed attribute based encryption (ABE) for Turing machines achieving adaptive indistinguishability based security against bounded (static) collusions from IBE, in the random oracle model. In this work, we significantly improve the state of art for dynamic bounded collusion FE and ABE for Turing machines by achieving adaptive simulation style security from a broad class of assumptions, in the standard model. In more detail, we obtain the following results:
We construct an adaptively secure () FE for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:yD5IFk8b50cC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"We define and construct Deniable Fully Homomorphic Encryption based on the Learning With Errors (LWE) polynomial hardness assumption. Deniable FHE enables storing encrypted data in the cloud to be processed securely without decryption, maintaining deniability of the encrypted data, as well the prevention of vote-buying in electronic voting schemes where encrypted votes can be tallied without decryption. Our constructions achieve compactness independently of the level of deniability-both the size of the public key and the size of the ciphertexts are bounded by a fixed polynomial, independent of the detection probability achieved by the scheme. This is in contrast to all previous constructions of deniable encryption schemes (even without requiring homomorphisms) which are based on polynomial hardness assumptions, originating with the seminal work of Canetti, Dwork, Naor and Ostrovsky (CRYPTO 1997) in which the ciphertext size grows with the inverse of the detection probability. Canetti et al. argued that this dependence``seems inherent'', but our constructions illustrate this is not the case. We note that the Sahai-Waters (STOC 2014) construction of deniable encryption from indistinguishability-obfuscation achieves compactness and can be easily modified to achieve deniable FHE as well, but it requires multiple, stronger sub-exponential hardness assumptions, which are furthermore not post-quantum secure. In contrast, our constructions rely only on the LWE polynomial hardness assumption, as currently required for FHE even without deniability. The running time of our encryption algorithm depends on the inverse of the detection …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:g5m5HwL7SMYC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"We present a brief introduction to post-quantum cryptography. This note introduces the concept of post-quantum cryptography, discusses its importance and provides a short overview of the mathematical techniques that are currently used to develop this field.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:YFjsv_pBGBYC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"A broadcast, trace and revoke system generalizes broadcast encryption as well as traitor tracing. In such a scheme, an encryptor can specify a list of revoked users so that (i) users in L can no longer decrypt ciphertexts, (ii) ciphertext size is independent of L, (iii) a pirate decryption box supports tracing of compromised users. The “holy grail” of this line of work is a construction which resists unbounded collusions, achieves all parameters (including public and secret key) sizes independent of |L| and |N|, and is based on polynomial hardness assumptions. In this work we make the following contributions:
Public Trace Setting: We provide a construction which (i) achieves optimal parameters, (ii) supports embedding identities (from an exponential space) in user secret keys, (iii) relies on polynomial hardness assumptions, namely compact functional encryption () and a key-policy attribute based encryption () with special efficiency properties, and (iv …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:abG-DnoFyZgC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"The four-volume proceedings LNCS 13791, 13792, 13793, and 13794 constitute the proceedings of the 28th International Conference on the Theory and Application of Cryptology and Information Security, ASIACRYPT 2022, held in Taipei, Taiwan, during December 5-9, 2022. The total of 98 full papers presented in these proceedings was carefully reviewed and selected from 364 submissions. The papers were organized in topical sections as follows: Part I: Award papers; functional and witness encryption; symmetric key cryptanalysis; multiparty computation; real world protocols; and blockchains and cryptocurrencies. Part II: Isogeny based cryptography; homomorphic encryption; NIZK and SNARKs; non interactive zero knowledge; and symmetric cryptography. Part III: Practical cryptography; advanced encryption; zero knowledge; quantum algorithms; lattice cryptoanalysis. Part IV: Signatures; commitments; theory; cryptoanalysis; and quantum cryptography.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:EUQCXRtRnyEC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Blind signatures are a fascinating primitive which allow a user to obtain signatures from a signer, while hiding the message. Tremendously useful, these have been studied extensively for decades. Yet, to the best of our knowledge, all concretely practical blind signatures rely on non-standard assumptions and/or achieve sub-optimal round complexity. In this work, we provide an efficient, round-optimal (two-round) blind signature scheme from the hardness of the discrete log (DL) problem {\it and} the learning with errors problem in the (non black-box) random oracle model. Our construction enjoys {\it post-quantum} blindness and does not rely on idealizations such as the algebraic group model or generic group model. We provide a concrete instantiation of our construction. Specifically, our blind signature size and verification time is the same as base Schnorr signature scheme which is used for a building block …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:pyW8ca7W8N0C,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"Laconic Function Evaluation (LFE) is a novel primitive introduced by Quach, Wee and Wichs (FOCS’18) that allows two parties to perform function evaluation laconically in the following manner: first, Alice sends a compressed “digest” of some function–say C–to Bob. Second, Bob constructs a ciphertext for his input M given the digest. Third, Alice, after receiving the ciphertext from Bob and having access to her circuit, can recover C (M) and (ideally) nothing more about Bob’s message. The protocol is said to be laconic if the sizes of the digest and ciphertext are much smaller than the circuit size| C|. Quach, Wee and Wichs provided a construction of laconic function evaluation for general circuits under the learning with errors (LWE) assumption (with subexponential approximation factors), where all parameters grow polynomially with the depth but not the size of the circuit. Under LWE, their construction achieves the restricted notion of selective security where Bob’s input M must be chosen non-adaptively before even the CRS is known.
In this work, we provide the first construction of LFE for NC1, which satisfies adaptive security from the ring learning with errors assumption (with polynomial approximation factors). The construction is based on the functional encryption scheme by Agrawal and Rosen (TCC 2017). Using the compiler from Quach, Wee and Wichs which bootstraps LFE to succinct, single key FE generically, we obtain a significant simplification of the succinct single key FE of Agrawal and Rosen.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:SeFeTyx0c_EC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"We introduce the notion of a Functionally Encrypted Datastore which collects data anonymously from multiple data-owners, stores it encrypted on an untrusted server, and allows untrusted clients to make select-and-compute queries on the collected data. Little coordination and no communication is required among the data-owners or the clients. Our notion is general enough to capture many real world scenarios that require controlled computation on encrypted data, such as is required for contact tracing in the wake of a pandemic. Our leakage and performance profile is similar to that of conventional searchable encryption systems, while the functionality we offer is significantly richer.
In more detail, the client specifies a query as a pair (Q, f) where Q is a filtering predicate which selects some subset of the dataset and f is a function on some computable values associated with the selected data. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:NaGl4SEjCO4C,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"We introduce the notion of a Functionally Encrypted Datastore which collects data from multiple data-owners, stores them encrypted on an untrusted server, and allows untrusted clients to make selectand-compute queries on the collected data. Little coordination and no communication is required among the data-owners or the clients. Our security and performance profile is similar to that of conventional searchable encryption systems, while the functionality we offer is significantly richer. The client specifies a query as a pair (Q, f) where Q is a filtering predicate which selects some subset of the dataset and f is a function on some computable values associated with the selected data. We provide efficient protocols for various functionalities of practical relevance. We demonstrate the utility, efficiency and scalability of our protocols via extensive experimentation. In particular, we use our protocols to model computations relevant to the Genome Wide Association Studies such as Minor Allele Frequency (MAF), Chi-square analysis and Hamming Distance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:BqipwSGYUEgC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],25,"In Public-Key Encryption, traditionally no security is expected if honest parties use keys provided by an adversary. In this work, we re-examine this premise. While using untrusted keys may seem nonsensical at first glance, we argue the use of providing certain security guarantees even in such situations. We propose Chosen Object Attack (COA) security as a broad generalization of various notions of security that have been considered in the literature, including CCA security, key anonymity and robustness, along with concerns arising from untrusted keys. The main premise of this definition is that any of the objects in a cryptographic scheme could be adversarialy generated, and that should not compromise the security of honest parties in a way an idealized scheme would not have. Our contributions are threefold.• Firstly, we develop a comprehensive security definition for PKE in the real/ideal paradigm. Our definition subsumes CCA2 security, Anonymity and Robustness as special cases, and also addresses security concerns in complex application scenarios where the keys may be malicious (without having to explicitly model the underlying attack scenarios). To avoid impossibility results associated with simulation-based security, we use the notion of indistinguishability-preserving security (IND-PRE) from the “Cryptographic Agents” framework (Agrawal et al., EUROCRYPT 2015). Towards this, we extend this framework to accommodate adversarially created objects. Our definition can alternately be interpreted as the union of all possible game-based security definitions. We remark that the agents framework as extended in this work is applicable to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&citation_for_view=uLkJ5_4AAAAJ:IWHjjKOFINEC,http://www.cse.iitm.ac.in/~shwetaag/
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Recently there has been a lot of work on pruning filters from deep convolutional neural networks (CNNs) with the intention of reducing computations. The key idea is to rank the filters based on a certain criterion (say, l1-norm, average percentage of zeros, etc) and retain only the top ranked filters. Once the low scoring filters are pruned away the remainder of the network is fine tuned and is shown to give performance comparable to the original unpruned network. In this work, we report experiments which suggest that the comparable performance of the pruned network is not due to the specific criterion chosen but due to the inherent plasticity of deep neural networks which allows them to recover from the loss of pruned filters once the rest of the filters are fine-tuned. Specifically, we show counter-intuitive results wherein by randomly pruning 25-50% filters from deep CNNs we are able to obtain the same performance as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:-FonjvnnhkoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Recent studies on interpretability of attention distributions have led to notions of faithful and plausible explanations for a model's predictions. Attention distributions can be considered a faithful explanation if a higher attention weight implies a greater impact on the model's prediction. They can be considered a plausible explanation if they provide a human-understandable justification for the model's predictions. In this work, we first explain why current attention mechanisms in LSTM based encoders can neither provide a faithful nor a plausible explanation of the model's predictions. We observe that in LSTM based encoders the hidden representations at different time-steps are very similar to each other (high conicity) and attention weights in these situations do not carry much meaning because even a random permutation of the attention weights does not affect the model's predictions. Based on experiments on a wide variety of tasks and datasets, we observe attention distributions often attribute the model's predictions to unimportant words such as punctuation and fail to offer a plausible explanation for the predictions. To make attention mechanisms more faithful and plausible, we propose a modified LSTM cell with a diversity-driven training objective that ensures that the hidden representations learned at different time steps are diverse. We show that the resulting attention distributions offer more transparency as they (i) provide a more precise importance ranking of the hidden states (ii) are better indicative of words important for the model's predictions (iii) correlate better with gradient-based attribution methods. Human evaluations indicate that the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:5MTHONV0fEkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Most methods that attempt to tackle the problem of Autonomous Driving and overtaking usually try to either directly minimize an objective function or iteratively in a Reinforcement Learning like framework to generate motor actions given a set of inputs. We follow a similar trend but train the agent in a way similar to a curriculum learning approach where the agent is first given an easier problem to solve, followed by a harder problem. We use Deep Deterministic Policy Gradients to learn overtaking maneuvers for a car, in presence of multiple other cars, in a simulated highway scenario. The novelty of our approach lies in the training strategy used where we teach the agent to drive in a manner similar to the way humans learn to drive and the fact that our reward function uses only the raw sensor data at the current time step. This method, which resembles a curriculum learning approach is able to learn smooth maneuvers …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:rmuvC79q63oC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the 'best of both worlds', i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:u-coK7KVo8oC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"In this work, we focus on the task of Automatic Question Generation (AQG) where given a passage and an answer the task is to generate the corresponding question. It is desired that the generated question should be (i) grammatically correct (ii) answerable from the passage and (iii) specific to the given answer. An analysis of existing AQG models shows that they produce questions which do not adhere to one or more of {the above-mentioned qualities}. In particular, the generated questions look like an incomplete draft of the desired question with a clear scope for refinement. {To alleviate this shortcoming}, we propose a method which tries to mimic the human process of generating questions by first creating an initial draft and then refining it. More specifically, we propose Refine Network (RefNet) which contains two decoders. The second decoder uses a dual attention network which pays attention to both (i) the original passage and (ii) the question (initial draft) generated by the first decoder. In effect, it refines the question generated by the first decoder, thereby making it more correct and complete. We evaluate RefNet on three datasets, \textit{viz.}, SQuAD, HOTPOT-QA, and DROP, and show that it outperforms existing state-of-the-art methods by 7-16\% on all of these datasets. Lastly, we show that we can improve the quality of the second decoder on specific metrics, such as, fluency and answerability by explicitly rewarding revisions that improve on the corresponding metric during training. The code has been made publicly available \footnote{https://github.com/PrekshaNema25/RefNet-QG}",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:HtS1dXgVpQUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Biological networks catalog the complex web of interactions happening between different molecules, typically proteins, within a cell. These networks are known to be highly modular, with groups of proteins associated with specific biological functions. Human diseases often arise from the dysfunction of one or more such proteins of the biological functional group. The ability, to identify and automatically extract these modules has implications for understanding the etiology of different diseases as well as the functional roles of different protein modules in disease. The recent DREAM challenge posed the problem of identifying disease modules from six heterogeneous networks of proteins/genes. There exist many community detection algorithms, but all of them are not adaptable to the biological context, as these networks are densely connected and the size of biologically relevant modules is quite small. The contribution of this study is 3-fold: first, we present a comprehensive assessment of many classic community detection algorithms for biological networks to identify non-overlapping communities, and propose heuristics to identify small and structurally well-defined communities—core modules. We evaluated our performance over 180 GWAS datasets. In comparison to traditional approaches, with our proposed approach we could identify 50% more number of disease-relevant modules. Thus, we show that it is important to identify more compact modules for better performance. Next, we sought to understand the peculiar characteristics of disease-enriched modules and what causes standard community detection algorithms to detect so few of them. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:a9-T7VOCCH8C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Machine learning approaches to predict essential genes have gained a lot of traction in recent years. These approaches predominantly make use of sequence and network-based features to predict essential genes. However, the scope of network-based features used by the existing approaches is very narrow. Further, many of these studies focus on predicting essential genes within the same organism, which cannot be readily used to predict essential genes across organisms. Therefore, there is clearly a need for a method that is able to predict essential genes across organisms, by leveraging network-based features. In this study, we extract several sets of network-based features from protein–protein association networks available from the STRING database. Our network features include some common measures of centrality, and also some novel recursive measures recently proposed in social network literature. We extract hundreds of network-based features from networks of 27 diverse organisms to predict the essentiality of 87000+ genes. Our results show that network-based features are statistically significantly better at classifying essential genes across diverse bacterial species, compared to the current state-of-the-art methods, which use mostly sequence and a few ‘conventional’ network-based features. Our diverse set of network properties gave an AUROC of 0.847 and a precision of 0.320 across 27 organisms. When we augmented the complete set of network features with sequence-derived features, we achieved an improved AUROC of 0.857 and a precision of 0.335. We also constructed a reduced set of 100 sequence and network …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:kh2fBNsKQNwC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"A serious challenge when finding influential actors in real-world social networks is the lack of knowledge about the structure of the underlying network. Current state-of-the-art methods rely on hand-crafted sampling algorithms; these methods sample nodes and their neighbours in a carefully constructed order and choose opinion leaders from this discovered network to maximize influence spread in the (unknown) complete network. In this work, we propose a reinforcement learning framework for network discovery that automatically learns useful node and graph representations that encode important structural properties of the network. At training time, the method identifies portions of the network such that the nodes selected from this sampled subgraph can effectively influence nodes in the complete network. The realization of such transferable network structure based adaptable policies is attributed to the meticulous design of the framework that encodes relevant node and graph signatures driven by an appropriate reward scheme. We experiment with real-world social networks from four different domains and show that the policies learned by our RL agent provide a 10-36% improvement over the current state-of-the-art method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:yMeIxYmEMEAC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Recently, there has been a lot of work on pruning filters from deep convolutional neural networks (CNNs) with the intention of reducing computations. The key idea is to rank the filters based on a certain criterion (say, -norm, average percentage of zeros, etc.) and retain only the top-ranked filters. Once the low-scoring filters are pruned away, the remainder of the network is fine-tuned and is shown to give performance comparable to the original unpruned network. In this work, we report experiments which suggest that the comparable performance of the pruned network is not due to the specific criterion chosen, but due to the inherent plasticity of deep neural networks which allows them to recover from the loss of pruned filters once the rest of the filters are fine-tuned. Specifically, we show counterintuitive results wherein by randomly pruning 25–50% filters from deep CNNs we are able to obtain the same …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:GtLg2Ama23sC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Learning on graphs is a subject of great interest due to the abundance of relational data from real-world systems. Many of these systems involve higher-order interactions (super-dyadic) rather than mere pairwise (dyadic) relationships; examples of these are co-authorship, co-citation, and metabolic reaction networks. Such super-dyadic relations are more adequately modeled using hypergraphs rather than graphs. Learning on hypergraphs has thus been garnering increased attention with potential applications in network analysis, VLSI design, and computer vision, among others. Especially, hypergraph clustering is gaining attention because of its enormous applications such as component placement in VLSI, group discovery in bibliographic systems, image segmentation in CV, etc. For the problem of clustering on graphs, modularity maximization has been known to work well in the pairwise setting. Our primary contribution in this article is to provide a generalization of the modularity maximization framework for clustering on hypergraphs. In doing so, we introduce a null model for graphs generated by hypergraph reduction and prove its equivalence to the configuration model for undirected graphs. The proposed graph reduction technique preserves the node degree sequence from the original hypergraph. The modularity function can be defined on a thus reduced graph, which can be maximized using any standard modularity maximization method, such as the Louvain method. We additionally propose an iterative technique that provides refinement over the obtained clusters. We demonstrate both the efficacy and efficiency of our methods on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:Bg7qf7VwUHIC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"The options framework in reinforcement learning models the notion of a skill or a temporally extended sequence of actions. The discovery of a reusable set of skills has typically entailed building options, that navigate to bottleneck states. This work adopts a complementary approach, where we attempt to discover options that navigate to landmark states. These states are prototypical representatives of well-connected regions and can hence access the associated region with relative ease. In this work, we propose Successor Options, which leverages Successor Representations to build a model of the state space. The intra-option policies are learnt using a novel pseudo-reward and the model scales to high-dimensional spaces easily. Additionally, we also propose an Incremental Successor Options model that iterates between constructing Successor Representations and building options, which is useful when robust Successor Representations cannot be built solely from primitive actions. We demonstrate the efficacy of our approach on a collection of grid-worlds, and on the high-dimensional robotic control environment of Fetch.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:mlAyqtXpCwEC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"State abstraction is necessary for better task transfer in complex reinforcement learning environments. Inspired by the benefit of state abstraction in MAXQ and building upon hybrid planner-RL architectures, we propose RePReL, a hierarchical framework that leverages a relational planner to provide useful state abstractions. Our experiments demonstrate that the abstractions enable faster learning and efficient transfer across tasks. More importantly, our framework enables the application of standard RL approaches for learning in structured domains. The benefit of using the state abstractions is critical in relational settings, where the number and/or types of objects are not fixed apriori. Our experiments clearly show that RePReL framework not only achieves better performance and efficient learning on the task at hand but also demonstrates better generalization to unseen tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:48xauSegjOkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Identification of modules in molecular networks is at the core of many current analysis methods in biomedical research. However, how well different approaches identify disease-relevant modules in different types of gene and protein networks remains poorly understood. We launched the “Disease Module Identification DREAM Challenge”, an open competition to comprehensively assess module identification methods across diverse protein-protein interaction, signaling, gene co-expression, homology, and cancer-gene networks. Predicted network modules were tested for association with complex traits and diseases using a unique collection of 180 genome-wide association studies (GWAS). Our critical assessment of 75 contributed module identification methods reveals novel top-performing algorithms, which recover complementary trait-associated modules. We find that most of these modules correspond to core disease-relevant pathways, which often comprise therapeutic targets and correctly prioritize candidate disease genes. This community challenge establishes benchmarks, tools and guidelines for molecular network analysis to study human disease biology (https://synapse.org/modulechallenge).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:pAkWuXOU-OoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Graphs are a natural abstraction for many problems where nodes represent entities and edges represent a relationship across entities. An important area of research that has emerged over the last decade is the use of graphs as a vehicle for non-linear dimensionality reduction in a manner akin to previous efforts based on manifold learning with uses for downstream database processing, machine learning and visualization. In this systematic yet comprehensive experimental survey, we benchmark several popular network representation learning methods operating on two key tasks: link prediction and node classification. We examine the performance of 12 unsupervised embedding methods on 15 datasets. To the best of our knowledge, the scale of our study -- both in terms of the number of methods and number of datasets -- is the largest to date. Our results reveal several key insights about work-to-date in this space. First, we find that certain baseline methods (task-specific heuristics, as well as classic manifold methods) that have often been dismissed or are not considered by previous efforts can compete on certain types of datasets if they are tuned appropriately. Second, we find that recent methods based on matrix factorization offer a small but relatively consistent advantage over alternative methods (e.g., random-walk based methods) from a qualitative standpoint. Specifically, we find that MNMF, a community preserving embedding method, is the most competitive method for the link prediction task. While NetMF is the most competitive baseline for node classification. Third, no single method completely outperforms other embedding methods on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:WJVC3Jt7v1AC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"We present a novel Multi-Relational Graph Convolutional Network (MRGCN) based framework to model on-road vehicle behaviors from a sequence of temporally ordered frames as grabbed by a moving monocular camera. The input to MRGCN is a multi-relational graph where the graph's nodes represent the active and passive agents/objects in the scene, and the bidirectional edges that connect every pair of nodes are encodings of their Spatio-temporal relations.We show that this proposed explicit encoding and usage of an intermediate spatio-temporal interaction graph to be well suited for our tasks over learning end-end directly on a set of temporally ordered spatial relations. We also propose an attention mechanism for MRGCNs that conditioned on the scene dynamically scores the importance of information from different interaction types.The proposed framework achieves significant performance gain over …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:gVv57TyPmFsC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Video image processing of traffic camera feeds is useful for counting and classifying vehicles, estimating queue length, traffic speed and also for tracking individual vehicles. Unlike homogeneous traffic, heterogeneous traffic includes multiple vehicle types that do not follow lane discipline. Vehicle detection is especially challenging when vehicles are occluded which is common in heterogeneous traffic. Recently Deep Learning has shown remarkable promise in solving many computer vision tasks such as object recognition, detection, and tracking. However, training deep learning architectures require huge labeled datasets which are time-consuming and expensive to acquire. We circumvent this problem by data augmentation. By properly augmenting an existing large general (non-traffic) dataset with a small low-resolution heterogeneous traffic dataset (that we collected), we obtain state-of-the-art vehicle detection …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:foquWX3nUaYC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Understanding on-road vehicle behaviour from a temporal sequence of sensor data is gaining in popularity. In this paper, we propose a pipeline for understanding vehicle behaviour from a monocular image sequence or video. A monocular sequence along with scene semantics, optical flow and object labels are used to get spatial information about the object (vehicle) of interest and other objects (semantically contiguous set of locations) in the scene. This spatial information is encoded by a Multi-Relational Graph Convolutional Network (MR-GCN), and a temporal sequence of such encodings is fed to a recurrent network to label vehicle behaviours. The proposed framework can classify a variety of vehicle behaviours to high fidelity on datasets that are diverse and include European, Chinese and Indian on-road scenes. The framework also provides for seamless transfer of models across datasets without entailing re …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:OP4eGU-M3BUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"This paper describes the application of reinforcement learning (RL) to multi-product inventory management in supply chains. The problem description and solution are both adapted from a real-world business solution. The novelty of this problem with respect to supply chain literature is (i) we consider concurrent inventory management of a large number (50 to 1000) of products with shared capacity, (ii) we consider a multi-node supply chain consisting of a warehouse which supplies three stores, (iii) the warehouse, stores, and transportation from warehouse to stores have finite capacities, (iv) warehouse and store replenishment happen at different time scales and with realistic time lags, and (v) demand for products at the stores is stochastic. We describe a novel formulation in a multi-agent (hierarchical) reinforcement learning framework that can be used for parallelised decision-making, and use the advantage actor critic (A2C) algorithm with quantised action spaces to solve the problem. Experiments show that the proposed approach is able to handle a multi-objective reward comprised of maximising product sales and minimising wastage of perishable products.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:gKiMpY-AVTkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Many real-world systems consist of entities that exhibit complex group interactions rather than simple pairwise relationships; such multi-way relations are more suitably modeled using hypergraphs. In this work, we generalize the framework of modularity maximization, commonly used for community detection on graphs, for the hypergraph clustering problem. We introduce a hypergraph null model that can be shown to correspond exactly to the configuration model for undirected graphs. We then derive an adjacency matrix reduction that preserves the hypergraph node degree sequence, for use with this null model. The resultant modularity function can be maximized using the Louvain method, a popular fast algorithm known to work well in practice for graphs. We additionally propose an iterative refinement over this clustering that exploits higher-order information within the hypergraph, seeking to encourage balanced …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:fFSKOagxvKUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Object detection in videos is an important task in computer vision for various applications such as object tracking, video summarization and video search. Although great progress has been made in improving the accuracy of object detection in recent years due to the rise of deep neural networks, the state-of-the-art algorithms are highly computationally intensive. In order to address this challenge, we make two important observations in the context of videos: (i) Objects often occupy only a small fraction of the area in each video frame, and (ii) There is a high likelihood of strong temporal correlation between consecutive frames. Based on these observations, we propose Pack and Detect (PaD), an approach to reduce the computational requirements of object detection in videos. In PaD, only selected video frames called anchor frames are processed at full size. In the frames that lie between anchor frames (inter-anchor …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:PVjk1bu6vJQC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Clustering on hypergraphs has been garnering increased attention with potential applications in network analysis, VLSI design and computer vision, among others. In this work, we generalize the framework of modularity maximization for clustering on hypergraphs. To this end, we introduce a hypergraph null model, analogous to the configuration model on undirected graphs, and a node-degree preserving reduction to work with this model. This is used to define a modularity function that can be maximized using the popular and fast Louvain algorithm. We additionally propose a refinement over this clustering, by reweighting cut hyperedges in an iterative fashion. The efficacy and efficiency of our methods are demonstrated on several real-world datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:_FM0Bhl9EiAC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Ensemble learning is a very prevalent method employed in machine learning. The relative success of ensemble methods is attributed to their ability to tackle a wide range of instances and complex problems that require different low-level approaches. However, ensemble methods are relatively less popular in reinforcement learning owing to the high sample complexity and computational expense involved in obtaining a diverse ensemble. We present a novel training and model selection framework for model-free reinforcement algorithms that use ensembles of policies obtained from a single training run. These policies are diverse in nature and are learned through directed perturbation of the model parameters at regular intervals. We show that learning and selecting an adequately diverse set of policies is required for a good ensemble while extreme diversity can prove detrimental to overall performance. Selection of an adequately diverse set of policies is done through our novel policy selection framework. We evaluate our approach on challenging discrete and continuous control tasks and also discuss various ensembling strategies. Our framework is substantially sample efficient, computationally inexpensive and is seen to outperform state-of-the-art (SOTA) scores in Atari 2600 and Mujoco.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:yFnVuubrUp4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"This article is one of two Distill publications about graph neural networks. Take a look at A Gentle Introduction to Graph Neural Networks for a companion view on many things graph and neural network related.
Many systems and interactions-social networks, molecules, organizations, citations, physical models, transactions-can be represented quite naturally as graphs. How can we reason about and make predictions within these systems?",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:WC23djZS0W4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Autonomous driving has emerged as one of the most active areas of research as it has the promise of making transportation safer and more efficient than ever before. Most real-world autonomous driving pipelines perform perception, motion planning and action in a loop. In this work we present MADRaS, an open-source multi-agent driving simulator for use in the design and evaluation of motion planning algorithms for autonomous driving. Given a start and a goal state, the task of motion planning is to solve for a sequence of position, orientation and speed values in order to navigate between the states while adhering to safety constraints. These constraints often involve the behaviors of other agents in the environment. MADRaS provides a platform for constructing a wide variety of highway and track driving scenarios where multiple driving agents can be trained for motion planning tasks using reinforcement learning and other machine learning algorithms. MADRaS is built on TORCS, an open-source car-racing simulator. TORCS offers a variety of cars with different dynamic properties and driving tracks with different geometries and surface. MADRaS inherits these functionalities from TORCS and introduces support for multi-agent training, inter-vehicular communication, noisy observations, stochastic actions, and custom traffic cars whose behaviors can be programmed to simulate challenging traffic conditions encountered in the real world. MADRaS can be used to create driving tasks whose complexities can be tuned along eight axes in well-defined steps. This makes it particularly suited for curriculum and continual learning. MADRaS is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:F1b5ZUV5XREC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"We propose a novel variant of the UCB algorithm (referred to as Efficient-UCB-Variance (EUCBV)) for minimizing cumulative regret in the stochastic multi-armed bandit (MAB) setting. EUCBV incorporates the arm elimination strategy proposed in UCB-Improved, while taking into account the variance estimates to compute the arms' confidence bounds, similar to UCBV. Through a theoretical analysis we establish that EUCBV incurs a gap-dependent regret bound which is an improvement over that of existing state-of-the-art UCB algorithms (such as UCB1, UCB-Improved, UCBV, MOSS). Further, EUCBV incurs a gap-independent regret bound which is an improvement over that of UCB1, UCBV and UCB-Improved, while being comparable with that of MOSS and OCUCB. Through an extensive numerical study we show that EUCBV significantly outperforms the popular UCB variants (like MOSS, OCUCB, etc.) as well as Thompson sampling and Bayes-UCB algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:LI9QrySNdTsC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Determining optimum inventory replenishment decisions are critical for retail businesses with uncertain demand. The problem becomes particularly challenging when multiple products with different lead times and cross-product constraints are considered. This paper addresses the aforementioned challenges in multi-product, multi-period inventory management using deep reinforcement learning (deep RL). The proposed approach improves upon existing methods for inventory control on three fronts: (1) concurrent inventory management of a large number (hundreds) of products under realistic constraints, (2) minimal retraining requirements on the RL agent under system changes through the definition of an individual product meta-model, (3) efficient handling of multi-period constraints that stem from different lead times of different products. We approach the inventory problem as a special class of dynamical system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:jgBuDB5drN8C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:S16KYo8Pm5AC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",41,"Many real-world systems involve higher-order interactions and thus demand complex models such as hypergraphs. For instance, a research article could have multiple collaborating authors, and therefore the co-authorship network is best represented as a hypergraph. In this work, we focus on the problem of hyperedge prediction. This problem has immense applications in multiple domains, such as predicting new collaborations in social networks, discovering new chemical reactions in metabolic networks, etc. Despite having significant importance, the problem of hyperedge prediction hasn’t received adequate attention, mainly because of its inherent complexity. In a graph with n nodes the number of potential edges is , whereas in a hypergraph, the number of potential hyperedges is . To avoid searching through the huge space of hyperedges, current methods restrain the original problem in the following two ways …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&citation_for_view=nGUcGrYAAAAJ:artPoR2Yc-kC,http://www.cse.iitm.ac.in/~ravi
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"In this paper, we introduce NLP resources for 11 major Indian languages from two major language families. These resources include:(a) large-scale sentence-level monolingual corpora,(b) pre-trained word embeddings,(c) pre-trained language models, and (d) multiple NLU evaluation datasets (IndicGLUE benchmark). The monolingual corpora contains a total of 8.8 billion tokens across all 11 languages and Indian English, primarily sourced from news crawls. The word embeddings are based on FastText, hence suitable for handling morphological complexity of Indian languages. The pre-trained language models are based on the compact ALBERT model. Lastly, we compile the (IndicGLUE benchmark for Indian language NLU. To this end, we create datasets for the following tasks: Article Genre Classification, Headline Prediction, Wikipedia Section-Title Prediction, Cloze-style Multiple choice QA, Winograd NLI and COPA. We also include publicly available datasets for some Indic languages for tasks like Named Entity Recognition, Cross-lingual Sentence Retrieval, Paraphrase detection, etc. Our embeddings are competitive or better than existing pre-trained embeddings on multiple tasks. We hope that the availability of the dataset will accelerate Indic NLP research which has the potential to impact more than a billion people. It can also help the community in evaluating advances in NLP over a more diverse pool of languages. The data and models are available at https://indicnlp. ai4bharat. org.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:K3LRdlH-MEoC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"While conversing with chatbots, humans typically tend to ask many questions, a significant portion of which can be answered by referring to large-scale knowledge graphs (KG). While Question Answering (QA) and dialog systems have been studied independently, there is a need to study them closely to evaluate such real-world scenarios faced by bots involving both these tasks. Towards this end, we introduce the task of Complex Sequential QA which combines the two tasks of (i) answering factual questions through complex inferencing over a realistic-sized KG of millions of entities, and (ii) learning to converse through a series of coherently linked QA pairs. Through a labor intensive semi-automatic process, involving in-house and crowdsourced workers, we created a dataset containing around 200K dialogs with a total of 1.6 M turns. Further, unlike existing large scale QA datasets which contain simple questions that can be answered from a single tuple, the questions in our dialogs require a larger subgraph of the KG. Specifically, our dataset has questions which require logical, quantitative, and comparative reasoning as well as their combinations. This calls for models which can:(i) parse complex natural language questions,(ii) use conversation context to resolve coreferences and ellipsis in utterances,(iii) ask for clarifications for ambiguous queries, and finally (iv) retrieve relevant subgraphs of the KG to answer such questions. However, our experiments with a combination of state of the art dialog and QA models show that they clearly do not achieve the above objectives and are inadequate for dealing with such complex real world settings. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:J_g5lzvAfSwC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Existing dialog datasets contain a sequence of utterances and responses without any explicit background knowledge associated with them. This has resulted in the development of models which treat conversation as a sequence-to-sequence generation task i.e, given a sequence of utterances generate the response sequence). This is not only an overly simplistic view of conversation but it is also emphatically different from the way humans converse by heavily relying on their background knowledge about the topic (as opposed to simply relying on the previous sequence of utterances). For example, it is common for humans to (involuntarily) produce utterances which are copied or suitably modified from background articles they have read about the topic. To facilitate the development of such natural conversation models which mimic the human process of conversing, we create a new dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie. We establish baseline results on this dataset (90K utterances from 9K conversations) using three different models: (i) pure generation based models which ignore the background knowledge (ii) generation based models which learn to copy information from the background knowledge when required and (iii) span prediction based models which predict the appropriate response span in the background knowledge.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:u_35RYKgDlwC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"We propose DuoRC, a novel dataset for Reading Comprehension (RC) that motivates several new challenges for neural approaches in language understanding beyond those offered by existing RC datasets. DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the collection reflects two versions of the same movie - one from Wikipedia and the other from IMDb - written by two different authors. We asked crowdsourced workers to create questions from one version of the plot and a different set of workers to extract or synthesize answers from the other version. This unique characteristic of DuoRC where questions and answers are created from different versions of a document narrating the same underlying story, ensures by design, that there is very little lexical overlap between the questions created from one version and the segments containing the answer in the other version. Further, since the two versions have different levels of plot detail, narration style, vocabulary, etc., answering questions from the second version requires deeper language understanding and incorporating external background knowledge. Additionally, the narrative style of passages arising from movie plots (as opposed to typical descriptive passages in existing datasets) exhibits the need to perform complex reasoning over events across multiple sentences. Indeed, we observe that state-of-the-art neural RC models which have achieved near human performance on the SQuAD dataset, even when coupled with traditional NLP techniques to address the challenges presented in DuoRC exhibit very poor …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:vV6vV6tmYwMC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"While multimodal conversation agents are gaining importance in several domains such as retail, travel etc., deep learning research in this area has been limited primarily due to the lack of availability of large-scale, open chatlogs. To overcome this bottleneck, in this paper we introduce the task of multimodal, domain-aware conversations, and propose the MMD benchmark dataset. This dataset was gathered by working in close coordination with large number of domain experts in the retail domain. These experts suggested various conversations flows and dialog states which are typically seen in multimodal conversations in the fashion domain. Keeping these flows and states in mind, we created a dataset consisting of over 150K conversation sessions between shoppers and sales agents, with the help of in-house annotators using a semi-automated manually intense iterative process. With this dataset, we propose 5 new sub-tasks for multimodal conversations along with their evaluation methodology. We also propose two multimodal neural models in the encode-attend-decode paradigm and demonstrate their performance on two of the sub-tasks, namely text response generation and best image response selection. These experiments serve to establish baseline performance and open new research directions for each of these sub-tasks. Further, for each of the sub-tasks, we present a'per-state evaluation'of 9 most significant dialog states, which would enable more focused research into understanding the challenges and complexities involved in each of these states.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:35N4QoGY0k4C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"In the last few years, a large number of automatic evaluation metrics have been proposed for evaluating Natural Language Generation (NLG) systems. The rapid development and adoption of such automatic evaluation metrics in a relatively short time has created the need for a survey of these metrics. In this survey, we (i) highlight the challenges in automatically evaluating NLG systems, (ii) propose a coherent taxonomy for organising existing evaluation metrics, (iii) briefly describe different existing metrics, and finally (iv) discuss studies criticising the use of automatic evaluation metrics. We then conclude the article highlighting promising future directions of research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:738O_yMBCRsC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"There has always been criticism for using -gram based similarity metrics, such as BLEU, NIST, etc, for evaluating the performance of NLG systems. However, these metrics continue to remain popular and are recently being used for evaluating the performance of systems which automatically generate questions from documents, knowledge graphs, images, etc. Given the rising interest in such automatic question generation (AQG) systems, it is important to objectively examine whether these metrics are suitable for this task. In particular, it is important to verify whether such metrics used for evaluating AQG systems focus on answerability of the generated question by preferring questions which contain all relevant information such as question type (Wh-types), entities, relations, etc. In this work, we show that current automatic evaluation metrics based on -gram similarity do not always correlate well with human judgments about answerability of a question. To alleviate this problem and as a first step towards better evaluation metrics for AQG, we introduce a scoring function to capture answerability and show that when this scoring function is integrated with existing metrics, they correlate significantly better with human judgments. The scripts and data developed as a part of this work are made publicly available at https://github.com/PrekshaNema25/Answerability-Metric",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:zA6iFVUQeVQC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Recently, there has been a lot of interest in building compact models for video classification which have a small memory footprint (< 1 GB). While these models are compact, they typically operate by repeated application of a small weight matrix to all the frames in a video. For example, recurrent neural network based methods compute a hidden state for every frame of the video using a recurrent weight matrix. Similarly, cluster-and-aggregate based methods such as NetVLAD have a learnable clustering matrix which is used to assign soft-clusters to every frame in the video. Since these models look at every frame in the video, the number of floating point operations (FLOPs) is still large even though the memory footprint is small. In this work, we focus on building compute-efficient video classification models which process fewer frames and hence have less number of FLOPs. Similar to memory efficient models, we use the idea of distillation albeit in a different setting. Specifically, in our case, a compute-heavy teacher which looks at all the frames in the video is used to train a compute-efficient student which looks at only a small fraction of frames in the video. This is in contrast to a typical memory efficient Teacher-Student setting, wherein both the teacher and the student look at all the frames in the video but the student has fewer parameters. Our work thus complements the research on memory efficient video classification. We do an extensive evaluation with three types of models for video classification, viz.,(i) recurrent models (ii) cluster-and-aggregate models and (iii) memory-efficient cluster-and-aggregate models and show that in each of these cases …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:b0M2c_1WBrUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Recently there has been a lot of work on pruning filters from deep convolutional neural networks (CNNs) with the intention of reducing computations. The key idea is to rank the filters based on a certain criterion (say, l1-norm, average percentage of zeros, etc) and retain only the top ranked filters. Once the low scoring filters are pruned away the remainder of the network is fine tuned and is shown to give performance comparable to the original unpruned network. In this work, we report experiments which suggest that the comparable performance of the pruned network is not due to the specific criterion chosen but due to the inherent plasticity of deep neural networks which allows them to recover from the loss of pruned filters once the rest of the filters are fine-tuned. Specifically, we show counter-intuitive results wherein by randomly pruning 25-50% filters from deep CNNs we are able to obtain the same performance as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:NaGl4SEjCO4C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Recent studies on interpretability of attention distributions have led to notions of faithful and plausible explanations for a model's predictions. Attention distributions can be considered a faithful explanation if a higher attention weight implies a greater impact on the model's prediction. They can be considered a plausible explanation if they provide a human-understandable justification for the model's predictions. In this work, we first explain why current attention mechanisms in LSTM based encoders can neither provide a faithful nor a plausible explanation of the model's predictions. We observe that in LSTM based encoders the hidden representations at different time-steps are very similar to each other (high conicity) and attention weights in these situations do not carry much meaning because even a random permutation of the attention weights does not affect the model's predictions. Based on experiments on a wide variety of tasks and datasets, we observe attention distributions often attribute the model's predictions to unimportant words such as punctuation and fail to offer a plausible explanation for the predictions. To make attention mechanisms more faithful and plausible, we propose a modified LSTM cell with a diversity-driven training objective that ensures that the hidden representations learned at different time steps are diverse. We show that the resulting attention distributions offer more transparency as they (i) provide a more precise importance ranking of the hidden states (ii) are better indicative of words important for the model's predictions (iii) correlate better with gradient-based attribution methods. Human evaluations indicate that the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:p2g8aNsByqUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"We present the IndicNLP corpus, a large-scale, general-domain corpus containing 2.7 billion words for 10 Indian languages from two language families. We share pre-trained word embeddings trained on these corpora. We create news article category classification datasets for 9 languages to evaluate the embeddings. We show that the IndicNLP embeddings significantly outperform publicly available pre-trained embedding on multiple evaluation tasks. We hope that the availability of the corpus will accelerate Indic NLP research. The resources are available at https://github.com/ai4bharat-indicnlp/indicnlp_corpus.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:u9iWguZQMMsC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"We present Samanantar, the largest publicly available parallel corpora collection for Indic languages. The collection contains a total of 49.7 million sentence pairs between English and 11 Indic languages (from two language families). Specifically, we compile 12.4 million sentence pairs from existing, publicly available parallel corpora, and additionally mine 37.4 million sentence pairs from the Web, resulting in a 4× increase. We mine the parallel sentences from the Web by combining many corpora, tools, and methods: (a) Web-crawled monolingual corpora, (b) document OCR for extracting sentences from scanned documents, (c) multilingual representation models for aligning sentences, and (d) approximate nearest neighbor search for searching in a large collection of sentences. Human evaluation of samples from the newly mined corpora validate the high quality of the parallel sentences across 11 languages …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&citation_for_view=DV8z8DYAAAAJ:5Ul4iDaHHb8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem. ADEM (Lowe et al. 2017) formulated the automatic evaluation of dialogue systems as a learning problem and showed that such a model was able to predict responses which correlate significantly with human judgements, both at utterance and system level. Their system was shown to have beaten word-overlap metrics such as BLEU with large margins. We start with the question of whether an adversary can game the ADEM model. We design a battery of targeted attacks at the neural network based ADEM evaluation system and show that automatic evaluation of dialogue systems still has a long way to go. ADEM can get confused with a variation as simple as reversing the word order in the text! We report experiments on several such adversarial scenarios that draw out counterintuitive scores on the dialogue responses. We take a systematic look at the scoring function proposed by ADEM and connect it to linear system theory to predict the shortcomings evident in the system. We also devise an attack that can fool such a system to rate a response generation system as favorable. Finally, we allude to future research directions of using the adversarial attacks to design a truly automated dialogue evaluation system.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:EUQCXRtRnyEC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"There is an increasing focus on model-based dialog evaluation metrics such as ADEM, RUBER, and the more recent BERT-based metrics. These models aim to assign a high score to all relevant responses and a low score to all irrelevant responses. Ideally, such models should be trained using multiple relevant and irrelevant responses for any given context. However, no such data is publicly available, and hence existing models are usually trained using a single relevant response and multiple randomly selected responses from other contexts (random negatives). To allow for better training and robust evaluation of model-based metrics, we introduce the DailyDialog++ dataset, consisting of (i) five relevant responses for each context and (ii) five adversarially crafted irrelevant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:l7t_Zn2s7bgC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"In this work, we focus on the task of Automatic Question Generation (AQG) where given a passage and an answer the task is to generate the corresponding question. It is desired that the generated question should be (i) grammatically correct (ii) answerable from the passage and (iii) specific to the given answer. An analysis of existing AQG models shows that they produce questions which do not adhere to one or more of {the above-mentioned qualities}. In particular, the generated questions look like an incomplete draft of the desired question with a clear scope for refinement. {To alleviate this shortcoming}, we propose a method which tries to mimic the human process of generating questions by first creating an initial draft and then refining it. More specifically, we propose Refine Network (RefNet) which contains two decoders. The second decoder uses a dual attention network which pays attention to both (i) the original passage and (ii) the question (initial draft) generated by the first decoder. In effect, it refines the question generated by the first decoder, thereby making it more correct and complete. We evaluate RefNet on three datasets, \textit{viz.}, SQuAD, HOTPOT-QA, and DROP, and show that it outperforms existing state-of-the-art methods by 7-16\% on all of these datasets. Lastly, we show that we can improve the quality of the second decoder on specific metrics, such as, fluency and answerability by explicitly rewarding revisions that improve on the corresponding metric during training. The code has been made publicly available \footnote{https://github.com/PrekshaNema25/RefNet-QG}",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:P5F9QuxV20EC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Converting an n-dimensional vector to a probability distribution over n objects is a commonly used component in many machine learning tasks like multiclass classification, multilabel classification, attention mechanisms etc. For this, several probability mapping functions have been proposed and employed in literature such as softmax, sum-normalization, spherical softmax, and sparsemax, but there is very little understanding in terms how they relate with each other. Further, none of the above formulations offer an explicit control over the degree of sparsity. To address this, we develop a unified framework that encompasses all these formulations as special cases. This framework ensures simple closed-form solutions and existence of sub-gradients suitable for learning via backpropagation. Within this framework, we propose two novel sparse formulations, sparsegen-lin and sparsehourglass, that seek to provide a control over the degree of desired sparsity. We further develop novel convex loss functions that help induce the behavior of aforementioned formulations in the multilabel classification setting, showing improved performance. We also demonstrate empirically that the proposed formulations, when used to compute attention weights, achieve better or comparable performance on standard seq2seq tasks like neural machine translation and abstractive summarization.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:fPk4N6BV_jEC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Existing synthetic datasets (FigureQA, DVQA) for reasoning over plots do not contain variability in data labels, real-valued data, or complex reasoning questions. Consequently, proposed models for these datasets do not fully address the challenge of reasoning over plots. In particular, they assume that the answer comes either from a small fixed size vocabulary or from a bounding box within the image. However, in practice, this is an unrealistic assumption because many questions require reasoning and thus have real-valued answers which appear neither in a small fixed size vocabulary nor in the image. In this work, we aim to bridge this gap between existing datasets and real-world plots. Specifically, we propose PlotQA with 28.9 million question-answer pairs over 224,377 plots on data from real-world sources and questions based on crowd-sourced question templates. Further, 80.76% of the out-of-vocabulary (OOV) questions in PlotQA have answers that are not in a fixed vocabulary. Analysis of existing models on PlotQA reveals that they cannot deal with OOV questions: their overall accuracy on our dataset is in single digits. This is not surprising given that these models were not designed for such questions. As a step towards a more holistic model which can address fixed vocabulary as well as OOV questions, we propose a hybrid approach: Specific questions are answered by choosing the answer from a fixed vocabulary or by extracting it from a predicted bounding box in the plot, while other questions are answered with a table question-answering engine which is fed with a structured table generated by detecting visual elements from the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:OU6Ihb5iCvQC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Indian Sign Language (ISL) is a complete language with its own grammar, syntax, vocabulary and several unique linguistic attributes. It is used by over 5 million deaf people in India. Currently, there is no publicly available dataset on ISL to evaluate Sign Language Recognition (SLR) approaches. In this work, we present the Indian Lexicon Sign Language Dataset - INCLUDE - an ISL dataset that contains 0.27 million frames across 4,287 videos over 263 word signs from 15 different word categories. INCLUDE is recorded with the help of experienced signers to provide close resemblance to natural conditions. A subset of 50 word signs is chosen across word categories to define INCLUDE-50 for rapid evaluation of SLR meth- ods with hyperparameter tuning. As the first large scale study of SLR on ISL, we evaluate several deep neural networks combining different methods for augmentation, feature extraction …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:08ZZubdj9fEC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"In this work, we focus on the task of generating natural language descriptions from a structured table of facts containing fields (such as nationality, occupation, etc) and values (such as Indian, actor, director, etc). One simple choice is to treat the table as a sequence of fields and values and then use a standard seq2seq model for this task. However, such a model is too generic and does not exploit task-specific characteristics. For example, while generating descriptions from a table, a human would attend to information at two levels: (i) the fields (macro level) and (ii) the values within the field (micro level). Further, a human would continue attending to a field for a few timesteps till all the information from that field has been rendered and then never return back to this field (because there is nothing left to say about it). To capture this behavior we use (i) a fused bifocal attention mechanism which exploits and combines this micro and macro level information and (ii) a gated orthogonalization mechanism which tries to ensure that a field is remembered for a few time steps and then forgotten. We experiment with a recently released dataset which contains fact tables about people and their corresponding one line biographical descriptions in English. In addition, we also introduce two similar datasets for French and German. Our experiments show that the proposed model gives 21% relative improvement over a recently proposed state of the art method and 10% relative improvement over basic seq2seq models. The code and the datasets developed as a part of this work are publicly available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:ldfaerwXgEUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Deep convolutional neural networks (CNNs) for video denoising are typically trained with supervision, assuming the availability of clean videos. However, in many applications, such as microscopy, noiseless videos are not available. To address this, we propose an Unsupervised Deep Video Denoiser (UDVD), a CNN architecture designed to be trained exclusively with noisy data. The performance of UDVD is comparable to the supervised state-of-the-art, even when trained only on a single short noisy video. We demonstrate the promise of our approach in real-world imaging applications by denoising raw video, fluorescence-microscopy and electron-microscopy data. In contrast to many current approaches to video denoising, UDVD does not require explicit motion compensation. This is advantageous because motion compensation is computationally expensive, and can be unreliable when the input data are noisy. A gradient-based analysis reveals that UDVD automatically tracks the motion of objects in the input noisy videos. Thus, the network learns to perform implicit motion compensation, even though it is only trained for denoising.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:4fKUyHm3Qg0C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Recently, there has been a lot of work on pruning filters from deep convolutional neural networks (CNNs) with the intention of reducing computations. The key idea is to rank the filters based on a certain criterion (say, -norm, average percentage of zeros, etc.) and retain only the top-ranked filters. Once the low-scoring filters are pruned away, the remainder of the network is fine-tuned and is shown to give performance comparable to the original unpruned network. In this work, we report experiments which suggest that the comparable performance of the pruned network is not due to the specific criterion chosen, but due to the inherent plasticity of deep neural networks which allows them to recover from the loss of pruned filters once the rest of the filters are fine-tuned. Specifically, we show counterintuitive results wherein by randomly pruning 25–50% filters from deep CNNs we are able to obtain the same …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:pyW8ca7W8N0C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Existing supervised solutions for Named Entity Recognition (NER) typically rely on a large annotated corpus. Collecting large amounts of NER annotated corpus is time-consuming and requires considerable human effort. However, collecting small amounts of annotated corpus for any language is feasible, but the performance degrades due to data sparsity. We address the data sparsity by borrowing features from the data of a closely related language. We use hierarchical neural networks to train a supervised NER system. The feature borrowing from a closely related language happens via the shared layers of the network. The neural network is trained on the combined dataset of the low-resource language and a closely related language, also termed Multilingual Learning. Unlike existing systems, we share all layers of the network between the two languages. We apply multilingual learning for NER in Indian …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:a0OBvERweLwC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Multilingual Language Models (\MLLMs) such as mBERT, XLM, XLM-R, \textit{etc.} have emerged as a viable option for bringing the power of pretraining to a large number of languages. Given their success in zero-shot transfer learning, there has emerged a large body of work in (i) building bigger \MLLMs~covering a large number of languages (ii) creating exhaustive benchmarks covering a wider variety of tasks and languages for evaluating \MLLMs~ (iii) analysing the performance of \MLLMs~on monolingual, zero-shot cross-lingual and bilingual tasks (iv) understanding the universal language patterns (if any) learnt by \MLLMs~ and (v) augmenting the (often) limited capacity of \MLLMs~ to improve their performance on seen or even unseen languages. In this survey, we review the existing literature covering the above broad areas of research pertaining to \MLLMs. Based on our survey, we recommend some promising directions of future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:fQNAKQ3IYiAC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"The task of Reading Comprehension with Multiple Choice Questions, requires a human (or machine) to read a given passage, question pair and select one of the n given options. The current state of the art model for this task first computes a question-aware representation for the passage and then selects the option which has the maximum similarity with this representation. However, when humans perform this task they do not just focus on option selection but use a combination of elimination and selection. Specifically, a human would first try to eliminate the most irrelevant option and then read the passage again in the light of this new information (and perhaps ignore portions corresponding to the eliminated option). This process could be repeated multiple times till the reader is finally ready to select the correct option. We propose ElimiNet, a neural network-based model which tries to mimic this process. Specifically, it has gates which decide whether an option can be eliminated given the passage, question pair and if so it tries to make the passage representation orthogonal to this eliminated option (akin to ignoring portions of the passage corresponding to the eliminated option). The model makes multiple rounds of partial elimination to refine the passage representation and finally uses a selection module to pick the best option. We evaluate our model on the recently released large scale RACE dataset and show that it outperforms the current state of the art model on 7 out of the question types in this dataset. Further, we show that taking an ensemble of our elimination-selection based method with a selection based method gives us an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:rO6llkc54NcC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"There is an increasing demand for goal-oriented conversation systems which can assist users in various day-to-day activities such as booking tickets, restaurant reservations, shopping, etc. Most of the existing datasets for building such conversation systems focus on monolingual conversations and there is hardly any work on multilingual and/or code-mixed conversations. Such datasets and systems thus do not cater to the multilingual regions of the world, such as India, where it is very common for people to speak more than one language and seamlessly switch between them resulting in code-mixed conversations. For example, a Hindi speaking user looking to book a restaurant would typically ask, ""Kya tum is restaurant mein ek table book karne mein meri help karoge?"" (""Can you help me in booking a table at this restaurant?""). To facilitate the development of such code-mixed conversation models, we build a goal-oriented dialog dataset containing code-mixed conversations. Specifically, we take the text from the DSTC2 restaurant reservation dataset and create code-mixed versions of it in Hindi-English, Bengali-English, Gujarati-English and Tamil-English. We also establish initial baselines on this dataset using existing state of the art models. This dataset along with our baseline implementations is made publicly available for research purposes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:3s1wT3WcHBgC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Domain-specific goal-oriented dialogue systems typically require modeling three types of inputs, namely, (i) the knowledge-base associated with the domain, (ii) the history of the conversation, which is a sequence of utterances, and (iii) the current utterance for which the response needs to be generated. While modeling these inputs, current state-of-the-art models such as Mem2Seq typically ignore the rich structure inherent in the knowledge graph and the sentences in the conversation context. Inspired by the recent success of structure-aware Graph Convolutional Networks (GCNs) for various NLP tasks such as machine translation, semantic role labeling, and document dating, we propose a memory-augmented GCN for goal-oriented dialogues. Our model exploits (i) the entity relation graph in a knowledge-base and (ii) the dependency graph associated with an utterance to compute richer representations for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:D03iK_w7-QYC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Structured data summarization involves generation of natural language summaries from structured input data. In this work, we consider summarizing structured data occurring in the form of tables as they are prevalent across a wide variety of domains. We formulate the standard table summarization problem, which deals with tables conforming to a single predefined schema. To this end, we propose a mixed hierarchical attention based encoder-decoder model which is able to leverage the structure in addition to the content of the tables. Our experiments on the publicly available WEATHERGOV dataset show around 18 BLEU (~ 30%) improvement over the current state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:2P1L_qKh6hAC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"In this paper, we study pre-trained sequence-to-sequence models for a group of related languages, with a focus on Indic languages. We present IndicBART, a multilingual, sequence-to-sequence pre-trained model focusing on 11 Indic languages and English. IndicBART utilizes the orthographic similarity between Indic scripts to improve transfer learning between similar Indic languages. We evaluate IndicBART on two NLG tasks: Neural Machine Translation (NMT) and extreme summarization. Our experiments on NMT and extreme summarization show that a model specific to related languages like IndicBART is competitive with large pre-trained models like mBART50 despite being significantly smaller. It also performs well on very low-resource translation scenarios where languages are not included in pre-training or fine-tuning. Script sharing, multilingual training, and better utilization of limited model capacity contribute to the good performance of the compact IndicBART model.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:eJXPG6dFmWUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"We address the task of joint training of transliteration models for multiple language pairs (multilingual transliteration). This is an instance of multitask learning, where individual tasks (language pairs) benefit from sharing knowledge with related tasks. We focus on transliteration involving related tasks i.e., languages sharing writing systems and phonetic properties (orthographically similar languages). We propose a modified neural encoder-decoder model that maximizes parameter sharing across language pairs in order to effectively leverage orthographic similarity. We show that multilingual transliteration significantly outperforms bilingual transliteration in different scenarios (average increase of 58% across a variety of languages we experimented with). We also show that multilingual transliteration models can generalize well to languages/language pairs not encountered during training and hence perform well …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:70eg2SAEIzsC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Natural Language Generation (NLG) evaluation is a multifaceted task requiring assessment of multiple desirable criteria, e.g., fluency, coherency, coverage, relevance, adequacy, overall quality, etc. Across existing datasets for 6 NLG tasks, we observe that the human evaluation scores on these multiple criteria are often not correlated. For example, there is a very low correlation between human scores on fluency and data coverage for the task of structured data to text generation. This suggests that the current recipe of proposing new automatic evaluation metrics for NLG by showing that they correlate well with scores assigned by humans for a single criteria (overall quality) alone is inadequate. Indeed, our extensive study involving 25 automatic evaluation metrics across 6 different tasks and 18 different evaluation criteria shows that there is no single metric which correlates well with human scores on all desirable criteria, for most NLG tasks. Given this situation, we propose CheckLists for better design and evaluation of automatic metrics. We design templates which target a specific criteria (e.g., coverage) and perturb the output such that the quality gets affected only along this specific criteria (e.g., the coverage drops). We show that existing evaluation metrics are not robust against even such simple perturbations and disagree with scores assigned by humans to the perturbed output. The proposed templates thus allow for a fine-grained assessment of automatic evaluation metrics exposing their limitations and will facilitate better design, analysis and evaluation of such metrics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:eflP2zaiRacC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Deep Learning has managed to push boundaries in a wide variety of tasks. One area of interest is to tackle problems in reasoning and understanding, with an aim to emulate human intelligence. In this work, we describe a deep learning model that addresses the reasoning task of question-answering on categorical plots. We introduce a novel architecture FigureNet, that learns to identify various plot elements, quantify the represented values and determine a relative ordering of these statistical values. We test our model on the FigureQA dataset which provides images and accompanying questions for scientific plots like bar graphs and pie charts, augmented with rich annotations. Our approach outperforms the state-of-the-art Relation Networks baseline by approximately 7% on this dataset, with a training time that is over an order of magnitude lesser.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:CHSYGLWDkRkC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Recent advances in Question Answering have lead to the development of very complex models which compute rich representations for query and documents by capturing all pairwise interactions between query and document words. This makes these models expensive in space and time, and in practice one has to restrict the length of the documents that can be fed to these models. Such models have also been recently employed for the task of predicting dialog responses from available background documents (eg, Holl-E dataset). However, here the documents are longer, thereby rendering these complex models infeasible except in select restricted settings. In order to overcome this, we use standard simple models which do not capture all pairwise interactions, but learn to emulate certain characteristics of a complex teacher network. Specifically, we first investigate the conicity of representations learned by a complex model and observe that it is significantly lower than that of simpler models. Based on this insight, we modify the simple architecture to mimic this characteristic. We go further by using knowledge distillation approaches, where the simple model acts as a student and learns to match the output from the complex teacher network. We experiment with the Holl-E dialog data set and show that by mimicking characteristics and matching outputs from a teacher, even a simple network can give improved performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:NhqRSupF_l8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"BERT and its variants have achieved state-of-the-art performance in various NLP tasks. Since then, various works have been proposed to analyze the linguistic information being captured in BERT. However, the current works do not provide an insight into how BERT is able to achieve near human-level performance on the task of Reading Comprehension based Question Answering. In this work, we attempt to interpret BERT for RCQA. Since BERT layers do not have predefined roles, we define a layer's role or functionality using Integrated Gradients. Based on the defined roles, we perform a preliminary analysis across all layers. We observed that the initial layers focus on query-passage interaction, whereas later layers focus more on contextual understanding and enhancing the answer prediction. Specifically for quantifier questions (how much/how many), we notice that BERT focuses on confusing words (i.e., on other numerical quantities in the passage) in the later layers, but still manages to predict the answer correctly. The fine-tuning and analysis scripts will be publicly available at https://github.com/iitmnlp/BERT-Analysis-RCQA .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:vRqMK49ujn8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"In many visual domains (like fashion, furniture, etc.) the search for products on online platforms requires matching textual queries to image content. For example, the user provides a search query in natural language (e.g.,pink floral top) and the results obtained are of a different modality (e.g., the set of images of pink floral tops). Recent work on multimodal representation learning enables such cross-modal matching by learning a common representation space for text and image. While such representations ensure that the n-dimensional representation of pink floral top is very close to representation of corresponding images, they do not ensure that the first k 1 (<; n) dimensions correspond to color, the next k 2 (<; n) correspond to style and so on. In other words, they learn entangled representations where each dimension does not correspond to a specific attribute. We propose two simple variants which can learn …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:M05iB0D1s5AC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"AI technologies for Natural Languages have made tremendous progress recently. However, commensurate progress has not been made on Sign Languages, in particular, in recognizing signs as individual words or as complete sentences. We introduce OpenHands, a library where we take four key ideas from the NLP community for low-resource languages and apply them to sign languages for word-level recognition. First, we propose using pose extracted through pretrained models as the standard modality of data to reduce training time and enable efficient inference, and we release standardized pose datasets for 6 different sign languages - American, Argentinian, Chinese, Greek, Indian, and Turkish. Second, we train and release checkpoints of 4 pose-based isolated sign language recognition models across all 6 languages, providing baselines and ready checkpoints for deployment. Third, to address the lack of labelled data, we propose self-supervised pretraining on unlabelled data. We curate and release the largest pose-based pretraining dataset on Indian Sign Language (Indian-SL). Fourth, we compare different pretraining strategies and for the first time establish that pretraining is effective for sign language recognition by demonstrating (a) improved fine-tuning performance especially in low-resource settings, and (b) high crosslingual transfer from Indian-SL to few other sign languages. We open-source all models and datasets in OpenHands with a hope that it makes research in sign languages more accessible, available here at https://github.com/AI4Bharat/OpenHands .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:q3oQSFYPqjQC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"With the prolification of multimodal interaction in various domains, recently there has been much interest in text based image retrieval in the computer vision community. However most of the state of the art techniques model this problem in a purely neural way, which makes it difficult to incorporate pragmatic strategies in searching a large scale catalog especially when the search requirements are insufficient and the model needs to resort to an interactive retrieval process through multiple iterations of question-answering. Motivated by this, we propose a neural-symbolic approach for a one-shot retrieval of images from a large scale catalog, given the caption description. To facilitate this, we represent the catalog and caption as scene-graphs and model the retrieval task as a learnable graph matching problem, trained end-to-end with a REINFORCE algorithm. Further, we briefly describe an extension of this pipeline to an iterative retrieval framework, based on interactive questioning and answering.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:KxtntwgDAa4C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Recent methods in speech and language technology pretrain very large models which are fine-tuned for specific tasks. However, the benefits of such large models are often limited to a few resource rich languages of the world. In this work, we make multiple contributions towards building ASR systems for low resource languages from the Indian subcontinent. First, we curate 17,000 hours of raw speech data for 40 Indian languages from a wide variety of domains including education, news, technology, and finance. Second, using this raw speech data we pretrain several variants of wav2vec style models for 40 Indian languages. Third, we analyze the pretrained models to find key features: codebook vectors of similar sounding phonemes are shared across languages, representations across layers are discriminative of the language family, and attention heads often pay attention within small local windows. Fourth, we fine-tune this model for downstream ASR for 9 languages and obtain state-of-the-art results on 3 public datasets, including on very low-resource languages such as Sinhala and Nepali. Our work establishes that multilingual pretraining is an effective strategy for building ASR systems for the linguistically diverse speakers of the Indian subcontinent.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:kRWSkSYxWN8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Semi-supervised node classification in attributed graphs, i.e., graphs with node features, involves learning to classify unlabeled nodes given a partially labeled graph. Label predictions are made by jointly modeling the node and its' neighborhood features. State-of-the-art models for node classification on such attributed graphs use differentiable recursive functions that enable aggregation and filtering of neighborhood information from multiple hops. In this work, we analyze the representation capacity of these models to regulate information from multiple hops independently. From our analysis, we conclude that these models despite being powerful, have limited representation capacity to capture multi-hop neighborhood information effectively. Further, we also propose a mathematically motivated, yet simple extension to existing graph convolutional networks (GCNs) which has improved representation capacity. We extensively evaluate the proposed model, F-GCN on eight popular datasets from different domains. F-GCN outperforms the state-of-the-art models for semi-supervised learning on six datasets while being extremely competitive on the other two.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:pqnbT2bcN3wC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Multi-headed attention heads are a mainstay in transformer-based models. Different methods have been proposed to classify the role of each attention head based on the relations between tokens which have high pair-wise attention. These roles include syntactic (tokens with some syntactic relation), local (nearby tokens), block (tokens in the same sentence) and delimiter (the special [CLS],[SEP] tokens). There are two main challenges with existing methods for classification:(a) there are no standard scores across studies or across functional roles, and (b) these scores are often average quantities measured across sentences without capturing statistical significance. In this work, we formalize a simple yet effective score that generalizes to all the roles of attention heads and employs hypothesis testing on this score for robust inference. This provides us the right lens to systematically analyze attention heads and confidently comment on many commonly posed questions on analyzing the BERT model. In particular, we comment on the co-location of multiple functional roles in the same attention head, the distribution of attention heads across layers, and effect of fine-tuning for specific NLP tasks on these functional roles. The code is made publicly available at https://github. com/iitmnlp/heads-hypothesis",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:8AbLer7MMksC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"We introduce Aksharantar, the largest publicly available transliteration dataset for 21 Indic languages containing 26 million transliteration pairs. We build this dataset by mining transliteration pairs from large monolingual and parallel corpora, as well as collecting transliterations from human annotators to ensure diversity of words and representation of low-resource languages. We introduce a new, large, diverse testset for Indic language transliteration containing 103k words pairs spanning 19 languages that enables fine-grained analysis of transliteration models. We train the IndicXlit model on the Aksharantar training set. IndicXlit is a single transformer-based multilingual transliteration model for roman to Indic script conversion supporting 21 Indic languages. It achieves state-of-the art results on the Dakshina testset, and establishes strong baselines on the Aksharantar testset released along with this work. All the datasets and models are publicly available at https://indicnlp.ai4bharat.org/aksharantar. We hope the availability of these large-scale, open resources will spur innovation for Indic language transliteration and downstream applications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:t6usbXjVLHcC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"In this paper, we present the IndicNLG suite, a collection of datasets for benchmarking Natural Language Generation (NLG) for 11 Indic languages. We focus on five diverse tasks, namely, biography generation using Wikipedia infoboxes (WikiBio), news headline generation, sentence summarization, question generation and paraphrase generation. We describe the process of creating the datasets and present statistics of the dataset, following which we train and report a variety of strong monolingual and multilingual baselines that leverage pre-trained sequence-to-sequence models and analyze the results to understand the challenges involved in Indic language NLG. To the best of our knowledge, this is the first NLG dataset for Indic languages and also the largest multilingual NLG dataset. Our methods can also be easily applied to modest-resource languages with reasonable monolingual and parallel corpora, as well as corpora containing structured data like Wikipedia. We hope this dataset spurs research in NLG on diverse languages and tasks, particularly for Indic languages. The datasets and models are publicly available at https://indicnlp.ai4bharat.org/indicnlg-suite.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:wbdj-CoPYUoC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Are existing object detection methods adequate for detecting text and visual elements in scientific plots which are arguably different than the objects found in natural images? To answer this question, we train and compare the accuracy of Fast/Faster R-CNN, SSD, YOLO and RetinaNet on the PlotQA dataset with over 220,000 scientific plots. At the standard IOU setting of 0.5, most networks perform well with mAP scores greater than 80% in detecting the relatively simple objects in plots. However, the performance drops drastically when evaluated at a stricter IOU of 0.9 with the best model giving a mAP of 35.70%. Note that such a stricter evaluation is essential when dealing with scientific plots where even minor localisation errors can lead to large errors in downstream numerical inferences. Given this poor performance, we propose minor modifications to existing models by combining ideas from different object detection networks. While this significantly improves the performance, there are still two main issues:(i) performance on text objects which are essential for reasoning is very poor, and (ii) inference time is unacceptably large considering the simplicity of plots. To solve this open problem, we make a series of contributions:(a) an efficient region proposal method based on Laplacian edge detectors,(b) a feature representation of region proposals that includes neighbouring information,(c) a linking component to join multiple region proposals for detecting longer textual objects, and (d) a custom loss function that combines a smooth L1-loss with an IOU-based loss. Combining these ideas, our final model is very accurate at extreme IOU values …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:Tiz5es2fbqcC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:1sJd4Hv_s6UC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"In recent years, it has been seen that deep neural networks are lacking robustness and are likely to break in case of adversarial perturbations in input data. Strong adversarial attacks are proposed by various authors for computer vision and Natural Language Processing (NLP). As a counter-effort, several defense mechanisms are also proposed to save these networks from failing. In contrast with image data, generating adversarial attacks and defending these models is not easy in NLP because of the discrete nature of the text data. However, numerous methods for adversarial defense are proposed of late, for different NLP tasks such as text classification, named entity recognition, natural language inferencing, etc. These methods are not just used for defending neural networks from adversarial attacks, but also used as a regularization mechanism during training, saving the model from overfitting. The proposed survey is an attempt to review different methods proposed for adversarial defenses in NLP in the recent past by proposing a novel taxonomy. This survey also highlights the fragility of the advanced deep neural networks in NLP and the challenges in defending them.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:bnK-pcrLprsC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Given the success of Transformer-based models, two directions of study have emerged: interpreting role of individual attention heads and down-sizing the models for efficiency. Our work straddles these two streams: We analyse the importance of basing pruning strategies on the interpreted role of the attention heads. We evaluate this on Transformer and BERT models on multiple NLP tasks. Firstly, we find that a large fraction of the attention heads can be randomly pruned with limited effect on accuracy. Secondly, for Transformers, we find no advantage in pruning attention heads identified to be important based on existing studies that relate importance to the location of a head. On the BERT model too we find no preference for top or bottom layers, though the latter are reported to have higher importance. However, strategies that avoid pruning middle layers and consecutive layers perform better. Finally, during fine-tuning the compensation for pruned attention heads is roughly equally distributed across the un-pruned heads. Our results thus suggest that interpretation of attention heads does not strongly inform pruning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:tS2w5q8j5-wC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Given a graph where every node has certain attributes associated with it and some nodes have labels associated with them, Collective Classification (CC) is the task of assigning labels to every unlabeled node using information from the node as well as its neighbors. It is often the case that a node is not only influenced by its immediate neighbors but also by higher order neighbors, multiple hops away. Recent state-of-the-art models for CC learn end-to-end differentiable variations of Weisfeiler-Lehman (WL) kernels to aggregate multi-hop neighborhood information. In this work, we propose a Higher Order Propagation Framework, HOPF, which provides an iterative inference mechanism for these powerful differentiable kernels. Such a combination of classical iterative inference mechanism with recent differentiable kernels allows the framework to learn graph convolutional filters that simultaneously exploit the attribute and label information available in the neighborhood. Further, these iterative differentiable kernels can scale to larger hops beyond the memory limitations of existing differentiable kernels. We also show that existing WL kernel-based models suffer from the problem of Node Information Morphing where the information of the node is morphed or overwhelmed by the information of its neighbors when considering multiple hops. To address this, we propose a specific instantiation of HOPF, called the NIP models, which preserves the node information at every propagation step. The iterative formulation of NIP models further helps in incorporating distant hop information concisely as summaries of the inferred labels. We do an extensive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:HoB7MX3m0LUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"We consider the task of generating dialogue responses from background knowledge comprising of domain specific resources. Specifically, given a conversation around a movie, the task is to generate the next response based on background knowledge about the movie such as the plot, review, Reddit comments etc. This requires capturing structural, sequential and semantic information from the conversation context and the background resources. This is a new task and has not received much attention from the community. We propose a new architecture that uses the ability of BERT to capture deep contextualized representations in conjunction with explicit structure and sequence information. More specifically, we use (i) Graph Convolutional Networks (GCNs) to capture structural information, (ii) LSTMs to capture sequential information and (iii) BERT for the deep contextualized representations that capture semantic information. We analyze the proposed architecture extensively. To this end, we propose a plug-and-play Semantics-Sequences-Structures (SSS) framework which allows us to effectively combine such linguistic information. Through a series of experiments we make some interesting observations. First, we observe that the popular adaptation of the GCN model for NLP tasks where structural information (GCNs) was added on top of sequential information (LSTMs) performs poorly on our task. This leads us to explore interesting ways of combining semantic and structural information to improve the performance. Second, we observe that while BERT already outperforms other deep contextualized representations such as ELMo, it still …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:XiSMed-E-HIC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Deep Learning has managed to push boundaries in a wide variety of tasks. One area of interest is to tackle problems in reasoning and understanding, in an aim to emulate human intelligence. In this work, we describe a deep learning model that addresses the reasoning task of question-answering on bar graphs and pie charts. We introduce a novel architecture that learns to identify various plot elements, quantify the represented values and determine a relative ordering of these statistical values. We test our model on the recently released FigureQA dataset, which provides images and accompanying questions, for bar graphs and pie charts, augmented with rich annotations. Our approach outperforms the state-of-the-art Relation Networks baseline and traditional CNN-LSTM models when evaluated on this dataset. Our model also has a considerably faster training time of approximately 2 days on 1 GPU compared to the Relation Networks baseline which requires around two weeks to train on 4 GPUs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:ZHo1McVdvXMC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"End-to-end (E2E) models have become the default choice for state-of-the-art speech recognition systems. Such models are trained on large amounts of labelled data, which are often not available for low-resource languages. Techniques such as self-supervised learning and transfer learning hold promise, but have not yet been effective in training accurate models. On the other hand, collecting labelled datasets on a diverse set of domains and speakers is very expensive. In this work, we demonstrate an inexpensive and effective alternative to these approaches by ``mining'' text and audio pairs for Indian languages from public sources, specifically from the public archives of All India Radio. As a key component, we adapt the Needleman-Wunsch algorithm to align sentences with corresponding audio segments given a long audio and a PDF of its transcript, while being robust to errors due to OCR, extraneous text, and non-transcribed speech. We thus create Shrutilipi, a dataset which contains over 6,400 hours of labelled audio across 12 Indian languages totalling to 4.95M sentences. On average, Shrutilipi results in a 2.3x increase over publicly available labelled data. We establish the quality of Shrutilipi with 21 human evaluators across the 12 languages. We also establish the diversity of Shrutilipi in terms of represented regions, speakers, and mentioned named entities. Significantly, we show that adding Shrutilipi to the training set of Wav2Vec models leads to an average decrease in WER of 5.8\% for 7 languages on the IndicSUPERB benchmark. For Hindi, which has the most benchmarks (7), the average WER falls from 18.8% to 13.5%. This …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:WqliGbK-hY8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Self-attention heads are characteristic of Transformer models and have been well studied for interpretability and pruning. In this work, we demonstrate an altogether different utility of attention heads, namely for adversarial detection. Specifically, we propose a method to construct input-specific attention subnetworks (IAS) from which we extract three features to discriminate between authentic and adversarial inputs. The resultant detector significantly improves (by over 7.5%) the state-of-the-art adversarial detection accuracy for the BERT encoder on 10 NLU datasets with 11 different adversarial attack types. We also demonstrate that our method (a) is more accurate for larger models which are likely to have more spurious correlations and thus vulnerable to adversarial attack, and (b) performs well even with modest training sets of adversarial examples.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:XiVPGOgt02cC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"Recent studies have shown the advantages of evaluating NLG systems using pairwise comparisons as opposed to direct assessment. Given systems, a naive approach for identifying the top-ranked system would be to uniformly obtain pairwise comparisons from all pairs of systems. However, this can be very expensive as the number of human annotations required would grow quadratically with . In this work, we introduce Active Evaluation, a framework to efficiently identify the top-ranked system by actively choosing system pairs for comparison using dueling bandit algorithms. We perform extensive experiments with 13 dueling bandits algorithms on 13 NLG evaluation datasets spanning 5 tasks and show that the number of human annotations can be reduced by 80%. To further reduce the number of human annotations, we propose model-based dueling bandit algorithms which combine automatic evaluation metrics with human evaluations. Specifically, we eliminate sub-optimal systems even before the human annotation process and perform human evaluations only on test examples where the automatic metric is highly uncertain. This reduces the number of human annotations required further by 89%. In effect, we show that identifying the top-ranked system requires only a few hundred human annotations, which grow linearly with . Lastly, we provide practical recommendations and best practices to identify the top-ranked system efficiently. Our code has been made publicly available at https://github.com/akashkm99/duelnlg",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:5ugPr518TE4C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",32,"The advent of Deep Learning and the availability of large scale datasets has accelerated research on Natural Language Generation with a focus on newer tasks and better models. With such rapid progress, it is vital to assess the extent of scientific progress made and identify the areas/components that need improvement. To accomplish this in an automatic and reliable manner, the NLP community has actively pursued the development of automatic evaluation metrics. Especially in the last few years, there has been an increasing focus on evaluation metrics, with several criticisms of existing metrics and proposals for several new metrics. This tutorial presents the evolution of automatic evaluation metrics to their current state along with the emerging trends in this field by specifically addressing the following questions:(i) What makes NLG evaluation challenging?(ii) Why do we need automatic evaluation metrics?(iii) What are the existing automatic evaluation metrics and how can they be organised in a coherent taxonomy?(iv) What are the criticisms and shortcomings of existing metrics?(v) What are the possible future directions of research?",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&citation_for_view=DV8z8DYAAAAJ:LPZeul_q3PIC,https://www.cse.iitm.ac.in/~miteshk
Manindra Agrawal,"['Theory of Computation', 'Complexity Theory']",26,"We show that for the blackbox polynomial identity testing (PIT) problem it suffices to study circuits that depend only on the first extremely few variables. One only need to consider size-s degree-s circuits that depend on the first log∘ c s variables (where c is a constant and we are composing c logarithms). Thus, hitting-set generator (hsg) manifests a bootstrapping behavior— a partial hsg against very few variables can be efficiently grown to a complete hsg. A boolean analog, or a pseudorandom generator property of this type, is unheard-of. Our idea is to use the partial hsg and its annihilator polynomial to efficiently bootstrap the hsg exponentially wrt variables. This is repeated c times in an efficient way.
Pushing the envelope further we show that: (1) a quadratic-time blackbox PIT for 6913-variate degree-s size-s polynomials, will lead to a “near”-complete derandomization of PIT, and (2) a blackbox PIT for n-variate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UBXqggoAAAAJ&citation_for_view=UBXqggoAAAAJ:oE_QS-WwsdAC,http://www.cse.iitk.ac.in/users/manindra
Manindra Agrawal,"['Theory of Computation', 'Complexity Theory']",26,"We study the query complexity of a permutation-based variant of the guessing game Mastermind. In this variant, the secret is a pair (z, π) which consists of a binary string z∈{0, 1} n and a permutation π of [n]. The secret must be unveiled by asking queries of the form x∈{0, 1} n. For each such query, we are returned the score f z, π (x)≔ max {i∈[0.. n]∣∀ j≤ i: z π (j)= x π (j)}; ie, the score of x is the length of the longest common prefix of x and z with respect to the order imposed by π. The goal is to minimize the number of queries needed to identify (z, π). This problem originates from the study of black-box optimization heuristics, where it is known as the LeadingOnes problem. In this work, we prove matching upper and lower bounds for the deterministic and randomized query complexity of this game, which are Θ (n log n) and Θ (n log log n), respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UBXqggoAAAAJ&cstart=20&pagesize=80&citation_for_view=UBXqggoAAAAJ:AubyX3KqGToC,http://www.cse.iitk.ac.in/users/manindra
Manindra Agrawal,"['Theory of Computation', 'Complexity Theory']",26,"We investigate a method for finding small integer solutions of a univariate modular equation, that was introduced by Coppersmith (Proceedings of Eurocrypt 1996, LNCS, vol 1070, pp 155–165, 1996) and extended by May (New RSA vulnerabilities using lattice reduction methods, Ph.D. thesis, University of Paderborn, 2003). We will refer this method as the Coppersmith technique. This paper provides a way to analyze a general limitations of the lattice construction for the Coppersmith technique. Our analysis upper bounds the possible range of U that is asymptotically equal to the bound given by the original result of Coppersmith and May. This means that they have already given the best lattice construction. In addition, we investigate the optimality for the bivariate equation to solve the small inverse problem, which was inspired by Kunihiro’s (LNCS 7483:55–69, 2012) argument. In particular, we show the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UBXqggoAAAAJ&cstart=20&pagesize=80&citation_for_view=UBXqggoAAAAJ:NaGl4SEjCO4C,http://www.cse.iitk.ac.in/users/manindra
Manindra Agrawal,"['Theory of Computation', 'Complexity Theory']",26,"Proof. This is trivially true when n= 2: r= 3 satisfies all conditions. So assume that n> 2. Then⌈ log5 n⌉> 10 and Lemma 3.1 applies. Observe that the largest value of k for any number of the form mk≤ B=⌈ log5 n⌉, m≥ 2, is⌊ log B⌋. Now consider the smallest number s that does not divide the product n⌊ log B⌋·
⌊ log2 n⌋",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UBXqggoAAAAJ&cstart=20&pagesize=80&citation_for_view=UBXqggoAAAAJ:HAmI6pRF5skC,http://www.cse.iitk.ac.in/users/manindra
Manindra Agrawal,"['Theory of Computation', 'Complexity Theory']",26,"The Isolation Lemma states that when random weights are assigned to the elements of a nite set E, then in any given family of subsets of E, exactly one set has the minimum weight, with high probability. In this note, we present two proofs for the fact that it is impossible to e ciently derandomize the Isolation Lemma for arbitrary families. The rst proof is from Chari, Rohatgi and Srinivasan and uses the potential method. An alternate proof is due to the rst author of this note. It uses the polynomial method. However, it is not written anywhere. The main purpose of this note is to present that proof. Additionally we show that the above lower bounds are almost tight with respect to various parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UBXqggoAAAAJ&cstart=20&pagesize=80&citation_for_view=UBXqggoAAAAJ:nj26e0utjpAC,http://www.cse.iitk.ac.in/users/manindra
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Diagnostic messages generated by compilers and interpreters such as syntax error messages have been researched for over half of a century. Unfortunately, these messages which include error, warning, and run-time messages, present substantial difficulty and could be more effective, particularly for novices. Recent years have seen an increased number of papers in the area including studies on the effectiveness of these messages, improving or enhancing them, and their usefulness as a part of programming process data that can be used to predict student performance, track student progress, and tailor learning plans. Despite this increased interest, the long history of literature is quite scattered and has not been brought together in any digestible form.
In order to help the computing education community (and related communities) to further advance work on programming error messages, we present a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&citation_for_view=WPLq_rQAAAAJ:hFOr9nPyWt4C,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Compile-time errors pose a major learning hurdle for students of introductory programming courses. Compiler error messages, while accurate, are targeted at seasoned programmers, and seem cryptic to beginners. In this work, we address this problem of pedagogically-inspired program repair and report TRACER (Targeted RepAir of Compilation ERrors), a system for performing repairs on compilation errors, aimed at introductory programmers.
TRACER invokes a novel combination of tools from programming language theory and deep learning and offers repairs that not only enable successful compilation, but repairs that are very close to those actually performed by students on similar errors. The ability to offer such targeted corrections, rather than just code that compiles, makes TRACER more relevant in offering real-time feedback to students in lab or tutorial sessions, as compared to existing works that merely …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&citation_for_view=WPLq_rQAAAAJ:QIV2ME_5wuYC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"We present TEGCER, an automated feedback tool for novice programmers. TEGCER uses supervised classification to match compilation errors in new code submissions with relevant pre-existing errors, submitted by other students before. The dense neural network used to perform this classification task is trained on 15000+ error-repair code examples. The proposed model yields a test set classification Pred@3 accuracy of 97.7% across 212 error category labels. Using this model as its base, TEGCER presents students with the closest relevant examples of solutions for their specific error on demand. A large scale (N>230) usability study shows that students who use TEGCER are able to resolve errors more than 25% faster on average than students being assisted by human tutors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&citation_for_view=WPLq_rQAAAAJ:hC7cP41nSMkC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"With MOOC sizes increasing every day, improving scalability and practicality of grading and tutoring of such courses is a worthwhile pursuit. To this end, we introduce TipsC. By analyzing a large number of correct submissions, TipsC can search for correct codes resembling a given incorrect solution. TipsC then suggests changes in the incorrect code to help the student fix logical errors.
We evaluate the effectiveness of TipsC’s clustering algorithm on data collected from past offerings of an introductory programming course conducted at IIT Kanpur. The results show the weighted average variance of marks for clusters when similar submissions are grouped together is 47% less compared to the case when all programs are grouped together.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&citation_for_view=WPLq_rQAAAAJ:mVmsd5A6BfQC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Diagnostic messages generated by compilers and interpreters such as syntax error messages have been researched for decades. Unfortunately these messages which include error, warning, and runtime messages, present substantial difficulty and could be more effective, particularly for novices. Recent years have seen increased number of papers in the area including studies on the effectiveness of these messages, improving or enhancing them, and their usefulness as a part of programming process data that can be used to predict student performance. Despite this increased interest, the long history of literature is quite scattered and has not been brought together in any digestible form. We argue that in order to help the community proceed with more work on diagnostic messages, the literature needs to be presented in a state-of-the-art report. In addition we will synthesize and present the existing evidence for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&citation_for_view=WPLq_rQAAAAJ:qUcmZB5y_30C,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Can automated adaptive feedback for correcting erroneous programs help novice programmers learn to code better? In a large-scale experiment, we compare student performance when tutored by human tutors, and when receiving automated adaptive feedback. The automated feedback was designed using one of two well-known instructional principles: (i) presenting the correct solution for the immediate problem, or (ii) presenting generated examples or analogies that guide towards the correct solution. We report empirical results from a large-scale (N = 480, 10,000 + person hour) experiment assessing the efficacy of these automated compilation-error feedback tools. Using the survival analysis on error rates of students measured over seven weeks, we found that automated feedback allows students to resolve errors in their code more efficiently than students receiving manual feedback. However, we also found …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&citation_for_view=WPLq_rQAAAAJ:j3f4tGmQtD8C,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"When student programs are compared for similarity as a step in the detection of academic misconduct, certain segments of code are always sure to be similar but are no cause for suspicion. Some of these segments are boilerplate code (e.g. public static void main String [] args) and some will be code that was provided to students as part of the assessment specification. This working group explores these and other types of code that are legitimately common in student assessments and can therefore be excluded from similarity checking.
From their own institutions, working group members collected assessment submissions that together encompass a wide variety of assessment tasks in a wide variety of programming languages. The submissions were analysed to determine what sorts of code segment arose frequently in each assessment task.
The group has found that common code can arise in programming …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&citation_for_view=WPLq_rQAAAAJ:bEWYMUwI8FkC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Smart contracts on Ethereum handle millions of U.S. Dollars and other financial assets. In the past, attackers have exploited smart contracts to steal these assets. The Ethereum community has developed plenty of tools to detect vulnerable smart contracts. However, there is no standardized data set to evaluate these existing tools, or any new tools developed. There is a need for an unbiased standard benchmark of real-world Ethereum smart contracts. We have created ScrawlD: an annotated data set of real-world smart contracts taken from the Ethereum network. The data set is labelled using 5 tools that detect various vulnerabilities in smart contracts, using majority voting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:maZDTaKrznsC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"An effective static slicing technique for functional programs must have two features. Its handling of function calls must be context sensitive without being inefficient, and, because of the widespread use of algebraic datatypes, it must take into account structure transmitted dependences. It has been shown that any analysis that combines these two characteristics is undecidable, and existing slicing methods drop one or the other. We propose a slicing method that only weakens (and not entirely drop) the requirement of contextsensitivity and that too for some and not all programs. We then consider applications that require the same program to be sliced with respect to several slicing criteria. We propose an incremental version of our slicing method to handle such situations efficiently. The incremental version consists of a one time precomputation step that uses the non-incremental version to slice the program with respect to a fixed default slicing criterion and processes the results to a canonical form. Presented with a slicing criterion, a low-cost incremental step uses the results of the precomputation to obtain the slice.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:ZeXyd9-uunAC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"A major drawback of shape analysis techniques is the trade-off between speed and precision. We present TwAS: a novel method to combine two shape analysis techniques-a fastbutless precise technique with a slow but more precise one-to get the best of both (speed as well as precision). The novelty of our approach is the use of fast analysis to filter heap variables for which the shape information is already precise and can not be refined further This allows us to run the slow analysis on only a small portion of the program, thus improving its performance.
We implemented TwAS in GCC as a dynamic plugin as an inter-procedural data-flow analysis and evaluated it on standard benchmarks against the component analyses. TwAS is able to achieve the same precision as the slow analysis at a marginal slowdown compared to the fast analysis. TwAS is able to improve precision for 5 out of 8 Olden benchmarks …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:7PzlFSSx8tAC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"In a CS1 course, testcases are the most common way of providing feedback. However, manually designed testcases, even if carefully crafted, may miss out on certain crucial corner cases. These testcases are only generated once for the whole class and do not take into account errors generated by specific students. This paper presents LEGenT, an automated tool that generates personalized testcases for student submission. LEGenT first localizes a statement in the program that causes deviation from the expected behaviour. Then it generates testcases that expose the deviation to the student. Our premise is that such a targeted test would help students identify one of the early reasons for the deviation.
LEGenT works by separating buggy programs from the correct ones using an off-the-shelf formal equivalence checker. It uses another off-the-shelf tool to cluster buggy as well as correct programs. It aligns an incorrect …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:blknAaTinKkC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Most of the 2.5 million undergraduates in CS and related programs in India are enrolled in institutions outside the top tier. While official policies broadly acknowledge that many instructors at these institutions lack the requisite domain competence, there is no precise understanding of their limitations. In this study, we analyse the ability of CS instructors from 10 mid-tier institutions in Karnataka (India) to perform CS1-level programming tasks. While instructors can perform simple code tracing tasks with reasonable accuracy, we find a sharp fall in their ability to reason about code abstractly, to modify given code, and to write code. Our findings have immediate implications for faculty training initiatives, which must initially focus on these foundational skills.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:k_IJM867U9cC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Computer-based tests (CBTs) play an important role in the professional career of any person. Universities use CBTs for admissions. Further, many large courses use CBTs for evaluation and grading. Almost all software companies use CBTs to offer jobs. However, many of these CBTs do not take attention to the accessibility barriers for persons with disabilities, specifically visually impaired persons. In this paper, we present a study of accessibility barriers in various CBTs as faced by visually impaired persons in India. These barriers have been identified by a questionnaire survey approach. Our analysis of the responses shows that most CBTs do not meet the expectations of visually impaired persons. We conclude the paper with some recommendations to improve accessibility.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:IWHjjKOFINEC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Abstract Graphics Processing Units (GPUs) maintain a large register file to increase the thread level parallelism (TLP). To increase the TLP further, recent GPUs have increased the number of on-chip registers in every generation. However, with the increase in the register file size, the leakage power increases. Also, with the technology advances, the leakage power component has increased and has become an important consideration for the manufacturing process. The leakage power of a register file can be reduced by turning infrequently used registers into low power (drowsy or off) state after accessing them. A major challenge in doing so is the lack of runtime register access information. To address this, we propose a system called. It employs a compiler analysis that determines the power state of the registers, ie, which registers can be switched off or placed in drowsy state at each program point and encodes this …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:L8Ckcad2t8MC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Automated pedagogical error repair (APER) is the task of suggesting fixes to buggy programs written by beginner or novice programmers. APER tools have been shown to greatly improve the learning experience for students for whom error messages offered by compilers or runtime environments are either unhelpful and often misleading. Consequently, several APER tools have been proposed in literature using a variety of powerful machine learning techniques including sequence-to-sequence modelling (TRACER), reinforcement learning (RLAssist), graph attention (DrRepair) and decision trees (MACER). Despite offering high repair rates, these tools are often bulky, requiring several days of training and extensive GPU resources. This paper describes CAPER, a novel APER tool for the C programming language that offers 4-5% higher repair accuracy than existing APER tools on multiple benchmark error repair …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:RGFaLdJalmkC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"We report the design, development and deployment of PRIORITY, an intelligent portal aimed at reducing the workload of instructors, tutors and teaching assistants in large programming courses of creating lab, assignment and exam problems every week. PRIORITY offers a scalable, user friendly and indexed repository of problems that can be queried to retrieve problems related to a particular programming concept, say for loops. PRIORITY accomplishes this by casting problem retrieval as a multi-label learning problem and using solving it using novel feature selection and AI-techniques. We also report the results of an A/B test and user survey, both conducted while PRIORITY was being used to offer a CS1 course taught at IIT Kanpur with over 500 students. PRIORITY has been in deployment at IIT Kanpur for almost 2 years now and our experience thus far suggests that it not only presents a valuable tool for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:ns9cj8rnVeAC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"The modernization of power systems has facilitated better communication infrastructure but raised concerns regarding privacy and security of the transmitted data. This paper demonstrates a comprehensive man-in-the-middle (MITM) attack in a synchrophasor network. The stealth of the MITM attack is presented in this paper, and it shows how the adversary’s presence remains undetected in the network. The intercepted communication between the phasor measurement unit (PMU) and phasor data concentrator (PDC) is examined. PDC analyzes the spoofed data without setting any alarms to network operators, thus affecting the power system automation. An experimental implementation of the MITM attack is carried out in a laboratory-scale setup, using commercial PMUs, PDC, and various routers to demonstrate the stealth and effectiveness of the attack.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:NaGl4SEjCO4C,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"NOVEMBER 2022| VOL. 65| NO. 11| COMMUNICATIONS OF THE ACM 63 hot topics india region automate mechanical and time-consuming tasks performed by instructors and TAs? Apart from reducing manual effort, this could also improve instruction quality in resource-strapped situations. Our research group at IIT Kanpur has used Prutor data to develop AI tools targeting core pedagogical aspects of a course, such as question creation, doubt clearing, and grading (see Figure 2). Prutor data has also enabled researchers at IISc Bengaluru, National University of Singapore, Queensland University of Technology, and Innopolis University to develop solutions for error repair and improved feedback generation resulting in work appearing in several top-tier publications. 2–5, 8, 9, 11, 15, 17, 18",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:BqipwSGYUEgC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"The accommodations in exams (for example, scribe, compensatory time, and magnification) are widely used for many years to accommodate persons with visual impairments (PVIs). Nowadays, most of the exams are conducted using computers and web-based technologies, referred to as Computer-based tests (CBTs). These CBTs play an important role in the professional assessment of an individual, starting from university admissions, courses evaluation, and grading, to recruitment in various sectors like banking, software, railways, etc. Barriers in accessing certain components of the CBTs limit the utilization of Computer-based technologies for PVIs. In this research, the availability and effectiveness of common accommodations in CBTs were evaluated and reviewed. To the best of our knowledge, this is one of the early attempts from India to systematically study the effectiveness of these accommodations. Driven by a universal design approach, it can play a key role towards the development of an inclusive examination system.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:isC4tDSrTZIC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"When student programs are compared for similarity, certain segments of code are always sure to be similar. Some of these segments are boilerplate code -- public static void main String [] args and the like -- and some will be code that was provided to students as part of the assessment specification. The purpose of this working group is to explore what other code is expected to be reasonably common in student assessments, and should therefore be excluded from similarity checking. The answers will clearly vary with programming language, and perhaps with level of assessment item. Working group members will collect assessment submissions from their own or their colleagues' students, and it is hoped that these submissions will together encompass a wide variety of assessment tasks in a wide variety of programming languages. The working group aims to deliver clear guidelines as to what code can reasonably …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:4JMBOYKVnBMC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"This is a short report on the Tutorials of the 13th Innovations in Software Engineering (ISEC 2020) conference held on 27th February 2020 in Jabalpur, India.
ISEC tutorials are 3-hour sessions providing a hands-on introduction to an emerging research area or a useful research tool on any topic relevant to software engineering. The tutorials are mainly geared towards students and young researchers and are designed to equip them with tools that can help their own research and foster new research directions. The tutorials at ISEC offer a glimpse of the state-of-the-art research in various disciplines of software engineering.
This year, ISEC tutorial track attracted a total of three submissions. Two submissions were selected based on the content and relevance to the theme of the conference.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:_Qo2XoVZTnwC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Software Engineering Researchers in India from both academia and industry are widely contributing to various research problems. In this report, we brie y summarize the key insights from 1st Software Engineering Research in India Update Meeting (SERI 2019), which provides a platform for all the researchers to present and discuss their research work. The essence of this research meeting is to examine the current research areas within the software engineering research community and discover the scope of collaboration. Speci cally, the rst SERI update meeting had a series of invited research talks presented by researchers from academia and industry representing various software engineering labs across India. These talks unveiled notable views through presentations and group discussions, and cogitation of topics that can lead to fruitful collaborations between software engineering researchers and industry …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:-f6ydRqryjwC,http://www.cse.iitk.ac.in/~karkare
Amey Karkare,"['Compilers', 'Programming Languages', 'Program Synthesis']",12,"Education is a fundamental right for everyone. In today’s world, methods of education are gradually shifting from traditional pen-paper based classrooms to computer-based classrooms. On the one hand, this shift has opened ample opportunities for availing the education at low cost to a large section of the community. On the other hand, there are many students with visual impairment, who are unable to use these digital resources due to their vision limitation. This research is an attempt to understand the challenges faced by visually impaired persons and to suggest remedies to provide better opportunities to visually impaired persons to avail inclusive education using various digital resources.
The entrance examinations are vital to open the world of education in most of the premium institutions across the globe. In India, major entrance examinations (JEE Mains, JEE Advanced, GATE, JAM, etc.) are now computer-based. We conducted a users’ study of challenges faced by visually impaired persons during the computer-based tests (CBTs) for these examinations. We further evaluated the effectiveness of multiple accommodations provided in these CBTs. After that, we worked on the more generic problem of accessibility barriers in web applications and challenges faced by web-developers in creating these applications. In order to ease the process of authoring accessible web-pages for web developers, we have created i) An accessible web-development manual, ii) Examples and videos demonstrating accessible vs. inaccessible components of web-applications, and iii) a semi-automated tool to fix accessibility issues in web-applications. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=WPLq_rQAAAAJ&cstart=20&pagesize=80&citation_for_view=WPLq_rQAAAAJ:e5wmG9Sq2KIC,http://www.cse.iitk.ac.in/~karkare
Sandeep Shukla,"['cyber security', 'Blockchain', 'cyber physical systems', 'Formal Method']",39,"Machine learning technology has become mainstream in a large number of domains, and cybersecurity applications of machine learning techniques are plenty. Examples include malware analysis, especially for zero‐day malware detection, threat analysis, anomaly based intrusion detection of prevalent attacks on critical infrastructures, and many others. Due to the ineffectiveness of signature‐based methods in detecting zero day attacks or even slight variants of known attacks, machine learning‐based detection is being used by researchers in many cybersecurity products. In this review, we discuss several areas of cybersecurity where machine learning is used as a tool. We also provide a few glimpses of adversarial attacks on machine learning algorithms to manipulate training and test data of classifiers, to render such tools ineffective.
This article is categorized under:
Application Areas > Science and Technology …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SKqctYsAAAAJ&citation_for_view=SKqctYsAAAAJ:I8rxH6phXEkC,http://www.cse.iitk.ac.in/users/sandeeps/
Sandeep Shukla,"['cyber security', 'Blockchain', 'cyber physical systems', 'Formal Method']",39,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SKqctYsAAAAJ&cstart=20&pagesize=80&citation_for_view=SKqctYsAAAAJ:ifOnle78iJkC,http://www.cse.iitk.ac.in/users/sandeeps/
Sandeep Shukla,"['cyber security', 'Blockchain', 'cyber physical systems', 'Formal Method']",39,"In the recent years, there has been an exponential growth in the number of malware captured and analyzed by the antivirus companies. However, much of these malware are variants of already known malware. Thus, it has become necessary to determine whether a malware belongs to a known family, or exhibits a new behavior hitherto unseen, and requires further analysis. Existing traditional approaches used by antivirus companies are based on signature-based detection and can be thwarted in case of zero-day exploit-based malware. Manual examination of such executables is extremely cumbersome due to the enormous number of such cases. Also, it has become necessary to speed up the detection process and predict before the executable releases its malicious payload. In this work, we addressed the above issues using automated yet efficient malware analysis. We classified the malicious executables into …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SKqctYsAAAAJ&cstart=20&pagesize=80&citation_for_view=SKqctYsAAAAJ:kUhpeDhEZMUC,http://www.cse.iitk.ac.in/users/sandeeps/
Sandeep Shukla,"['cyber security', 'Blockchain', 'cyber physical systems', 'Formal Method']",39,"Ethereum is a blockchain platform where users can transact cryptocurrency as well as build and deploy decentralized applications using smart contracts. The participants in the Ethereum platform are ‘pseudo-anonymous’ and same user can have multiple accounts under multiple cryptographic identities. As a result, detecting malicious users engaged in fraudulent activities as well as attribution are quite difficult. In the recent past, multiple such activities came to light. In the famous Ethereum DAO attack, hackers exploited bug in smart contracts stole large amount of cryptocurrency using fraudulent transactions. However, activities such as ponzi-scheme, tax evasion by transacting in cryptocurrency, using pseudo-anonymous accounts for receiving ransom payment, consolidation of funds accumulated under multiple identities etc. should be monitored and detected in order to keep legitimate users safe on the platform …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SKqctYsAAAAJ&cstart=20&pagesize=80&citation_for_view=SKqctYsAAAAJ:AFmTUeZ1pmEC,http://www.cse.iitk.ac.in/users/sandeeps/
Sandeep Shukla,"['cyber security', 'Blockchain', 'cyber physical systems', 'Formal Method']",39,"Directed Graph based models of a blockchain that capture accounts as nodes and transactions as edges, evolve over time. This temporal nature of a blockchain model enables us to understand the behavior (malicious or benign) of the accounts. Predictive classification of accounts as malicious or benign could help users of the permissionless blockchain platforms to operate in a secure manner. Motivated by this, we introduce temporal features such as burst and attractiveness on top of several already used graph properties such as the node degree and clustering coefficient. Using identified features, we train various Machine Learning (ML) models and identify the algorithm that performs the best in detecting malicious accounts. We then study the behavior of the accounts over different temporal granularities of the dataset before assigning them malicious tags. For the Ethereum blockchain, we identify that for the entire dataset—the ExtraTreesClassifier performs the best among supervised ML algorithms. On the other hand, using cosine similarity on top of the results provided by unsupervised ML algorithms such as K-Means on the entire dataset, we were able to detect 554 more suspicious accounts. Further, using behavior change analysis for accounts, we identify 814 unique suspicious accounts across different temporal granularities.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SKqctYsAAAAJ&cstart=20&pagesize=80&citation_for_view=SKqctYsAAAAJ:DquSII9TDu4C,http://www.cse.iitk.ac.in/users/sandeeps/
Sandeep Shukla,"['cyber security', 'Blockchain', 'cyber physical systems', 'Formal Method']",39,"The energy output a photo voltaic(PV) panel is a function of solar irradiation and weather parameters like temperature and wind speed etc. A general measure for solar irradiation called Global Horizontal Irradiance (GHI), customarily reported in Watt/meter2, is a generic indicator for this intermittent energy resource. An accurate prediction of GHI is necessary for reliable grid integration of the renewable as well as for power market trading. While some machine learning techniques are well introduced along with the traditional time-series forecasting techniques, deep-learning techniques remains less explored for the task at hand. In this paper we give deep learning models suitable for sequence to sequence prediction of GHI. The deep learning models are reported for shortterm forecasting {1 - 24} hour along with the state-of-the art techniques like Gradient Boosted Regression Trees(GBRT) and Feed Forward Neural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SKqctYsAAAAJ&cstart=20&pagesize=80&citation_for_view=SKqctYsAAAAJ:urP0JZOBBUsC,http://www.cse.iitk.ac.in/users/sandeeps/
Sandeep Shukla,"['cyber security', 'Blockchain', 'cyber physical systems', 'Formal Method']",39,"In this paper, we present a mimicry attack to transform malware binary, which can evade detection by API call sequence based malware classifiers. While original malware was detectable by malware classifiers, transformed malware, when run, with modified API call sequence without compromising the payload of the original, is effectively able to avoid detection. Our model is effective against a large set of malware classifiers which includes linear models such as Random Forest (RF), Decision Tree (DT) and XGBoost classifiers and fully connected NNs, CNNs and RNNs and its variants. Our implementation is easy to use (i.e., a malware transformation only requires running a couple of commands) and generic (i.e., works for any malware without requiring malware specific changes). We also show that adversarial retraining can make malware classifiers robust against such evasion attacks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SKqctYsAAAAJ&cstart=20&pagesize=80&citation_for_view=SKqctYsAAAAJ:RXiHnyRawswC,http://www.cse.iitk.ac.in/users/sandeeps/
Sandeep Shukla,"['cyber security', 'Blockchain', 'cyber physical systems', 'Formal Method']",39,"In today’s world of devices, smart phones, tablets, and wearable devices, are widely used for communication, photography, entertainment, monitoring health status, and many more applications. Applications installed in the smartphones provide useful services, but they may maliciously send sensitive information to a remote location for various purposes. Due to the nature of open-source ecosystem, the usage of Android platform in mobile devices has grown significantly, and the security concerns have also increased manifold. Malware and software vulnerabilities issues violated end users’ security and privacy. This article discusses and analyzes the Android architecture and platform vulnerabilities along with threat models, and malware analysis techniques followed by a few security challenges and future research directions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=SKqctYsAAAAJ&cstart=20&pagesize=80&citation_for_view=SKqctYsAAAAJ:uAPFzskPt0AC,http://www.cse.iitk.ac.in/users/sandeeps/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"This report summarizes the results of the SemEval 2018 task on machine comprehension using commonsense knowledge. For this machine comprehension task, we created a new corpus, MCScript. It contains a high number of questions that require commonsense knowledge for finding the correct answer. 11 teams from 4 different countries participated in this shared task, most of them used neural approaches. The best performing system achieves an accuracy of 83.95%, outperforming the baselines by a large margin, but still far from the human upper bound, which was found to be at 98%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:eQOLeE2rZwMC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"The majority of current systems for end-to-end dialog generation focus on response quality without an explicit control over the affective content of the responses. In this paper, we present an affect-driven dialog system, which generates emotional responses in a controlled manner using a continuous representation of emotions. The system achieves this by modeling emotions at a word and sequence level using: (1) a vector representation of the desired emotion, (2) an affect regularizer, which penalizes neutral words, and (3) an affect sampling method, which forces the neural network to generate diverse words that are emotionally relevant. During inference, we use a reranking procedure that aims to extract the most emotionally relevant responses using a human-in-the-loop optimization process. We study the performance of our system in terms of both quantitative (BLEU score and response diversity), and qualitative (emotional appropriateness) measures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:Se3iqnhoufwC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"We introduce a large dataset of narrative texts and questions about these texts, intended to be used in a machine comprehension task that requires reasoning using commonsense knowledge. Our dataset complements similar datasets in that we focus on stories about everyday activities, such as going to the movies or working in the garden, and that the questions require commonsense knowledge, or more specifically, script knowledge, to be answered. We show that our mode of data collection via crowdsourcing results in a substantial amount of such inference questions. The dataset forms the basis of a shared task on commonsense and script knowledge organized at SemEval 2018 and provides challenging test cases for the broader natural language understanding community.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:WF5omc3nYNoC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"An automated system that could assist a judge in predicting the outcome of a case would help expedite the judicial process. For such a system to be practically useful, predictions by the system should be explainable. To promote research in developing such a system, we introduce ILDC (Indian Legal Documents Corpus). ILDC is a large corpus of 35k Indian Supreme Court cases annotated with original court decisions. A portion of the corpus (a separate test set) is annotated with gold standard explanations by legal experts. Based on ILDC, we propose the task of Court Judgment Prediction and Explanation (CJPE). The task requires an automated system to predict an explainable outcome of a case. We experiment with a battery of baseline models for case predictions and propose a hierarchical occlusion based model for explainability. Our best prediction model has an accuracy of 78% versus 94% for human legal experts, pointing towards the complexity of the prediction task. The analysis of explanations by the proposed algorithm reveals a significant difference in the point of view of the algorithm and legal experts for explaining the judgments, pointing towards scope for future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:HDshCWvjkbEC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"The task of Emotion-Cause Pair Extraction (ECPE) aims to extract all potential clause-pairs of emotions and their corresponding causes in a document. Unlike the more well-studied task of Emotion Cause Extraction (ECE), ECPE does not require the emotion clauses to be provided as annotations. Previous works on ECPE have either followed a multi-stage approach where emotion extraction, cause extraction, and pairing are done independently or use complex architectures to resolve its limitations. In this paper, we propose an end-to-end model for the ECPE task. Due to the unavailability of an English language ECPE corpus, we adapt the NTCIR-13 ECE corpus and establish a baseline for the ECPE task on this dataset. On this dataset, the proposed method produces significant performance improvements (~6.5 increase in F1 score) over the multi-stage approach and achieves comparable performance to the state-of-the-art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:mVmsd5A6BfQC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"This paper describes our participating system in the WASSA 2018 shared task on emotion prediction. The task focuses on implicit emotion prediction in a tweet. In this task, keywords corresponding to the six emotion labels used (anger, fear, disgust, joy, sad, and surprise) have been removed from the tweet text, making emotion prediction implicit and the task challenging. We propose a model based on an ensemble of classifiers for prediction. Each classifier uses a sequence of Convolutional Neural Network (CNN) architecture blocks and uses ELMo (Embeddings from Language Model) as an input. Our system achieves a 66.2% F1 score on the test set. The best performing system in the shared task has reported a 71.4% F1 score.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:LkGwnXOMwfcC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,A computer-implemented method for predicting answers to questions concerning medical image analytics reports includes splitting a medical image analytics report into a plurality of sentences and generating a plurality of sentence embedding vectors by applying a natural language processing framework to the plurality of sentences. A question related to subject matter included in the medical image analytics report is received and a question embedding vector is generated by applying the natural language processing framework to the question. A subset of the sentence embedding vectors most similar to the question embedding vector is identified by applying a similarity matching process to the sentence embedding vectors and the question embedding vector. A trained recurrent neural network (RNN) is used to determine a predicted answer to the question based on the subset of the sentence embedding vectors.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:ufrVoPGSRksC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Social media is abundant in visual and textual information presented together or in isolation. Memes are the most popular form, belonging to the former class. In this paper, we present our approaches for the Memotion Analysis problem as posed in SemEval-2020 Task 8. The goal of this task is to classify memes based on their emotional content and sentiment. We leverage techniques from Natural Language Processing (NLP) and Computer Vision (CV) towards the sentiment classification of internet memes (Subtask A). We consider Bimodal (text and image) as well as Unimodal (text-only) techniques in our study ranging from the Na ̈ıve Bayes classifier to Transformer-based approaches. Our results show that a text-only approach, a simple Feed Forward Neural Network (FFNN) with Word2vec embeddings as input, performs superior to all the others. We stand first in the Sentiment analysis task with a relative improvement of 63% over the baseline macro-F1 score. Our work is relevant to any task concerned with the combination of different modalities.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:Zph67rFs4hoC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Human use language not just to convey information but also to express their inner feelings and mental states. In this work, we adapt the state-of-the-art language generation models to generate affective (emotional) text. We posit a model capable of generating affect-driven and topic focused sentences without losing grammatical correctness as the affect intensity increases. We propose to incorporate emotion as prior for the probabilistic state-of-the-art text generation model such as GPT-2. The model gives a user the flexibility to control the category and intensity of emotion as well as the topic of the generated text. Previous attempts at modelling fine-grained emotions fall out on grammatical correctness at extreme intensities, but our model is resilient to this and delivers robust results at all intensities. We conduct automated evaluations and human studies to test the performance of our model, and provide a detailed comparison of the results with other models. In all evaluations, our model outperforms existing affective text generation models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:4DMP91E08xMC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Automatically generating animation from natural language text finds application in a number of areas e.g. movie script writing, instructional videos, and public safety. However, translating natural language text into animation is a challenging task. Existing text-to-animation systems can handle only very simple sentences, which limits their applications. In this paper, we develop a text-to-animation system which is capable of handling complex sentences. We achieve this by introducing a text simplification step into the process. Building on an existing animation generation system for screenwriting, we create a robust NLP pipeline to extract information from screenplays and map them to the system's knowledge base. We develop a set of linguistic transformation rules that simplify complex sentences. Information extracted from the simplified sentences is used to generate a rough storyboard and video depicting the text. Our sentence simplification module outperforms existing systems in terms of BLEU and SARI metrics.We further evaluated our system via a user study: 68 % participants believe that our system generates reasonable animation from input screenplays.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:0EnyYjriUFMC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Developing intelligent virtual characters has attracted a lot of attention in the recent years. The process of creating such characters often involves a team of creative authors who describe different aspects of the characters in natural language, and planning experts that translate this description into a planning domain. This can be quite challenging as the team of creative authors should diligently define every aspect of the character especially if it contains complex human-like behavior. Also a team of engineers has to manually translate the natural language description of a character's personality into the planning domain knowledge. This can be extremely time and resource demanding and can be an obstacle to author's creativity. The goal of this paper is to introduce an authoring assistant tool to automate the process of domain generation from natural language description of virtual characters, thus bridging between the creative authoring team and the planning domain experts. Moreover, the proposed tool also identifies possible missing information in the domain description and iteratively makes suggestions to the author.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:hqOjcs7Dif8C,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Recently, text world games have been proposed to enable artificial agents to understand and reason about real-world scenarios. These text-based games are challenging for artificial agents, as it requires an understanding of and interaction using natural language in a partially observable environment. Agents observe the environment via textual descriptions designed to be challenging enough for even human players. Past approaches have not paid enough attention to the language understanding capability of the proposed agents. Typically, these approaches train from scratch, an agent that learns both textual representations and the gameplay online during training using a temporal loss function. Given the sample-inefficiency of RL approaches, it is inefficient to learn rich enough textual representations to be able to understand and reason using the textual observation in such a complicated game environment setting. In this paper, we improve the semantic understanding of the agent by proposing a simple RL with LM framework where we use transformer-based language models with Deep RL models. We perform a detailed study of our framework to demonstrate how our model outperforms all existing agents on the popular game, Zork1, to achieve a score of 44.7, which is 1.6 higher than the state-of-the-art model. Overall, our proposed approach outperforms 4 games out of the 14 text-based games, while performing comparable to the state-of-the-art models on the remaining games.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&citation_for_view=AWu6f60AAAAJ:TQgYirikUcIC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In populous countries, pending legal cases have been growing exponentially. There is a need for developing techniques for processing and organizing legal documents. In this paper, we introduce a new corpus for structuring legal documents. In particular, we introduce a corpus of legal judgment documents in English that are segmented into topical and coherent parts. Each of these parts is annotated with a label coming from a list of pre-defined Rhetorical Roles. We develop baseline models for automatically predicting rhetorical roles in a legal document based on the annotated corpus. Further, we show the application of rhetorical roles to improve performance on the tasks of summarization and legal judgment prediction. We release the corpus and baseline model code along with the paper.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:j3f4tGmQtD8C,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In this paper, we present our approaches for the FinSim 2020 shared task on ""Learning Semantic Representations for the Financial Domain"". The goal of this task is to classify financial terms into the most relevant hypernym (or top-level) concept in an external ontology. We leverage both context-dependent and context-independent word embeddings in our analysis. Our systems deploy Word2vec embeddings trained from scratch on the corpus (Financial Prospectus in English) along with pre-trained BERT embeddings. We divide the test dataset into two subsets based on a domain rule. For one subset, we use unsupervised distance measures to classify the term. For the second subset, we use simple supervised classifiers like Naive Bayes, on top of the embeddings, to arrive at a final prediction. Finally, we combine both the results. Our system ranks 1st based on both the metrics, i.e., mean rank and accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:MXK_kJrjxJIC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Many populous countries including India are burdened with a considerable backlog of legal cases. Development of automated systems that could process legal documents and augment legal practitioners can mitigate this. However, there is a dearth of high-quality corpora that is needed to develop such data-driven systems. The problem gets even more pronounced in the case of low resource languages such as Hindi. In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of more than 900K legal documents in Hindi. Documents are cleaned and structured to enable the development of downstream applications. Further, as a use-case for the corpus, we introduce the task of bail prediction. We experiment with a battery of models and propose a Multi-Task Learning (MTL) based model for the same. MTL models use summarization as an auxiliary task along with bail prediction as the main task. Experiments with different models are indicative of the need for further research in this area. We release the corpus and model implementation code with this paper: https://github.com/Exploration-Lab/HLDC",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:TFP_iSt0sucC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Legal documents are unstructured, use legal jargon, and have considerable length, making them difficult to process automatically via conventional text processing techniques. A legal document processing system would benefit substantially if the documents could be segmented into coherent information units. This paper proposes a new corpus of legal documents annotated (with the help of legal experts) with a set of 13 semantically coherent units labels (referred to as Rhetorical Roles), e.g., facts, arguments, statute, issue, precedent, ruling, and ratio. We perform a thorough analysis of the corpus and the annotations. For automatically segmenting the legal documents, we experiment with the task of rhetorical role prediction: given a document, predict the text segments corresponding to various roles. Using the created corpus, we experiment extensively with various deep learning-based baseline models for the task. Further, we develop a multitask learning (MTL) based deep model with document rhetorical role label shift as an auxiliary task for segmenting a legal document. The proposed model shows superior performance over the existing models. We also experiment with model performance in the case of domain transfer and model distillation techniques to see the model performance in limited data conditions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:RHpTSmoSYBkC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"This paper presents the system for SemEval 2021 Task 8 (MeasEval). MeasEval is a novel span extraction, classification, and relation extraction task focused on finding quantities, attributes of these quantities, and additional information, including the related measured entities, properties, and measurement contexts. Our submitted system, which placed fifth (team rank) on the leaderboard, consisted of SciBERT with [CLS] token embedding and CRF layer on top. We were also placed first in Quantity (tied) and Unit subtasks, second in MeasuredEntity, Modifier and Qualifies subtasks, and third in Qualifier subtask.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:L8Ckcad2t8MC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Sentiment Analysis of code-mixed text has diversified applications in opinion mining ranging from tagging user reviews to identifying social or political sentiments of a sub-population. In this paper, we present an ensemble architecture of convolutional neural net (CNN) and self-attention based LSTM for sentiment analysis of code-mixed tweets. While the CNN component helps in the classification of positive and negative tweets, the self-attention based LSTM, helps in the classification of neutral tweets, because of its ability to identify correct sentiment among multiple sentiment bearing units. We achieved F1 scores of 0.707 (ranked 5th) and 0.725 (ranked 13th) on Hindi-English (Hinglish) and Spanish-English (Spanglish) datasets, respectively. The submissions for Hinglish and Spanglish tasks were made under the usernames ayushk and harsh_6 respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:kNdYIx-mwKoC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In this work, we present our approach and findings for SemEval-2021 Task 5 - Toxic Spans Detection. The task's main aim was to identify spans to which a given text's toxicity could be attributed. The task is challenging mainly due to two constraints: the small training dataset and imbalanced class distribution. Our paper investigates two techniques, semi-supervised learning and learning with Self-Adjusting Dice Loss, for tackling these challenges. Our submitted system (ranked ninth on the leader board) consisted of an ensemble of various pre-trained Transformer Language Models trained using either of the above-proposed techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:IWHjjKOFINEC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"This paper describes our submissions to SemEval 2020 Task 11: Detection of Propaganda Techniques in News Articles for each of the two subtasks of Span Identification and Technique Classification. We make use of pre-trained BERT language model enhanced with tagging techniques developed for the task of Named Entity Recognition (NER), to develop a system for identifying propaganda spans in the text. For the second subtask, we incorporate contextual features in a pre-trained RoBERTa model for the classification of propaganda techniques. We were ranked 5th in the propaganda technique classification subtask.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:4TOpqqG69KYC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,This paper describes the system proposed for addressing the research problem posed in Task 10 of SemEval-2020: Emphasis Selection For Written Text in Visual Media. We propose an end-to-end model that takes as input the text and corresponding to each word gives the probability of the word to be emphasized. Our results show that transformer-based models are particularly effective in this task. We achieved the best Matchm score (described in section 2.2) of 0.810 and were ranked third on the leaderboard.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:YOwf2qJgpHMC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"This paper describes our efforts in tackling Task 5 of SemEval-2020. The task involved detecting a class of textual expressions known as counterfactuals and separating them into their constituent elements. Counterfactual statements describe events that have not or could not have occurred and the possible implications of such events. While counterfactual reasoning is natural for humans, understanding these expressions is difficult for artificial agents due to a variety of linguistic subtleties. Our final submitted approaches were an ensemble of various fine-tuned transformer-based and CNN-based models for the first subtask and a transformer model with dependency tree information for the second subtask. We ranked 4-th and 9-th in the overall leaderboard. We also explored various other approaches that involved the use of classical methods, other neural architectures and the incorporation of different linguistic features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:ULOm3_A8WrAC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Emotions are an inherent part of human interactions, and consequently, it is imperative to develop AI systems that understand and recognize human emotions. During a conversation involving various people, a person's emotions are influenced by the other speaker's utterances and their own emotional state over the utterances. In this paper, we propose COntextualized Graph Neural Network based Multimodal Emotion recognitioN (COGMEN) system that leverages local information (i.e., inter/intra dependency between speakers) and global information (context). The proposed model uses Graph Neural Network (GNN) based architecture to model the complex dependencies (local and global information) in a conversation. Our model gives state-of-the-art (SOTA) results on IEMOCAP and MOSEI datasets, and detailed ablation experiments show the importance of modeling information at both levels.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:isC4tDSrTZIC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In this work, we present our approach for solving the SemEval 2021 Task 2: Multilingual and Cross-lingual Word-in-Context Disambiguation (MCL-WiC). The task is a sentence pair classification problem where the goal is to detect whether a given word common to both the sentences evokes the same meaning. We submit systems for both the settings - Multilingual (the pair's sentences belong to the same language) and Cross-Lingual (the pair's sentences belong to different languages). The training data is provided only in English. Consequently, we employ cross-lingual transfer techniques. Our approach employs fine-tuning pre-trained transformer-based language models, like ELECTRA and ALBERT, for the English task and XLM-R for all other tasks. To improve these systems' performance, we propose adding a signal to the word to be disambiguated and augmenting our data by sentence pair reversal. We further augment the dataset provided to us with WiC, XL-WiC and SemCor 3.0. Using ensembles, we achieve strong performance in the Multilingual task, placing first in the EN-EN and FR-FR sub-tasks. For the Cross-Lingual setting, we employed translate-test methods and a zero-shot method, using our multilingual models, with the latter performing slightly better.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:9ZlFYXVOiuMC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Humor and Offense are highly subjective due to multiple word senses, cultural knowledge, and pragmatic competence. Hence, accurately detecting humorous and offensive texts has several compelling use cases in Recommendation Systems and Personalized Content Moderation. However, due to the lack of an extensive labeled dataset, most prior works in this domain haven't explored large neural models for subjective humor understanding. This paper explores whether large neural models and their ensembles can capture the intricacies associated with humor/offense detection and rating. Our experiments on the SemEval-2021 Task 7: HaHackathon show that we can develop reasonable humor and offense detection systems with such models. Our models are ranked third in subtask 1b and consistently ranked around the top 33% of the leaderboard for the remaining subtasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:ZeXyd9-uunAC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Deep learning models are susceptible to adversarial examples that have imperceptible perturbations in the original input, resulting in adversarial attacks against these models. Analysis of these attacks on the state of the art transformers in NLP can help improve the robustness of these models against such adversarial inputs. In this paper, we present Adv-OLM, a black-box attack method that adapts the idea of Occlusion and Language Models (OLM) to the current state of the art attack methods. OLM is used to rank words of a sentence, which are later substituted using word replacement strategies. We experimentally show that our approach outperforms other attack methods for several text classification tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:Wp0gIr-vW9MC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:bEWYMUwI8FkC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Predicting emotions expressed in text is a well-studied problem in the NLP community. Recently there has been active research in extracting the cause of an emotion expressed in text. Most of the previous work has done causal emotion entailment in documents. In this work, we propose neural models to extract emotion cause span and entailment in conversations. For learning such models, we use RECCON dataset, which is annotated with cause spans at the utterance level. In particular, we propose MuTEC, an end-to-end Multi-Task learning framework for extracting emotions, emotion cause, and entailment in conversations. This is in contrast to existing baseline models that use ground truth emotions to extract the cause. MuTEC performs better than the baselines for most of the data folds provided in the dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:blknAaTinKkC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"A real-world application or setting involves interaction between different modalities (e.g., video, speech, text). In order to process the multimodal information automatically and use it for an end application, Multimodal Representation Learning (MRL) has emerged as an active area of research in recent times. MRL involves learning reliable and robust representations of information from heterogeneous sources and fusing them. However, in practice, the data acquired from different sources are typically noisy. In some extreme cases, a noise of large magnitude can completely alter the semantics of the data leading to inconsistencies in the parallel multimodal data. In this paper, we propose a novel method for multimodal representation learning in a noisy environment via the generalized product of experts technique. In the proposed method, we train a separate network for each modality to assess the credibility of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:JV2RwH3_ST0C,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Emotion Recognition in Conversations (ERC) is an important and active research problem. Recent work has shown the benefits of using multiple modalities (e.g., text, audio, and video) for the ERC task. In a conversation, participants tend to maintain a particular emotional state unless some external stimuli evokes a change. There is a continuous ebb and flow of emotions in a conversation. Inspired by this observation, we propose a multimodal ERC model and augment it with an emotion-shift component. The proposed emotion-shift component is modular and can be added to any existing multimodal ERC model (with a few modifications), to improve emotion recognition. We experiment with different variants of the model, and results show that the inclusion of emotion shift signal helps the model to outperform existing multimodal models for ERC and hence showing the state-of-the-art performance on MOSEI and IEMOCAP datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:4JMBOYKVnBMC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Various embodiments disclosed herein provide techniques for performing incremental natural language understanding on a natural language understanding (NLU) system. The NLU system acquires a first audio speech segment associated with a user utterance. The NLU system converts the first audio speech segment into a first text segment. The NLU system determines a first intent based on a text string associated with the first text segment, wherein the text string represents a portion of the user utterance. The NLU system generates a first response based on the first intent prior to when the user utterance completes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:-f6ydRqryjwC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"This paper describes our contribution to SemEval 2021 Task 1: Lexical Complexity Prediction. In our approach, we leverage the ELECTRA model and attempt to mirror the data annotation scheme. Although the task is a regression task, we show that we can treat it as an aggregation of several classification and regression models. This somewhat counter-intuitive approach achieved an MAE score of 0.0654 for Sub-Task 1 and MAE of 0.0811 on Sub-Task 2. Additionally, we used the concept of weak supervision signals from Gloss-BERT in our work, and it significantly improved the MAE score in Sub-Task 1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:7PzlFSSx8tAC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In this paper, we present various systems submitted by our team problemConquero for SemEval-2020 Shared Task 12 “Multilingual Offensive Language Identification in Social Media”. We participated in all the three sub-tasks of OffensEval-2020, and our final submissions during the evaluation phase included transformer-based approaches and a soft label-based approach. BERT based fine-tuned models were submitted for each language of sub-task A (offensive tweet identification). RoBERTa based fine-tuned model for sub-task B (automatic categorization of offense types) was submitted. We submitted two models for sub-task C (offense target identification), one using soft labels and the other using BERT based fine-tuned model. Our ranks for sub-task A were Greek-19 out of 37, Turkish-22 out of 46, Danish-26 out of 39, Arabic-39 out of 53, and English-20 out of 85. We achieved a rank of 28 out of 43 for sub-task B. Our best rank for sub-task C was 20 out of 39 using BERT based fine-tuned model.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:3fE2CSJIrl8C,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"The paper introduces a multi-level annotation of the R. GVEDA, a fundamental Sanskrit text composed in the 2. millenium BCE that is important for South-Asian and Indo-European linguistics, as well as Cultural Studies. We describe the individual annotation levels, including phonetics, morphology, lexicon, and syntax, and show how these different levels of annotation are merged to create a novel annotated corpus of Vedic Sanskrit. Vedic Sanskrit is a complex, but computationally under-resourced language. Therefore, creating this resource required considerable domain adaptation of existing computational tools, which is discussed in this paper. Because parts of the annotations are selective, we propose a bi-directional LSTM based sequential model to supplement missing verb-argument links.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:_FxGoFyzp5QC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In populous countries, pending legal cases have been growing exponentially. There is a need for developing NLP-based techniques for processing and automatically understanding legal documents. To promote research in the area of Legal NLP we organized the shared task LegalEval - Understanding Legal Texts at SemEval 2023. LegalEval task has three sub-tasks: Task-A (Rhetorical Roles Labeling) is about automatically structuring legal documents into semantically coherent units, Task-B (Legal Named Entity Recognition) deals with identifying relevant entities in a legal document and Task-C (Court Judgement Prediction with Explanation) explores the possibility of automatically predicting the outcome of a legal case along with providing an explanation for the prediction. In total 26 teams (approx. 100 participants spread across the world) submitted systems paper. In each of the sub-tasks, the proposed systems outperformed the baselines; however, there is a lot of scope for improvement. This paper describes the tasks, and analyzes techniques proposed by various teams.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:YFjsv_pBGBYC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Emotion Recognition in Conversations (ERC) is an important and active research area. Recent work has shown the benefits of using multiple modalities (eg, text, audio, and video) for the ERC task. In a conversation, participants tend to maintain a particular emotional state unless some stimuli evokes a change. There is a continuous ebb and flow of emotions in a conversation. Inspired by this observation, we propose a multimodal ERC model and augment it with an emotion-shift component that improves performance. The proposed emotion-shift component is modular and can be added to any existing multimodal ERC model (with a few modifications). We experiment with different variants of the model, and results show that the inclusion of emotion shift signal helps the model to outperform existing models for ERC on MOSEI and IEMOCAP datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:maZDTaKrznsC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In this paper, we propose a new framework for fine-grained emotion prediction in the text through emotion definition modeling. Our approach involves a multi-task learning framework that models definitions of emotions as an auxiliary task while being trained on the primary task of emotion prediction. We model definitions using masked language modeling and class definition prediction tasks. Our models outperform existing state-of-the-art for fine-grained emotion dataset GoEmotions. We further show that this trained model can be used for transfer learning on other benchmark datasets in emotion prediction with varying emotion label sets, domains, and sizes. The proposed models outperform the baselines on transfer learning experiments demonstrating the generalization capability of the models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:R3hNpaxXUhUC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Climate change is a burning issue of our time, with the Sustainable Development Goal (SDG) 13 of the United Nations demanding global climate action. Realizing the urgency, in 2015 in Paris, world leaders signed an agreement committing to taking voluntary action to reduce carbon emissions. However, the scale, magnitude, and climate action processes vary globally, especially between developed and developing countries. Therefore, from parliament to social media, the debates and discussions on climate change gather data from wide-ranging sources essential to the policy design and implementation. The downside is that we do not currently have the mechanisms to pool the worldwide dispersed knowledge emerging from the structured and unstructured data sources. The paper thematically discusses how NLP techniques could be employed in climate policy research and contribute to society's good at large. In particular, we exemplify symbiosis of NLP and Climate Policy Research via four methodologies. The first one deals with the major topics related to climate policy using automated content analysis. We investigate the opinions (sentiments) of major actors' narratives towards climate policy in the second methodology. The third technique explores the climate actors' beliefs towards pro or anti-climate orientation. Finally, we discuss developing a Climate Knowledge Graph. The present theme paper further argues that creating a knowledge platform would help in the formulation of a holistic climate policy and effective climate action. Such a knowledge platform would integrate the policy actors' varied opinions from different social sectors like …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:mB3voiENLucC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Recently, there has been an interest in factual verification and prediction over structured data like tables and graphs. To circumvent any false news incident, it is necessary to not only model and predict over structured data efficiently but also to explain those predictions. In this paper, as part of the SemEval-2021 Task 9, we tackle the problem of fact verification and evidence finding over tabular data. There are two subtasks. Given a table and a statement/fact, subtask A determines whether the statement is inferred from the tabular data, and subtask B determines which cells in the table provide evidence for the former subtask. We make a comparison of the baselines and state-of-the-art approaches over the given SemTabFact dataset. We also propose a novel approach CellBERT to solve evidence finding as a form of the Natural Language Inference task. We obtain a 3-way F1 score of 0.69 on subtask A and an F1 score of 0.65 on subtask B.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:hC7cP41nSMkC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Research in Natural Language Processing is making rapid advances, resulting in the publication of a large number of research papers. Finding relevant research papers and their contribution to the domain is a challenging problem. In this paper, we address this challenge via the SemEval 2021 Task 11: NLPContributionGraph, by developing a system for a research paper contributions-focused knowledge graph over Natural Language Processing literature. The task is divided into three sub-tasks: extracting contribution sentences that show important contributions in the research article, extracting phrases from the contribution sentences, and predicting the information units in the research article together with triplet formation from the phrases. The proposed system is agnostic to the subject domain and can be applied for building a knowledge graph for any area. We found that transformer-based language models can significantly improve existing techniques and utilized the SciBERT-based model. Our first sub-task uses Bidirectional LSTM (BiLSTM) stacked on top of SciBERT model layers, while the second sub-task uses Conditional Random Field (CRF) on top of SciBERT with BiLSTM. The third sub-task uses a combined SciBERT based neural approach with heuristics for information unit prediction and triplet formation from the phrases. Our system achieved F1 score of 0.38, 0.63 and 0.76 in end-to-end pipeline testing, phrase extraction testing and triplet extraction testing respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:qUcmZB5y_30C,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"This paper describes our system for Task 4 of SemEval-2021: Reading Comprehension of Abstract Meaning (ReCAM). We participated in all subtasks where the main goal was to predict an abstract word missing from a statement. We fine-tuned the pre-trained masked language models namely BERT and ALBERT and used an Ensemble of these as our submitted system on Subtask 1 (ReCAM-Imperceptibility) and Subtask 2 (ReCAM-Nonspecificity). For Subtask 3 (ReCAM-Intersection), we submitted the ALBERT model as it gives the best results. We tried multiple approaches and found that Masked Language Modeling(MLM) based approach works the best.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:dhFuZR0502QC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Human use language not just to convey information but also to express their inner feelings and mental states. In this work, we adapt the state-of-the-art language generation models to generate affective (emotional) text. We posit a model capable of generating affect-driven and topic-focused sentences without losing grammatical correctness as the affect intensity increases. We propose to incorporate emotion as prior for the probabilistic state-of-the-art text generation model such as GPT-2. The model gives a user the flexibility to control the category and intensity of emotion as well as the topic of the generated text. Previous attempts at modelling fine-grained emotions fall out on grammatical correctness at extreme intensities, but our model is resilient to this and delivers robust results at all intensities. We conduct automated evaluations and human studies to test the performance of our model and provide a detailed comparison of the results with other models. In all evaluations, our model outperforms existing affective text generation models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:aqlVkmm33-oC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"This research paper proposes a COVID-19 monitoring and response system to identify the surge in the volume of patients at hospitals and shortage of critical equipment like ventilators in South-east Asian countries, to understand the burden on health facilities. This can help authorities in these regions with resource planning measures to redirect resources to the regions identified by the model. Due to the lack of publicly available data on the influx of patients in hospitals, or the shortage of equipment, ICU units or hospital beds that regions in these countries might be facing, we leverage Twitter data for gleaning this information. The approach has yielded accurate results for states in India, and we are working on validating the model for the remaining countries so that it can serve as a reliable tool for authorities to monitor the burden on hospitals.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:qxL8FJ1GzNcC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In this paper, we describe our system for Task 4 of SemEval 2020, which involves differentiating between natural language statements that confirm to common sense and those that do not. The organizers propose three subtasks - first, selecting between two sentences, the one which is against common sense. Second, identifying the most crucial reason why a statement does not make sense. Third, generating novel reasons for explaining the against common sense statement. Out of the three subtasks, this paper reports the system description of subtask A and subtask B. This paper proposes a model based on transformer neural network architecture for addressing the subtasks. The novelty in work lies in the architecture design, which handles the logical implication of contradicting statements and simultaneous information extraction from both sentences. We use a parallel instance of transformers, which is responsible for a boost in the performance. We achieved an accuracy of 94.8% in subtask A and 89% in subtask B on the test set.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:_kc_bZDykSQC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Recently, fine-tuned transformer-based models (eg, PubMedBERT, BioBERT) have shown the state-of-the-art performance of a number of BioNLP tasks, such as Named Entity Recognition (NER). However, transformer-based models are complex and have millions of parameters, and, consequently, are relatively slow during inference. In this paper, we address the time complexity limitations of the BioNLP transformer models. In particular, we propose a Multi-Task Learning based framework for jointly learning three different biomedical NER tasks. Our experiments show a reduction in inference time by a factor of three without any reduction in prediction accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:NMxIlDl6LWMC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Indian Sign Language, though used by a diverse community, still lacks well-annotated resources for developing systems that would enable sign language processing. In recent years researchers have actively worked for sign languages like American Sign Languages, however, Indian Sign language is still far from data-driven tasks like machine translation. To address this gap, in this paper, we introduce a new dataset CISLR (Corpus for Indian Sign Language Recognition) for word-level recognition in Indian Sign Language using videos. The corpus has a large vocabulary of around 4700 words covering different topics and domains. Further, we propose a baseline model for word recognition from sign language videos. To handle the low resource problem in the Indian Sign Language, the proposed model consists of a prototype-based one-shot learner that leverages resource rich American Sign Language to learn generalized features for improving predictions in Indian Sign Language. Our experiments show that gesture features learned in another sign language can help perform one-shot predictions in CISLR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:hMod-77fHWUC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"Recent progress in deep learning has primarily been fueled by the availability of large amounts of annotated data that is obtained from highly expensive manual annotating pro-cesses. To tackle this issue of availability of annotated data, a lot of research has been done on unsupervised domain adaptation that tries to generate systems for an unlabelled target domain data, given labeled source domain data. However, the availability of annotated or labelled source domain dataset can’t always be guaranteed because of data-privacy issues. This is especially the case with medical data, as it may contain sensitive information of the patients. Source-free domain adaptation (SFDA) aims to resolve this issue by us-ing models trained on the source data instead of using the original annotated source data. In this work, we try to build SFDA systems for semantic processing by specifically focusing on the negation detection subtask of the SemEval2021 Task 10. We propose two approaches-ProtoAUGandAdapt-ProtoAUGthat use the idea of self-entropy to choose reliable and high confidence samples, which are then used for data augmentation and subsequent training of the models. Our methods report an improvement of up to 7% in F1 score over the baseline for the Negation Detection subtask.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:e5wmG9Sq2KIC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In various embodiments, a communication fusion application enables other software application (s) to interpret spoken user input. In operation, a communication fusion application determines that a prediction is relevant to a text input derived from a spoken input received from a user. Subsequently, the communication fusion application generates a predicted context based on the prediction. The communication fusion application then transmits the predicted context and the text input to the other software application (s). The other software application (s) perform additional action (s) based on the text input and the predicted context. Advantageously, by providing additional, relevant information to the software application (s), the communication fusion application increases the level of understanding during interactions with the user and the overall user experience is improved.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:hFOr9nPyWt4C,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"This paper describes our contribution to SemEval 2021 Task 1: Lexical Complexity Prediction. In our approach, we leverage the ELECTRA model and attempt to mirror the data annotation scheme. Although the task is a regression task, we show that we can treat it as an aggregation of several classification and regression models. This somewhat counter-intuitive approach achieved an MAE score of 0.0654 for Sub-Task 1 and MAE of 0.0811 on Sub-Task 2. Additionally, we used the concept of weak supervision signals from Gloss-BERT in our work, and it significantly improved the MAE score in Sub-Task 1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:QIV2ME_5wuYC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"According to one implementation, an affect-driven dialog generation system includes a computing platform having a hardware processor and a system memory storing a software code including a sequence-to-sequence (seq2seq) architecture trained using a loss function having an affective regularizer term based on a difference in emotional content between a target dialog response and a dialog sequence determined by the seq2seq architecture during training. The hardware processor executes the software code to receive an input dialog sequence, and to use the seq2seq architecture to generate emotionally diverse dialog responses based on the input dialog sequence and a predetermined target emotion. The hardware processor further executes the software code to determine, using the seq2seq architecture, a final dialog sequence responsive to the input dialog sequence based on an emotional relevance of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:8k81kl-MbHgC,https://ashutosh-modi.github.io/
Ashutosh Modi,"['Natural Language Processing', 'Machine and Deep Learning', 'Artificial Intelligence', 'Affective Computing', 'Legal AI']",17,"In this paper, we describe our system for Task 4 of SemEval 2020, which involves differentiating between natural language statements that confirm to common sense and those that do not. The organizers propose three subtasks-first, selecting between two sentences, the one which is against common sense. Second, identifying the most crucial reason why a statement does not make sense. Third, generating novel reasons for explaining the against common sense statement. Out of the three subtasks, this paper reports the system description of subtask A and subtask B. This paper proposes a model based on transformer neural network architecture for addressing the subtasks. The novelty in work lies in the architecture design, which handles the logical implication of contradicting statements and simultaneous information extraction from both sentences. We use a parallel instance of transformers, which is responsible …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AWu6f60AAAAJ&cstart=20&pagesize=80&citation_for_view=AWu6f60AAAAJ:M3ejUd6NZC8C,https://ashutosh-modi.github.io/
Surender Baswana,['Design and analysis of algorithms'],19,"We present an algorithm for maintaining a maximal matching in a graph under addition and deletion of edges. Our algorithm is randomized and it takes expected amortized time for each edge update, where is the number of vertices in the graph. Moreover, for any sequence of edge updates, the total time taken by the algorithm is with high probability. (Original article at https://doi.org/10.1137/130914140.)",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&citation_for_view=U42j5MkAAAAJ:lSLTfruPkqcC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"The centrally funded technical institutes (CFTIs) for undergraduate studies in India consist of the prestigious Indian Institutes of Technology (IITs) as well as several non-IITs (the National Institutes of Technology, the Indian Institutes of Information Technology, and others). The IITs use the candidate rankings obtained from performance on the JEE Advanced exam for their admissions, whereas the non-IITs use a different set of rankings (obtained from the JEE Main exam) for their admissions. Until 2014, the IITs and the non-IITs used two separate processes to allocate seats to candidates. Every year, several individual candidates would get two seats, one from each of these processes. As a result, at least one of those two seats would go vacant. This would especially be a problem for the IITs as their allocation process would complete before that of the non-IITs. In 2015, we designed and implemented a new joint …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&citation_for_view=U42j5MkAAAAJ:vV6vV6tmYwMC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"Depth first search (DFS) tree is a fundamental data structure for solving various problems in graphs. It is well known that it takes time to build a DFS tree for a given undirected graph on vertices and edges. We address the problem of maintaining a DFS tree when the graph is undergoing updates (insertion and deletion of vertices or edges). We present the following results for this problem: (1) Fault tolerant DFS tree: There exists a data structure of size (where hides the polylogarithmic factors) which can be preprocessed in time such that given any set of failed vertices or edges, a DFS tree of the graph can be reported in time. (2) Fully dynamic DFS tree: There exists a fully dynamic algorithm for maintaining a DFS tree that takes time for preprocessing and worst case time per update for any arbitrary online sequence of updates. (3) Incremental DFS tree: There exists an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&citation_for_view=U42j5MkAAAAJ:GnPB-g6toBAC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"In this paper we study the problem of maintaining the strongly connected components of a graph in the presence of failures. In particular, we show that given a directed graph with and , and an integer value , there is an algorithm that computes in time for any set F of size at most k the strongly connected components of the graph . The running time of our algorithm is almost optimal since the time for outputting the SCCs of is at least . The algorithm uses a data structure that is computed in a preprocessing phase in polynomial time and is of size . Our result is obtained using a new observation on the relation between strongly connected components (SCCs) and reachability. More specifically, one of the main building blocks in our result is a restricted variant of the problem in which we only compute strongly connected components that intersect a certain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:ns9cj8rnVeAC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"Let G=(V,E) be an n-vertices m-edges directed graph with edge weights in the range [1,W] for some parameter W, and sϵ V be a designated source. In this article, we address several variants of the problem of maintaining the (1+ε)-approximate shortest path from s to each vϵ V{s} in the presence of a failure of an edge or a vertex.
From the graph theory perspective, we show that G has a subgraph H with Õ(ε -1} nlog W) edges such that for any x,vϵ V, the graph H \ x contains a path whose length is a (1+ε)-approximation of the length of the shortest path from s to v in G \ x. We show that the size of the subgraph H is optimal (up to logarithmic factors) by proving a lower bound of Ω (ε -1 n log W) edges. Demetrescu, Thorup, Chowdhury, and Ramachandran (SICOMP 2008) showed that the size of a fault tolerant exact shortest path subgraph in weighted directed/undirected graphs is Ω (m). Parter and Peleg (ESA 2013 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:RYcK_YlVTxYC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"Let G be an undirected graph. We address the problem of fault tolerant depth first search (DFS) tree defined as follows. Build a compact data structure that, given any set of failed vertices or edges, can efficiently report a DFS tree of . We present an algorithm which is drastically simpler and yet more efficient than the current state-of-the-art algorithms for this problem. Additionally, for achieving efficiency, the current-state-of-the-algorithms have to crucially rely on sophisticated data structures. The simplicity of our algorithm also enables us to replace these sophisticated data structures with much simpler and lighter data structures that occupy optimal space and take optimal preprocessing time. Our algorithm for the fault tolerant DFS tree also leads to a better time complexity for maintaining a DFS tree in a fully dynamic environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:3s1wT3WcHBgC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"The depth first search (DFS) tree is a fundamental data structure used for solving various graph problems. For a given graph G = (V, E) on n vertices and m edges, a DFS tree can be built in O(m + n) time. In the last 20 years, a few algorithms have been designed for maintaining a DFS tree efficiently under insertion of edges. For undirected graphs, there are two prominent algorithms, namely, ADFS1 and ADFS2 [ICALP14] that achieve total update time of and O(n2) respectively. For directed acyclic graphs, the only non-trivial algorithm, namely, FDFS [IPL97] requires total O(mn) update time. However, even after 20 years of this result, there does not exist any non-trivial incremental algorithm for maintaining a DFS tree in directed graphs with o(m2) worst case bound.
In this paper, we carry out extensive experimental and theoretical evaluation of the existing incremental DFS algorithms in random graphs and real world …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:NaGl4SEjCO4C,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"Let be an undirected graph on n vertices with non-negative capacities on its edges. The mincut sensitivity problem for the insertion of an edge is defined as follows. Build a compact data structure for G and a given set of vertices that, on receiving any edge of positive capacity as query input, can efficiently report the set of all pairs from whose mincut value increases upon insertion of the edge (x, y) to G. The only result that exists for this problem is for a single pair of vertices (Picard and Queyranne, in: Rayward-Smith (ed) Combinatorial optimization II. Mathematical programming Studies, vol 13, no 1. Springer, Berlin, pp 8–16, 1980. https://doi.org/10.1007/BFb0120902, and dates back to 1980. We present the following results for the single source and the all-pairs versions of this problem.
Single source  Given any designated source vertex s, there exists a data structure of size (Data structure sizes are in words …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:M05iB0D1s5AC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"Until 2014, admissions to the Indian Institutes of Technology (IITs) were conducted under one umbrella, whereas the admissions to the non-IIT Centrally Funded Government Institutes (CFTIs) were conducted under a different umbrella, the Central Seat Allocation Board. In 2015, a new Multi-Round Multi-Run Deferred Acceptance joint seat allocation process was implemented, improving the efficiency and productivity of concerned stakeholders. The process brings all CFTIs under one umbrella for admissions: 100 institutes and approximately 39000 seats in 2018. In this scheme, each candidate submits a single choice list over all available programs, and receives no more than a single seat from the system, based on the choices and the ranks in the relevant merit lists. Significantly, overbooking of seats is forbidden. In this report, we provide details of our safe, fair and optimal algorithm. Novel features include the ability to handle multiple merit lists, seat guarantee across multiple rounds, implementing reservation, and de-reservation rules, handling escalation of ranks due to a revision of marks by state boards during the allocation process, and dealing with last minute de-recognition of other backward caste categories. A notable rule required the allocation of supernumerary seats to females, provided the program did not have a sufficient desired percentage, while, at the same time, not reducing the number of seats available to non-females. Looking forward, we posit first that it is inevitable that different colleges will prefer different mechanisms of judging merit, and assigning relative rank. We believe the ability of our algorithm to gracefully handle …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:2P1L_qKh6hAC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"Let G = (V, E) be an undirected unweighted graph on n vertices and m edges. We address the problem of sensitivity oracle for all-pairs mincuts in G defined as follows.
Build a compact data structure that, on receiving any pair of vertices s,t ∊ V and failure (or insertion) of any edge as query, can efficiently report the mincut between s and t after the failure (or the insertion).
To the best of our knowledge, there exists no data structure for this problem which takes o(mn) space and a non-trivial query time. We present the following results.
Our first data structure occupies space and guarantees query time to report the value of resulting (s, t)-mincut upon failure (or insertion) of any edge. Moreover, the set of vertices defining a resulting (s, t)-mincut after the update can be reported in time which is worst-case optimal.
Our second data structure optimizes space at the expense of increased query time. It takes space–which is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:ZHo1McVdvXMC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"Let G=(V, E) be an undirected unweighted graph on n vertices and m edges. We address the problem of fault-tolerant data structure for all-pairs mincuts in G defined as follows. Build a compact data structure that, on receiving a pair of vertices s, t∈ V and any edge (x, y) as query, can efficiently report the value of the mincut between s and t upon failure of the edge (x, y).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:g5m5HwL7SMYC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"Let G = (V, E) be an undirected weighted graph on n = |V| vertices and m = |E| edges. Length of a path between two vertices is the sum of the weights of all the edges of the path. The shortest path between a pair of vertices is the path of least length among all possible paths between the two vertices in the graph. The length of the shortest path between two vertices is also called the distance between the two vertices. An α-approximate shortest path between two vertices is a path of length at-most α times the length of the shortest path.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:HoB7MX3m0LUC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],19,"Let G be a directed multi-graph on n vertices and m edges with a designated source vertex s and a designated sink vertex t. We study the (s, t)-cuts of capacity minimum+ 1 and as an important application of them, we give a solution to the dual edge sensitivity for (s, t)-mincuts-reporting the (s, t)-mincut upon failure or addition of any pair of edges.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&cstart=20&pagesize=80&citation_for_view=U42j5MkAAAAJ:rO6llkc54NcC,http://www.cse.iitk.ac.in/~sbaswana
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"We show that for the blackbox polynomial identity testing (PIT) problem it suffices to study circuits that depend only on the first extremely few variables. One only need to consider size-s degree-s circuits that depend on the first log∘ c s variables (where c is a constant and we are composing c logarithms). Thus, hitting-set generator (hsg) manifests a bootstrapping behavior— a partial hsg against very few variables can be efficiently grown to a complete hsg. A boolean analog, or a pseudorandom generator property of this type, is unheard-of. Our idea is to use the partial hsg and its annihilator polynomial to efficiently bootstrap the hsg exponentially wrt variables. This is repeated c times in an efficient way.
Pushing the envelope further we show that: (1) a quadratic-time blackbox PIT for 6913-variate degree-s size-s polynomials, will lead to a “near”-complete derandomization of PIT, and (2) a blackbox PIT for n-variate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&citation_for_view=1Yl1h_YAAAAJ:5Ul4iDaHHb8C,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"Derandomization of blackbox identity testing reduces to extremely special circuit models. After a line of work, it is known that focusing on circuits with constant-depth and constantly many variables is enough (Agrawal, Ghosh, Saxena, STOC'18) to get to general hitting-sets and circuit lower bounds. This inspires us to study circuits with few variables, eg. logarithmic in the size s. We give the first poly (s)-time blackbox identity test for n= O (log s) variate size-s circuits that have poly (s)-dimensional partial derivative space; eg. depth-3 diagonal circuits (or Sigma wedge Sigma^ n). The former model is well-studied (Nisan, Wigderson, FOCS'95) but no poly (s2^ n)-time identity test was known before us. We introduce the concept of cone-closed basis isolation and prove its usefulness in studying log-variate circuits. It subsumes the previous notions of rank-concentration studied extensively in the context of ROABP models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:kRWSkSYxWN8C,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"Newton iteration (NI) is an almost 350 years old recursive formula that approximates a simple root of a polynomial quite rapidly. We generalize it to a matrix recurrence (allRootsNI) that approximates all the roots simultaneously. In this form, the process yields a better circuit complexity in the case when the number of roots r is small but the multiplicities are exponentially large. Our method sets up a linear system in r unknowns and iteratively builds the roots as formal power series. For an algebraic circuit f(x1,…,xn) of size s we prove that each factor has size at most a polynomial in: s and the degree of the squarefree part of f. Consequently, if f1 is a 2Ω(n)-hard polynomial then any nonzero multiple ∏i fiei is equally hard for arbitrary positive ei’s, assuming that ∑ideg(fi) is at most 2O(n).
It is an old open question whether the class of poly(n)-sized formulas (resp. algebraic branching programs) is closed under factoring …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:8AbLer7MMksC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"Polynomial factoring has famous practical algorithms over fields-- finite, rational and p-adic. However, modulo prime powers, factoring gets harder because there is non-unique factorization and a combinatorial blowup ensues. For example, x^2+p \bmod p^2 is irreducible, but x^2+px \bmod p^2 has exponentially many factors! We present the first randomized poly(\deg f, łog p) time algorithm to factor a given univariate integral f(x) modulo p^k, for a prime p and k łeq 4. Thus, we solve the open question of factoring modulo p^3 posed in (Sircana, ISSAC'17). Our method reduces the general problem of factoring f(x) mod p^k to that of \em root finding in a related polynomial E(y) \bmodłangle p^k, \varphi(x)^\ell \rangle for some irreducible \varphi \bmod p. We can efficiently solve the latter for kłe4, by incrementally transforming E(y). Moreover, we discover an efficient refinement of Hensel lifting to lift factors of f(x) \bmod p to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:Mojj43d5GZwC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"The motivation for this work (Pandey et al. 2016) comes from two problems: testing algebraic independence of arithmetic circuits over a field of small characteristic and generalizing the structural property of algebraic dependence used by Kumar, Saraf, CCC’16 to arbitrary fields. It is known that in the case of zero, or large characteristic, using a classical criterion based on the Jacobian, we get a randomized poly-time algorithm to test algebraic independence. Over small characteristic, the Jacobian criterion fails and there is no subexponential time algorithm known. This problem could well be conjectured to be in RP, but the current best algorithm puts it in NP (Mittmann, Saxena, Scheiblechner, Trans.AMS’14). Currently, even the case of two bivariate circuits over is open. We come up with a natural generalization of Jacobian criterion that works over all characteristics. The new criterion is efficient if the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:NhqRSupF_l8C,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"We consider the problem of recovering (that is, interpolating) and identity testing of a “hidden” monic polynomial f, given an oracle access to for , where is finite field of q elements (extension fields access is not permitted). The naive interpolation algorithm needs queries and thus requires . We design algorithms that are asymptotically better in certain cases; requiring only queries to the oracle. In the randomized (and quantum) setting, we give a substantially better interpolation algorithm, that requires only queries. Such results have been known before only for the special case of a linear f, called the hidden shifted power problem. We use techniques from algebra, such as effective versions of Hilbert’s Nullstellensatz, and analytic number theory, such as results on the distribution of rational functions in subgroups and character sum estimates.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:isC4tDSrTZIC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"Finding an irreducible factor, of a polynomial modulo a prime , is not known to be in deterministic polynomial time. Though there is such a classical algorithm that {\em counts} the number of irreducible factors of . We can ask the same question modulo prime-powers . The irreducible factors of blow up exponentially in number; making it hard to describe them. Can we count those irreducible factors that remain irreducible mod ? These are called {\em basic-irreducible}. A simple example is in ; it has many basic-irreducible factors. Also note that, is irreducible but not basic-irreducible! We give an algorithm to count the number of basic-irreducible factors of in deterministic poly(deg)-time. This solves the open questions posed in (Cheng et al, ANTS'18 \& Kopp et al, Math.Comp.'19). In particular, we are counting roots ; which gives the first deterministic poly-time algorithm to compute Igusa zeta function of . Also, our algorithm efficiently partitions the set of all basic-irreducible factors (possibly exponential) into merely deg-many disjoint sets, using a compact tree data structure and {\em split} ideals.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:_B80troHkn4C,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"Testing whether a set of polynomials has an algebraic dependence is a basic problem with several applications. The polynomials are given as algebraic circuits. Algebraic independence testing question is wide open over finite fields (Dvir, Gabizon, Wigderson, FOCS'07). The best complexity known is NP (Mittmann, Saxena, Scheiblechner, Trans.AMS'14). In this work we put the problem in AM coAM. In particular, dependence testing is unlikely to be NP-hard and joins the league of problems of ""intermediate"" complexity, eg. graph isomorphism & integer factoring. Our proof method is algebro-geometric-- estimating the size of the image/preimage of the polynomial map over the finite field. A gap in this size is utilized in the AM protocols. Next, we study the open question of testing whether every annihilator of has zero constant term (Kayal, CCC'09). We give a geometric characterization using Zariski closure of the image of ; introducing a new problem called approximate polynomials satisfiability (APS). We show that APS is NP-hard and, using projective algebraic-geometry ideas, we put APS in PSPACE (prior best was EXPSPACE via Grobner basis computation). As an unexpected application of this to approximative complexity theory we get-- Over any field, hitting-set for can be designed in PSPACE. This solves an open problem posed in (Mulmuley, FOCS'12, J.AMS 2017); greatly mitigating the GCT Chasm (exponentially in terms of space complexity).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:BrmTIyaxlBUC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"Testing whether a set f of polynomials has an algebraic dependence is a basic problem with several applications. The polynomials are given as algebraic circuits. The complexity of algebraic independence testing is wide open over finite fields (Dvir, Gabizon, Wigderson, FOCS’07). Previously, the best complexity bound known was NP# P (Mittmann, Saxena, Scheiblechner, Trans. AMS 2014). In this article we put the problem in AM∩ coAM. In particular, dependence testing is unlikely to be NP-hard. Our proof uses methods of algebraic geometry. We estimate the size of the image and the sizes of the preimages of the polynomial map f over the finite field. A gap between the corresponding sizes for independent and for dependent sets of polynomials is utilized in the AM protocols.
A conference version of this paper appeared in the Proceedings of the 33rd Computational Complexity Conference (CCC’18)[24] and as a poster in STOC 2018: TheoryFest.∗ Supported by DST and Research I Foundation of CSE, IITK.† Supported by DST/SJF/MSA-01/2013-14.‡ Supported by DFG grant TH 472/5-1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:dTyEYWd-f8wC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"Proof. This is trivially true when n= 2: r= 3 satisfies all conditions. So assume that n> 2. Then⌈ log5 n⌉> 10 and Lemma 3.1 applies. Observe that the largest value of k for any number of the form mk≤ B=⌈ log5 n⌉, m≥ 2, is⌊ log B⌋. Now consider the smallest number s that does not divide the product n⌊ log B⌋·
⌊ log2 n⌋",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:AXPGKjj_ei8C,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",24,"Isomorphism problems about structures frequently appear in computer science. Some example structures are NP-hard problems, graphs, fields, algebras, and polynomials. Indian theorists have been studying these closely, and have proved some of the best results known. Communication complexity studies the interaction required to solve a problem when the input is distributed across multiple parties. Indian researchers, notably at Tata Institute of Fundamental Research, Mumbai (TIFR), have made leading contributions to this area.
Logic and automata theory. The close interplay between automata theory and logic was first identified by Buchi. Pnueli introduced temporal logic as a language for specifying properties of reactive systems. Emerson, Clarke, and Sifakis invented model checking: determining algorithmically whether a formal model satisfies a temporal logic specification.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&cstart=20&pagesize=80&citation_for_view=1Yl1h_YAAAAJ:PR6Y55bgFSsC,http://www.cse.iitk.ac.in/users/nitin
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",17,"Nearest neighbor searching of large databases in high-dimensional spaces is inherently difficult due to the curse of dimensionality. A flavor of approximation is, therefore, necessary to practically solve the problem of nearest neighbor search. In this paper, we propose a novel yet simple indexing scheme, HD-Index, to solve the problem of approximate k-nearest neighbor queries in massive high-dimensional databases. HD-Index consists of a set of novel hierarchical structures called RDB-trees built on Hilbert keys of database objects. The leaves of the RDB-trees store distances of database objects to reference objects, thereby allowing efficient pruning using distance filters. In addition to triangular inequality, we also use Ptolemaic inequality to produce better lower bounds. Experiments on massive (up to billion scale) high-dimensional (up to 1000+) datasets show that HD-Index is effective, efficient, and scalable.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&citation_for_view=Sk-JV9QAAAAJ:mVmsd5A6BfQC,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",17,"Money laundering refers to activities pertaining to hiding the true income, evading taxes, or converting illegally earned money for normal use. These activities are often performed through shell companies that masquerade as real companies but where actual the purpose is to launder money. Shell companies are used in all the three phases of money laundering, namely, placement, layering, and integration, often simultaneously. In this paper, we aim to identify shell companies. We propose to use only bank transactions since that is easily available. In particular, we look at all incoming and outgoing transactions from a particular bank account along with its various attributes, and use anomaly detection techniques to identify the accounts that pertain to shell companies. Our aim is to create an initial list of potential shell company candidates which can be investigated by financial experts later. Due to lack of real data, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&citation_for_view=Sk-JV9QAAAAJ:r0BpntZqJG4C,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",17,"Optimal location queries identify the best locations to set up new facilities for providing service to its users. For several businesses such as fuel stations, cellphone base-stations, etc., placement queries require taking into account the mobility patterns (or trajectories) of the users. In this work, we formulate the TOPS (Trajectory-Aware Optimal Placement of Services) query that locates the best k sites on a road network for the prevailing user trajectories. The problem is NP-hard. The greedy approach, which is the state-of-the-art technique for this problem, is not scalable and practical for real urban-scale scenarios, primarily due to its high memory footprint beyond the capabilities of commodity machines. To overcome these challenges, we develop an indexing framework called NETCLUS that derives its power through an unique combination of FM sketches with network clustering. Empirical studies show that NETCLUS …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&citation_for_view=Sk-JV9QAAAAJ:isC4tDSrTZIC,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",17,"A combinatorial algorithm to find a largest rectangle (LR) inside the inner isothetic cover which tightly inscribes a given digital object without holes is presented here which runs in O (k. n/g+(n/g) log⁡(n/g)) time, where n, g, and k being the number of pixels on the contour of the digital object, grid size, and the number of convex regions, respectively. Certain combinatorial rules are formulated to obtain an LR. An LR divides the object in several parts. The object can be rectangularized by recursive generation of a set of LRs and it generates LR-Graph which is useful for shape analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&cstart=20&pagesize=80&citation_for_view=Sk-JV9QAAAAJ:bEWYMUwI8FkC,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",17,"Crowdsourcing, where the power of the human thinking is harnessed to answer queries that are otherwise difficult for computers to answer, has been successfully used in many applications. A particularly interesting application of crowdsourcing is crowd mining, where given a dataset, patterns are learned by asking questions to the crowd. Crowd mining is extremely useful in situations where either the information is complex or it is not available in a systematic manner. In this paper, we target one such scenario, that of common health practices and cures. A web-based framework, called MineAr, is built to ask simple questions to the crowd. The questions ask whether a common product helps in a disease (such as ginger for cold). The crowd worker can choose an answer from different grades varying from ""always"" to ""never"", or can skip if she is not sure. Association rules are then mined from these answers using …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&cstart=20&pagesize=80&citation_for_view=Sk-JV9QAAAAJ:iH-uZ7U-co4C,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",17,"The phenomenal growth of graph data from a wide variety of real-world applications has rendered graph querying to be a problem of paramount importance. Traditional techniques use structural as well as node similarities to find matches of a given query graph in a (large) target graph. However, almost all existing techniques have tacitly ignored the presence of relationships in graphs, which are usually encoded through interactions between node and edge labels. In this paper, we propose RAQ-Relationship-Aware Graph Querying-to mitigate this gap. Given a query graph, RAQ identifies the k best matching subgraphs of the target graph that encode similar relationships as in the query graph. To assess the utility of RAQ as a graph querying paradigm for knowledge discovery and exploration tasks, we perform a user survey on the Internet Movie Database (IMDb), where an overwhelming 86% of the 170 surveyed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&cstart=20&pagesize=80&citation_for_view=Sk-JV9QAAAAJ:Wp0gIr-vW9MC,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",17,"Searching is one of the fundamental tasks in Computer Science. An intuitive way to search is to do it linearly, that is, start at the beginning of the dataset and continue till the searched-for item is found or nothing is found. However, as the volume of data increases, the response time of linear search is no longer acceptable. Indexes are designed to search through massive datasets quickly. There are a number of different ways of building complex and advanced indexes. Appropriate selection and modification of indexing structures according to dynamic business requirements is crucial for data-intensive applications. In this work, we present a few basic reusable indexing structures. These structures can be used to create advanced and complex indexing structures with lesser effort and time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&cstart=20&pagesize=80&citation_for_view=Sk-JV9QAAAAJ:TFP_iSt0sucC,http://www.cse.iitk.ac.in/users/arnabb/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Compile-time errors pose a major learning hurdle for students of introductory programming courses. Compiler error messages, while accurate, are targeted at seasoned programmers, and seem cryptic to beginners. In this work, we address this problem of pedagogically-inspired program repair and report TRACER (Targeted RepAir of Compilation ERrors), a system for performing repairs on compilation errors, aimed at introductory programmers.
TRACER invokes a novel combination of tools from programming language theory and deep learning and offers repairs that not only enable successful compilation, but repairs that are very close to those actually performed by students on similar errors. The ability to offer such targeted corrections, rather than just code that compiles, makes TRACER more relevant in offering real-time feedback to students in lab or tutorial sessions, as compared to existing works that merely …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&citation_for_view=MNXz0AoAAAAJ:IjCSPb-OGe4C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Extreme multi-label classification (XML) involves tagging a data point with its most relevant subset of labels from an extremely large label set, with several applications such as product-to-product recommendation with millions of products. Although leading XML algorithms scale to millions of labels, they largely ignore label metadata such as textual descriptions of the labels. On the other hand, classical techniques that can utilize label metadata via representation learning using deep networks struggle in extreme settings. This paper develops the DECAF algorithm that addresses these challenges by learning models enriched by label metadata that jointly learn model parameters and feature representations using deep networks and offer accurate classification at the scale of millions of labels. DECAF makes specific contributions to model architecture design, initialization, and training, enabling it to offer up to 2-6 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&citation_for_view=MNXz0AoAAAAJ:mB3voiENLucC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"We present algorithms for solving multi-armed and linear-contextual bandit tasks in the face of adversarial corruptions in the arm responses. Traditional algorithms for solving these problems assume that nothing but mild, e.g., i.i.d. sub-Gaussian, noise disrupts an otherwise clean estimate of the utility of the arm. This assumption and the resulting approaches can fail catastrophically if there is an observant adversary that corrupts even a small fraction of the responses generated when arms are pulled. To rectify this, we propose algorithms that use recent advances in robust statistical estimation to perform arm selection in polynomial time. Our algorithms are easy to implement and vastly outperform several existing UCB and EXP-style algorithms for stochastic and adversarial multi-armed and linear-contextual bandit problems in wide variety of experimental settings. Our algorithms enjoy minimax-optimal regret …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&citation_for_view=MNXz0AoAAAAJ:UebtZRa9Y70C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"We present a class of algorithms capable of directly training deep neural networks with respect to popular families of task-specific performance measures for binary classification such as the F-measure, QMean and the Kullback–Leibler divergence that are structured and non-decomposable. Our goal is to address tasks such as label-imbalanced learning and quantification. Our techniques present a departure from standard deep learning techniques that typically use squared or cross-entropy loss functions (that are decomposable) to train neural networks. We demonstrate that directly training with task-specific loss functions yields faster and more stable convergence across problems and datasets. Our proposed algorithms and implementations offer several advantages including (i) the use of fewer training samples to achieve a desired level of convergence, (ii) a substantial reduction in training time, (iii) a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&citation_for_view=MNXz0AoAAAAJ:KlAtU1dfN6UC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Deep extreme classification (XC) seeks to train deep architectures that can tag a data point with its most relevant subset of labels from an extremely large label set. The core utility of XC comes from predicting labels that are rarely seen during training. Such rare labels hold the key to personalized recommendations that can delight and surprise a user. However, the large number of rare labels and small amount of training data per rare label offer significant statistical and computational challenges. State-of-the-art deep XC methods attempt to remedy this by incorporating textual descriptions of labels but do not adequately address the problem. This paper presents ECLARE, a scalable deep learning architecture that incorporates not only label text, but also label correlations, to offer accurate real-time predictions within a few milliseconds. Core contributions of ECLARE include a frugal architecture and scalable …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&citation_for_view=MNXz0AoAAAAJ:r0BpntZqJG4C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Deep extreme multi-label learning (XML) requires training deep architectures that can tag a data point with its most relevant subset of labels from an extremely large label set. XML applications such as ad and product recommendation involve labels rarely seen during training but which nevertheless hold the key to recommendations that delight users. Effective utilization of label metadata and high quality predictions for rare labels at the scale of millions of labels are thus key challenges in contemporary XML research. To address these, this paper develops the SiameseXML framework based on a novel probabilistic model that naturally motivates a modular approach melding Siamese architectures with high-capacity extreme classifiers, and a training pipeline that effortlessly scales to tasks with 100 million labels. SiameseXML offers predictions 2–13% more accurate than leading XML methods on public benchmark datasets, as well as in live A/B tests on the Bing search engine, it offers significant gains in click-through-rates, coverage, revenue and other online metrics over state-of-the-art techniques currently in production. Code for SiameseXML is available at https://github. com/Extreme-classification/siamesexml",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:iH-uZ7U-co4C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Low-cost sensors offer an attractive solution to the challenge of establishing affordable and dense spatio-temporal air quality monitoring networks with greater mobility and lower maintenance costs. These low-cost sensors offer reasonably consistent measurements but require in-field calibration to improve agreement with regulatory instruments. In this paper, we report the results of a deployment and calibration study on a network of six air quality monitoring devices built using the Alphasense O3 (OX-B431) and NO2 (NO2-B43F) electrochemical gas sensors. The sensors were deployed in two phases over a period of 3 months at sites situated within two megacities with diverse geographical, meteorological and air quality parameters. A unique feature of our deployment is a swap-out experiment wherein three of these sensors were relocated to different sites in the two phases. This gives us a unique opportunity to study the effect of seasonal, as well as geographical, variations on calibration performance. We report an extensive study of more than a dozen parametric and non-parametric calibration algorithms. We propose a novel local non-parametric calibration algorithm based on metric learning that offers, across deployment sites and phases, an R2 coefficient of up to 0.923 with respect to reference values for O3 calibration and up to 0.819 for NO2 calibration. This represents a 4–20 percentage point increase in terms of R2 values offered by classical non-parametric methods. We also offer a critical analysis of the effect of various data preparation and model design choices on calibration performance. The key recommendations emerging out of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:UeHWp8X0CEIC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"We provide the first global model recovery results for the IRLS (iteratively reweighted least squares) heuristic for robust regression problems. IRLS is known to offer excellent performance, despite bad initializations and data corruption, for several parameter estimation problems. Existing analyses of IRLS frequently require careful initialization, thus offering only local convergence guarantees. We remedy this by proposing augmentations to the basic IRLS routine that not only offer guaranteed global recovery, but in practice also outperform state-of-the-art algorithms for robust regression. Our routines are more immune to hyperparameter misspecification in basic regression tasks, as well as applied tasks such as linear-armed bandit problems. Our theoretical analyses rely on a novel extension of the notions of strong convexity and smoothness to weighted strong convexity and smoothness, and establishing that sub-Gaussian designs offer bounded weighted condition numbers. These notions may be useful in analyzing other algorithms as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:u5HHmVD_uO8C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Mass public quarantining, colloquially known as a lock-down, is a non-pharmaceutical intervention to check spread of disease. This paper presents ESOP (Epidemiologically and Socio-economically Optimal Policies), a novel application of active machine learning techniques using Bayesian optimization, that interacts with an epidemiological model to arrive at lock-down schedules that optimally balance public health benefits and socio-economic downsides of reduced economic activity during lock-down periods. The utility of ESOP is demonstrated using case studies with VIPER (Virus-Individual-Policy-EnviRonment), a stochastic agent-based simulator that this paper also proposes. However, ESOP is flexible enough to interact with arbitrary epidemiological simulators in a black-box manner, and produce schedules that involve multiple phases of lock-downs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:ULOm3_A8WrAC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Extreme classification seeks to assign each data point, the most relevant labels from a universe of a million or more labels. This task is faced with the dual challenge of high precision and scalability, with millisecond level prediction times being a benchmark. We propose DEFRAG, an adaptive feature agglomeration technique to accelerate extreme classification algorithms. Despite past works on feature clustering and selection, DEFRAG distinguishes itself in being able to scale to millions of features, and is especially beneficial when feature sets are sparse, which is typical of recommendation and multi-label datasets. The method comes with provable performance guarantees and performs efficient task-driven agglomeration to reduce feature dimensionalities by an order of magnitude or more. Experiments show that DEFRAG can not only reduce training and prediction times of several leading extreme classification algorithms by as much as 40%, but also be used for feature reconstruction to address the problem of missing features, as well as offer superior coverage on rare labels.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:Se3iqnhoufwC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Automated compilation error repair, the problem of suggesting fixes to buggy programs that fail to compile, has pedagogical applications for novice programmers who find compiler error messages cryptic and unhelpful. Existing works frequently involve black-box application of generative models, e.g. sequence-to-sequence prediction (TRACER) or reinforcement learning (RLAssist). Although convenient, this approach is inefficient at targeting specific error types as well as increases training costs. We present MACER, a novel technique for accelerated error repair based on a modular segregation of the repair process into repair identification and repair application. MACER uses powerful yet inexpensive learning techniques such as multi-label classifiers and rankers to first identify the type of repair required and then apply the suggested repair. Experiments indicate that this fine-grained approach offers not only superior error …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:hqOjcs7Dif8C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"This paper develops the MUFIN technique for extreme classification (XC) tasks with millions of labels where datapoints and labels are endowed with visual and textual descriptors. Applications of MUFIN to product-to-product recommendation and bid query prediction over several millions of products are presented. Contemporary multi-modal methods frequently rely on purely embedding-based methods. On the other hand, XC methods utilize classifier architectures to offer superior accuracies than embedding-only methods but mostly focus on text-based categorization tasks. MUFIN bridges this gap by reformulating multi-modal categorization as an XC problem with several millions of labels. This presents the twin challenges of developing multi-modal architectures that can offer embeddings sufficiently expressive to allow accurate categorization over millions of labels; and training and inference routines that scale logarithmically in the number of labels. MUFIN develops an architecture based on cross-modal attention and trains it in a modular fashion using pre-training and positive and negative mining. A novel product-to-product recommendation dataset MM-AmazonTitles-300K containing over 300K products was curated from publicly available amazon. com listings with each product endowed with a title and multiple images. On the MM-AmazonTitles-300K and Polyvore datasets, and a dataset with over 4 million labels curated from click logs of the Bing search engine, MUFIN offered at least 3% higher accuracy than leading text-based, image-based and multi-modal techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:maZDTaKrznsC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,Training multi-layer Graph Convolution Networks (GCN) using standard SGD techniques scales poorly as each descent step ends up updating node embeddings for a large portion of the graph. Recent attempts to remedy this sub-sample the graph that reduces compute but introduce additional variance and may offer suboptimal performance. This paper develops the IGLU method that caches intermediate computations at various GCN layers thus enabling lazy updates that significantly reduce the compute cost of descent. IGLU introduces bounded bias into the gradients but nevertheless converges to a first-order saddle point under standard assumptions such as objective smoothness. Benchmark experiments show that IGLU offers up to 1.2% better accuracy despite requiring up to 88% less compute.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:isC4tDSrTZIC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Extreme Classification (XC) seeks to tag data points with the most relevant subset of labels from an extremely large label set. Performing deep XC with dense, learnt representations for data points and labels has attracted much attention due to its superiority over earlier XC methods that used sparse, hand-crafted features. Negative mining techniques have emerged as a critical component of all deep XC methods, allowing them to scale to millions of labels. However, despite recent advances, training deep XC models with large encoder architectures such as transformers remains challenging. This paper notices that memory overheads of popular negative mining techniques often force mini-batch sizes to remain small and slow training down. In response, this paper introduces NGAME, a light-weight mini-batch creation technique that offers provably accurate in-batch negative samples. This allows training with larger …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:M3NEmzRMIkIC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"This paper presents AGGLIO (Accelerated Graduated Generalized LInear-model Optimization), a stage-wise, graduated optimization technique that offers global convergence guarantees for non-convex optimization problems whose objectives offer only local convexity and may fail to be even quasi-convex at a global scale. In particular, this includes learning problems that utilize popular activation functions such as sigmoid, softplus and SiLU that yield non-convex training objectives. AGGLIO can be readily implemented using point as well as mini-batch SGD updates and offers provable convergence to the global optimum in general conditions. In experiments, AGGLIO outperformed several recently proposed optimization techniques for non-convex and locally convex objectives in terms of convergence rate as well as convergent accuracy. AGGLIO relies on a graduation technique for generalized linear models, as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:k_IJM867U9cC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"This paper establishes the algorithmic principle of alternating projections onto incoherent low-rank subspaces (APIS) as a unifying principle for designing robust regression algorithms that offer consistent model recovery even when a significant fraction of training points are corrupted by an adaptive adversary. APIS offers the first algorithm for robust non-parametric (kernel) regression with an explicit breakdown point that works for general PSD kernels under minimal assumptions. APIS also offers, as straightforward corollaries, robust algorithms for a much wider variety of well-studied settings, including robust linear regression, robust sparse recovery, and robust Fourier transforms. Algorithms offered by APIS enjoy formal guarantees that are frequently sharper than (especially in non-parametric settings) or competitive to existing results in these settings. They are also straightforward to implement and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:TFP_iSt0sucC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Hierarchical classification is supervised multi-class classification problem over the set of class labels organized according to a hierarchy. In this report, we study the work by Ramaswamy et. al. on hierarchical classification over symmetric tree distance loss. We extend the consistency of hierarchical classification algorithm over asymmetric tree distance loss. We design a algorithm to find Bayes optimal classification for a k-ary tree as a hierarchy. We show that under reasonable assumptions over asymmetric loss function, the Bayes optimal classification over this asymmetric loss can be found in . We exploit this insight and attempt to extend the Ova-Cascade algorithm \citet{ramaswamy2015convex} for hierarchical classification over the asymmetric loss.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:u-x6o8ySG0sC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Automated pedagogical error repair (APER) is the task of suggesting fixes to buggy programs written by beginner or novice programmers. APER tools have been shown to greatly improve the learning experience for students for whom error messages offered by compilers or runtime environments are either unhelpful and often misleading. Consequently, several APER tools have been proposed in literature using a variety of powerful machine learning techniques including sequence-to-sequence modelling (TRACER), reinforcement learning (RLAssist), graph attention (DrRepair) and decision trees (MACER). Despite offering high repair rates, these tools are often bulky, requiring several days of training and extensive GPU resources. This paper describes CAPER, a novel APER tool for the C programming language that offers 4-5% higher repair accuracy than existing APER tools on multiple benchmark error repair …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:J_g5lzvAfSwC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"We report the design, development and deployment of PRIORITY, an intelligent portal aimed at reducing the workload of instructors, tutors and teaching assistants in large programming courses of creating lab, assignment and exam problems every week. PRIORITY offers a scalable, user friendly and indexed repository of problems that can be queried to retrieve problems related to a particular programming concept, say for loops. PRIORITY accomplishes this by casting problem retrieval as a multi-label learning problem and using solving it using novel feature selection and AI-techniques. We also report the results of an A/B test and user survey, both conducted while PRIORITY was being used to offer a CS1 course taught at IIT Kanpur with over 500 students. PRIORITY has been in deployment at IIT Kanpur for almost 2 years now and our experience thus far suggests that it not only presents a valuable tool for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:NaGl4SEjCO4C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"Modern deep neural networks achieve excellent predictive performance due to their massive scale, flexible architecture design and availability of large training datasets. However, several applications additionally demand reliable estimates of model and predictive uncertainty that help in making robust predictions with limited training data, enabling out-of-distribution generalization, etc. Neural networks do not offer such uncertainly estimates out-of-the-box. Although Bayesian approaches to deep learning do provide a natural way to quantify model and predictive uncertainty by inferring the posterior distribution of the model weights and averaging the model’s predictions over the entire posterior distribution, standard Bayesian inference methods such as MCMC and variational inference are difficult to design and scale to massive networks. An appealing and popular alternative is to learn an ensemble of model weights …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:RGFaLdJalmkC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"This paper presents SVAM (Sequential Variance-Altered MLE), a unified framework for learning generalized linear models under adversarial label corruption in training data. SVAM extends to tasks such as least squares regression, logistic regression, and gamma regression, whereas many existing works on learning with label corruptions focus only on least squares regression. SVAM is based on a novel variance reduction technique that may be of independent interest and works by iteratively solving weighted MLEs over variance-altered versions of the GLM objective. SVAM offers provable model recovery guarantees superior to the state-of-the-art for robust regression even when a constant fraction of training labels are adversarially corrupted. SVAM also empirically outperforms several existing problem-specific techniques for robust regression and classification. Code for SVAM is available at https://github.com/purushottamkar/svam/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:ns9cj8rnVeAC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"The identification and control of human factors in climate change is a rapidly growing concern and robust, real-time air-quality monitoring and forecasting plays a critical role in allowing effective policy formulation and implementation. This paper presents DELFI, a novel deep learning-based mixture model to make effective long-term predictions of Particulate Matter (PM) 2.5 concentrations. A key novelty in DELFI is its multi-scale approach to the forecasting problem. The observation that point predictions are more suitable in the short-term and probabilistic predictions in the long-term allows accurate predictions to be made as much as 24 hours in advance. DELFI incorporates meteorological data as well as pollutant-based features to ensure a robust model that is divided into two parts: (i) a stack of three Long Short-Term Memory (LSTM) networks that perform differential modelling of the same window of past data, and (ii) a fully-connected layer enabling attention to each of the components. Experimental evaluation based on deployment of 13 stations in the Delhi National Capital Region (Delhi-NCR) in India establishes that DELFI offers far superior predictions especially in the long-term as compared to even non-parametric baselines. The Delhi-NCR recorded the 3rd highest PM levels amongst 39 mega-cities across the world during 2011-2015 and DELFI's performance establishes it as a potential tool for effective long-term forecasting of PM levels to enable public health management and environment protection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:O3NaXMp0MMsC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",22,"NOVEMBER 2022| VOL. 65| NO. 11| COMMUNICATIONS OF THE ACM 63 hot topics india region automate mechanical and time-consuming tasks performed by instructors and TAs? Apart from reducing manual effort, this could also improve instruction quality in resource-strapped situations. Our research group at IIT Kanpur has used Prutor data to develop AI tools targeting core pedagogical aspects of a course, such as question creation, doubt clearing, and grading (see Figure 2). Prutor data has also enabled researchers at IISc Bengaluru, National University of Singapore, Queensland University of Technology, and Innopolis University to develop solutions for error repair and improved feedback generation resulting in work appearing in several top-tier publications. 2–5, 8, 9, 11, 15, 17, 18",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&citation_for_view=MNXz0AoAAAAJ:GnPB-g6toBAC,https://www.cse.iitk.ac.in/users/purushot/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We propose MAD-GAN, an intuitive generalization to the Generative Adversarial Networks (GANs) and its conditional variants to address the well known problem of mode collapse. First, MAD-GAN is a multi-agent GAN architecture incorporating multiple generators and one discriminator. Second, to enforce that different generators capture diverse high probability modes, the discriminator of MAD-GAN is designed such that along with finding the real and fake samples, it is also required to identify the generator that generated the given fake sample. Intuitively, to succeed in this task, the discriminator must learn to push different generators towards different identifiable modes. We perform extensive experiments on synthetic and real datasets and compare MAD-GAN with different variants of GAN. We show high quality diverse sample generations for challenging tasks such as image-to-image translation and face generation. In addition, we also show that MAD-GAN is able to disentangle different modalities when trained using highly challenging diverse-class dataset (eg dataset with images of forests, icebergs, and bedrooms). In the end, we show its efficacy on the unsupervised feature representation task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:fbc8zXXH2BUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this work, we investigate the problem of lip-syncing a talking face video of an arbitrary identity to match a target speech segment. Current works excel at producing accurate lip movements on a static image or videos of specific people seen during the training phase. However, they fail to accurately morph the lip movements of arbitrary identities in dynamic, unconstrained talking face videos, resulting in significant parts of the video being out-of-sync with the new audio. We identify key reasons pertaining to this and hence resolve them by learning from a powerful lip-sync discriminator. Next, we propose new, rigorous evaluation benchmarks and metrics to accurately measure lip synchronization in unconstrained videos. Extensive quantitative evaluations on our challenging benchmarks show that the lip-sync accuracy of the videos generated by our Wav2Lip model is almost as good as real synced videos. We provide …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:MAUkC_7iAq8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"The exponential increase in COVID-19 patients is overwhelming healthcare systems across the world. With limited testing kits, it is impossible for every patient with respiratory illness to be tested using conventional techniques (RT-PCR). The tests also have long turn-around time, and limited sensitivity. Detecting possible COVID-19 infections on Chest X-Ray may help quarantine high risk patients while test results are awaited. X-Ray machines are already available in most healthcare systems, and with most modern X-Ray systems already digitized, there is no transportation time involved for the samples either. In this work we propose the use of chest X-Ray to prioritize the selection of patients for further RT-PCR testing. This may be useful in an inpatient setting where the present systems are struggling to decide whether to keep the patient in the ward along with other patients or isolate them in COVID-19 areas. It would also help in identifying patients with high likelihood of COVID with a false negative RT-PCR who would need repeat testing. Further, we propose the use of modern AI techniques to detect the COVID-19 patients using X-Ray images in an automated manner, particularly in settings where radiologists are not available, and help make the proposed testing technology scalable. We present CovidAID: COVID-19 AI Detector, a novel deep neural network based model to triage patients for appropriate testing. On the publicly available covid-chestxray-dataset [2], our model gives 90.5% accuracy with 100% sensitivity (recall) for the COVID-19 infection. We significantly improve upon the results of Covid-Net [10] on the same dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:WC9gN4BGCRcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Object detection methods like Single Shot Multibox Detector (SSD) provide highly accurate object detection that run in real-time. However, these approaches require a large number of annotated training images. Evidently, not all of these images are equally useful for training the algorithms. Moreover, obtaining annotations in terms of bounding boxes for each image is costly and tedious. In this paper, we aim to obtain a highly accurate object detector using only a fraction of the training images. We do this by adopting active learning that uses ‘human in the loop’paradigm to select the set of images that would be useful if annotated. Towards this goal, we make the following contributions: 1. We develop a novel active learning method which poses the layered architecture used in object detection as a ‘query by committee’paradigm to choose the set of images to be queried.
2. We introduce a framework to use the exploration/exploitation trade-off in our methods. 3. We analyze the results on standard object detection datasets which show that with only a third of the training data, we can obtain more than 95% of the localization accuracy of full supervision. Further our methods outperform classical uncertainty-based active learning algorithms like maximum entropy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:uDGL6kOW6j0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we aim to solve for unsupervised domain adaptation of classifiers where we have access to label information for the source domain while these are not available for a target domain. While various methods have been proposed for solving these including adversarial discriminator based methods, most approaches have focused on the entire image based domain adaptation. In an image, there would be regions that can be adapted better, for instance, the foreground object may be similar in nature. To obtain such regions, we propose methods that consider the probabilistic certainty estimate of various regions and specific focus on these during classification for adaptation. We observe that just by incorporating the probabilistic certainty of the discriminator while training the classifier, we are able to obtain state of the art results on various datasets as compared against all the recent methods. We provide a thorough empirical analysis of the method by providing ablation analysis, statistical significance test, and visualization of the attention maps and t-SNE embeddings. These evaluations convincingly demonstrate the effectiveness of the proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:kVjdVfd2voEC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Unsupervised Domain adaptation methods solve the adaptation problem for an unlabeled target set, assuming that the source dataset is available with all labels. However, the availability of actual source samples is not always possible in practical cases. It could be due to memory constraints, privacy concerns, and challenges in sharing data. This practical scenario creates a bottleneck in the domain adaptation problem. This paper addresses this challenging scenario by proposing a domain adaptation technique that does not need any source data. Instead of the source data, we are only provided with a classifier that is trained on the source data. Our proposed approach is based on a generative framework, where the trained classifier is used for generating samples from the source classes. We learn the joint distribution of data by using the energy-based modeling of the trained classifier. At the same time, a new classifier is also adapted for the target domain. We perform various ablation analysis under different experimental setups and demonstrate that the proposed approach achieves better results than the baseline models in this extremely novel scenario.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:w0F2JDEymm0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In light of the recent breakthroughs in automatic machine translation systems, we propose a novel approach that we term as ""Face-to-Face Translation"". As today's digital communication becomes increasingly visual, we argue that there is a need for systems that can automatically translate a video of a person speaking in language A into a target language B with realistic lip synchronization. In this work, we create an automatic pipeline for this problem and demonstrate its impact in multiple real-world applications. First, we build a working speech-to-speech translation system by bringing together multiple existing modules from speech and language. We then move towards ""Face-to-Face Translation"" by incorporating a novel visual module, LipGAN for generating realistic talking faces from the translated audio. Quantitative evaluation of LipGAN on the standard LRW test set shows that it significantly outperforms existing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:FiytvqdAVhgC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In the general settings of supervised learning, human action recognition has been a widely studied topic. The classifiers learned in this setting assume that the training and test data have been sampled from the same underlying probability distribution. However, in most of the practical scenarios, this assumption is not true, resulting in a suboptimal performance of the classifiers. This problem, referred to as Domain Shift, has been extensively studied, but mostly for image/object classification task. In this paper, we investigate the problem of Domain Shift in action videos, an area that has remained under-explored, and propose two new approaches named Action Modeling on Latent Subspace (AMLS) and Deep Adversarial Action Adaptation (DAAA). In the AMLS approach, the action videos in the target domain are modeled as a sequence of points on a latent subspace and adaptive kernels are successively learned between the source domain point and the sequence of target domain points on the manifold. In the DAAA approach, an end-to-end adversarial learning framework is proposed to align the two domains. The action adaptation experiments were conducted using various combinations of multi-domain action datasets, including six common classes of Olympic Sports and UCF50 datasets and all classes of KTH, MSR and our own SonyCam datasets. In this paper, we have achieved consistent improvements over chosen baselines and obtained some state-of-the-art results for the datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:4xDN1ZYqzskC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We present a novel deep learning architecture in which the convolution operation leverages heterogeneous kernels. The proposed HetConv (Heterogeneous Kernel-Based Convolution) reduces the computation (FLOPs) and the number of parameters as compared to standard convolution operation while still maintaining representational efficiency. To show the effectiveness of our proposed convolution, we present extensive experimental results on the standard convolutional neural network (CNN) architectures such as VGG and ResNet. We find that after replacing the standard convolutional filters in these architectures with our proposed HetConv filters, we achieve 3X to 8X FLOPs based improvement in speed while still maintaining (and sometimes improving) the accuracy. We also compare our proposed convolutions with group/depth wise convolutions and show that it achieves more FLOPs reduction with significantly higher accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:jgBuDB5drN8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper we aim to answer questions based on images when provided with a dataset of question-answer pairs for a number of images during training. A number of methods have focused on solving this problem by using image based attention. This is done by focusing on a specific part of the image while answering the question. Humans also do so when solving this problem. However, the regions that the previous systems focus on are not correlated with the regions that humans focus on. The accuracy is limited due to this drawback. In this paper, we propose to solve this problem by using an exemplar based method. We obtain one or more supporting and opposing exemplars to obtain a differential attention region. This differential attention is closer to human attention than other image based attention methods. It also helps in obtaining improved accuracy when answering questions. The method is evaluated on challenging benchmark datasets. We perform better than other image based attention methods and are competitive with other state of the art methods that focus on both image and questions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:Bg7qf7VwUHIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Humans involuntarily tend to infer parts of the conversation from lip movements when the speech is absent or corrupted by external noise. In this work, we explore the task of lip to speech synthesis, ie, learning to generate natural speech given only the lip movements of a speaker. Acknowledging the importance of contextual and speaker-specific cues for accurate lip-reading, we take a different path from existing works. We focus on learning accurate lip sequences to speech mappings for individual speakers in unconstrained, large vocabulary settings. To this end, we collect and release a large-scale benchmark dataset, the first of its kind, specifically to train and evaluate the single-speaker lip to speech task in natural settings. We propose a novel approach with key design choices to achieve accurate, natural lip to speech synthesis in such unconstrained scenarios for the first time. Extensive evaluation using quantitative, qualitative metrics and human evaluation shows that our method is four times more intelligible than previous works in this space.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:SjuI4pbJlxcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We present a filter correlation based model compression approach for deep convolutional neural networks. Our approach iteratively identifies pairs of filters with the largest pairwise correlations and drops one of the filters from each such pair. However, instead of discarding one of the filters from each such pair naively, the model is re-optimized to make the filters in these pairs maximally correlated, so that discarding one of the filters from the pair results in minimal information loss. Moreover, after discarding the filters in each round, we further finetune the model to recover from the potential small loss incurred by the compression. We evaluate our proposed approach using a comprehensive set of experiments and ablation studies. Our compression method yields state-of-the-art FLOPs compression rates on various benchmarks, such as LeNet-5, VGG-16, and ResNet-50, 56, while still achieving excellent predictive performance for tasks such as object detection on benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:buQ7SEKw-1sC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Understanding and explaining deep learning models is an imperative task. Towards this, we propose a method that obtains gradient-based certainty estimates that also provide visual attention maps. Particularly, we solve for visual question answering task. We incorporate modern probabilistic deep learning methods that we further improve by using the gradients for these estimates. These have two-fold benefits: a) improvement in obtaining the certainty estimates that correlate better with misclassified samples and b) improved attention maps that provide state-of-the-art results in terms of correlation with human attention regions. The improved attention maps result in consistent improvement for various methods for visual question answering. Therefore, the proposed technique can be thought of as a recipe for obtaining improved certainty estimates and explanation for deep learning models. We provide detailed empirical analysis for the visual question answering task on all standard benchmarks and comparison with state of the art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:j7_hQOaDUrUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"While convolutional neural networks (CNN) have achieved impressive performance on various classification/recognition tasks, they typically consist of a massive number of parameters. This results in significant memory requirement as well as computational overheads. Consequently, there is a growing need for filter-level pruning approaches for compressing CNN based models that not only reduce the total number of parameters but reduce the overall computation as well. We present a new min-max framework for filter-level pruning of CNNs. Our framework, called Play and Prune (PP), jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance. Our framework consists of two modules: (1) An adaptive filter pruning (AFP) module, which minimizes the number of filters in the model; and (2) A pruning rate controller (PRC) module, which maximizes the accuracy during pruning. Moreover, unlike most previous approaches, our approach allows directly specifying the desired error tolerance instead of pruning level. Our compressed models can be deployed at run-time, without requiring any special libraries or hardware. Our approach reduces the number of parameters of VGG-16 by an impressive factor of 17.5X, and number of FLOPS by 6.43X, with no loss of accuracy, significantly outperforming other state-of-the-art filter pruning methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:v1_lew4L6wgC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Training Neural Ordinary Differential Equations (ODEs) is often computationally expensive. Indeed, computing the forward pass of such models involves solving an ODE which can become arbitrarily complex during training. Recent works have shown that regularizing the dynamics of the ODE can partially alleviate this. In this paper we propose a new regularization technique: randomly sampling the end time of the ODE during training. The proposed regularization is simple to implement, has negligible overhead and is effective across a wide variety of tasks. Further, the technique is orthogonal to several other methods proposed to regularize the dynamics of ODEs and as such can be used in conjunction with them. We show through experiments on normalizing flows, time series models and image recognition that the proposed regularization can significantly decrease training time and even improve performance over baseline models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:jFemdcug13IC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we propose a method for obtaining sentence-level embeddings. While the problem of securing word-level embeddings is very well studied, we propose a novel method for obtaining sentence-level embeddings. This is obtained by a simple method in the context of solving the paraphrase generation task. If we use a sequential encoder-decoder model for generating paraphrase, we would like the generated paraphrase to be semantically close to the original sentence. One way to ensure this is by adding constraints for true paraphrase embeddings to be close and unrelated paraphrase candidate sentence embeddings to be far. This is ensured by using a sequential pair-wise discriminator that shares weights with the encoder that is trained with a suitable loss function. Our loss function penalizes paraphrase sentence embedding distances from being too large. This loss is used in combination with a sequential encoder-decoder network. We also validated our method by evaluating the obtained embeddings for a sentiment analysis task. The proposed method results in semantic embeddings and outperforms the state-of-the-art on the paraphrase generation and sentiment analysis task on standard datasets. These results are also shown to be statistically significant.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&citation_for_view=JyHi9OoAAAAJ:LgRImbQfgY4C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Generating natural questions from an image is a semantic task that requires using visual and language modality to learn multimodal representations. Images can have multiple visual and language contexts that are relevant for generating questions namely places, captions, and tags. In this paper, we propose the use of exemplars for obtaining the relevant context. We obtain this by using a Multimodal Differential Network to produce natural and engaging questions. The generated questions show a remarkable similarity to the natural questions as validated by a human study. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics (BLEU, METEOR, ROUGE, and CIDEr).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:0CzhzZyukY4C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We present sentence aligned parallel corpora across 10 Indian Languages - Hindi, Telugu, Tamil, Malayalam, Gujarati, Urdu, Bengali, Oriya, Marathi, Punjabi, and English - many of which are categorized as low resource. The corpora are compiled from online sources which have content shared across languages. The corpora presented significantly extends present resources that are either not large enough or are restricted to a specific domain (such as health). We also provide a separate test corpus compiled from an independent online source that can be independently used for validating the performance in 10 Indian languages. Alongside, we report on the methods of constructing such corpora using tools enabled by recent advances in machine translation and cross-lingual retrieval using deep neural network based methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:rHJHxKgnXwkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we solve the problem of adapting classifiers across domains. We consider the problem of domain adaptation for multi-class classification where we are provided a labeled set of examples in a source dataset and we are provided a target dataset with no supervision. In this setting, we propose an adversarial discriminator based approach. While the approach based on adversarial discriminator has been previously proposed; in this paper, we present an informed adversarial discriminator. Our observation relies on the analysis that shows that if the discriminator has access to all the information available including the class structure present in the source dataset, then it can guide the transformation of features of the target set of classes to a more structure adapted space. Using this formulation, we obtain state-of-the-art results for the standard evaluation on benchmark datasets. We further provide detailed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:BzfGm06jWhQC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we aim to obtain improved attention for a visual question answering (VQA) task. It is challenging to provide supervision for attention. An observation we make is that visual explanations as obtained through class activation mappings (specifically Grad-CAM) that are meant to explain the performance of various networks could form a means of supervision. However, as the distributions of attention maps and that of Grad-CAMs differ, it would not be suitable to directly use these as a form of supervision. Rather, we propose the use of a discriminator that aims to distinguish samples of visual explanation and attention maps. The use of adversarial training of the attention regions as a two-player game between attention and explanation serves to bring the distributions of attention maps and visual explanations closer. Significantly, we observe that providing such a means of supervision also results in attention maps that are more closely related to human attention resulting in a substantial improvement over baseline stacked attention network (SAN) models. It also results in a good improvement in rank correlation metric on the VQA task. This method can also be combined with recent MCB based methods and results in consistent improvement. We also provide comparisons with other means for learning distributions such as based on Correlation Alignment (Coral), Maximum Mean Discrepancy (MMD) and Mean Square Error (MSE) losses and observe that the adversarial loss outperforms the other forms of learning the attention maps. Visualization of the results also confirms our hypothesis that attention maps improve using this form of supervision.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:owLR8QvbtFgC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Our goal is to spot words in silent speech videos without explicitly recognizing the spoken words, where the lip motion of the speaker is clearly visible and audio is absent. Existing work in this domain has mainly focused on recognizing a fixed set of words in word-segmented lip videos, which limits the applicability of the learned model due to limited vocabulary and high dependency on the model's recognition performance. Our contribution is two-fold: 1) we develop a pipeline for recognition-free retrieval, and show its performance against recognition-based retrieval on a large-scale dataset and another set of out-of-vocabulary words. 2) We introduce a query expansion technique using pseudo-relevant feedback and propose a novel re-ranking method based on maximizing the correlation between spatio-temporal landmarks of the query and the top retrieval candidates. Our word spotting method achieves 35 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:artPoR2Yc-kC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Convolutional neural networks (CNN) have achieved impressive performance on the wide variety of tasks (classification, detection, etc.) across multiple domains at the cost of high computational and memory requirements. Thus, leveraging CNNs for real-time applications necessitates model compression approaches that not only reduce the total number of parameters but reduce the overall computation as well. In this work, we present a stability-based approach for filter-level pruning of CNNs. We evaluate our proposed approach on different architectures (LeNet, VGG-16, ResNet, and Faster RCNN) and datasets and demonstrate its generalizability through extensive experiments. Moreover, our compressed models can be used at run-time without requiring any special libraries or hardware. Our model compression method reduces the number of FLOPS by an impressive factor of 6.03X and GPU memory footprint by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:wMgC3FpKEyYC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Deep learning models suffer from catastrophic forgetting when trained in an incremental learning setting. In this work, we propose a novel approach to address the task incremental learning problem, which involves training a model on new tasks that arrive in an incremental manner. The task incremental learning problem becomes even more challenging when the test set contains classes that are not part of the train set, ie, a task incremental generalized zero-shot learning problem. Our approach can be used in both the zero-shot and non zero-shot task incremental learning settings. Our proposed method uses weight rectifications and affine transformations in order to adapt the model to different tasks that arrive sequentially. Specifically, we adapt the network weights to work for new tasks by"" rectifying"" the weights learned from the previous task. We learn these weight rectifications using very few parameters. We additionally learn affine transformations on the outputs generated by the network in order to better adapt them for the new task. We perform experiments on several datasets in both zero-shot and non zero-shot task incremental learning settings and empirically show that our approach achieves state-of-the-art results. Specifically, our approach outperforms the state-of-the-art non zero-shot task incremental learning method by over 5% on the CIFAR-100 dataset. Our approach also significantly outperforms the state-of-the-art task incremental generalized zero-shot learning method by absolute margins of 6.91% and 6.33% for the AWA1 and CUB datasets, respectively. We validate our approach using various ablation studies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:WAzi4Gm8nLoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Indian language machine translation performance is hampered due to the lack of large scale multi-lingual sentence aligned corpora and robust benchmarks. Through this paper, we provide and analyse an automated framework to obtain such a corpus for Indian language neural machine translation (NMT) systems. Our pipeline consists of a baseline NMT system, a retrieval module, and an alignment module that is used to work with publicly available websites such as press releases by the government. The main contribution towards this effort is to obtain an incremental method that uses the above pipeline to iteratively improve the size of the corpus as well as improve each of the components of our system. Through our work, we also evaluate the design choices such as the choice of pivoting language and the effect of iterative incremental increase in corpus size. Our work in addition to providing an automated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:jE2MZjpN3IcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we propose a method to obtain robust explanations for visual question answering (VQA) that correlate well with the answers. Our model explains the answers obtained through a VQA model by providing visual and textual explanations. The main challenges that we address are i) Answers and textual explanations obtained by current methods are not well correlated and ii) Current methods for visual explanation do not focus on the right location for explaining the answer. We address both these challenges by using a collaborative correlated module which ensures that even if we do not train for noise based attacks, the enhanced correlation ensures that the right explanation and answer can be generated. We further show that this also aids in improving the generated visual and textual explanations. The use of the correlated module can be thought of as a robust method to verify if the answer and explanations are coherent. We evaluate this model using VQA-X dataset. We observe that the proposed method yields better textual and visual justification that supports the decision. We showcase the robustness of the model against a noise-based perturbation attack using corresponding visual and textual explanations. A detailed empirical analysis is shown.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:Br1UauaknNIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We propose a framework for compressing state-of-the-art Single Shot MultiBox Detector (SSD). The framework addresses compression in the following stages: Sparsity Induction, Filter Selection, and Filter Pruning. In the Sparsity Induction stage, the object detector model is sparsified via an improved global threshold. In Filter Selection & Pruning stage, we select and remove filters using sparsity statistics of filter weights in two consecutive convolutional layers. This results in the model with the size smaller than most existing compact architectures. We evaluate the performance of our framework with multiple datasets and compare over multiple methods. Experimental results show that our method achieves state-of-the-art compression of 6.7X and 4.9X on PASCAL VOC dataset on models SSD300 and SSD512 respectively. We further show that the method produces maximum compression of 26X with SSD512 on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:QD3KBmkZPeQC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Obtaining efficient Convolutional Neural Networks (CNNs) are imperative to enable their application for a wide variety of tasks (classification, detection, etc.). While several methods have been proposed to solve this problem, we propose a novel strategy for solving the same that is orthogonal to the strategies proposed so far. We hypothesize that if we add a fatuous auxiliary task, to a network which aims to solve a semantic task such as classification or detection, the filters devoted to solving this frivolous task would not be relevant for solving the main task of concern. These filters could be pruned and pruning these would not reduce the performance on the original task. We demonstrate that this strategy is not only successful, it in fact allows for improved performance for a variety of tasks such as object classification, detection and action recognition. An interesting observation is that the task needs to be fatuous so that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:CB2v5VPnA5kC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We introduce a monaural audio source separation framework using a latent generative model. Traditionally, discriminative training for source separation is proposed using deep neural networks or non-negative matrix factorization. In this paper, we propose a principled generative approach using variational autoencoders (VAE) for audio source separation. VAE computes efficient Bayesian inference which leads to a continuous latent representation of the input data (spectrogram). It contains a probabilistic encoder which projects an input data to latent space and a probabilistic decoder which projects data from latent space back to input space. This allows us to learn a robust latent representation of sources corrupted with noise and other sources. The latent representation is then fed to the decoder to yield the separated source. Both encoder and decoder are implemented via multilayer perceptron (MLP). In contrast to prevalent techniques, we argue that VAE is a more principled approach to source separation. Experimentally, we find that the proposed framework yields reasonable improvements when compared to baseline methods available in the literature ie DNN and RNN with different masking functions and autoencoders. We show that our method performs better than best of the relevant methods with∼ 2 dB improvement in the source to distortion ratio.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:6yz0xqPARnAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Domain adaptation is essential to enable wide usage of deep learning based networks trained using large labeled datasets. Adversarial learning based techniques have shown their utility towards solving this problem using a discriminator that ensures source and target distributions are close. However, here we suggest that rather than using a point estimate, it would be useful if a distribution based discriminator could be used to bridge this gap. This could be achieved using multiple classifiers or using traditional ensemble methods. In contrast, we suggest that a Monte Carlo dropout based ensemble discriminator could suffice to obtain the distribution based discriminator. Specifically, we propose a curriculum based dropout discriminator that gradually increases the variance of the sample based distribution and the corresponding reverse gradients are used to align the source and target feature representations. The detailed results and thorough ablation analysis show that our model outperforms state-of-the-art results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:nRpfm8aw39MC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"While convolutional neural networks (CNNs) have achieved remarkable performance on various supervised and unsupervised learning tasks, they typically consist of a massive number of parameters. This results in significant memory requirements as well as a computational burden. Consequently, there is a growing need for filter-level pruning approaches for compressing CNN based models that not only reduce the total number of parameters but reduce the overall computation as well. We present a new min-max framework for the filter-level pruning of CNNs. Our framework jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance. Our framework consists of two modules: (1) An adaptive filter pruning (AFP) module, which minimizes the number of filters in the model; and (2) A pruning rate controller (PRC) module, which maximizes the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:DBa1UEJaJKAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we propose a novel approach for generalized zero-shot learning in a multi-modal setting, where we have novel classes of audio/video during testing that are not seen during training. We use the semantic relatedness of text embeddings as a means for zero-shot learning by aligning audio and video embeddings with the corresponding class label text feature space. Our approach uses a cross-modal decoder and a composite triplet loss. The cross-modal decoder enforces a constraint that the class label text features can be reconstructed from the audio and video embeddings of data points. This helps the audio and video embeddings to move closer to the class label text embedding. The composite triplet loss makes use of the audio, video, and text embeddings. It helps bring the embeddings from the same class closer and push away the embeddings from different classes in a multi-modal setting. This helps the network to perform better on the multi-modal zero-shot learning task. Importantly, our multi-modal zero-shot learning approach works even if a modality is missing at test time. We test our approach on the generalized zero-shot classification and retrieval tasks and show that our approach outperforms other models in the presence of a single modality as well as in the presence of multiple modalities. We validate our approach by comparing it with previous approaches and using various ablations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:q-HalDI95KYC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We present a simple, yet effective, Neural Machine Translation system for Indian languages. We demonstrate the feasibility for multiple language pairs, and establish a strong baseline for further research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:7BrZ7Jt4UNcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Understanding the relationship between the auditory and visual signals is crucial for many different applications ranging from computer-generated imagery (CGI) and video editing automation to assisting people with hearing or visual impairments. However, this is challenging since the distribution of both audio and visual modality is inherently multi-modal. Therefore, most of the existing methods ignore the multimodal aspect and assume that there only exists a deterministic one-to-one mapping between the two modalities. It can lead to low-quality predictions as the model collapses to optimizing the average behavior rather than learning the full data distributions. In this paper, we present a stochastic model for generating speech in a silent video. The proposed model combines recurrent neural networks and variational deep generative models to learn the auditory signal’s conditional distribution given the visual signal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:O0nohqN1r9EC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Convolutional neural networks (CNNs) have been the source of recent breakthroughs in many vision tasks. Feature pooling layers are being widely used in CNNs to reduce the spatial dimensions of the feature maps of the hidden layers. This gives CNNs the property of spatial invariance and also results in speed-up and reduces over-fitting. However, this also causes significant information loss. All existing feature pooling layers follow a one-step procedure for spatial pooling, which affects the overall performance due to significant information loss. Not much work has been done to do efficient feature pooling operation in CNNs. To reduce the loss of information at this critical operation of the CNNs, we propose a new EDS layer (Expansion Downsampling learnable-Scaling) to replace the existing pooling mechanism. We propose a two-step procedure to minimize the information loss by increasing the number of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:6bLC7aUMtPcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Convolution Neural Networks (CNN) have been extremely successful in solving intensive computer vision tasks. The convolutional filters used in CNNs have played a major role in this success, by extracting useful features from the inputs. Recently researchers have tried to boost the performance of CNNs by re-calibrating the feature maps produced by these filters, eg, Squeeze-and-Excitation Networks (SENets). These approaches have achieved better performance by Exciting up the important channels or feature maps while diminishing the rest. However, in the process, architectural complexity has increased. We propose an architectural block that introduces much lower complexity than the existing methods of CNN performance boosting while performing significantly better than them. We carry out experiments on the CIFAR, ImageNet and MS-COCO datasets, and show that the proposed block can challenge the state-of-the-art results. Our method boosts the ResNet-50 architecture to perform comparably to the ResNet-152 architecture, which is a three times deeper network, on classification. We also show experimentally that our method is not limited to classification but also generalizes well to other tasks such as object detection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:ubry08Y2EpUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"One of the major limitations of deep learning models is that they face catastrophic forgetting in an incremental learning scenario. There have been several approaches proposed to tackle the problem of incremental learning. Most of these methods are based on knowledge distillation and do not adequately utilize the information provided by older task models, such as uncertainty estimation in predictions. The predictive uncertainty provides the distributional information can be applied to mitigate catastrophic forgetting in a deep learning framework. In the proposed work, we consider a Bayesian formulation to obtain the data and model uncertainties. We also incorporate self-attention framework to address the incremental learning problem. We define distillation losses in terms of aleatoric uncertainty and self-attention. In the proposed work, we investigate different ablation analyses on these losses. Furthermore, we are able to obtain better results in terms of accuracy on standard benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:F2UWTTQJPOcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Generating natural questions from an image is a semantic task that requires using vision and language modalities to learn multimodal representations. Images can have multiple visual and language cues such as places, captions, and tags. In this paper, we propose a principled deep Bayesian learning framework that combines these cues to produce natural questions. We observe that with the addition of more cues and by minimizing uncertainty in the among cues, the Bayesian network becomes more confident. We propose a Minimizing Uncertainty of Mixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues experts for generating probabilistic questions. This is a Bayesian framework and the results show a remarkable similarity to natural questions as validated by a human study. We observe that with the addition of more cues and by minimizing uncertainty among the cues, the Bayesian framework becomes more confident. Ablation studies of our model indicate that a subset of cues is inferior at this task and hence the principled fusion of cues is preferred. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE, and CIDEr). Here we provide project link for Deep Bayesian VQG https://delta-lab-iitk. github. io/BVQG/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:hsZV8lGYWTMC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Researchers have proposed various activation functions. These activation functions help the deep network to learn non-linear behavior with a significant effect on training dynamics and task performance. The performance of these activations also depends on the initial state of the weight parameters, ie, different initial state leads to a difference in the performance of a network. In this paper, we have proposed a cooperative initialization for training the deep network using ReLU activation function to improve the network performance. Our approach uses multiple activation functions in the initial few epochs for the update of all sets of weight parameters while training the network. These activation functions cooperate to overcome their drawbacks in the update of weight parameters, which in effect learn better"" feature representation"" and boost the network performance later. Cooperative initialization based training also helps in reducing the overfitting problem and does not increase the number of parameters, inference (test) time in the final model while improving the performance. Experiments show that our approach outperforms various baselines and, at the same time, performs well over various tasks such as classification and detection. The Top-1 classification accuracy of the model trained using our approach improves by 2.8% for VGG-16 and 2.1% for ResNet-56 on CIFAR-100 dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:prdVHNxh-e8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we propose a probabilistic framework for solving the task of ‘Visual Dialog’. Solving this task requires reasoning and understanding of visual modality, language modality, and common sense knowledge to answer. Various architectures have been proposed to solve this task by variants of multi-modal deep learning techniques that combine visual and language representations. However, we believe that it is crucial to understand and analyze the sources of uncertainty for solving this task. Our approach allows for estimating uncertainty and also aids a diverse generation of answers. The proposed approach is obtained through a probabilistic representation module that provides us with representations for image, question and conversation history, a module that ensures that diverse latent representations for candidate answers are obtained given the probabilistic representations and an uncertainty …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:IaI1MmNe2tcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"While usage of convolutional neural networks (CNN) is widely prevalent, methods proposed so far always have considered homogeneous kernels for this task. In this paper, we propose a new type of convolution operation using heterogeneous kernels. The proposed Heterogeneous Kernel-Based Convolution (HetConv) reduces the computation (FLOPs) and the number of parameters as compared to standard convolution operation while it maintains representational efficiency. To show the effectiveness of our proposed convolution, we present extensive experimental results on the standard CNN architectures such as VGG, ResNet, Faster-RCNN, MobileNet, and SSD. We observe that after replacing the standard convolutional filters in these architectures with our proposed HetConv filters, we achieve 1.5  to 8  FLOPs based improvement in speed while it maintains (sometimes improves) the accuracy. We also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:PYBJJbyH-FwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Convolutional layers are a major driving force behind the successes of deep learning. Pointwise convolution (PWC) is a 1 × 1 convolutional filter that is primarily used for parameter reduction. However, the PWC ignores the spatial information around the points it is processing. This design is by choice, in order to reduce the overall parameters and computations. However, we hypothesize that this shortcoming of PWC has a significant impact on the network performance. We propose an alternative design for pointwise convolution, which uses spatial information from the input efficiently. Our design significantly improves the performance of the networks without substantially increasing the number of parameters and computations. We experimentally show that our design results in significant improvement in the performance of the network for classification as well as detection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:WHdLCjDvYFkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this work, we re-think the task of speech enhancement in unconstrained real-world environments. Current state-of-the-art methods use only the audio stream and are limited in their performance in a wide range of real-world noises. Recent works using lip movements as additional cues improve the quality of generated speech over"" audio-only"" methods. But, these methods cannot be used for several applications where the visual stream is unreliable or completely absent. We propose a new paradigm for speech enhancement by exploiting recent breakthroughs in speech-driven lip synthesis. Using one such model as a teacher network, we train a robust student network to produce accurate lip movements that mask away the noise, thus acting as a"" visual noise filter"". The intelligibility of the speech enhanced by our pseudo-lip approach is comparable (< 3% difference) to the case of using real lips. This implies that we can exploit the advantages of using lip movements even in the absence of a real video stream. We rigorously evaluate our model using quantitative metrics as well as human evaluations. Additional ablation studies and a demo video on our website containing qualitative comparisons and results clearly illustrate the effectiveness of our approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:HhcuHIWmDEUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we propose an approach to improve few-shot classification performance using a composite rotation based auxiliary task. Few-shot classification methods aim to produce neural networks that perform well for classes with a large number of training samples and classes with less number of training samples. They employ techniques to enable the network to produce highly discriminative features that are also very generic. Generally, the better the quality and generic-nature of the features produced by the network, the better is the performance of the network on few-shot learning. Our approach aims to train networks to produce such features by using a self-supervised auxiliary task. Our proposed composite rotation based auxiliary task performs rotation at two levels, ie, rotation of patches inside the image (inner rotation) and rotation of the whole image (outer rotation) and assigns one out of 16 rotation classes to the modified image. We then simultaneously train for the composite rotation prediction task along with the original classification task, which forces the network to learn high-quality generic features that help improve the few-shot classification performance. We experimentally show that our approach performs better than existing few-shot learning methods on multiple benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:1Ye0OR6EYb4C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,This document describes the machine translation system used in the submissions of IIIT-Hyderabad CVIT-MT for the WAT-2018 English-Hindi translation task. Performance is evaluated on the associated corpus provided by the organizers. We experimented with convolutional sequence to sequence architectures. We also train with additional data obtained through backtranslation.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:zCSUwVk65WsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Understanding and explaining deep learning models is an imperative task. Towards this, we propose a method that obtains gradient-based certainty estimates that also provide visual attention maps. Particularly, we solve for visual question answering task. We incorporate modern probabilistic deep learning methods that we further improve by using the gradients for these estimates. These have two-fold benefits: a) improvement in obtaining the certainty estimates that correlate better with misclassified samples and b) improved attention maps that provide state-of-the-art results in terms of correlation with human attention regions. The improved attention maps result in consistent improvement for various methods for visual question answering. Therefore, the proposed technique can be thought of as a tool for obtaining improved certainty estimates and explanations for deep learning models. We provide detailed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:-nhnvRiOwuoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Method for capturing an environment with objects, using a 3D camera, wherein the images of the cameras captured at different moments in time are used to generate 3D models, and wherein accuracy values are assigned to segments of the models allowing efficient refining of the models using the accuracy values.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:Aul-kAQHnToC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Learning from a few examples is an important practical aspect of training classifiers. Various works have examined this aspect quite well. However, all existing approaches assume that the few examples provided are always correctly labeled. This is a strong assumption, especially if one considers the current techniques for labeling using crowd-based labeling services. We address this issue by proposing a novel robust few-shot learning approach. Our method relies on generating robust prototypes from a set of few examples. Specifically, our method refines the class prototypes by producing hybrid features from the support examples of each class. The refined prototypes help to classify the query images better. Our method can replace the evaluation phase of any few-shot learning method that uses a nearest neighbor prototype-based evaluation procedure to make them robust. We evaluate our method on standard mini-ImageNet and tiered-ImageNet datasets. We perform experiments with various label corruption rates in the support examples of the few-shot classes. We obtain significant improvement over widely used few-shot learning methods that suffer significant performance degeneration in the presence of label noise. We finally provide extensive ablation experiments to validate our method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:pAkWuXOU-OoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We present a filter pruning approach for deep model compression, using a multitask network. Our approach is based on learning aa pruner network to prune a pre-trained target network. The pruner is essentially a multitask deep neural network with binary outputs that help identify the filters from each layer of the original network that do not have any significant contribution to the model and can therefore be pruned. The pruner network has the same architecture as the original network except that it has a multitask/multi-output last layer containing binary-valued outputs (one per filter), which indicate which filters have to be pruned. The pruner's goal is to minimize the number of filters from the original network by assigning zero weights to the corresponding output feature-maps. In contrast to most of the existing methods, instead of relying on iterative pruning, our approach can prune the network (original network) in one go and, moreover, does not require specifying the degree of pruning for each layer (and can learn it instead). The compressed model produced by our approach is generic and does not need any special hardware/software support. Moreover, augmenting with other methods such as knowledge distillation, quantization, and connection pruning can increase the degree of compression for the proposed approach. We show the efficacy of our proposed approach for classification and object detection tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:yxmsSjX2EkcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Objectives
To study whether a trained convolutional neural network (CNN) can be of assistance to radiologists in differentiating Coronavirus disease (COVID)–positive from COVID-negative patients using chest X-ray (CXR) through an ambispective clinical study. To identify subgroups of patients where artificial intelligence (AI) can be of particular value and analyse what imaging features may have contributed to the performance of AI by means of visualisation techniques.
Methods
CXR of 487 patients were classified into [4] categories—normal, classical COVID, indeterminate, and non-COVID by consensus opinion of 2 radiologists. CXR which were classified as “normal” and “indeterminate” were then subjected to analysis by AI, and final categorisation provided as guided by prediction of the network. Precision and recall of the radiologist alone and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:ziOE8S1-AIUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Convolution operation in deep convolutional neural networks is the most computationally expensive as compared to other operations. Most of the model computation (FLOPS) in the deep architecture belong to convolution operation. In this paper, we are proposing a novel skip convolution operation that employs significantly fewer computation as compared to the traditional one without sacrificing model accuracy. Skip convolution operation produces structured sparsity in the output feature maps without requiring sparsity in the model parameters for computation reduction. The existing convolution operation performs the redundant computation for object feature representation while the proposed convolution skips redundant computation. Our empirical evaluation for various deep models (VGG, ResNet, MobileNet, and Faster R-CNN) over various benchmarked datasets (CIFAR-10, CIFAR-100, ImageNet, and MS …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:RoXSNcbkSzsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"This paper describes the Neural Machine Translation systems used by IIIT Hyderabad (CVIT-MT) for the translation tasks part of WAT-2019. We participated in tasks pertaining to Indian languages and submitted results for English-Hindi, Hindi-English, English-Tamil and Tamil-English language pairs. We employ Transformer architecture experimenting with multilingual models and methods for low-resource languages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:7wO8s98CvbsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"There have been a number of techniques that have demonstrated the generation of multimedia data for one modality at a time using GANs, such as the ability to generate images, videos, and audio. However, so far, the task of multi-modal generation of data, specifically for audio and videos both, has not been sufficiently well-explored. Towards this, we propose a method that demonstrates that we are able to generate naturalistic samples of video and audio data by the joint correlated generation of audio and video modalities. The proposed method uses multiple discriminators to ensure that the audio, video, and the joint output are also indistinguishable from real-world samples. We present a dataset for this task and show that we are able to generate realistic samples. This method is validated using various standard metrics such as Inception Score, Frechet Inception Distance (FID) and through human evaluation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:kF1pexMAQbMC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"A great number of situational comedies (sitcoms) are being regularly made and the task of adding laughter tracks to these is a critical task. Providing an ability to be able to predict whether something will be humorous to the audience is also crucial. In this project, we aim to automate this task. Towards doing so, we annotate an existing sitcom (Big Bang Theory') and use the laughter cues present to obtain a manual annotation for this show. We provide detailed analysis for the dataset design and further evaluate various state of the art baselines for solving this task. We observe that existing LSTM and BERT based networks on the text alone do not perform as well as joint text and video or only video-based networks. Moreover, it is challenging to ascertain that the words attended to while predicting laughter are indeed humorous. Our dataset and analysis provided through this paper is a valuable resource towards solving this interesting semantic and practical task. As an additional contribution, we have developed a novel model for solving this task that is a multi-modal self-attention based model that outperforms currently prevalent models for solving this task. The project page for the submission is\url https://multimodal-humor-dataset. github. io/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:3bvyWxjaHKcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In recent years, the attention mechanism has become a fairly popular concept and has proven to be successful in many machine learning applications. However, deep learning models do not employ supervision for these attention mechanisms which can improve the model's performance significantly. Therefore, in this paper, we tackle this limitation and propose a novel method to improve the attention mechanism by inducing"" self-supervision"". We devise a technique to generate desirable attention maps for any model that utilizes an attention module. This is achieved by examining the model's output for different regions sampled from the input and obtaining the attention probability distributions that enhance the proficiency of the model. The attention distributions thus obtained are used for supervision. We rely on the fact, that attenuation of the unimportant parts, allows a model to attend to more salient regions, thus strengthening the prediction accuracy. The quantitative and qualitative results published in this paper show that this method successfully improves the attention mechanism as well as the model's accuracy. In addition to the task of Visual Question Answering (VQA), we also show results on the task of Image classification and Text classification to prove that our method can be generalized to any vision and language model that uses an attention module",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:FiDNX6EVdGUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we address the task of improving pair-wise machine translation for specific low resource Indian languages. Multilingual NMT models have demonstrated a reasonable amount of effectiveness on resource-poor languages. In this work, we show that the performance of these models can be significantly improved upon by using back-translation through a filtered back-translation process and subsequent fine-tuning on the limited pair-wise language corpora. The analysis in this paper suggests that this method can significantly improve a multilingual model's performance over its baseline, yielding state-of-the-art results for various Indian languages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:VN7nJs4JPk0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Generative models have recently shown the ability to realistically generate data and model the distribution accurately. However, joint modeling of an image with the attribute that it is labeled with requires learning a cross modal correspondence between images and the attribute data. Though the information present in the images and attributes possess completely different statistical properties altogether, there exists an inherent correspondence that is challenging to capture. Various models have aimed at capturing this correspondence either through joint modeling of a variational autoencoder or through separate encoder networks that are then concatenated. We present an alternative by proposing a bridged variational autoencoder that allows for learning cross-modal correspondence by incorporating cross-modal hallucination losses in the latent space. In comparison to the existing methods, we have found that by incorporating this information into the network we not only obtain better generation results, but also obtain very distinctive latent embeddings thereby increasing the accuracy of cross-modal generated results. We validate the proposed method through comparison with state of the art methods and benchmarking on standard datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:LPtt_HFRSbwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this work, we propose a modeling technique for jointly training image and video generation models by simultaneously learning to map latent variables with a fixed prior onto real images and interpolate over images to generate videos. The proposed approach models the variations in representations using residual vectors encoding the change at each time step over a summary vector for the entire video. We utilize the technique to jointly train an image generation model with a fixed prior along with a video generation model lacking constraints such as disentanglement. The joint training enables the image generator to exploit temporal information while the video generation model learns to flexibly share information across frames. Moreover, experimental results verify our approach's compatibility with pre-training on videos or images and training on datasets containing a mixture of both. A comprehensive set of quantitative and qualitative evaluations reveal the improvements in sample quality and diversity over both video generation and image generation baselines. We further demonstrate the technique's capabilities of exploiting similarity in features across frames by applying it to a model based on decomposing the video into motion and content. The proposed model allows minor variations in content across frames while maintaining the temporal dependence through latent vectors encoding the pose or motion features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:jU7OWUQzBzMC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Abnormal activity recognition requires detection of occurrence of anomalous events that suffer from a severe imbalance in data. In a video, normal is used to describe activities that conform to usual events while the irregular events which do not conform to the normal are referred to as abnormal. It is far more common to observe normal data than to obtain abnormal data in visual surveillance. In this paper, we propose an approach where we can obtain abnormal data by transforming normal data. This is a challenging task that is solved through a multi-stage pipeline approach. We utilize a number of techniques from unsupervised segmentation in order to synthesize new samples of data that are transformed from an existing set of normal examples. Further, this synthesis approach has useful applications as a data augmentation technique. An incrementally trained Bayesian convolutional neural network (CNN) is used …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:U4n9YNQMCAIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Our goal is to spot words in silent speech videos without explicitly recognizing the spoken words, where the lip motion of the speaker is clearly visible and audio is absent. Existing work in this domain has mainly focused on recognizing a fixed set of words in word-segmented lip videos, which limits the applicability of the learned model due to limited vocabulary and high dependency on the model’s recognition performance. Our contribution is twofold: (1) we develop a pipeline for recognition-free retrieval and show its performance against recognition-based retrieval on a large-scale dataset and another set of out-of-vocabulary words. (2) We introduce a query expansion technique using pseudo-relevant feedback and propose a novel re-ranking method based on maximizing the correlation between spatiotemporal landmarks of the query and the top retrieval candidates. Our word spotting method achieves 35 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:48xauSegjOkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"The prohibitive amounts of time required to review the large amounts of data captured by surveillance and other cameras has brought into question the very utility of large scale video logging. Yet, one recognizes that such logging and analysis are indispensable to security applications. The only way out of this paradox is to devise expedited browsing, by the creation of hyperlapse. We address the hyperlapse problem for the very challenging category of intensive egomotion which makes the hyperlapse highly jerky. We propose an economical approach for trajectory estimation based on Visual Odometry and implement cost functions to penalize pose and path deviations. Also, this is implemented on data taken by omni-directional camera, so that the viewer can opt to observe any direction while browsing. This requires many innovations, including handling the massive radial distortions and implementing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:vDZJ-YLwNdEC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Convolutional layers convolve the input feature maps to generate valuable output features, and they help deep learning methods significantly in solving complex problems. In order to tackle problems efficiently, deep learning solutions should ensure that the parameters of the model do not increase significantly with the complexity of the problem. Pointwise convolutions are primarily used for parameter reduction in many deep learning architectures. They are convolutional filters of kernel size 1× 1. The pointwise convolution, however, ignores the spatial information around the points it is processing. This design is by choice, in order to reduce the overall parameters and computations. However, we hypothesize that this shortcoming of pointwise convolution has a significant impact on network performance. We propose a novel alternative design for pointwise convolution, which uses spatial information from the input …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:SnGPuo6Feq8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"This paper proposes a video editor based on OpenShot with several state-of-the-art facial video editing algorithms as added functionalities. Our editor provides an easy-to-use interface to apply modern lip-syncing algorithms interactively. Apart from lip-syncing, the editor also uses audio and facial re-enactment to generate expressive talking faces. The manual control improves the overall experience of video editing without missing out on the benefits of modern synthetic video generation algorithms. This control enables us to lip-sync complex dubbed movie scenes, interviews, television shows, and other visual content. Furthermore, our editor provides features that automatically translate lectures from spoken content, lip-sync of the professor, and background content like slides. While doing so, we also tackle the critical aspect of synchronizing background content with the translated speech. We qualitatively evaluate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:HJSXoJQnj-YC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Adaptation of a classifier to new domains is one of the challenging problems in machine learning. This has been addressed using many deep and non-deep learning based methods. Among the methodologies used, that of adversarial learning is widely applied to solve many deep learning problems along with domain adaptation. These methods are based on a discriminator that ensures source and target distributions are close. However, here we suggest that rather than using a point estimate obtaining by a single discriminator, it would be useful if a distribution based on ensembles of discriminators could be used to bridge this gap. This could be achieved using multiple classifiers or using traditional ensemble methods. In contrast, we suggest that a Monte Carlo dropout based ensemble discriminator could suffice to obtain the distribution based discriminator. Specifically, we propose a curriculum based dropout …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:EPG8bYD4jVwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Many performance improvement techniques calibrate the outputs of convolutional layers to improve the performance of convolutional neural networks, e.g., Squeeze-and-Excitation Networks (SENets). These techniques train the network to extract calibration weights from the input itself. However, these methods increase the complexity of the model in order to perform calibration. We propose an approach to calibrate the outputs of convolutional layers efficiently. Specifically, we propose an architectural block called Accuracy Booster, which calibrates the convolutional layer outputs channel-wise while introducing minimal extra parameters and computation. We experimentally show that our approach achieves higher performance than existing calibration methods over several datasets and architectures while introducing lesser parameters than them. We also generalize our proposed block to calibrate the channel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:oi2SiIJ9l4AC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we propose a method for obtaining sentence-level embeddings. While the problem of obtaining word-level embeddings is very well studied, we propose a novel method for obtaining sentence-level embeddings. This is obtained by a simple method in the context of solving the paraphrase generation task. If we use a sequential encoder-decoder model for generating paraphrase, we would like the generated paraphrase to be semantically close to the original sentence. One way to ensure this is by adding constraints for true paraphrase embeddings to be close and unrelated paraphrase candidate sentence embeddings to be far. This is ensured by using a sequential pair-wise discriminator that shares weights with the encoder. This discriminator is trained with a suitable loss function. Our loss function penalizes paraphrase sentence embedding distances from being too large. This loss is used in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:XUvXOeBm_78C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"A few-shot learning model generally consists of a feature extraction network and a classification module. In this paper, we propose an approach to improve few-shot image classification performance by increasing the representational capacity of the feature extraction network and improving the quality of the features extracted by it. The ability of the feature extraction network to extract highly discriminative features from images is essential to few-shot learning. Such features are generally class agnostic and contain information about the general content of the image. Our approach improves the training of the feature extraction network in order to enable them to produce such features. We train the network using filter-grafting along with an auxiliary self-supervision task and a knowledge distillation procedure. Particularly, filter-grafting rejuvenates unimportant (invalid) filters in the feature extraction network to make them …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:Dem6FJhTUoYC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Multi-task learning (MTL) using convolutional neural networks (CNN) deals with training the network for multiple correlated tasks in concert. For accuracy-critical applications, there are endeavors to boost the model performance by resorting to a deeper network, which also increases the model complexity. However, such burdensome models are difficult to be deployed on mobile or edge devices. To ensure a trade-off between performance and complexity of CNNs in the context of MTL, we introduce the novel paradigm of self-distillation within the network. Different from traditional knowledge distillation (KD), which trains the Student in accordance with a cumbersome Teacher, our self-distilled multi-task CNN model: SD-MTCNN aims at distilling knowledge from deeper CNN layers into the shallow layers. Precisely, we follow a hard-sharing based MTL setup where all the tasks share a generic feature-encoder on top of which separate task-specific decoders are enacted. Under this premise, SD-MTCNN distills the more abstract features from the decoders to the encoded feature space, which guarantees improved multi-task performance from different parts of the network. We validate SDMTCNN on three benchmark datasets: CityScapes, NYUv2, and Mini-Taskonomy, and results confirm the improved generalization capability of self-distilled multi-task CNNs in comparison to the literature and baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:OBSaB-F7qqsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"This work proposes a novel method to generate realistic talking head videos using audio and visual streams. We animate a source image by transferring head motion from a driving video using a dense motion field generated using learnable keypoints. We improve the quality of lip sync using audio as an additional input, helping the network to attend to the mouth region. We use additional priors using face segmentation and face mesh to improve the structure of the reconstructed faces. Finally, we improve the visual quality of the generations by incorporating a carefully designed identity-aware generator module. The identity-aware generator takes the source image and the warped motion features as input to generate a high-quality output with fine-grained details. Our method produces state-of-the-art results and generalizes well to unseen faces, languages, and voices. We comprehensively evaluate our approach using multiple metrics and outperforming the current techniques both qualitative and quantitatively. Our work opens up several applications, including enabling low bandwidth video calls. We release a demo video and additional information at http://cvit. iiit. ac. in/research/projects/cvit-projects/avfr",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:qwy9JoKyICEC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We aim to solve the highly challenging task of generating continuous sign language videos solely from speech segments for the first time. Recent efforts in this space have focused on generating such videos from human-annotated text transcripts without considering other modalities. However, replacing speech with sign language proves to be a practical solution while communicating with people suffering from hearing loss. Therefore, we eliminate the need of using text as input and design techniques that work for more natural, continuous, freely uttered speech covering an extensive vocabulary. Since the current datasets are inadequate for generating sign language directly from speech, we collect and release the first Indian sign language dataset comprising speech-level annotations, text transcripts, and the corresponding sign-language videos. Next, we propose a multi-tasking transformer network trained to generate signer's poses from speech segments. With speech-to-text as an auxiliary task and an additional cross-modal discriminator, our model learns to generate continuous sign pose sequences in an end-to-end manner. Extensive experiments and comparisons with other baselines demonstrate the effectiveness of our approach. We also conduct additional ablation studies to analyze the effect of different modules of our network. A demo video containing several results is attached to the supplementary material.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:eO3_k5sD8BwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Convolutional Neural Networks (CNNs) have been successfully applied for relative camera pose estimation from labeled image-pair data, without requiring any handengineered features, camera intrinsic parameters or depth information. The trained CNN can be utilized for performing pose based visual servo control (PBVS). One of the ways to improve the quality of visual servo output is to improve the accuracy of the CNN for estimating the relative pose estimation. With a given state-of-the-art CNN for relative pose regression, how can we achieve an improved performance for visual servo control? In this paper, we explore switching of CNNs to improve the precision of visual servo control. The idea of switching a CNN is due to the fact that the dataset for training a relative camera pose regressor for visual servo control must contain variations in relative pose ranging from a very small scale to eventually a larger scale …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:KaMxkj08jr0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"We present a determinantal point process (DPP) inspired alternative to non-maximum suppression (NMS) which has become an integral step in all state-of-the-art object detection frameworks. DPPs have been shown to encourage diversity in subset selection problems. We pose NMS as a subset selection problem and posit that directly incorporating DPP like framework can improve the overall performance of the object detection system. We propose an optimization problem which takes the same inputs as NMS, but introduces a novel sub-modularity based diverse subset selection functional. Our results strongly indicate that the modifications proposed in this paper can provide consistent improvements to state-of-the-art object detection pipelines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:HGTzPopzzJcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"In this paper, we consider the problem of solving semantic tasks such as `Visual Question Answering' (VQA), where one aims to answers related to an image and `Visual Question Generation' (VQG), where one aims to generate a natural question pertaining to an image. Solutions for VQA and VQG tasks have been proposed using variants of encoder-decoder deep learning based frameworks that have shown impressive performance. Humans however often show generalization by relying on exemplar based approaches. For instance, the work by Tversky and Kahneman suggests that humans use exemplars when making categorizations and decisions. In this work, we propose the incorporation of exemplar based approaches towards solving these problems. Specifically, we incorporate exemplar based approaches and show that an exemplar based module can be incorporated in almost any of the deep learning architectures proposed in the literature and the addition of such a block results in improved performance for solving these tasks. Thus, just as the incorporation of attention is now considered de facto useful for solving these tasks, similarly, incorporating exemplars also can be considered to improve any proposed architecture for solving this task. We provide extensive empirical analysis for the same through various architectures, ablations, and state of the art comparisons.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:L1USKYWJimsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Recent advances in reinforcement learning have proved that given an environment we can learn to perform a task in that environment if we have access to some form of a reward function (dense, sparse or derived from IRL). But most of the algorithms focus on learning a single best policy to perform a given set of tasks. In this paper, we focus on an algorithm that learns to not just perform a task but different ways to perform the same task. As we know when the environment is complex enough there always exists multiple ways to perform a task. We show that using the concept of information maximization it is possible to learn latent codes for discovering multiple ways to perform any given task in an environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:cK4Rrx0J3m0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",27,"Understanding videos of people speaking across international borders is hard as audiences from different demographies do not understand the language. Such speech videos are often supplemented with language subtitles. However, these hamper the viewing experience as the attention is shared. Simple audio dubbing in a different language makes the video appear unnatural due to unsynchronized lip motion. In this paper, we propose a system for automated cross-language lip synchronization for re-dubbed videos. Our model generates superior photorealistic lip-synchronization over original video in comparison to the current re-dubbing method. With the help of a user-based study, we verify that our method is preferred over unsynchronized videos.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&citation_for_view=JyHi9OoAAAAJ:43bX7VzcjpAC,https://vinaypn.github.io/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&citation_for_view=D50grEgAAAAJ:qmtmRrLr0tkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Paraphrase generation is an important problem in NLP, especially in question answering, information retrieval, information extraction, conversation systems, to name a few. In this paper, we address the problem of generating paraphrases automatically. Our proposed method is based on a combination of deep generative models (VAE) with sequence-to-sequence models (LSTM) to generate paraphrases, given an input sentence. Traditional VAEs when combined with recurrent neural networks can generate free text but they are not suitable for paraphrase generation for a given sentence. We address this problem by conditioning the both, encoder and decoder sides of VAE, on the original sentence, so that it can generate the given sentence's paraphrases. Unlike most existing models, our model is simple, modular and can generate multiple paraphrases, for a given sentence. Quantitative evaluation of the proposed method on a benchmark paraphrase dataset demonstrates its efficacy, and its performance improvement over the state-of-the-art methods by a significant margin, whereas qualitative human evaluation indicate that the generated paraphrases are well-formed, grammatically correct, and are relevant to the input sentence. Furthermore, we evaluate our method on a newly released question paraphrase dataset, and establish a new baseline for future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&citation_for_view=D50grEgAAAAJ:X0DADzN9RKwC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a deep generative model for Zero-Shot Learning (ZSL). Unlike most existing methods for this problem, that represent each class as a point (via a semantic embedding), we represent each seen/unseen class using a class-specific latent-space distribution, conditioned on class attributes. We use these latent-space distributions as a prior for a supervised variational autoencoder (VAE), which also facilitates learning highly discriminative feature representations for the inputs. The entire framework is learned end-to-end using only the seen-class training data. At test time, the label for an unseen-class test input is the class that maximizes the VAE lower bound. We further extend the model to a (i) semi-supervised/transductive setting by leveraging unlabeled unseen-class data via an unsupervised learning module, and (ii) few-shot learning where we also have a small number of labeled inputs from the unseen classes. We compare our model with several state-of-the-art methods through a comprehensive set of experiments on a variety of benchmark data sets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&citation_for_view=D50grEgAAAAJ:2vr6o8x5NLkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a generative framework for zero-shot action recognition where some of the possible action classes do not occur in the training data. Our approach is based on modeling each action class using a probability distribution whose parameters are functions of the attribute vector representing that action class. In particular, we assume that the distribution parameters for any action class in the visual space can be expressed as a linear combination of a set of basis vectors where the combination weights are given by the attributes of the action class. These basis vectors can be learned solely using labeled data from the known (i.e., previously seen) action classes, and can then be used to predict the parameters of the probability distributions of unseen action classes. We consider two settings: (1) Inductive setting, where we use only the labeled examples of the seen action classes to predict the unseen action class …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&citation_for_view=D50grEgAAAAJ:pQTOvowfQioC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Word embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings. SynGCN utilizes the dependency context of a word without increasing the vocabulary size. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both models available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&citation_for_view=D50grEgAAAAJ:KTwcwpFFj4wC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a novel deep learning architecture in which the convolution operation leverages heterogeneous kernels. The proposed HetConv (Heterogeneous Kernel-Based Convolution) reduces the computation (FLOPs) and the number of parameters as compared to standard convolution operation while still maintaining representational efficiency. To show the effectiveness of our proposed convolution, we present extensive experimental results on the standard convolutional neural network (CNN) architectures such as VGG and ResNet. We find that after replacing the standard convolutional filters in these architectures with our proposed HetConv filters, we achieve 3X to 8X FLOPs based improvement in speed while still maintaining (and sometimes improving) the accuracy. We also compare our proposed convolutions with group/depth wise convolutions and show that it achieves more FLOPs reduction with significantly higher accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&citation_for_view=D50grEgAAAAJ:7H_jS4BsgvYC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Stochastic blockmodels (SBM) and their variants, , mixed-membership and overlapping stochastic blockmodels, are latent variable based generative models for graphs. They have proven to be successful for various tasks, such as discovering the community structure and link prediction on graph-structured data. Recently, graph neural networks, , graph convolutional networks, have also emerged as a promising approach to learn powerful representations (embeddings) for the nodes in the graph, by exploiting graph properties such as locality and invariance. In this work, we unify these two directions by developing a sparse variational autoencoder for graphs, that retains the interpretability of SBMs, while also enjoying the excellent predictive performance of graph neural nets. Moreover, our framework is accompanied by a fast recognition model that enables fast inference of the node embeddings (which are of independent interest for inference in SBM and its variants). Although we develop this framework for a particular type of SBM, namely the overlapping stochastic blockmodel, the proposed framework can be adapted readily for other types of SBMs. Experimental results on several benchmarks demonstrate encouraging results on link prediction while learning an interpretable latent structure that can be used for community discovery.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&citation_for_view=D50grEgAAAAJ:RMgMIBzvq-4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a filter correlation based model compression approach for deep convolutional neural networks. Our approach iteratively identifies pairs of filters with the largest pairwise correlations and drops one of the filters from each such pair. However, instead of discarding one of the filters from each such pair naively, the model is re-optimized to make the filters in these pairs maximally correlated, so that discarding one of the filters from the pair results in minimal information loss. Moreover, after discarding the filters in each round, we further finetune the model to recover from the potential small loss incurred by the compression. We evaluate our proposed approach using a comprehensive set of experiments and ablation studies. Our compression method yields state-of-the-art FLOPs compression rates on various benchmarks, such as LeNet-5, VGG-16, and ResNet-50, 56, while still achieving excellent predictive performance for tasks such as object detection on benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&citation_for_view=D50grEgAAAAJ:hNSvKAmkeYkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Learning to classify unseen class samples at test time is popularly referred to as zero-shot learning (ZSL). If test samples can be from training (seen) as well as unseen classes, it is a more challenging problem due to the existence of strong bias towards seen classes. This problem is generally known as generalized zero-shot learning (GZSL). Thanks to the recent advances in generative models such as VAEs and GANs, sample synthesis based approaches have gained considerable attention for solving this problem. These approaches are able to handle the problem of class bias by synthesizing unseen class samples. However, these ZSL/GZSL models suffer due to the following key limitations:(i) Their training stage learns a class-conditioned generator using only seen class data and the training stage does not explicitly learn to generate the unseen class samples;(ii) They do not learn a generic optimal parameter which can easily generalize for both seen and unseen class generation; and (iii) If we only have access to a very few samples per seen class, these models tend to perform poorly. In this paper, we propose a meta-learning based generative model that naturally handles these limitations. The proposed model is based on integrating model-agnostic meta learning with a Wasserstein GAN (WGAN) to handle (i) and (iii), and uses a novel task distribution to handle (ii). Our proposed model yields significant improvements on standard ZSL as well as more challenging GZSL setting. In ZSL setting, our model yields 4.5%, 6.0%, 9.8%, and 27.9% relative improvements over the current state-of-the-art on CUB, AWA1, AWA2, and aPY datasets …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&citation_for_view=D50grEgAAAAJ:9shLKfS_uJEC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"While convolutional neural networks (CNN) have achieved impressive performance on various classification/recognition tasks, they typically consist of a massive number of parameters. This results in significant memory requirement as well as computational overheads. Consequently, there is a growing need for filter-level pruning approaches for compressing CNN based models that not only reduce the total number of parameters but reduce the overall computation as well. We present a new min-max framework for filter-level pruning of CNNs. Our framework, called Play and Prune (PP), jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance. Our framework consists of two modules: (1) An adaptive filter pruning (AFP) module, which minimizes the number of filters in the model; and (2) A pruning rate controller (PRC) module, which maximizes the accuracy during pruning. Moreover, unlike most previous approaches, our approach allows directly specifying the desired error tolerance instead of pruning level. Our compressed models can be deployed at run-time, without requiring any special libraries or hardware. Our approach reduces the number of parameters of VGG-16 by an impressive factor of 17.5X, and number of FLOPS by 6.43X, with no loss of accuracy, significantly outperforming other state-of-the-art filter pruning methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:Y0-TYkg6YM4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present an approach for lifelong/continual learning of convolutional neural networks (CNN) that does not suffer from the problem of catastrophic forgetting when moving from one task to the other. We show that the activation maps generated by the CNN trained on the old task can be calibrated using very few calibration parameters, to become relevant to the new task. Based on this, we calibrate the activation maps produced by each network layer using spatial and channel-wise calibration modules and train only these calibration parameters for each new task in order to perform lifelong learning. Our calibration modules introduce significantly less computation and parameters as compared to the approaches that dynamically expand the network. Our approach is immune to catastrophic forgetting since we store the task-adaptive calibration parameters, which contain all the task-specific knowledge and is exclusive to each task. Further, our approach does not require storing data samples from the old tasks, which is done by many replay based methods. We perform extensive experiments on multiple benchmark datasets (SVHN, CIFAR, ImageNet, and MS-Celeb), all of which show substantial improvements over state-of-the-art methods (eg, a 29% absolute increase in accuracy on CIFAR-100 with 10 classes at a time). On large-scale datasets, our approach yields 23.8% and 9.7% absolute increase in accuracy on ImageNet-100 and MS-Celeb-10K datasets, respectively, by employing very few (0.51% and 0.35% of model parameters) task-adaptive calibration parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:as0KMg8qHbkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Many real-world classification problems often have classes with very few labeled training samples. Moreover, all possible classes may not be initially available for training, and may be given incrementally. Deep learning models need to deal with this two-fold problem in order to perform well in real-life situations. In this paper, we propose a novel Few-Shot Lifelong Learning (FSLL) method that enables deep learning models to perform lifelong/continual learning on few-shot data. Our method selects very few parameters from the model for training every new set of classes instead of training the full model. This helps in preventing overfitting. We choose the few parameters from the model in such a way that only the currently unimportant parameters get selected. By keeping the important parameters in the model intact, our approach minimizes catastrophic forgetting. Furthermore, we minimize the cosine similarity between the new and the old class prototypes in order to maximize their separation, thereby improving the classification performance. We also show that integrating our method with self-supervision improves the model performance significantly. We experimentally show that our method significantly outperforms existing methods on the miniImageNet, CIFAR-100, and CUB-200 datasets. Specifically, we outperform the state-of-the-art method by an absolute margin of 19.27% for the CUB dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:X4-KO54GjGYC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present an attention-based ranking framework for learning to order sentences given a paragraph. Our framework is built on a bidirectional sentence encoder and a self-attention based transformer network to obtain an input order invariant representation of paragraphs. Moreover, it allows seamless training using a variety of ranking based loss functions, such as pointwise, pairwise, and listwise ranking. We apply our framework on two tasks: Sentence Ordering and Order Discrimination. Our framework outperforms various state-of-the-art methods on these tasks on a variety of evaluation metrics. We also show that it achieves better results when using pairwise and listwise ranking losses, rather than the pointwise ranking loss, which suggests that incorporating relative positions of two or more sentences in the loss function contributes to better learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:BAanoTsO0WEC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"As neural networks are increasingly being applied to real-world applications, mechanisms to address distributional shift and sequential task learning without forgetting are critical. Methods incorporating network expansion have shown promise by naturally adding model capacity for learning new tasks while simultaneously avoiding catastrophic forgetting. However, the growth in the number of additional parameters of many of these types of methods can be computationally expensive at larger scales, at times prohibitively so. Instead, we propose a simple task-specific feature map transformation strategy for continual learning, which we call Efficient Feature Transformations (EFTs). These EFTs provide powerful flexibility for learning new tasks, achieved with minimal parameters added to the base architecture. We further propose a feature distance maximization strategy, which significantly improves task prediction in class incremental settings, without needing expensive generative models. We demonstrate the efficacy and efficiency of our method with an extensive set of experiments in discriminative (CIFAR-100 and ImageNet-1K) and generative (LSUN, CUB-200, Cats) sequences of tasks. Even with low single-digit parameter growth rates, EFTs can outperform many other continual learning methods in a wide range of settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:e84hm74t-eoC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Diffusion Probabilistic models have been shown to generate state-of-the-art results on several competitive image synthesis benchmarks but lack a low-dimensional, interpretable latent space, and are slow at generation. On the other hand, Variational Autoencoders (VAEs) typically have access to a low-dimensional latent space but exhibit poor sample quality. Despite recent advances, VAEs usually require high-dimensional hierarchies of the latent codes to generate high-quality samples. We present DiffuseVAE, a novel generative framework that integrates VAE within a diffusion model framework, and leverage this to design a novel conditional parameterization for diffusion models. We show that the resulting model can improve upon the unconditional diffusion model in terms of sampling efficiency while also equipping diffusion models with the low-dimensional VAE inferred latent code. Furthermore, we show that the proposed model can generate high-resolution samples and exhibits synthesis quality comparable to state-of-the-art models on standard benchmarks. Lastly, we show that the proposed method can be used for controllable image synthesis and also exhibits out-of-the-box capabilities for downstream tasks like image super-resolution and denoising. For reproducibility, our source code is publicly available at \url{https://github.com/kpandey008/DiffuseVAE}.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:rFyVMFCKTwsC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Simple weighted averaging of word vectors often yields effective representations for sentences which outperform sophisticated seq2seq neural models in many tasks. While it is desirable to use the same method to represent documents as well, unfortunately, the effectiveness is lost when representing long documents involving multiple sentences. One of the key reasons is that a longer document is likely to contain words from many different topics; hence, creating a single vector while ignoring all the topical structure is unlikely to yield an effective document representation. This problem is less acute in single sentences and other short text fragments where the presence of a single topic is most likely. To alleviate this problem, we present P-SIF, a partitioned word averaging model to represent long documents. P-SIF retains the simplicity of simple weighted word averaging while taking a document's topical structure into account. In particular, P-SIF learns topic-specific vectors from a document and finally concatenates them all to represent the overall document. We provide theoretical justifications on the correctness of P-SIF. Through a comprehensive set of experiments, we demonstrate P-SIF's effectiveness compared to simple weighted averaging and many other baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:Y9VhQm-5nPIC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Deep learning models suffer from catastrophic forgetting when trained in an incremental learning setting. In this work, we propose a novel approach to address the task incremental learning problem, which involves training a model on new tasks that arrive in an incremental manner. The task incremental learning problem becomes even more challenging when the test set contains classes that are not part of the train set, ie, a task incremental generalized zero-shot learning problem. Our approach can be used in both the zero-shot and non zero-shot task incremental learning settings. Our proposed method uses weight rectifications and affine transformations in order to adapt the model to different tasks that arrive sequentially. Specifically, we adapt the network weights to work for new tasks by"" rectifying"" the weights learned from the previous task. We learn these weight rectifications using very few parameters. We additionally learn affine transformations on the outputs generated by the network in order to better adapt them for the new task. We perform experiments on several datasets in both zero-shot and non zero-shot task incremental learning settings and empirically show that our approach achieves state-of-the-art results. Specifically, our approach outperforms the state-of-the-art non zero-shot task incremental learning method by over 5% on the CIFAR-100 dataset. Our approach also significantly outperforms the state-of-the-art task incremental generalized zero-shot learning method by absolute margins of 6.91% and 6.33% for the AWA1 and CUB datasets, respectively. We validate our approach using various ablation studies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:RfUwGJFMQ-0C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a domain adaptation based generative framework for zero shot learning. We address the problem of domain shift between the seen and unseen class distribution in Zero-Shot Learning (ZSL) and seek to minimize it by developing a generative model and training it via adversarial domain adaptation. Our approach is based on end-to-end learning of the class distributions of seen classes and unseen classes. To enable the model to learn the class distributions of unseen classes, we parameterize these class distributions in terms of the class attribute information (which is available for both seen and unseen classes). This provides a very simple way to learn the class distribution of any unseen class, given only its class attribute information, and no labeled training data. Training this model with adversarial domain adaptation provides robustness against the distribution mismatch between the data from seen and unseen classes. It also engenders a novel way for training neural net based classifiers to overcome the hubness problem in Zero-Shot learning. Through a comprehensive set of experiments, we show that our model yields superior accuracies as compared to various state-of-the-art zero shot learning models, on a variety of benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:TesyEGJKHF4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a label embedding based approach to large-scale multi-label learning, drawing inspiration from ideas rooted in distributional semantics, specifically the Skip Gram Negative Sampling (SGNS) approach, widely used to learn word embeddings. Besides leading to a highly scalable model for multi-label learning, our approach highlights interesting connections between label embedding methods commonly used for multi-label learning and paragraph embedding methods commonly used for learning representations of text data. The framework easily extends to incorporating auxiliary information such as label-label correlations; this is crucial especially when many training instances are only partially annotated. To facilitate end-to-end learning, we develop a joint learning algorithm that can learn the embeddings as well as a regression model that predicts these embeddings for the new input to be annotated, via efficient gradient based methods. We demonstrate the effectiveness of our approach through an extensive set of experiments on a variety of benchmark datasets, and show that the proposed models perform favorably as compared to state-of-the-art methods for large-scale multi-label learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:W2uZP3ddy8sC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a probabilistic framework for community discovery and link prediction for graph-structured data, based on a novel, gamma ladder variational autoencoder (VAE) architecture. We model each node in the graph via a deep hierarchy of gamma-distributed embeddings, and define each link probability via a nonlinear function of the bottom-most layer's embeddings of its associated nodes. In addition to leveraging the representational power of multiple layers of stochastic variables via the ladder VAE architecture, our framework offers the following benefits:(1) Unlike existing ladder VAE architectures based on real-valued latent variables, the gamma-distributed latent variables naturally result in non-negativity and sparsity of the learned embeddings, and facilitate their direct interpretation as membership of nodes into (possibly multiple) communities/topics;(2) A novel recognition model for our gamma ladder VAE architecture allows fast inference of node embeddings; and (3) The framework also extends naturally to incorporate node side information (features and/or labels). Our framework is also fairly modular and can leverage a wide variety of graph neural networks as the VAE encoder. We report both quantitative and qualitative results on several benchmark datasets and compare our model with several state-of-the-art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:3lUAU8Oskd0C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Continual Learning is a learning paradigm where learning systems are trained on a sequence of tasks. The goal here is to perform well on the current task without suffering from a performance drop on the previous tasks. Two notable directions among the recent advances in continual learning with neural networks are (1) variational Bayes based regularization by learning priors from previous tasks, and,(2) learning the structure of deep networks to adapt to new tasks. So far, these two approaches have been largely orthogonal. We present a novel Bayesian framework based on continually learning the structure of deep neural networks, to unify these distinct yet complementary approaches. The proposed framework learns the deep structure for each task by learning which weights to be used, and supports inter-task transfer through the overlapping of different sparse subsets of weights learned by different tasks. An appealing aspect of our proposed continual learning framework is that it is applicable to both discriminative (supervised) and generative (unsupervised) settings. Experimental results on supervised and unsupervised benchmarks demonstrate that our approach performs comparably or better than recent advances in continual learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:BJtnxTr0fRcC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"While convolutional neural networks (CNNs) have achieved remarkable performance on various supervised and unsupervised learning tasks, they typically consist of a massive number of parameters. This results in significant memory requirements as well as a computational burden. Consequently, there is a growing need for filter-level pruning approaches for compressing CNN based models that not only reduce the total number of parameters but reduce the overall computation as well. We present a new min-max framework for the filter-level pruning of CNNs. Our framework jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance. Our framework consists of two modules: (1) An adaptive filter pruning (AFP) module, which minimizes the number of filters in the model; and (2) A pruning rate controller (PRC) module, which maximizes the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:JH5k92_tO-AC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a probabilistic model for Sketch-Based Image Retrieval (SBIR) where, at retrieval time, we are given sketches from novel classes, that were not present at training time. Existing SBIR methods, most of which rely on learning class-wise correspondences between sketches and images, typically work well only for previously seen sketch classes, and result in poor retrieval performance on novel classes. To address this, we propose a generative model that learns to generate images, conditioned on a given novel class sketch. This enables us to reduce the SBIR problem to a standard image-to-image search problem. Our model is based on an inverse auto-regressive flow based variational autoencoder, with a feedback mechanism to ensure robust image generation. We evaluate our model on two very challenging datasets, Sketchy, and TU Berlin, with novel train-test split. The proposed approach significantly outperforms various baselines on both the datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:vVJNg6_NJEsC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"In Test-time Adaptation (TTA), given a model trained on some source data, the goal is to adapt it to make better predictions for test instances from a different distribution. Crucially, TTA assumes no access to the source data or even any additional labeled/unlabeled samples from the target distribution to finetune the source model. In this work, we consider TTA in a more pragmatic setting which we refer to as SITA (Single Image Test-time Adaptation). Here, when making each prediction, the model has access only to the given \emph{single} test instance, rather than a \emph{batch} of instances, as has typically been considered in the literature. This is motivated by the realistic scenarios where inference is needed in an on-demand fashion that may not be delayed to ""batch-ify"" incoming requests or the inference is happening on an edge device (like mobile phone) where there is no scope for batching. The entire adaptation process in SITA should be extremely fast as it happens at inference time. To address this, we propose a novel approach AugBN for the SITA setting that requires only forward propagation. The approach can adapt any off-the-shelf trained model to individual test instances for both classification and segmentation tasks. AugBN estimates normalisation statistics of the unseen test distribution from the given test image using only one forward pass with label-preserving transformations. Since AugBN does not involve any back-propagation, it is significantly faster compared to other recent methods. To the best of our knowledge, this is the first work that addresses this hard adaptation problem using only a single test image. Despite being very …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:9LpHyFPp1DQC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a probabilistic, fully Bayesian framework for multi-label learning. Our framework is based on the idea of learning a joint low-rank embedding of the label matrix and the label co-occurrence matrix. The proposed framework has the following appealing aspects:(1) It leverages the sparsity in the label matrix and the feature matrix, which results in very efficient inference, especially for sparse datasets, commonly encountered in multi-label learning problems, and (2) By effectively utilizing the label co-occurrence information, the model yields improved prediction accuracies, especially in the case where the amount of training data is low and/or the label matrix has a significant fraction of missing labels. Our framework enjoys full local conjugacy and admits a simple inference procedure via a scalable Gibbs sampler. We report experimental results on a number of benchmark datasets, on which it outperforms several state-of-the-art multi-label learning models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:c59VksA5Vz4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a meta-learning based generative model for zero-shot learning (ZSL) towards a challenging setting when the number of training examples from each seen class is very few. This setup is in contrast to the conventional ZSL approaches, where training typically assumes the availability of a sufficiently large number of training examples from each of the seen classes. The proposed approach leverages meta-learning to train a deep generative model that integrates variational autoencoder an generative adversarial network. To simulate the ZSL behaviour in training, we propose a novel task distribution where meta-train and meta-validation classes are disjoint. Once trained, the model can generate synthetic examples from seen and unseen classes. Synthesize samples can then be used to train the ZSL framework in a supervised manner. The meta-learner enables our model to generates high-fidelity samples using only a small number of training examples from seen classes. We conduct extensive experiments and ablation studies on four benchmark datasets of ZSL and observe that the proposed model outperforms state-of-the-art approaches by a significant margin when the number of examples per seen class is very small.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:idthP5jqfYAC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"While usage of convolutional neural networks (CNN) is widely prevalent, methods proposed so far always have considered homogeneous kernels for this task. In this paper, we propose a new type of convolution operation using heterogeneous kernels. The proposed Heterogeneous Kernel-Based Convolution (HetConv) reduces the computation (FLOPs) and the number of parameters as compared to standard convolution operation while it maintains representational efficiency. To show the effectiveness of our proposed convolution, we present extensive experimental results on the standard CNN architectures such as VGG, ResNet, Faster-RCNN, MobileNet, and SSD. We observe that after replacing the standard convolutional filters in these architectures with our proposed HetConv filters, we achieve 1.5  to 8  FLOPs based improvement in speed while it maintains (sometimes improves) the accuracy. We also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:U0iAMwwPxtsC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Many applications, such as text modelling, high-throughput sequencing, and recommender systems, require analysing sparse, high-dimensional, and overdispersed discrete (count or binary) data. Recent deep probabilistic models based on variational autoencoders (VAE) have shown promising results on discrete data but may have inferior modelling performance due to the insufficient capability in modelling overdispersion and model misspecification. To address these issues, we develop a VAE-based framework using the negative binomial distribution as the data distribution. We also provide an analysis of its properties vis-à-vis other models. We conduct extensive experiments on three problems from discrete data analysis: text analysis/topic modelling, collaborative filtering, and multi-label learning. Our models outperform state-of-the-art approaches on these problems, while also capturing the phenomenon of overdispersion more effectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:bVQMTfhMCi4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a continual learning approach for generative adversarial networks (GANs), by designing and leveraging parameter-efficient feature map transformations. Our approach is based on learning a set of global and task-specific parameters. The global parameters are fixed across tasks whereas the task-specific parameters act as local adapters for each task, and help in efficiently obtaining task-specific feature maps. Moreover, we propose an element-wise addition of residual bias in the transformed feature space, which further helps stabilize GAN training in such settings. Our approach also leverages task similarities based on the Fisher information matrix. Leveraging this knowledge from previous tasks significantly improves the model performance. In addition, the similarity measure also helps reduce the parameter growth in continual adaptation and helps to learn a compact model. In contrast to the recent approaches for continually-learned GANs, the proposed approach provides a memory-efficient way to perform effective continual data generation. Through extensive experiments on challenging and diverse datasets, we show that the feature-map-transformation approach outperforms state-of-the-art methods for continually-learned GANs, with substantially fewer parameters. The proposed method generates high-quality samples that can also improve the generative-replay-based continual learning for discriminative tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:T8_be82Iz5gC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Learning from data sequentially arriving, possibly in a non i.i.d. way, with changing task distribution over time is called continual learning. Much of the work thus far in continual learning focuses on supervised learning and some recent works on unsupervised learning. In many domains, each task contains a mix of labelled (typically very few) and unlabelled (typically plenty) training examples, which necessitates a semi-supervised learning approach. To address this in a continual learning setting, we propose a framework for semi-supervised continual learning called Meta-Consolidation for Continual Semi-Supervised Learning (MCSSL). Our framework has a hypernetwork that learns the meta-distribution that generates the weights of a semi-supervised auxiliary classifier generative adversarial network $(\textit{Semi-ACGAN})$ as the base network. We consolidate the knowledge of sequential tasks in the hypernetwork, and the base network learns the semi-supervised learning task. Further, we present $\textit{Semi-Split CIFAR-10}$, a new benchmark for continual semi-supervised learning, obtained by modifying the $\textit{Split CIFAR-10}$ dataset, in which the tasks with labelled and unlabelled data arrive sequentially. Our proposed model yields significant improvements in the continual semi-supervised learning setting. We compare the performance of several existing continual learning approaches on the proposed continual semi-supervised learning benchmark of the Semi-Split CIFAR-10 dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:wuD5JclIwkYC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Humans possess an innate ability to identify and differentiate instances that they are not familiar with, by leveraging and adapting the knowledge that they have acquired so far. Importantly, they achieve this without deteriorating the performance on their earlier learning. Inspired by this, we identify and formulate a new, pragmatic problem setting of NCDwF: Novel Class Discovery without Forgetting, which tasks a machine learning model to incrementally discover novel categories of instances from unlabeled data, while maintaining its performance on the previously seen categories. We propose 1) a method to generate pseudo-latent representations which act as a proxy for (no longer available) labeled data, thereby alleviating forgetting, 2) a mutual-information based regularizer which enhances unsupervised discovery of novel classes, and 3) a simple Known Class Identifier which aids generalized inference when …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:oYLFIHfuHKwC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a filter pruning approach for deep model compression, using a multitask network. Our approach is based on learning aa pruner network to prune a pre-trained target network. The pruner is essentially a multitask deep neural network with binary outputs that help identify the filters from each layer of the original network that do not have any significant contribution to the model and can therefore be pruned. The pruner network has the same architecture as the original network except that it has a multitask/multi-output last layer containing binary-valued outputs (one per filter), which indicate which filters have to be pruned. The pruner's goal is to minimize the number of filters from the original network by assigning zero weights to the corresponding output feature-maps. In contrast to most of the existing methods, instead of relying on iterative pruning, our approach can prune the network (original network) in one go and, moreover, does not require specifying the degree of pruning for each layer (and can learn it instead). The compressed model produced by our approach is generic and does not need any special hardware/software support. Moreover, augmenting with other methods such as knowledge distillation, quantization, and connection pruning can increase the degree of compression for the proposed approach. We show the efficacy of our proposed approach for classification and object detection tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:vnF2_uLGgtgC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Allowing effective inference of latent vectors while training GANs can greatly increase their applicability in various downstream tasks. Recent approaches, such as ALI and BiGAN frameworks, develop methods of inference of latent variables in GANs by adversarially training an image generator along with an encoder to match two joint distributions of image and latent vector pairs. We generalize these approaches to incorporate multiple layers of feedback on reconstructions, self-supervision, and other forms of supervision based on prior or learned knowledge about the desired solutions. We achieve this by modifying the discriminator's objective to correctly identify more than two joint distributions of tuples of an arbitrary number of random variables consisting of images, latent vectors, and other variables generated through auxiliary tasks, such as reconstruction and inpainting or as outputs of suitable pre-trained models. We design a non-saturating maximization objective for the generator-encoder pair and prove that the resulting adversarial game corresponds to a global optimum that simultaneously matches all the distributions. Within our proposed framework, we introduce a novel set of techniques for providing self-supervised feedback to the model based on properties, such as patch-level correspondence and cycle consistency of reconstructions. Through comprehensive experiments, we demonstrate the efficacy, scalability, and flexibility of the proposed approach for a variety of tasks. The appendix of the paper can be found at the following link: https://drive. google. com/file/d/1i99e682CqYWMEDXlnqkqrctGLVA9viiz/view? usp= sharing",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:Ej9njvOgR2oC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Recent works have shown that most deep learning models are often poorly calibrated, i.e., they may produce overconfident predictions that are wrong. It is therefore desirable to have models that produce predictive uncertainty estimates that are reliable. Several approaches have been proposed recently to calibrate classification models. However, there is relatively little work on calibrating regression models. We present a method for calibrating regression models based on a novel quantile regularizer defined as the cumulative KL divergence between two CDFs. Unlike most of the existing approaches for calibrating regression models, which are based on post-hoc processing of the model's output and require an additional dataset, our method is trainable in an end-to-end fashion without requiring an additional dataset. The proposed regularizer can be used with any training objective for regression. We also show that post-hoc calibration methods like Isotonic Calibration sometimes compound miscalibration whereas our method provides consistently better calibrations. We provide empirical results demonstrating that the proposed quantile regularizer significantly improves calibration for regression models trained using approaches, such as Dropout VI and Deep Ensembles.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:KI9T_ytC6pkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"In this work, we propose a modeling technique for jointly training image and video generation models by simultaneously learning to map latent variables with a fixed prior onto real images and interpolate over images to generate videos. The proposed approach models the variations in representations using residual vectors encoding the change at each time step over a summary vector for the entire video. We utilize the technique to jointly train an image generation model with a fixed prior along with a video generation model lacking constraints such as disentanglement. The joint training enables the image generator to exploit temporal information while the video generation model learns to flexibly share information across frames. Moreover, experimental results verify our approach's compatibility with pre-training on videos or images and training on datasets containing a mixture of both. A comprehensive set of quantitative and qualitative evaluations reveal the improvements in sample quality and diversity over both video generation and image generation baselines. We further demonstrate the technique's capabilities of exploiting similarity in features across frames by applying it to a model based on decomposing the video into motion and content. The proposed model allows minor variations in content across frames while maintaining the temporal dependence through latent vectors encoding the pose or motion features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:3A3nxV7CjKIC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"We present a probabilistic framework for multi-label learning based on a deep generative model for the binary label vector associated with each observation. Our generative model learns deep multi-layer latent embeddings of the binary label vector, which are conditioned on the input features of the observation. The model also has an interesting interpretation in terms of a deep topic model, with each label vector representing a bag-of-words document, with the input features being its meta-data. In addition to capturing the structural properties of the label space (eg, a near-low-rank label matrix), the model also offers a clean, geometric interpretation. In particular, the nonlinear classification boundaries learned by the model can be seen as the union of multiple convex polytopes. Our model admits a simple and scalable inference via efficient Gibbs sampling or EM algorithm. We compare our model with state-of-the-art baselines for multi-label learning on benchmark data sets, and also report some interesting qualitative results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:tz746QTLzJkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Novel Class Discovery (NCD) is a learning paradigm, where a machine learning model is tasked to semantically group instances from unlabeled data, by utilizing labeled instances from a disjoint set of classes. In this work, we first characterize existing NCD approaches into single-stage and two-stage methods based on whether they require access to labeled and unlabeled data together while discovering new classes. Next, we devise a simple yet powerful loss function that enforces separability in the latent space using cues from multi-dimensional scaling, which we refer to as Spacing Loss. Our proposed formulation can either operate as a standalone method or can be plugged into existing methods to enhance them. We validate the efficacy of Spacing Loss with thorough experimental evaluation across multiple settings on CIFAR-10 and CIFAR-100 datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:K4-iKlO5MD4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Mixture-of-Experts (MoE) enable learning highly nonlinear models by combining simple expert models. Each expert handles a small region of the data space, as dictated by the gating network which generates the (soft) assignment of input to the corresponding experts. Despite their flexibility and renewed interest lately, existing MoE constructions pose several difficulties during model training. Crucially, neither of the two popular gating networks used in MoE, namely the softmax gating network and hierarchical gating network (the latter used in the hierarchical mixture of experts), have efficient inference algorithms. The problem is further exacerbated if the experts do not have conjugate likelihood and lack a naturally probabilistic formulation (e.g., logistic regression or large-margin classifiers such as SVM). To address these issues, we develop novel inference algorithms with closed-form parameter updates …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:yeL6HyUMUGUC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Traditional collaborative filtering (CF) based recommender systems tend to perform poorly when the user-item interactions/ratings are highly scarce. To address this, we propose a learning framework that improves collaborative filtering with a synthetic feedback loop (CF-SFL) to simulate the user feedback. The proposed framework consists of a recommender and a virtual user. The recommender is formulated as a CF model, recommending items according to observed user preference. The virtual user estimates rewards from the recommended items and generates a feedback in addition to the observed user preference. The recommender connected with the virtual user constructs a closed loop, that recommends users with items and imitates the unobserved feedback of the users to the recommended items. The synthetic feedback is used to augment the observed user preference and improve recommendation results. Theoretically, such model design can be interpreted as inverse reinforcement learning, which can be learned effectively via rollout (simulation). Experimental results show that the proposed framework is able to enrich the learning of user preference and boost the performance of existing collaborative filtering methods on multiple datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:ukw-9cB-YDkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"The latent feature relational model (LFRM) is a generative model for graph-structured data to learn a binary vector representation for each node in the graph. The binary vector denotes the node's membership in one or more communities. At its core, the LFRM miller2009nonparametric is an overlapping stochastic blockmodel, which defines the link probability between any pair of nodes as a bilinear function of their community membership vectors. Moreover, using a nonparametric Bayesian prior (Indian Buffet Process) enables learning the number of communities automatically from the data. However, despite its appealing properties, inference in LFRM remains a challenge and is typically done via MCMC methods. This can be slow and may take a long time to converge. In this work, we develop a small-variance asymptotics based framework for the non-parametric Bayesian LFRM. This leads to an objective function that retains the nonparametric Bayesian flavor of LFRM, while enabling us to design deterministic inference algorithms for this model, that are easy to implement (using generic or specialized optimization routines) and are fast in practice. Our results on several benchmark datasets demonstrate that our algorithm is competitive to methods such as MCMC, while being much faster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:m4fbC6XIj1kC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Test-time adaptation is the problem of adapting a source pre-trained model using test inputs from a target domain without access to source domain data. Most of the existing approaches address the setting in which the target domain is stationary. Moreover, these approaches are prone to making erroneous predictions with unreliable uncertainty estimates when distribution shifts occur. Hence, test-time adaptation in the face of non-stationary target domain shift becomes a problem of significant interest. To address these issues, we propose a principled approach, PETAL (Probabilistic lifElong Test-time Adaptation with seLf-training prior), which looks into this problem from a probabilistic perspective using a partly data-dependent prior. A student-teacher framework, where the teacher model is an exponential moving average of the student model naturally emerges from this probabilistic perspective. In addition, the knowledge from the posterior distribution obtained for the source task acts as a regularizer. To handle catastrophic forgetting in the long term, we also propose a data-driven model parameter resetting mechanism based on the Fisher information matrix (FIM). Moreover, improvements in experimental results suggest that FIM based data-driven parameter restoration contributes to reducing the error accumulation and maintaining the knowledge of recent domain by restoring only the irrelevant parameters. In terms of predictive error rate as well as uncertainty based metrics such as Brier score and negative log-likelihood, our method achieves better results than the current state-of-the-art for online lifelong test time adaptation across various …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:a2necdfpwlEC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"For most existing federated learning algorithms, each round consists of minimizing a loss function at each client to learn an optimal model at the client, followed by aggregating these client models at the server. Point estimation of the model parameters at the clients does not take into account the uncertainty in the models estimated at each client. In many situations, however, especially in limited data settings, it is beneficial to take into account the uncertainty in the client models for more accurate and robust predictions. Uncertainty also provides useful information for other important tasks, such as active learning and out-of-distribution (OOD) detection. We present a framework for Bayesian federated learning where each client infers the posterior predictive distribution using its training data and present various ways to aggregate these client-specific predictive distributions at the server. Since communicating and aggregating predictive distributions can be challenging and expensive, our approach is based on distilling each client's predictive distribution into a single deep neural network. This enables us to leverage advances in standard federated learning to Bayesian federated learning as well. Unlike some recent works that have tried to estimate model uncertainty of each client, our work also does not make any restrictive assumptions, such as the form of the client's posterior distribution. We evaluate our approach on classification in federated setting, as well as active learning and OOD detection in federated settings, on which our approach outperforms various existing federated learning baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:wBLCggQE-ToC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"In this paper, we propose a new framework for fine-grained emotion prediction in the text through emotion definition modeling. Our approach involves a multi-task learning framework that models definitions of emotions as an auxiliary task while being trained on the primary task of emotion prediction. We model definitions using masked language modeling and class definition prediction tasks. Our models outperform existing state-of-the-art for fine-grained emotion dataset GoEmotions. We further show that this trained model can be used for transfer learning on other benchmark datasets in emotion prediction with varying emotion label sets, domains, and sizes. The proposed models outperform the baselines on transfer learning experiments demonstrating the generalization capability of the models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:inmFHauC9wsC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Presently, 17 out of 30 Indian cities are ranked worst in air quality around the globe due to high emissions of fine particulate matter, PM 2.5 (particles less than 2.5 µm diameter). These particles can reach deeper into the lungs and cause serious health problems, including cardiovascular obstructive pulmonary disease, lung cancer, stroke, and asthma. To take prompt actions towards mitigating and controlling the adverse effects of air pollution, it is important to monitor the ambient air quality regularly and at the neighbourhood level. However, the distribution of the regulatory central ambient air quality monitoring stations (CAAQMS) in India is sparse, and many states and cities lack any regulatory stationary monitors (RSMs). Conventional air quality monitoring techniques are inefficient and incapable of mapping PM 2.5 at a sub-Km level. The heterogeneity of PM 2.5 concentrations at large-scale and high spatial …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:VnuxuLaQPLMC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"Modern deep neural networks achieve excellent predictive performance due to their massive scale, flexible architecture design and availability of large training datasets. However, several applications additionally demand reliable estimates of model and predictive uncertainty that help in making robust predictions with limited training data, enabling out-of-distribution generalization, etc. Neural networks do not offer such uncertainly estimates out-of-the-box. Although Bayesian approaches to deep learning do provide a natural way to quantify model and predictive uncertainty by inferring the posterior distribution of the model weights and averaging the model’s predictions over the entire posterior distribution, standard Bayesian inference methods such as MCMC and variational inference are difficult to design and scale to massive networks. An appealing and popular alternative is to learn an ensemble of model weights …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:eFf2swCANGcC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",32,"In the task incremental learning problem, deep learning models suffer from catastrophic forgetting of previously seen classes/tasks as they are trained on new classes/tasks. This problem becomes even harder when some of the test classes do not belong to the training class set, i.e., the task incremental generalized zero-shot learning problem. We propose a novel approach to address the task incremental learning problem for both the non zero-shot and zero-shot settings. Our proposed approach, called Rectification-based Knowledge Retention (RKR), applies weight rectifications and affine transformations for adapting the model to any task. During testing, our approach can use the task label information (task-aware) to quickly adapt the network to that task. We also extend our approach to make it task-agnostic so that it can work even when the task label information is not available during testing. Specifically, given a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&citation_for_view=D50grEgAAAAJ:Nufq_to8ts0C,https://www.cse.iitk.ac.in/users/piyush/
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"Recent worldwide cybersecurity attacks caused by Cryptographic Ransomware infected systems across countries and organizations with millions of dollars lost in paying extortion amounts. This form of malicious software takes user files hostage by encrypting them and demands a large ransom payment for providing the decryption key. Signature-based methods employed by Antivirus Software are insufficient to evade Ransomware attacks due to code obfuscation techniques and creation of new polymorphic variants everyday. Generic Malware Attack vectors are also not robust enough for detection as they do not completely track the specific behavioral patterns shown by Cryptographic Ransomware families. This work based on analysis of an extensive dataset of Ran-somware families presents RansomWall, a layered defense system for protection against Cryptographic Ransomware. It follows a Hybrid approach of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&citation_for_view=XxeF6MkAAAAJ:P5F9QuxV20EC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"One major shortcoming of permissionless blockchains such as Bitcoin and Ethereum is that they are unsuitable for running Computationally Intensive smart Contracts (CICs). This prevents such blockchains from running Machine Learning algorithms, Zero-Knowledge proofs, etc. which may need non-trivial computation. In this paper, we present YODA, which is to the best of our knowledge the first solution for efficient computation of CICs in permissionless blockchains with guarantees for a threat model with both Byzantine and selfish nodes. YODA selects one or more execution sets (ES) via Sortition to execute a particular CIC off-chain. One key innovation is the MultI-Round Adaptive Consensus using Likelihood Estimation (MIRACLE) algorithm based on sequential hypothesis testing. M I RACLE allows the execution sets to be small thus making YODA efficient while ensuring correct CIC execution with high probability. It adapts the number of ES sets automatically depending on the concentration of Byzantine nodes in the system and is optimal in terms of the expected number of ES sets used in certain scenarios. Through a suite of economic incentives and technical mechanisms such as the novel Randomness Inserted Contract Execution (RICE) algorithm, we force selfish nodes to behave honestly. We also prove that the honest behavior of selfish nodes is an approximate Nash Equilibrium. We present the system design and details of YODA and prove the security properties of MIRACLE and RICE. Our prototype implementation built on top of Ethereum demonstrates the ability of YODA to run CICs with orders of magnitude higher gas per unit time …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&citation_for_view=XxeF6MkAAAAJ:XiSMed-E-HIC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"We present a novel scheme called Decentralized Attestation for Device Swarms (DADS), which is, to the best of our knowledge, the first to accomplish decentralized attestation in device swarms. Device swarms are smart, mobile, and interconnected devices that operate in large numbers and are likely to be part of emerging applications in Cyber-Physical Systems (CPS) and Industrial Internet of Things (IIoTs). Swarm devices process and exchange safety, privacy, and mission-critical information. Thus, it is important to have a good code verification technique that scales to device swarms and establishes trust among collaborating devices. DADS has several advantages over current state-of-the-art swarm attestation techniques: It is decentralized, has no single point of failure, and can handle changing topologies after nodes are compromised. DADS assures system resilience to node compromise/failure while …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:K3LRdlH-MEoC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"Cryptocurrency networks are a promising infrastructure for pseudonymous online payments. However, low throughput has prevented their widespread acceptance. A promising solution to scale throughput is the Payment channel network (PCN), exemplified by the Lightning Network (LN), that uses a network of off-chain bidirectional payment channels between parties that wish to transact often. Since payments use the shortest paths with sufficient funds over this network, channel balances get exhausted in the direction transactions flow and eventually become unidirectional. This results in transactions failing and consequently a lower transaction success ratio. Our observations on the production LN show that over 63% of the channels lose over 80% of the channel balance in one direction over time, which makes the success ratio of a real-world workload drop from 71% to 29%. A unidirectional channel along a path …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:fQNAKQ3IYiAC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"In recent times, the world has seen a tremendous increase in the number of attacks on IoT devices. A majority of these attacks have been botnet attacks, where an army of compromised IoT devices is used to launch DDoS attacks on targeted systems. In this paper, we study how the choice of a dataset and the extracted features determine the performance of a Machine Learning model, given the task of classifying Linux Binaries (ELFs) as being benign or malicious. Our work focuses on Linux systems since embedded Linux is the more popular choice for building today’s IoT devices and systems. We propose using 4 different types of files as the dataset for any ML model. These include system files, IoT application files, IoT botnet files and general malware files. Further, we propose using static, dynamic as well as network features to do the classification task. We show that existing methods leave out one or the other …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:4fKUyHm3Qg0C,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"Proof-of-Work (PoW) based blockchains typically allocate only a tiny fraction (e.g., less than 1% for Ethereum) of the average interarrival time (I) between blocks for validating smart contracts present in transactions. In such systems, block validation and PoW mining are typically performed sequentially, the former by CPUs and the latter by ASICs. A trivial increase in validation time (τ) introduces the popularly known Verifier's Dilemma, and as we demonstrate, causes more forking and hurts fairness. Large τ also reduces the tolerance for safety against a Byzantine adversary. Solutions that offload validation to a set of non-chain nodes (a.k.a. off-chain approaches) suffer from trust and performance issues that are non-trivial to resolve. In this paper, we present Tuxedo, the first on-chain protocol to theoretically scale τ/I ≈1 in PoW blockchains. The key innovation in Tuxedo is to perform CPU-based block processing in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:VOx2b1Wkg3QC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"A botnet is a network of devices infected by the same malware, acting as a single entity and controlled by a botmaster. They are the biggest cybersecurity threat to carry out large-scale attacks from spamming, ransomware, data exfiltration, and denial-of-service attacks. Lightweight IoT devices without traditional security mechanisms have become favorite victims and agents to carry out botnet attacks. In our work, we seek to detect botnet-infected IoT nodes.
This paper presents BOND, a frugal Deep Learning analysis of network traffic for detecting IoT devices infected with botnet(s), correctly classifying Zero-Day attacks and newer benign traffic. BOND is designed considering the constraints of IoT gateways and betters the F1 score of standard benchmark ML algorithms and State-of-The-Art method - Kitsune, by at least 10%, with under 1 millisecond inference time and less than 150 KB of model memory.
This paper …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:LPZeul_q3PIC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"A Blockchain system such as Ethereum is a peer to peer network where each node works in three phases: creation, mining, and validation phases. In the creation phase, it executes a subset of locally cached transactions to form a new block. In the mining phase, the node solves a cryptographic puzzle (Proof of Work-PoW) on the block it forms. On receiving a block from another peer, it starts the validation phase, where it executes the transactions in the received block in order to ensure all transactions are valid. This execution also updates the blockchain state, which must be completed before creating the next block. A long block validation time lowers the system's overall throughput and brings the well known Verifier's dilemma into play. Additionally, this leads to wasted mining power utilization (MPU).
Through extensive measurement of 2000 nodes from the production Ethereum network we find that during block …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:sSrBHYA8nusC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"Permissionless blockchain consensus protocols have been designed primarily for defining decentralized economies for the commercial trade of assets, both virtual and physical, using cryptocurrencies. In most instances, the assets being traded are regulated, which mandates that the legal right to their trade and their trade value are determined by the governmental regulator of the jurisdiction in which the trade occurs. Unfortunately, existing blockchains do not formally recognise proposal of legal cryptocurrency transactions, as part of the execution of their respective consensus protocols, resulting in rampant illegal activities in the associated crypto-economies. In this contribution, we motivate the need for regulated blockchain consensus protocols with a case study of the illegal, cryptocurrency based, Silk Road darknet market. We present a novel regulatory framework for blockchain protocols, for ensuring legal transaction confirmation as part of the blockchain distributed consensus. As per our regulatory framework, we derive conditions under which legal transaction throughput supersedes throughput of traditional transactions, which are, in the worst case, an indifferentiable mix of legal and illegal transactions. Finally, we show that with a small change to the standard blockchain consensus execution policy (appropriately introduced through regulation), the legal transaction throughput in the blockchain network can be maximized.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:B3FOqHPlNUQC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"The present invention provides a computer implemented method in a blockchain system, wherein said method comprising: plurality of anchors, wherein said anchors includes a bitstring comprising (i) hash of a block in a main chain, and (ii) a Proof Of Work (PoW). The plurality of anchors generated, propagated and thereby accepted by plurality of peer nodes in a network on said blockchain system so as to increase the responsiveness and stability of a blockchain.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:q3oQSFYPqjQC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"The Computer architecture research extensively studies system resource consumption by algorithms and applications. On the other hand, Machine Learning (ML) research focuses on obtaining high levels of accuracy without any computational constraint. The typical approach for addressing the need for higher compute power and system resources for ML tasks is to add more hardware and employ lighter frameworks (e.g., using TensorFlow Lite and PyTorch Mobile instead of TensorFlow and Pytorch, respectively). Extensive use of ML models for applications, especially in Internet of Things (IoT) security requires investigation of resource consumption of ML models. Most tasks employing Artificial Intelligence/ Machine Learning need to choose appropriate models judiciously considering the system resources consumed. Therefore it is required to investigate various ML techniques and benchmark them in terms of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:eflP2zaiRacC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"The proliferation of application specific cyber-physical systems coupled with the emergence of a variety of attacks on such systems (malware such as Mirai and Hajime) underlines the need to secure such networks. Most existing security efforts have focused on only detection of the presence of malware. However given the ability of most attacks to spread through the network once they infect a few devices, it is important to contain the spread of a virus and at the same time systematically cleanse the impacted nodes using the communication capabilities of the network. Toward this end, we present Airmed - a method and system to not just detect corruption of the application software on a IoT node, but to self correct itself using its neighbors. Airmed's decentralized mechanisms prevent the spread of self-propagating malware and can also be used as a technique for updating application code on such IoT devices. Among the novelties of Airmed are a novel bloom-filter technique along with hardware support to identify position of the malware program from the benign application code, an adaptive self-check for computational efficiency, and a uniform random-backoff and stream signatures for secure and bandwidth efficient code exchange to correct corrupted devices. We assess the performance of Airmed, using the embedded systems security architecture of TrustLite in the OMNeT++ simulator. The results show that Airmed scales up to thousands of devices, ensures guaranteed update of the entire network, and can recover 95% of the nodes in 10 minutes in both internal and external propagation models. Moreover, we evaluate memory and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:tOudhMTPpwUC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"Permissionless blockchain consensus protocols have been leveraged for defining decentralized economies for the (commercial or private) trade of virtual and physical assets, using cryptocurrencies. In most instances, the assets being traded are regulated, which mandates that the legal right to their trade and their trade value are determined by the governmental regulator of the jurisdiction in which the trade occurs. Unfortunately, existing blockchains do not formalize proposal of legal cryptocurrency transactions, as part of the execution of their respective consensus protocols, resulting in illegal activities in the associated crypto-economies. In this contribution, unlike existing non-consensus solutions, which are prone to be more compute-time and audit-time intensive, we present a novel regulatory framework for blockchain protocols, for ensuring legal transaction confirmation as part of the blockchain consensus. As …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:5ugPr518TE4C,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"Accordingly, embodiment herein disclose a method for handling block chain operation in a block chain system. The method includes parallelizing, by the block chain system, a block creation along with a consensus mechanism. The block creation along with the consensus mechanism includes parallelly combining a pre-computed state of a succeeding block (at height “k” greater than the current block, where “k” is a positive integer parameter chosen by the system designer) with transactions in a current block to obtain state to be stored in a next succeeding block (at height “k+ 1” greater than the current block) along with running a consensus protocol to finalize transactions to include in an immediate next block (at height one greater than the current block). Further, the method includes handling, by the block chain system, the block chain operation based on parallelizing. The method can be used for scaling up …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:tS2w5q8j5-wC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"We consider the problem of correctly identifying the mode of a discrete distribution with sufficiently high probability by observing a sequence of iid samples drawn from . This problem reduces to the estimation of a single parameter when has a support set of size . After noting that this special case is handled very well by prior-posterior-ratio (PPR) martingale confidence sequences (Waudby-Smith and Ramdas, 2020), we propose a generalisation to mode estimation, in which may take values. To begin, we show that the"" one-versus-one"" principle to generalise from to classes is more efficient than the"" one-versus-rest"" alternative. We then prove that our resulting stopping rule, denoted PPR-1v1, is asymptotically optimal (as the mistake probability is taken to 0). PPR-1v1 is simple and computationally light, and incurs significantly fewer samples than competitors even in the non-asymptotic regime. We demonstrate its gains in two practical applications of sampling: election forecasting and verification of smart contracts in blockchains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:5Ul4iDaHHb8C,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"Proof-of-work (PoW) consensus generates blocks at random time instants, and consequently, adds weight to the blockchain at these random instants. This unsteady increase in chain weight over time along with the large network delay of blocks is the root cause of many security and performance problems such as high fork resolution times, vulnerability to double-spend and selfish mining attacks, and also a high block confirmation time. In this paper, we propose a novel signaling scheme of PoW called Anchors that can be implemented on any PoW blockchain system to improve their stability, reduce fork resolution times, prevent forks, strengthen the system against double spend attacks and reduce block confirmation times by half. In a partially synchronous model with a general adversary, we prove that a system with anchors has faster, more stable chain growth as compared to PoW systems without anchors and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:eJXPG6dFmWUC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"Proof-of-Work (PoW) blockchains add blocks, and consequently the chain weight, randomly. The blocks added also have a significant network delay owing to their large size. Large delay combined with randomness causes forks that are responsible for many security problems. One can reduce fork occurrences by designing a system with large block intervals and size but this design compromises performance aspects such as confirmation time guarantees. The trade-off between security and performance in PoW blockchain is a well discussed topic in the literature. In this paper, we aim to reduce the conflict between security and performance through our novel concept of Links. Links are small, fast and frequent structures that can be incorporated on any new or existing PoW blockchains. Links help reduce the confirmation time of its underlying blockchain while preserving its consistency security guarantees. Our novel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:BrmTIyaxlBUC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"We consider the problem of correctly identifying the\textit {mode} of a discrete distribution with sufficiently high probability by observing a sequence of iid samples drawn from . This problem reduces to the estimation of a single parameter when has a support set of size . After noting that this special case is tackled very well by prior-posterior-ratio (PPR) martingale confidence sequences\citep {waudby-ramdas-ppr}, we propose a generalisation to mode estimation, in which may take values. To begin, we show that the"" one-versus-one"" principle to generalise from to classes is more efficient than the"" one-versus-rest"" alternative. We then prove that our resulting stopping rule, denoted PPR-1v1, is asymptotically optimal (as the mistake probability is taken to ). PPR-1v1 is parameter-free and computationally light, and incurs significantly fewer samples than competitors even in the non …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:8AbLer7MMksC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",22,"Proof-of-Work~(PoW) based blockchains typically allocate only a tiny fraction (e.g., less than 1% for Ethereum) of the average interarrival time~() between blocks for validating transactions. A trivial increase in validation time~() introduces the popularly known Verifier's Dilemma, and as we demonstrate, causes more forking and increases unfairness. Large also reduces the tolerance for safety against a Byzantine adversary. Solutions that offload validation to a set of non-chain nodes (a.k.a. off-chain approaches) suffer from trust issues that are non-trivial to resolve. In this paper, we present Tuxedo, the first on-chain protocol to theoretically scale in PoW blockchains. The key innovation in Tuxedo is to separate the consensus on the ordering of transactions from their execution. We achieve this by allowing miners to delay validation of transactions in a block by up to blocks, where is a system parameter. We perform security analysis of Tuxedo considering all possible adversarial strategies in a synchronous network with end-to-end delay and demonstrate that Tuxedo achieves security equivalent to known results for longest chain PoW Nakamoto consensus. Additionally, we also suggest a principled approach for practical choices of parameter as per the application requirement. Our prototype implementation of Tuxedo atop Ethereum demonstrates that it can scale without suffering the harmful effects of naive scaling in existing blockchains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&cstart=20&pagesize=80&citation_for_view=XxeF6MkAAAAJ:08ZZubdj9fEC,https://www.cse.iitb.ac.in/~vinayr
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"We show that non-Markovian effects of the reservoirs can be used as a resource to extract work from an Otto cycle. The state transformation under non-Markovian dynamics is achieved via a two-step process, namely an isothermal process using a Markovian reservoir followed by an adiabatic process. From second law of thermodynamics, we show that the maximum amount of extractable work from the state prepared under the non-Markovian dynamics quantifies a lower bound of non-Markovianity. We illustrate our ideas with an explicit example of non-Markovian evolution.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&citation_for_view=UU9KftAAAAAJ:8baWPQ8fTxwC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&citation_for_view=UU9KftAAAAAJ:sc_hyC0iex0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"A master equation has been constructed for a global system–bath interaction in the both absence and presence of non-Markovian noise. For the memoryless case, it has been exactly solved for a paradigmatic class of two qubit states in high- and zero-temperature thermal environment. For the non-Markovian model, it has been solved for zero-temperature bath. The evolution of quantum coherence and entanglement has been observed in the presence of the above-mentioned interactions. We show that the global part of the system–bath interaction compensates for the decoherence, resulting in slowdown of coherence and entanglement decay. For an appropriately defined limiting case, both coherence and entanglement show freezing behavior for the high-temperature bath. In case of zero-temperature bath, the mentioned interaction not only stabilizes the non-classical correlations, but also enhances them …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&citation_for_view=UU9KftAAAAAJ:J_g5lzvAfSwC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Quantum non-Markovianity of a quantum noisy channel is typically identified with information backflow or, more generally, with departure of the intermediate map from complete positivity. But here, we also indicate certain non-Markovian channels that cannot be witnessed by the CP-divisibility criterion. In complex systems, non-Markovianity becomes more involved on account of subsystem dynamics. Here we study various facets of non-Markovian evolution, in the context of coined quantum walks, with particular stress on disambiguating the internal vs. environmental contributions to non-Markovian backflow. For the above problem of disambiguation, we present a general power-spectral technique based on a distinguishability measure such as trace-distance or correlation measure such as mutual information. We also study various facets of quantum correlations in the transition from quantum to classical random …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&citation_for_view=UU9KftAAAAAJ:EGhj4itiAA0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"We study the interplay between coherence and mixedness in meson and neutrino systems. The dynamics of the meson system is treated using the generic decoherence model taking into account the decaying nature of the system. Neutrino dynamics is studied in the context of three flavour oscillations within the framework of a decoherence model recently used in the context of LSND (Liquid Scintillator Neutrino Detector) experiment. For meson systems, the decoherence effect is negligible in the limit of zero CP violation. Interestingly, the average mixedness increases with time for about one lifetime of these particles. For neutrino system, in the context of the model considered, the decoherence effect is maximum for neutrino energy around 30 MeV. Further, the effect of CP violating phase is found to decrease (increase) the coherence in the upper (lower ) half plane.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:hmHAmvAdi5MC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"We introduce a method to construct non-Markovian variants of completely positive (CP) dynamical maps, particularly, qubit Pauli channels. We identify non-Markovianity with the breakdown in CP divisibility of the map, ie, appearance of a not-completely positive intermediate map. In particular, we consider the case of non-Markovian dephasing in detail. The eigenvalues of the Choi matrix of the intermediate map crossover at a point which corresponds to a singularity in the canonical decoherence rate of the corresponding master equation and thus to a momentary noninvertibility of the map. Thereafter, the rate becomes negative, indicating non-Markovianity. We quantify the non-Markovianity by two methods, one based on CP divisibility [Hall et al., Phys. Rev. A 89, 042120 (2014)], which does not require optimization but requires normalization to handle the singularity, and another method, based on distinguishability …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:xZ4F5NOCMJ0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"In this work, we derive a quantum information theoretic quantity similar to the Leggett-Garg inequality, which can be defined in terms of neutrino transition probabilities. For the case of ν μ→ ν e/ν¯ μ→ ν¯ e transitions, this quantity is sensitive to CP violating effects as well as the neutrino mass-hierarchy, namely which neutrino mass eigenstate is heavier than the other ones. The violation of the inequality for this quantity shows an interesting dependence on mass-hierarchy. For normal (inverted) mass-hierarchy, it is significant for ν μ→ ν e (ν¯ μ→ ν¯ e) transitions. This is applied to the two ongoing accelerator experiments T2K and NOνA as well as the future experiment DUNE.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:KgQn5aR88cEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"The present work is devoted to the characterization of the Leggett-Garg inequality (LGI) for three flavored neutrino oscillations in the presence of both matter and charge-conjugation and parity violating effects. This study complements and completes the recent one put forward in arXiv: 1710.05562 by relaxing the stationary condition. At variance with the latter case, the LGI contains interference terms which cannot be expressed in terms of experimentally measurable quantities, thus drawing a clear-cut distinction between the two scenarios, as well as highlighting the role of the stationary assumption on such systems. We find that the additional terms are small for a high energy neutrino beam compared to the maximum value attained by the Leggett-Garg parameter.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:rlkjS_mI7T0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"The problem of defining quantum non-Markovianity has proven elusive, with various in-equivalent criteria put forth to address it. The concept of CP-indivisibility and the hierarchy of stronger divisibility criteria going up to P-indivisibility, capture a fundamental aspect of memory in quantum non-Markovianity. In practice, however, there can be a memory-like influence associated with divisible channels in the form of weakening, if not reversing, the effects of decoherence. Arguably, such a facet of memory relates to CP-indivisibility as quantum discord relates to entanglement. We concretize this weaker notion of non-Markovianity by identifying it with deviation from “temporal self-similarity”, the property of a system dynamics whereby the propagator between two intermediate states is independent of the initial time . We illustrate this idea through examples, and propose a geometric quantification of temporal self-similarity …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:2K5qSjdd3awC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Nonclassical properties of photon added and subtracted displaced Fock states are studied using various witnesses of lower‐ and higher‐order nonclassicality. Compact analytic expressions are obtained for the nonclassicality witnesses. Using those expressions, it is established that these states and the states that can be obtained as their limiting cases (except coherent states) are highly nonclassical as they show the existence of lower‐ and higher‐order antibunching and sub‐Poissonian photon statistics, in addition to the nonclassical features revealed through the Mandel parameter, zeros of Q function, Klyshko's criterion, and Agarwal–Tara criterion. Further, some comparison between the nonclassicality of photon added and subtracted displaced Fock states have been performed using witnesses of nonclassicality. This has established that between the two types of non‐Gaussianity inducing operations (i.e …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:mdGv78FIKkEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"The interplay between the nonclassical features and the parity-time (PT) symmetry (or its breaking) is studied here by considering a PT-symmetric system consisting of two cavities with gain and loss. The conditions for PT invariance are obtained for this system. The behavior of the average photon number corresponding to the gain and loss modes for different initial states (eg, vacuum, NOON, coherent, and thermal states) has also been obtained. With the help of the number operators, quantum Zeno and anti-Zeno effects are studied, and the observed behavior is compared in PT-symmetric (PTS) and PT-symmetry-broken (PTSB) regimes. It has been observed that the relative phase of the input coherent fields plays a key role in the occurrence of these effects. Further, some nonclassicality features are witnessed using criteria based on the number operator (s). Specifically, intermodal antibunching, sum, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:W-zclTkWZekC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"In this work we study temporal quantum correlations, quantified by Leggett-Garg (LG) and LG-type inequalities, in the B and K meson systems. We use the tools of open quantum systems to incorporate the effect of decoherence which is quantified by a single phenomenological parameter. The effect of C P violation is also included in our analysis. We find that the LG inequality is violated for both B and K meson systems, the violation being most prominent in the case of K mesons and least for B s system. Since the systems with no coherence do not violate LGI, incorporating decoherence is expected to decrease the extent of violation of LGI and is clearly brought out in our results. We show that the expression for the LG functions depends upon an additional term, apart from the experimentally measurable meson transition probabilities. This term vanishes in the limit of zero decoherence. On the other hand, the LG-type …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:Zrzg8MEyHc4C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Quantum key distribution (QKD) is a key exchange protocol which is implemented over free space optical links or optical fiber cable. When direct communication is not possible, QKD is performed over fiber cables, but the imperfections in detectors used at the receiver side and also the material properties of fiber cables limit the long-distance communication. Free space-based QKD is free from such limitations and can pave the way for satellite-based quantum communication to set up a global network for sharing secret messages. To implement free space optical links, it is essential to study the effect of atmospheric turbulence. Here, an analysis is made for satellite-based quantum communication using QKD protocols. We assume two specific attacks, namely PNS (photon number splitting) and IRUD (intercept-resend with unambiguous discrimination), which could be main threats for future QKD-based satellite …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:Cd1N8iHLSCsC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"We consider two non-Markovian models: random telegraph noise and non-Markovian dephasing. The memory in these models is studied from the perspective of quantum Fisher information flow. This is found to be consistent with the other well-known witnesses of non-Markovianity. The two noise channels are characterized quantum information theoretically by studying their gate and channel fidelities. Further, the quantum coherence and its balance with mixedness is studied. This helps to put in perspective the role that the two noise channels can play in various facets of quantum information processing and quantum communication.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:MhMRrlfrL94C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Quantum phase properties of photon added and subtracted displaced Fock states (and their limiting cases) are investigated from a number of perspectives, and it is shown that the quantum phase properties are dependent on the quantum state engineering operations performed. Specifically, the analytic expressions for quantum phase distributions and angular Q distribution as well as measures of quantum phase fluctuation and phase dispersion are obtained. The uniform phase distribution of the initial Fock states is observed to be transformed by the unitary operation (i.e., displacement operator) into non‐Gaussian shape, except for the initial vacuum state. It is observed that the phase distribution is symmetric with respect to the phase of the displacement parameter and becomes progressively narrower as its amplitude increases. The non‐unitary (photon addition/subtraction) operations make it even narrower in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:g2bnS7N2_ggC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"The possibility of observing nonclassical features in a physical system comprised of a cavity with two ensembles of two-level atoms has been investigated by considering different configurations of the ensembles with respect to the node and antinode of the cavity field under the framework of open quantum systems. The study reveals the strong presence of nonclassical characters in the physical system by establishing the existence of many facets of nonclassicality, such as the sub-Poissonian boson statistics and squeezing in single modes, intermodal squeezing, intermodal entanglement, antibunching, and steering. The effect of a number of parameters, characterizing the physical system, on the different aspects of nonclassicality is also investigated. Specifically, it is observed that the depth of the nonclassicality witnessing parameters can be enhanced by externally driving one of the ensembles with an optical field …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:lsEYeSe2tpEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Non-Markovian quantum effects are typically observed in systems interacting with structured reservoirs. Discrete-time quantum walks are prime example of such systems in which, quantum memory arises due to the controlled interaction between the coin and position degrees of freedom. Here we show that the information backflow that quantifies memory effects can be enhanced when the particle is subjected to uncorrelated static or dynamic disorder. The presence of disorder in the system leads to localization effects in 1-dimensional quantum walks. We shown that it is possible to infer about the nature of localization in position space by monitoring the information backflow in the reduced system. Further, we study other useful properties of quantum walk such as entanglement, interference and its connection to quantum non-Markovianity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:UIW7YHcmbUEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Quantum key distribution is an effective encryption technique which can be used to perform secure quantum communication between satellite and ground stations. Quantum cryptography enhances security in various networks such as optical fibers and wireless networks. In addition to this, these networks become vulnerable in presence of high attenuation due to atmospheric effects and noise. Hence, errors occurs due to decoherence. The noisy quantum channel is modeled and implemented by the redundancy-free quantum error correction scheme which provides better security and throughput efficiency as shown in simulation results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:iMbXGt5dmAEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"We investigate the dynamics of quantum correlation (QC) under the effects of reservoir memory, as a resource for quantum information and computation tasks. Quantum correlations of two-qubit systems are used for implementing quantum teleportation successfully, and for investigating how teleportation fidelity, violation of Bell-CHSH inequality, quantum steering and entanglement are connected with each other under the influence of noisy environments. Both Markovian and non-Markovian channels are considered, and it is shown that the decay and revival of correlations follow the hierarchy of quantum correlations in the state space. Noise tolerance of quantum correlations is checked for different types of unital and non-unital quantum channels, with and without memory. The quantum speed limit time is investigated from the perspective of memory of quantum noise, and the corresponding dynamics …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:oe-dhlAyNXgC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Many facets of nonclassicality are probed in the context of three flavour neutrino oscillations including matter effects and CP violation. The analysis is carried out for parameters relevant to two ongoing experiments and T2K, and also for the upcoming experiment DUNE. The various quantum correlations turn out to be sensitive to the mass-hierarchy problem in neutrinos. This sensitivity is found to be more prominent in DUNE experiment as compared to and T2K experiments. This can be attributed to the large baseline and high energy of the DUNE experiment. Further, we find that to probe these correlations, the neutrino (antineutrino) beam should be preferred if the sign of mass square difference turns out to be positive (negative).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:9djSGow2EaoC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Various nonclassical and quantum phase properties of photon added then subtracted displaced Fock state have been examined systematically and rigorously. Higher-order moments of the relevant bosonic operators are computed to test the nonclassicality of the state of interest, which reduces to various quantum states (having applications in quantum optics, metrology and information processing) in different limits ranging from the coherent (classical) state to the Fock (most nonclassical) states. The nonclassical features are discussed using Klyshko’s, Vogel’s, and Agarwal–Tara’s criteria as well as the criteria of lower-and higher-order antibunching, sub-Poissonian photon statistics and squeezing. In addition, phase distribution function and quantum phase fluctuation have been studied. These properties are examined for various combinations of number of photon addition and/or subtraction and Fock parameter …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:grZTYWtF7b0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Gravity induced neutrino-antineutrino oscillations are studied in the context of one-and two-flavor scenarios. This allows one to investigate the particle-antiparticle correlations in two and four level systems, respectively. Flavor entropy is used to probe the entanglement in the system. The well known witnesses of nonclassicality such as Mermin and Svetlichny inequalities are investigated. Since the extent of neutrino-antineutrino oscillation is governed by the strength of the gravitational field, the behavior of nonclassicality shows interesting features as one varies the strength of the gravitational field. Specifically, the suppression of the entanglement with the increase of the gravitational field is observed which is witnessed in the form of decrease in the flavor entropy of the system. The features of the Mermin and the Svetlichny inequalities allow one to make statements about the degeneracy of neutrino mass eigenstates.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:QhyW1pcpMSYC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"In quantum key distribution, one conservatively assumes that the eavesdropper Eve is restricted only by physical laws, whereas the legitimate parties, namely the sender Alice and receiver Bob, are subject to realistic constraints, such as noise due to environment-induced decoherence. In practice, Eve too may be bound by the limits imposed by noise, which can give rise to the possibility that decoherence works to the advantage of the legitimate parties. A particular scenario of this type is one where Eve can’t replace the noisy communication channel with an ideal one, but her eavesdropping channel itself remains noiseless. Here, we point out such a situation, where the security of the ping–pong protocol (modified to a key distribution scheme) against a noise-restricted adversary improves under a non-unital noisy channel, but deteriorates under unital channels. This highlights the surprising fact that, contrary …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:bB6ab1qDjH0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Entropic Leggett–Garg inequality is studied in systems like neutrinos in the context of two and three flavor neutrino oscillations and in neutral, and K mesons. The neutrino dynamics is described with the matter effect taken into consideration. For the decohering B/K meson systems, the effect of decoherence and CP violation have also been taken into account, using the techniques of open quantum systems. Enhancement in the violation with increase in the number of measurements has been found, in consistency with findings in spin-s systems. The effect of decoherence is found to bring the deficit parameter closer to its classical value zero, as expected. The violation of entropic Leggett–Garg inequality lasts for a much longer time in K meson system than in and systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:9bzyojSiTPoC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"IIn this letter, we study the indirect detection of Cosmological Constant from an open quantum system of N entangled spins, weakly interacting with a thermal bath, a massless scalar field minimally coupled with the static De Sitter background, by computing the spectroscopic shifts. By assuming pairwise entanglement between spins, we construct entangled N states using a generalisation of the superposition principle. We have found that in the realistic large N limit, where the system consists of N∼ O (103− 104) spins, the corresponding spectroscopic shifts, caused by the effective Hamiltonian of the system due to Casimir Polder interaction with the bath, play a crucial role to determine the observationally consistent Cosmological Constant, Λ∼ O (10− 122)(Planckian units) in the static patch of De Sitter space.
In recent times the study of the quantum systems that are interacting with their surroundings has acquired a lot of attention in different fields ranging from condensed matter [1–4], quantum information [5], subatomic physics [6–11], quantum dissipative systems [12], holography [13, 14] to cosmology [5, 15–46] for a sample of the relevant literature. Here our interest is the study of the curvature of the static patch of De Sitter space as well as the Cosmological Constant from the spectroscopic Lamb shift [47–49]. The system under consideration is an open quantum system of N entangled spins which are weakly coupled to their environment, modelled by a massless scalar field minimally coupled to static patch of De Sitter space-time. We are interested to study how the entangled states of the system and the Lamb shift change affect the curvature of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:etrBy31LU9kC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"We study the geometric phase for neutrinos at various man-made facilities, such as the reactor and accelerator neutrino experiments. The analysis is done for the three flavor neutrino scenario, in the presence of matter and for general, noncyclic paths. The geometric phase is seen to be sensitive to the CP violating phase in the leptonic sector and the sign ambiguity in . We find that for neutrino experimental facilities where the geometric phase can complete one cycle, all the phase curves corresponding to different values of CP violating phase, converge to a single point, called the cluster point. There are two distinct cluster points for positive and negative signs of Δ 31. Thus, the geometric phase can contribute to our understanding of the neutrino mass hierarchy problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:9Nmd_mFXekcC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"We make a detailed analysis of quantumness for various quantum noise channels, both Markovian and non-Markovian. The noise channels considered include dephasing channels like random telegraph noise, non-Markovian dephasing and phase damping, as well as the non-dephasing channels such as generalized amplitude damping and Unruh channels. We make use of a recently introduced witness for quantumness based on the square norm of coherence. It is found that the increase in the degree of non-Markovianity increases the quantumness of the channel. This may be attributed to the fact that the non-Markovian dynamics involves the generation of entanglement between the system and environment degrees of freedom.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:xdWr7vBG5PQC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"The effect of two quantum state engineering processes that can be used to burn a hole at vacuum in the photon number distribution of quantum states of radiation field is compared using various witnesses of lower‐ and higher‐order nonclassicality as well as a measure of nonclassicality. Specifically, the modification in nonclassical properties due to vacuum state filtration and a single photon addition on an even coherent state, binomial state, and Kerr state are investigated using the criteria of lower‐ and higher‐order antibunching, squeezing, and sub‐Poissonian photon statistics. Further, the amount of nonclassicality present in these engineered quantum states having enormous applications in continuous variable quantum communication is quantified and analyzed by using an linear entropy‐based entanglement potential. It is observed that all the quantum states studied here are highly nonclassical, and the hole …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:0a-0BRjGxG0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"We report an unusual buildup of the quantum coherence in a qubit subjected to non-Hermitian evolution generated by a parity-time () symmetric Hamiltonian, which is reinterpreted as a Hermitian system in a higher dimensional space using Naimark dilation. The coherence is found to be maximum about the exceptional points (EPs), ie the points of coalescence of the eigenvalues as well as the eigenvectors. The nontrivial physics about EPs has been observed in various systems, particularly in photonic systems. As a consequence of enhancement in coherence, the various formulations of Leggett–Garg inequality tests show maximal violation about the EPs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:BvbJ36a9xgsC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"In this article, we study the quantum field theoretic generalization of the Caldeira-Leggett model to describe the Brownian Motion in general curved space-time considering interactions between two scalar fields in a classical gravitational background. The thermalization phenomena is then studied from the obtained de Sitter solution using quantum quench from one scalar field model obtained from path integrated effective action in Euclidean signature. We consider an instantaneous quench in the time-dependent mass protocol of the field of our interest. We find that the dynamics of the field post-quench can be described in terms of the state of the generalized Calabrese-Cardy (gCC) form and computed the different types of two-point correlation functions in this context. We explicitly found the conserved charges of algebra that represents the gCC state after a quench in de Sitter space and found it to be significantly different from the flat space-time results. We extend our study for the different two-point correlation functions not only considering the pre-quench state as the ground state, but also a squeezed state. We found that irrespective of the pre-quench state, the post quench state can be written in terms of the gCC state showing that the subsystem of our interest thermalizes in de Sitter space. Furthermore, we provide a general expression for the two-point correlators and explicitly show the thermalization process by considering a thermal Generalized Gibbs ensemble (GGE). Finally, from the equal time momentum dependent counterpart of the obtained results for the two-point correlators, we have studied the hidden features of the power spectra …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:4Ol-GlP6dRYC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"A three-level atom in Λ configuration is reduced to an effective two-level system, under appropriate conditions, and its PT symmetric properties are investigated. This effective qubit system, when subjected to a beam-splitter type of interaction, provides the scope of directly (indirectly) probing the nonclassical properties of the output (input) state. Here, we study nonclassical properties of the output state by using some well-known measures of nonclassical correlations like the measurement-induced disturbance, concurrence, and negativity. The nonclassical features are found to enhance in the PT symmetric (PTS) phase compared to the PT symmetry broken (PTB) phase. Further, the output ports of the beam splitter are subjected to different quantum noise channels, both non-Markovian, eg, random telegraph noise as well as Markovian, eg, phase damping and amplitude damping noise. The application of noise …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:_obbd28Je0oC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"For combining different single photon channels into a single path, we use an effective and reliable technique which is known as quantum multiple access. We take advantage of an add-drop multiplexer capable of pushing and withdrawing a single photon into an optical fiber cable which carries quantum bits from multiusers. In addition to this, spreading spreads the channel noise at receiver side and use of filters stop the overlapping of adjacent channels, which helps in reducing the noise level and improved signal-to-noise ratio. In this way, we obtain enhanced performance of code division multiple access-based QKD links with a single photon without necessity of amplifiers and modulators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:-QO_JlXAMEAC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"We study various formulations of Leggett–Garg inequality (LGI), specifically, the Wigner and Clauser–Horne forms of LGI, in the context of subatomic systems, in particular, three flavor neutrino as well as meson systems. The optimal forms of various LGIs for either neutrinos or mesons are seen to depend on measurement settings. For the neutrinos, some of these inequalities can be written completely in terms of experimentally measurable probabilities. Hence, the Wigner and Clauser–Horne forms of LGI are found to be more suitable as compared to the standard LGI from the experimental point of view for the neutrino system. Further, these inequalities exhibit maximum quantum violation around the energies roughly corresponding to the maximum neutrino flux. The Leggett–Garg type inequality is seen to be more suited for the meson dynamics. The meson system being inherently a decaying system allows one to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:9nzIJd-pbyIC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"The violation of Leggett-Garg-type inequalities (LGtIs) is studied on a two-level atom, driven by an external field in the presence of a squeezed thermal reservoir. The violations are observed in the underdamped regime where the spontaneous transition rate is much smaller compared to the Rabi frequency. An increase in thermal effects is found to decrease the extent of violation as well as the time over which the violation lasts. With the increase in the value of the squeezing parameter the extent of violation of LGtIs is seen to reduce. The violation of LGtIs is favored by an increase in the driving frequency. Further, the interplay of the degree of violation and strength of the measurements is studied. It is found that the maximum violation occurs for ideal projective measurements.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:yd8rdvfCKnwC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",32,"Spread-spectrum techniques are widely used in radio communication and telecommunication. Any signal like acoustic, electrical, and electromagnetic signal produced with a specific bandwidth is spread in frequency hence results in a wider bandwidth. Spread spectrum techniques are deployed in telecommunication because of many significant advantages, eg, to achieve secure communications, to detect the eavesdropping, to resist natural interference, to bound power flux density for satellite down links and resistance to noise and jamming. In spread spectrum technique, frequency hopping (FH) is used as a basic modulation technique by which any telecommunication signal can be transmitted on a wider bandwidth (radio bandwidth) as compared to frequency value of the original signal. Spread spectrum techniques deploy FH, direct sequence (DS), or mix of both methods so that it can be used for multiple access and reduces the interference to other receivers to get the overall privacy. At the receiver side, the received signals are correlated to extract the original information being sent. The two main motivation behind spread spectrum are: to create anti-jamming for unauthenticated person and to provide low probability of interception. Spread spectrum technique includes chirp spread spectrum (CSS), directsequence spread spectrum (DSSS), frequency-hopping spread spectrum (FHSS), and time-hopping spread spectrum (THSS). In all these methods pseudorandom number sequences are used throughout the bandwidth to confirm and to adjust the spreading pattern. IEEE 802.11 wireless standard uses DSSS or FHSS in radio communication …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&citation_for_view=UU9KftAAAAAJ:T3x1S4x-kFYC,http://home.iitj.ac.in/~subhashish
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Reliable on-off control of peripherals on smart devices is a key to security and privacy in many scenarios. Journalists want to reliably turn off radios to protect their sources during investigative reporting. Users wish to ensure cameras and microphones are reliably off during private meetings. In this paper, we present SeCloak, an ARM TrustZone-based solution that ensures reliable on-off control of peripherals even when the platform software is compromised. We design a secure kernel that co-exists with software running on mobile devices (e.g., Android and Linux) without requiring any code modifications. An Android prototype demonstrates that mobile peripherals like radios, cameras, and microphones can be controlled reliably with a very small trusted computing base and with minimal performance overhead.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&citation_for_view=yTPVlzgAAAAJ:ZeXyd9-uunAC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Classifying and counting vehicles in road traffic has numerous applications in the transportation engineering domain. However, the wide variety of vehicles (two-wheelers, three-wheelers, cars, buses, trucks etc.) plying on roads of developing regions without any lane discipline, makes vehicle classification and counting a hard problem to automate. In this paper, we use state of the art Convolutional Neural Network (CNN) based object detection models and train them for multiple vehicle classes using data from Delhi roads. We get upto 75% MAP on an 80-20 train-test split using 5562 video frames from four different locations. As robust network connectivity is scarce in developing regions for continuous video transmissions from the road to cloud servers, we also evaluate the latency, energy and hardware cost of embedded implementations of our CNN model based inferences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&citation_for_view=yTPVlzgAAAAJ:mB3voiENLucC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Many emerging systems concurrently execute multiple applications that use deep neural network (DNN) as a key portion of the computation. To speedup the execution of such DNNs, various hardware accelerators have been proposed in recent works. Deep learning processor unit (DPU) from Xilinx is one such accelerator targeted for field programmable gate array (FPGA)-based systems. We study the runtime and energy consumption for different DNNs on a range of DPU configurations and derive useful insights. Using these insights, we formulate a design space exploration (DSE) strategy to explore tradeoffs in accuracy, runtime, cost, and energy consumption arising due to flexibility in choosing DNN topology, DPU configuration, and FPGA model. The proposed strategy provides a reduction of 28× in the number of design points to be simulated and 23× in the pruning time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&citation_for_view=yTPVlzgAAAAJ:r0BpntZqJG4C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Edge devices are seeing tremendous growth in sensing and computational capabilities. Running state-of-the-art deep neural network (NN) based data processing on multi-core CPU processors, embedded Graphics Processing Units (GPU), Tensor Processing Units (TPU), Neural Processing Units (NPU), Deep Learning Accelerators (DLA) etc., edge devices are now able to handle heavy data computations with limited or without cloud connectivity. In addition to hardware resources, software frameworks that optimize a trained neural network (NN) model through weight clustering and pruning, weight and input-output quantization to fewer bits, fusing NN layers etc., for more efficient execution of NN inferences on edge platforms, play an important role in making machine learning at the edge (namely EdgeML) a reality. This paper is a first effort in characterizing these software frameworks for DNN inference …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&citation_for_view=yTPVlzgAAAAJ:JV2RwH3_ST0C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"This poster describes a low-cost and robust embedded platform, designed for vehicle mounted sensing of particulate matter (PM2.5 and PM10). The prototype is specifically designed to be mounted on the Delhi Integrated Multi-Modal Transit System (DIMTS) buses. Movement of the buses adds noise to pollution data. Error in GPS measurement causes issues in detecting moving vs. stationary state of the buses, useful to filter out noisy pollution data collected in the moving state. Intermittent cellular network connectivity causes frequent disconnects with the remote server. Our prototype is designed to handle such real world deployment challenges. Pilot deployment with this platform is currently ongoing. Preliminary data analysis from the pilot deployment will be discussed as part of the poster presentation, along with demonstration of the prototype sensor platform. This hardware prototype has the potential of creating …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&citation_for_view=yTPVlzgAAAAJ:hFOr9nPyWt4C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Travel time estimates are highly useful in planning urban mobility events. This paper investigates the quality of travel time estimates in the Indian capital city of Delhi and the National Capital Region (NCR). Using Uber mobile and web applications, we collect data about 610 trips from 34 Uber users. We empirically show the unpredictability of travel time estimates for Uber cabs. We also discuss the adverse effects of such unpredictability on passengers waiting for the cabs, leading to a whopping 28.4% of the requested trips being cancelled. Our empirical observations differ significantly from the high accuracies reported in travel time estimation literature. These pessimistic results will hopefully trigger useful investigations in future on why the travel time estimates are mismatching the high accuracy levels reported in literature - (a) is it a lack of training data issue for developing countries or (b) an algorithmic shortcoming …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:RHpTSmoSYBkC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"In its most basic form, the spatial capital of a neighborhood entails that most aspects of daily life are located close at hand. Urban planning researchers have widely recognized its importance, not least because it can be transformed in other forms of capital such as economical capital (e.g., house prices, retail sales) and social capital (e.g., neighborhood cohesion). Researchers have already studied spatial capital from official city data. Their work led to important planning decisions, yet it also relied on data that is costly to create and update, and produced metrics that are difficult to compare across cities. By contrast, we propose to measure spatial capital in cheap and standardized ways around the world. Hence the name of our project “World Wide Spatial Capital”. Our measures are cheap as they rely on the most basic information about a city that is currently available on the Web (i.e., which amenities are available and where). They are also standardized because they can be applied in any city in the five continents (as opposed to previous metrics that were mainly applied in USA and UK). We show that, upon these metrics, one could produce insights at the core of the urban planning discipline: which areas would benefit the most from urban interventions; how to inform planning depending on whether a city’s activity is mono- or poly-centric; how different cities fare against each other; and how spatial capital correlates with other urban characteristics such as mobility patterns and road network structure.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:L8Ckcad2t8MC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Deep Learning Processor Unit (DPU) from XILINX is among the numerous accelerators that have been proposed to speed up the execution of Convolutional Neural Networks (CNNs) on embedded platforms. DPUs are available in different configurable sizes and can execute any given CNN. Neural network researchers are also rapidly bringing out newer CNN algorithms with improved performance (typically higher prediction accuracy) with a trade-off in size or energy consumption for embedded applications. To enable quick evaluation of choices among evolving CNN algorithms and accelerator configurations, we propose INFER (INterFerence-aware Estimation of Runtime). INFER is a framework to estimate the execution time of any CNN on a given size of DPU without actual implementation. Further, current FPGA platforms are capable of implementing multiple DPUs whereas many applications consist of multiple …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:TFP_iSt0sucC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Effective intersection control can play an important role in reducing traffic congestion and associated vehicular emissions. This is vitally needed in developing countries, where air pollution is reaching life threatening levels. This paper presents EcoLight intersection control for developing regions, where budget is constrained and network connectivity is very poor. EcoLight learns effective control offline using state-of-the-art Deep Reinforcement Learning methods, but deploys highly efficient runtime control algorithms on low cost embedded devices that work stand-alone on road without server connectivity. EcoLight optimizes both average case and worst case values of throughput, travel time and other metrics, as evaluated on open-source datasets from New York and on a custom developing region dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:iH-uZ7U-co4C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Machine Learning (EdgeML) algorithms on edge devices facilitate safety-critical applications like building security management and smart city interventions. However, their wired/wireless connections with the Internet make such platforms vulnerable to attacks compromising the embedded software. We find that in the prior works, the issue of regular runtime integrity assessment of the deployed software with negligible EdgeML performance degradation is still unresolved. In this paper, we present PracAttest, a practical runtime attestation framework for embedded devices running compute-heavy EdgeML applications. Unlike the conventional remote attestation schemes that check the entire software in each attestation event, PracAttest segments the software and randomizes the integrity check of these segments over short random attestation intervals. The segmentation coupled with the randomization leads to a novel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:maZDTaKrznsC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Convolutional Neural Networks (CNNs) are increasingly becoming popular in embedded and energy limited mobile applications. Hardware designers have proposed various accelerators to speed up the execution of CNNs on embedded platforms. Deep Learning Processor Unit (DPU) is one such generic CNN accelerator for Xilinx platforms that can execute any CNN on one or more DPUs configured on an FPGA. In a period of rapid growth in CNN algorithms and the availability of multiple configurations of CNN accelerators (like DPU), the design space is expanding fast. These design points show significant trade-off in execution time, energy consumption and application performance measured in terms of accuracy. To be able to perform this trade-off, we propose a methodology for energy estimation of a CNN running on a DPU. We build an energy model using characteristics of few CNNs and use this model for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:M3NEmzRMIkIC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Companies providing services like cab sharing, e-commerce logistics, food delivery are willing to instrument their vehicles for scaling up measurements of traffic congestion, travel time, road surface quality, air quality, etc.[1]. Analyzing fine-grained sensors data from such large fleets can be highly beneficial; however, this sensor information reveals the locations and the number of vehicles in the deployed fleet. This sensitive data is of high business value to rival companies in the same business domain, eg, Uber vs. Ola, Uber vs. Lyft in cab sharing, or Amazon vs. Alibaba in the e-commerce domain. This paper provides privacy guarantees for the scenario mentioned above using Gaussian Process Regression (GPR) based interpolation, Differential Privacy (DP), and Secure two-party computations (2PC). The sensed values from instrumented vehicle fleets are made available preserving fleet and client privacy, along with client utility. Our system has efficient latency and bandwidth overheads, even for resource-constrained mobile clients. To demonstrate our end-to-end system, we build a sample Android application that gives the least polluted route alternatives given a source-destination pair in a privacy preserved manner.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:blknAaTinKkC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Classifying and counting vehicles in road traffic has numerous applications in the transportation engineering domain. However, the wide variety of vehicles (two-wheelers, three-wheelers, cars, buses, trucks etc.) plying on roads of developing regions without any lane discipline, makes vehicle classification and counting a hard problem to automate. In this paper, we use state of the art Convolutional Neural Network (CNN) based object detection models and train them for multiple vehicle classes using data from Delhi roads. We get upto 75% MAP on an 80-20 train-test split using 5562 video frames from four different locations. As robust network connectivity is scarce in developing regions for continuous video transmissions from the road to cloud servers, we also evaluate the latency, energy and hardware cost of embedded implementations of our CNN model based inferences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:j3f4tGmQtD8C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Deep learning Processor Units (DPUs) from Xilinx are design-time configurable CNN accelerators for FPGAs. We propose EXPRESS, which predicts the execution time of any given CNN on a DPU. EXPRESS incorporates the effect of bus connections into prediction. As a DPU is invoked by a host CPU to process a CNN layer by layer, EXPRESS considers the CPU and the DPU execution time for predicting the end-to-end processing time. EXPRESS has an average prediction error of 2.2% and significantly outperforms state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:RGFaLdJalmkC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Road traffic congestion increases vehicular emissions and air pollution. Traffic rule violation causes road accidents. Both pollution and accidents take tremendous social and economic toll worldwide, and more so in developing countries where the skewed vehicle to road infrastructure ratio amplifies the problems. Automating traffic intersection management to detect and penalize traffic rule violations and reduce traffic congestion, is the focus of this paper, using state-of-the-art Convolutional Neural Network (CNN) on traffic camera feeds. There are however non-trivial challenges in handling the chaotic, non-laned traffic scenes in developing countries. Maintaining high throughput is one of the challenges, as broadband connectivity to remote GPU servers is absent in developing countries, and embedded GPU platforms on roads need to be low cost due to budget constraints. Additionally, ambient temperatures in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:NMxIlDl6LWMC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",16,"Developing countries are home to the most polluted cities in the world. Particulate Matter (PM), one of the most serious air pollutants, needs to be measured at scale across urban areas in such countries. Factors potentially affecting PM like road traffic, green cover, industrial emissions etc., also need to be quantified, to enable fine-grained correlation analyses among PM and its causes. This paper presents an IoT platform with multiple sensors, latest deep neural network based edge-computing, local storage and communication support – to measure PM and its associated factors. Through real world deployments, the first in depth empirical analysis of a government enforced traffic control policy for pollution control, is presented as a use case of our IoT platform. We demonstrate the potential of IoT and edge computing in urban sustainability questions in this paper, especially in a developing region context. At the same …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&cstart=20&pagesize=80&citation_for_view=yTPVlzgAAAAJ:hMod-77fHWUC,http://www.cse.iitd.ac.in/~rijurekha/
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Convolutional neural networks (CNNs) have proven to be a disruptive technology in most vision, speech and image processing tasks. Given their ubiquitous acceptance, the research community is investing a lot of time and resources on deep neural networks. Custom hardware such as ASICs are proving to be extremely worthy platforms for running such programs. However, the ever-increasing complexity of these algorithms poses challenges in achieving real-time performance. Specifically, CNNs have prohibitive costs in terms of computation time, throughput, latency, storage space, memory bandwidth, and power consumption.
Hence, in the last 5 years, a lot of work has been done by the scientific community to mitigate these costs. Researchers have primarily focused on reducing the computation time, the number of computations, the memory access time, and the size of the memory footprint. In this survey paper …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&citation_for_view=-5JfCRsAAAAJ:VOx2b1Wkg3QC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Numerous challenges present themselves when scaling traditional on-chip electrical networks to large manycore processors. Some of these challenges include high latency, limitations on bandwidth, and power consumption. Researchers have therefore been looking for alternatives. As a result, on-chip nanophotonics has emerged as a strong substitute for traditional electrical NoCs.
As of 2017, on-chip optical networks have moved out of textbooks and found commercial applicability in short-haul networks such as links between servers on the same rack or between two components on the motherboard. It is widely acknowledged that in the near future, optical technologies will move beyond research prototypes and find their way into the chip. Optical networks already feature in the roadmaps of major processor manufacturers and most on-chip optical devices are beginning to show signs of maturity.
This article is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&citation_for_view=-5JfCRsAAAAJ:xtRiw3GOFMkC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"The vision encompassing Smart and Software-defined Buildings (SSDB) is becoming more popular and its implementation is now more accessible due to the widespread adoption of the Internet of Things (IoT) infrastructure. Some of the most important applications sustaining this vision are energy management, environmental comfort, safety and surveillance. This paper surveys IoT and SSB technologies and their cooperation towards the realization of smart spaces. We propose a four-layer reference architecture and we organize related concepts around it. This conceptual frame is useful to identify the current literature on the topic and to connect the dots into a coherent vision of the future of residential and commercial buildings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&citation_for_view=-5JfCRsAAAAJ:SP6oXDckpogC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"The Internet of Things (IoT) is poised to be one of the most disruptive technologies over the next decade. It is speculated, that we shall have billions of devices with communication capabilities very soon. Minimizing energy consumption is one of the most important problems in such IoT networks mainly because IoT nodes are distributed in the field with limited, unreliable, and intermittent sources of power. Even though the area of reducing power for stand-alone machines is very rich, there are very few references in the area of co-operative power minimization in a system with many IoT nodes. We propose two algorithms in this paper, which are at the two ends of the spectrum: Local exchanges information between neighboring nodes, and Global uses a global server that has recent snapshots of the global state of the network. We show that both these algorithms reduce energy consumption by roughly 40% for settings …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:f2IySw72cVMC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Ensuring the functional correctness of networks-on-chip (NoCs) can be particularly challenging, and communication-centric debug methodologies have been widely used by engineers to validate NoC functionality during post-silicon validation. Design-for-debug structures, such as trace buffers and monitors, are usually inserted in such systems-on-chip to enhance signal visibility. However, this debug hardware becomes underutilized once the chip goes into production. While the size and organization of the router buffers directly impact network throughput, these buffers also dominate the on-chip router area. We propose a scheme augmented virtual channel (AugVC) to reuse trace buffers to augment router buffers, with the objective of improving the overall network performance. The experimental results for a 64-node mesh network show that our proposed approach can reduce latency by up to 38.25% for transpose …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:XiSMed-E-HIC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Thermal modeling and simulation have become imperative in recent years owing to the increased power density of high performance microprocessors. Temperature is a first-order design criteria, and hence special consideration has to be given to it in every stage of the design process. If not properly accounted for, temperature can have disastrous effects on the performance of the chip, often leading to failure. To streamline research efforts, there is a strong need for a comprehensive survey of the techniques and tools available for thermal simulation. This will help new researchers entering the field to quickly familiarize themselves with the state of the art and enable existing researchers to further improve upon their proposed techniques. In this article, we present a survey of the package level thermal simulation techniques developed over the past two decades.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:u9iWguZQMMsC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"In this paper, we present a novel optical power splitter having an arbitrary split-ratio that can be tuned over a wide range by employing relatively low voltage levels. It is based on a slotted ring resonator. A 120 nm electro-optic polymer-filled slot is created throughout the circumference of the ring. The hybrid ring resonator is made to work between the full and off resonance states, allowing it to work as a power splitter. This is done by changing the refractive index of the electro-optic polymer inside the slot by the application of an external electric field. The splitter combines the electro-optic functionality of the polymer with the high index contrast of the silicon, resulting in a low tuning voltage power splitter. Over a small voltage range of 0–1 V, it is possible to change the split-ratio of this splitter from 0.031–16.738, making it 10 times better than other competing designs. In addition, it takes less than 500 ps to reconfigure the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:OU6Ihb5iCvQC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"With the increasing complexity of modern systems-on-chip, the possibility of functional errors escaping design verification is growing. Postsilicon validation targets the discovery of these errors in early hardware prototypes. Due to limited visibility and observability, dedicated design-for-debug (DFD) hardware, such as trace buffers, is inserted to aid postsilicon validation. In spite of its benefit, such hardware incurs area overheads that impose size limitations. However, the effective overhead could be reduced if the area dedicated to DFD could be reused in-field. In this paper, we present a novel method for reusing an existing trace buffer as a victim cache of a processor to enhance the performance. The trace buffer storage space is reused for the victim cache with a small additional controller logic. Simultaneous multithreading allows further fine-grained control of the victim cache, which can be shared between the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:pyW8ca7W8N0C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"With the advent of 5G and M2M architectures, energy harvesting devices are expected to become far more prevalent. Such devices harvest energy from ambient sources such as solar energy or vibration energy (from machines) and use it for sensing the environmental parameters and further processing them. Given that the rate of energy consumption is more than the rate of energy production, it is necessary to frequently halt the processor and accumulate energy from the environment. During this period it is mandatory to take a checkpoint to avoid the loss of data. State of the art algorithms use software based methods that extensively rely on compiler analyses. In this paper, we provide the first formal model for such systems, and show that we can arrive at an optimal check-pointing schedule using a quadratically constrained linear program (QCLP) solver. Using this as a baseline, we show that existing algorithms for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:Tiz5es2fbqcC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"This article presents BigBus, a novel design of an on-chip photonic network for a 1,024-node system. For such a large on-chip network, performance and power reduction are two mutually conflicting goals. This article uses a combination of strategies to reduce static power consumption while simultaneously improving performance and the energy-delay2 (ED2) product. The crux of the article is to segment the entire system into smaller clusters of nodes and adopt a hybrid strategy for each segment that includes conventional laser modulation, as well as a novel technique for sharing power across nodes dynamically. We represent energy internally as tokens, where one token will allow a node to send a message to any other node in its cluster. We allow optical stations to arbitrate for tokens at a global level, and then we predict the number of token equivalents of power that the off-chip laser needs to generate. Using …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:NhqRSupF_l8C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Temperature simulation is a classic problem in EDA, and researchers have been working on it for at least the last 15 years. In this paper, we focus on fast Green's function based approaches, where computing the temperature profile is as simple as computing the convolution of the power profile with the Green's function. We observe that for many problems of interest the process of computing the Green's function is the most time consuming phase, because we need to compute it with the slower finite difference or finite element based approaches. In this paper we propose a solution, NanoTherm, to compute the Green's function using a fast analytical approach that exploits the symmetry in the thermal distribution. Secondly, conventional analyses based on the Fourier's heat transfer equation fail to hold at the nanometer level. To accurately compute the temperature at the level of a standard cell, it is necessary to solve …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:tOudhMTPpwUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Modern enterprise servers are increasingly embracing tiered memory systems with a combination of low latency DRAMs and large capacity but high latency non-volatile main memories (NVMMs) such as Intel’s Optane DC PMM. Prior works have focused on the efficient placement and migration of data on a tiered memory system, but have not studied the optimal placement of page tables.
Explicit and efficient placement of page tables is crucial for large memory footprint applications with high TLB miss rates because they incur dramatically higher page walk latency when page table pages are placed in NVMM. We show that (i) page table pages can end up on NVMM even when enough DRAM memory is available and (ii) page table pages that spill over to NVMM due to DRAM memory pressure are not migrated back later when memory is available in DRAM.
We study the performance impact of page table …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:t6usbXjVLHcC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"High static power consumption is widely regarded as one of the largest bottlenecks in creating scalable optical NoCs. The standard techniques to reduce static power are based on sharing optical channels and modulating the laser. We show in this article that state-of-the-art techniques in these areas are suboptimal, and there is a significant room for further improvement. We propose two novel techniques—a neural network--based method for laser modulation by predicting optical traffic and a distributed and altruistic algorithm for channel sharing—that are significantly closer to a theoretically ideal scheme. In spite of this, a lot of laser power still gets wasted. We propose to reuse this energy to heat micro-ring resonators (achieve thermal tuning) by efficiently recirculating it. These three methods help us significantly reduce the energy requirements. Our design consumes 4.7× lower laser power as compared to other …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:K3LRdlH-MEoC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Silicon photonics is beginning to play an important role in driving innovations in communication and computation for an increasing number of applications, from health care and biomedical sensors to autonomous driving, datacenter networking, and security. In recent years, there has been a significant amount of effort in industry and academia to innovate, design, develop, analyze, optimize, and fabricate systems employing silicon photonics, shaping the future of not only Datacom and telecom technology but also high-performance computing and emerging computing paradigms, such as optical computing and artificial intelligence. Different from existing books in this area, Silicon Photonics for High-Performance Computing and Beyond presents a comprehensive overview of the current state-of-the-art technology and research achievements in applying silicon photonics for communication and computation. It focuses on various design, development, and integration challenges, reviews the latest advances spanning materials, devices, circuits, systems, and applications. Technical topics discussed in the book include:• Requirements and the latest advances in high-performance computing systems• Device-and system-level challenges and latest improvements to deploy silicon photonics in computing systems• Novel design solutions and design automation techniques for silicon photonic integrated circuits• Novel materials, devices, and photonic integrated circuits on silicon• Emerging computing technologies and applications based on silicon photonics Silicon Photonics for High-Performance Computing and Beyond presents a compilation of 19 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:UHK10RUVsp4C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"In this article, we propose a fast thermal modeling tool, 3DSim, using a Green's-function-based approach. Green's-function-based approaches have been shown to be faster than the traditional finite-difference-based techniques. Our proposed tool can model steady-state and transient thermal profiles for both 2-D and 3-D chips, which may contain multiple active layers and fluid-carrying microchannels for heat removal. The unique advantage of our tool is that it models leakage power analytically using a piecewise-linear leakage model, thereby eliminating the need to iterate multiple times through the leakage-temperature feedback loop. We use several algebraic techniques and transforms to compute the thermal profile analytically and thereby speedup the process of calculation. To the best of our knowledge, transform-based approaches have not been used before to model the temperature in 3-D chips with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:eflP2zaiRacC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"On-chip photonics is a disruptive technology, and such NoCs are superior to traditional electrical NoCs in terms of latency, power, and bandwidth. Hence, researchers have proposed a wide variety of optical networks for multicore processors. The high bandwidth and low latency features of photonic NoCs have led to the overall improvement in the system performance. However, there are very few proposals that discuss the usage of optical interconnects in Graphics Processor Units (GPUs). GPUs can also substantially gain from such novel technologies, because they need to provide significant computational throughput without further stressing their power budgets.
The main shortcoming of optical networks is their high static power usage, because the lasers are turned on all the time by default, even when there is no traffic inside the chip, and thus sophisticated laser modulation schemes are required. Such …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:eJXPG6dFmWUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"With the advent of ultra-low-power embedded processors, energy harvesting devices (EHDs) are becoming exceedingly prevalent. These devices are highly portable, self-sustainable, and once deployed, they can run for an extremely long time. They can thus be installed at hard-to-reach locations. Despite the benefits, it is challenging to use these devices as they rely on sporadic and variable sources of ambient energy, and are equipped with very small memories. The intermittent nature of the ambient energy leads to a loss of device state. Such repeated failures might cause non-termination of the programs executing on these devices. To achieve termination, we need to use state retention techniques that guarantee the programs’ forward progress.
Checkpointing is the most common state retention technique. However, performing checkpointing arbitrarily can lead to inefficient and incorrect execution of the program …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:uLbwQdceFCQC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Recent years have witnessed a significant interest in the “generative adversarial networks” (GANs) due to their ability to generate high-fidelity data. Many models of GANs have been proposed for a diverse range of domains ranging from natural language processing to image processing. GANs have a high compute and memory requirements. Also, since they involve both convolution and deconvolution operation, they do not map well to the conventional accelerators designed for convolution operations. Evidently, there is a need of customized accelerators for achieving high efficiency with GANs. In this work, we present a survey of techniques and architectures for accelerating GANs. We organize the works on key parameters to bring out their differences and similarities. Finally, we present research challenges that are worthy of attention in near future. More than summarizing the state-of-art, this survey seeks to spark …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:WA5NYHcadZ8C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"A trusted execution environment or a TEE facilitates the secure execution of an application on a remote untrusted server. In a TEE, the confidentiality, integrity, and freshness properties for the code and data hold throughout the execution. In a TEE setting, specifically Intel SGX, even the operating system (OS) is not trusted. This results in certain limitations of a secure application’s functionality, such as no access to the file system and network – as it requires OS support.
Prior works have focused on alleviating this problem by allowing an application to access the file system securely. However, we show that they are susceptible to replay attacks, where replaying an old encrypted version of a file may remain undetected. Furthermore, they do not consider the impact of Intel SGX operations on the design of the file system.
To this end, we present SecureFS, a secure, efficient, and scalable file system for Intel SGX that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:AXPGKjj_ei8C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"We use license servers to verify users' credentials and to restrict access to proprietary software. Due to logistical reasons, it is often economical to use third-party servers to manage licenses. Sadly, users on client machines can mount sophisticated attacks on the executables and try to circumvent the license check. This can be used to crack the software, and thus it is necessary for software writers to prevent such attacks, which include the use of additional code to check the integrity of the binary and the control flow. In spite of such techniques, modern control flow bending(CFB) techniques that rely on running instrumented binaries on virtual machines can circumvent such checks and change the behavior of branches and jumps at runtime. They are however extremely computationally inefficient. We propose an AI-based technique that is an order of magnitude faster than the state-of-the-art and show its efficacy by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:WbkHhVStYXYC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"In this paper, we propose an energy efficient and scalable optical interconnect for GPUs. We intelligently divide the components in a GPU into different types of clusters and enable these clusters to communicate optically with each other. In order to reduce the network delay, we use separate networks for coherence and non-coherence traffic. Moreover, to reduce the static power consumption in optical interconnects, we modulate the off-chip light source by proposing a novel GPU specific prediction scheme for on-chip network traffic. Using our design, we were able to increase the performance by 17% and achieve a 65% reduction in ED2 as compared to a state-of-the-art optical topology.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:738O_yMBCRsC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"In the last 15 years, we have witnessed a never ending arm’s race between the attacker and the defender with respect to cache-based side-channel attacks. We have seen a slew of attacks, countermeasures (CMs), counterattacks, counter-countermeasures and so on. We analyze the evolution of this area, propose three necessary conditions for designing a successful CM, and then analyze timing and address-based CMs for popular algorithms such as AES and PRESENT. We show that an optimal yet trivial solution for timing-based CMs is possible. Furthermore, address-based CMs are inferior to timing-based CMs, and they can be broken in O(nlog(log(n))) time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:fEOibwPWpKIC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"The unprecedented growth of edge computing and 5G has led to an increased offloading of mobile applications to cloud servers or edge cloudlets. The most prominent workloads comprise computer vision applications. Conventional wisdom suggests that computer vision workloads perform significantly well on SIMD/SIMT architectures such as GPUs owing to the dominance of linear algebra kernels in their composition. In this work, we debunk this popular belief by performing a lot of experiments with the concurrent execution of these workloads, which is the most popular pattern in which these workloads are executed on cloud servers. We show that the performance of these applications on GPUs does not scale well with an increase in the number of concurrent applications primarily because of contention at the shared resources and lack of efficient virtualization techniques for GPUs. Hence, there is a need to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:JQOojiI6XY0C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Modern UAV s are incredibly complex systems with numerous tunable knobs such as the battery capacity, camera settings, sampling rate, constraints on the route, etc. The area of theoretical exploration of the optimization problems that arise in such settings is dominated by traditional approaches that use regular nonlinear optimization often enhanced with AI-based techniques such as genetic algorithms. These techniques are sadly rather slow, have convergence issues, and are typically not suitable for use at runtime. In this paper, we leverage recent and promising research results that propose to convert the optimization problem into a game and then find the set of equilibrium strategies of different players. The strategies can then be mapped to the optimal values of the tunable parameters. With simulation studies in virtual worlds, we show that our solutions are 5-21% better than those produced by traditional …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:wbdj-CoPYUoC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Designing the ISA (instruction set architecture) is a very critical activity in the entire ASIP (application-specific instruction set processor) design process. There is a long history of using automated tools that suggest custom instructions based on an analysis of the data flow graphs (DFGs) of target programs. Such approaches often create an ISA that is overspecialized for a small set of applications and they often suggest a plethora of custom instructions that cannot be practically implemented. A survey of recent work indicates that adding custom instructions to freely available ISAs such as RISC-V still relies on bespoke analyses and institutional memory. In this paper, we focus on such modern applications, where we only need to add a few instructions to an existing ISA such as RISC-V. The aim is to either supplant or complement the extensive manual analysis that goes into such decision making. We propose an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:J-pR_7NvFogC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"With the growth of edge computing, applicationspecific workloads based on computer vision are steadily migrating to edge cloudlets. Scheduling has been identified to be a major problem in these cloudlets. In this article, we propose a generic architectural solution, VisSched, that leverages the fact that most vision workloads share similar code kernels (such as library code for linear algebra), and as a result, they tend to exhibit similar phase behavior. This allows us to create an auction theory-based scheduling mechanism, where we give each thread a replenishable virtual wallet, and threads are scheduled based on the amounts that they bid for executing on a free core. We show that in 20%-40% of the cases, our scheduling algorithm is theoretically optimal, and in the remaining cases, it reaches a global optimum obtained using Monte Carlo simulations 90%-95% of the time. Our results for the MEVBench vision …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:BrmTIyaxlBUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Photonic networks are already commercially available at the board-level, and many fabrication facilities can fabricate optical networks and integrate them with traditional silicon-based SoCs. Almost all the research in on-chip photonics has been in the areas of performance enhancement and static power reduction. However, before the large-scale adoption of such technologies, it is necessary to solve security problems. As opposed to electrical NoCs, optical NoCs are shared to a much larger extent, and are significantly more sensitive to the latencies of cryptographic operations. Hence, it is necessary to design a novel protocol for securing such networks. We propose a novel, secure, and efficient optical network in this paper (SecONet) that is immune to eavesdropping, spoofing, replay, and message-removal attacks. Using a combination of speculative execution and pre-computation, we reduce the performance …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:D_sINldO8mEC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"When modern systems-on-chip (SoCs), containing designs from different organizations, miscompute or underperform in the field, discerning the responsible component is a non-trivial task. A perfectly accountable system is one in which the on-chip component at fault is always unambiguously detected. The achievement of accountability can be greatly aided by the collection of runtime information that captures the events in the system that led to the error. Such information collection must be fair and impartial to all parties. In this article, we prove that logging messages communicated between components from different organizations is sufficient to provide accountability, provided the logs are authentic. We then construct a solution based on this premise, with an on-chip trusted auditing system to authenticate the logs. We present a thorough design of the auditing system, and demonstrate that its performance overhead …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:b0M2c_1WBrUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"In this work, we present a study of the leakage power modeling techniques commonly used in the architecture community. We further provide an analysis of the error in leakage power estimation using the various modeling techniques. We strongly believe that this study will help researchers determine an appropriate leakage model to use in their work, based on the desired modeling accuracy and speed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:abG-DnoFyZgC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"State of the art XML parsing approaches read an XML file byte by byte, and use complex finite state machines to process each byte. In this paper, we propose a new parser, HPXA, which reads and processes 16 bytes at a time. We designed most of the components ab initio, to ensure that they can process multiple XML tokens and tags in parallel. We propose two basic elements - a sparse 1D array compactor, and a hardware unit called LTMAdder that takes its decisions based on adding the rows of a lower triangular matrix. We demonstrate that we are able to process 16 bytes in parallel with very few pipeline stalls for a suite of widely used XML benchmarks. Moreover, for a 28nm technology node, we can process XML data at 106 Gbps, which is roughly 6.5X faster than competing prior work.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:a0OBvERweLwC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Securing deep neural networks (DNNs) is a problem of significant interest since an ML model incorporates high-quality intellectual property, features of data sets painstakingly collated by mechanical turks, and novel methods of training on large cluster computers. Sadly, attacks to extract model parameters are on the rise, and thus designers are being forced to create architectures for securing such models. State-of-the-art proposals in this field take the deterministic memory access patterns of such networks into cognizance (albeit partially), group a set of memory blocks into a tile, and maintain state at the level of tiles (to reduce storage space). For providing integrity guarantees (tamper avoidance), they don’t propose any significant optimizations, and still maintain block-level state.We observe that it is possible to exploit the deterministic memory access patterns of DNNs even further, and maintain state information for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:_Ybze24A_UAC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Trusted execution environments (TEEs) such as Intel SGX facilitate the secure execution of an application on untrusted machines. A plethora of work focuses on improving the performance of such environments necessitating the need for a standard, widely accepted benchmark suite. We present SGXGauge, a benchmark suite for SGX containing a diverse set of workloads from different domains. We also thoroughly characterize the behavior of the benchmark suite on a native platform and on a platform that uses a library OS-based shim layer (GrapheneSGX).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:NJ774b8OgUMC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Stereo vision algorithms are important building blocks of self-driving applications. The two primary requirements of a self-driving vehicle are real-time operation and nearly 100% accuracy in constructing the 3D scene regardless of the weather conditions and the degree of ambient light. Sadly, most real-time systems as of today provide a level of accuracy that is inadequate and this endangers the life of the passengers; consequently, it is necessary to supplement such systems with expensive LiDAR-based sensors. We observe that for a given scene, different stereo matching algorithms can have vastly different accuracies, and among these algorithms, there is no clear winner. This makes the case for a hybrid stereo vision system where the best stereo vision algorithm for a stereo image pair is chosen by a predictor dynamically, in real-time. We implement such a system called PredStereo in ASIC that combines two diametrically different stereo vision algorithms, CNN-based and traditional, and chooses the best one at runtime. In addition, it associates a confidence with the chosen algorithm, such that the higher-level control system can be switched on in case of a low confidence value. We show that designing a predictor that is explainable and a system that respects soft real-time constraints is non-trivial. Hence, we propose a variety of hardware optimizations that enable our system to work in real-time. Overall, PredStereo improves the disparity estimation error over a state-of-the-art CNN-based stereo vision system by up to 18%(on average 6.25%) with a negligible area overhead (0.003 mm^ 2) while respecting real-time constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:Y5dfb0dijaUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Modern enterprise servers are increasingly embracing tiered memory systems with a combination of low latency DRAMs and large capacity but high latency non-volatile main memories (NVMMs) such as Intel's Optane DC PMM. Prior works have focused on efficient placement and migration of data on a tiered memory system, but have not studied the optimal placement of page tables. Explicit and efficient placement of page tables is crucial for large memory footprint applications with high TLB miss rates because they incur dramatically higher page walk latency when page table pages are placed in NVMM. We show that (i) page table pages can end up on NVMM even when enough DRAM memory is available and (ii) page table pages that spill over to NVMM due to DRAM memory pressure are not migrated back later when memory is available in DRAM. We study the performance impact of page table placement in a tiered memory system and propose an efficient and transparent page table management technique that (i) applies different placement policies for data and page table pages, (ii) introduces a differentiating policy for page table pages by placing a small but critical part of the page table in DRAM, and (iii) dynamically and judiciously manages the rest of the page table by transparently migrating the page table pages between DRAM and NVMM. Our implementation on a real system equipped with Intel's Optane NVMM running Linux reduces the page table walk cycles by 12% and total cycles by 20% on an average. This improves the runtime by 20% on an average for a set of synthetic and real-world large memory footprint applications …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:XiVPGOgt02cC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"With rising power densities in modern-day electronic systems, temperature has emerged as a fundamental design constraint. This has led to the advent of a range of thermal-aware design and runtime management techniques. However, such techniques are heavily dependent on a fast and accurate thermal modeling method. These methods need to account for manufacturing variability, that significantly impacts the chip's power and performance. Similarly, leakage power too contributes to a substantial portion of the total power. Thus a thermal modeling method can be accurate only if it is capable of incorporating the effects of process variation as well as leakage power. In this paper, we propose a simple and elegant residual convolutional neural network for thermal estimation in the presence of variability, which leverages the physics of heat transfer. Our approach is capable of modeling modern-day 3D chips with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:5ugPr518TE4C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"In this paper, we present a fast, compact thermal model for modeling the temperature of smartphones. Existing approaches use the finite element (FEM) or finite difference (FDM) based methods that are very slow. Even fast Green's function-based approaches always use such FEM/FDM based approaches to compute the Green's function (impulse response of a power source) in the first place. This significantly slows down the process of design space exploration. To ameliorate this, we propose an ultra-fast model that can be used to model the temperature of mobile phones: we use simple polynomial or exponential expressions to compute the Green's functions. These expressions can be evaluated very quickly and can be generalized for a wide variety of electronic components. In a smartphone, analysis of the temperature hotspots is very crucial in the design process. We can estimate the location of hotspots and the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:1qzjygNMrQYC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"Energy harvesting devices (EHDs) are becoming extremely prevalent in remote and hazardous environments. They sense the ambient parameters and compute some statistics on them, which are then sent to a remote server. Due to the resource-constrained nature of EHDs, it is challenging to perform exact computations on streaming data; however, if we are willing to tolerate a slight amount of inaccuracy, we can leverage the power of sketching algorithms to provide quick answers with significantly lower energy consumption.
In this paper, we propose a novel hardware architecture called EHDSktch -- a set of IP blocks that can be used to implement most of the popular sketching algorithms. We demonstrate an energy savings of 4-10X and a speedup of more than 10X over state-of-the-art software implementations. Leveraging the temporal locality further provides us a performance gain of 3-20% in energy and time …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:V3AGJWp-ZtQC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",23,"With the advent of edge computing and 5G, multiple mobile applications are being offloaded to cloud servers to meet their computational demands. Computer vision workloads dominate this space. Since the vision workloads are composed of linear algebra kernels, they perform significantly well on SIMT/SIMD architectures such as GPUs. While an application can maximize its performance on a GPU when it is the sole consumer of the GPU's resources, it fails to maintain that performance in a multi-application scenario. The primary cause of this problem is the lack of efficient virtualization techniques for GPUs and contention among the applications for the shared resources. Sadly, most of the prior work in this area is devoted to predicting single application performance. To the best of our knowledge we propose the first machine learning based predictor to predict the performance of an ensemble of applications on a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&citation_for_view=-5JfCRsAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitd.ac.in/~srsarangi
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"We study the fair and efficient allocation of a set of indivisible goods among agents, where each good has several copies, and each agent has an additively separable concave valuation function with a threshold. These valuations capture the property of diminishing marginal returns, and they are more general than the well-studied case of additive valuations. We present a polynomial-time algorithm that approximates the optimal Nash social welfare (NSW) up to a factor of e 1/e≈ 1.445. This matches with the state-of-the-art approximation factor for additive valuations. The computed allocation also satisfies the popular fairness guarantee of envy-freeness up to one good (EF1) up to a factor of 2+ ε. For instances without thresholds, it is also approximately Pareto-optimal. For instances satisfying a large market property, we show an improved approximation factor. Lastly, we show that the upper bounds on the optimal NSW introduced in Cole and Gkatzelis (2018) and Barman et al.(2018) have the same value.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:WZBGuue-350C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"For a 3-edge-connected cubic graph G=(V, E), we give an algorithm to construct a connected Eulerian subgraph of 2 G using at most⌊ 4| V|∕ 3⌋ edges.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:KUbvn5osdkgC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"The notion of competitive ratio often turns out to be too pessimistic for the analysis of online algorithms. Although the approach of resource augmentation (introduced by Kalyanasundaram and Pruhs) has been very successful in dealing with a variety of objective functions, there are problems for which even a (arbitrary) constant speedup cannot lead to a constant competitive algorithm. Here we propose a rejection model which permits the online algorithm to not serve epsilon-fraction of requests. We present O (log 2⁡ 1/ε) and O (1/ε 4)-competitive algorithms for the problems of load balancing and minimizing maximum flow time in the restricted assignment setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:nrtMV_XWKgEC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"In the weighted flow-time problem on a single machine, we are given a set of jobs, where each job has a processing requirement , release date , and weight . The goal is to find a preemptive schedule which minimizes the sum of weighted flow-time of jobs, where the flow-time of a job is the difference between its completion time and its released date. We give the first pseudo-polynomial time constant approximation algorithm for this problem. The algorithm also extends directly to the problem of minimizing the norm of weighted flow-times. The running time of our algorithm is polynomial in , the number of jobs, and , which is the ratio of the largest to the smallest processing requirement of a job. Our algorithm relies on a novel reduction of this problem to a generalization of the multicut problem on trees, which we call the Demand MultiCut problem. Even though we do not give a constant factor …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:TIZ-Mc8IlK0C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"Given n jobs with release dates, deadlines and processing times we consider the problem of scheduling them on m parallel machines so as to minimize the total energy consumed. Machines can enter a sleep state and they consume no energy in this state. Each machine requires L units of energy to awaken from the sleep state and in its active state the machine can process jobs and consumes a unit of energy per unit time. We allow for preemption and migration of jobs and provide the first constant approximation algorithm for this problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:EYYDruWGBe4C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"We consider the online problem of scheduling jobs on identical machines, where jobs have precedence constraints. We are interested in the demanding setting where the jobs sizes are not known up-front, but are revealed only upon completion (the non-clairvoyant setting). Such precedence-constrained scheduling problems routinely arise in map-reduce and large-scale optimization. In this paper, we make progress on this problem. For the objective of total weighted completion time, we give a constant-competitive algorithm. And for total weighted flow-time, we give an -competitive algorithm under -speed augmentation and a natural ``no-surprises'' assumption on release dates of jobs (which we show is necessary in this context). Our algorithm proceeds by assigning {\em virtual rates} to all the waiting jobs, including the ones which are dependent on other uncompleted jobs, and then use these virtual rates to decide on the actual rates of minimal jobs (i.e., jobs which do not have dependencies and hence are eligible to run). Interestingly, the virtual rates are obtained by allocating time in a fair manner, using a Eisenberg-Gale-type convex program (which we can also solve optimally using a primal-dual scheme). The optimality condition of this convex program allows us to show dual-fitting proofs more easily, without having to guess and hand-craft the duals. We feel that this idea of using fair virtual rates should have broader applicability in scheduling problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:g3aElNc5_aQC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"In this paper, we bound the integrality gap and the approximation ratio for maximum plane multiflow problems and deduce bounds on the flow-multicut-gap. We consider instances where the union of the supply and demand graphs is planar and prove that there exists a multiflow of value at least half the capacity of a minimum multicut. We then show how to convert any multiflow into a half-integer flow of value at least half the original multiflow. Finally, we round any half-integer multiflow into an integer multiflow, losing at most half the value thus providing a 1/4-approximation algorithm and integrality gap for maximum integer multiflows in the plane.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:k8Z6L05lTy4C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"Given an edge weighted graph and a forest $F$, the $\textit{2-edge connectivity augmentation problem}$ is to pick a minimum weighted set of edges, $E'$, such that every connected component of $E'\cup F$ is 2-edge connected. Williamson et al. gave a 2-approximation algorithm (WGMV) for this problem using the primal-dual schema. We show that when edge weights are integral, the WGMV procedure can be modified to obtain a half-integral dual. The 2-edge connectivity augmentation problem has an interesting connection to routing flow in graphs where the union of supply and demand is planar. The half-integrality of the dual leads to a tight 2-approximate max-half-integral-flow min-multicut theorem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:BwyfMAYsbu0C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"In this paper, we propose and analyze a local search algorithm for the Universal facility location problem. Our algorithm improves the approximation ratio of this problem from 5.83, given by Angel et al., to 5. A second major contribution of the paper is that it gets rid of the expensive multi operation that was a mainstay of all previous local search algorithms for capacitated facility location and universal facility location problem. The only operations that we require to prove the 5-approximation are add, open, and close. A multi operation is basically a combination of the open and close operations. The 5-approximation algorithm for the capacitated facility location problem, given by Bansal et al., also uses the multi operation. However, on careful observation, it turned out that add, open, and close operations are sufficient to prove a 5-factor for the problem. This resulted into an improved algorithm for the universal facility location problem, with an improved factor.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:gsN89kCJA0AC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"Vehicle routing problems are a broad class of combinatorial optimization problems that can be formulated as the problem of finding a tour in a weighted graph that optimizes some function of the visited vertices. For instance, a canonical and extensively studied vehicle routing problem is the orienteering problem where the goal is to find a tour that maximizes the number of vertices visited by a given deadline. In this paper, we consider the computational tractability of a well-known generalization of the orienteering problem called the Orient-MTW problem. The input to Orient-MTW consists of a weighted graph G(V, E) where for each vertex v ∊ V we are given a set of time instants Tv ⊆ [T], and a source vertex s. A tour starting at s is said to visit a vertex v if it transits through v at any time in the set Tv. The goal is to find a tour starting at the source vertex that maximizes the number of vertices visited. It is known that this …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:ML0RJ9NH7IQC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",33,"In this paper, we consider the problem of locating service and charging stations to serve commuters. In the service station location problem we are given the paths followed by m clients and wish to locate k service stations, from a set of feasible locations, such that the maximum detour that a client has to take is minimized. We give a solution that has a maximum detour \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$3\texttt{OPT}+L$$\end{document} where L is the length of the longest client-path.
Electric vehicles have a limited range and charging stations need to be located so that a client can drive from the source to destination without running out of charge. We consider two variants of the problem …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&cstart=20&pagesize=80&citation_for_view=wNRE148AAAAJ:S16KYo8Pm5AC,http://www.cse.iitd.ac.in/~naveen/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",10,"Mobile app energy profilers provide a foundational energy diagnostic tool by identifying energy hotspots in the app source code. However, they only tackle the first challenge faced by developers, as, after presented with the energy hotspots, developers typically do not have any guidance on how to proceed with the remaining optimization process:(1) Is there a more energy-efficient implementation for the same app task?(2) How to come up with the more efficient implementation?",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&citation_for_view=_af8suQAAAAJ:pyW8ca7W8N0C,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",10,"A differential resource analyzer performs differential resource profiling of two applications. The two applications are made to perform an operation. The differential resource analyzer matches a first application task of a first application to a second application task of a second application based on a determination that the first application task is similar to the second application task, and measures resource consumed in the first application task and the second application task. Responsive to determining that the second application task consumes less resource than the first application task, the differential resource analyzer performs an action to reduce resource consumption by the first application based on the second application task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&citation_for_view=_af8suQAAAAJ:_xSYboBqXhAC,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",10,"Embodiments of the present invention provide a system and methods for detecting power bugs. In one embodiment, a computer-implemented method for analyzing a computer code includes generating a control flow graph for at least a portion of the computer code at a processor. The method further includes identifying power bugs by traversing the control flow graph if the control flow graph exits without performing a function call to deactivate power to any component of a device configured to execute computer executable instructions based on the computer code after performing a function call to activate power.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&citation_for_view=_af8suQAAAAJ:EUQCXRtRnyEC,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",10,"In this paper, we report on our 6-year experience developing Eagle Tester (eTester for short) - a mobile battery drain testing and diagnostic tool. We show how eTester evolved from an ""academic"" prototype to a fully automated tool usable by the mobile industry.
We first present the design of our initial research prototype and discuss 8 key requirements for a usable battery drain testing and diagnostic tool gathered from some of the most popular software vendors in the Android ecosystem. These requirements posed interesting scientific and engineering challenges such as how to accurately estimate battery drain without requiring a priori power modeling, work on unmodified devices, and automatically monitor code evolution to generate high-fidelity battery spike alerts with actionable insights. These requirements motivated a complete overhaul of the eTester design and led to the creation of a novel battery drain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&citation_for_view=_af8suQAAAAJ:b0M2c_1WBrUC,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",10,"In this paper, we observe that modern mobile apps come with a large number of parameters that control the app behavior which indirectly affect the app energy drain, and using incorrect or non-optimal values for such app parameters can lead to app energy drain deficiency or even energy bugs. We argue conventional app energy optimization using an energy profiler which pinpoints energy hotspot code segments in the app source code may be ineffective in detecting such parameter-induced app energy deficiency. We propose app parameter energy profiling which identifies tunable app parameters that can reduce app energy drain without affecting app functions as a potentially more effective solution for debugging such app energy deficiency. We present the design and implementation of Medusa, an app parameter energy profiling framework. Medusa overcomes three key design challenges: how to filter out and narrow down candidate parameters, how to pick alternative parameter values, and how to perform reliable energy drain testing of app versions with mutated parameter values. We demonstrate the effectiveness of Medusa by applying it to a set of Android apps which successfully identifies tunable energy-reducing parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&citation_for_view=_af8suQAAAAJ:bFI3QPDXJZMC,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",10,"Improving software performance through configuration parameter tuning is a common activity during software maintenance. Beyond traditional performance metrics like latency, mobile app developers are interested in reducing app energy usage. Some mobile apps have centralized locations for parameter tuning, similar to databases and operating systems, but it is common for mobile apps to have hundreds of parameters scattered around the source code. The correlation between these “deep” parameters and app energy usage is unclear. Researchers have studied the energy effects of deep parameters in specific modules, but we lack a systematic understanding of the energy impact of mobile deep parameters. In this paper we empirically investigate this topic, combining a developer survey with systematic energy measurements. Our motivational survey of 25 Android developers suggests that developers do not …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&citation_for_view=_af8suQAAAAJ:NhqRSupF_l8C,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",10,"Embodiments of the present invention provide a system and methods for detecting power bugs. In one embodiment, a computer-implemented method for analyzing a computer code includes generating a control flow graph for at least a portion of the computer code at a processor. The method further includes identifying power bugs by traversing the control flow graph if the control flow graph exits without performing a function call to deactivate power to any component of a device configured to execute computer executable instructions based on the computer code after performing a function call to activate power.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&citation_for_view=_af8suQAAAAJ:abG-DnoFyZgC,http://abhilash-jindal.com/
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&citation_for_view=K4w5qYUAAAAJ:rbm3iO8VlycC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"We study the problem of route recommendation to idle taxi drivers such that the distance between the taxi and an anticipated customer request is minimized. Minimizing the distance to the next anticipated customer leads to more productivity for the taxi driver and less waiting time for the customer. To anticipate when and where future customer requests are likely to come from and accordingly recom- mend routes, we develop a route recommendation engine called MDM: Minimizing Distance through Monte Carlo Tree Search. In contrast to existing techniques, MDM employs a continuous learning platform where the underlying model to predict future customer requests is dynamically updated. Extensive experiments on real taxi data from New York and San Francisco reveal that MDM is up to 70% better than the state of the art and robust to anomalous events such as concerts, sporting events, etc.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&citation_for_view=K4w5qYUAAAAJ:YsrPvlHIBpEC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"There has been an increased interest in discovering heuristics for combinatorial problems on graphs through machine learning. While existing techniques have primarily focused on obtaining high-quality solutions, scalability to billion-sized graphs has not been adequately addressed. In addition, the impact of a budget-constraint, which is necessary for many practical scenarios, remains to be studied. In this paper, we propose a framework called GCOMB to bridge these gaps. GCOMB trains a Graph Convolutional Network (GCN) using a novel probabilistic greedy mechanism to predict the quality of a node. To further facilitate the combinatorial nature of the problem, GCOMB utilizes a Q-learning framework, which is made efficient through importance sampling. We perform extensive experiments on real graphs to benchmark the efficiency and efficacy of GCOMB. Our results establish that GCOMB is 100 times faster and marginally better in quality than state-of-the-art algorithms for learning combinatorial algorithms. Additionally, a case-study on the practical combinatorial problem of Influence Maximization (IM) shows GCOMB is 150 times faster than the specialized IM algorithm IMM with similar quality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&citation_for_view=K4w5qYUAAAAJ:CYCckWUYoCcC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Graph generative models have been extensively studied in the data mining literature. While traditional techniques are based on generating structures that adhere to a pre-decided distribution, recent techniques have shifted towards learning this distribution directly from the data. While learning-based approaches have imparted significant improvement in quality, some limitations remain to be addressed. First, learning graph distributions introduces additional computational overhead, which limits their scalability to large graph databases. Second, many techniques only learn the structure and do not address the need to also learn node and edge labels, which encode important semantic information and influence the structure itself. Third, existing techniques often incorporate domain-specific rules and lack generalizability. Fourth, the experimentation of existing techniques is not comprehensive enough due to either …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&citation_for_view=K4w5qYUAAAAJ:69ZgNCALVd0C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"In taxi ride-sharing, multiple customers are allotted to the same taxi as long as they are compatible, i.e., if none of them suffers a detour beyond a permissible threshold. To attract customers to ride-sharing, taxi operators promise a reduced fare upfront. As a result, if the taxi fails to pair the initial customer with additional compatible passengers, the taxi operator incurs a financial loss. Hence, it is important to ensure that the taxi finds compatible customers once it has picked up the initial customer. In the current scenario, the appearance of subsequent compatible customers is left to luck: a taxi moves along the shortest (or quickest) path for the existing customer and hopes to find additional compatible customers on its way. In this paper, we ask: Is the shortest path the optimal path for ride-sharing? To investigate this question, we develop a route recommendation algorithm called Share, which predicts the route with the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&citation_for_view=K4w5qYUAAAAJ:SGW5VrABaM0C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"A fundamental query in labeled graphs is to determine if there exists a path between a given source and target vertices, such that the path satisfies a given label constraint. One of the powerful forms of specifying label constraints is through regular expressions, and the resulting problem of reachability queries under regular simple paths (RSP) form the core of many practical graph query languages such as SPARQL from W3C, Cypher of Neo4J, Oracle's PGQL and LDBC's G-CORE. Despite its importance, since it is known that answering RSP queries is NP-Hard, there are no scalable and practical solutions for answering reachability with full-range of regular expressions as constraints. In this paper, we circumvent this computational bottleneck by designing a random-walk based sampling algorithm called ARRIVAL, which is backed by theoretical guarantees on its expected quality. Extensive experiments on billion …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&citation_for_view=K4w5qYUAAAAJ:2l5NCbZemmgC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"A search query, being a very concise grounding of user intent, could potentially have many possible interpretations. Search engines hedge their bets by diversifying top results to cover multiple such possibilities so that the user is likely to be satisfied, whatever be her intended interpretation. Diversified Query Expansion is the problem of diversifying query expansion suggestions, so that the user can specialize the query to better suit her intent, even before perusing search results. In this paper, we consider the usage of semantic resources and tools to arrive at improved methods for diversified query expansion. In particular, we develop two methods, those that leverage Wikipedia and pre-learnt distributional word embeddings respectively. Both the approaches operate on a common three-phase framework; that of first taking a set of informative terms from the search results of the initial query, then building a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&citation_for_view=K4w5qYUAAAAJ:uVUOdF_882EC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"An efficient public bus transit service is critical to achieving sustainable urban transport. To design an efficient bus transit system, a fundamental requirement is the complete list of all bus stops in the city. Often the bus stops are owned and maintained by a different government entity from that which plans and operates the buses. As a result, bus stop information is incomplete, erroneous, and outdated leading to sub-optimal planning and operations and consequent reduction in the transit agency's ridership. In this work, we propose an algorithm to mine bus stops automatically from bus GPS trajectories. The proposed technique is powered by a novel combination of feature mining with classification algorithms to predict bus stops in a city. Our technique negates the need for manual field visits to annotate bus stops and saves time and cost for transit agencies. We perform extensive empirical analysis on real datasets …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:mUJArPsKIAAC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Several services today are annotated with points of interest (PoIs) such as ""coffee shop"", ""park"", etc. In this paper, we study the query where a user provides a set of relevant PoIs and wants to identify the optimal route covering these PoIs. Ideally, the route should be small in length so that the user can conveniently explore the PoIs. On the other hand, the route should cover as many of the input PoIs as possible. These conflicting requirements of the optimal route raise an intriguing question: how do you balance the importance of route length vs. PoI coverage? If the route is to be covered on foot, and it is raining, length is critical for convenience. On the other hand, if the weather conditions are good, or the user is equipped with a vehicle, coverage is more important. In essence, the relative importance depends on several latent factors and we solve this dilemma through skyline route queries. Skyline routes subsume the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:pS0ncopqnHgC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"In several domains, the flow of data is governed by an underlying network. Reduction of delays in end-to-end data flow is an important network optimization task. Reduced delays enable shorter travel times for vehicles in road networks, faster information flow in social networks, and increased rate of packets in communication networks. While techniques for network delay minimization have been proposed, they fail to provide any noticeable reduction in individual data flows. Furthermore, they treat all nodes as equally important, which is often not the case in real-world networks. In this paper, we incorporate these practical aspects and propose a network design problem where the goal is to perform k network upgrades such that it maximizes the number of flows in the network with a noticeable reduction in delay. We show that the problem is NP-hard, APX-hard, and non-submodular. We overcome these computational …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:ziOE8S1-AIUC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Given a stream of food orders and available delivery vehicles, how should orders be assigned to vehicles so that the delivery time is minimized? For a successful assignment strategy, two key decisions need to be made: (1) assignment of orders to vehicles, (2) grouping orders into batches to cope with limited vehicle availability. We show that the minimization problem is not only NP-hard but inapproximable in polynomial time. To mitigate this computational bottleneck, we develop an algorithm called FOODMATCH, which maps the vehicle assignment problem to that of minimum weight perfect matching on a bipartite graph. The solution quality is further enhanced by reducing batching to a graph clustering problem. Extensive experiments on food-delivery data from large metropolitan cities establish that FOODMATCH is substantially better than baseline strategies on a number of metrics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:HJSXoJQnj-YC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Majority of the existing graph neural networks (GNN) learn node embeddings that encode their local neighborhoods but not their positions. Consequently, two nodes that are vastly distant but located in similar local neighborhoods map to similar embeddings in those networks. This limitation prevents accurate performance in predictive tasks that rely on position information. In this paper, we develop GraphReach, a position-aware inductive GNN that captures the global positions of nodes through reachability estimations with respect to a set of anchor nodes. The anchors are strategically selected so that reachability estimations across all the nodes are maximized. We show that this combinatorial anchor selection problem is NP-hard and, consequently, develop a greedy (1-1/e) approximation heuristic. Empirical evaluation against state-of-the-art GNN architectures reveal that GraphReach provides up to 40% relative improvement in accuracy. In addition, it is more robust to adversarial attacks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:JTqpx9DYBaYC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"We investigate the problem of correlated subgraphs mining (CSM) where the goal is to identify pairs of subgraph patterns that frequently co-occur in proximity within a single graph. Correlated subgraph patterns are different from frequent subgraphs due to the flexibility in connections between constituent subgraph instances and thus, existing frequent subgraphs mining algorithms cannot be directly applied for CSM. Moreover, computing the degree of correlation between two patterns requires enumerating and finding distances between every pair of subgraph instances of both patterns - a task that is both memory-intensive as well as computationally demanding. To this end, we propose two holistic best-first exploration algorithms: CSM-E (an exact method) and CSM-A (a more efficient approximate method with near-optimal quality). To further improve efficiency, we propose a top-k pruning strategy, while to reduce …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:SnGPuo6Feq8C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Mining subgraph patterns is an active area of research due to its wide-ranging applications. Examples include frequent subgraph mining, discriminative subgraph mining, statistically significant subgraphs. Existing research has primarily focused on mining all subgraph patterns in the database. However, due to the exponential subgraph search space, the number of patterns mined, typically, is too large for any human-mediated analysis. Consequently, deriving insights from the mined patterns is hard for domain scientists. In addition, subgraph pattern mining is posed in multiple forms: the function that models if a subgraph is a pattern varies based on the application and the database could be over multiple graphs or a single, large graph. In this paper, we ask the following question: Given a subgraph importance function and a budget k, which are the k subgraph patterns that best represent all other patterns of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:3bvyWxjaHKcC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Similarity search in graph databases is one of the most fundamental operations in graph analytics. Among various distance functions, graph and subgraph edit distances (GED and SED respectively) are two of the most popular and expressive measures. Unfortunately, exact computations for both are NP-hard. To overcome this computational bottleneck, neural approaches to learn and predict edit distance in polynomial time have received much interest. While considerable progress has been made, there exist limitations that need to be addressed. First, the efficacy of an approximate distance function lies not only in its approximation accuracy, but also in the preservation of its properties. To elaborate, although GED is a metric, its neural approximations do not provide such a guarantee. This prohibits their usage in higher order tasks that rely on metric distance functions, such as clustering or indexing. Second, several existing frameworks for GED do not extend to SED due to SED being asymmetric. In this work, we design a novel siamese graph neural network called Greed, which through a carefully crafted inductive bias, learns GED and SED in a property-preserving manner. Through extensive experiments across real graph datasets containing up to million edges, we establish that Greed is not only more accurate than the state of the art, but also up to orders of magnitude faster. Even more significantly, due to preserving the triangle inequality, the generated embeddings are indexable and consequently, even in a CPU-only environment, Greed is up to times faster than GPU-powered computations of the closest baseline.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:zdjWy_NXXwUC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"The inherent conflict between noncovalent interactions and the large conformational entropy of the polypeptide chain forces folding reactions and their mechanisms to deviate significantly from chemical reactions. Accordingly, measures of structure in the transition state ensemble (TSE) are strongly influenced by the underlying distributions of microscopic folding pathways that are challenging to discern experimentally. Here, we present a detailed analysis of 150,000 folding transition paths of five proteins at three different thermodynamic conditions from an experimentally consistent statistical mechanical model. We find that the underlying TSE structural distributions are rarely unimodal, and the average experimental measures arise from complex underlying distributions. Unfolding pathways also exhibit subtle differences from folding counterparts due to a combination of Hammond behavior and native-state …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:oi2SiIJ9l4AC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Physical systems are commonly represented as a combination of particles, the individual dynamics of which govern the system dynamics. However, traditional approaches require the knowledge of several abstract quantities such as the energy or force to infer the dynamics of these particles. Here, we present a framework, namely, Lagrangian graph neural network (LGnn), that provides a strong inductive bias to learn the Lagrangian of a particle-based system directly from the trajectory. We test our approach on challenging systems with constraints and drag—LGnn outperforms baselines such as feed-forward Lagrangian neural network (Lnn) with improved performance. We also show the zero-shot generalizability of the system by simulating systems two orders of magnitude larger than the trained one and also hybrid systems that are unseen by the model, a unique feature. The graph architecture of LGnn …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:-DxkuPiZhfEC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Lagrangian and Hamiltonian neural networks LNN and HNNs, respectively) encode strong inductive biases that allow them to outperform other models of physical systems significantly. However, these models have, thus far, mostly been limited to simple systems such as pendulums and springs or a single rigid body such as a gyroscope or a rigid rotor. Here, we present a Lagrangian graph neural network (LGNN) that can learn the dynamics of articulated rigid bodies by exploiting their topology. We demonstrate the performance of LGNN by learning the dynamics of ropes, chains, and trusses with the bars modeled as rigid bodies. LGNN also exhibits generalizability---LGNN trained on chains with a few segments exhibits generalizability to simulate a chain with large number of links and arbitrary link length. We also show that the LGNN can simulate unseen hybrid systems including bars and chains, on which they have not been trained on. Specifically, we show that the LGNN can be used to model the dynamics of complex real-world structures such as the stability of tensegrity structures. Finally, we discuss the non-diagonal nature of the mass matrix and its ability to generalize in complex systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:wE-fMHVdjMkC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"In signed networks, each edge is labeled as either positive or negative. The edge sign captures the polarity of a relationship. Balance of signed networks is a well-studied property in graph theory. In a balanced (sub)graph, the vertices can be partitioned into two subsets with negative edges present only across the partitions. Balanced portions of a graph have been shown to increase coherence among its members and lead to better performance. While existing works have focused primarily on finding the largest balanced subgraph inside a graph, we study the network design problem of maximizing balance of a target community (subgraph). In particular, given a budget b and a community of interest within the signed network, we aim to make the community as close to being balanced as possible by deleting up to b edges. Besides establishing NP-hardness, we also show that the problem is non-monotone and non …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:PkcyUWeTMh0C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Realistic models of physical world rely on differentiable symmetries that, in turn, correspond to conservation laws. Recent works on Lagrangian and Hamiltonian neural networks show that the underlying symmetries of a system can be easily learned by a neural network when provided with an appropriate inductive bias. However, these models still suffer from issues such as inability to generalize to arbitrary system sizes, poor interpretability, and most importantly, inability to learn translational and rotational symmetries, which lead to the conservation laws of linear and angular momentum, respectively. Here, we present a momentum conserving Lagrangian neural network (MCLNN) that learns the Lagrangian of a system, while also preserving the translational and rotational symmetries. We test our approach on linear and non-linear spring systems, and a gravitational system, demonstrating the energy and momentum conservation. We also show that the model developed can generalize to systems of any arbitrary size. Finally, we discuss the interpretability of the MCLNN, which directly provides physical insights into the interactions of multi-particle systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:UuEBAcK4md4C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Instead of measuring the betweenness of a node with respect to an individual source and an individual target node, we consider the case where the source, as well as the target, are two groups of nodes. To concretize this, we present Group-to-group random walk betweenness centrality, which is a generalization of random walk betweenness proposed by Newman (2005). We also show an interesting connection between the Laplacian equations and the hitting times of random walks, which allows us to use Laplacian solvers to compute our metric efficiently. Using our new centrality, we study a setting where a source group of nodes is infected and we wish to vaccinate or quarantine a limited number of uninfected nodes in such a way that the target group of nodes is protected and the infection is controlled. Empirical evaluation on real-world networks establishes that our group-to-group centrality metric is more …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:IsPWOBWtZBwC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"We have developed a new algorithm for tracking 3D seismic horizons. The algorithm combines an inversion-based, seismic-dip flattening technique with conventional, similarity-based autotracking. The inversion part of the algorithm aims to minimize the error between horizon dips and computed seismic dips. After each cycle in the inversion loop, more seeds are added to the horizon by the similarity-based autotracker. In the example data set, the algorithm is first used to quickly track a set of framework horizons, each guided by a small set of user-picked seed positions. Next, the intervals bounded by the framework horizons are infilled to generate a dense set of horizons, also known as HorizonCube. This is done under the supervision of a human interpreter in a similar manner. The results show that the algorithm behaves better than unconstrained flattening techniques in intervals with trackable events …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:TlpoogIpr_IC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"The ability to search for a query molecule on massive molecular repositories is a fundamental task in chemoinformatics and drug-discovery. Chemical fingerprints are commonly used to characterize the structure and properties of molecules. Some fingerprints, particularly unfolded fingerprints, are often of extreme high dimension and sparse where only few features have a positive value. In this work, we propose a new searching algorithm, RISC, which exploits sparsity in high-dimensional fingerprints to derive effective pruning mechanisms and dramatically speed-up searching efficiency. RISC is robust enough to work on both binary and nonbinary chemical fingerprints. Extensive experiments on Range Queries and Top-k Queries across several molecular repositories demonstrate that at fingerprints of dimension 2048 and above, which is often the case with unfolded fingerprints, RISC is consistently faster than the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:An6A6Jpfc1oC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Recently, graph neural networks have been gaining a lot of attention to simulate dynamical systems due to their inductive nature leading to zero-shot generalizability. Similarly, physics-informed inductive biases in deep-learning frameworks have been shown to give superior performance in learning the dynamics of physical systems. There is a growing volume of literature that attempts to combine these two approaches. Here, we evaluate the performance of thirteen different graph neural networks, namely, Hamiltonian and Lagrangian graph neural networks, graph neural ODE, and their variants with explicit constraints and different architectures. We briefly explain the theoretical formulation highlighting the similarities and differences in the inductive biases and graph architecture of these systems. We evaluate these models on spring, pendulum, gravitational, and 3D deformable solid systems to compare the performance in terms of rollout error, conserved quantities such as energy and momentum, and generalizability to unseen system sizes. Our study demonstrates that GNNs with additional inductive biases, such as explicit constraints and decoupling of kinetic and potential energies, exhibit significantly enhanced performance. Further, all the physics-informed GNNs exhibit zero-shot generalizability to system sizes an order of magnitude larger than the training system, thus providing a promising route to simulate large-scale realistic systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:g5Ck-dwhA_QC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Neural networks with physics based inductive biases such as Lagrangian neural networks (LNN), and Hamiltonian neural networks (HNN) learn the dynamics of physical systems by encoding strong inductive biases. Alternatively, Neural ODEs with appropriate inductive biases have also been shown to give similar performances. However, these models, when applied to particle based systems, are transductive in nature and hence, do not generalize to large system sizes. In this paper, we present a graph based neural ODE, GNODE, to learn the time evolution of dynamical systems. Further, we carefully analyse the role of different inductive biases on the performance of GNODE. We show that, similar to LNN and HNN, encoding the constraints explicitly can significantly improve the training efficiency and performance of GNODE significantly. Our experiments also assess the value of additional inductive biases, such as Newtons third law, on the final performance of the model. We demonstrate that inducing these biases can enhance the performance of model by orders of magnitude in terms of both energy violation and rollout error. Interestingly, we observe that the GNODE trained with the most effective inductive biases, namely MCGNODE, outperforms the graph versions of LNN and HNN, namely, Lagrangian graph networks (LGN) and Hamiltonian graph networks (HGN) in terms of energy violation error by approx 4 orders of magnitude for a pendulum system, and approx 2 orders of magnitude for spring systems. These results suggest that competitive performances with energy conserving neural networks can be obtained for NODE based systems …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:X9ykpCP0fEIC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"There has been a recent surge in learning generative models for graphs. While impressive progress has been made on static graphs, work on generative modeling of temporal graphs is at a nascent stage with significant scope for improvement. First, existing generative models do not scale with either the time horizon or the number of nodes. Second, existing techniques are transductive in nature and thus do not facilitate knowledge transfer. Finally, due to relying on one-to-one node mapping from source to the generated graph, existing models leak node identity information and do not allow up-scaling/down-scaling the source graph size. In this paper, we bridge these gaps with a novel generative model called TIGGER. TIGGER derives its power through a combination of temporal point processes with auto-regressive modeling enabling both transductive and inductive variants. Through extensive experiments on real datasets, we establish TIGGER generates graphs of superior fidelity, while also being up to 3 orders of magnitude faster than the state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:SIv7DqKytYAC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Food delivery, today, is a multi-billion dollar industry. Minimizing food delivery time is a key contributor towards building positive customer experiences. More precisely, given a stream of food orders and available delivery vehicles, how should orders be assigned to vehicles so the delivery time is minimized? Several decisions have to be made: (1) assignment of orders to vehicles, (2) grouping orders into batches to cope with limited vehicle availability, (3) adapting to dynamic positions of delivery vehicles, and (4) ensuring scalability to the demands of real-world workloads. We show that the minimization problem is not only NP-hard but inapproximable in polynomial time. To mitigate this computational bottleneck, we develop an algorithm called FoodMatch, which maps the vehicle assignment problem to that of minimum weight perfect matching on a bipartite graph. To further reduce the quadratic construction cost of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:UmS_249rOGwC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"The phenomenal growth of graph data from a wide variety of real-world applications has rendered graph querying to be a problem of paramount importance. Traditional techniques use structural as well as node similarities to find matches of a given query graph in a (large) target graph. However, almost all existing techniques have tacitly ignored the presence of relationships in graphs, which are usually encoded through interactions between node and edge labels. In this paper, we propose RAQ-Relationship-Aware Graph Querying-to mitigate this gap. Given a query graph, RAQ identifies the k best matching subgraphs of the target graph that encode similar relationships as in the query graph. To assess the utility of RAQ as a graph querying paradigm for knowledge discovery and exploration tasks, we perform a user survey on the Internet Movie Database (IMDb), where an overwhelming 86% of the 170 surveyed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:DkZNVXde3BIC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"The steady growth of graph data from social networks has resulted in wide-spread research on the influence maximization (IM) problem. This results in extension of the state-of-the-art almost every year. With the recent explosion in the application of IM in solving real-world problems, it is no longer a theoretical exercise. Today, IM is used in a plethora of real-world scenarios, with OnePlus 1 series of mobile phones, Hokey Pokey 2 ice-creams, and galleri5 influencer marketplace 3 being the most prominent industrial use-cases. Given this scenario, navigating the maze of IM techniques to get an in-depth understanding of their utilities is of prime importance. In this tutorial, we address this paramount issue and solve the dilemma of “Which IM technique to use and under What scenarios”?“What does it really mean to claim to be the state-of-the-art”?
This tutorial builds upon our benchmarking study [1], and will provide a concise and intuitive overview of the most important IM techniques, which is usually lost in the technical literature. Specifically, we will unearth a series of incorrect claims made by prominent IM papers, disseminate the inherent deficiencies of existing approaches, and surface the open challenges in IM even after a decade of research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:eO3_k5sD8BwC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Predicting the most likely route from a source location to a destination is a core functionality in mapping services. Although the problem has been studied in the literature, two key limitations remain to be addressed. First, our study reveals that a significant portion of the routes recommended by existing methods fail to reach the destination. Second, existing techniques are transductive in nature; hence, they fail to recommend routes if unseen roads are encountered at inference time. In this paper, we address these limitations through an inductive algorithm called NeuroMLR. NeuroMLR learns a generative model from historical trajectories by conditioning on three explanatory factors: the current location, the destination, and real-time traffic conditions. The conditional distributions are learned through a novel combination of Lipschitz embedding with Graph Convolutional Networks (GCN) using historical trajectory data. Through in-depth experiments on real-world datasets, we establish that NeuroMLR imparts significant improvement in accuracy over the state of the art. More importantly, NeuroMLR generalizes dramatically better to unseen data and the recommended routes reach the destination with much higher likelihood than existing techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:Hck25ST_3aIC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Horizons in a seismic image are geologically signficant surfaces that can be used for understanding geological structures and stratigraphy models. However, horizon tracking in seismic data is a time consuming and challenging task. Saving geologist's time from this seismic interpretation task is essential given the time constraints for the decision making in the oil & gas industry. We take advantage of the deep convolutional neural networks (CNN) to track the horizons directly from the seismic images. We propose a novel automatic seismic horizon tracking method that can reduce the time needed for interpretation, as well as increase the accuracy for the geologists. We show the performance comparison of the proposed CNN model for different training data set sizes and different methods of balancing the classes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:QUX0mv85b1cC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Graph neural networks (GNNs) find applications in various domains such as computational biology, natural language processing, and computer security. Owing to their popularity, there is an increasing need to explain GNN predictions since GNNs are black-box machine learning models. One way to address this is counterfactual reasoning where the objective is to change the GNN prediction by minimal changes in the input graph. Existing methods for counterfactual explanation of GNNs are limited to instance-specific local reasoning. This approach has two major limitations of not being able to offer global recourse policies and overloading human cognitive ability with too much information. In this work, we study the global explainability of GNNs through global counterfactual reasoning. Specifically, we want to find a small set of representative counterfactual graphs that explains all input graphs. Towards this goal, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:kJDgFkosVoMC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Along with the rapid growth and rise to prominence of food delivery platforms, concerns have also risen about the terms of employment of the``gig workers''underpinning this growth. Our analysis on data derived from a real-world food delivery platform across three large cities from India show that there is significant inequality in the money delivery agents earn. In this paper, we formulate the problem of fair income distribution among agents while also ensuring timely food delivery. We establish that the problem is not only NP-hard but also inapproximable in polynomial time. We overcome this computational bottleneck through a novel matching algorithm called FairFoody. Extensive experiments over real-world food delivery datasets show FairFoody imparts up to 10 times improvement in equitable income distribution when compared to baseline strategies, while also ensuring minimal impact on customer experience.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:DyXnQzXoVgIC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Regular simple path query (RPQ) is one of the fundamental operators in graph analytics. In an RPQ, the input is a graph, a source node and a regular expression. The goal is to identify all nodes that are connected to the source through a simple path whose label sequence satisfies the given regular expression. The regular expression acts as a formal specification of the search space that is of interest to the user. Although regular expressions have high expressive power, they act as barrier to non-technical users. Furthermore, to fully realize the power of regular expressions, the user must be familiar with the domain of the graph dataset. In this study, we address this bottleneck by bridging RPQs with the query-by-example paradigm. More specifically, we ask the user for an exemplar pair that characterizes the paths of interest, and the regular expression is automatically inferred from this exemplar. This novel problem …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:aIdbFUkbNIkC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Influence maximization (IM) refers to the problem of finding a subset of nodes in a network through which we could maximize our reach to other nodes in the network. This set is often called the ""seed set"", and its constituent nodes maximize the social diffusion process. IM has previously been studied in various settings, including under a time deadline, subject to constraints such as that of budget or coverage, and even subject to measures other than the centrality of nodes. The solution approach has generally been to prove that the objective function is submodular, or has a submodular proxy, and thus has a close greedy approximation. In this paper, we explore a variant of the IM problem where we wish to reach out to and maximize the probability of infection of a small subset of bounded capacity K. We show that this problem does not exhibit the same submodular guarantees as the original IM problem, for which we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:1tZ8xJnm2c8C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Optimization of atomic structures presents a challenging problem, due to their highly rough and non-convex energy landscape, with wide applications in the fields of drug design, materials discovery, and mechanics. Here, we present a graph reinforcement learning approach, StriderNET, that learns a policy to displace the atoms towards low energy configurations. We evaluate the performance of StriderNET on three complex atomic systems, namely, binary Lennard-Jones particles, calcium silicate hydrates gel, and disordered silicon. We show that StriderNET outperforms all classical optimization algorithms and enables the discovery of a lower energy minimum. In addition, StriderNET exhibits a higher rate of reaching minima with energies, as confirmed by the average over multiple realizations. Finally, we show that StriderNET exhibits inductivity to unseen system sizes that are an order of magnitude different from the training system.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:ghEM2AJqZyQC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Social commerce platforms are emerging businesses where producers sell products through re-sellers who advertise the products to other customers in their social network. Due to the increasing popularity of this business model, thousands of small producers and re-sellers are starting to depend on these platforms for their livelihood; thus, it is important to provide fair earning opportunities to them. The enormous product space in such platforms prohibits manual search, and motivates the need for recommendation algorithms to effectively allocate product exposure and, consequently, earning opportunities. In this work, we focus on the fairness of such allocations in social commerce platforms and formulate the problem of assigning products to re-sellers as a fair division problem with indivisible items under two-sided cardinality constraints, wherein each product must be given to at least a certain number of re-sellers and each re-seller must get a certain number of products. Our work systematically explores various well-studied benchmarks of fairness—including Nash social welfare, envy-freeness up to one item (𝐸𝐹1), and equitability up to one item (𝐸𝑄1)—from both theoretical and experimental perspectives. We find that the existential and computational guarantees of these concepts known from the unconstrained setting do not extend to our constrained model. To address this limitation, we develop a mixed-integer linear program and other scalable heuristics that provide near-optimal approximation of Nash social welfare in simulated and real social commerce datasets. Overall, our work takes the first step towards achieving provable fairness …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:2ywjKiB__4kC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Understanding the evolution of communities and the factors that contribute to their development, stability and disappearance over time is a fundamental problem in the study of temporal networks. The concept of𝑘-core is one of the most popular metrics to detect communities. Since the 𝑘-core of a temporal network changes with time, an important question arises: Are there nodes that always remain within the 𝑘-core? In this paper, we explore this question by introducing the notion of core-invariant nodes. Given a temporal window∆ and a parameter K, the core-invariant nodes are those that are part of the K-core throughout∆. Coreinvariant nodes have been shown to dictate the stability of networks, while being also useful in detecting anomalous behavior. The complexity of finding core-invariant nodes is 𝑂 (|∆|×| 𝐸|), which is exorbitantly high for million-scale networks. We overcome this computational bottleneck by designing an algorithm called Kwiq. Kwiq efficiently processes the cascading impact of network updates through a novel data structure called orientation graph. Through extensive experiments on real temporal networks containing millions of nodes, we establish that the proposed pruning strategies are more than 5 times faster than baseline strategies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:27LrP4qxOz0C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Mixed Integer programs (MIPs) are typically solved by the Branch-and-Bound algorithm. Recently, Learning to imitate fast approximations of the expert strong branching heuristic has gained attention due to its success in reducing the running time for solving MIPs. However, existing learning-to-branch methods assume that the entire training data is available in a single session of training. This assumption is often not true, and if the training data is supplied in continual fashion over time, existing techniques suffer from catastrophic forgetting. In this work, we study the hitherto unexplored paradigm of Lifelong Learning to Branch on Mixed Integer Programs. To mitigate catastrophic forgetting, we propose LIMIP, which is powered by the idea of modeling an MIP instance in the form of a bipartite graph, which we map to an embedding space using a bipartite Graph Attention Network. This rich embedding space avoids catastrophic forgetting through the application of knowledge distillation and elastic weight consolidation, wherein we learn the parameters key towards retaining efficacy and are therefore protected from significant drift. We evaluate LIMIP on a series of NP-hard problems and establish that in comparison to existing baselines, LIMIP is up to 50% better when confronted with lifelong learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:v6i8RKmR8ToC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Learning the structure--dynamics correlation in disordered systems is a long-standing problem. Here, we use unsupervised machine learning employing graph neural networks (GNN) to investigate the local structures in disordered systems. We test our approach on 2D binary A65B35 LJ glasses and extract structures corresponding to liquid, supercooled and glassy states at different cooling rates. The neighborhood representation of atoms learned by a GNN in an unsupervised fashion, when clustered, reveal local structures with varying potential energies. These clusters exhibit dynamical heterogeneity in the structure in congruence with their local energy landscape. Altogether, the present study shows that unsupervised graph embedding can reveal the structure--dynamics correlation in disordered structures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:2v_ZtQDX9iAC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"With the increasing popularity of food delivery platforms, it has become pertinent to look into the working conditions of the 'gig' workers in these platforms, especially providing them fair wages, reasonable working hours, and transparency on work availability. However, any solution to these problems must not degrade customer experience and be cost-effective to ensure that platforms are willing to adopt them. We propose WORK4FOOD, which provides income guarantees to delivery agents, while minimizing platform costs and ensuring customer satisfaction. WORK4FOOD ensures that the income guarantees are met in such a way that it does not lead to increased working hours or degrade environmental impact. To incorporate these objectives, WORK4FOOD balances supply and demand by controlling the number of agents in the system and providing dynamic payment guarantees to agents based on factors such as agent location, ratings, etc. We evaluate WORK4FOOD on a real-world dataset from a leading food delivery platform and establish its advantages over the state of the art in terms of the multi-dimensional objectives at hand.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:8Xgff_V0N9gC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"Graph neural networks (GNNs) have witnessed significant adoption in the industry owing to impressive performance on various predictive tasks. Performance alone, however, is not enough. Any widely deployed machine learning algorithm must be robust to adversarial attacks. In this work, we investigate this aspect for GNNs, identify vulnerabilities, and link them to graph properties that may potentially lead to the development of more secure and robust GNNs. Specifically, we formulate the problem of task and model agnostic evasion attacks where adversaries modify the test graph to affect the performance of any unknown downstream task. The proposed algorithm, GRAND (aph ttack via eighborhood istortion) shows that distortion of node neighborhoods is effective in drastically compromising prediction performance. Although neighborhood distortion is an NP-hard problem, GRAND designs an effective heuristic through a novel combination of Graph Isomorphism Network with deep -learning. Extensive experiments on real datasets show that, on average, GRAND is up to more effective than state of the art techniques, while being more than times faster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:LXmCCkuhhTsC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",22,"The present disclosure relates to a method performed by a network node (54) in a communication network (50) comprising a plurality of communication devices (51), for finding temporally connected connection patterns of the communication devices in the network. The method comprises identifying signalling between the communication devices during a predefined time duration to form a main communication graph in which the plurality of communication devices are nodes. The method also comprises partitioning the main communication graph for a time period comprised in said time duration to capture temporally connected signalling between some of the communication devices as illustrated in the main communication graph in a partitioned communication graph. The method also comprises forming at least one subgraph from the partitioned communication graph, comprising m nodes corresponding to m …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&citation_for_view=K4w5qYUAAAAJ:-nhnvRiOwuoC,http://www.cse.iitd.ac.in/~sayan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"The exponential increase in COVID-19 patients is overwhelming healthcare systems across the world. With limited testing kits, it is impossible for every patient with respiratory illness to be tested using conventional techniques (RT-PCR). The tests also have long turn-around time, and limited sensitivity. Detecting possible COVID-19 infections on Chest X-Ray may help quarantine high risk patients while test results are awaited. X-Ray machines are already available in most healthcare systems, and with most modern X-Ray systems already digitized, there is no transportation time involved for the samples either. In this work we propose the use of chest X-Ray to prioritize the selection of patients for further RT-PCR testing. This may be useful in an inpatient setting where the present systems are struggling to decide whether to keep the patient in the ward along with other patients or isolate them in COVID-19 areas. It would also help in identifying patients with high likelihood of COVID with a false negative RT-PCR who would need repeat testing. Further, we propose the use of modern AI techniques to detect the COVID-19 patients using X-Ray images in an automated manner, particularly in settings where radiologists are not available, and help make the proposed testing technology scalable. We present CovidAID: COVID-19 AI Detector, a novel deep neural network based model to triage patients for appropriate testing. On the publicly available covid-chestxray-dataset [2], our model gives 90.5% accuracy with 100% sensitivity (recall) for the COVID-19 infection. We significantly improve upon the results of Covid-Net [10] on the same dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&citation_for_view=Q8cTLNMAAAAJ:maZDTaKrznsC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Automated brain tissue segmentation into white matter (WM), gray matter (GM), and cerebro-spinal fluid (CSF) from magnetic resonance images (MRI) is helpful in the diagnosis of neuro-disorders such as epilepsy, Alzheimer's, multiple sclerosis, etc. However, thin GM structures at the periphery of cortex and smooth transitions on tissue boundaries such as between GM and WM, or WM and CSF pose difficulty in building a reliable segmentation tool. This paper proposes a Fully Convolutional Neural Network (FCN) tool, that is a hybrid of two widely used deep learning segmentation architectures SegNet and U-Net, for improved brain tissue segmentation. We propose a skip connection inspired from U-Net, in the SegNet architetcure, to incorporate fine multiscale information for better tissue boundary identification. We show that the proposed U-SegNet architecture, improves segmentation performance, as measured …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&citation_for_view=Q8cTLNMAAAAJ:IWHjjKOFINEC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Requirement of large annotated datasets restrict the use of deep convolutional neural networks (CNNs) for many practical applications. The problem can be mitigated by using active learning (AL) techniques which, under a given annotation budget, allow to select a subset of data that yields maximum accuracy upon fine tuning. State of the art AL approaches typically rely on measures of visual diversity or prediction uncertainty, which are unable to effectively capture the variations in spatial context. On the other hand, modern CNN architectures make heavy use of spatial context for achieving highly accurate predictions. Since the context is difficult to evaluate in the absence of ground-truth labels, we introduce the notion of contextual diversity that captures the confusion associated with spatially co-occurring classes. Contextual Diversity (CD) hinges on a crucial observation that the probability vector predicted …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&citation_for_view=Q8cTLNMAAAAJ:M05iB0D1s5AC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"The possibility of sharing one's point of view makes the use of wearable cameras compelling. These videos are often long, boring, and coupled with extreme shaking, as the camera is worn on a moving person. Fast-forwarding (i.e., frame sampling) is a natural choice for quick video browsing. However, this accentuates the shake caused by natural head motion in an egocentric video, making the fast-forwarded video useless. We propose EgoSampling, an adaptive frame sampling that gives stable, fast-forwarded, hyperlapse videos. Adaptive frame sampling is formulated as an energy minimization problem, whose optimal solution can be found in polynomial time. We further turn the camera shake from a drawback into a feature, enabling the increase in field of view of the output video. This is obtained when each output frame is mosaiced from several input frames. The proposed technique also enables the generation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&citation_for_view=Q8cTLNMAAAAJ:MXK_kJrjxJIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&citation_for_view=Q8cTLNMAAAAJ:r0BpntZqJG4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Gait recognition is a non-invasive biometric technology that can be used to identify humans in surveillance systems. It is based on the style or manner in which a person walk and can be realized with minimal amount of individual cooperation for its acquisition. However, it may causes many challenges in the form of varying viewpoints, carrying conditions and clothing variations. To tackle such limitations, we present a view-invariant gait recognition network that divide the gait cycle into five segments (GCS). The intra gait-cycle-segment (GCS) convolutional spatio-temporal relationships has been obtained by employing a 3D-CNN via. transfer learning mechanism. Later, a stacked LSTM has been trained over spatio-temporal features to learn the long and short relationship between inter gait-cycle-segment.
The first step in our work is data pre-processing, in which we create silhouette stereo map (SSM) from the binary …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&citation_for_view=Q8cTLNMAAAAJ:_Qo2XoVZTnwC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Developing recommendation system for fashion images is challenging due to the inherent ambiguity associated with what criterion a user is looking at. Suggesting multiple images where each output image is similar to the query image on the basis of a different feature or part is one way to mitigate the problem. Existing works for fashion recommendation have used Siamese or Triplet network to learn features between a similar pair and a similar-dissimilar triplet respectively. However, these methods do not provide basic information such as, how two clothing images are similar, or which parts present in the two images make them similar. In this paper, we propose to recommend images by explicitly learning and exploiting part based similarity. We propose a novel approach of learning discriminative features from weakly-supervised data by using visual attention over the parts and a texture encoding network. We show …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&citation_for_view=Q8cTLNMAAAAJ:hC7cP41nSMkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"In this paper, we address the problem of road segmentation and free space detection in the context of autonomous driving. Traditional methods either use 3-dimensional (3D) cues such as point clouds obtained from LIDAR, RADAR or stereo cameras or 2-dimensional (2D) cues such as lane markings, road boundaries and object detection. Typical 3D point clouds do not have enough resolution to detect fine differences in heights such as between road and pavement. Image based 2D cues fail when encountering uneven road textures such as due to shadows, potholes, lane markings or road restoration. We propose a novel free road space detection technique combining both 2D and 3D cues. In particular, we use CNN based road segmentation from 2D images and plane/box fitting on sparse depth data obtained from SLAM as priors to formulate an energy minimization using conditional random field (CRF), for road …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:4DMP91E08xMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"We focus on the problem of parsing fashion images for detecting various types of clothing and style. The current state-of-the-art techniques for the problem are mostly based on variations of the SegNet model. The techniques formulate the problem as segmentation and typically rely on geometrical shapes and position to segment the image. However, specifically for fashion images, each clothing item is made of specific type of materials with characteristic visual texture patterns. Exploiting the texture for recognizing the clothing type is an important cue which has been ignored so far by the state-of-the-art. In this paper, we propose a two-stream deep neural network architecture for fashion image parsing. While the first stream uses the regular fully convolutional network segmentation architecture to give accurate spatial segments, the second stream provides texture features learned from hand-crafted Gabor feature …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:dhFuZR0502QC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Applications like autonomous driving, industrial robotics, surveillance, and wearable assistive technology rely on object detectors as an integral part of the system. Thus, an increase in performance of object detectors directly affects the quality of such systems. In the recent years, convolutional neural networks (CNNs) and its variants emerged as the state of art in object detection, where performance is usually measured either in terms of mean average precision (mAP) or number of frames processed per second (fps). Many applications which use object detectors are resource constrained in practice. Even though it is clear from the published results, that a frame-level analysis of the system in terms of mAP or fps proves the superiority of one algorithm over the other, we observe that such metrics do not necessarily apply to real time applications with resource constraints. A slower algorithm even though highly accurate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:mVmsd5A6BfQC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Monocular Depth Estimation (MDE) aims to predict pixel-wise depth given a single RGB image. For both, the convolutional as well as the recent attention-based models, encoder-decoder-based architectures have been found to be useful due to the simultaneous requirement of global context and pixel-level resolution. Typically, a skip connection module is used to fuse the encoder and decoder features, which comprises of feature map concatenation followed by a convolution operation. Inspired by the demonstrated benefits of attention in a multitude of computer vision problems, we propose an attention-based fusion of encoder and decoder features. We pose MDE as a pixel query refinement problem, where coarsest-level encoder features are used to initialize pixel-level queries, which are then refined to higher resolutions by the proposed Skip Attention Module (SAM). We formulate the prediction problem as ordinal regression over the bin centers that discretize the continuous depth range and introduce a Bin Center Predictor (BCP) module that predicts bins at the coarsest level using pixel queries. Apart from the benefit of image adaptive depth binning, the proposed design helps learn improved depth embedding in initial pixel queries via direct supervision from the ground truth. Extensive experiments on the two canonical datasets, NYUV2 and KITTI, show that our architecture outperforms the state-of-the-art by 5.3% and 3.9%, respectively, along with an improved generalization performance by 9.4% on the SUNRGBD dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:p2g8aNsByqUC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"We focus on first-person action recognition from egocentric videos. Unlike third person domain, researchers have divided first-person actions into two categories: involving hand-object interactions and the ones without, and developed separate techniques for the two action categories. Further, it has been argued that traditional cues used for third person action recognition do not suffice, and egocentric specific features, such as head motion and handled objects have been used for such actions. Unlike the state-of-the-art approaches, we show that a regular two stream Convolutional Neural Network (CNN) with Long Short-Term Memory (LSTM) architecture, having separate streams for objects and motion, can generalize to all categories of first-person actions. The proposed approach unifies the feature learned by all action categories, making the proposed architecture much more practical. In an important observation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:-f6ydRqryjwC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Background
Minimally invasive neurosurgical approaches reduce patient morbidity by providing the surgeon with better visualization and access to complex lesions, with minimal disruption to normal anatomy. The use of rigid or flexible neuroendoscopes, supplemented with a conventional stereoscopic operating microscope, has been integral to the adoption of these techniques. Neurosurgeons commonly use neuroendoscopes to perform the ventricular and endonasal approaches. It is challenging to learn neuroendoscopy skills from the existing apprenticeship model of surgical education. The training methods, which use simulation-based systems, have achieved wide acceptance. Physical simulators provide anatomic orientation and hands-on experience with repeatability. Our aim is to review the existing physical simulators on the basis of the skills training of neuroendoscopic procedures.
Methods
We searched …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:k_IJM867U9cC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Deep Neural Networks (DNNs) are known to make overconfident mistakes, which makes their use problematic in safety-critical applications. State-of-the-art (SOTA) calibration techniques improve on the confidence of predicted labels alone, and leave the confidence of non-max classes (eg top-2, top-5) uncalibrated. Such calibration is not suitable for label refinement using post-processing. Further, most SOTA techniques learn a few hyper-parameters post-hoc, leaving out the scope for image, or pixel specific calibration. This makes them unsuitable for calibration under domain shift, or for dense prediction tasks like semantic segmentation. In this paper, we argue for intervening at the train time itself, so as to directly produce calibrated DNN models. We propose a novel auxiliary loss function: Multi-class Difference in Confidence and Accuracy (MDCA), to achieve the same. MDCA can be used in conjunction with other application/task specific loss functions. We show that training with MDCA leads to better calibrated models in terms of Expected Calibration Error (ECE), and Static Calibration Error (SCE) on image classification, and segmentation tasks. We report ECE (SCE) score of 0.72 (1.60) on the CIFAR100 dataset, in comparison to 1.90 (1.71) by the SOTA. Under domain shift, a ResNet-18 model trained on PACS dataset using MDCA gives a average ECE (SCE) score of 19.7 (9.7) across all domains, compared to 24.2 (11.8) by the SOTA. For segmentation task, we report a 2x reduction in calibration error on PASCAL-VOC dataset in comparison to Focal Loss. Finally, MDCA training improves calibration even on imbalanced data, and for natural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:u_35RYKgDlwC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Recent efforts in multi-domain learning for semantic segmentation attempt to learn multiple geographical datasets in a universal, joint model. A simple fine-tuning experiment performed sequentially on three popular road scene segmentation datasets demonstrates that existing segmentation frameworks fail at incrementally learning on a series of visually disparate geographical domains. When learning a new domain, the model catastrophically forgets previously learned knowledge. In this work, we pose the problem of multi-domain incremental learning for semantic segmentation. Given a model trained on a particular geographical domain, the goal is to (i) incrementally learn a new geographical domain,(ii) while retaining performance on the old domain,(iii) given that the previous domain's dataset is not accessible. We propose a dynamic architecture that assigns universally shared, domain-invariant parameters to capture homogeneous semantic features present in all domains, while dedicated domain-specific parameters learn the statistics of each domain. Our novel optimization strategy helps achieve a good balance between retention of old knowledge (stability) and acquiring new knowledge (plasticity). We demonstrate the effectiveness of our proposed solution on domain incremental settings pertaining to real-world driving scenes from roads of Germany (Cityscapes), the United States (BDD100k), and India (IDD).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:NaGl4SEjCO4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Independent mobility of visually impaired people is key to making an inclusive society for them. Unstructured infrastructure in developing countries pose significant challenges in developing aids to address the mobility problem of visually impaired. Most of the assistive devices available internationally assume a structured and controlled environment severely restricting the applicability of such devices. In this paper, we assess the ability of state-of-the-art assistive devices for addressing the independent outdoor mobility needs of the visually impaired in an unstructured environment. We have created realistic datasets for various scenarios and evaluate deep neural networks for object detection on these datasets. We also present a portable prototype for the task. Further, we have also developed a cloud based solution to address the mobility requirements. We compare the local device based and cloud based solutions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:e5wmG9Sq2KIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"We explore the potential of CNN-based models for gallbladder cancer (GBC) detection from ultrasound (USG) images as no prior study is known. USG is the most common diagnostic modality for GB diseases due to its low cost and accessibility. However, USG images are challenging to analyze due to low image quality, noise, and varying viewpoints due to the handheld nature of the sensor. Our exhaustive study of state-of-the-art (SOTA) image classification techniques for the problem reveals that they often fail to learn the salient GB region due to the presence of shadows in the USG images. SOTA object detection techniques also achieve low accuracy because of spurious textures due to noise or adjacent organs. We propose GBCNet to tackle the challenges in our problem. GBCNet first extracts the regions of interest (ROIs) by detecting the GB (and not the cancer), and then uses a new multi-scale, second-order pooling architecture specializing in classifying GBC. To effectively handle spurious textures, we propose a curriculum inspired by human visual acuity, which reduces the texture biases in GBCNet. Experimental results demonstrate that GBCNet significantly outperforms SOTA CNN models, as well as the expert radiologists. Our technical innovations are generic to other USG image analysis tasks as well. Hence, as a validation, we also show the efficacy of GBCNet in detecting breast cancer from USG images. Project page with source code, trained models, and data is available at https://gbc-iitd. github. io/gbcnet.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:4OULZ7Gr8RgC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Regardless of the tremendous progress, a truly general purpose pipeline for Simultaneous Localization and Mapping (SLAM) remains a challenge. We investigate the reported failure of state of the art (SOTA) SLAM techniques on egocentric videos. We find that the dominant 3D rotations, low parallax between successive frames, and primarily forward motion in egocentric videos are the most common causes of failures. The incremental nature of SOTA SLAM, in the presence of unreliable pose and 3D estimates in egocentric videos, with no opportunities for global loop closures, generates drifts and leads to the eventual failures of such techniques. Taking inspiration from batch mode Structure from Motion (SFM) techniques, we propose to solve SLAM as an SFM problem over the sliding temporal windows. This makes the problem well constrained. Further, we propose to initialize the camera poses using 2D rotation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:TQgYirikUcIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Objectives
To study whether a trained convolutional neural network (CNN) can be of assistance to radiologists in differentiating Coronavirus disease (COVID)–positive from COVID-negative patients using chest X-ray (CXR) through an ambispective clinical study. To identify subgroups of patients where artificial intelligence (AI) can be of particular value and analyse what imaging features may have contributed to the performance of AI by means of visualisation techniques.
Methods
CXR of 487 patients were classified into [4] categories—normal, classical COVID, indeterminate, and non-COVID by consensus opinion of 2 radiologists. CXR which were classified as “normal” and “indeterminate” were then subjected to analysis by AI, and final categorisation provided as guided by prediction of the network. Precision and recall of the radiologist alone and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:RGFaLdJalmkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"The popularity of egocentric cameras and their always-on nature has lead to the abundance of day-long first-person videos. Because of the extreme shake and highly redundant nature, these videos are difficult to watch from beginning to end and often require summarization tools for their efficient consumption. However, traditional summarization techniques developed for static surveillance videos, or highly curated sports videos and movies are, either, not suitable or simply do not scale for such hours long videos in the wild. On the other hand, specialized summarization techniques developed for egocentric videos limit their focus to important objects and people. In this paper, we present a novel unsupervised reinforcement learning technique to generate video summaries from day long egocentric videos. Our approach can be adapted to generate summaries of various lengths making it possible to view even 1 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:RHpTSmoSYBkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Few-Shot Object Detectors (FSOD) are tasked to localize and classify objects in an image given only a few data samples. Recent trends in FSOD research show the adoption of metric and meta-learning techniques, which are prone to catastrophic forgetting and class confusion. To overcome these pitfalls in metric learning based FSOD techniques, we introduce an Attention Guided Cosine Margin (AGCM) that facilitates the creation of tighter and well separated class-specific feature clusters in the classification head of the object detector. The Attentive Proposal Fusion (APF) module introduced in AGCM minimizes catastrophic forgetting by reducing the intra-class variance among co-occurring classes. At the same time, the Cosine Margin penalty in AGCM increases the angular margin between confusing classes to overcome the challenge of class confusion between already learned (base) and newly added (novel) classes. We conduct our experiments on the India Driving Dataset (IDD), which presents a real-world class-imbalanced setting alongside popular FSOD benchmark PASCAL-VOC. Our method outperforms existing approaches by up to 6.4 mAP points on the IDD-OS and up to 2.0 mAP points on the IDD-10 splits for the 10-shot setting. On the PASCAL-VOC dataset, we outperform existing approaches by up to 4.9 mAP points.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:g5m5HwL7SMYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"The long and unconstrained nature of egocentric videos makes it imperative to use temporal segmentation as an important pre-processing step for many higher-level inference tasks. Activities of the wearer in an egocentric video typically span over hours and are often separated by slow, gradual changes. Furthermore, the change of camera viewpoint due to the wearer's head motion causes frequent and extreme, but, spurious scene changes. The continuous nature of boundaries makes it difficult to apply traditional Markov Random Field (MRF) pipelines relying on temporal discontinuity, whereas deep Long Short Term Memory (LSTM) networks gather context only upto a few hundred frames, rendering them ineffective for egocentric videos. In this paper, we present a novel unsupervised temporal segmentation technique especially suited for day-long egocentric videos. We formulate the problem as detecting concept …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:BqipwSGYUEgC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Easy availability of wearable egocentric cameras, and the sense of privacy propagated by the fact that the wearer is never seen in the captured videos, has led to a tremendous rise in public sharing of such videos. Unlike hand-held cameras, egocentric cameras are harnessed on the wearer’s head, which makes it possible to track the wearer’s head motion by observing optical flow in the egocentric videos. In this work, we create a novel kind of privacy attack by extracting the wearer’s gait profile, a well known biometric signature, from such optical flow in the egocentric videos. We demonstrate strong wearer recognition capabilities based on extracted gait features, an unprecedented and critical weakness completely absent in hand-held videos. We demonstrate the following attack scenarios: (1) In a closed-set scenario, we show that it is possible to recognize the wearer of an egocentric video with an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:YFjsv_pBGBYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Procedure learning involves identifying the key-steps and determining their logical order to perform a task. Existing approaches commonly use third-person videos for learning the procedure, making the manipulated object small in appearance and often occluded by the actor, leading to significant errors. In contrast, we observe that videos obtained from first-person (egocentric) wearable cameras provide an unobstructed and clear view of the action. However, procedure learning from egocentric videos is challenging because (a) the camera view undergoes extreme changes due to the wearer’s head motion, and (b) the presence of unrelated frames due to the unconstrained nature of the videos. Due to this, current state-of-the-art methods’ assumptions that the actions occur at approximately the same time and are of the same duration, do not hold. Instead, we propose to use the signal provided by the temporal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:abG-DnoFyZgC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Contextual information is a valuable cue for Deep Neural Networks (DNNs) to learn better representations and improve accuracy. However, co-occurrence bias in the training dataset may hamper a DNN model's generalizability to unseen scenarios in the real world. For example, in COCO [??], many object categories have a much higher co-occurrence with men compared to women, which can bias a DNN's prediction in favor of men. Recent works have focused on task-specific training strategies to handle bias in such scenarios, but fixing the available data is often ignored. In this paper, we propose a novel and more generic solution to address the contextual bias in the datasets by selecting a subset of the samples, which is fair in terms of the co-occurrence with various classes for a protected attribute. We introduce a data repair algorithm using the coefficient of variation (c_v), which can curate fair and contextually balanced data for a protected class (es). This helps in training a fair model irrespective of the task, architecture or training methodology. Our proposed solution is simple, effective and can even be used in an active learning setting where the data labels are not present or being generated incrementally. We demonstrate the effectiveness of our algorithm for the task of object detection and multi-label image classification across different datasets. Through a series of experiments, we validate that curating contextually fair data helps make model predictions fair by balancing the true positive rate for the protected class across groups without compromising on the model's overall performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:RYcK_YlVTxYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Backdoor attacks embed a hidden functionality into deep neural networks, causing the network to display anomalous behavior when activated by a predetermined pattern in the input (Trigger), while behaving well otherwise on public test data. Recent works have shown that backdoored face recognition (FR) systems can respond to natural-looking triggers like a particular pair of sunglasses. Such attacks pose a serious threat to the applicability of FR systems in high-security applications. We propose a novel technique to (1) detect whether an FR network is compromised with a natural, physically realizable trigger, and (2) identify such triggers given a compromised network. We demonstrate the effectiveness of our methods with a compromised FR network, where we are able to identify the trigger (e.g. green-sunglasses or redbowtie) with a top-5 accuracy of 74%, whereas a naïve brute force baseline achieves 56 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:35N4QoGY0k4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"The 6th National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2017) was held at Mandi, Himachal Pradesh, during December 16–19, 2017. NCVPRIPG 2017 was organized by the Indian Institute of Technology Mandi in association with the Indian Unit for Pattern Recognition and Artificial Intelligence (IUPRAI). The NCVPRIPG series of conferences aims to bring together researchers and practitioners from the allied areas of computer vision, graphics, image processing, and pattern recognition, in order to promote community-wide discussions of ideas that will influence and foster continued research in the field. Over the years the conference has grown into a vibrant national conference with participations from many students and researchers in the field. These proceedings contain the papers accepted and presented at the conference (including those presented in the oral as well as poster sessions). The papers showcased original contemporary research spanning various broad themes such as video processing, image and signal processing, segmentation, retrieval, captioning, and various pattern recognition applications. Out of a total of 147 papers submitted to the conference, 48 were accepted and presented, following an elaborate double-blind review process. After the review process, the final decision process was carried out by the Program Chairs based on the review comments. The conference involved eight oral sessions with a total of 25 papers presented, and two poster sessions containing a total of 23 papers. The papers in the proceedings are the revised versions which were …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:7PzlFSSx8tAC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"The use of 360 degree cameras, enabling one to record and share full-spherical 360° X 180° view without any cropping in the viewing angle, is on the rise. Shake in such videos is problematic, especially when used in conjunction with VR headsets causing cybersickness to the viewer. The current state-of-the-art video stabilization algorithm [17] designed specifically for 360 degree videos considers the special geometrical constraints in such videos. However, the specific steps in the algorithm can abruptly change the viewing direction in a video leading to unnatural experience for the viewer. In this paper, we propose to fix this anomaly by the use of L1 smoothness constraints on the camera path, as suggested by Grundmann et al. [7]. The modified algorithm is generic and our experiments indicate that the proposed algorithm not only gives a more natural and smoother stabilization for 360 degree videos but can be …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:L8Ckcad2t8MC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Higher Order MRF-MAP formulation has been a popular technique for solving many problems in computer vision. Inference in a general MRF-MAP problem is NP Hard, but can be performed in polynomial time for the special case when potential functions are submodular. Two popular combinatorial approaches for solving such formulations are flow based and polyhedral approaches. Flow based approaches work well with small cliques and in that mode can handle problems with millions of variables. Polyhedral approaches can handle large cliques but in small numbers. We show in this paper that the variables in these seemingly disparate techniques can be mapped to each other. This allows us to combine the two styles in a joint framework exploiting the strength of both of them. Using the proposed joint framework, we are able to perform tractable inference in MRF-MAP problems with millions of variables and a mix of small and large cliques, a formulation which can not be solved by either of the two styles individually. We show applicability of this hybrid framework on object segmentation problem as an example of a situation where quality of results is significantly better than systems which are based only on the use of small or large cliques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:ZeXyd9-uunAC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Annotation is a crucial first step in the semantic segmentation of urban images that facilitates the development of autonomous navigation systems. However, annotating complex urban images is time-consuming and challenging. It requires significant human effort making it expensive and error-prone. To reduce human effort during annotation, multiple images need to be annotated in a short time-span. In this paper, we introduce ScribbleNet, an interactive image segmentation algorithm to address this issue. Our approach provides users with a pre-segmented image that iteratively improves the segmentation using scribble as an annotation input. This method is based on conditional inference and exploits the learnt correlations in a deep neural network (DNN). ScribbleNet can:(1) work with urban city scenes captured in unseen environments,(2) annotate new classes not present in the training set, and (3) correct …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:dshw04ExmUIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Attention-based models such as transformers have shown outstanding performance on dense prediction tasks, such as semantic segmentation, owing to their capability of capturing long-range dependency in an image. However, the benefit of transformers for monocular depth prediction has seldom been explored so far. This paper benchmarks var-ious transformer-based models for the depth estimation task on an indoor NYUV2 dataset and an outdoor KITTI dataset. We propose a novel attention-based architecture, Depthformer for monocular depth estimation that uses multi-head self-attention to produce the multiscale feature maps, which are effectively combined by our proposed de-coder network. We also propose a Transbins module that divides the depth range into bins whose center value is estimated adaptively per image. The final depth estimated is a linear combination of bin centers for each pixel. Trans …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:uWQEDVKXjbEC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Advancements in adaptive object detection can lead to tremendous improvements in applications like autonomous navigation, as they alleviate the distributional shifts along the detection pipeline. Prior works adopt adversarial learning to align image features at global and local levels, yet the instance-specific misalignment persists. Also, adaptive object detection remains challenging due to visual diversity in background scenes and intricate combinations of objects. Motivated by structural importance, we aim to attend prominent instance-specific regions, overcoming the feature misalignment issue. We propose a novel resIduaL seLf-attentive featUre alignMEnt (ILLUME) method for adaptive object detection. ILLUME comprises Self-Attention Feature Map (SAFM) module that enhances structural attention to object-related regions and thereby generates domain invariant features. Our approach significantly reduces the domain distance with the improved feature alignment of the instances. Qualitative results demonstrate the ability of ILLUME to attend important object instances required for alignment. Experimental results on several benchmark datasets show that our method outperforms the existing state-of-the-art approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:2P1L_qKh6hAC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Manipulators are helpful in performing various hazardous tasks like sanitization with chemicals in germs infected areas, spraying pesticides in fields, pick and place of heavy and hazardous materials where direct human intervention is difficult. For manipulators to perform its assigned task accurately, prior estimation of its pose needs to be pinpointed. End-effector grasping and arm manipulation require estimation of 3D object poses. Recently, a number of procedures and databases for vision-based estimation of object pose have been advised. However, it is not clear about the performance of the developed algorithms for visual pose estimation of robot manipulation. In this paper we present the pose estimation of a 5-dof PhantomX Reactor Arm using On-Body/Aruco Markers. Forward and inverse kinematics were used to estimate the pose from the position coordinates calculated using computer vision techniques …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:HoB7MX3m0LUC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"In egocentric videos, the face of a wearer capturing the video is never captured. This gives a false sense of security that the wearer's privacy is preserved while sharing such videos. However, egocentric cameras are typically harnessed to wearer's head, and hence, also capture wearer's gait. Recent works have shown that wearer gait signatures can be extracted from egocentric videos, which can be used to determine if two egocentric videos have the same wearer. In a more damaging scenario, one can even recognize a wearer using hand gestures from egocentric videos, or identify a wearer in third person videos such as from a surveillance camera. We believe, this could be a death knell in sharing of egocentric videos, and fatal for egocentric vision research. In this work, we suggest a novel technique to anonymize egocentric videos, which create carefully crafted, but small, and imperceptible optical flow perturbations in an egocentric video's frames. Importantly, these perturbations do not affect object detection or action/activity recognition from egocentric videos but are strong enough to dis-balance the gait recovery process. In our experiments on benchmark\epic dataset, the proposed perturbation degrades the wearer recognition performance of [??], from 66.3% to 13.4%, while preserving the activity recognition performance of [??] from 89.6% to 87.4%. To test our anonymization with more wearer recognition techniques, we also developed a stronger, and more generalizable wearer recognition method based on camera egomotion cues. The approach achieves state-of-the-art (SOTA) performance of 59.67% on\epicns, compared to 55.06% by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:J_g5lzvAfSwC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"With the improvement in technology, both the cost and the power requirement of cameras, as well as other sensors have come down significantly. It has allowed these sensors to be integrated into portable as well as wearable systems. Such systems are usually operated in a hands-free and always-on manner where they need to function continuously in a variety of scenarios. In such situations, relying on a single sensor or a fixed sensor combination can be detrimental to both performance as well as energy requirements. Consider the case of an obstacle detection task. Here using an RGB camera helps in recognizing the obstacle type but takes much more energy than an ultrasonic sensor. Infrared cameras can perform better than RGB camera at night but consume twice the energy. Therefore, an efficient system must use a combination of sensors, with an adaptive control that ensures the use of the sensors …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:4JMBOYKVnBMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"A method and a system for generating adaptive fast forward of egocentric videos are provided here. The method may include the following steps: obtaining a video footage containing a sequence of image frames captured by a non-stationary capturing device; estimating a moving direction of the non-stationary capturing device for a plurality of frames in the sequence of image frames; and generating a shortened video footage having fewer frames than said video footage, by sampling the sequence of image frames, wherein the sampling is carried out by selecting specific image frames and that minimize an overall cost associated with a deviation from a specific direction related to the moving direction, calculated for each of said plurality of image frames.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:qUcmZB5y_30C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"We focus on the problem of fine-grained visual classification (FGVC). We posit that unreasonable effectiveness of the state-of-the-art in this area is because of similar object categories present in the ImageNet dataset, which allows such models to be pretrained on a much larger set of samples and learn generic features for those object categories. We observe an important and often ignored additional structure present in an FGVC problem: the objects are captured from a small set of viewing angles only. We notice that subtle differences between object categories are difficult to pick from an arbitrary angle but easier to identify from a similar pose. We show in this paper that training specialized pose experts, focusing on classification from a single, fixed pose, and combining them in an ensemble style framework successfully exploits the structure in the problem. We demonstrate the effectiveness of the proposed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:mB3voiENLucC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Self-supervised methods have shown promising results in denoising and dehazing tasks, where the collection of the paired dataset is challenging and expensive. However, we find that these methods fail to remove the rain streaks when applied for image deraining tasks. The method's poor performance is due to the explicit assumptions:(i) the distribution of noise or haze is uniform and (ii) the value of a noisy or hazy pixel is independent of its neighbors. The rainy pixels are non-uniformly distributed, and it is not necessarily dependant on its neighboring pixels. Hence, we conclude that the self-supervised method needs to have some prior knowledge about rain distribution to perform the deraining task. To provide this knowledge, we hypothesize a network trained with minimal supervision to estimate the likelihood of rainy pixels. This leads us to our proposed method called FLUID: Few Shot Self-Supervised Image Deraining. We perform extensive experiments and comparisons with existing image deraining and few-shot image-to-image translation methods on Rain 100L and DDN-SIRR datasets containing real and synthetic rainy images. In addition, we use the Rainy Cityscapes dataset to show that our method trained in a few-shot setting can improve semantic segmentation and object detection in rainy conditions. Our approach obtains a mIoU gain of 51.20 over the current best-performing deraining method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:zA6iFVUQeVQC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"The popularity of egocentric cameras and their always-on nature has lead to the abundance of day long first-person videos. The highly redundant nature of these videos and extreme camera-shakes make them difficult to watch from beginning to end. These videos require efficient summarization tools for consumption. However, traditional summarization techniques developed for static surveillance videos or highly curated sports videos and movies are either not suitable or simply do not scale for such hours long videos in the wild. On the other hand, specialized summarization techniques developed for egocentric videos limit their focus to important objects and people. This paper presents a novel unsupervised reinforcement learning framework to summarize egocentric videos both in terms of length and the content. The proposed framework facilitates incorporating various prior preferences such as faces, places, or …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:lSLTfruPkqcC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"During the COVID-19 pandemic, the lives of healthcare professionals are at significant threat because of the enormous workload and cross-infection risk. Ultrasound (US) imaging plays a vital role in the diagnosis and follow-up of COVID-19 patients; however, it requires a close-physical contact by the sonographer. In this context, this paper presents a Telerobotic Ultrasound (TR-US) system for complete remote control of the US probe, thereby preventing direct physical contact between patients and sonographers. The system consists of a 6-DOF robot arm at the remote site and a haptic device at the doctor’s site. The control architecture precisely transmits the intended position and orientation of the US probe to the remote location for transversal and sagittal plane scanning. This architecture, when integrated with an admittance controller-based force modulation and feedback transmission, enables the radiologists to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:yD5IFk8b50cC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Object detection is a key component in autonomous navigation systems that enables localization and classification of the objects in a road scene. Existing object detection methods are trained and inferred on a fixed number of known classes present in road scenes. However, in real-world or open-world road scenes, while inference, we come across unknown objects that the detection model hasn’t seen while training. Hence, we propose Open World Object Detection on Road Scenes (ORDER) to address the aforementioned problem for road scenes. Firstly, we introduce Feature-Mix to improve the unknown object detection capabilities of an object detector. Feature-Mix widens the gap between known and unknown classes in latent feature space that helps improve the unknown object detection. Next, we identify that the road scene dataset compared to generic object dataset contains a significant proportion of small objects and has higher intra-class bounding box scale variations, making it challenging to detect the known and unknown objects. We propose a novel loss: Focal regression loss that collectively addresses the problem of small object detection and intra-class bounding box by penalizing more the small bounding boxes and dynamically changing the loss according to object size. Further, the detection of small objects is improved by curriculum learning. Finally, we present an extensive evaluation on two road scene datasets: BDD and IDD. Our experimental evaluations on BDD and IDD shows consistent improvement over the current state-of-the-art method. We believe that this work will lay the foundation for real-world object detection for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:pqnbT2bcN3wC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Wearable egocentric cameras are typically harnessed to a wearer's head, giving them the unique advantage of capturing their points of view. Hoshen and Peleg have shown that egocentric cameras indirectly capture the wearer's gait, which can be used to identify a wearer based on their egocentric videos. The authors have shown a wearer recognition accuracy of up to 77% over 32 subjects. However, an important limitation of their work is that such gait features can be extracted only from walking sequences of a wearer. In this work, we take the privacy threat a notch higher and show that even the wearer's hand gestures, as seen through an egocentric video, leak wearer's identity. We have designed a model to extract and match hand gesture signatures from egocentric videos. We demonstrate the threat on the EPIC kitchen dataset containing 55 hours of the egocentric videos acquired from 32 subjects doing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:O3NaXMp0MMsC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"We propose a novel deep neural network architecture to learn interpretable representation for medical image analysis. Our architecture generates a global attention for region of interest, and then learns bag of words style deep feature embeddings with local attention. The global, and local feature maps are combined using a contemporary transformer architecture for highly accurate Gallbladder Cancer (GBC) detection from Ultrasound (USG) images. Our experiments indicate that the detection accuracy of our model beats even human radiologists, and advocates its use as the second reader for GBC diagnosis. Bag of words embeddings allow our model to be probed for generating interpretable explanations for GBC detection consistent with the ones reported in medical literature. We show that the proposed model not only helps understand decisions of neural network models but also aids in discovery of new visual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:u9iWguZQMMsC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Computer vision systems for autonomous navigation must generalize well in adverse weather and illumination conditions expected in the real world. However, semantic segmentation of images captured in such conditions remains a challenging task for current state-of-the-art (SOTA) methods trained on broad daylight images, due to the associated distribution shift. On the other hand, domain adaptation techniques developed for the purpose rely on the availability of the source data, (un)labeled target data and/or its auxiliary information (e.g., GPS). Even then, they typically adapt to a single(specific) target domain(s). To remedy this, we propose a novel, fully test time, adaptation technique, named Master of ALL (MALL), for simultaneous generalization to multiple target domains. MALL learns to generalize on unseen adverse weather images from multiple target domains directly at the inference time. More specifically …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:nb7KW1ujOQ8C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"BACKGROUND
Performing ultrasound during the current pandemic time is quite challenging. To reduce the chances of cross-infection and keep healthcare workers safe, a robotic ultrasound system was developed, which can be controlled remotely. It will also pave way for broadening the reach of ultrasound in remote distant rural areas as well.
AIM
To assess the feasibility of a robotic system in performing abdominal ultrasound and compare it with the conventional ultrasound system.
METHODS
A total of 21 healthy volunteers were recruited. Ultrasound was performed in two settings, using the robotic arm and conventional hand-held procedure. Images acquired were analyzed by separate radiologists.
RESULTS
Our study showed that the robotic arm model was feasible, and the results varied based on the organ imaged. The liver images showed no significant difference. For other organs, the need for repeat imaging was higher in the robotic arm, which could be attributed to the radiologist’s learning curve and ability to control the haptic device. The doctor and volunteer surveys also showed significant comfort with acceptance of the technology and they expressed their desire to use it in the future.
CONCLUSION
This study shows that robotic ultrasound is feasible and is the need of the hour during the pandemic.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:b0M2c_1WBrUC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Attention-based models such as transformers have shown outstanding performance on dense prediction tasks, such as semantic segmentation, owing to their capability of capturing long-range dependency in an image. However, the benefit of transformers for monocular depth prediction has seldom been explored so far. This paper benchmarks various transformer-based models for the depth estimation task on an indoor NYUV2 dataset and an outdoor KITTI dataset. We propose a novel attention-based architecture, Depthformer for monocular depth estimation that uses multi-head self-attention to produce the multiscale feature maps, which are effectively combined by our proposed decoder network. We also propose a Transbins module that divides the depth range into bins whose center value is estimated adaptively per image. The final depth estimated is a linear combination of bin centers for each pixel. Transbins module takes advantage of the global receptive field using the transformer module in the encoding stage. Experimental results on NYUV2 and KITTI depth estimation benchmark demonstrate that our proposed method improves the state-of-the-art by 3.3%, and 3.3% respectively in terms of Root Mean Squared Error (RMSE).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:EUQCXRtRnyEC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"While detection of malignancies on mammography has received a boost with the use of Convolutional Neural Networks (CNN), detection of cancers of very small size remains challenging. This is however clinically significant as the purpose of mammography is early detection of cancer, making it imperative to pick them up when they are still very small. Mammography has the highest spatial resolution (image sizes as high as 3328 × 4096 pixels) out of all imaging modalities, a requirement that stems from the need to detect fine features of the smallest cancers on screening. However due to computational constraints, most state of the art CNNs work on reduced resolution images. Those that work on higher resolutions, compromise on global context and work at single scale. In this work, we show that resolution, scale and image-context are all important independent factors in detection of small masses. We thereby use …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:_xSYboBqXhAC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Few-shot object detection (FSOD) localizes and classifies objects in an image given only a few data samples. Recent trends in FSOD research show the adoption of metric and meta-learning techniques, which are prone to catastrophic forgetting and class confusion. To overcome these pitfalls in metric learning based FSOD techniques, we introduce Attention Guided Cosine Margin (AGCM) that facilitates the creation of tighter and well separated class-specific feature clusters in the classification head of the object detector. Our novel Attentive Proposal Fusion (APF) module minimizes catastrophic forgetting by reducing the intra-class variance among co-occurring classes. At the same time, the proposed Cosine Margin Cross-Entropy loss increases the angular margin between confusing classes to overcome the challenge of class confusion between already learned (base) and newly added (novel) classes. We conduct our experiments on the challenging India Driving Dataset (IDD), which presents a real-world class-imbalanced setting alongside popular FSOD benchmark PASCAL-VOC. Our method outperforms State-of-the-Art (SoTA) approaches by up to 6.4 mAP points on the IDD-OS and up to 2.0 mAP points on the IDD-10 splits for the 10-shot setting. On the PASCAL-VOC dataset, we outperform existing SoTA approaches by up to 4.9 mAP points.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:pyW8ca7W8N0C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"In this paper, we propose an algorithm for optimal solutions to submodular higher order multi-label MRF-MAP energy functions which can handle practical computer vision problems with up to 16 labels and cliques of size 100. The algorithm uses a transformation which transforms a multi-label problem to a 2-label problem on a much larger clique. Earlier algorithms based on this transformation could not handle problems larger than 16 labels on cliques of size 4. The proposed algorithm optimizes the resultant 2-label problem using the submodular polyhedron based Min Norm Point algorithm. The task is challenging because the state space of the transformed problem has a very large number of invalid states. For polyhedral based algorithms the presence of invalid states poses a challenge as apart from numerical instability, the transformation also increases the dimension of the polyhedral space making the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:NMxIlDl6LWMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Summary form only given, as follows. Census 2011 classifies more that 5 million people as visually disabled In India. AssisTech (Assistive Technology) group at IIT Delhi aims to develop technological solutions to address their two key challenges; namely independent mobility and access to education. In this tutorial, we will firstly brief about the challenge of mobility and education for visually impaired people. Solutions addressing these challenges could be developed using embedded sensors or with embedded computer vision. Our existing products like SmartCaneTM and OnBoard are embedded system based solutions and are aimed towards facilitating independent mobility. There have been major advances in vision based techniques including possibility of their implementation on low cost embedded platforms. This has encouraged us to visualize a device named MAVI (Mobility Assistant for Visually Impaired …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:QIV2ME_5wuYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Many prediction tasks, especially in computer vision, are often inherently ambiguous. For example, the output of semantic segmentation may depend on the scale one is looking at. Similarly, image saliency or video summarization is often user or context dependent. Arguably, in such scenarios, exploiting instance specific evidence, such as scale or user context, can help resolve the underlying ambiguity leading to the improved predictions. While existing literature has considered incorporating such evidence in classical models such as probabilistic graphical models (PGMs), there is limited (or no) prior work looking at this problem in the context of deep neural network (DNN) models. In this paper, we present a generic multi-task learning (MTL) based framework which handles the evidence as the output of one or more secondary tasks, while modeling the original problem as the primary task of interest. Our training phase is identical to the one used by standard MTL architectures. During prediction, we back-propagate the loss on secondary task (s) such that network weights are re-adjusted to match the evidence. An early stopping or two norm based regularizer ensures weights do not deviate significantly from the ones learned originally. Implementation in a scenario of predicting semantic segmentation given the image level tags clearly demonstrates the effectiveness of our proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:isC4tDSrTZIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Many prediction tasks, especially in computer vision, are often inherently ambiguous. For example, the output of semantic segmentation may depend on the scale one is looking at. Similarly, image saliency or video summarization is often user or context dependent. Arguably, in such scenarios, exploiting instance specific evidence, such as scale or user context, can help resolve the underlying ambiguity leading to the improved predictions. While existing literature has considered incorporating such evidence in classical models such as probabilistic graphical models (PGMs), there is limited (or no) prior work looking at this problem in the context of deep neural network (DNN) models. In this paper, we present a generic multi-task learning (MTL) based framework which handles the evidence as the output of one or more secondary tasks, while modeling the original problem as the primary task of interest. Our training phase is identical to the one used by standard MTL architectures. During prediction, we back-propagate the loss on secondary task (s) such that network weights are re-adjusted to match the evidence. An early stopping or two norm based regularizer ensures weights do not deviate significantly from the ones learned originally. Implementation in a scenario of predicting semantic segmentation given the image level tags clearly demonstrates the effectiveness of our proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:HDshCWvjkbEC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"We focus on the problem of LiDAR point cloud based loop detection (or Finding) and closure (LDC) in a multi-agent setting. State-of-the-art (SOTA) techniques directly generate learned embeddings of a given point cloud, require large data transfers, and are not robust to wide variations in 6 Degrees-of-Freedom (DOF) viewpoint. Moreover, absence of strong priors in an unstructured point cloud leads to highly inaccurate LDC. In this original approach, we propose independent roll and pitch canonicalization of the point clouds using a common dominant ground plane. Discretization of the canonicalized point cloud along the axis perpendicular to the ground plane leads to an image similar to Digital Elevation Maps (DEMs), which exposes strong spatial priors in the scene. Our experiments show that LDC based on learnt embeddings of such DEMs is not only data efficient but also significantly more robust, and generalizable than the current SOTA. We report significant performance gain in terms of Average Precision for loop detection and absolute translation/rotation error for relative pose estimation (or loop closure) on Kitti, GPR and Oxford Robot Car over multiple SOTA LDC methods. Our encoder technique allows to compress the original point cloud by over 830 times. To further test the robustness of our technique we create and opensource a custom dataset called Lidar-UrbanFly Dataset (LUF) which consists of point clouds obtained from a LiDAR mounted on a quadrotor.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:Tiz5es2fbqcC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Modern deep neural network models are known to erroneously classify out-of-distribution (OOD) test data into one of the in-distribution (ID) training classes with high confidence. This can have disastrous consequences for safety-critical applications. A popular mitigation strategy is to train a separate classifier that can detect such OOD samples at test time. In most practical settings OOD examples are not known at train time, and hence a key question is: how to augment theID data with syntheticOOD samples for training such anOOD detector? In this paper, we propose a novel Compounded Corruption (CnC) technique for the OOD data augmentation. One of the major advantages of CnC is that it does not require any hold-out data apart from training set. Further, unlike current state-of-the-art (SOTA) techniques, CnC does not require backpropagation or ensembling at the test time, making our method much faster at …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:CHSYGLWDkRkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Egocentric videos are recorded in a hands-free, always-on, under enhanced privacy-sensitive scenario and are often collected from day to weeks. For efficient consumption, such videos require robust video analysis techniques that can deal with extremely long sequences in an unsupervised setting. This dissertation explores a novel research area by developing video analysis tasks for extremely long and sequential data (ranging from a day to weeks long) in a self supervised /unsupervised setting. In this dissertation, we address the three key video analysis problems, namely temporal segmentation, summa-rization, and recovering activity patterns, specifically designed to deal with the issues of scalability, privacy, and unlabeled data.There are a plethora of works in the literature for third person video analysis. How-ever, third person videos are often recorded from point-and-shoot cameras, thus gener-ating small …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:WbkHhVStYXYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Minimally invasive surgeries and related applications demand surgical tool classification and segmentation at the instance level. Surgical tools are similar in appearance and are long, thin, and handled at an angle. The fine-tuning of state-of-the-art (SOTA) instance segmentation models trained on natural images for instrument segmentation has difficulty discriminating instrument classes. Our research demonstrates that while the bounding box and segmentation mask are often accurate, the classification head misclassifies the class label of the surgical instrument. We present a new neural network framework that adds a classification module as a new stage to existing instance segmentation models. This module specializes in improving the classification of instrument masks generated by the existing model. The module comprises multi-scale mask attention, which attends to the instrument region and masks the distracting background features. We propose training the proposed classifier module using metric learning with arc loss to handle low inter-class variance of surgical instruments. We conduct exhaustive experiments on the benchmark datasets EndoVis2017 and EndoVis2018. We demonstrate that our method outperforms all (more than 18) SOTA methods compared with and improves the\sota performance by at least 12 points (20%) on the EndoVis2017 benchmark challenge and generalizes effectively across the datasets. Project page with source code is available at nets-iitd. github. io/s3net.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:XiSMed-E-HIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"In Active Domain Adaptation (ADA), one uses Active Learning (AL) to select target domain frames to annotate for Domain Adaptation (DA). Thus, ADA creates a continuum of cost-performance trade-off models, with unsupervised, and fully supervised DA techniques at the two ends. We observe that in ADA not all regions of a selected frame contribute equally to a model's performance, and there is a strong correlation between annotating certain hard/unique/novel object/stuff instances, and a model's performance. Eg, road regions in a target dataset may look mostly similar to source domain except for certain curved instances, where annotation may be more useful. Based on the observation, we propose Anchor-based and Augmentation-based ADA techniques, which, given a selected frame, determine certain'hard'semantic regions to be annotated in that frame, such that the selected regions are complementary and diverse in the context of the current labeled set. The proposed techniques carefully avoid the pitfall of region based AL techniques which try to choose most uncertain regions in a frame, but ends up selecting all edge pixels, and similar annotation cost as the whole frame. We show that our approach achieves 66.6\miou on\gta->\cityscapes dataset with a budget of 4.7% in comparison to 64.9\miou by MADA [??]. Our technique can also be used as a decorator for any existing frame-based AL technique. Eg, we report 1.5% performance improvement for CDAL [??] on\cityscapes using our approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:OU6Ihb5iCvQC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Object detection plays an essential role in providing localization, path planning, and decision making capabilities in autonomous navigation systems. However, existing object detection models are trained and tested on a fixed number of known classes. This setting makes the object detection model difficult to generalize well in real-world road scenarios while encountering an unknown object. We address this problem by introducing our framework that handles the issue of unknown object detection and updates the model when unknown object labels are available. Next, our solution includes three major components that address the inherent problems present in the road scene datasets. The novel components are a) Feature-Mix that improves the unknown object detection by widening the gap between known and unknown classes in latent feature space, b) Focal regression loss handling the problem of improving …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:P5F9QuxV20EC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Surgical simulators provide hands-on training and learning of the necessary psychomotor skills. Automated skill evaluation of the trainee doctors based on the video of a task being performed by them is an important key step for the optimal utilization of such simulators. However, current skill evaluation techniques require accurate tracking information of the instruments which restricts their applicability to robot assisted surgeries only. In this paper, we propose a novel neural network architecture that can perform skill evaluation using video data alone (and no tracking information). Given the small dataset available for training such a system, the network trained using ℓ 2 regression loss easily overfits the training data. We propose a novel rank loss to help learn robust representation, leading to 5% improvement for skill score prediction on the benchmark JIGSAWS dataset. To demonstrate the applicability of our method …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:KxtntwgDAa4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Rich temporal information and variations in viewpoints make video data an attractive choice for learning image representations using unsupervised contrastive learning (UCL) techniques. State-of-the-art (SOTA) contrastive learning techniques consider frames within a video as positives in the embedding space, whereas the frames from other videos are considered negatives. We observe that unlike multiple views of an object in natural scene videos, an Ultrasound (US) video captures different 2D slices of an organ. Hence, there is almost no similarity between the temporally distant frames of even the same US video. In this paper we propose to instead utilize such frames as hard negatives. We advocate mining both intra-video and cross-video negatives in a hardness-sensitive negative mining curriculum in a UCL framework to learn rich image representations. We deploy our framework to learn the representations …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:xtRiw3GOFMkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"A system and method for generating an optimized image with scribble-based interactive image segmentation model using a machine learning are provided. The method includes,(i) segmenting, using a machine learning model, an image to classify into classes each class is represented with a label,(ii) displaying the classified image which specifies the classes on the classified image with outlines,(iii) enabling a user to scribble on the classified image to annotate the classes if an area is not classified,(iv) assigning a color mask for each scribbled area,(v) computing, using the machine learning model, a loss function for a location of pixels based on color mask,(vi) modifying pre-defined weights for each scribbled area to match the annotated image and a determined class on the classified image, and (vii) generating the optimized image if the annotated image is matched with the determined class on the classified image.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:UxriW0iASnsC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:bFI3QPDXJZMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"A system and method generating an optimized medical image using a machine learning model are provided. The method includes (i) receiving one or more medical images,(ii) segmenting to generate a transformed medical image for detecting a plurality of target elements,(iii) displaying the transformed medical image,(iv) receiving markings and scribblings associated with scribble locations from a user,(v) identifying errors associated with an outline of a target element,(vi) computing a loss function for a location of pixels where the target element is located on the transformed medical image,(vii) modifying the pre-defined weights (w) to match the segmentation output and the determined target element,(viii) determining whether the segmentation output is matched with the target element and (ix) generating the optimized medical image if the segmentation output is matched with the determined target element.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:NhqRSupF_l8C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Initiation, monitoring, and evaluation of development programmes can involve field-based data collection about project activities. This data collection through digital devices may not always be feasible though, for reasons such as unaffordability of smartphones and tablets by field-based cadre, or shortfalls in their training and capacity building. Paper-based data collection has been argued to be more appropriate in several contexts, with automated digitization of the paper forms through OCR (Optical Character Recognition) and OMR (Optical Mark Recognition) techniques. We contribute with providing a large dataset of handwritten digits, and deep learning based models and methods built using this data, that are effective in real-world environments. We demonstrate the deployment of these tools in the context of a maternal and child health and nutrition awareness project, which uses IVR (Interactive Voice …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:D03iK_w7-QYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"With the rapid integration of artificial intelligence (AI) into medical practice, there has been an exponential increase in the number of scientific papers and industry players offering models designed for various tasks. Understanding these, however, is difficult for a radiologist in practice, given the core mathematical principles and complicated terminology involved. This review aims to elucidate the core mathematical concepts of both machine learning and deep learning models, explaining the various steps and common terminology in common layman language. Thus, by the end of this article, the reader should be able to understand the basics of how prediction models are built and trained, including challenges faced and how to avoid them. The reader would also be equipped to adequately evaluate various models, and take a decision on whether a model is likely to perform adequately in the real-world setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:dfsIfKJdRG4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"A large proportion of videos captured today are first per-son videos shot from wearable cameras. Similar to other computer vision tasks, Deep Neural Networks (DNNs) are the workhorse for most state-of-the-art (SOTA) egocentric vision techniques. On the other hand DNNs are known to be susceptible to Adversarial Attacks (AAs) which add im-perceptible noise to the input. Both black-box, as well as white-box attacks on image as well as video analysis tasks have been shown. We observe that most AA techniques basically add intensity perturbation to an image. Even for videos, the same process is essentially repeated for each frame independently. We note that the definition of imperceptibility used for images may not be applicable for videos, where a small intensity change happening randomly in two consecutive frames may still be perceptible. In this paper we make a key novel suggestion to use perturbation in optical flow to carry out AAs on a video analysis system. Such perturbation is especially useful for egocentric videos, because there is a lot of shake in the egocentric videos anyways, and adding a little more, keeps it highly imperceptible. In general, our idea can be seen as adding structured, para-metric noise as the adversarial perturbation. Our implementation of the idea by adding 3D rotations to the frames reveal that using our technique, one can mount a black-box AA on an egocentric activity detection system in one-third of the queries compared to the SOTA AA technique.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:cFHS6HbyZ2cC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:3s1wT3WcHBgC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Video object detection is the task of detecting objects in a sequence of frames, typically, with a significant overlap in content among consecutive frames. Mean Average Precision (mAP) was originally proposed for evaluating object detection techniques in independent frames, but has been used for evaluating video based object detectors as well. This is undesirable since the average precision over all frames masks the biases that a certain object detector might have against certain types of objects depending on the number of frames for which the object is present in a video sequence. In this paper we show several disadvantages of mAP as a metric for evaluating video based object detection. Specifically, we show that: (a) some object detectors could be severely biased against some specific kind of objects, such as small, blurred, or low contrast objects, and such differences may not reflect in mAP based evaluation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:vV6vV6tmYwMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",20,"Scene Text Recognition (STR) refers to the task of recognition of text in natural scenes. The success of OCR models is hard to achieve on natural scene images due to a variety of challenges, including - variation in orientation and pixel intensities in images, low resolution and errors in bounding box detection, as well as variation in fonts and shapes of print of characters. Our main objective is to obtain a model that achieves near State of the Art performance out custom MAVI dataset, which will allow it to be used in the real world application of assisting a visually impaired person to read signboards in order to obtain directions. We provide an end-to-end detection and recognition system for the same. Problems arise when the distribution of data seen during test time differs from the training data. The model cannot make reliable predictions in such a scenario. We perform experiments to demonstrate how the model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&citation_for_view=Q8cTLNMAAAAJ:fPk4N6BV_jEC,http://www.cse.iitd.ac.in/~chetan
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"For several problems of interest, there are natural constraints which exist over the output label space. For example, for the joint task of NER and POS labeling, these constraints might specify that the NER label ‘organization’is consistent only with the POS labels ‘noun’and ‘preposition’. These constraints can be a great way of injecting prior knowledge into a deep learning model, thereby improving overall performance. In this paper, we present a constrained optimization formulation for training a deep network with a given set of hard constraints on output labels. Our novel approach first converts the label constraints into soft logic constraints over probability distributions outputted by the network. It then converts the constrained optimization problem into an alternating min-max optimization with Lagrangian variables defined for each constraint. Since the constraints are independent of the target labels, our framework easily generalizes to semi-supervised setting. We experiment on the tasks of Semantic Role Labeling (SRL), Named Entity Recognition (NER) tagging, and fine-grained entity typing and show that our constraints not only significantly reduce the number of constraint violations, but can also result in state-of-the-art performance",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&citation_for_view=V49BsgMAAAAJ:EUQCXRtRnyEC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Objective:
Since its outbreak, the rapid spread of COrona VIrus Disease 2019 (COVID-19) across the globe has pushed the health care system in many countries to the verge of collapse. Therefore, it is imperative to correctly identify COVID-19 positive patients and isolate them as soon as possible to contain the spread of the disease and reduce the ongoing burden on the healthcare system. The primary COVID-19 screening test, RT-PCR although accurate and reliable, has a long turn-around time. In the recent past, several researchers have demonstrated the use of Deep Learning (DL) methods on chest radiography (such as X-ray and CT) for COVID-19 detection. However, existing CNN based DL methods fail to capture the global context due to their inherent image-specific inductive bias.
Methods:
Motivated by this, in this work, we propose the use of vision transformers (instead of convolutional networks) for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&citation_for_view=V49BsgMAAAAJ:XiSMed-E-HIC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"CommonsenseQA (CQA)(Talmor et al., 2019) dataset was recently released to advance the research on common-sense question answering (QA) task. Whereas the prior work has mostly focused on proposing QA models for this dataset, our aim is to retrieve as well as generate explanation for a given (question, correct answer choice, incorrect answer choices) tuple from this dataset. Our explanation definition is based on certain desiderata, and translates an explanation into a set of positive and negative common-sense properties (aka facts) which not only explain the correct answer choice but also refute the incorrect ones. We human-annotate a first-of-its-kind dataset (called ECQA) of positive and negative properties, as well as free-flow explanations, for 11K QA pairs taken from the CQA dataset. We propose a latent representation based property retrieval model as well as a GPT-2 based property generation model with a novel two step fine-tuning procedure. We also propose a free-flow explanation generation model. Extensive experiments show that our retrieval model beats BM25 baseline by a relative gain of 100% in F 1 score, property generation model achieves a respectable F 1 score of 36.4, and free-flow generation model achieves a similarity score of 61.9, where last two scores are based on a human correlated semantic similarity metric.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:738O_yMBCRsC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Fluctuations in food prices can cause distress among both consumers and producers, and are often exacerbated by trading networks especially in developing economies where marketplaces may not be operating under conditions of perfect competition for various contextual reasons. We look at onion and potato trading in India and present the evaluation of a price forecasting model, and an anomaly detection and classification system to identify incidents of hoarding of stock by the traders. Our dataset is composed of time series of wholesale prices and arrival volumes of the agricultural commodities at several village-level marketplaces, and retail prices of the commodities at the city centers. We also provide an in-depth qualitative analysis of the effect on these time series of events such as hoarding, weather disturbances, and external shocks. Our results are encouraging and point towards the possibility of building …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:D03iK_w7-QYC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"We present the novel task of understanding multi-sentence entity-seeking questions (MSEQs), that is, the questions that may be expressed in multiple sentences, and that expect one or more entities as an answer. We formulate the problem of understanding MSEQs as a semantic labeling task over an open representation that makes minimal assumptions about schema or ontology-specific semantic vocabulary. At the core of our model, we use a BiLSTM (bidirectional LSTM) conditional random field (CRF), and to overcome the challenges of operating with low training data, we supplement it by using BERT embeddings, hand-designed features, as well as hard and soft constraints spanning multiple sentences. We find that this results in a 12–15 points gain over a vanilla BiLSTM CRF. We demonstrate the strengths of our work using the novel task of answering real-world entity-seeking questions from the tourism …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:abG-DnoFyZgC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Several domains in AI need to represent the relational structure as well as model uncertainty. Markov Logic is a powerful formalism which achieves this by attaching weights to formulas in finite first-order logic. Though Markov Logic Networks (MLNs) have been used for a wide variety of applications, a significant challenge remains that weights do not generalize well when training domain sizes are different from those seen during testing. In particular, it has been observed that marginal probabilities tend to extremes in the limit of increasing domain sizes. As the first contribution of our work, we further characterize the distribution and show that marginal probabilities tend to a constant independent of weights and not always to extremes as was previously observed. As our second contribution, we present a principled solution to this problem by defining Domain-size Aware Markov Logic Networks (DA-MLNs) which can be seen as re-parameterizing the MLNs after taking domain size into consideration. For some simple but representative MLN formulas, we formally prove that probabilities defined by DA-MLNs are well behaved. On a practical side, DA-MLNs allow us to generalize the weights learned over small-sized training data to much larger domains. Experiments on three different benchmark MLNs show that our approach results in significant performance gains compared to existing methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:yD5IFk8b50cC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"The field of neural generative models is dominated by the highly successful Generative Adversarial Networks (GANs) despite their challenges, such as training instability and mode collapse. Auto-Encoders (AE) with regularized latent space provide an alternative framework for generative models, albeit their performance levels have not reached that of GANs. In this work, we hypothesise that the dimensionality of the AE model's latent space has a critical effect on the quality of generated data. Under the assumption that nature generates data by sampling from a ""true"" generative latent space followed by a deterministic function, we show that the optimal performance is obtained when the dimensionality of the latent space of the AE-model matches with that of the ""true"" generative latent space. Further, we propose an algorithm called the Mask Adversarial Auto-Encoder (MaskAAE), in which the dimensionality of the latent space of an adversarial auto encoder is brought closer to that of the ""true"" generative latent space, via a procedure to mask the spurious latent dimensions. We demonstrate through experiments on synthetic and several real-world datasets that the proposed formulation yields betterment in the generation quality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:dshw04ExmUIC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Our goal is to answer real-world tourism questions that seek Points-of-Interest (POI) recommendations. Such questions express various kinds of spatial and non-spatial constraints, necessitating a combination of textual and spatial reasoning. In response, we develop the first joint spatio-textual reasoning model, which combines geo-spatial knowledge with information in textual corpora to answer questions. We first develop a modular spatial-reasoning network that uses geo-coordinates of location names mentioned in a question, and of candidate answer POIs, to reason over only spatial constraints. We then combine our spatial-reasoner with a textual reasoner in a joint model and present experiments on a real world POI recommendation task. We report substantial improvements over existing models without joint spatio-textual reasoning. To the best of our knowledge, we are the first to develop a joint QA model that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:UxriW0iASnsC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Lifted inference reduces the complexity of inference in relational probabilistic models by identifying groups of constants (or atoms) which behave symmetric to each other. A number of techniques have been proposed in the literature for lifting marginal as well MAP inference. We present the first application of lifting rules for marginal-MAP (MMAP), an important inference problem in models having latent (random) variables. Our main contribution is two fold: (1) we define a new equivalence class of (logical) variables, called Single Occurrence for MAX (SOM), and show that solution lies at extreme with respect to the SOM variables, i.e., predicate groundings differing only in the instantiation of the SOM variables take the same truth value (2) we define a sub-class {\em SOM-R} (SOM Reduce) and exploit properties of extreme assignments to show that MMAP inference can be performed by reducing the domain of SOM-R variables to a single constant.We refer to our lifting technique as the {\em SOM-R} rule for lifted MMAP. Combined with existing rules such as decomposer and binomial, this results in a powerful framework for lifted MMAP. Experiments on three benchmark domains show significant gains in both time and memory compared to ground inference as well as lifted approaches not using SOM-R.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:f2IySw72cVMC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Auto-Encoder (AE) based neural generative frameworks model the joint-distribution between the data and the latent space using an Encoder-Decoder pair, with regularization imposed in terms of a prior over the latent space. Despite their advantages, such as stability in training, efficient inference, the performance of AE based models has not reached the superior standards of the other generative models such as Generative Adversarial Networks (GANs). Motivated by this, we examine the effect of the latent prior on the generation quality of deterministic AE models in this paper. Specifically, we consider the class of Generative AE models with deterministic Encoder-Decoder pair (such as Wasserstein Auto-Encoder (WAE), Adversarial Auto-Encoder (AAE)), and show that having a fixed prior distribution, a priori, oblivious to the dimensionality of the ‘true’latent space, will lead to the infeasibility of the optimization problem considered. As a remedy to the issue mentioned above, we introduce an additional state space in the form of flexibly learnable latent priors, in the optimization objective of WAE/AAE. Additionally, we employ a latent-space interpolation based smoothing scheme to address the non-smoothness that may arise from highly flexible priors. We show the efficacy of our proposed models, called FlexAE and FlexAE-SR, through several experiments on multiple datasets, and demonstrate that FlexAE-SR is the new state-of-the-art for the AE based generative models in terms of generation quality as measured by several metrics such as Fr\’echet Inception Distance, Precision/Recall score.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:u9iWguZQMMsC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"In this paper, we describe IIT Delhi’s submissions to the WMT 2020 task on Similar Language Translation for four language directions: Hindi<-> Marathi and Spanish<-> Portuguese. We try out three different model settings for the translation task and select our primary and contrastive submissions on the basis of performance of these three models. For our best submissions, we fine-tune the mBART model on the parallel data provided for the task. The pre-training is done using self-supervised objectives on a large amount of monolingual data for many languages. Overall, our models are ranked in the top four of all systems for the submitted language pairs, with first rank in Spanish-> Portuguese.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:SP6oXDckpogC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any one of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks, demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:KxtntwgDAa4C,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"State-of-the-art models for Knowledge Base Completion (KBC) are based on tensor factorization (TF), e.g, DistMult, ComplEx. While they produce good results, they cannot expose any rationale behind their predictions, potentially reducing the trust of a user in the model. Previous works have explored creating an inherently explainable model, e.g. Neural Theorem Proving (NTP), DeepPath, MINERVA, but explainability comes at the cost of performance. Others have tried to create an auxiliary explainable model having high fidelity with the underlying TF model, but unfortunately, they do not scale on large KBs such as FB15k and YAGO. In this work, we propose OxKBC -- an Outcome eXplanation engine for KBC, which provides a post-hoc explanation for every triple inferred by an (uninterpretable) factorization based model. It first augments the underlying Knowledge Graph by introducing weighted edges between entities based on their similarity given by the underlying model. In the augmented graph, it defines a notion of human-understandable explanation paths along with a language to generate them. Depending on the edges, the paths are aggregated into second-order templates for further selection. The best template with its grounding is then selected by a neural selection module that is trained with minimal supervision by a novel loss function. Experiments over Mechanical Turk demonstrate that users find our explanations more trustworthy compared to rule mining.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:P5F9QuxV20EC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"One popular way for lifted inference in probabilistic graphical models is to first merge symmetric states into a single cluster (orbit) and then use these for downstream inference, via variations of orbital MCMC [Niepert, 2012]. These orbits are represented compactly using permutations over variables, and variable-value (VV) pairs, but they can miss several state symmetries in a domain. We define the notion of permutations over block-value (BV) pairs, where a block is a set of variables. BV strictly generalizes VV symmetries, and can compute many more symmetries for increasing block sizes. To operationalize use of BV permutations in lifted inference, we describe 1) an algorithm to compute BV permutations given a block partition of the variables, 2) BV-MCMC, an extension of orbital MCMC that can sample from BV orbits, and 3) a heuristic to suggest good block partitions. Our experiments show that BV-MCMC can mix much faster compared to vanilla MCMC and orbital MCMC.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:ZHo1McVdvXMC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Neural models for distantly supervised relation extraction (DS-RE) encode each sentence in an entity-pair bag separately. These are then aggregated for bag-level relation prediction. Since, at encoding time, these approaches do not allow information to flow from other sentences in the bag, we believe that they do not utilize the available bag data to the fullest. In response, we explore a simple baseline approach (PARE) in which all sentences of a bag are concatenated into a passage of sentences, and encoded jointly using BERT. The contextual embeddings of tokens are aggregated using attention with the candidate relation as query–this summary of whole passage predicts the candidate relation. We find that our simple baseline solution outperforms existing state-of-the-art DS-RE models in both monolingual and multilingual DS-RE datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:vRqMK49ujn8C,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Clustering single-cell RNA sequence (scRNA-seq) data poses statistical and computational challenges due to their high-dimensionality and data-sparsity, also known as ‘dropout’ events. Recently, Regularized Auto-Encoder (RAE) based deep neural network models have achieved remarkable success in learning robust low-dimensional representations. The basic idea in RAEs is to learn a non-linear mapping from the high-dimensional data space to a low-dimensional latent space and vice-versa, simultaneously imposing a distributional prior on the latent space, which brings in a regularization effect. This paper argues that RAEs suffer from the infamous problem of bias-variance trade-off in their naive formulation. While a simple AE wita latent regularization results in data over-fitting, a very strong prior leads to under-representation and thus bad clustering. To address the above issues, we propose a modified RAE …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:WbkHhVStYXYC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"We introduce the novel task of answering entity-seeking recommendation questions using a collection of reviews that describe candidate answer entities. We harvest a QA dataset that contains 47,124 paragraph-sized real user questions from travelers seeking recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate answers to choose from and each candidate is associated with a collection of unstructured reviews. This dataset is especially challenging because commonly used neural architectures for reasoning and QA are prohibitively expensive for a task of this scale. As a solution, we design a scalable cluster-select-rerank approach. It first clusters text for each entity to identify exemplar sentences describing an entity. It then uses a scalable neural information retrieval (IR) module to select a set of potential entities from the large candidate set. A reranker uses a deeper attention-based architecture to pick the best answers from the selected entities. This strategy performs better than a pure IR or a pure attention-based reasoning approach yielding nearly 25% relative improvement in Accuracy@3 over both approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:bFI3QPDXJZMC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"We introduce the novel and challenging task of answering Points-of-interest (POI) recommendation questions, using a collection of reviews that describe candidate answer entities (POIs). We harvest a QA dataset that contains 47,124 paragraph-sized user questions from travelers seeking POI recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate entities to choose from and each candidate is associated with a collection of unstructured reviews. Questions can include requirements based on physical location, budget, timings as well as other subjective considerations related to ambience, quality of service etc. Our dataset requires reasoning over a large number of candidate answer entities (over 5300 per question on average) and we find that running commonly used neural architectures for QA is prohibitively expensive. Further, commonly used retriever-ranker …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:tOudhMTPpwUC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Pre-trained language models (LMs) like BERT have shown to store factual knowledge about the world. This knowledge can be used to augment the information present in Knowledge Bases, which tend to be incomplete. However, prior attempts at using BERT for task of Knowledge Base Completion (KBC) resulted in performance worse than embedding based techniques that rely only on the graph structure. In this work we develop a novel model, Cross-Entity Aware Reranker (CEAR), that uses BERT to re-rank the output of existing KBC models with cross-entity attention. Unlike prior work that scores each entity independently, CEAR uses BERT to score the entities together, which is effective for exploiting its factual knowledge. CEAR achieves a new state of art for the OLPBench dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:p2g8aNsByqUC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"We present the novel task of understanding multi-sentence entity-seeking questions (MSEQs) ie, questions that may be expressed in multiple sentences, and that expect one or more entities as an answer. We formulate the problem of understanding MSEQs as a semantic labeling task over an open representation that makes minimal assumptions about schema or ontology specific semantic vocabulary. At the core of our model, we use a BiDiLSTM (bi-directional LSTM) CRF and to overcome the challenges of operating with low training data, we supplement it by using hand-designed features, as well as hard and soft constraints spanning multiple sentences. We find that this results in a 6-7pt gain over a vanilla BiDiL-STM CRF. We demonstrate the strengths of our work using the novel task of answering real-world entity-seeking questions from the tourism domain. The use of our labels helps answer 53% more questions with 42% more accuracy as compared to baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:_xSYboBqXhAC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Many prediction tasks, especially in computer vision, are often inherently ambiguous. For example, the output of semantic segmentation may depend on the scale one is looking at. Similarly, image saliency or video summarization is often user or context dependent. Arguably, in such scenarios, exploiting instance specific evidence, such as scale or user context, can help resolve the underlying ambiguity leading to the improved predictions. While existing literature has considered incorporating such evidence in classical models such as probabilistic graphical models (PGMs), there is limited (or no) prior work looking at this problem in the context of deep neural network (DNN) models. In this paper, we present a generic multi-task learning (MTL) based framework which handles the evidence as the output of one or more secondary tasks, while modeling the original problem as the primary task of interest. Our training phase is identical to the one used by standard MTL architectures. During prediction, we back-propagate the loss on secondary task (s) such that network weights are re-adjusted to match the evidence. An early stopping or two norm based regularizer ensures weights do not deviate significantly from the ones learned originally. Implementation in a scenario of predicting semantic segmentation given the image level tags clearly demonstrates the effectiveness of our proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:zA6iFVUQeVQC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Class imbalance is a common phenomenon in multiple application domains such as healthcare, where the sample occurrence of one or few class categories is more prevalent in the dataset than the rest. This work addresses the class-imbalance issue by proposing an over-sampling method for the minority classes in the latent space of a Regularized Auto-Encoder (RAE). Specifically, we construct a latent space by maximizing the conditional data likelihood using an Encoder-Decoder structure, such that oversampling through convex combinations of latent samples preserves the class identity. A jointly-trained linear classifier that separates convexly coupled latent vectors from different classes is used to impose this property on the AE’s latent space. Further, the aforesaid linear classifier is used for final classification without retraining. We theoretically show that our method can achieve a low variance risk estimate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:1qzjygNMrQYC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Multi-modal learning aims at simultaneously modelling data from several modalities such as image, text and speech. The goal is to simultaneously learn representations and make them disentangled so that a variety of downstream tasks such as causal reasoning, fair ML and domain adaptation are well supported. In this work, we propose a novel semi-supervised method to learn disentangled representations for multi-modal data using variational inference. We incorporate a two-component latent space in a Variational Auto-Encoder (VAE) that comprises of domain-invariant (shared) and domain-specific (private) representations across modalities with partitioned discrete and continuous components. We combine the shared continuous and discrete latent spaces via Product-of-experts and statistical ensembles, respectively. We conduct several experiments on multiple multimodal datasets (dSprite-Text, Shaped3D …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:8AbLer7MMksC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Image manipulation via natural language text -- an extremely useful task for multiple AI applications but requires complex reasoning over multi-modal spaces. Neuro-symbolic approaches has been quite effective in solving such tasks as they offer better modularity, interpretability, and generalizability. A noteworthy such approach is NSCL [10] developed for the task of Visual Question Answering (VQA). We extend NSCL for the image manipulation task and propose a solution referred to as NEUROSIM. Unlike previous works, which either require supervised data training or can only deal with simple reasoning instructions over single object scenes; NEUROSIM can perform complex multi-hop reasoning over multi-object scenes and requires only weak supervision in the form of annotated data for the VQA task. On the language side, NEUROSIM contains neural modules that parse an instruction into a symbolic program over a Domain Specific Language (DSL) comprising manipulation operations that guide the manipulation. On the perceptual side, NEUROSIM contains neural modules which first generate a scene graph of the input image and then change the scene graph representation following the parsed instruction. To train these modules, we design novel loss functions capable of testing the correctness of manipulated object and scene graph representations via query networks. An image decoder is trained to render the final image from the manipulated scene graph representation. Extensive experiments demonstrate that NEUROSIM is highly competitive with state-of-the-art supervised baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:eJXPG6dFmWUC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Given a natural language instruction, and an input and an output scene, our goal is to train a neuro-symbolic model which can output a manipulation program that can be executed by the robot on the input scene resulting in the desired output scene. Prior approaches for this task possess one of the following limitations: (i) rely on hand-coded symbols for concepts limiting generalization beyond those seen during training [1] (ii) infer action sequences from instructions but require dense sub-goal supervision [2] or (iii) lack semantics required for deeper object-centric reasoning inherent in interpreting complex instructions [3]. In contrast, our approach is neuro-symbolic and can handle linguistic as well as perceptual variations, is end-to-end differentiable requiring no intermediate supervision, and makes use of symbolic reasoning constructs which operate on a latent neural object-centric representation, allowing for deeper reasoning over the input scene. Central to our approach is a modular structure, consisting of a hierarchical instruction parser, and a manipulation module to learn disentangled action representations, both trained via RL. Our experiments on a simulated environment with a 7-DOF manipulator, consisting of instructions with varying number of steps, as well as scenes with different number of objects, and objects with unseen attribute combinations, demonstrate that our model is robust to such variations, and significantly outperforms existing baselines, particularly in generalization settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:D_sINldO8mEC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"There is a recent focus on designing architectures that have an Integer Linear Programming (ILP) layer within a neural model (referred to as Neural ILP in this paper). Neural ILP architectures are suitable for pure reasoning tasks that require data-driven constraint learning or for tasks requiring both perception (neural) and reasoning (ILP). A recent SOTA approach for end-to-end training of Neural ILP explicitly defines gradients through the ILP black box (Paulus et al. 2021) - this trains extremely slowly, owing to a call to the underlying ILP solver for every training data point in a minibatch. In response, we present an alternative training strategy that is solver-free, i.e., does not call the ILP solver at all at training time. Neural ILP has a set of trainable hyperplanes (for cost and constraints in ILP), together representing a polyhedron. Our key idea is that the training loss should impose that the final polyhedron separates the positives (all constraints satisfied) from the negatives (at least one violated constraint or a suboptimal cost value), via a soft-margin formulation. While positive example(s) are provided as part of the training data, we devise novel techniques for generating negative samples. Our solution is flexible enough to handle equality as well as inequality constraints. Experiments on several problems, both perceptual as well as symbolic, which require learning the constraints of an ILP, show that our approach has superior performance and scales much better compared to purely neural baselines and other state-of-the-art models that require solver-based training. In particular, we are able to obtain excellent performance in 9 x 9 symbolic and visual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Relational MDPs (RMDPs) compactly represent an infinite set of MDPs with an unbounded number of objects. Solving an RMDP requires a generalized policy that applies to all instances of a domain. Recently, Garg et al. proposed SymNet for this task–it constructs a graph neural network that shares parameters across all instances in a domain, thus making it applicable to any instance in a zero-shot manner. Our analysis of SymNet reveals that it performs no better than random on 1/4th of planning competition domains. The key reasons are its design choices: it misses important information during graph construction, leading to (1) poor generalizability, and (2) potential non-identifiability of different actions. In response, our solution, SymNet2. 0, substantially augments SymNet’s graph construction approach by introducing additional nodes and edges which allow a better transfer of important information about a domain. It also improves SymNet’s action decoders with relevant information from objects to make different actions identifiable during scoring. Extensive experiments on twelve competition domains, where we use imitation learning over data generated from the PROST planner, demonstrate that SymNet2. 0 performs vastly better than SymNet. Interestingly, even though SymNet2. 0 is trained over data from PROST, it outperforms the planner on several test instances due to former’s ability to scale to large instances in a zero-shot manner.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:tS2w5q8j5-wC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Recently many neural models have been proposed to solve combinatorial puzzles by implicitly learning underlying constraints using their solved instances, such as sudoku or graph coloring (GCP). One drawback of the proposed architectures, which are often based on Graph Neural Networks (GNN), is that they cannot generalize across the size of the output space from which variables are assigned a value, for example, set of colors in a GCP, or board-size in sudoku. We call the output space for the variables as 'value-set'. While many works have demonstrated generalization of GNNs across graph size, there has been no study on how to design a GNN for achieving value-set invariance for problems that come from the same domain. For example, learning to solve 16 x 16 sudoku after being trained on only 9 x 9 sudokus. In this work, we propose novel methods to extend GNN based architectures to achieve value-set invariance. Specifically, our model builds on recently proposed Recurrent Relational Networks. Our first approach exploits the graph-size invariance of GNNs by converting a multi-class node classification problem into a binary node classification problem. Our second approach works directly with multiple classes by adding multiple nodes corresponding to the values in the value-set, and then connecting variable nodes to value nodes depending on the problem initialization. Our experimental evaluation on three different combinatorial problems demonstrates that both our models perform well on our novel problem, compared to a generic neural reasoner. Between two of our models, we observe an inherent trade-off: while the binarized …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:08ZZubdj9fEC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"We introduce the novel and challenging task of answering Points-of-interest (POI) recommendation questions, using a collection of reviews that describe candidate answer entities (POIs). We harvest a QA dataset that contains 47,124 paragraph-sized real user questions from travelers seeking POI recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate entities to choose from and each candidate is associated with a collection of unstructured reviews. Questions can include requirements based on physical location, budget, timings as well as other subjective considerations related to ambience, quality of service etc. We find that commonly used neural architectures for QA are prohibitively expensive for reasoning over the large number of candidate answer entities found in our dataset (over 5300 per question on average). Further, commonly used retriever-ranker based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:q3oQSFYPqjQC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Distantly supervised relation extraction (DS-RE) is generally framed as a multi-instance multi-label (MI-ML) task, where the optimal aggregation of information from multiple instances is of key importance. Intra-bag attention (Lin et al., 2016) is an example of a popularly used aggregation scheme for this framework. Apart from this scheme, however, there is not much to choose from in the DS-RE literature as most of the advances in this field are focused on improving the instance-encoding step rather than the instance-aggregation step. With recent works leveraging large pre-trained language models as encoders, the increased capacity of models might allow for more flexibility in the instance-aggregation step. In this work, we explore this hypothesis and come up with a novel aggregation scheme which we call Passage-Att. Under this aggregation scheme, we combine all instances mentioning an entity pair into a ""passage of instances"", which is summarized independently for each relation class. These summaries are used to predict the validity of a potential triple. We show that our Passage-Att with BERT as passage encoder achieves state-of-the-art performance in three different settings (monolingual DS, monolingual DS with manually-annotated test set, multilingual DS).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"We focus on the task of future frame prediction in video governed by underlying physical dynamics. We work with models which are object-centric, i.e., explicitly work with object representations, and propagate a loss in the latent space. Specifically, our research builds on recent work by Kipf et al. \cite{kipf&al20}, which predicts the next state via contrastive learning of object interactions in a latent space using a Graph Neural Network. We argue that injecting explicit inductive bias in the model, in form of general physical laws, can help not only make the model more interpretable, but also improve the overall prediction of model. As a natural by-product, our model can learn feature maps which closely resemble actual object positions in the image, without having any explicit supervision about the object positions at the training time. In comparison with earlier works \cite{jaques&al20}, which assume a complete knowledge of the dynamics governing the motion in the form of a physics engine, we rely only on the knowledge of general physical laws, such as, world consists of objects, which have position and velocity. We propose an additional decoder based loss in the pixel space, imposed in a curriculum manner, to further refine the latent space predictions. Experiments in multiple different settings demonstrate that while Kipf et al. model is effective at capturing object interactions, our model can be significantly more effective at localising objects, resulting in improved performance in 3 out of 4 domains that we experiment with. Additionally, our model can learn highly intrepretable feature maps, resembling actual object positions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:Tiz5es2fbqcC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"We introduce the novel and challenging task of answering Pointsof-interest (POI) recommendation questions, using a collection of reviews that describe candidate answer entities (POIs). We harvest a QA dataset that contains 47,124 paragraph-sized user questions from travelers seeking POI recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate entities to choose from and each candidate is associated with a collection of unstructured reviews. Questions can include requirements based on physical location, budget, timings as well as other subjective considerations related to ambience, quality of service etc. Our dataset requires reasoning over a large number of candidate answer entities (over 5300 per question on average) and we find that running commonly used neural architectures for QA is prohibitively expensive. Further, commonly used retriever-ranker based methods also do not work well for our task due to the nature of review-documents. Thus, as a first attempt at addressing some of the novel challenges of reasoning-at-scale posed by our task, we present a task specific baseline model that uses a three-stage cluster-select-rerank architecture. The model first clusters text for each entity to identify exemplar sentences describing an entity. It then uses a neural information retrieval (IR) module to select a set of potential entities from the large candidate set. A reranker uses a deeper attention-based architecture to pick the best answers from the selected entities. This strategy performs better than a pure retrieval or a pure attention-based reasoning approach yielding nearly 25% relative …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:K3LRdlH-MEoC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Regularized Auto-Encoders (RAEs) form a rich class of neural generative models. They effectively model the joint-distribution between the data and the latent space using an Encoder-Decoder combination, with regularization imposed in terms of a prior over the latent space. Despite their advantages, such as stability in training, the performance of AE based models has not reached the superior standards as that of the other generative models such as Generative Adversarial Networks (GANs). Motivated by this, we examine the effect of the latent prior on the generation quality of deterministic AE models in this paper. Specifically, we consider the class of RAEs with deterministic Encoder-Decoder pairs, Wasserstein Auto-Encoders (WAE), and show that having a fixed prior distribution, \textit{a priori}, oblivious to the dimensionality of the `true' latent space, will lead to the infeasibility of the optimization problem considered. Further, we show that, in the finite data regime, despite knowing the correct latent dimensionality, there exists a bias-variance trade-off with any arbitrary prior imposition. As a remedy to both the issues mentioned above, we introduce an additional state space in the form of flexibly learnable latent priors, in the optimization objective of the WAEs. We implicitly learn the distribution of the latent prior jointly with the AE training, which not only makes the learning objective feasible but also facilitates operation on different points of the bias-variance curve. We show the efficacy of our model, called FlexAE, through several experiments on multiple datasets, and demonstrate that it is the new state-of-the-art for the AE based generative models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:CHSYGLWDkRkC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Symmetry breaking is a popular technique to reduce the search space for SAT solving by exploiting the underlying symmetry over variables and clauses in a formula. The key idea is to first identify sets of assignments which fall in the same symmetry class, and then impose ordering constraints, called Symmetry Breaking Predicates (SBPs), such that only one (or a small subset) of these assignments is allowed to be a solution of the original SAT formula. While this technique has been exploited extensively in the SAT literature, there is little work on using symmetry breaking for SAT Modulo Theories (SMT). In SMT, logical constraints in SAT theories are combined with another set of theory operations defined over non-Boolean variables such as integers, reals, etc. SMT solvers typically use a combination of SAT solving techniques augmented with calls to the theory solver. In this work, we take up the advances in SAT symmetry breaking and apply them to the domain of SMT. Our key technical contribution is the formulation of symmetry breaking over the Boolean skeleton variables, which are placeholders for actual theory operations in SMT solving. These SBPs are then applied over the SAT solving part of the SMT solver. We implement our SBP ideas on top of CVC4, which is a state-of-the-art SMT solver. Our approach can result in significantly faster solutions on several benchmark problems compared to the state-of-the-art. Our final solver is a hybrid of the original CVC4 solver, and an SBP based solver, and can solve up to 3.8% and 3.1% more problems in the QF_NIA category of 2018 and 2019 SMT benchmarks, respectively, compared to CVC4 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:NhqRSupF_l8C,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"The field of neural generative models is dominated by the highly successful Generative Adversarial Networks (GANs) despite their challenges, such as training instability and mode collapse. Auto-Encoders (AE) with regularized latent space provides an alternative framework for generative models, albeit their performance levels have not reached that of GANs. In this work, we identify one of the causes for the under-performance of AE-based models and propose a remedial measure. Specifically, we hypothesise that the dimensionality of the AE model’s latent space has a critical effect on the quality of the generated data. Under the assumption that nature generates data by sampling from a “true” generative latent space followed by a deterministic non-linearity, we show that the optimal performance is obtained when the dimensionality of the latent space of the AE-model matches with that of the “true” generative latent space. Further, we propose an algorithm called the Latent Masked Generative Auto-Encoder (LMGAE), in which the dimensionality of the model’s latent space is brought closer to that of the “true” generative latent space, via a novel procedure to mask the spurious latent dimensions. We demonstrate through experiments on synthetic and several realworld datasets that the proposed formulation yields generation quality that is better than the state-of-the-art AE-based generative models and is comparable to that of GANs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:b0M2c_1WBrUC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"We present CVC4-SymBreak, a derived SMT solver based on CVC4 [1], and a noncompeting participant of SMT-COMP 2019 [13]. Our technique exploits symmetries over the Boolean skeleton variables in an SMT problem to prune the search space. We use an ensemble of a solver with and without symmetries to be more effective. Our approach results in significantly faster solutions on a subset of available SMT benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:pyW8ca7W8N0C,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Auxiliary information can be exploited in machine learning models using the paradigm of evidence based conditional inference. Multi-modal techniques in Deep Neural Networks (DNNs) can be seen as perturbing the latent feature representation for incorporating evidence from the auxiliary modality. However, they require training a specialized network which can map sparse evidence to a high dimensional latent space vector. Designing such a network, as well as collecting jointly labeled data for training is a non-trivial task. In this paper, we present a novel multi-task learning (MTL) based framework to perform evidence based conditional inference in DNNs which can overcome both these shortcomings. Our framework incorporates evidence as the output of secondary task(s), while modeling the original problem as the primary task of interest. During inference, we employ a novel Bayesian formulation to change the joint latent feature representation so as to maximize the probability of the observed evidence. Since our approach models evidence as prediction from a DNN, this can often be achieved using standard pre-trained backbones for popular tasks, eliminating the need for training altogether. Even when training is required, our MTL architecture ensures the same can be done without any need for jointly labeled data. Exploiting evidence using our framework, we show an improvement of 3.9% over the state-of-the-art, for predicting semantic segmentation given the image tags, and 2.8% for predicting instance segmentation given image captions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:1sJd4Hv_s6UC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Combining logic and probability has been a long stand- ing goal of AI research. Markov Logic Networks (MLNs) achieve this by attaching weights to formulas in first-order logic, and can be seen as templates for constructing features for ground Markov networks. Most techniques for learning weights of MLNs are domain-size agnostic, i.e., the size of the domain is not explicitly taken into account while learn- ing the parameters of the model. This often results in ex- treme probabilities when testing on domain sizes different from those seen during training. In this paper, we propose Domain Aware Markov logic Networks (DA-MLNs) which present a principled solution to this problem. While defin- ing the ground network distribution, DA-MLNs divide the ground feature weight by a scaling factor which is a function of the number of connections the ground atoms appearing in the feature are involved in. We show that standard MLNs fall out as a special case of our formalism when this func- tion evaluates to a constant equal to 1. Experiments on the benchmark Friends & Smokers domain show that our ap- proach results in significantly higher accuracies compared to existing methods when testing on domains whose sizes different from those seen during training.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:3s1wT3WcHBgC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"Higher order MRF-MAP formulation has been shown to improve solutions in many popular computer vision problems. Most of these approaches have considered hand tuned clique potentials only. Over the last few years, while there has been steady improvement in inference techniques making it possible to perform tractable inference for clique sizes even up to few hundreds, the learning techniques for such clique potentials have been limited to clique size of merely 3 or 4. In this paper, we investigate learning of higher order clique potentials up to clique size of 16. We use structural support vector machine (SSVM), a large-margin learning framework, to learn higher order potential functions from data. It formulates the training problem as a quadratic programming problem (QP) that requires solving MAP inference problems in the inner iteration. We introduce multiple innovations in the formulation by introducing soft …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:pqnbT2bcN3wC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",24,"We introduce the first system towards the novel task of answering complex multisentence recommendation questions in the tourism domain. Our solution uses a pipeline of two modules: question understanding and answering. For question understanding, we define an SQL-like query language that captures the semantic intent of a question; it supports operators like subset, negation, preference and similarity, which are often found in recommendation questions. We train and compare traditional CRFs as well as bidirectional LSTM-based models for converting a question to its semantic representation. We extend these models to a semisupervised setting with partially labeled sequences gathered through crowdsourcing. We find that our best model performs semi-supervised training of BiDiLSTM+CRF with hand-designed features and CCM(Chang et al., 2007) constraints. Finally, in an end to end QA system, our answering component converts our question representation into queries fired on underlying knowledge sources. Our experiments on two different answer corpora demonstrate that our system can significantly outperform baselines with up to 20 pt higher accuracy and 17 pt higher recall.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&citation_for_view=V49BsgMAAAAJ:2P1L_qKh6hAC,http://www.cse.iitd.ac.in/~parags
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"We develop CALM, a coordination analyzer that improves upon the conjuncts identified from dependency parses. It uses a language model based scoring and several linguistic constraints to search over hierarchical conjunct boundaries (for nested coordination). By splitting a conjunctive sentence around these conjuncts, CALM outputs several simple sentences. We demonstrate the value of our coordination analyzer in the end task of Open Information Extraction (Open IE). State-of-the-art Open IE systems lose substantial yield due to ineffective processing of conjunctive sentences. Our Open IE system, CALMIE, performs extraction over the simple sentences identified by CALM to obtain up to 1.8 x yield with a moderate increase in precision compared to extractions from original sentences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:owLR8QvbtFgC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"For several problems of interest, there are natural constraints which exist over the output label space. For example, for the joint task of NER and POS labeling, these constraints might specify that the NER label ‘organization’is consistent only with the POS labels ‘noun’and ‘preposition’. These constraints can be a great way of injecting prior knowledge into a deep learning model, thereby improving overall performance. In this paper, we present a constrained optimization formulation for training a deep network with a given set of hard constraints on output labels. Our novel approach first converts the label constraints into soft logic constraints over probability distributions outputted by the network. It then converts the constrained optimization problem into an alternating min-max optimization with Lagrangian variables defined for each constraint. Since the constraints are independent of the target labels, our framework easily generalizes to semi-supervised setting. We experiment on the tasks of Semantic Role Labeling (SRL), Named Entity Recognition (NER) tagging, and fine-grained entity typing and show that our constraints not only significantly reduce the number of constraint violations, but can also result in state-of-the-art performance",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:2v_ZtQDX9iAC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"A recent state-of-the-art neural open information extraction (OpenIE) system generates extractions iteratively, requiring repeated encoding of partial outputs. This comes at a significant computational cost. On the other hand, sequence labeling approaches for OpenIE are much faster, but worse in extraction quality. In this paper, we bridge this trade-off by presenting an iterative labeling-based system that establishes a new state of the art for OpenIE, while extracting 10x faster. This is achieved through a novel Iterative Grid Labeling (IGL) architecture, which treats OpenIE as a 2-D grid labeling task. We improve its performance further by applying coverage (soft) constraints on the grid at training time. Moreover, on observing that the best OpenIE systems falter at handling coordination structures, our OpenIE system also incorporates a new coordination analyzer built with the same IGL architecture. This IGL based coordination analyzer helps our OpenIE system handle complicated coordination structures, while also establishing a new state of the art on the task of coordination analysis, with a 12.3 pts improvement in F1 over previous analyzers. Our OpenIE system, OpenIE6, beats the previous systems by as much as 4 pts in F1, while being much faster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:TaaCk18tZOkC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"While traditional systems for Open Information Extraction were statistical and rule-based, recently neural models have been introduced for the task. Our work builds upon CopyAttention, a sequence generation OpenIE model (Cui et. al., 2018). Our analysis reveals that CopyAttention produces a constant number of extractions per sentence, and its extracted tuples often express redundant information. We present IMoJIE, an extension to CopyAttention, which produces the next extraction conditioned on all previously extracted tuples. This approach overcomes both shortcomings of CopyAttention, resulting in a variable number of diverse extractions per sentence. We train IMoJIE on training data bootstrapped from extractions of several non-neural systems, which have been automatically filtered to reduce redundancy and noise. IMoJIE outperforms CopyAttention by about 18 F1 pts, and a BERT-based strong baseline by 2 F1 pts, establishing a new state of the art for the task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:jtI9f0ekYq0C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Open Information Extraction (Open IE) systems have been traditionally evaluated via manual annotation. Recently, an automated evaluator with a benchmark dataset (OIE2016) was released–it scores Open IE systems automatically by matching system predictions with predictions in the benchmark dataset. Unfortunately, our analysis reveals that its data is rather noisy, and the tuple matching in the evaluator has issues, making the results of automated comparisons less trustworthy. We contribute CaRB, an improved dataset and framework for testing Open IE systems. To the best of our knowledge, CaRB is the first crowdsourced Open IE dataset and it also makes substantive changes in the matching code and metrics. NLP experts annotate CaRB’s dataset to be more accurate than OIE2016. Moreover, we find that on one pair of Open IE systems, CaRB framework provides contradictory results to OIE2016. Human assessment verifies that CaRB’s ranking of the two systems is the accurate ranking. We release the CaRB framework along with its crowdsourced dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:DyXnQzXoVgIC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"State-of-the-art knowledge base completion (KBC) models predict a score for every known or unknown fact via a latent factorization over entity and relation embeddings. We observe that when they fail, they often make entity predictions that are incompatible with the type required by the relation. In response, we enhance each base factorization with two type-compatibility terms between entity-relation pairs, and combine the signals in a novel manner. Without explicit supervision from a type catalog, our proposed modification obtains up to 7% MRR gains over base models, and new state-of-the-art results on several datasets. Further analysis reveals that our models better represent the latent types of entities and their embeddings also predict supervised types better than the embeddings fitted by baseline models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:jFemdcug13IC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Temporal knowledge bases associate relational (s,r,o) triples with a set of times (or a single time instant) when the relation is valid. While time-agnostic KB completion (KBC) has witnessed significant research, temporal KB completion (TKBC) is in its early days. In this paper, we consider predicting missing entities (link prediction) and missing time intervals (time prediction) as joint TKBC tasks where entities, relations, and time are all embedded in a uniform, compatible space. We present TIMEPLEX, a novel time-aware KBC method, that also automatically exploits the recurrent nature of some relations and temporal interactions between pairs of relations. TIMEPLEX achieves state-of-the-art performance on both prediction tasks. We also find that existing TKBC models heavily overestimate link prediction performance due to imperfect evaluation mechanisms. In response, we propose improved TKBC evaluation protocols for both link and time prediction tasks, dealing with subtle issues that arise from the partial overlap of time intervals in gold instances and system predictions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:QsKbpXNoaWkC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Neural planners for RDDL MDPs produce deep reactive policies in an offline fashion. These scale well with large domains, but are sample inefficient and time-consuming to train from scratch for each new problem. To mitigate this, recent work has studied neural transfer learning, so that a generic planner trained on other problems of the same domain can rapidly transfer to a new problem. However, this approach only transfers across problems of the same size. We present the first method for neural transfer of RDDL MDPs that can transfer across problems of different sizes. Our architecture has two key innovations to achieve size independence:(1) a state encoder, which outputs a fixed length state embedding by max pooling over varying number of object embeddings,(2) a single parameter-tied action decoder that projects object embeddings into action probabilities for the final policy. On the three challenging RDDL domains of SysAdmin, Game Of Life and Academic Advising, our approach powerfully transfers across problem sizes and has superior learning curves over training from scratch.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:D_tqNUsBuKoC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"The Knowledge Base (KB) used for real-world applications, such as booking a movie or restaurant reservation, keeps changing over time. End-to-end neural networks trained for these task-oriented dialogs are expected to be immune to any changes in the KB. However, existing approaches breakdown when asked to handle such changes. We propose an encoder-decoder architecture (BoSsNet) with a novel Bag-of-Sequences (BoSs) memory, which facilitates the disentangled learning of the response's language model and its knowledge incorporation. Consequently, the KB can be modified with new knowledge without a drop in interpretability. We find that BoSsNet outperforms state-of-the-art models, with considerable improvements (> 10\%) on bAbI OOV test sets and other human-human datasets. We also systematically modify existing datasets to measure disentanglement and show BoSsNet to be robust to KB modifications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:65Yg0jNCQDAC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Machine learning in real-world high-skew domains is difficult, because traditional strategies for crowdsourcing labeled training examples are ineffective at locating the scarce minority-class examples. For example, both random sampling and traditional active learning (which reduces to random sampling when just starting) will most likely recover very few minority-class examples. To bootstrap the machine learning process, researchers have proposed tasking the crowd with finding or generating minority-class examples, but such strategies have their weaknesses as well. They are unnecessarily expensive in well-balanced domains, and they often yield samples from a biased distribution that is unrepresentative of the one being learned. This paper extends the traditional active learning framework by investigating the problem of intelligently switching between various crowdsourcing strategies for obtaining labeled training examples in order to optimally train a classifier. We start by analyzing several such strategies (eg, annotate an example, generate a minority-class example, etc.), and then develop a novel, skew-robust algorithm, called MB-CB, for the control problem. Experiments show that our method outperforms state-of-the-art GL-Hybrid by up to 14.3 points in F1 AUC, across various domains and class-frequency settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:CdxZDUztZiMC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"While crowdsourcing enables data collection at scale, ensuring high-quality data remains a challenge. In particular, effective task design underlies nearly every reported crowdsourcing success, yet remains difficult to accomplish. Task design is hard because it involves a costly iterative process: identifying the kind of work output one wants, conveying this information to workers, observing worker performance, understanding what remains ambiguous, revising the instructions, and repeating the process until the resulting output is satisfactory. To facilitate this process, we propose a novel meta-workflow that helps requesters optimize crowdsourcing task designs and Sprout, our open-source tool, which implements this workflow. Sprout improves task designs by (1) eliciting points of confusion from crowd workers, (2) enabling requesters to quickly understand these misconceptions and the overall space of questions, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:-7ulzOJl1JYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"A Relational Markov Decision Process (RMDP) is a first-order representation to express all instances of a single probabilistic planning domain with possibly unbounded number of objects. Early work in RMDPs outputs generalized (instance-independent) first-order policies or value functions as a means to solve all instances of a domain at once. Unfortunately, this line of work met with limited success due to inherent limitations of the representation space used in such policies or value functions. Can neural models provide the missing link by easily representing more complex generalized policies, thus making them effective on all instances of a given domain? We present SymNet, the first neural approach for solving RMDPs that are expressed in the probabilistic planning language of RDDL. SymNet trains a set of shared parameters for an RDDL domain using training instances from that domain. For each instance, SymNet first converts it to an instance graph and then uses relational neural models to compute node embeddings. It then scores each ground action as a function over the first-order action symbols and node embeddings related to the action. Given a new test instance from the same domain, SymNet architecture with pre-trained parameters scores each ground action and chooses the best action. This can be accomplished in a single forward pass without any retraining on the test instance, thus implicitly representing a neural generalized policy for the whole domain. Our experiments on nine RDDL domains from IPPC demonstrate that SymNet policies are significantly better than random and sometimes even more effective than training a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:37UQlXuwjP4C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"State-of-the-art models for multi-hop question answering typically augment large-scale language models like BERT with additional, intuitively useful capabilities such as named entity recognition, graph-based reasoning, and question decomposition. However, does their strong performance on popular multi-hop datasets really justify this added design complexity? Our results suggest that the answer may be no, because even our simple pipeline based on BERT, named Quark, performs surprisingly well. Specifically, on HotpotQA, Quark outperforms these models on both question answering and support identification (and achieves performance very close to a RoBERTa model). Our pipeline has three steps: 1) use BERT to identify potentially relevant sentences independently of each other; 2) feed the set of selected sentences as context into a standard BERT span prediction model to choose an answer; and 3) use the sentence selection model, now with the chosen answer, to produce supporting sentences. The strong performance of Quark resurfaces the importance of carefully exploring simple model designs before using popular benchmarks to justify the value of complex techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:Vr2j17o0sqMC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Domain-independent probabilistic planners input an MDP description in a factored representation language such as PPDDL or RDDL, and exploit the specifics of the representation for faster planning. Traditional algorithms operate on each problem instance independently, and good methods for transferring experience from policies of other instances of a domain to a new instance do not exist. Recently, researchers have begun exploring the use of deep reactive policies, trained via deep reinforcement learning (RL), for MDP planning domains. One advantage of deep reactive policies is that they are more amenable to transfer learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:OBSaB-F7qqsC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"A large amount of materials science knowledge is generated and stored as text published in peer-reviewed scientific literature. While recent developments in natural language processing, such as Bidirectional Encoder Representations from Transformers (BERT) models, provide promising information extraction tools, these models may yield suboptimal results when applied on materials domain since they are not trained in materials science specific notations and jargons. Here, we present a materials-aware language model, namely, MatSciBERT, trained on a large corpus of peer-reviewed materials science publications. We show that MatSciBERT outperforms SciBERT, a language model trained on science corpus, and establish state-of-the-art results on three downstream tasks, named entity recognition, relation classification, and abstract classification. We make the pre-trained weights of MatSciBERT publicly …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:KTwcwpFFj4wC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"We observe that end-to-end memory networks (MN) trained for task-oriented dialogue, such as for recommending restaurants to a user, suffer from an out-ofvocabulary (OOV) problem–the entities returned by the Knowledge Base (KB) may not be seen by the network at training time, making it impossible for it to use them in dialogue. We propose a Hierarchical Pointer Memory Network (HyP-MN), in which the next word may be generated from the decode vocabulary or copied from a hierarchical memory maintaining KB results and previous utterances. Evaluating over the dialog bAbI tasks, we find that HyP-MN drastically outperforms MN obtaining 12% overall accuracy gains. Further analysis reveals that MN fails completely in recommending any relevant restaurant, whereas HyP-MN recommends the best next restaurant 80% of the time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:wKETBy42zhYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Knowledge Base Completion (KBC) has been a very active area lately. Several recent KBCpapers propose architectural changes, new training methods, or even new formulations. KBC systems are usually evaluated on standard benchmark datasets: FB15k, FB15k-237, WN18, WN18RR, and Yago3-10. Most existing methods train with a small number of negative samples for each positive instance in these datasets to save computational costs. This paper discusses how recent developments allow us to use all available negative samples for training. We show that Complex, when trained using all available negative samples, gives near state-of-the-art performance on all the datasets. We call this approach COMPLEX-V2. We also highlight how various multiplicative KBC methods, recently proposed in the literature, benefit from this train-ing regime and become indistinguishable in terms of performance on most datasets. Our work calls for a reassessment of their individual value, in light of these findings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:c1e4I3QdEKYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"We present the novel task of understanding multi-sentence entity-seeking questions (MSEQs), that is, the questions that may be expressed in multiple sentences, and that expect one or more entities as an answer. We formulate the problem of understanding MSEQs as a semantic labeling task over an open representation that makes minimal assumptions about schema or ontology-specific semantic vocabulary. At the core of our model, we use a BiLSTM (bidirectional LSTM) conditional random field (CRF), and to overcome the challenges of operating with low training data, we supplement it by using BERT embeddings, hand-designed features, as well as hard and soft constraints spanning multiple sentences. We find that this results in a 12–15 points gain over a vanilla BiLSTM CRF. We demonstrate the strengths of our work using the novel task of answering real-world entity-seeking questions from the tourism …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:z6xuaG2dYH0C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Knowledge Graph Completion (KGC) predicts missing facts in an incomplete Knowledge Graph. Almost all of existing KGC research is applicable to only one KG at a time, and in one language only. However, different language speakers may maintain separate KGs in their language and no individual KG is expected to be complete. Moreover, common entities or relations in these KGs have different surface forms and IDs, leading to ID proliferation. Entity alignment (EA) and relation alignment (RA) tasks resolve this by recognizing pairs of entity (relation) IDs in different KGs that represent the same entity (relation). This can further help prediction of missing facts, since knowledge from one KG is likely to benefit completion of another. High confidence predictions may also add valuable information for the alignment tasks. In response, we study the novel task of jointly training multilingual KGC, relation alignment and entity alignment models. We present ALIGNKGC, which uses some seed alignments to jointly optimize all three of KGC, EA and RA losses. A key component of ALIGNKGC is an embedding based soft notion of asymmetric overlap defined on the (subject, object) set signatures of relations this aids in better predicting relations that are equivalent to or implied by other relations. Extensive experiments with DBPedia in five languages establish the benefits of joint training for all tasks, achieving 10-32 MRR improvements of ALIGNKGC over a strong state-of-the-art single-KGC system completion model over each monolingual KG . Further, ALIGNKGC achieves reasonable gains in EA and RA tasks over a vanilla completion model over a KG that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:KI9T_ytC6pkC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Progress with supervised Open Information Extraction (OpenIE) has been primarily limited to English due to the scarcity of training data in other languages. In this paper, we explore techniques to automatically convert English text for training OpenIE systems in other languages. We introduce the Alignment-Augmented Constrained Translation (AACTrans) model to translate English sentences and their corresponding extractions consistently with each other—with no changes to vocabulary or semantic meaning which may result from independent translations. Using the data generated with AACTrans, we train a novel two-stage generative OpenIE model, which we call Gen2OIE, that outputs for each sentence: 1) relations in the first stage and 2) all extractions containing the relation in the second stage. Gen2OIE increases relation coverage using a training data transformation technique that is generalizable to multiple languages, in contrast to existing models that use an English-specific training loss. Evaluations on 5 languages—Spanish, Portuguese, Chinese, Hindi and Telugu—show that the Gen2OIE with AACTrans data outperforms prior systems by a margin of 6-25% in F1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:wyM6WWKXmoIC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Our goal is to answer real-world tourism questions that seek Points-of-Interest (POI) recommendations. Such questions express various kinds of spatial and non-spatial constraints, necessitating a combination of textual and spatial reasoning. In response, we develop the first joint spatio-textual reasoning model, which combines geo-spatial knowledge with information in textual corpora to answer questions. We first develop a modular spatial-reasoning network that uses geo-coordinates of location names mentioned in a question, and of candidate answer POIs, to reason over only spatial constraints. We then combine our spatial-reasoner with a textual reasoner in a joint model and present experiments on a real world POI recommendation task. We report substantial improvements over existing models without joint spatio-textual reasoning. To the best of our knowledge, we are the first to develop a joint QA model that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:_AeoHAGD03cC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"This paper studies a novel reviewer-paper matching approach that was recently deployed in the 35th AAAI Conference on Artificial Intelligence (AAAI 2021), and has since been adopted by other conferences including AAAI 2022 and ICML 2022. This approach has three main elements: (1) collecting and processing input data to identify problematic matches and generate reviewer-paper scores; (2) formulating and solving an optimization problem to find good reviewer-paper matchings; and (3) the introduction of a novel, two-phase reviewing process that shifted reviewing resources away from papers likely to be rejected and towards papers closer to the decision boundary. This paper also describes an evaluation of these innovations based on an extensive post-hoc analysis on real data -- including a comparison with the matching algorithm used in AAAI's previous (2020) iteration -- and supplements this with additional numerical experimentation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:xGWFX6Gbr9MC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Robots assisting us in factories or homes must learn to make use of objects as tools to perform tasks, e.g., a tray for carrying objects. We consider the problem of learning commonsense knowledge of when a tool may be useful and how its use may be composed with other tools to accomplish a high-level task instructed by a human. We introduce a novel neural model, termed TANGO, for predicting task-specific tool interactions, trained using demonstrations from human teachers instructing a virtual robot. TANGO encodes the world state, comprising objects and symbolic relationships between them, using a graph neural network. The model learns to attend over the scene using knowledge of the goal and the action history, finally decoding the symbolic action to execute. Crucially, we address generalization to unseen environments where some known tools are missing, but alternative unseen tools are present. We show that by augmenting the representation of the environment with pre-trained embeddings derived from a knowledge-base, the model can generalize effectively to novel environments. Experimental results show a 60.5-78.9% absolute improvement over the baseline in predicting successful symbolic plans in unseen settings for a simulated mobile manipulator.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:wSy_KLzO7YEC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any one of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks, demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:xyvS_IvSCKsC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"State-of-the-art models for Knowledge Base Completion (KBC) are based on tensor factorization (TF), e.g, DistMult, ComplEx. While they produce good results, they cannot expose any rationale behind their predictions, potentially reducing the trust of a user in the model. Previous works have explored creating an inherently explainable model, e.g. Neural Theorem Proving (NTP), DeepPath, MINERVA, but explainability comes at the cost of performance. Others have tried to create an auxiliary explainable model having high fidelity with the underlying TF model, but unfortunately, they do not scale on large KBs such as FB15k and YAGO. In this work, we propose OxKBC -- an Outcome eXplanation engine for KBC, which provides a post-hoc explanation for every triple inferred by an (uninterpretable) factorization based model. It first augments the underlying Knowledge Graph by introducing weighted edges between entities based on their similarity given by the underlying model. In the augmented graph, it defines a notion of human-understandable explanation paths along with a language to generate them. Depending on the edges, the paths are aggregated into second-order templates for further selection. The best template with its grounding is then selected by a neural selection module that is trained with minimal supervision by a novel loss function. Experiments over Mechanical Turk demonstrate that users find our explanations more trustworthy compared to rule mining.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:LGlY6t8CeOMC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"End-to-End task-oriented dialogue systems generate responses based on dialog history and an accompanying knowledge base (KB). Inferring those KB entities that are most relevant for an utterance is crucial for response generation. Existing state of the art scales to large KBs by softly filtering over irrelevant KB information. In this paper, we propose a novel filtering technique that consists of (1) a pairwise similarity based filter that identifies relevant information by respecting the n-ary structure in a KB record. and, (2) an auxiliary loss that helps in separating contextually unrelated KB information. We also propose a new metric -- multiset entity F1 which fixes a correctness issue in the existing entity F1 metric. Experimental results on three publicly available task-oriented dialog datasets show that our proposed approach outperforms existing state-of-the-art models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:PQEM9vzQD9gC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",46,"We propose a novel problem within end-to-end learning of task-oriented dialogs (TOD), in which the dialog system mimics a troubleshooting agent who helps a user by diagnosing their problem (e.g., car not starting). Such dialogs are grounded in domain-specific flowcharts, which the agent is supposed to follow during the conversation. Our task exposes novel technical challenges for neural TOD, such as grounding an utterance to the flowchart without explicit annotation, referring to additional manual pages when user asks a clarification question, and ability to follow unseen flowcharts at test time. We release a dataset (FloDial) consisting of 2,738 dialogs grounded on 12 different troubleshooting flowcharts. We also design a neural model, FloNet, which uses a retrieval-augmented generation architecture to train the dialog agent. Our experiments find that FloNet can do zero-shot transfer to unseen flowcharts, and sets a strong baseline for future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&citation_for_view=5y4YmFcAAAAJ:V_vSwabWVtYC,http://www.cse.iitd.ac.in/~mausam
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"We present a System Dynamics (SD) model of the Covid-19 pandemic spread in India. The detailed age-structured compartment-based model endogenously captures various disease transmission pathways, expanding significantly from the standard SEIR model. The model is customized for India by using the appropriate population pyramid, contact rate matrices, external arrivals (as per actual data), and a few other calibrated fractions based on the reported cases of Covid-19 in India. Also, we have explicitly modeled, using independent time-variant levers, the effects of testing, contact tracing, isolating Covid-positive patients, quarantining, use of mask/better hygiene practices, social distancing through contact rate reductions at distinct zones of home(H), work(W), school(S) and other(O) locations. Simulation results show that, even after an extended lock-down, some non-trivial number of infections (even asymptomatic) will be left and the pandemic will resurface. Only tools that work against the pandemic is high rate of testing of those who show Covid-19 like symptoms, isolating them if they are positive and contact tracing all contacts of positive patients and quarantining them, in combination with use of face masks and personal hygiene. A wide range of combination of effectiveness of contact tracing, isolation, quarantining and personal hygiene measures help minimize the pandemic impact and some imperfections in implementation of one measure can be compensated by better implementation of other measures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&citation_for_view=oEuni4IAAAAJ:hMod-77fHWUC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"A holistic set of indicators using a stock and flow framework is used to assess farming practices across socio-economic and ecological dimensions. We design a methodology to estimate, normalize, and aggregate the indicators to form composite indices. The indicators under each dimension are aggregated using the progressive weighted average to give three-dimensional indices viz. economic, social, and ecological indices, which are aggregated to give a single holistic index called Farm Assessment Index (FAI). Unlike other approaches where the comparison of farming system is restricted within the sample under study, normalization of indicators using regional averages makes the FAI suitable for universal comparisons of farming systems across crops and regions. The methodology was applied to evaluate farming practices of 60 organic and 60 conventional farmers, from two Indian states over three years. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:NMxIlDl6LWMC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"Sustainable intensification (SI) of agriculture combines the dual goals of increasing productivity while staying within safe limits of resource use. In practice, how can thresholds which operate at resource scale guide intensification driven by social, economic and biophysical factors at the farm scale? In this paper, we present the case of agricultural intensification in the shallow hard-rock aquifer region of western India to illustrate how cross-scale feedback effects are crucial determinants of not only the resource sustainability and farm productivity but also of social dimensions of SI such as equity and justice. Supported by private investment in plastic-lined farm-ponds, the increasing shift to horticulture in the study area raises questions about the sustainability of the practice. We use a socio-hydrological lens and develop a system dynamics model to analyze how the growing technology-mediated intensification may lead …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:RGFaLdJalmkC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"Government bodies responsible for drinking water distribution in India face the challenging task of designing schemes that provide a quality of service that is adequate to meet the needs of citizens at a cost below the strict government norms. Engineers at these government bodies must undertake the design process using tools that are not optimal and consider only pipe diameter selection, which is only one component of the entire scheme design. As such, much of the design process is undertaken in an ad hoc and heuristic manner, relying on the experience and intuition of the engineers. We developed JalTantra, a web system that aids these government engineers in sizing both pipe diameters and the various other water network components, such as tanks, pumps, and valves. We use an integer linear program model, which allows us to solve the problem optimally and quickly.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:M3NEmzRMIkIC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"Minor irrigation structures such as well and farm ponds play very important roles in agriculture growth in developing countries. Typically, a minor irrigation census is conducted every five years to take inventory of these structures. It is essential that an up to date database of these structures be maintained for planning and policy formulation purposes. In this work, we present the design and implementation of an online system for the automatic detection of irrigation structures from satellite images. Our system is built using three popular object detection architectures-YOLO, FasterRCNN and RetinaNet. Our system takes input at multiple resolutions and fragments and reassembles the input region to perform object detection. Since currently there exists no dataset for farm pond and the only publicly available well dataset covers a small geographical region, we have prepared object detection datasets for farm ponds and wells using Google Maps satellite images. We compare the performance of a number of state of the art object detection models and find that a clear trade-off exists between the detection accuracy and inference time with the RetinaNet providing a golden mean.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:GnPB-g6toBAC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"Deep learning has led to many recent advances in object detection and instance segmentation, among other computer vision tasks. These advancements have led to wide application of deep learning based methods and related methodologies in object detection tasks for satellite imagery. In this paper, we introduce MIS Check-Dam, a new dataset of check-dams from satellite imagery for building an automated system for the detection and mapping of check-dams, focusing on the importance of irrigation structures used for agriculture. We review some of the most recent object detection and instance segmentation methods and assess their performance on our new dataset. We evaluate several single stage, two-stage and attention based methods under various network configurations and backbone architectures. The dataset and the pre-trained models are available at https://www.cse.iitb.ac.in/gramdrishti/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:ns9cj8rnVeAC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"The design of rural drinking water schemes consists of optimization of several network components like pipes, tanks, pumps and valves. The sizing and configuration of these network configurations need to be such that the water requirements are met while at the same time being cost efficient so as to be within government norms. We developed the JalTantra system to design such water distribution networks. The Integer Linear Program (ILP) model used in JalTantra and described in our previous work solved the problem optimally, but took a significant amount of time for larger networks—an hour for a network with 100 nodes. In this current work, we describe a series of three improvements of the model. We prove that these improvements result in tighter models, i.e. the set of points of linear relaxation is strictly smaller than the linear relaxation for the initial model. We test the series of three improved models along …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:bEWYMUwI8FkC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"The Government of India conducts a well census every five years. It is time-consuming, costly, and usually incomplete. By using transfer learning-based object detection algorithms, we have built a system for the automatic detection of wells in satellite images. We analyze the performance of three object detection algorithms-Convolutional Neural Network, HaarCascade, and Histogram of Oriented Gradients on the task of well detection and find that the Convolutional Neural Network based YOLOv2 performs best and forms the core of our system. Our current system has a precision value of 0.95 and a recall value of 0.91 on our dataset. The main contribution of our work is to create a novel open-source system for well detection in satellite images and create an associated dataset which will be put in the public domain. A related contribution is the development of a general purpose satellite image annotation system to annotate and validate objects in satellite images. While our focus is on well detection, the system is general purpose and can be used for detection of other objects as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:YFjsv_pBGBYC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"Change detection for aerial imagery involves locating and identifying changes associated with the areas of interest between co-registered bi-temporal or multi-temporal images of a geographical location. Farm ponds are man-made structures belonging to the category of minor irrigation structures used to collect surface run-off water for future irrigation purposes. Detection of farm ponds from aerial imagery and their evolution over time helps in land surveying to analyze the agricultural shifts, policy implementation, seasonal effects and climate changes. In this paper, we introduce a publicly available object detection and instance segmentation (OD/IS) dataset for localizing farm ponds from aerial imagery. We also collected and annotated the bi-temporal data over a time-span of 14 years across 17 villages, resulting in a binary change detection dataset called \textbf{F}arm \textbf{P}ond \textbf{C}hange \textbf{D}etection Dataset (\textbf{FPCD}). We have benchmarked and analyzed the performance of various object detection and instance segmentation methods on our OD/IS dataset and the change detection methods over the FPCD dataset. The datasets are publicly accessible at this page: \textit{\url{https://huggingface.co/datasets/ctundia/FPCD}}",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:70eg2SAEIzsC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"Existing techniques for the cost optimization of water distribution networks either employ meta-heuristics, or try to develop problem-specific optimization techniques. Instead, we exploit recent advances in generic NLP solvers and explore a rich set of model refinement techniques. The networks that we study contain a single source and multiple demand nodes with residual pressure constraints. Indeterminism of flow values and flow direction in the network leads to non-linearity in these constraints making the optimization problem non-convex. While the physical network is cyclic, flow through the network is necessarily acyclic and thus enforces an acyclic orientation. We devise different strategies of finding acyclic orientations and explore the benefit of enforcing such orientations explicitly as a constraint. Finally, we propose a parallel link formulation that models flow in each link as two separate flows with opposing directions. This allows us to tackle numerical difficulties in optimization when flow in a link is near zero. We find that all our proposed formulations give results at par with least cost solutions obtained in the literature on benchmark networks. We also introduce a suite of large test networks since existing benchmark networks are small in size, and find that the parallel link approach outperforms all other approaches on these bigger networks, resulting in a more tractable technique of cost optimization.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:O3NaXMp0MMsC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",18,"A national identity scheme has long-term and large-scale implications to the welfare of the people, efficiency of governance and law enforcement, individuals’ fundamental right to privacy and national security. Motivated by several issues surfaced by the implementation of Aadhaar, and several privacy and security concerns that have been pointed out, we develop a (non-exhaustive) list of technical guidelines for national identity schemes. We observe that the current Aadhaar design significantly deviates from these guidelines, strongly suggesting that to address the root causes of the issues that have manifested so far, many parts of the system require major redesign. We also put forth several policy guidelines, which we believe are crucial to the success of a national identity scheme in India.
Digital technology is a powerful tool, and India, like any other modern nation, can ill afford to keep away from exploiting the promises it offers. Yet, one needs to wield this technology with caution, like a scalpel rather than a sledge hammer, especially when it is applied at a national scale and affects millions of the poorest and most vulnerable. One should also bear in mind that any cyber infrastructure that is being developed today will become targets for cyber warfare in the future.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&cstart=20&pagesize=80&citation_for_view=oEuni4IAAAAJ:blknAaTinKkC,https://www.cse.iitb.ac.in/~damani/
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"Sketching is one of the most natural ways for representing any object pictorially. It is however, challenging to convert sketches to 3D content that is suitable for various applications like movies, games and computer aided design. With the advent of more accessible Virtual Reality (VR) and Augmented Reality (AR) technologies, sketching can potentially become a more powerful yet easy‐to‐use modality for content creation. In this state‐of‐the‐art report, we aim to present a comprehensive overview of techniques related to sketch based content creation, both on the desktop and in VR/AR. We discuss various basic concepts related to static and dynamic content creation using sketches. We provide a structured review of various aspects of content creation including model generation, coloring and texturing, and finally animation. We try to motivate the advantages that VR/AR based sketching techniques and systems can …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&citation_for_view=kOkSgaMAAAAJ:r0BpntZqJG4C,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"We work on the problem of recognizing license plates and street signs automatically in challenging conditions such as chaotic traffic. We leverage state-of-the-art text spotters to generate a large amount of noisy labeled training data. The data is filtered using a pattern derived from domain knowledge. We augment training and testing data with interpolated boxes and annotations that makes our training and testing robust. We further use synthetic data during training to increase the coverage of the training data. We train two different models for recognition. Our baseline is a conventional Convolution Neural Network (CNN) encoder followed by a Recurrent Neural Network (RNN) decoder. As our first contribution, we bypass the detection phase by augmenting the baseline with an Attention mechanism in the RNN decoder. Next, we build in the capability of training the model end-to-end on scenes containing license …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&citation_for_view=kOkSgaMAAAAJ:4JMBOYKVnBMC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"Sanskrit OCR documents have a lot of errors. Correcting those errors using conventional spell-checking approaches breaks down due to the limited vocabulary. This is because of high inflections of Sanskrit, where words are dynamically formed by Sandhi rules, Samāsa rules, Taddhita affixes, etc. Therefore, correcting OCR documents require huge efforts. In this paper, we present different machine learning approaches and various ways to improve features for ameliorating the error corrections in Sanskrit OCR documents. We simulated Subanta Prakaraṇam of VaiyākaraṇaSiddhāntaKaumudī for synthesizing off-the-shelf dictionary. Most of the methods we propose can also work for general Sanskrit word corrections.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&citation_for_view=kOkSgaMAAAAJ:TQgYirikUcIC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"Texts in Indic Languages contain a large proportion of out-of-vocabulary (OOV) words due to frequent fusion using conjoining rules (of which there are around 4000 in Sanskrit). OCR errors further accentuate this complexity for the error correction systems. Variations of sub-word units such as n-grams, possibly encapsulating the context, can be extracted from the OCR text as well as the language text individually. Some of the sub-word units that are derived from the texts in such languages highly correlate to the word conjoining rules. Signals such as frequency values (on a corpus) associated with such sub-word units have been used previously with log-linear classifiers for detecting errors in Indic OCR texts. We explore two different encodings to capture such signals and augment the input to Long Short Term Memory (LSTM) based OCR correction models, that have proven useful in the past for jointly learning the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&citation_for_view=kOkSgaMAAAAJ:e5wmG9Sq2KIC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"Sculpting is an art form that relies on both the visual and tactile senses. A faithful simulation of sculpting, therefore, requires interactive, physically accurate haptic and visual feedback. We present an interactive physics-based sculpting framework with faithful haptic feedback. We enable cutting of the material by designing a stable, remeshing-free cutting algorithm called Improved stable eXtended Finite Element Method. We present a simulation framework to enable stable visual and haptic feedback at interactive rates. We evaluate the performance of our framework quantitatively and quantitatively through an extensive user study.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:JV2RwH3_ST0C,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"Fracture produces new mesh fragments that introduce additional degrees of freedom in the system dynamics. Existing finite element method (FEM) based solutions suffer from an explosion in computational cost as the system matrix size increases. We solve this problem by presenting a graph-based FEM model for fracture simulation that is remeshing-free and easily scales to high-resolution meshes. Our algorithm models fracture on the graph induced in a volumetric mesh with tetrahedral elements. We relabel the edges of the graph using a computed damage variable to initialize and propagate fracture. We prove that non-linear, hyper-elastic strain energy is expressible entirely in terms of the edge lengths of the induced graph. This allows us to reformulate the system dynamics for the relabeled graph without changing the size of system dynamics matrix and thus prevents the computational cost from blowing up. The fractured surface has to be reconstructed explicitly only for visualization purposes. We simulate standard laboratory experiments from structural mechanics and compare the results with corresponding real-world experiments. We fracture objects made of a variety of brittle and ductile materials, and show that our technique offers stability and speed that is unmatched in current literature.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:TFP_iSt0sucC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"Obtaining a high-quality OCR output in smart cities, with human-in-the-loop, is an interesting problem for surveillance and other similar applications. Achieving high accuracy while reading license plates in the real world videos is cumbersome due to complexities like multiple vehicles, high-density traffic in spatial and temporal domains, varying camera angles and illumination, occlusions and multiple resolutions. We present a modular framework for OCR corrections in the chaotic Indian traffic videos that especially involve complex license plate patterns. Such patterns are obtained from a state-of-the-art deep learning model trained on video frames. Since such a model reads the text from videos (instead of images), we incorporate multi-frame consensus for generating suggestions in our framework. To ease the correction process, our human-interactive framework first breaks down the multi-vehicle videos into …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:RHpTSmoSYBkC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"We present a physics-based framework to simulate porous, deformable materials and interactive tools with haptic feedback that can reshape it. In order to allow the material to be moulded non-homogeneously, we propose an algorithm to change the material properties of the object depending on its water content. We present a multi-resolution, multi-timescale simulation framework to enable stable visual and haptic feedback at interactive rates. We test our model for physical consistency, accuracy, interactivity and appeal through a user study and quantitative performance evaluation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:maZDTaKrznsC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"Fracture of solid objects produces debris. Modelling the physics that produces the broken fragments from the original solid requires an increase in the number of degrees of freedom. This causes a huge increase in computational cost for FEM based methods used to model such phenomena. We present a graph-based FEM method that tackles this issue by relabeling the edges of the graph induced in a volumetric mesh, using a damage variable. We reformulate the system dynamics for this relabelled graph in order to simulate the fracture mechanics using FEM without an explosion in the computation cost. Our method therefore requires no remeshing of the volumetric mesh used for computation and this makes it very scalable to high-resolution meshes. We demonstrate that the method can simulate both brittle and ductile fracture.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:isC4tDSrTZIC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"General relativity describes the curvature of spacetime. Rays of light follow geodesic paths in curved spacetime. Visualizing scenes containing spacetime regions with pronounced curvature requires tracing of these light ray paths. We present a monte carlo approach for non-linear raytracing to render scenes in curved spacetime. In contrast to earlier work, we can accurately resolve ray-object interactions. This allows us to create plausible visualizations of what happens when a black hole appears in a more known environment, like a room with regular specular and diffuse surfaces. We demonstrate that our solution is correct at cosmological scales by showing how spacetime warps around a stationary schwarzschild black hole and a non-stationary kerr black hole. We verify that the solution is consistent with the predictions of general relativity. In the absence of any curvature in spacetime, our renderer behaves like a normal linear ray tracer. Our method has the potential to create rich, physically plausible visualizations of complex phenomena that can be used for a range of purposes, from creating visual effects to making pedagogical aids to understand the behaviour of spacetime as predicted by general relativity. Copyright © 2021 by scitepress – science and technology publications, lda. All rights reserved",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:70eg2SAEIzsC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"We present an unsupervised incremental learning method for refining hand shape and pose estimation. We propose a refiner network (RefNet) that can augment a state-of-the-art hand tracking system (BaseNet) by refining its estimations on unlabeled data. At each input depth frame, the estimations from the BaseNet are iteratively refined by RefNet using a model-fitting strategy. During this process, the RefNet adapts to the input data characteristics by incremental learning. We show that our method provides more accurate hand shape and pose estimates on both a standard dataset and real data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:_Qo2XoVZTnwC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"We present a reduced model based on position based dynamics for real-time simulation of human musculature. We demonstrate our methods on the muscles of the human arm. Co-simulation of all the muscles of the human arm allow us to accurately track the development of stresses and strains in the muscles, when the arm is moved. We evaluate our method for accuracy by comparing it with gold standard simulation models based on finite volume methods, and demonstrate the stability of the method under flexion, extension and torsion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:R3hNpaxXUhUC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"We present an intuitive method to create 2D hand-drawn character animation suitable for novice animators. Given the 2D model sheet of the character that shows how the character looks from the front and side, our method can generate sketched views of the character from any direction, using the sketch stroke style used in the model sheet. Subsequently, our system can generate an animation of the character using motion capture data, and render it using the same sketched strokes. Our method is not only able to reproduce the sketch stroke style, but also the colours and other character details that the animator adds to the model sheet. The method can resolve occlusion correctly, both due to moving body parts and change in orientation of the character with respect to the camera. The animator can interactively change the sketch style, colours or other details, at any frame, as required. The animation generated by our method has the fluid style of hand sketched animation, and provides a very good starting point for novice animators that can be then improved to create the final, desired animation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:HDshCWvjkbEC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"Fracture produces new mesh fragments that introduce additional degrees of freedom in the system dynamics. Existing finite element method (FEM) based solutions suffer from increasing computational cost as the system matrix size increases. We solve this problem by presenting a graph‐based FEM model for fracture simulation that is remeshing‐free and easily scales to high‐resolution meshes. Our algorithm models fracture on the graph induced in a volumetric mesh with tetrahedral elements. We relabel the edges of the graph using a computed damage variable to initialize and propagate fracture. We prove that non‐linear, hyper‐elastic strain energy density is expressible entirely in terms of the edge lengths of the induced graph. This allows us to reformulate the system dynamics for the relabelled graph without changing the size of the system dynamics matrix and thus prevents the computational cost from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:ns9cj8rnVeAC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,Fracture simulation of real-world materials is an exceptionally challenging problem due to complex material properties like anisotropic elasticity and the presence of material impurities. We present a graph-based finite element method to simulate dynamic fracture in anisotropic materials. We further enhance this model by developing a novel probabilistic damage mechanics for modelling materials with impurities using a random graph-based formulation. We demonstrate how this formulation can be used by artists for directing and controlling fracture. We simulate and render fractures for a diverse set of materials to demonstrate the potency and robustness of our methods.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:O3NaXMp0MMsC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"When an object breaks, simulating evolution of fracture as per artist control while maintaining physical realism and plausibility is a challenging problem due to different complex material properties of real world objects. In this work, we present impurity maps as a way to guide fracture paths for both brittle and ductile fracture. We develop a novel probabilistic damage mechanics to model fracture in materials with impurities, using a random graph-based formulation in conjunction with graph-based FEM. An artist created map allows us to selectively distribute the impurities in the material, to weaken the object in those specific regions where the imperfections are added. During simulation, the presence of impurities guide the cracks that develop such that the fracture pattern closely follows the impurity map. We simulate artist-controlled fractures on different materials to demonstrate the potency of our method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:BqipwSGYUEgC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"The accuracy of hand pose and shape recovery algorithms depends on how closely the geometric hand model resembles the user’s hand. Most existing methods rely on learned shape space, e.g. MANO; but this shape model fails to generalize to unseen hand shapes with large deviations from the training set. We introduce a new hand shape model, aMANO, that augments MANO by introducing local scale adaptation that enables modeling substantially different hand sizes. We use both MANO and aMANO for calibrating the shape to new users from a stream of depth images and observe the improvement of aMANO over MANO. We believe that our new hand shape model is a significant step in improving the robustness and accuracy of existing hand tracking solutions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:YFjsv_pBGBYC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,Our first approach is based on linearization of the hyper-elastic strain energy first and then projecting out stresses along the fractured edges; and finally weakening just the fractured edges similar to [Khodabakhshi et al. 2016]. The residual stress continues working on the remaining intact edges. The fracture simulation results using this approach are presented in Figure 1.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:RYcK_YlVTxYC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"The accuracy of hand tracking algorithms depends on how closely the geometry of the mesh model resembles the user’s hand shape. Most existing methods rely on a learned shape space model; however, this fails to generalize to unseen hand shapes with significant deviations from the training set. We introduce local scale adaptation to augment this data-driven shape model and thus enable modeling hands of substantially different sizes. We also present a framework to calibrate our proposed hand shape model by registering it to depth data and achieve accurate and robust tracking. We demonstrate the capability of our proposed adaptive shape model over the most widely used existing hand model by registering it to subjects from different demographics. We also validate the accuracy and robustness of our tracking framework on challenging public hand datasets where we improve over state-of-the-art methods. Our adaptive hand shape model and tracking framework offer a significant boost towards generalizing the accuracy of hand tracking.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:NaGl4SEjCO4C,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"We present a deep neural framework that allows users to create surfaces from a stream of sparse 3D sketch strokes. Our network consists of a global surface estimation module followed by a local surface refinement. This facilitates in the incremental prediction of surfaces. Thus, our proposed method works with 3D sketch strokes and estimate a surface interactively in real time. We compare the proposed method with various state-of-the-art methods and show its efficacy for surface fitting. Further, we integrate our method into an existing Blender based 3D content creation pipeline to show its usefulness in 3D modeling.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:GnPB-g6toBAC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",10,"We present a CATALIST model that ‘tames’ the attention (heads) of an attention-based scene text recognition model. We provide supervision to the attention masks at multiple levels, i.e., line, word, and character levels while training the multi-head attention model. We demonstrate that such supervision improves training performance and testing accuracy. To train CATALIST and its attention masks, we also present a synthetic data generator ALCHEMIST that enables the synthetic creation of large scene-text video datasets, along with mask information at character, word, and line levels. We release a real scene-text dataset of 2k videos,  with videos of real scenes that potentially contain scene-text in a combination of three different languages, namely, English, Hindi, and Marathi. We record these videos using 5 types of camera transformations - (i) translation, (ii) roll, (iii) tilt, (iv) pan, and (v) zoom to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&citation_for_view=kOkSgaMAAAAJ:k_IJM867U9cC,http://www.cse.iitb.ac.in/~paragc
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"For image segmentation, typical fully convolutional networks (FCNs) need strong supervision through a large sample of high-quality dense segmentations, entailing high costs in expert-raters’ time and effort. We propose MS-Net, a new FCN to significantly reduce supervision cost, and improve performance, by coupling strong supervision with weak supervision through low-cost input in the form of bounding boxes and landmarks. Our MS-Net enables instance-level segmentation at high spatial resolution, with feature extraction using dilated convolutions. We propose a new loss function using bootstrapped Dice overlap for precise segmentation. Results on large datasets show that MS-Net segments more accurately at reduced supervision costs, compared to the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&citation_for_view=xVs3dPgAAAAJ:f2IySw72cVMC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"We propose a novel Bayesian decision theoretic deep-neural-network (DNN) framework for image segmentation, enabling us to define a principled measure of uncertainty associated with label probabilities. Our framework estimates uncertainty analytically at test time, unlike the state of the art that relies on approximate and expensive algorithms using sampling or multiple passes. Moreover, our framework leads to a novel Bayesian interpretation of the softmax layer. We propose a novel method to improve DNN calibration. Results on three large datasets show that our framework improves segmentation quality and calibration, and provides more realistic uncertainty estimates, over existing methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:b0M2c_1WBrUC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"For simultaneous positron-emission-tomography and magnetic-resonance-imaging (PET-MRI) systems, while early methods relied on independently reconstructing PET and MRI images, recent works have demonstrated improvement in image reconstructions of both PET and MRI using joint reconstruction methods. The current state-of-the-art joint reconstruction priors rely on fine-scale PET-MRI dependencies through the image gradients at corresponding spatial locations in the PET and MRI images. In the general context of image restoration, compared to gradient-based models, patch-based models (e.g., sparse dictionaries) have demonstrated better performance by modeling image texture better. Thus, we propose a novel joint PET-MRI patch-based dictionary prior that learns inter-modality higher-order dependencies together with intra-modality textural patterns in the images. We model the joint-dictionary prior …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:u9iWguZQMMsC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Abnormality detection in biomedical images is a one-class classification problem, where methods learn a statistical model to characterize the inlier class using training data solely from the inlier class. Typical methods (i) need well-curated training data and (ii) have formulations that are unable to utilize expert feedback through (a small amount of) labeled outliers. In contrast, we propose a novel deep neural network framework that (i) is robust to corruption and outliers in the training data, which are inevitable in real-world deployment, and (ii) can leverage expert feedback through high-quality labeled data. We introduce an autoencoder formulation that (i) gives robustness through a non-convex loss and a heavy-tailed distribution model on the residuals and (ii) enables semi-supervised learning with labeled outliers. Results on three large medical datasets show that our method outperforms the state of the art in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:4OULZ7Gr8RgC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"For medical image segmentation, most fully convolutional networks (FCNs) need strong supervision through a large sample of high-quality dense segmentations, which is taxing in terms of costs, time and logistics involved. This burden of annotation can be alleviated by exploiting weak inexpensive annotations such as bounding boxes and anatomical landmarks. However, it is very difficult to \textit{a priori} estimate the optimal balance between the number of annotations needed for each supervision type that leads to maximum performance with the least annotation cost. To optimize this cost-performance trade off, we present a budget-based cost-minimization framework in a mixed-supervision setting via dense segmentations, bounding boxes, and landmarks. We propose a linear programming (LP) formulation combined with uncertainty and similarity based ranking strategy to judiciously select samples to be annotated next for optimal performance. In the results section, we show that our proposed method achieves comparable performance to state-of-the-art approaches with significantly reduced cost of annotations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:bFI3QPDXJZMC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Radiation exposure in positron emission tomography (PET) imaging limits its usage in the studies of radiation-sensitive populations, e.g., pregnant women, children, and adults that require longitudinal imaging. Reducing the PET radiotracer dose or acquisition time reduces photon counts, which can deteriorate image quality. Recent deep-neural-network (DNN) based methods for image-to-image translation enable the mapping of low-quality PET images (acquired using substantially reduced dose), coupled with the associated magnetic resonance imaging (MRI) images, to high-quality PET images. However, such DNN methods focus on applications involving test data that match the statistical characteristics of the training data very closely and give little attention to evaluating the performance of these DNNs on new out-of-distribution (OOD) acquisitions. We propose a novel DNN formulation that models the (i …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:eJXPG6dFmWUC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Abnormality detection in medical images is a one-class classification problem for which existing methods typically involve variants of kernel principal component analysis or one-class support vector machines. However, existing methods rely on highly-curated training sets with full supervision, often using heuristics for model fitting or ignore the variances of the data within principal subspaces. In contrast, we propose novel methods that can work with imperfectly curated datasets using robust statistical learning, by extending the multivariate generalized-Gaussian distribution to a reproducing kernel Hilbert space (RKHS) and employing it within a mixture model. We propose a novel semi-supervised extension of our learning scheme, showing that a small amount of expert feedback through high-quality labeled data of the outlier class can boost performance. We propose expectation maximization for our semi-supervised …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:XiSMed-E-HIC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Super-resolution using deep neural networks typically relies on highly curated training sets that are often unavailable in clinical deployment scenarios. Using loss functions that assume Gaussian-distributed residuals makes the learning sensitive to corruptions in clinical training sets. We propose novel loss functions that are robust to corruptions in training sets by modeling heavy-tailed non-Gaussian distributions on the residuals. We propose a loss based on an autoencoder-based manifold-distance between the super-resolved and high-resolution images, to reproduce realistic textural content in super-resolved images. We propose to learn to super-resolve images to match human perceptions of structure, luminance, and contrast. Results on a large clinical dataset shows the advantages of each of our contributions, where our framework improves over the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:_xSYboBqXhAC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Deep neural networks for image quality enhancement typically need large quantities of highly-curated training data comprising pairs of low-quality images and their corresponding high-quality images. While high-quality image acquisition is typically expensive and time-consuming, medium-quality images are faster to acquire, at lower equipment costs, and available in larger quantities. Thus, we propose a novel generative adversarial network (GAN) that can leverage training data at multiple levels of quality (e.g., high and medium quality) to improve performance while limiting costs of data curation. We apply our mixed-supervision GAN to (i) super-resolve histopathology images and (ii) enhance laparoscopy images by combining super-resolution and surgical smoke removal. Results on large clinical and pre-clinical datasets show the benefits of our mixed-supervision GAN over the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:1sJd4Hv_s6UC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Multimodal imaging combining positron emission tomography (PET) and magnetic resonance imaging (MRI) provides complementary information about metabolism and anatomy. While the appearances of MRI and PET images are distinctive, there are fundamental inter-image dependencies relating structure and function. In PET-MRI imaging, typical PET reconstruction methods use priors to enforce PET-MRI dependencies at the very fine scale of image gradients and, so, cannot capture larger-scale inter-image correlations and intra-image texture patterns. Some recent methods enforce statistical models of MRI-image patches on PET-image patches, risking infusing anatomical features into PET images. In contrast, we propose a novel patch-based joint dictionary model for PET and MRI, learning regularity in individual patches and correlations in spatially-corresponding patches, for Bayesian PET …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:D03iK_w7-QYC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Image-to-image translation is an ill-posed problem as unique one-to-one mapping may not exist between the source and target images. Learning-based methods proposed in this context often evaluate the performance on test data that is similar to the training data, which may be impractical. This demands robust methods that can quantify uncertainty in the prediction for making informed decisions, especially for critical areas such as medical imaging. Recent works that employ conditional generative adversarial networks (GANs) have shown improved performance in learning photo-realistic image-to-image mappings between the source and the target images. However, these methods do not focus on (i) robustness of the models to out-of-distribution (OOD)-noisy data and (ii) uncertainty quantification. This paper proposes a GAN-based framework that (i) models an adaptive loss function for robustness to OOD-noisy data that automatically tunes the spatially varying norm for penalizing the residuals and (ii) estimates the per-voxel uncertainty in the predictions. We demonstrate our method on two key applications in medical imaging:(i) undersampled magnetic resonance imaging (MRI) reconstruction (ii) MRI modality propagation. Our experiments with two different real-world datasets show that the proposed method (i) is robust to OOD-noisy test data and provides improved accuracy and (ii) quantifies voxel-level uncertainty in the predictions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:eflP2zaiRacC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Typical methods for image segmentation, or labeling, formulate and solve an optimization problem to produce a single optimal solution. For applications in clinical decision support relying on automated medical image segmentation, it is also desirable for methods to inform about (i) the uncertainty in label assignments or object boundaries or (ii) alternate close-to-optimal solutions. However, typical methods fail to do so. To estimate uncertainty, while some Bayesian methods rely on simplified prior models and approximate variational inference schemes, others rely on sampling segmentations from the associated posterior model using (i) traditional Markov chain Monte Carlo (MCMC) methods based on Gibbs sampling or (ii) approximate perturbation models. However, in such typical approaches, in practice, the resulting inference or generated sample set are approximations that deviate significantly from those …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:EUQCXRtRnyEC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Faster resting-state functional magnetic resonance imaging (R-fMRI) can improve spatiotemporal resolution and functional sensitivity. To speedup scans, current methods rely on complex pulse-sequence design or straightforward undersampling along with (weak) priors on the signal. We propose a Bayesian graphical R-fMRI reconstruction framework relying on learning data-adaptive prior models through dictionaries that we design to be robust to large physiological fluctuations typical in R-fMRI signals. Our dictionary adapts to multiple subjects through an optimal similarity transform. Our reconstructions on simulated and real-world R-fMRI give more accurate functional networks and better spatial resolution than the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:cFHS6HbyZ2cC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Typical deep-neural-network (DNN) based generative image models often (i) show limited ability to learn a disentangled latent representation, (ii) show limited controllability leading to undesirable side effects when manipulating selected attributes during image generation, and (iii) require large attribute-annotated training sets. We propose a generative DNN model for face images by explicitly disentangling geometry and appearance modeling to achieve selective controllability of the desired attributes with less side effects. To learn geometric variability, we leverage grayscale sketch representations to learn (i) a deformable mean template representing the population-mean face geometry and (ii) a generative model of deformations to model individual face-geometry variations, using dense image registration. We learn the appearance variability in a (color-image) space that we explicitly design by factoring out the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:B3FOqHPlNUQC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Functional positron emission tomography (fPET) imaging using continuous infusion of [18F]-fluorodeoxyglucose (FDG) is a novel neuroimaging technique to track dynamic glucose utilization in the brain. In comparison to conventional static or dynamic bolus PET, fPET maintains a sustained supply of glucose in the blood plasma which improves sensitivity to measure dynamic glucose changes in the brain, and enables mapping of dynamic brain activity in task-based and resting-state fPET studies. However, there is a trade-off between temporal resolution and spatial noise due to the low concentration of FDG and the limited sensitivity of multi-ring PET scanners. Images from fPET studies suffer from partial volume errors and residual scatter noise that may cause the cerebral metabolic functional maps to be biased. Gaussian smoothing filters used to denoise the fPET images are suboptimal, as they introduce additional …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:4fKUyHm3Qg0C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"In this paper, we propose a new method to perform Sparse Kernel Principal Component Analysis (SKPCA) and also mathematically analyze the validity of SKPCA. We formulate SKPCA as a constrained optimization problem with elastic net regularization in kernel feature space and solve it. We consider outlier detection (where KPCA is employed) as an application for SKPCA, using the RBF kernel. We test it on 5 real world datasets and show that by using just 4% (or even less) of the principal components (PCs), where each PC has on average less than 12% non-zero elements in the worst case among all 5 datasets, we are able to nearly match and in 3 datasets even outperform KPCA. We also compare the performance of our method with a recently proposed method for SKPCA and show that our method performs better in terms of both accuracy and sparsity. We also provide a novel probabilistic proof to justify the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:a0OBvERweLwC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Typical segmentation methods produce a single optimal solution and fail to inform about (i) the confidence/uncertainty in the object boundaries or (ii) alternate close-to-optimal solutions. To estimate uncertainty, some methods intend to sample segmentations from an associated posterior model using Markov chain Monte Carlo (MCMC) sampling or perturbation models. However, they cannot guarantee sampling from the true posterior, deviating significantly in practice. We propose a novel method that guarantees exact MCMC sampling, in finite time, of multi-label segmentations from generic Bayesian Markov random field (MRF) models. For exact sampling, we propose Fill’s strategy and extend it to generic MRF models via a novel bounding chain algorithm. Results on simulated data and clinical brain images from 4 classic problems show that our uncertainty estimates gain accuracy over the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:pyW8ca7W8N0C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Accelerated resting-state functional magnetic resonance imaging (R-fMRI) can provide higher spatial resolution and improved brain connectivity maps. Current methods for fast R-fMRI rely on either fully-sampled parallel imaging or undersampled reconstruction using signal priors, but not both. We propose a novel Bayesian reconstruction framework that combines simultaneous multislice (SMS) imaging, controlled aliasing, and undersampling in k-space and time to reconstruct high-quality signals and connectivity maps. We use a generative dictionary model on R-fMRI time-series, which is robust to signal fluctuations and artifacts, adapts to inter-subject variations through optimized similarity transforms on its atoms, and uses spatially regularized sparsity. Results on simulated and clinical R-fMRI show that our method gives more accurate reconstructions and connectivity maps than the state of the art, and can enable …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:WbkHhVStYXYC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Higher spatial resolution in resting-state functional magnetic resonance imaging (R-fMRI) can give reliable information about the functional networks in the cerebral cortex. Typical methods can achieve higher spatial or temporal resolution by speeding up scans using either (i) complex pulse-sequence designs or (ii) k-space undersampling coupled with priors on the signal. We propose to undersample the R-fMRI acquisition in k-space and time to speedup scans in order to improve spatial resolution. We propose a novel model-based R-fMRI reconstruction framework using a robust, subject-invariant, spatially regularized dictionary prior on the signal. Furthermore, we propose a novel inference framework based on variational Bayesian expectation maximization with nested minorization (VB-EM-NM). Our inference framework allows us to provide an estimate of uncertainty of the reconstruction, unlike typical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:K3LRdlH-MEoC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Simultaneous positron emission tomography (PET) and magnetic resonance imaging (MRI) provide complementary information about brain function and structure. Joint reconstruction of MRI and PET images can improve image quality in both modalities, potentially enabling faster MRI and lower-dose PET scans. Current methods for joint MRI-PET reconstruction use priors that model inter-modality dependencies in image gradients. Many methods also ignore the potential in parallel MRI for acceleration. In contrast, we combine accelerated parallel MRI with a joint MRI-PET patch-based dictionary model to infer higher-order dependencies across MRI and PET image neighborhoods. We propose a novel Bayesian framework for joint MRI-PET reconstruction. The results show that our method reconstructs images more accurately, in simulated and in vivo MRI-PET (in parallel MRI) cases, than the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:nb7KW1ujOQ8C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Anomaly detection is a one-class classification (OCC) problem where the methods learn either a generative model of the inlier class (eg, in the variants of kernel principal component analysis) or a decision boundary to encapsulate the inlier class (eg, in the one-class variants of the support vector machine). Learning schemes for OCC typically rely on training data solely from the inlier class, but some recent approaches have proposed semi-supervised extensions, eg, variants of semi-supervised anomaly detection that also leverage a small amount of training data from outlier classes. Other recent methods extend existing principles to employ deep neural network (DNN) modeling that relies on learning (for the inlier class) either latent-space distributions or autoencoders, but not both. We propose a novel semi-supervised variational formulation, leveraging generalized-Gaussian models leading to data-adaptive, robust, and uncertainty-aware distribution modeling in both latent space and image space. For variational learning, we propose a novel reparameterization for sampling from the latent-space generalized-Gaussian to enable backpropagation-based optimization. Results on several public image sets show the benefits of our method over state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:BrmTIyaxlBUC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Deep neural networks (DNNs) for nonlinear generative mixture modeling typically rely on unsupervised learning that employs hard clustering schemes, or variational learning with loose / approximate bounds, or under-regularized modeling. We propose a novel statistical framework for a DNN mixture model using a single generative adversarial network. Our learning formulation proposes a novel data-likelihood term relying on a well-regularized / constrained Gaussian mixture model in the latent space along with a prior term on the DNN weights. Our min-max learning increases the data likelihood using a tight variational lower bound using expectation maximization (EM). We leverage our min-max EM learning scheme for semi-supervised learning. Results on three real-world image datasets demonstrate the benefits of our compact modeling and learning formulation over the state of the art for nonlinear generative …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:geHnlv5EZngC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Statistical shape priors can be crucial in segmenting objects when the data differentiates poorly between the object and its surroundings. For reliable learning, while some methods need high-quality expert segmentations, other methods need large training sets, both of which can often be difficult to obtain in clinical deployment or scientific studies. We propose to couple deep neural networks with a pointset-based shape prior that can be learned effectively despite training sets having small size and imperfections in expert curation. The prior relies on sparse Riemannian modeling in Kendall shape space. Results on clinical brain magnetic resonance imaging data show that our framework improves over the state of the art in segmenting the thalamus and the caudate.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:Tiz5es2fbqcC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Abnormality detection in medical images is a one-class classification problem for which typical methods use variants of kernel principal component analysis or one-class support vector machines. However, in practical deployment scenarios, many such methods are sensitive to the outliers present in the imperfectly-curated training sets. Current robust methods use heuristics for model fitting or lack formulations to leverage even a small amount of high-quality expert feedback. In contrast, we propose a novel method combining (i) robust statistical modeling, extending the multivariate generalized-Gaussian to a reproducing kernel Hilbert space, with (ii) semi-supervised learning to leverage a small expert-labeled outlier set. Results on simulated and real-world data, including endoscopy data, show that our method outperforms the state of the art in accurately detecting abnormalities.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:NhqRSupF_l8C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Current approaches for semantic image inpainting rely on deep neural networks (DNNs) that learn under full supervision, i.e., using a training set comprising pairs of (i) corrupted images with holes and (ii) corresponding uncorrupted images. However, for several real-world applications, obtaining large sets of uncorrupted images is challenging or infeasible. Current methods also rely on adversarial training involving min-max optimization that is prone to instability during learning. We propose a novel self-supervised image-inpainting DNN framework that can learn in both completely unsupervised and semi-supervised modes. Moreover, our DNN learning formulation bypasses adversarial training and, thereby, lends itself to more stable training. Results on the publicly available CelebA dataset show that our method, even when learning unsupervisedly, outperforms the state of the art that learns with full supervision.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:8AbLer7MMksC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Undersampled reconstruction in resting functional magnetic resonance imaging (R-fMRI) holds the potential to enable higher spatial resolution in brain R-fMRI without increasing scan duration. We propose a novel approach to reconstruct kt undersampled R-fMRI relying on a deep convolutional neural network (CNN) framework. The architecture of our CNN framework comprises a novel scheme for R-fMRI reconstruction that jointly learns two multilayer CNN components for (i) explicitly filling in missing k-space data, using acquired data in frequency-temporal neighborhoods, and (ii) image quality enhancement in the spatiotemporal domain. The architecture sandwiches the Fourier transformation from the frequency domain to the spatial domain between the two aforementioned CNN components, during, both, CNN learning and inference. We propose four methods within our framework, including a Bayesian CNN …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:sSrBHYA8nusC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Functional positron emission tomography (fPET) imaging using continuous infusion of [18F]-fluorodeoxyglucose (FDG) is a novel neuroimaging technique to track dynamic glucose utilization in the brain. In comparison to conventional static PET, fPET maintains a sustained supply of glucose in the blood plasma which improves sensitivity to measure dynamic glucose changes in the brain, and enables mapping of dynamic brain activity in task-based and resting-state fPET studies. However, there is a trade-off between temporal resolution and spatial noise due to the low concentration of FDG and the limited sensitivity of multi-ring PET scanners. Images from fPET studies suffer from partial volume errors and residual scatter noise that may cause the cerebral metabolic functional maps to be biased. Gaussian smoothing filters used to denoise the fPET images are suboptimal, as they introduce additional partial volume errors. In this work, a post-processing framework based on a magnetic resonance (MR) Bowsher-like prior was used to improve the spatial and temporal signal to noise characteristics of the fPET images. The performance of the MR guided method was compared with conventional Gaussian filtering using both simulated and in vivo task fPET datasets. The results demonstrate that the MR guided fPET framework reduces the partial volume errors, enhances the sensitivity of identifying brain activation, and improves the anatomical accuracy for mapping changes of brain metabolism in response to a visual stimulation task. The framework extends the use of functional PET to investigate the dynamics of brain metabolic responses for faster …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Uncertainty quantification in medical imaging is critical for clinical translation of deep learningbased methods. Modality propagation within the context of medical imaging is a problem of interest, both across as well as within modalities. For magnetic resonance imaging (MRI), often, multicontrast MRI images are acquired for improved diagnosis and prognosis. In this work, we focus on the synthesis of T2w MRI images from T1w MRI images. Prior works used generative adversarial networks (GANs), but lack (i) uncertainty quantification,(ii) evaluating the robustness of the network to out-of-distribution data (common in medical imaging). We propose a robust GAN framework that incorporates uncertainty quantification using quasi-norm based penalties, and also show the efficacy of the method on unseen systemic and physiological perturbations on a large publicly available multimodal MRI dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:08ZZubdj9fEC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"In digital fluorescence microscopy, colocalization estimate between two biological entities within a specimen is often based on subjective visual inspection of images or ad hoc sequence of algorithms with several manually-tuned parameters, leading to irreproducible and unreliable estimates. We propose a novel Bayesian Markov random field (MRF) model for colocalization estimation from dual-channel images, encoding colocalization as a model parameter, to solve a unified data-driven optimization problem that, unlike existing methods, automatically deals with common-background removal, object labeling, parameter tuning, and noise. For model fitting, we propose Monte Carlo expectation maximization (EM) with perfect sampling extended from priors to posteriors, for our MRF model, to guarantee sampler convergence. We use consistent pseudo-likelihood estimators to deal with intractability in MRF parameter …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:dfsIfKJdRG4C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"The propensity of task-based functional magnetic resonance imaging (T-fMRI) to large physiological fluctuations, measurement noise, and imaging artifacts entail longer scans and higher temporal resolution (trading off spatial resolution) to alleviate the effects of degradation. This paper focuses on methods towards reducing scan times and enabling higher spatial resolution in T-fMRI. We propose a novel mixed-dictionary model combining (i) the task-based design matrix,(ii) a learned dictionary from resting-state fMRI, and (iii) an analytically-defined wavelet frame. For model fitting, we propose a novel adaptation of the inference framework relying on variational Bayesian expectation maximization with nested minorization. We leverage the mixed-dictionary model coupled with variational inference to enable 2× shorter scan times in T-fMRI, improving activation-map estimates towards the same quality as those …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:kRWSkSYxWN8C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"One-class classification (OCC) methods for abnormality detection learn either a generative model of the inlier class (e.g., using variants of kernel principal component analysis) or a decision boundary to encapsulate the inlier class (e.g., using one-class variants of the support vector machine). Recent methods use deep-neural-network models to learn (for the inlier class) either latent-space distributions or autoencoders, but not both. OCC learning typically relies solely on inlier-class data, but some recent semi-supervised versions also leverage some outlier-class training data. We propose a robust and uncertainty-aware variational framework for OCC, leveraging data-adaptive generalized-Gaussian (GG) models leading to distribution modeling in both latent space and image space. We propose a reparameterization for samples from the latent-space GG to enable backpropagation. Results on publicly available real …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:J-pR_7NvFogC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Reducing the dose of ionizing radiation underlying combined imaging with positron emission tomography (PET) and computed tomography (CT) typically leads to reduced image quality. We propose a novel variational deep-neural-network (DNN) framework for image quality enhancement of low-dose PET-CT images, relying on Monte-Carlo expectation maximization. Unlike existing DNN-based training that pairs low-dose PET-CT images with their corresponding high-dose versions, we propose a semi-supervised learning framework that enables learning using a small number of high-dose images. We propose a robust and uncertainty-aware loss motivated by a heavy-tailed generalized-Gaussian distribution on the residuals between the DNN output and the PET-CT data, aiding our semi-supervised learning scheme. Results on publicly available data show the benefits of our framework, quantitatively and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:1qzjygNMrQYC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Resting-state functional magnetic resonance imaging (R-fMRI) applications can entail a higher temporal-sampling rate that trades off spatial resolution, thereby challenging effective scientific studies. To enable higher spatial resolution, current schemes speedup per-timeframe scanning by reconstruction from simultaneous multislice (SMS) magnetic resonance imaging (MRI) with k-space undersampling (sometimes temporal undersampling), while using prior models on the signal. We propose a novel algorithmic framework to reconstruct R-fMRI (SMS with controlled aliasing) that has, both, k-space undersampling and temporal undersampling. We propose a coupled spatiotemporal sparse model, incorporating (i) a robust spatially-regularized temporal-dictionary prior and (ii) a spatiotemporal wavelet prior, which we fit efficiently using variational Bayesian expectation maximization with nested minorization (VBEMNM …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:D_sINldO8mEC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"We introduce a machine learning-based method for fully automated diagnosis of sickle cell disease of poor-quality unstained images of a mobile microscope. Our method is capable of distinguishing between diseased, trait (carrier), and normal samples unlike the previous methods that are limited to distinguishing the normal from the abnormal samples only. The novelty of this method comes from distinguishing the trait and the diseased samples from challenging images that have been captured directly in the field. The proposed approach contains two parts, the segmentation part followed by the classification part. We use a random forest algorithm to segment such challenging images acquitted through a mobile phone-based microscope. Then, we train two classifiers based on a random forest (RF) and a support vector machine (SVM) for classification. The results show superior performances of both of the classifiers not only for images which have been captured in the lab, but also for the ones which have been acquired in the field itself.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:LPZeul_q3PIC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"Typical methods for semantic image segmentation rely on large training sets comprising pixel-level segmentations and pixel-level classifications. In medical applications, a large number of training images with per-pixel segmentations are difficult to obtain. In addition, many applications involve images or image tiles containing a single object/region of interest, where the image/tile-level information about object/region class is readily available. We propose a novel deep-neural-network (DNN) framework for joint segmentation and recognition of objects relying on weakly-supervised learning from training sets having very few expert segmentations, but with object-class labels available for all images/tiles. For weakly-supervised learning, we propose a variational-learning framework relying on Monte Carlo expectation maximization (MCEM), inferring a posterior distribution on the missing segmentations. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:VOx2b1Wkg3QC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",25,"In high-angular-resolution diffusion imaging (HARDI), simultaneous multislice (SMS) acquisition incorporated in multi-coil parallel imaging offers speedups in addition to the speedup obtained from undersampling gradient directions. We propose a novel learning-based method for reconstructing direction-undersampled SMS HARDI data. Our method relies on random-forest regression that also informs on the uncertainty in the reconstructions stemming from noise and artifacts. Results on a large clinical HARDI dataset show that our method significantly improves over the state of the art on SMS HARDI reconstruction qualitatively and quantitatively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&citation_for_view=xVs3dPgAAAAJ:CHSYGLWDkRkC,http://www.cse.iitb.ac.in/~suyash
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"The COVID-19 pandemic has strained testing capabilities worldwide. There is an urgent need to find economical and scalable ways to test more people. We present Tapestry, a novel quantitative nonadaptive pooling scheme to test many samples using only a few tests. The underlying molecular diagnostic test is any real-time RT-PCR diagnostic panel approved for the detection of the SARS-CoV-2 virus. In cases where most samples are negative for the virus, Tapestry accurately identifies the status of each individual sample with a single round of testing in fewer tests than simple two-round pooling. We also present a companion Android application BYOM Smart Testing which guides users through the pipetting steps required to perform the combinatorial pooling. The results of the pooled tests can be fed into the application to recover the status and estimated viral load for each individual sample.
NOTE: This protocol has been validated with in vitro experiments that used synthetic RNA and DNA fragments and additionally, its expected behavior has been confirmed using computer simulations. Validation with clinical samples is ongoing. We are looking for clinical collaborators with access to patient samples. Please contact the corresponding author if you wish to validate this protocol on clinical samples.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&citation_for_view=CkTW7PwAAAAJ:YFjsv_pBGBYC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"We propose Tapestry, a novel approach to pooled testing with application to COVID-19 testing with quantitative Polymerase Chain Reaction (PCR) that can result in shorter testing time and conservation of reagents and testing kits. Tapestry combines ideas from compressed sensing and combinatorial group testing with a novel noise model for PCR. Unlike Boolean group testing algorithms, the input is a quantitative readout from each test, and the output is a list of viral loads for each sample. While other pooling techniques require a second confirmatory assay, Tapestry obtains individual sample-level results in a single round of testing. When testing n samples with t tests, as many as k= O (t/log n) infected samples can be identified at clinically-acceptable false positive and false negative rates. This makes Tapestry viable even at prevalence rates as high as 10%. Tapestry has been validated in simulations as well as in wet lab experiments with oligomers. Clinical trials with Covid-19 samples are underway. An accompanying Android application Byom Smart Testing which makes the Tapestry protocol straightforward to implement in testing centres is available for free download.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&citation_for_view=CkTW7PwAAAAJ:WbkHhVStYXYC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"We propose ‘Tapestry’, a single-round pooled testing method with application to COVID-19 testing using quantitative Reverse Transcription Polymerase Chain Reaction (RT-PCR) that can result in shorter testing time and conservation of reagents and testing kits, at clinically acceptable false positive or false negative rates. Tapestry combines ideas from compressed sensing and combinatorial group testing to create a new kind of algorithm that is very effective in deconvoluting pooled tests. Unlike Boolean group testing algorithms, the input is a quantitative readout from each test and the output is a list of viral loads for each sample relative to the pool with the highest viral load. For guaranteed recovery of infected samples out of being tested, Tapestry needs only tests with high probability, using random binary pooling matrices. However, we propose deterministic binary pooling matrices based on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&citation_for_view=CkTW7PwAAAAJ:RGFaLdJalmkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Group testing can save testing resources in the context of the ongoing COVID-19 pandemic. In group testing, we are given n samples, one per individual, and arrange them into m < n pooled samples, where each pool is obtained by mixing a subset of the n individual samples. Infected individuals are then identified using a group testing algorithm. In this paper, we use side information (SI) collected from contact tracing (CT) within nonadaptive/single-stage group testing algorithms. We generate data by incorporating CT SI and characteristics of disease spread between individuals. These data are fed into two signal and measurement models for group testing, where numerical results show that our algorithms provide improved sensitivity and specificity. While Nikolopoulos et al. utilized family structure to improve nonadaptive group testing, ours is the first work to explore and demonstrate how CT SI can further improve …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&citation_for_view=CkTW7PwAAAAJ:SeFeTyx0c_EC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Images of static scenes submerged beneath a wavy water surface exhibit severe non-rigid distortions. The physics of water flow suggests that water surfaces possess spatio-temporal smoothness and temporal periodicity. Hence they possess a sparse representation in the 3D discrete Fourier (DFT) basis. Motivated by this, we pose the task of restoration of such video sequences as a compressed sensing (CS) problem. We begin by tracking a few salient feature points across the frames of a video sequence of the submerged scene. Using these point trajectories, we show that the motion fields at all other (non-tracked) points can be effectively estimated using a typical CS solver. This by itself is a novel contribution in the field of non-rigid motion estimation. We show that this method outperforms state of the art algorithms for underwater image restoration. We further consider a simple optical flow algorithm based on local polynomial expansion of the image frames (PEOF). Surprisingly, we demonstrate that PEOF is more efficient and often outperforms all the state of the art methods in terms of numerical measures. Finally, we demonstrate that a two-stage approach consisting of the CS step followed by PEOF much more accurately preserves the image structure and improves the (visual as well as numerical) video quality as compared to just the PEOF stage. The source code, datasets and supplemental material can be accessed at [??],[??].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&citation_for_view=CkTW7PwAAAAJ:r0BpntZqJG4C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Most existing bounds for signal reconstruction from compressive measurements make the assumption of additive signal-independent noise. However in many compressive imaging systems, the noise statistics are more accurately represented by Poisson or Poisson–Gaussian noise models. In this paper, we derive upper bounds for signal reconstruction error from compressive measurements which are corrupted by Poisson or Poisson–Gaussian noise. The features of our bounds are as follows:(1) the bounds are derived for a computationally tractable convex estimator with statistically motivated parameter selection. The estimator penalizes signal sparsity subject to a constraint that imposes a novel statistically motivated upper bound on a term based on variance stabilization transforms to approximate the Poisson or Poisson–Gaussian distributions by distributions with (nearly) constant variance.(2) The bounds are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&citation_for_view=CkTW7PwAAAAJ:TQgYirikUcIC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In many compressive sensing reconstruction algorithms, a good choice of important parameters such as the optimal number of measurements (which is dependent upon the unknown signal sparsity) or the regularization parameter, is critical for successful signal recovery. Cross-validation provides a principled method of doing so, by dividing the measurements into a ‘reconstruction set’ to recover the signal given each candidate parameter value, and a ‘cross-validation set’ to determine in a purely data-driven manner as to which candidate parameter value is optimal. In previous work, such a technique has been theoretically analyzed for the case of noiseless compressive measurements or for the case of additive i.i.d. Gaussian noise in the measurements. This paper presents the first theoretical analysis of this technique for compressed sensing when the measurements are corrupted by Poisson noise, the dominant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:ZHo1McVdvXMC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Group testing can help maintain a widespread testing program using fewer resources amid a pandemic. In group testing, we are given samples, one per individual. These samples are arranged into pooled samples, where each pool is obtained by mixing a subset of the individual samples. Infected individuals are then identified using a group testing algorithm. In this paper, we use side information (SI) collected from contact tracing (CT) within nonadaptive/single-stage group testing algorithms. We generate CT SI data by incorporating characteristics of disease spread between individuals. These data are fed into two signal and measurement models for group testing, and numerical results show that our algorithms provide improved sensitivity and specificity. We also show how to incorporate CT SI into the design of the pooling matrix. That said, our numerical results suggest that the utilization of SI in the pooling matrix design based on the minimization of a weighted coherence measure does not yield significant performance gains beyond the incorporation of SI in the group testing algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:yD5IFk8b50cC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,Method and electronic device for providing image-based CAPTCHA challenge Embodiments herein achieve an electronic device for providing an image-based CAPTCHA challenge. The electronic device is configured to cause to display the image-based CAPTCHA challenge for a user of the electronic device. The image-based CAPTCHA challenge includes a first image and a second image of an object displayed from different viewpoints. The first image includes a challenge point in at least one portion of the object. The electronic device is further configured to detect at least one input from the user indicating the at least one challenge point on at least one portion of the second image. The electronic device is further configured to automatically determine whether the at least one portion of the second image on which the at least one input performed by the user corresponds to the at least one portion of the first image …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:KxtntwgDAa4C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Low-dose tomography is highly preferred in medical procedures for its reduced radiation risk when compared to standard-dose Computed Tomography (CT). However, the lower the intensity of X-rays, the higher the acquisition noise and hence the reconstructions suffer from artefacts. A large body of work has focussed on improving the algorithms to minimize these artefacts. In this work, we propose two new techniques, rescaled non-linear least squares and Poisson-Gaussian convolution, that reconstruct the underlying image making use of an accurate or near-accurate statistical model of the noise in the projections. We also propose a reconstruction method when prior knowledge of the underlying object is available in the form of templates. This is applicable to longitudinal studies wherein the same object is scanned multiple times to observe the changes that evolve in it over time. Our results on 3D data show that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:blknAaTinKkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Joint probability density or joint probability mass function (PDF/PMF) estimation is a fundamental machine learning problem. The number of free parameters scales exponentially with respect to the number of random variables. Hence, most work on nonparametric joint distribution estimation is based on some structural assumptions such as clique factorization adopted by probabilistic graphical models, imposition of low rank on the joint probability tensor and reconstruction from 3-way or 2-way marginals, etc. In the current work, we link random projections of data to the problem of PMF estimation using techniques from tomography. Using it alongside low-rank tensor decomposition, we present an approach to estimate joint distribution from just one-way marginals in a transformed space. We provide a novel algorithm for recovering factors of the tensor from one-way marginals, test it across synthetic and real-world …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:u_35RYKgDlwC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In this paper, an approach to optimize a device discovery process using highly directive antennas for Terahertz communications is introduced. An algorithm using compressed sensing and some first results based on simulation data are presented. The simulation environment and scenarios as well as the compressed sensing theory are explained and the concept is evaluated considering different propagation scenarios as well as different frequencies and angular resolutions. Finally, the results show that the number of directions of the considered device discovery process can be reduced by up to 61 % on average.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:4OULZ7Gr8RgC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In many applications in compressed sensing, the measurement matrix is a Fourier matrix, ie, it measures the Fourier transform of the underlying signal at some specified ‘base’frequencies {u i} i= 1 M, where M is the number of measurements. However due to system calibration errors, the system may measure the Fourier transform at frequencies {u i+ δ i} i= 1 M that are different from the base frequencies and where {δ i} i= 1 M are unknown frequency perturbations. Ignoring such perturbations can lead to major errors in signal recovery. In this paper, we present a simple but effective alternating minimization algorithm to recover the perturbations in the frequencies in situ with the signal, which we assume is sparse or compressible in some known basis. In many cases, the perturbations {δ i} i= 1 M can be expressed in terms of a small number of unique parameters P≪ M. We demonstrate that in such cases, the method …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:j3f4tGmQtD8C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In this paper, we consider the problem of nonlinear blind compressed sensing, i.e. jointly estimating the sparse codes and sparsity-promoting basis, under signal-dependent noise. We focus our efforts on the Poisson noise model, though other signal-dependent noise models can be considered. By employing a well-known variance stabilizing transform such as the Anscombe transform, we formulate our task as a nonlinear least squares problem with the ℓ 1 penalty imposed for promoting sparsity. We solve this objective function under non-negativity constraints imposed on both the sparse codes and the basis. To this end, we propose a multiplicative update rule, similar to that used in non-negative matrix factorization (NMF), for our alternating minimization algorithm. To the best of our knowledge, this is the first attempt at a formulation for nonlinear blind compressed sensing, with and without the Poisson noise model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:k_IJM867U9cC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Recovery error bounds in compressed sensing under Gaussian or uniform bounded noise do not translate easily to the case of Poisson noise. Reasons for this include the signal dependent nature of Poisson noise, and also the fact that the negative log likelihood in case of a Poisson distribution (which is directly related to the generalized Kullback–Leibler divergence) is not a metric and does not obey the triangle inequality. There exist prior theoretical results in the form of provable error bounds for computationally tractable estimators for compressed sensing problems under Poisson noise. However, these results do not apply to realistic compressive systems, which must obey some crucial constraints such as non-negativity and flux preservation. On the other hand, there exist provable error bounds for such realistic systems in the published literature, but they are for estimators that are computationally intractable. In …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:4JMBOYKVnBMC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In many applications in compressed sensing, the measurement matrix is a Fourier matrix, i.e., it measures the Fourier transform of the underlying signal at some specified `base' frequencies {u i } M i=1 , where M is the number of measurements. However due to system calibration errors, the system may measure the Fourier transform at frequencies {u i + δ i } M i=1 that are different from the base frequencies and where {δ i } M i=1 are unknown. Ignoring perturbations of this nature can lead to major errors in signal recovery. In this paper, we present a simple but effective alternating minimization algorithm to recover the perturbations in the frequencies in situ with the signal, which we assume is sparse or compressible in some known basis. In many practical cases, the perturbations {δ i } M i=1 can be expressed in terms of a small number of unique parameters P z M. We demonstrate that in such cases, the method …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:_Qo2XoVZTnwC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Brain neural connectivity patterns are increasingly analyzed with diffusion magnetic resonance imaging (dMRI) via the estimation of local fiber-tract orientations. High angular resolution diffusion imaging (HARDI), a variant of dMRI, is known to produce better representation of fiber orientations than the traditionally used diffusion tensor imaging (DTI). However, it requires a large number of samples leading to longer scan times. In this paper, we propose a new method, namely, MSR-HARDI, for the accelerated reconstruction of HARDI data using multiple sparsity regularizers in the k - q space. Combination of regularizers is observed to provide improved reconstructions as compared to individual regularizers. The proposed method is also observed to provide better reconstruction than the existing state-of-the-art methods in terms of the normalized mean squared error.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:g5m5HwL7SMYC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Consider a scene submerged underneath a fluctuating water surface. Images of such a scene, when acquired from a camera in the air, exhibit significant spatial distortions. In this paper, we present a novel, computationally efficient pre-processing algorithm to correct a significant amount (~ 50%) of apparent distortion present in video sequences of such a scene. We demonstrate that when the partially restored video output from this stage is given as input to other methods, it significantly improves their performance. This algorithm involves (i) tracking a small number N of salient feature points across the T frames to yield point-trajectories\\boldsymbol q_i\triangleq\(x_ it, y_ it)\_ t= 1^ T\_ i= 1^ N, and (ii) using the point-trajectories to infer the deformations at other non-tracked points in every frame. A Fourier decomposition of the N trajectories, followed by a novel Fourier phase-interpolation step, is used to infer deformations at all other points. Our method exploits the inherent spatio-temporal characteristics of the fluctuating water surface to correct non-rigid deformations to a very large extent. The source code, datasets and supplemental material can be accessed at [1],[2].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:NMxIlDl6LWMC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Abnormality detection in medical images is a one-class classification problem for which typical methods use variants of kernel principal component analysis or one-class support vector machines. However, in practical deployment scenarios, many such methods are sensitive to the outliers present in the imperfectly-curated training sets. Current robust methods use heuristics for model fitting or lack formulations to leverage even a small amount of high-quality expert feedback. In contrast, we propose a novel method combining (i) robust statistical modeling, extending the multivariate generalized-Gaussian to a reproducing kernel Hilbert space, with (ii) semi-supervised learning to leverage a small expert-labeled outlier set. Results on simulated and real-world data, including endoscopy data, show that our method outperforms the state of the art in accurately detecting abnormalities.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:bEWYMUwI8FkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"The need for tomographic reconstruction from sparse measurements arises when the measurement process is potentially harmful, needs to be rapid, or is uneconomical. In such cases, prior information from previous longitudinal scans of the same or similar objects helps to reconstruct the current object whilst requiring significantly fewer `updating' measurements. However, a significant limitation of all prior-based methods is the possible dominance of the prior over the reconstruction of new localised information that has evolved within the test object. In this paper, we improve the state of the art by (1) detecting potential regions where new changes may have occurred, and (2) effectively reconstructing both the old and new structures by computing regional weights that moderate the local influence of the priors. We have tested the efficacy of our method on synthetic as well as real volume data. The results demonstrate that using weighted priors significantly improves the overall quality of the reconstructed data whilst minimising their impact on regions that contain new information.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:-f6ydRqryjwC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Most existing work in designing sensing matrices for compressive recovery is based on optimizing some quality factor, such as mutual coherence, average coherence or the restricted isometry constant (RIC), of the sensing matrix. In this paper, we report anomalous results that show that such a design is not always guaranteed to improve reconstruction results. We also present a design method based on the minimum mean squared error (MMSE) criterion, imposing priors on signal and noise for natural images, and show that it yields results superior to results from coherence-based methods while taking into account physical constraints on the sensing matrix.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:hFOr9nPyWt4C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Let X∗ be the true rank 1 matrix that satisfies the constraints in Q1, andX be the solution to Q1 for an appropriate choice of parameters. We define∆= X− X⋆. For a matrix X∈ R d× d, XT denotes a matrix with all values zero except the indices in T, which are set to the corresponding values of X.∀ λ≥ 2d
1− ρ+ d k 1 2 and δ≤",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:JV2RwH3_ST0C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Videos shot by laymen using hand-held cameras contain undesirable shaky motion. Estimating the global motion between successive frames, in a manner not influenced by moving objects, is central to many video stabilization techniques, but poses significant challenges. A large body of work uses 2D affine transformations or homography for the global motion. However, in this work, we introduce a more general representation scheme, which adapts any existing optical flow network to ignore the moving objects and obtain a spatially smooth approximation of the global motion between video frames. We achieve this by a knowledge distillation approach, where we first introduce a low pass filter module into the optical flow network to constrain the predicted optical flow to be spatially smooth. This becomes our student network, named as GLOBALFLOWNET. Then, using the original optical flow network as the teacher network, we train the student network using a robust loss function. Given a trained GLOBALFLOWNET, we stabilize videos using a two stage process. In the first stage, we correct the instability in affine parameters using a quadratic programming approach constrained by a user-specified cropping limit to control loss of field of view. In the second stage, we stabilize the video further by smoothing global motion parameters, expressed using small number of discrete cosine transform coefficients. In extensive experiments on a variety of different videos, our technique outperforms state of the art techniques in terms of subjective quality and different quantitative measures of video stability. Additionally, we present a new measure for evaluation of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:p2g8aNsByqUC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"The COVID-19 pandemic has adversely affected millions all over the world. Efficient and effective testing of individuals for COVID-19, via modalities such as reverse transcription polymerase chain reaction (RT-PCR) is a crucial factor in combating this menace. Given the widespread scarcity of testing resources including testing kits, reagents, skilled manpower and available time, pooled testing has been advocated as a method of speed-up. Pooling involves mixing together small portions of ‘samples’ of different individuals, followed by testing the pools instead of the individual samples. It has been observed that a much smaller number of pools, as compared to the number of samples, is sufficient to allow for accurate prediction of the health status of the constituent samples, under the common and reasonable assumption that only a small number of the samples were infected. Artificial intelligence (AI) has emerged as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:XiSMed-E-HIC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Radial sampling pattern is an important signal acquisition strategy in magnetic resonance imaging (MRI) owing to better immunity to motion-induced artifacts and less pronounced aliasing due to undersampling compared to the Cartesian sampling. These advantages of radial sampling can be exploited in acquisition of multidimensional signals such as High Angular Resolution Diffusion Imaging (HARDI), with tremendous scope of acceleration. Despite such benefits, gradient delays lead to samples being acquired from unknown miscentered radial trajectories, severely degrading the image reconstruction quality. In the present work, we propose Csr-Pert that is a joint framework, wherein these perturbed radial trajectories are estimated and utilized for image reconstruction from the compressively sensed measurements of (i) MRI data and (ii) HARDI data. The proposed Csr-Pert method is tested on one real MRI …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:OU6Ihb5iCvQC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In this work, we study non-parametric estimation of joint probabilities of a given set of discrete and continuous ran-dom variables from their (empirically estimated) 2D marginals, under the assumption that the distribution could be approxi-mated by a mixture of product densities/mass functions. Estimation of joint probability density function using semi-parametric techniques such as Gaussian Mixture Models (GMMs) is widely studied. However, they yield poor results when the underlying densities are mixtures of various other families such as Laplacian, generalized Gaussian, uniform, etc. Further, GMMs are not the best choice to estimate distributions which are hybrid in nature, i.e., when it contains both discrete and continuous components. We present a novel approach for estimating the distribution using ideas from dictionary representations in signal processing coupled with low rank tensor decomposition. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:uWQEDVKXjbEC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In this paper, we consider compressive inversion of a signal/image that is sparse in typical orthonormal bases used in image processing, given its measurements that have been corrupted by Poisson noise. The square-root operation is known to convert a Poisson random variable into one that is approximately Gaussian distributed with a constant variance. We present two different computationally tractable, penalized estimators with a data-fidelity term based on the aforementioned square-root based ‘variance stabilization transform’. The first estimator has been proposed earlier in the literature, but this is the first paper to analyze its theoretical performance in compressed sensing. Our second estimator is completely novel, and also has the interesting statistical property of being an approximately pivotal estimator. For both estimators, we specifically consider the case of a physically realistic sensing matrix in our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:cFHS6HbyZ2cC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"This paper addresses the task of projection design for source separation in the compressive domain, where one observes a compressed linear mixture of two source signals with known priors. By positioning that both the sources follow a Gaussian mixture, we formulate an objective that tightly approximates the minimum mean squared error and solve the optimization problem using a gradient-based approach. In the blind setting, where the mixing ratio unknown, we propose a cross-validation approach to independently estimate the mixing ratio. We also provide a number of numerical results on synthetic and real image data that validate our findings. To the best of our knowledge, this is the first effort in projection design for prior-based source separation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:TFP_iSt0sucC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In this paper, we present an algorithm to automatically construct all the conformations of a heterogeneous planar object from their tomographic projections at random unknown view angles. Our statistically motivated approach can reveal and analyze the heterogeneity in the projection dataset and segregate the projections belonging to different structures without requiring prior structural information or templates, expert human intervention or even the knowledge of the number of conformations present in the sample. Even in the presence of high noise variance (low SNR) and a large number of conformations, our algorithm can estimate the structures of each conformation to a high degree of accuracy. We demonstrate the broad applicability of our algorithm by evaluating its performance on synthetic 2D datasets of well-known protein complexes such as Lipase under varying levels of noise and different number of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:RHpTSmoSYBkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,We present an algorithm for image denoising under Poisson noise using the theory of variance stabilization transforms. We derive worst-case performance bounds for our algorithm. Our proposed estimator allows for easy and very principled parameter tuning unlike existing approaches which require specification of signal dependent parameters. Moreover our estimator is computationally tractable. We also demonstrate numerical results on image denoising under Poisson noise to support the theoretical results.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:HDshCWvjkbEC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In this paper, we present an algorithm for effectively reconstructing an object from a set of its tomographic projections without any knowledge of the viewing directions or any prior structural information, in the presence of pathological amounts of noise, unknown shifts in the projections, and outliers among the projections. The outliers are mainly in the form of a number of projections of a completely different object, as compared to the object of interest. We introduce a novel approach of first processing the projections, then obtaining an initial estimate for the orientations and the shifts, and then define a refinement procedure to obtain the final reconstruction. Even in the presence of high noise variance (up to of the average value of the (noiseless) projections) and presence of outliers, we are able to successfully reconstruct the object. We also provide interesting empirical comparisons of our method with the sparsity based optimization procedures that have been used earlier for image reconstruction tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:hC7cP41nSMkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In this paper, we describe a method for estimating the joint probability density from data samples by assuming that the underlying distribution can be decomposed as a mixture of product densities with few mixture components. Prior works have used such a decomposition to estimate the joint density from lower-dimensional marginals, which can be estimated more reliably with the same number of samples. We combine two key ideas: dictionaries to represent 1-D densities, and random projections to estimate the joint distribution from 1-D marginals, explored separately in prior work. Our algorithm benefits from improved sample complexity over the previous dictionary-based approach by using 1-D marginals for reconstruction. We evaluate the performance of our method on estimating synthetic probability densities and compare it with the previous dictionary-based approach and Gaussian Mixture Models (GMMs). Our algorithm outperforms these other approaches in all the experimental settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:08ZZubdj9fEC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"It is well known that a band-limited signal can be reconstructed from its uniformly spaced samples if the sampling rate is sufficiently high. More recently, it has been proved that one can reconstruct a 1D band-limited signal even if the exact sample locations are unknown, but given just the distribution of the sample locations and their ordering in 1D. In this work, we extend the analytical bounds on the reconstruction error in such scenarios for quasi-bandlimited signals. We also prove that the method for such a reconstruction is resilient to a certain proportion of errors in the specification of the sample location ordering. We then express the problem of tomographic reconstruction of 2D images from 1D Radon projections under unknown angles with known angle distribution, as a special case for reconstruction of quasi-bandlimited signals from samples at unknown locations with known distribution. Building upon our theoretical background, we present asymptotic bounds for 2D quasi-bandlimited image reconstruction from 1D Radon projections in the unknown angles setting, which commonly occurs in cryo-electron microscopy (cryo-EM). To the best of our knowledge, this is the first piece of work to perform such an analysis for 2D cryo-EM, even though the associated reconstruction algorithms have been known for a long time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Videos shot by laymen using hand-held cameras contain undesirable shaky motion. Estimating the global motion between successive frames, in a manner not influenced by moving objects, is central to many video stabilization techniques, but poses significant challenges. A large body of work uses 2D affine transformations or homography for the global motion. However, in this work, we introduce a more general representation scheme, which adapts any existing optical flow network to ignore the moving objects and obtain a spatially smooth approximation of the global motion between video frames. We achieve this by a knowledge distillation approach, where we first introduce a low pass filter module into the optical flow network to constrain the predicted optical flow to be spatially smooth. This becomes our student network, named as GlobalFlowNet. Then, using the original optical flow network as the teacher …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:738O_yMBCRsC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Group testing can help maintain a widespread testing program using fewer resources amid a pandemic. In a group testing setup, we are given n samples, one per individual. Each individual is either infected or uninfected. These samples are arranged into m < n pooled samples, where each pool is obtained by mixing a subset of the n individual samples. Infected individuals are then identified using a group testing algorithm. In this paper, we incorporate side information (SI) collected from contact tracing (CT) into nonadaptive/single-stage group testing algorithms. We generate different types of possible CT SI data by incorporating different possible characteristics of the spread of the disease. These data are fed into a group testing framework based on generalized approximate message passing (GAMP). Numerical results show that our GAMP-based algorithms provide improved accuracy. Compared to a loopy belief propagation algorithm, our proposed framework can increase the success probability by 0.25 for a group testing problem of n = 500 individuals with m = 100 pooled samples.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:u9iWguZQMMsC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Methods and systems for determining viruses in biological samples using a single round based pooling. Embodiments disclosed herein relate to quantitative testing of biological samples, and more particularly to a quantitative, non-adaptive and single round pooling method for testing of viruses (for example: Coronavirus disease of 2019 (COVID-19), Severe Acute Respiratory Syndrome (SARS), or the like) in biological samples of individuals.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:nb7KW1ujOQ8C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Tomographic reconstruction from undersampled measurements is a necessity when the measurement process is potentially harmful, needs to be rapid, or is resource-expensive. In such cases, information from previously existing longitudinal scans of the same object (‘object-prior’) helps in the reconstruction of the current object (‘test’) from its significantly fewer measurements. A common problem with these techniques is the influence of object-priors in the reconstruction of new changes in the test. In this work, we mitigate this problem by first estimating the location of changes (‘new regions’) and then imposing object-prior in only those regions which are similar to the prior (‘old regions’). Our work is based on longitudinal data acquisition scenarios where we wish to study new changes that evolve within an object over time, such as in repeated scanning for disease monitoring, or in tomography-guided surgical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:1sJd4Hv_s6UC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Diffusion magnetic resonance imaging (dMRI) is being extensively used to study the neural architecture of the brain. High angular resolution diffusion imaging (HARDI), a variant of diffusion MRI, measures the diffusion of water molecules along the angular gradient directions in the q-space. It provides better estimates of fiber orientations compared to the traditionally used diffusion tensor imaging (DTI). However, HARDI requires acquisition of relatively large number of samples leading to longer scanning times. Several approaches based on compressive sensing (CS) have been proposed to accelerate HARDI acquisition, leveraging on the sparse representation of the HARDI signal in a pre-specified sparsifying basis. In this paper, we propose to carry out reconstruction of compressively sensed HARDI data using an adaptively learned transform. The transform is learned (i) from the compressive measurements on-the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:abG-DnoFyZgC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"In this work, we study non-parametric estimation of joint probabilities of a given set of discrete and continuous random variables from their (empirically estimated) 2D marginals, under the assumption that the joint probability could be decomposed and approximated by a mixture of product densities/mass functions. The problem of estimating the joint probability density function (PDF) using semi-parametric techniques such as Gaussian Mixture Models (GMMs) is widely studied. However such techniques yield poor results when the underlying densities are mixtures of various other families of distributions such as Laplacian or generalized Gaussian, uniform, Cauchy, etc. Further, GMMs are not the best choice to estimate joint distributions which are hybrid in nature, i.e., some random variables are discrete while others are continuous. We present a novel approach for estimating the PDF using ideas from dictionary representations in signal processing coupled with low rank tensor decompositions. To the best our knowledge, this is the first work on estimating joint PDFs employing dictionaries alongside tensor decompositions. We create a dictionary of various families of distributions by inspecting the data, and use it to approximate each decomposed factor of the product in the mixture. Our approach can naturally handle hybrid -dimensional distributions. We test our approach on a variety of synthetic and real datasets to demonstrate its effectiveness in terms of better classification rates and lower error rates, when compared to state of the art estimators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:CHSYGLWDkRkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"As compared to using randomly generated sensing matrices, optimizing the sensing matrix w.r.t. a carefully designed criterion is known to lead to better quality signal recovery given a set of compressive measurements. In this paper, we propose generalizations of the well-known mutual coherence criterion for optimizing sensing matrices starting from random initial conditions. We term these generalizations as bi-coherence or tri-coherence and they are based on a criterion that discourages any one column of the sensing matrix from being close to a sparse linear combination of other columns. We also incorporate training data to further improve the sensing matrices through weighted coherence, weighted bi-coherence, or weighted tri-coherence criteria, which assign weights to sensing matrix columns as per their importance. An algorithm is also presented to solve the optimization problems. Finally, the effectiveness of the proposed algorithm is demonstrated through empirical results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:EUQCXRtRnyEC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Compressed sensing (CS) involves sampling signals at rates less than their Nyquist rates and attempting to reconstruct them after sample acquisition. Most such algorithms have parameters, for example the regularization parameter in LASSO, which need to be chosen carefully for optimal performance. These parameters can be chosen based on assumptions on the noise level or signal sparsity, but this knowledge may often be unavailable. In such cases, cross validation (CV) can be used to choose these parameters in a purely data-driven fashion. Previous work analyzing the use of CV in CS has been based on the cross-validation error with Gaussian measurement noise. But it is well known that the error is not robust to impulse noise and provides a poor estimate of the recovery error, failing to choose the best parameter. Here we propose using the error which provides substantial performance benefits given …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:zA6iFVUQeVQC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Most compressed sensing algorithms do not account for the effect of saturation in noisy compressed measurements, though saturation is an important consequence of the limited dynamic range of existing sensors. The few algorithms that handle saturation effects either simply discard saturated measurements, or impose additional constraints to ensure consistency of the estimated signal with the saturated measurements (based on a known saturation threshold) given uniform-bounded noise. In this paper, we instead propose a new data fidelity function which is directly based on ensuring a certain form of consistency between the signal and the saturated measurements, and can be expressed as the negative logarithm of a certain carefully designed likelihood function. Our estimator works even in the case of Gaussian noise (which is potentially unbounded) in the measurements. We prove that our data fidelity function …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:3s1wT3WcHBgC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Compressed Sensing assumes a linear model for acquiring signals however imperfections may arise in the specification of the ‘ideal’ measurement model. We present the first study which considers the case of two such common calibration issues: (a) unknown measurement scaling (sensor gains) due to hardware vagaries or due to unknown object motion in MRI scanning, in conjunction with (b) unknown offsets to measurement frequencies in case of a Fourier measurement matrix. We propose an alternating minimisation algorithm for on-the-fly signal recovery in the case when errors (a) and (b) occur jointly. We show simulation results over a variety of situations that outperform the baselines of signal recovery by ignoring either or both types of calibration errors. We also show theoretical results for signal recovery by introducing a perturbed version of the well-known Generalized Multiple Measurement Vectors …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:dfsIfKJdRG4C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Given a set of N random variables X1, X2,..., XN, estimating the joint density p (X1, X2,..., XN) is a fundamental problem in many fields such as statistics and machine learning. This probabilistic interpretation can help us make may inferences to help us aid take better decisions for the problem in hand. For a simple example, take X1 as the time taken to drive to a particular destination and Xi, 2≤ i≤ N denote a scalar number indicating the traffic on the N− 1 streets. We would want to make predictions such as the minimum time needed for reaching the destination given we somehow know the traffic profiles of all the streets, ie more formally, we would want to find the following: min p (X1| X2, X3,..., XN). Maximum a posteriori (MAP) estimation of the joint probability density is used in classification problems. Probabilistic models can also be used for anomaly detection in various fields like law, medicine. Capturing the joint density is helpful as we can infer a variety of queries of such form easily (?). Most the work done can be classified in a few categories namely:
1. If the realisations of these random variables are discrete, then standard histogramming would work but it requires a large number of samples (exponential in N) to make the estimate of the joint close to the actual density and is clearly not scalable for large N. In the big data era, it is very common for data to be high dimensional (an image of size 200× 200 is 40k dimensional), and hence such a naive approach for modelling densities without accounting for the inherent structure which data posseses fails in these scenarios.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:_xSYboBqXhAC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Compressed sensing is a signal processing technique for efficiently acquiring and reconstructing a signal, by finding solutions to underdetermined linear systems. The signals are generally undersampled below Nyquist rate and then a lossy reconstruction is performed. For reconstruction, the sparsity of signals in certain bases is exploited. Generally for images, these bases could be DCT (Discrete Cosine Transform), Wavelet, Fourier or even dictionaries learned using training data. For reconstruction, algorithms such as OMP or LASSO are generally used.
Let x be the signal and be the sensing matrix. Then=· represent the measurements which we obtain. Since x is a sparse signal in some basis, let= where D is the basis and is the sparse vector. Then the compressed sensing problems tries to find using y and=·",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:pyW8ca7W8N0C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"We have previously described Tapestry Pooling, a scheme to enhance the capacity of RT-qPCR testing, and provided experimental evidence with spiked synthetic RNA to show that it can help to scale testing and restart the economy. Here we report on validation studies with Covid19 patient samples for the Tapestry Pooling scheme with prevalence in the range of 1% to 2%. We pooled RNA extracted from patient samples that were previously tested for Covid19, sending each sample to three pools. Following three different pooling schemes, we pipetted 320 samples into 48 pools with pool size of 20 at prevalence rate of 1.6%, 500 samples into 60 pools with pool size of 25 at prevalence rate of 2%, and 961 samples into 93 pools with pool size of 31 at prevalence rate of 1%. Of the 191 RT-qPCR experiments that we performed, only one pool was incorrect (false negative). Our recovery algorithm correctly called results for the individual samples, with a 100% sensitivity and a 99.9% specificity, with only one false positive across all the 1,781 blinded results required to be called. We show up to 10X savings in number of tests required at a range of prevalence rates and pool sizes. These experiments establish that Tapestry Pooling is robust enough to handle the diversity of sample constitutions and viral loads seen in real-world samples.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:pqnbT2bcN3wC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"The COVID-19 pandemic has strained testing capabilities worldwide. There is an urgent need to find economical and scalable ways to test more people. We present Tapestry, a novel quantitative nonadaptive pooling scheme to test many samples using only a few tests. The underlying molecular diagnostic test is any real-time RT-PCR diagnostic panel approved for the detection of the SARS-CoV-2 virus. In cases where most samples are negative for the virus, Tapestry accurately identifies the status of each individual sample with a single round of testing in fewer tests than simple two-round pooling. We also present a companion Android application BYOM Smart Testing which guides users through the pipetting steps required to perform the combinatorial pooling. The results of the pooled tests can be fed into the application to recover the status and estimated viral load for each individual sample.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:tOudhMTPpwUC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Low-dose tomography is highly preferred in medical procedures for its reduced radiation risk when compared to standard-dose Computed Tomography (CT). However, the lower the intensity of X-rays, the higher the acquisition noise and hence the reconstructions suffer from artefacts. A large body of work has focussed on improving the algorithms to minimize these artefacts. In this work, we propose two new techniques, rescaled non-linear least squares and Poisson-Gaussian convolution, that reconstruct the underlying image making use of an accurate or near-accurate statistical model of the noise in the projections. We also propose a reconstruction method when prior knowledge of the underlying object is available in the form of templates. This is applicable to longitudinal studies wherein the same object is scanned multiple times to observe the changes that evolve in it over time. Our results on 3D data show that prior information can be used to compensate for the low-dose artefacts, and we demonstrate that it is possible to simultaneously prevent the prior from adversely biasing the reconstructions of new changes in the test object, via a method called ``re-irradiation''. Additionally, we also present two techniques for automated tuning of the regularization parameters for tomographic inversion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:D03iK_w7-QYC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"We present a technique for compressive phase retrieval under Poisson noise using the theory of variance stabilization transforms (VSTs). We modify two existing algorithms using VSTs, and derive worst-case performance bounds for both the algorithms. Our proposed modification allows for easy and very principled parameter tuning. Our estimator is tractable and we also show numerical results on phase recovery of sparse signals for Poisson corrupted measurements, and demonstrate the relative advantage of our modification at low intensities. We also present a comparison of the performance and other theoretical aspects of both the algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:isC4tDSrTZIC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"The need for tomographic reconstruction from sparse measurements arises when the measurement process is potentially harmful, needs to be rapid, or is uneconomical. In such cases, information from previous longitudinal scans of the same object helps to reconstruct the current object while requiring significantly fewer updating measurements. Our work is based on longitudinal data acquisition scenarios where we wish to study new changes that evolve within an object over time, such as in repeated scanning for disease monitoring, or in tomography-guided surgical procedures. While this is easily feasible when measurements are acquired from a large number of projection views, it is challenging when the number of views is limited. If the goal is to track the changes while simultaneously reducing sub-sampling artefacts, we propose (1) acquiring measurements from a small number of views and using a global unweighted prior-based reconstruction. If the goal is to observe details of new changes, we propose (2) acquiring measurements from a moderate number of views and using a more involved reconstruction routine. We show that in the latter case, a weighted technique is necessary in order to prevent the prior from adversely affecting the reconstruction of new structures that are absent in any of the earlier scans. The reconstruction of new regions is safeguarded from the bias of the prior by computing regional weights that moderate the local influence of the priors. We are thus able to effectively reconstruct both the old and the new structures in the test. In addition to testing on simulated data, we have validated the efficacy of our method on real …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:maZDTaKrznsC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"Traditionally, direction of arrival (DOA) estimation techniques have been based on spectral estimation methods utilizing signal and noise subspaces [1]. Such techniques perform well when sensor measurements are available at multiple snapshots. Recently, compressed sensing (CS) based DOA estimation techniques have been introduced, which improve source localization in the single snapshot case by modeling the angle search as a sparse recovery problem. In this domain, various on-grid and off-grid methods have been proposed in the existing literature [2] [3] [4]. The on-grid methods rely on a fixed basis and solve traditional CS based sparse recovery problems while the latter has modifications based on first-order Taylor approximation of the array manifold matrix. In this paper, we present an off-grid CS based formulation, where we employ an alternating minimization strategy for fine-grid search of source …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:R3hNpaxXUhUC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",15,"We present an estimator, based on the Anscombe transform, for the problem of low-rank matrix recovery under Poisson noise. We derive an upper bound on the matrix reconstruction error for this estimator, considering a linear sensing operator which obeys realistic constraints like non-negativity and flux-preservation. Besides being computationally tractable (convex), our estimator also allows for principled parameter tuning. Moreover, our method is capable of handling Poisson-Gaussian noise and the case where the Poisson or Poisson-Gaussian corrupted measurements are uniformly quantized. In addition to our theoretical results, we present some numerical results for Poisson low-rank matrix recovery under varying intensity levels and number of measurements.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&citation_for_view=CkTW7PwAAAAJ:mB3voiENLucC,http://www.cse.iitb.ac.in/~ajitvr
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",84,"Data driven building energy consumption forecasting models play a significant role in enhancing the energy efficiency of the buildings through building energy management, energy operations, and control strategies. The multi-source and heterogeneous energy consumption data necessitates the integration of evolutionary algorithms and data-driven models for better forecast accuracy and robustness. We present eDemand, an energy consumption forecasting model which employs long short term memory networks and improved sine cosine optimization algorithm for accurate and robust building energy consumption forecasting. A novel Haar wavelet based mutation operator was introduced to enhance the divergence nature of sine cosine optimization algorithm towards the global optimal solution. Further, the hyperparameters (learning rate, weight decay, momentum, and number of hidden layers) of the LSTM …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&citation_for_view=LFLG5pcAAAAJ:17ZO-CJnx_8C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",84,"Increasing global building energy demand, with the related economic and environmental impact, upsurges the need for the design of reliable energy demand forecast models. This work presents k CNN-LSTM, a deep learning framework that operates on the energy consumption data recorded at predefined intervals to provide accurate building energy consumption forecasts. k CNN-LSTM employs (i) k− means clustering–to perform cluster analysis to understand the energy consumption pattern/trend;(ii) Convolutional Neural Networks (CNN)–to extract complex features with non-linear interactions that affect energy consumption; and (iii) Long Short Term Memory (LSTM) neural networks–to handle long-term dependencies through modeling temporal information in the time series data. The efficiency and applicability of k CNN-LSTM were demonstrated using a real time building energy consumption data acquired …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&citation_for_view=LFLG5pcAAAAJ:LWqeokA2EBkC,http://www.cse.iitb.ac.in/~krithi
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Hardware prefetching is one of the common off-chip DRAM latency hiding techniques. Though hardware prefetchers are ubiquitous in the commercial machines and prefetching techniques are well studied in the computer architecture community, the “memory wall” problem still exists after decades of microarchitecture research and is considered to be an essential problem to solve. In this paper, we make a case for breaking the memory wall through data prefetching at the L1 cache.We propose a bouquet of hardware prefetchers that can handle a variety of access patterns driven by the control flow of an application. We name our proposal Instruction Pointer Classifier based spatial Prefetching (IPCP). We propose IPCP in two flavors: (i) an L1 spatial data prefetcher that classifies instruction pointers at the L1 cache level, and issues prefetch requests based on the classification, and (ii) a multi-level IPCP where the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&citation_for_view=ZGZkHzcAAAAJ:4JMBOYKVnBMC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Micro-architectural attacks exploit timing channels at different micro-architecture units. Some of the micro-architecture units like cache automatically provide the timing difference (the difference between a hit and a miss). However, there are other units that are not documented, and their influence on the timing difference is not fully understood. One such micro-architecture unit is an L2 hardware prefetcher named Streamer. In this paper, we reverse-engineer the Stream prefetcher, which is commercially available in the Intel machines. We perform a set of experiments and provide our observations and insights. Further, we use these observations to construct a cross-thread covert channel using the Stream prefetcher, with an accuracy of 91.3% and a bandwidth of 54.44 KBps.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&citation_for_view=ZGZkHzcAAAAJ:iH-uZ7U-co4C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Cross-core last-level cache (LLC) eviction based side-channel attacks are becoming practical because of the inclusive nature of shared resources (e.g., an inclusive LLC), that creates back-invalidation-hits at the private caches. Most of the cross-core eviction based side-channel attack strategies exploit the same for a successful attack. The fundamental principle behind all the cross-core eviction attack strategies is that the attacker can observe LLC access time differences (in terms of latency differences between events such as hits/misses) to infer about the data used by the victim. We fool the attacker (by providing LLC hits to the addresses of interest) through a back-invalidation-hits triggered hardware prefetching technique (BITP). BITP is an L2 cache level hardware prefetcher that prefetches the back-invalidated block addresses and refills the LLC (along with the L2) before the attacker's observation/access …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&citation_for_view=ZGZkHzcAAAAJ:_Qo2XoVZTnwC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Over the past few years, Android has become one of the most popular operating systems for smartphones as it is open-source and provides extensive support for wide variety of applications. This has led to an increase in the number of malware targeting Android devices. The lack of robust security enforcement in Play Store along with the rapid increase in the number of new Android malware presents a scope for a variety of diverse malicious applications to spread across devices. Further-more, Android allows installation of an application from unver-ified sources (e.g., third-party market and sideloading), which opens up other ways for mal ware to infect the smartphones. This paper presents DeepDetect that enables on-device malware detection by employing a machine learning based model on static features. With effective feature engineering, DeepDetect can be used on-device. To classify an Android application …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&citation_for_view=ZGZkHzcAAAAJ:GnPB-g6toBAC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Hardware data prefetching is a latency hiding technique that mitigates the memory wall problem by fetching data blocks into caches before the processor demands them. For high performing state-of-the-art data prefetchers, this increases dynamic and static energy in memory hierarchy, due to increase in number of requests. A trivial way to improve energy-efficiency of hardware prefetchers is to prefetch instructions on the critical path of execution. As criticality-based data prefetching does not degrade performance significantly; this is an ideal approach to solve the energy-efficiency problem. We discuss limitations of existing critical instruction detection techniques and propose a new technique that uses re-order buffer occupancy as a metric to detect critical instructions and performs prefetcher-specific threshold tuning. With our detector, we achieve maximum memory hierarchy energy savings of 12.3% with 1.4 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&citation_for_view=ZGZkHzcAAAAJ:NMxIlDl6LWMC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Sophisticated malware employs various emulation-detection techniques to bypass the dynamic analysis systems that are running on top of virtualized environments. Hence, a defense mechanism needs to be incorporated in emulation based analysis platforms to mitigate the emulation-detection strategies opted by malware. In this paper, first we design an emulation-detection library that has configurable capabilities ranging from basic to advanced detection techniques like distributed detection and GPS information. We use this library to arm several existing malware with different levels of emulation-detection capabilities and study the efficacy of anti-emulation-detection measures of well known emulator driven dynamic analysis frameworks. Furthermore, we propose STDNeut (Sensor, Telephony system, and Device state information Neutralizer) – a configurable anti-emulation-detection mechanism that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&citation_for_view=ZGZkHzcAAAAJ:bEWYMUwI8FkC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Through this paper, we propose an instruction pointer classifier based hardware prefetching technique for the DPC-3. We use multiple instruction pointer based prefetchers that suit different access patterns and overall cover a wide spectrum of access patterns. Our classifier classifies instruction pointers at the L1 cache level and communicate the same to the L2 prefetcher. Our prefetching framework named Instruction Pointer Classifier based Prefetching (IPCP) provides 43.75% improvement for single-core and 22% for 25 selectively chosen multi-core mixes, respectively. IPCP demands a hardware overhead of 16.7 KB per core.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&citation_for_view=ZGZkHzcAAAAJ:g5m5HwL7SMYC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Recent advances in research on compressed caches make them an attractive design point for effective hardware implementation for last-level caches. For instance, the yet another compressed cache (YACC) layout leverages both spatial and compression factor localities to pack compressed contiguous memory blocks from a 4-block super-block in a single cache block location. YACC requires less than 2% extra storage over a conventional uncompressed cache.
Performance of LLC is also highly dependent on its cache block replacement management. This includes allocation and bypass decision on a miss as well as replacement target selection which is guided by priority insertion policy on allocation and priority promotion policy on a hit. YACC uses the same cache layout as a conventional set-associative uncompressed cache Therefore the LLC cache management policies that were introduced during the past …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&citation_for_view=ZGZkHzcAAAAJ:ZeXyd9-uunAC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Large instruction working sets are common with modern client and server workloads. These working sets often fit in the large last-level cache (LLC). However, the L1 instruction cache (L1-I) suffers from a high miss rate blocking the instruction supply to the front-end of the processor. Instruction prefetching is a latency hiding technique that can bring instructions from the LLC into the L1-I. We propose a bouquet of instruction pointer (IP) jumpers, named JIP. JIP is a high-performance L1-I prefetcher that uses different prefetching techniques by classifying instructions into the following categories:(i) a nonbranch,(ii) a branch that jumps to a single target IP on all instances, and (iii) a branch that jumps to different target IPs on different instances. Compared to a baseline with no instruction prefetching, averaged across 50 traces, JIP provides a prefetch coverage of 91.33%(as high as 99.99%), which leads to a performance improvement of 27.75%(as high as 93%). JIP makes a strong case for instruction prefetching as the performance gap between the perfect L1-I and JIP is just 7.49%. JIP demands a hardware overhead of 127.8 KB.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:j3f4tGmQtD8C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Cross-core last-level cache based side-channel attacks are becoming practical, affecting all forms of computing devices like mobiles, desktops, servers, and cloud based systems. Mitigating last-level cache based side channel attacks has become an active area of research and many proposals target to mitigate cross-core based conflict attacks. Secure Cache Hierarchy Aware Replacement Policy (SHARP) is one of the recent proposals that mitigate the conflict attacks by changing the underlying last-level cache replacement policy. Though SHARP is an elegant proposal; there are many subtle points, which were not part of the original SHARP proposal that appeared in the ISCA’17. Through this paper, we discuss and debate the subtle issues that are left unanswered in the original SHARP paper.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:HDshCWvjkbEC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Value prediction is one of the promising micro-architectural techniques to improve the processor performance. Through this paper, we provide a series of four enhancements that we apply on top of Differential Finite Context-Method (DFCM) value predictor and call it DFCM++. Our design achieves a geomean IPC of 4.11 whereas the baseline system, without any value predictor, provides a geomean IPC of 3.21 (an improvement of 28.1%). In comparison to the baseline DFCM, which provides a geomean IPC of 2.93, DFCM++ delivers an improvement of 40.2%. Additionally, we show the effectiveness of our enhancements on some of the state-of-the-art value predictors such as VTAGE and DVTAGE.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:mVmsd5A6BfQC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Cross-core conflict-based timing attacks like Prime+Probe at the shared last-level cache (LLC) are practical and can cause information leakage. Cache address randomization is one of the techniques that claim to mitigate these attacks. CEASER, CEASER-S, and ScatterCache are the three recent randomized caches that use encryption engines to randomize the memory address mapping. CEASER and CEASER-S, along with encryption engines, remap the cache blocks periodically to break the static mapping of memory blocks into the LLC blocks. Encryption engine and remapping provide security to the randomized caches. However, access to encryption engines and the remapping of cache blocks are on the critical path of LLC accesses. We target encryption engine and remapping of randomized cache to mount a denial of service (DoS) attack named DAMARU. In DAMARU, the attacker frequently sends memory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:JV2RwH3_ST0C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Flush based cache attacks like Flush+ Reload and Flush+ Flush are one of the highly effective cache attacks. In fact, the Flush+ Flush attack is stealthy too. Most of the flush based attacks provide high accuracy in controlled environments where attacker and victim are the only two processes that are running on a system by sharing OS pages. However, we observe that these attacks lose their effectiveness (prone to low accuracy) on a noisy multi-core system where co-running applications run along with the attacker and the victim. Two root causes for the varying accuracy of flush based attacks are:(i) the dynamic nature of core frequencies that fluctuate depending on the system load, and (ii) the relative placement of victim and attacker threads in the processor (same logical core, same physical core, different physical cores). The variation in the processor frequencies and placement of threads affect one of the critical attack steps (the cache latency calibration step as the latency threshold set to distinguish a cache hit from a miss becomes inaccurate). We propose a set of refinements (DABANGG refinements) to make existing flush attacks resilient to frequency changes and thread placement in the processor, and therefore system noise. We propose refinements to pre-attack and attack steps and make it conscious about the latency change. We evaluate DABANGG-enabled Flush+ Reload and Flush+ Flush attacks (DABANGG+ Flush+ Reload and DABANGG+ Flush+ Flush, respectively) against the standard Flush+ Reload and Flush+ Flush attacks across four scenarios for eight different combinations of system noise capturing different levels of compute …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:r0BpntZqJG4C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Memory deduplication in virtualized systems is shown to be a very useful memory optimization as it is simple to use and provides memory efficient cloud hosting. However, memory deduplication based side channel attacks---information disclosure attacks and covert channel construction across virtual machines---can be mounted using the timing information available because of Copy-on-Write (CoW) fault handling semantics. The CoW semantic has been a necessary-evil with regard to deduplication as it plays a vital role in supporting guest OS transparent deduplication but enables a timing channel for exploitation. Thus to decimate the huge access time difference between a normal write and a write to a shared page, we propose CoWLight, a combination of hardware and software techniques for handling the CoW page faults in an efficient manner. In this work, we propose to address the security issues at its …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:hC7cP41nSMkC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"With the inception of the Spectre attack in 2018, microarchitecture mitigation strategies propose secure cache hi-erarchies that do not leak the speculative state. Among many mitigation strategies, MuonTrap, proposes an efficient, secure cache hierarchy that provides speculative attack resiliency with minimum performance slowdown. Hardware prefetchers play a significant role in improving application performance by fetching and bringing data and instructions into caches before time. To prevent hardware prefetchers from leaking information about the speculative blocks brought into the cache, MuonTrap trains and triggers hardware prefetchers on the committed instruction streams, eliminating speculative state leakage. We find that on-commit prefetching can lead to significant performance slowdown as high as 20.46 % (primarily because of prefetch timeliness issues), making hardware prefetchers less effective …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:YFjsv_pBGBYC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Flush-based cache attacks like Flush+Reload and Flush+Flush are highly precise and effective. Most of the flush-based attacks provide high accuracy in controlled and isolated environments where attacker and victim share OS pages. However, we observe that these attacks are prone to low accuracy on a noisy multi-core system with co-running applications. Two root causes for the varying accuracy of flush-based attacks are: (i) the dynamic nature of core frequencies that fluctuate depending on the system load, and (ii) the relative placement of victim and attacker threads in the processor, like same or different physical cores. These dynamic factors critically affect the execution latency of key instructions like clflush and mov, rendering the pre-attack calibration step ineffective.We propose DABANGG, a set of novel refinements to make flush-based attacks resilient to system noise by making them aware of frequency …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:J_g5lzvAfSwC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"High-performance branch target buffers (BTBs) and the L1I cache are key to high-performance front-end. Modern branch predictors are highly accurate, but with an increase in code footprint in modern-day server workloads, BTB and L1I misses are still frequent. Recent industry trend shows usage of large BTBs (100s of KB per core) that provide performance closer to the ideal BTB along with a decoupled front-end that provides efficient fetch-directed L1I instruction prefetching. On the other hand, techniques proposed by academia, like BTB prefetching and using retire order stream for learning, fail to provide significant performance with modern-day processor cores that are deeper and wider.
We solve the problem fundamentally by increasing the storage density of the last-level BTB. We observe that not all branch instructions require a full branch target address. Instead, we can store the branch target as a branch …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:RGFaLdJalmkC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Recent trends of the use of deep neural networks (DNNs) in mission-critical applications have increased the threats of microarchitectural attacks on DNN models. Recently, researchers have proposed techniques for inferring the DNN model based on microarchitecture-level clues. However, existing techniques require prior knowledge of victim models, lack generality, or provide incomplete information of the victim model architecture. This paper proposes an attack that leaks the layer-type of DNNs using hardware performance monitoring counters (PMCs).
Our attack works by profiling low-level hardware events and then analyzes this data using machine learning algorithms. We also apply techniques for removing the class imbalance in the PMC traces and for removing the noise. We present microarchitectural insights (hardware PMCs such as cache accesses/misses, branch instructions, and total instructions) that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:hMod-77fHWUC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Cross-core cache attacks glean sensitive data by exploiting the fundamental interference at the shared resources like the last-level cache (LLC) and coherence directories. Complete non-interference will make cross-core cache attacks unsuccessful. To this end, we propose a seclusive cache hierarchy with zero storage overhead and a marginal increase in on-chip traffic, that provides non-interference by employing cache-privatization on demand. Upon a cross-core eviction by an attacker core at the LLC, the block is back-filled into the private cache of the victim core. Our back-fill strategy mitigates cross-core conflict based LLC and coherence directory-based attacks. We show the efficacy of the seclusive cache hierarchy by comparing it with existing cache hierarchies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:TFP_iSt0sucC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Value prediction has immense potential in improving performance of the modern day processors. Based on the CVP leaderboard, the ideal value predictor provides 107% speedup whereas the state-of-the-art EVES predictor provides 35.8% with an unlimited storage. Through this manuscript, we attempt to push the limits of EVES. We propose a finite context method based value predictor named Sliding FCM. A sliding window FCM stores the history of values for a particular instruction pointer and while predicting in the future, it matches the recent history of values with a relatively older set of values. In case of a match, it predicts the next value from the history of values as the value to predict. Sliding FCM coupled with EVES (we call it STEVES) improves the average performance to 37% with a maximum speedup of 1000%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:hFOr9nPyWt4C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"With wide adaptation of open-source Android into mobile devices by different device vendors, sophisticated malware are developed to exploit security vulnerabilities. As comprehensive security analysis on physical devices are impractical and costly, emulator-driven security analysis has gained popularity in recent times. Existing dynamic analysis frameworks suffer from two major issues: (i) they do not provide foolproof anti-emulation-detection measures even for fingerprint-based attacks, and (ii) they lack efficient cross-layer profiling capabilities. In this work, we present InviSeal, a comprehensive and scalable dynamic analysis framework that includes low-overhead cross-layer profiling techniques and detailed anti-emulation-detection measures along with the basic emulation features. While providing an emulator-based comprehensive analysis platform, InviSeal strives to remain behind-the-scene to avoid …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:ldfaerwXgEUC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Data prefetching is a technique that plays a crucial role in modern high-performance processors by hiding long latency memory accesses. Several state-of-the-art hardware prefetchers exploit the concept of deltas, defined as the difference between the cache line addresses of two demand accesses. Existing delta prefetchers, such as best offset prefetching (BOP) and multi-lookahead prefetching (MLOP), train and predict future accesses based on global deltas. We observed that the use of global deltas results in missed opportunities to anticipate memory accesses.In this paper, we propose Berti, a first-level data cache prefetcher that selects the best local deltas, i.e., those that consider only demand accesses issued by the same instruction. Thanks to a high-confidence mechanism that precisely detects the timely local deltas with high coverage, Berti generates accurate prefetch requests. Then, it orchestrates the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:2P1L_qKh6hAC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"On a multi-core system, the shared last-level cache(LLC) is vulnerable to various kinds of cross-core contention-based attacks. LLC randomization and LLC partitioning are two promising mitigation strategies that mitigate these attacks. LLC-randomization techniques make an attacker’s life difficult in mounting contention-based attacks but do not entirely mitigate them. Randomized caches are also ineffective in preventing occupancy-based attacks. In contrast, state-of-the-art LLC partitioning techniques mitigate all possible LLC contention-based attacks by allocating isolated LLC regions to different processes or security domains. However, restricting processes to isolated LLC region(s) affects overall LLC utilization and incurs performance overhead (as high as 72%) and memory subsystem energy overhead (as high as 89%); effectively providing security guarantee at the cost of performance and energy.One of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:70eg2SAEIzsC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Intel SGX preserves the confidentiality and integrity aspects of data and code through enclaves (that reside in the trusted part of the memory) and protects it from different layers of the malicious system software, including the OS. Micro-architecture research in the presence of SGX is an interesting theme to explore as SGX does not mitigate timing side-channel attacks at various levels of a memory hierarchy and causes significant performance slowdown. The research community extensively uses existing benchmark suites like SPEC CPU 2017 for evaluating new proposals on the various aspects of micro-architecture research. As there is no benchmark suite available for micro-architecture research with SGX, state-of-the-art micro-architecture research in the presence of SGX assumes an entire SPEC benchmark is running inside an enclave. In reality, Intel SGX assumes that a major portion of the application's code …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:ns9cj8rnVeAC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"With the large-scale adaptation of Android OS and ever-increasing contributions in the Android application space, Android has become the number one target of malware writers. In recent years, a large number of automatic malware detection and classification systems have evolved to tackle the dynamic nature of malware growth using either static or dynamic analysis techniques. Performance of static malware detection methods degrade due to the obfuscation attacks. Although many benchmark datasets are available to measure the performance of malware detection and classification systems, only a single obfuscated malware dataset (PRAGuard) is available to showcase the efficacy of the existing malware detection systems against the obfuscation attacks. PRAGuard contains outdated samples till March 2013 and does not represent the latest application categories. Moreover, PRAGuard does not provide the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:lSLTfruPkqcC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Usage of the execution stack at run-time captures the dynamic state of programs and can be used to derive useful insights into the program behaviour. The stack usage information can be used to identify and debug performance and security aspects of applications. Binary run-time instrumentation techniques are well known to capture the memory access traces during program execution. Tracing the program in entirety and filtering out stack specific accesses is a commonly used technique for stack related analysis. However, applying vanilla tracing techniques (using tools like Intel Pin) for multi-threaded programs has challenges such as identifying the stack areas to perform efficient run-time tracing.
In this paper, we introduce SniP, an open-source stack tracing framework for multi-threaded programs built around Intel's binary instrumentation tool Pin. SniP provides a framework for efficient run-time tracing of stack …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:RYcK_YlVTxYC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Performance of Translation Lookaside Buffers (TLBs) and on-chip caches plays a crucial role in delivering high-performance for memory-intensive applications with irregular memory accesses. Our observations show that, on average, an L2 TLB (STLB) miss for address translation can stall the head of the reorder buffer (ROB) for a maximum of 50 cycles. The corresponding data request, also called as the replay load can stall the head of the ROB for more than 200 cycles. We show that current state-of-the-art mid-level (L2C) and last-level cache (LLC) replacement policies do not treat cache block with address translations and replay data access differently. As a result these policies fail to reduce ROB stalls because of translation and replay data access misses. To improve the performance further on top of high-performing cache replacement policies, we propose address translation and replay data access conscious …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:NaGl4SEjCO4C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Non-volatile memory (NVM) provides persistent memory semantics with access latencies comparable to volatile DRAM. The persistent nature of NVM requires the application developers to design data consistency mechanisms for failure recovery, without which application may end up with inconsistent memory state after a power failure or a system crash. Most commonly employed methods use architectural support for cache line flushing and memory fencing to enforce ordering of writes to NVM. In this paper, we study the performance overhead of different hardware primitives used to achieve NVM consistency on Intel x86-64 and Arm64 systems using micro-benchmarks. Further, we also empirically analyze the impact of working set size and memory access characteristics (read-to-write ratio) of applications on different data consistency techniques. Logging based mechanisms (e.g., redo and undo logging …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:BqipwSGYUEgC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"Keystone is a trusted execution environment, based on RISC-V architecture. It divides the memory into a secure Keystone private memory and an unsecure non-Keystone memory, and allows code that lies inside the Keystone private memory to execute securely. Simple demand paging in Keystone ends up leaking sensitive access patterns of Keystone application to the Operating System(OS), that is assumed to be malicious. This is because, to access the unsecure non-Keystone memory, Keystone needs support of the OS. To mitigate this, Keystone needs to implement oblivious demand paging while obfuscating its page access patterns by using Oblivious RAM(ORAM) techniques. This causes substantial slowdown in the application execution. In this paper, we bridge the performance gap between application execution time with unsecure and secure demand paging in Keystone by using Deterministic, stash free, Write only ORAM (DetWoORAM) for oblivious demand paging. We also show why DetWoORAM, that is a write-only ORAM, is sufficient for oblivious demand paging. DetWoORAM logically partitions the memory into a main area and a holding area. The actual pages are stored in main area. We propose two enhancements over DetWoORAM that improves the application execution slowdown. The first enhancement, which we call the Eager DetWoORAM, involves page preloading that exploits the deterministic access pattern of DetWoORAM, and tries to hide the ORAM latency. The second enhancement, which we call the Parallel DetWoORAM, involves spawning multiple threads and each thread performs a part of the DetWoORAM …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:M3NEmzRMIkIC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,"High-performance branch target buffers (BTBs) and the L1I cache are key to high-performance front-end. Modern branch predictors are highly accurate, but with an increase in code footprint in modern-day server workloads, BTB and L1I misses are still frequent. Recent industry trend shows usage of large BTBs (100s of KB per core) that provide performance closer to the ideal BTB along with a decoupled front-end that provides efficient fetch-directed L1I instruction prefetching. On the other hand, techniques proposed by academia, like BTB prefetching and using retire order stream for learning, fail to provide significant performance with modern-day processor cores that are deeper and wider. We solve the problem fundamentally by increasing the storage density of the last-level BTB. We observe that not all branch instructions require a full branch target address. Instead, we can store the branch target as a branch offset, relative to the branch instruction. Using branch offset enables the BTB to store multiple branches per entry. We reduce the BTB storage in half, but we observe that it increases skewness in the BTB. We propose a skewed indexed and compressed last-level BTB design called MicroBTB (MBTB) that stores multiple branches per BTB entry. We evaluate MBTB on 100 industry-provided server workloads. A 4K-entry MBTB provides 17.61% performance improvement compared to an 8K-entry baseline BTB design with a storage savings of 47.5KB per core.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:k_IJM867U9cC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:blknAaTinKkC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",8,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&citation_for_view=ZGZkHzcAAAAJ:R3hNpaxXUhUC,https://www.cse.iitb.ac.in/~biswa
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"In September 2016, Stanford's ""One Hundred Year Study on Artificial Intelligence"" project (AI100) issued the first report of its planned long-term periodic assessment of artificial intelligence (AI) and its impact on society. It was written by a panel of 17 study authors, each of whom is deeply rooted in AI research, chaired by Peter Stone of the University of Texas at Austin. The report, entitled ""Artificial Intelligence and Life in 2030,"" examines eight domains of typical urban settings on which AI is likely to have impact over the coming years: transportation, home and service robots, healthcare, education, public safety and security, low-resource communities, employment and workplace, and entertainment. It aims to provide the general public with a scientifically and technologically accurate portrayal of the current state of AI and its potential and to help guide decisions in industry and governments, as well as to inform research and development in the field. The charge for this report was given to the panel by the AI100 Standing Committee, chaired by Barbara Grosz of Harvard University.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&citation_for_view=YZkeEqAAAAAJ:9ZlFYXVOiuMC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"In the future of India lies the future of a sixth of the world's population. As the Artificial Intelligence (AI) revolution sweeps through societies and enters daily life, its role in shaping India's development and growth is bound to be substantial. For India, AI holds promise as a catalyst to accelerate progress, while providing mechanisms to leapfrog traditional hurdles such as poor infrastructure and bureaucracy. At the same time, an investment in AI is accompanied by risk factors with long-term implications on society: it is imperative that risks be vetted at this early stage. In this paper, we describe opportunities and challenges for AI in India. We detail opportunities that are cross-cutting (bridging India's linguistic divisions, mining public data), and also specific to one particular sector (healthcare). We list challenges that originate from existing social conditions (such as equations of caste and gender). Thereafter we distill out …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&citation_for_view=YZkeEqAAAAAJ:L8Ckcad2t8MC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"We consider the problem of identifying any k out of the best m arms in an n-armed stochastic multi-armed bandit; framed in the PAC setting, this particular problem generalises both the problem of “best subset selection”(Kalyanakrishnan & Stone, 2010) and that of selecting “one out of the best m” arms (Roy Chaudhuri & Kalyanakrishnan, 2017). We present a lower bound on the worst-case sample complexity for general k, and a fully sequential PAC algorithm, LUCB-km, which is more sample-efficient on easy instances. Also, extending our analysis to infinite-armed bandits, we present a PAC algorithm that is independent of n, which identifies an arm from the best fraction of arms using at most an additive poly-log number of samples than compared to the lower bound, thereby improving over Roy Chaudhuri & Kalyanakrishnan (2017) and Aziz et al.(2018). The problem of identifying k> 1 distinct arms from the best fraction is not always well-defined; for a special class of this problem, we present lower and upper bounds. Finally, through a reduction, we establish a relation between upper bounds for the “one out of the best ” problem for infinite instances and the “one out of the best m” problem for finite instances. We conjecture that it is more efficient to solve “small” finite instances using the latter formulation, rather than going through the former.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&citation_for_view=YZkeEqAAAAAJ:hFOr9nPyWt4C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"The stochastic multi-armed bandit is a wellstudied abstraction of decision making in the face of uncertainty. We consider the setting in which the number of bandit arms is much larger than the possible number of pulls, and can even be infinite. With the aim of minimising regret with respect to an optimal arm, existing methods for this setting either assume some structure over the set of arms (Kleinberg et al., 2008, Ray Chowdhury and Gopalan, 2017), or some property of the reward distribution (Wang et al., 2008). Invariably, the validity of such assumptions—and therefore the performance of the corresponding methods—depends on instance-specific parameters, which might not be known beforehand.
We propose a conceptually simple, parameter-free, and practically effective alternative. Specifically we introduce a notion of regret with respect to the top quantile of a probability distribution over the expected reward of randomly drawn arms. Our main contribution is an algorithm that achieves sublinear “quantile-regret”, both (1) when it is specified a quantile, and (2) when the quantile can be any (unknown) positive value. The algorithm needs no side information about the arms or about the structure of their reward distributions: it relies on random sampling to reach arms in the top quantile. Experiments show that our algorithm outperforms several previous methods (in terms of conventional regret) when the latter are not tuned well, and often even when they are.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:hC7cP41nSMkC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"In the practice of sequential decision making, agents are often designed to sense state at regular intervals of time steps, , ignoring state information in between sensing steps. While it is clear that this practice can reduce sensing and compute costs, recent results indicate a further benefit. On many Atari console games, reinforcement learning (RL) algorithms deliver substantially better policies when run with -- in fact with even as high as . In this paper, we investigate the role of the parameter in RL; is called the ""frame-skip"" parameter, since states in the Atari domain are images. For evaluating a fixed policy, we observe that under standard conditions, frame-skipping does not affect asymptotic consistency. Depending on other parameters, it can possibly even benefit learning. To use in the control setting, one must first specify which -step open-loop action sequences can be executed in between sensing steps. We focus on ""action-repetition"", the common restriction of this choice to -length sequences of the same action. We define a task-dependent quantity called the ""price of inertia"", in terms of which we upper-bound the loss incurred by action-repetition. We show that this loss may be offset by the gain brought to learning by a smaller task horizon. Our analysis is supported by experiments on different tasks and learning algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:r0BpntZqJG4C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"Regret minimisation in stochastic multi-armed bandits is a well-studied problem, for which several optimal algorithms have been proposed. Such algorithms depend on (sufficient statistics of) the empirical reward distributions of the arms to decide which arm to pull next. In this paper, we consider the design of algorithms that are constrained to store statistics from only a bounded number of arms. For bandits with a finite set of arms, we derive a sub-linear upper bound on the regret that decreases with the “arm memory” size M. For instances with a large, possibly infinite, set of arms, we show a sub-linear bound on the quantile regret.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:-f6ydRqryjwC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"Policy Iteration (PI) is a popular family of algorithms to compute an optimal policy for a givenMarkov Decision Problem (MDP). Starting from an arbitrary initial policy, PI repeatedly performs locally-improving switches until an optimal policy is found. The exact form of the switching rule gives rise to different variants of PI. Two decades ago, Mansour and Singh [1999] provided the first non-trivial “strong” upper bound on the number of iterations taken by “Howard’s PI”(HPI), a widelyused variant of PI (strong bounds depend only on the number of states and actions in the MDP). They also proposed a randomised variant (RPI) and showed an even tighter strong upper bound. Their bounds for HPI and RPI have not been improved subsequently.\\{We} revisit the algorithms and analysis of Mansour and Singh [1999]. We prove a novel result on the structure of the policy space for k-action MDPs, , which generalises a result known for k= 2. Also proposing a new counting argument, we obtain a strong bound of (O iterations for an algorithm akin to RPI, improving significantly upon Mansour and Singh’s original bound of roughly O (). Similar analysis of a randomised variant of HPI also yields a strong upper bound of (O ( iterations, registering the first exponential improvement for HPI over the trivial bound of . Our other contributions include a lower bound of iterations for RPI and an upper bound of iterations for a randomised variant of “Batch-Switching PI”[Kalyanakrishnan et al., 2016a] on 2-action MDPs—the tightest strong upper bound shown yet for the PI family.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:e5wmG9Sq2KIC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"POMDPs are capable of modelling a large class of decision and planning problems. However, solving large POMDPs optimally is infeasible. The following text reports observations of various experiments related to solving large POMDPs using various strategies conducted as part of an R&D project at IIT Bombay. The section 2 and 3 in the text formally define MDPs and POMDPs and also mention how POMDP solutions (formally called policies) are represented. Important existing POMDP solving algorithms relevant to the experiments conducted are summarized in section 4. Section 5 describes the Subset Update algorithm introduced in [8]. Section 6 mentions a way to reduce the FSC sizes during each iteration by a logical pruning step. Section 7 specifies a few methods to combine two FSCs into a single FSC. Section 8 reports certain empirical results. Some observations and possibilities of future work have been highlighted in the last section.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:k_IJM867U9cC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"Policy Iteration (PI) is a classical family of algorithms to compute an optimal policy for any given Markov Decision Problem (MDP). The basic idea in PI is to begin with some initial policy and to repeatedly update the policy to one from an improving set, until an optimal policy is reached. Different variants of PI result from the (switching) rule used for improvement. An important theoretical question is how many iterations a specified PI variant will take to terminate as a function of the number of states n and the number of actions k in the input MDP. While there has been considerable progress towards upper-bounding this number, there are fewer results on lower bounds. In particular, existing lower bounds primarily focus on the special case of k = 2 actions. We devise lower bounds for k ≥ 3. Our main result is that a particular variant of PI can take Ω(k n /2) iterations to terminate. We also generalise existing constructions on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:j3f4tGmQtD8C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"This paper describes a policy search approach for railway scheduling using the covariance matrix adaptation evolution strategy (CMA-ES). The goal is to define arrival/departure times and track allocations for all trains such that the resource and operating constraints of the railway line are satisfied, and priority-weighted train departure delay is minimised. The proposed approach is scalable in the sense that (i) the optimised policy can be applied to an arbitrarily long railway line, independent of the number of trains, tracks, and stations, and (ii) the on-line implementation is computationally light enough to be applied in real-time. Our experiments show that policies computed with CMA-ES are able to produce solutions with lower priorityweighted delay than heuristics and reinforcement learning (RL) algorithms reported in literature, on synthetic examples as well as actual railway line data from portions of the Indian Railway network.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:RHpTSmoSYBkC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"Policy Iteration (PI) is a widely used family of algorithms to compute optimal policies for Markov Decision Problems (MDPs). We derive upper bounds on the running time of PI on Deterministic MDPs (DMDPs): the class of MDPs in which every state-action pair has a unique next state. Our results include a non-trivial upper bound that applies to the entire family of PI algorithms, and affirmation that a conjecture regarding Howard's PI on MDPs is true for DMDPs. Our analysis is based on certain graph-theoretic results, which may be of independent interest.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:NaGl4SEjCO4C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"Reconnaissance Blind Chess is an imperfect-information variant of chess with significant private information that challenges state-of-the-art algorithms. The Johns Hopkins University Applied Physics Laboratory and several organizing partners held the second NeurIPS machine Reconnaissance Blind Chess competition in 2021. 18 bots competed in 9,180 games, revealing a dominant champion with 91% wins. The top four bots in the tournament matched or exceeded the performance of the inaugural tournament’s winner. However, none of the algorithms converge to an optimal, unexploitable strategy or appear to have addressed the core research challenges associated with Reconnaissance Blind Chess.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:ns9cj8rnVeAC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"We consider the problem of correctly identifying the mode of a discrete distribution with sufficiently high probability by observing a sequence of iid samples drawn from . This problem reduces to the estimation of a single parameter when has a support set of size . After noting that this special case is handled very well by prior-posterior-ratio (PPR) martingale confidence sequences (Waudby-Smith and Ramdas, 2020), we propose a generalisation to mode estimation, in which may take values. To begin, we show that the"" one-versus-one"" principle to generalise from to classes is more efficient than the"" one-versus-rest"" alternative. We then prove that our resulting stopping rule, denoted PPR-1v1, is asymptotically optimal (as the mistake probability is taken to 0). PPR-1v1 is simple and computationally light, and incurs significantly fewer samples than competitors even in the non-asymptotic regime. We demonstrate its gains in two practical applications of sampling: election forecasting and verification of smart contracts in blockchains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:TFP_iSt0sucC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"The Indian railway network carries the largest number of passengers in the world, with over 8.4 billion transported in 2018, in addition to 1.2 billion tonnes of freight [1]. Nonetheless, the network has only about a tenth the “track-length per passenger” of the U.S., and half that of China [2]. This severe limitation of infrastructure, coupled with variability and heterogeneity in operations, raises significant challenges in scheduling. In this paper, we describe a policy search approach to decide arrival/departure times and track allocations for trains such that the resource and operating constraints of the railway line are satisfied, while the priority-weighted departure delay (PWDD) is minimised. We evaluate our approach on three large railway lines from the Indian network. We observe significant reductions of PWDD over traditional heuristics and a solution based on reinforcement learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:M3NEmzRMIkIC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"We consider the problem of correctly identifying the\textit {mode} of a discrete distribution with sufficiently high probability by observing a sequence of iid samples drawn from . This problem reduces to the estimation of a single parameter when has a support set of size . After noting that this special case is tackled very well by prior-posterior-ratio (PPR) martingale confidence sequences\citep {waudby-ramdas-ppr}, we propose a generalisation to mode estimation, in which may take values. To begin, we show that the"" one-versus-one"" principle to generalise from to classes is more efficient than the"" one-versus-rest"" alternative. We then prove that our resulting stopping rule, denoted PPR-1v1, is asymptotically optimal (as the mistake probability is taken to ). PPR-1v1 is parameter-free and computationally light, and incurs significantly fewer samples than competitors even in the non …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:bEWYMUwI8FkC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"My research is driven by my curiosity about the nature of intelligence. Of the several aspects that characterise the behaviour of intelligent agents, I primarily study sequential decision making, learning, and exploration. My interests also extend to broader questions on the effects of AI on life and society. In this paper, I present four distinct investigations drawn from my recent work, which range from theoretical to applied, and which involve both analysis and design. I also share my outlook as an early-career researcher.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:iH-uZ7U-co4C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,"POMDPs are capable of modelling a large class of decision and planning problems. However, solving large POMDPs optimally is infeasible. The following text proposes a variant of Policy Iteration in POMDPs, which makes this solving more tractable. We specify a method which regulates the update of Finite-State Controllers (FSCs) in Hansen’s Policy Iteration algorithm [1]. We selectively add only a subset of improving FSC nodes (as opposed to adding all improvements), during Policy Improvement. Towards the end of the text, we also suggest a method to locally combine FSC nodes, in order to decrease controller size without impairing the policy.
The 2nd and 3rd section in the text formally define MDPs and POMDPs and also mention how POMDP solutions (formally called policies) are represented. Important existing POMDP solving algorithms are summarized in section 4. The initial insights gained during the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:4JMBOYKVnBMC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",19,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&cstart=20&pagesize=80&citation_for_view=YZkeEqAAAAAJ:_Qo2XoVZTnwC,http://www.cse.iitb.ac.in/~shivaram
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"We address the verification of concurrent programs running under the release-acquire (RA) semantics. We show that the reachability problem is undecidable even in the case where the input program is finite-state. Given this undecidability, we follow the spirit of the work on context-bounded analysis for detecting bugs in programs under the classical SC model, and propose an under-approximate reachability analysis for the case of RA. To this end, we propose a novel notion, called view-switching, and provide a code-to-code translation from an input program under RA to a program under SC. This leads to a reduction, in polynomial time, of the bounded view-switching reachability problem under RA to the bounded context-switching problem under SC. We have implemented a prototype tool VBMC and tested it on a set of benchmarks, demonstrating that many bugs in programs can be found using a small number of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&citation_for_view=14JlaZsAAAAJ:tOudhMTPpwUC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Functional MSO transductions, deterministic two-way transducers, as well as streaming string transducers are all equivalent models for regular functions. In this paper, we show that every regular function, either on finite words or on infinite words, captured by a deterministic two-way transducer, can be described with a regular transducer expression (RTE). For infinite words, the transducer uses Muller acceptance and ω-regular look-ahead. RTEs are constructed from constant functions using the combinators if-then-else (deterministic choice), Hadamard product, and unambiguous versions of the Cauchy product, the 2-chained Kleene-iteration and the 2-chained omega-iteration. Our proof works for transformations of both finite and infinite words, extending the result on finite words of Alur et al. in LICS'14. In order to construct an RTE associated with a deterministic two-way Muller transducer with look-ahead, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&citation_for_view=14JlaZsAAAAJ:738O_yMBCRsC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"We define two classes of functions, called regular (respectively, first-order) list functions, which manipulate objects such as lists, lists of lists, pairs of lists, lists of pairs of lists, etc. The definition is in the style of regular expressions: the functions are constructed by starting with some basic functions (e.g. projections from pairs, or head and tail operations on lists) and putting them together using four combinators (most importantly, composition of functions). Our main results are that first-order list functions are exactly the same as first-order transductions, under a suitable encoding of the inputs; and the regular list functions are exactly the same as MSO-transductions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&citation_for_view=14JlaZsAAAAJ:u9iWguZQMMsC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Given a Boolean formula F(X, Y), where X is a vector of outputs and Y is a vector of inputs, the Boolean functional synthesis problem requires us to compute a Skolem function vector Ψ(Y) such that F(Ψ(Y), Y) holds whenever ∃X F(X, Y) holds. In this paper, we investigate the relation between the representation of the specification F(X, Y) and the complexity of synthesis. We introduce a new normal form for Boolean formulas, called SynNNF, that guarantees polynomial-time synthesis and also polynomial-time existential quantification for some order of quantification of variables. We show that several normal forms studied in the knowledge compilation literature are subsumed by SynNNF, although SynNNF can be super-polynomially more succinct than them. Motivated by these results, we propose an algorithm to convert a specification in CNF to SynNNF, with the intent of solving the Boolean functional synthesis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:4fKUyHm3Qg0C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Testing containment of queries is a fundamental reasoning task in knowledge representation. We study here the containment problem for Conjunctive Regular Path Queries (CRPQs), a navigational query language extensively used in ontology and graph database querying. While it is known that containment of CRPQs is expspace-complete in general, we focus here on severely restricted fragments, which are known to be highly relevant in practice according to several recent studies. We obtain a detailed overview of the complexity of the containment problem, depending on the features used in the regular expressions of the queries, with completeness results for np, pitwo, pspace or expspace.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:eflP2zaiRacC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Regular functions from infinite words to infinite words can be equivalently specified by MSO-transducers, streaming ω-string transducers as well as deterministic two-way transducers with look-ahead. In their one-way restriction, the latter transducers define the class of rational functions. Even though regular functions are robustly characterised by several finite-state devices, even the subclass of rational functions may contain functions which are not computable (by a Turing machine with infinite input). This paper proposes a decision procedure for the following synthesis problem: given a regular function f (equivalently specified by one of the aforementioned transducer model), is f computable and if it is, synthesize a Turing machine computing it.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:q3oQSFYPqjQC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"We study two formalisms that allow to compare transducers over words under origin semantics: rational and regular resynchronizers, and show that the former are captured by the latter. We then consider some instances of the following synthesis problem: given transducers T1, T2, construct a rational (resp. regular) resynchronizer R, if it exists, such that T1 is contained in R(T2) under the origin semantics. We show that synthesis of rational resynchronizers is decidable for functional, and even finite-valued, one-way transducers, and undecidable for relational one-way transducers. In the two-way setting, synthesis of regular resynchronizers is shown to be decidable for unambiguous two-way transducers. For larger classes of two-way transducers, the decidability status is open.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:vRqMK49ujn8C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"This paper investigates a decidable and highly expressive real time logic QkMSO which is obtained by extending MSO [<] with guarded quantification using block of less than k metric quantifiers. The resulting logic is shown to be expressively equivalent to 1-clock ATA where loops are without clock resets, as well as, RatMTL, a powerful extension of MTL [U_I] with regular expressions. We also establish 4-variable property for QkMSO and characterize the expressive power of its 2-variable fragment. Thus, the paper presents progress towards expressively complete logics for 1-clock ATA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:UxriW0iASnsC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"FO transductions, aperiodic deterministic two-way transducers, as well as aperiodic streaming string transducers are all equivalent models for first order definable functions. In this paper, we solve the problem of expressions capturing first order definable functions, thereby generalizing the seminal SF=AP (star-free expressions = aperiodic languages) result of Schützenberger. Our result also generalizes a lesser known characterization by Schutzenberger of aperiodic languages by SD-regular expressions (SD=AP). We show that every first order definable function over finite words captured by an aperiodic deterministic two-way transducer can be described with an SD-regular transducer expression (SDRTE). An SDRTE is a regular expression where Kleene stars are used in a restricted way: they can appear only on aperiodic languages which are prefix codes of bounded synchronization delay. SDRTEs are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:V3AGJWp-ZtQC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"We consider the reachability problem for finite-state multi-threaded programs under the promising semantics (PS 2.0) of Lee et al., which captures most common program transformations. Since reachability is already known to be undecidable in the fragment of PS 2.0 with only release-acquire accesses (PS 2.0-ra), we consider the fragment with only relaxed accesses and promises (PS 2.0-rlx). We show that reachability under PS 2.0-rlx is undecidable in general and that it becomes decidable, albeit non-primitive recursive, if we bound the number of promises.
Given these results, we consider a bounded version of the reachability problem. To this end, we bound both the number of promises and of “view-switches”, i.e., the number of times the processes may switch their local views of the global memory. We provide a code-to-code translation from an input program under PS 2.0 (with relaxed and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:wbdj-CoPYUoC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Multi-pushdown systems are a standard model for concurrent recursive programs, but they have an undecidable reachability problem. Therefore, there have been several proposals to underapproximate their sets of runs so that reachability in this underapproximation becomes decidable. One such underapproximation that covers a relatively high portion of runs is scope boundedness. In such a run, after each push to stack , the corresponding pop operation must come within a bounded number of visits to stack . In this work, we generalize this approach to a large class of infinite-state systems. For this, we consider the model of valence systems, which consist of a finite-state control and an infinite-state storage mechanism that is specified by a finite undirected graph. This framework captures pushdowns, vector addition systems, integer vector addition systems, and combinations thereof. For this framework, we propose a notion of scope boundedness that coincides with the classical notion when the storage mechanism happens to be a multi-pushdown. We show that with this notion, reachability can be decided in PSPACE for every storage mechanism in the framework. Moreover, we describe the full complexity landscape of this problem across all storage mechanisms, both in the case of (i) the scope bound being given as input and (ii) for fixed scope bounds. Finally, we provide an almost complete description of the complexity landscape if even a description of the storage mechanism is part of the input.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:WA5NYHcadZ8C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Boolean programs with multiple recursive threads can be captured as pushdown automata with multiple stacks. This model is Turing complete, and hence, one is often interested in analyzing a restricted class which still captures useful behaviors. In this paper, we propose a new class of bounded underapproximations for multi-pushdown systems, which subsumes most existing classes. We develop an efficient algorithm for solving the under-approximate reachability problem, which is based on efficient fix-point computations. We implement it in our tool BHIM and illustrate its applicability by generating a set of relevant benchmarks and examining its performance. As an additional takeaway BHIM solves the binary reachability problem in pushdown automata. To show the versatility of our approach, we then extend our algorithm to the timed setting and provide the first implementation that can handle timed multi …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"In this paper, we analyze timed systems with data structures. We start by describing behaviors of timed systems using graphs with timing constraints. Such a graph is called realizable if we can assign time-stamps to nodes or events so that they are consistent with the timing constraints. The logical definability of several graph properties [20], [10] has been a challenging problem, and we show, using a highly nontrivial argument, that the realizability property for collections of graphs with strict timing constraints is logically definable in a class of propositional dynamic logic (EQ-ICPDL), which is strictly contained in MSO. Using this result, we propose a novel, algorithmically efficient and uniform proof technique for the analysis of timed systems enriched with auxiliary data structures, like stacks and queues. Our technique unravels new results (for emptiness checking as well as model checking) for timed systems with richer …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:K3LRdlH-MEoC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Perfect languages, characterized by closure under Boolean operations and decidable emptiness problem, form the basis for decidable automata-theoretic model-checking for the corresponding class of models. Regular languages and visibly pushdown languages are paradigmatic examples of perfect languages. In a previous work authors have established a timed context-sensitive perfect language characterized by multistack pushdown automata (MPA) with an explicit bound on number of rounds where in each round at most one stack is used. This paper complements the results of on bounded-round timed MPA by characterizing an alternative restriction on timed context-sensitive perfect languages called the scope-bounded multi-stack timed push-down automata where every stack symbol must be popped within a bounded number of stack contexts. The proposed model uses visibly-pushdown alphabet …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"In this paper, we look at an unambiguous version of Simon's forest factorization theorem, a very deep result which has wide connections in algebra, logic and automata. Given a morphism from to a finite semigroup , we construct a universal, unambiguous automaton A which is ""good"" for . The goodness of $\Aa$ gives a very easy proof for the forest factorization theorem, providing a Ramsey split for any word in such that the height of the Ramsey split is bounded by the number of states of A. An important application of synthesizing good automata from the morphim is in the construction of regular transducer expressions (RTE) corresponding to deterministic two way transducers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:SP6oXDckpogC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"The class of regular transformations has several equivalent characterizations such as functional MSO transductions, deterministic two-way transducers, streaming string transducers, as well as regular transducer expressions (RTE).
For algorithmic applications, it is very common and useful to transform a specification, here, an RTE, to a machine, here, a transducer. In this paper, we give an efficient construction of a two-way reversible transducer (2RFT) equivalent to a given RTE. 2RFTs form a well behaved class of transducers which are deterministic and co-deterministic (hence allows evaluation in linear time w.r.t. the input word), and where composition has only polynomial complexity.
As a significant complexity improvement over existing techniques, we give the first elementary procedure for translating RTEs to machines. For full RTE, the constructed 2RFT has size doubly exponential in the size of the expression …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:PELIpwtuRlgC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Metric Temporal Logic (MTL) and Timed Propositional Temporal Logic (TPTL) are prominent real-time extensions of Linear Temporal Logic (LTL). In general, the satisfiability checking problem for these extensions is undecidable when both the future U and the past S modalities are used. In a classical result, the satisfiability checking for MITL[U,S], a non-punctual fragment of MTL[U,S], is shown to be decidable with EXPSPACE complete complexity. Given that this notion of non-punctuality does not recover decidability in the case of TPTL[U,S], we propose a generalization of non-punctuality called non-adjacency for TPTL[U,S], and focus on its 1-variable fragment, 1-TPTL[U,S]. While non-adjacent 1-TPTL[U,S] appears to be a very small fragment, it is strictly more expressive than MITL. As our main result, we show that the satisfiability checking problem for non-adjacent 1-TPTL[U,S] is decidable with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:t6usbXjVLHcC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"We address the separability problem for straight-line string constraints. The separability problem for languages of a class C by a class S asks: given two languages A and B in C, does there exist a language I in S separating A and B (i.e., I is a superset of A and disjoint from B)? The separability of string constraints is the same as the fundamental problem of interpolation for string constraints. We first show that regular separability of straight line string constraints is undecidable. Our second result is the decidability of the separability problem for straight-line string constraints by piece-wise testable languages, though the precise complexity is open. In our third result, we consider the positive fragment of piece-wise testable languages as a separator, and obtain an EXPSPACE algorithm for the separability of a useful class of straight-line string constraints, and a PSPACE-hardness result.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:VOx2b1Wkg3QC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"In automatic control synthesis, we may need to handle specifications with timing constraints and control such that the system meets the specification as much as possible, which is called robust control. In this paper, we present a method for open loop robust controller synthesis from duration calculus (DC) specifications. For robust synthesis, we propose an approach to evaluate the robustness of DC specifications on a given run of a system. We leverage a CEGIS like method for synthesizing robust control signals. In our method, the DC specifications and the system under control are encoded into mixed integer linear problems, and the optimization problem is solved to yield a control signal. We have implemented a tool (ControlDC) based on the method and applied it on a set of benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:mvPsJ3kp5DgC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"We introduce the model of communicating timed automata (CTA) that extends the classical models of finite-state processes communicating through FIFO perfect channels and timed automata, in the sense that the finite-state processes are replaced by timed automata, and messages inside the perfect channels are equipped with clocks representing their ages. In addition to the standard operations (resetting clocks, checking guards of clocks) each automaton can either (1) append a message to the tail of a channel with an initial age or (2) receive the message at the head of a channel if its age satisfies a set of given constraints. In this paper, we show that the reachability problem is undecidable even in the case of two timed automata connected by one unidirectional timed channel if one allows global clocks (that the two automata can check and manipulate). We prove that this undecidability still holds even for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:KxtntwgDAa4C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,Release-acquire (RA) is a popular fragment of C++ 11 [12](in which reads are annotated by acquire and writes by release) that strikes a good balance between programmability and performance and has,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:SdhP9T11ey4C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Functional MSO transductions, deterministic two-way transducers, as well as streaming string transducers are all equivalent models for regular functions. In this paper, we show that every regular function, either on finite words or on infinite words, captured by a deterministic two-way transducer, can be described with a regular transducer expression (RTE ). For infinite words, the two-way transducer uses Muller acceptance and ω-regular look-ahead. RTEs are constructed from constant functions using the combinators if-then-else (deterministic choice), Hadamard product, and unambiguous versions of the Cauchy product, the 2-chained Kleene-iteration and the 2-chained omega-iteration. Our proof works for transformations of both finite and infinite words, extending the result on finite words of Alur et al. in LICS'14.
The construction of an RTE associated with a deterministic two-way transducer is guided by a regular …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:VL0QpB8kHFEC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Reinforcement Learning (RL) is a sampling based approach to optimization, where learning agents rely on scalar reward signals to discover optimal solutions. The specification of learning objectives as scalar rewards is tedious and error prone, and more so for real-time systems with complex time-critical requirements. This paper advocates the use of Duration Calculus (DC)—a highly expressive real-time logic with duration and length modalities—in expressing the learning objectives in model-free RL for stochastic real-time systems. On the other hand, to model stochastic real-time environments, we consider probabilistic timed automata (PTA)—Markov decision processes extended with clock variables—that provide an expressive yet computationally decidable formalism to capture real-time constraints over nondeterministic and probabilistic behaviors. The key hurdle in developing a convergent RL algorithm for DC …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:tkaPQYYpVKoC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Regular model checking is an exploration technique for infinite state systems where state spaces are represented as regular languages and transition relations are expressed using rational relations over infinite (or finite) strings. We extend the regular model checking paradigm to permit the use of more powerful transition relations: the class of regular relations, of which the rational relations are a strict subset. We use the language of monadic second-order logic (MSO) on infinite strings to specify such relations and adopt streaming string transducers (SSTs) as a suitable computational model. We introduce nondeterministic SSTs over infinite strings (-NSSTs) and show that they precisely capture the relations definable in MSO. We further explore theoretical properties of -NSSTs required to effectively carry out regular model checking. In particular, we establish that the regular type checking problem for  …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:Mojj43d5GZwC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"We study the safety verification problem for parameterized systems under the release-acquire (RA) semantics. It has been shown that the problem is intractable for systems with unlimited access to atomic compare-and-swap (CAS) instructions. We show that, from a verification perspective where approximate results help, this is overly pessimistic. We study parameterized systems consisting of an unbounded number of environment threads executing identical but CAS-free programs and a fixed number of distinguished threads that are unrestricted. Our first contribution is a new semantics that considerably simplifies RA but is still equivalent for the above systems as far as safety verification is concerned. We apply this (general) result to two subclasses of our model. We show that safety verification is only \pspace-complete for the bounded model checking problem where the distinguished threads are loop-free. Interestingly, we can still afford the unbounded environment. We show that the complexity jumps to \nexp-complete for thread-modular verification where an unrestricted distinguished `ego' thread interacts with an environment of CAS-free threads plus loop-free distinguished threads (as in the earlier setting). Besides the usefulness for verification, the results are strong in that they delineate the tractability border for an established semantics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:J-pR_7NvFogC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",19,"Regular functions from infinite words to infinite words can be equivalently specified by MSO-transducers, streaming -string transducers as well as deterministic two-way transducers with look-ahead. In their one-way restriction, the latter transducers define the class of rational functions. Even though regular functions are robustly characterised by several finite-state devices, even the subclass of rational functions may contain functions which are not computable (by a Turing machine with infinite input). This paper proposes a decision procedure for the following synthesis problem: given a regular function (equivalently specified by one of the aforementioned transducer model), is computable and if it is, synthesize a Turing machine computing it. For regular functions, we show that computability is equivalent to continuity, and therefore the problem boils down to deciding continuity. We establish a generic characterisation of continuity for functions preserving regular languages under inverse image (such as regular functions). We exploit this characterisation to show the decidability of continuity (and hence computability) of rational and regular functions. For rational functions, we show that this can be done in \textsc{NLogSpace} (it was already known to be in \textsc{PTime} by Prieur). In a similar fashion, we also effectively characterise uniform continuity of regular functions, and relate it to the notion of uniform computability, which offers stronger efficiency guarantees.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&citation_for_view=14JlaZsAAAAJ:08ZZubdj9fEC,http://www.cse.iitb.ac.in/~krishnas
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Given a relational specification between Boolean inputs and outputs, the goal of Boolean functional synthesis is to synthesize each output as a function of the inputs such that the specification is met. In this paper, we first show that unless some hard conjectures in complexity theory are falsified, Boolean functional synthesis must generate large Skolem functions in the worst-case. Given this inherent hardness, what does one do to solve the problem? We present a two-phase algorithm, where the first phase is efficient both in terms of time and size of synthesized functions, and solves a large fraction of benchmarks. To explain this surprisingly good performance, we provide a sufficient condition under which the first phase must produce correct answers. When this condition fails, the second phase builds upon the result of the first phase, possibly requiring exponential time and generating exponential-sized …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:g3aElNc5_aQC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Boolean functional synthesis is the process of constructing a Boolean function from a Boolean specification that relates input and output variables. Despite recent developments in synthesis algorithms, Boolean functional synthesis remains a challenging problem even when state-of-the-art techniques are used for decomposing the specification. In this work, we present a new decomposition approach that decomposes the specification into separate input and output components. To begin with, we adapt the notion of “sequential decomposition” and present a framework that allows the input and output components to be independently synthesized and then re-composed to yield an implementation of the overall specification. Although theoretically appealing, this approach suffers from some practical drawbacks, as evidenced by our experiments. This motivates us to propose a relaxed approach to synthesis by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:VL0QpB8kHFEC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"We present a full-program induction technique for proving (a sub-class of) quantified as well as quantifier-free properties of programs manipulating arrays of parametric size N. Instead of inducting over individual loops, our technique inducts over the entire program (possibly containing multiple loops) directly via the program parameter N. Significantly, this does not require generation or use of loop-specific invariants. We have developed a prototype tool Vajra to assess the efficacy of our technique. We demonstrate the performance of Vajra vis-a-vis several state-of-the-art tools on a set of array manipulating benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:NJ774b8OgUMC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Given a Boolean formula F(X, Y), where X is a vector of outputs and Y is a vector of inputs, the Boolean functional synthesis problem requires us to compute a Skolem function vector Ψ(Y) such that F(Ψ(Y), Y) holds whenever ∃X F(X, Y) holds. In this paper, we investigate the relation between the representation of the specification F(X, Y) and the complexity of synthesis. We introduce a new normal form for Boolean formulas, called SynNNF, that guarantees polynomial-time synthesis and also polynomial-time existential quantification for some order of quantification of variables. We show that several normal forms studied in the knowledge compilation literature are subsumed by SynNNF, although SynNNF can be super-polynomially more succinct than them. Motivated by these results, we propose an algorithm to convert a specification in CNF to SynNNF, with the intent of solving the Boolean functional synthesis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:hkOj_22Ku90C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"We present a novel verification technique to prove properties of a class of array programs with a symbolic parameter N denoting the size of arrays. The technique relies on constructing two slightly different versions of the same program. It infers difference relations between the corresponding variables at key control points of the joint control-flow graph of the two program versions. The desired post-condition is then proved by inducting on the program parameter N, wherein the difference invariants are crucially used in the inductive step. This contrasts with classical techniques that rely on finding potentially complex loop invaraints for each loop in the program. Our synergistic combination of inductive reasoning and finding simple difference invariants helps prove properties of programs that cannot be proved even by the winner of Arrays sub-category in SV-COMP 2021. We have implemented a prototype tool …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:ipzZ9siozwsC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"VeriAbs is a strategy selection based reachability verifier for C code. It analyzes the structure of loops, and intervals of inputs to choose one of the four verification strategies implemented in VeriAbs. In this paper, we present VeriAbs version 1.4 with updates in three strategies. We add an array verification technique called full-program induction, and enhance the existing techniques of loop pruning, k-path interval analysis, and disjunctive loop summarization. These changes have improved the verification of programs with arrays, and unstructured loops and unstructured control flows.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:2KloaMYe4IUC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Given a relational specification between Boolean inputs and outputs, Boolean functional synthesis seeks to synthesize each output as a function of the inputs such that the specification is met. Despite significant algorithmic advances in Boolean functional synthesis over the past few years, there are relatively small specifications that have remained beyond the reach of all state-of-the-art tools. In trying to understand this behaviour, we show that unless some hard conjectures in complexity theory are falsified, Boolean functional synthesis must generate large Skolem functions in the worst-case. Given this inherent hardness, what does one do to solve the problem? We present a two-phase algorithm, where the first phase is efficient in practice both in terms of time and size of synthesized functions, and solves a large fraction of our benchmarks. This phase is also guaranteed to solve the problem when the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:hMsQuOkrut0C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Model counting, or counting solutions of a set of constraints, is a fundamental problem in Computer Science with diverse applications. Since exact counting is computationally hard (# P complete), approximate counting techniques have received much attention over the past few decades. In this chapter, we focus on counting models of propositional formulas, and discuss in detail universal-hashing based approximate counting, which has emerged as the predominant paradigm for state-of-the-art approximate model counters. These counters are randomized algorithms that exploit properties of universal hash functions to provide rigorous approximation guarantees, while piggybacking on impressive advances in propositional satisfiability solving to scale up to problem instances with a million variables. We elaborate on various choices in designing such approximate counters and the implications of these choices. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:nrtMV_XWKgEC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"A promising approach to probabilistic inference that has attracted recent attention exploits its reduction to a set of model counting queries. Since probabilistic inference and model counting are# P-hard, various relaxations are used in practice, with the hope that these relaxations allow efficient computation while also providing rigorous approximation guarantees.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:WqliGbK-hY8C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"We present a new multi-objective optimization approach for synthesizing interpretations that “explain” the behavior of black-box machine learning models. Constructing human-understandable interpretations for black-box models often requires balancing conflicting objectives. A simple interpretation may be easier to understand for humans while being less precise in its predictions vis-a-vis a complex interpretation. Existing methods for synthesizing interpretations use a single objective function and are often optimized for a single class of interpretations. In contrast, we provide a more general and multi-objective synthesis framework that allows users to choose (1) the class of syntactic templates from which an interpretation should be synthesized, and (2) quantitative measures on both the correctness and explainability of an interpretation. For a given black-box, our approach yields a set of Pareto-optimal interpretations with respect to the correctness and explainability measures. We show that the underlying multi-objective optimization problem can be solved via a reduction to quantitative constraint solving, such as weighted maximum satisfiability. To demonstrate the benefits of our approach, we have applied it to synthesize interpretations for black-box neural-network classifiers. Our experiments show that there often exists a rich and varied set of choices for interpretations that are missed by existing approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:uWiczbcajpAC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Boolean Skolem function synthesis concerns syn¬thesizing outputs as Boolean functions of inputs such that a relational specification between inputs and outputs is satisfied. This problem, also known as Boolean functional synthesis, has several applications, including design of safe controllers for autonomous systems, certified QBF solving, cryptanalysis etc. Recently, complexity theoretic hardness results have been shown for the problem, although several algorithms proposed in the literature are known to work well in practice. This dichotomy between theoretical hardness and practical efficacy has motivated research on normal forms of specification representation that guarantee efficient synthesis, thus partially explaining the efficacy of some of these algorithms.In this paper we go one step further and ask if there exists a normal form representation of the specification that precisely characterizes ""efficient"" synthesis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:uc_IGeMz5qoC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"A key problem in constrained random verification (CRV) concerns generation of input stimuli that result in good coverage of the system's runs in targeted corners of its behavior space. Existing CRV solutions however provide no formal guarantees on the distribution of the system's runs. In this paper, we take a first step towards solving this problem. We present an algorithm based on Algebraic Decision Diagrams for sampling bounded traces (i.e. sequences of states) of a sequential circuit with provable uniformity (or bias) guarantees, while satisfying given constraints. We have implemented our algorithm in a tool called TraceSampler. Extensive experiments show that TraceSampler outperforms alternative approaches that provide similar uniformity guarantees.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:35r97b3x0nAC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Demand-driven methods for program analysis have primarily been viewed as efficient algorithms for computing the same information as the corresponding exhaustive methods, but for a given set of demands. We explore demand-driven flow-sensitive alias analysis (which we call ADFSA ) and propose its improved version called PDFSA that computes both aliases and pointers for the demands raised by changing the notion of relevance for indirect assignment statements. We formally show that while ADFSA is as precise as the corresponding exhaustive flow-sensitive alias analysis (EFSA ), PDFSA can be more precise than both ADFSA and EFSA. This surprising result is based on the following insight: A demand-driven method computes less information than the corresponding exhaustive method. PDFSA exploits this to reduce the uncertainty caused by aliasing which in turn, reduces the conflation of memory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:Fu2w8maKXqMC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"A demand-driven approach to program analysis have been viewed as efficient algorithms to compute only the information required to serve a target demand. In contrast, an exhaustive approach computes all information in anticipation of it being used later. However, for a given set of demands, demand-driven methods are believed to compute the same information that would be computed by the corresponding exhaustive methods. We investigate the precision and bidirectional nature of demand-driven methods and show that: (a) demand-driven methods can be formalized inherently as bidirectional data flow analysis because the demands are propagated against the control flow and the information to satisfy the demands is propagated along the control flow. We extend the formalization of the Meet Over Paths solution to bidirectional flows. This formalization helps us to prove the soundness and precision of our analysis, and (b) since a demand-driven method computes only the required information to meet a demand, it should be able to reduce the imprecision caused by data abstractions and hence should be more precise than an exhaustive method. We show that while this is indeed the case with Java, for C/C++, the precision critically hinges on how indirect assignments are handled. We use this insight and propose a demand-driven alias analysis that is more precise than an exhaustive analysis for C/C++ too. We have chosen devirtualization as an application. Our measurements show that our method is not only more efficient but more precise than the existing demand-driven method, as well as the corresponding exhaustive method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:1yQoGdGgb4wC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"We present VeriAbsL, a reachability verifier that performs verification in three stages. First, it slices the input code using a combination of two slicers, then it verifies the slices using predicted strategies, and at last, it composes the result of verifying the individual slices. We introduce a novel shallow slicing technique that uses variable reference information of the program, and data and control dependencies of the entry function to generate slices. We also introduce a novel strategy prediction technique that uses machine learning to predict a strategy. It uses boolean features to describe a program to a neural network that predicts a strategy. We use the portfolio of VeriAbs, a reachabiltiy verifier with manually defined strategies. In sv-comp 2023, VeriAbsL verified 227 (Without witness validation.) more programs than VeriAbs, and 475 (Without witness validation.) programs that VeriAbs could not verify.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:lmc2jWPfTJgC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Skolem functions play a central role in logic, from helping eliminate quantifiers in first-order logic formulas to providing functional implementations of relational specifications. While their existence follows from classical results in logic, less is known about how to compute them effectively and efficiently (whenever such computation is possible). The problem of computing or synthesizing Skolem functions from relational specifications, however, continues to show up in many interesting applications. Recently, a rich line of work has considered theoretical and practical aspects of the problem in a restricted setting, namely synthesis of Boolean Skolem functions from Boolean relational specifications. In this chapter, we take an in-depth look into this fascinating problem and its various implications, from general theoretical and complexity results to practical algorithms, and also draw interesting connections to the knowledge …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:kuK5TVdYjLIC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Given a system of constraints over a set X of variables, projected model counting asks us to count satisfying assignments of the constraint system projected on a subset of X. A key idea used in modern projected counters is to first compute an independent support, say , that is often a small subset of , and to then count models projected on instead of on . While this has been effective in scaling performance of counters, the question of whether we can benefit by projecting on variables beyond has not been explored. In this paper, we study this question and show that contrary to intuition, it can be beneficial to project on variables even beyond . In several applications, a good upper bound of the projected model count often suffices. We show that in several such cases, we can identify a set of variables, called upper bound support (UBS), that is not necessarily a subset of , and yet counting models …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:URolC5Kub84C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Skolem functions play a central role in the study of first order logic, both from theoretical and practical perspectives. While every Skolemized formula in first-order logic makes use of Skolem constants and/or functions, not all such Skolem constants and/or functions admit effectively computable interpretations. Indeed, the question of whether there exists an effectively computable interpretation of a Skolem function, and if so, how to automatically synthesize it, is fundamental to their use in several applications, such as planning, strategy synthesis, program synthesis etc.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:EYYDruWGBe4C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Skolem functions play a central role in the study of first order logic, both from theoretical and practical perspectives. While every Skolemized formula in first-order logic makes use of Skolem constants and/or functions, not all such Skolem constants and/or functions admit effectively computable interpretations. Indeed, the question of whether there exists an effectively computable interpretation of a Skolem function, and if so, how to automatically synthesize it, is fundamental to their use in several applications, such as planning, strategy synthesis, program synthesis etc. In this paper, we investigate the computability of Skolem functions and their automated synthesis in the full generality of first order logic. We first show a strong negative result, that even under mild assumptions on the vocabulary, it is impossible to obtain computable interpretations of Skolem functions. We then show a positive result, providing a precise characterization of first-order theories that admit effective interpretations of Skolem functions, and also present algorithms to automatically synthesize such interpretations. We discuss applications of our characterization as well as complexity bounds for Skolem functions (interpreted as Turing machines).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:9Nmd_mFXekcC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Finding gene regulatory pathways that explain outcomes of wet-lab experiments is one of the holy grails of systems biology. SAT-solving techniques have been used in the past to find few small explanatory pathways assuming either zero or a few known perturbations in the experimental observations. Unfortunately, these approaches do not work when (i) there is noise in the experimental data or domain knowledge, as opposed to known perturbations, and (ii) the number of possible pathways generated by repeatedly invoking a SAT-solver is too large to be analyzed by enumeration. In such settings, determining if an actor plays a functionally significant role towards explaining experimental observations is very difficult using existing SAT-based techniques.
In this paper, we formalize the problem of functional significance checking in gene-regulatory pathways in the presence of a bounded amount of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:ZfRJV9d4-WMC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Counting the number of perfect matchings in bipartite graphs, or equivalently computing the permanent of 0-1 matrices, is an important combinatorial problem that has been extensively studied by theoreticians and practitioners alike. The permanent is #P-Complete; hence it is unlikely that a polynomial-time algorithm exists for the problem. Researchers have therefore focused on finding tractable subclasses of matrices for permanent computation. One such subclass that has received much attention is that of sparse matrices i.e. matrices with few entries set to 1, the rest being 0. For this subclass, improved theoretical upper bounds and practically efficient algorithms have been developed. In this paper, we ask whether it is possible to go beyond sparse matrices in our quest for developing scalable techniques for the permanent, and answer this question affirmatively. Our key insight is to represent permanent …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:dQ2og3OwTAUC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Boolean functional synthesis concerns the automatic generation of Boolean functions satisfying given logical specifications. This problem has numerous applications, and has attracted significant attention from researchers over the past decade. Complexity-theoretic arguments indicate that it is extremely unlikely that the problem has any polynomial-time algorithm. Yet, state-of-the-art tools for this problem routinely handle problems with several thousands of variables. What makes these algorithms tick? In this paper, we provide an overview of some of the techniques that underlie the practical efficiency of these solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:gsN89kCJA0AC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Results: A total of 800 patients met the inclusion criteria, of whom 75 (9.37%) had ISH. Blood Pressure increased with age. The most common echocardiographic change observed in ISH patients was increased Left Ventricular Mass Index (LVMI), while concentric Left Ventricular Hypertrophy (LVH) was more common in women than men with isolated Systolic Hypertension. The incidence of LVMI increased as the severity of ISH increased. Furthermore, patients with stage 3 ISH were nearly 4 times more likely to develop Proteinuria. Conclusion: The findings of this study are in line with previous studies evaluating the presence of ISH in the adult Indian population. There is need for effective population screening along with effective treatment for Blood Pressure to reduce morbidity and mortality. Primary prevention strategies may be the need of the hour in the Indian population which is at risk of cardiovascular Disease associated with Hypertension.[J Indian Med Assoc 2023; 121 (3): 43-7]",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:MLfJN-KU85MC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"Arrays are commonly used in a variety of software to store and process data in loops. Automatically proving safety properties of such programs that manipulate arrays is challenging. We present a novel verification technique, called full-program induction, for proving (a sub-class of) quantified as well as quantifier-free properties of programs manipulating arrays of parametric size N. Instead of inducting over individual loops, our technique inducts over the entire program (possibly containing multiple loops) directly via the program parameter N. The technique performs non-trivial transformations of the given program and pre-conditions during the inductive step. The transformations assist in effectively reducing the assertion checking problem by transforming a program with multiple loops to a program which has fewer and simpler loops or is loop free. Significantly, full-program induction does not require generation or use …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:ILKRHgRFtOwC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"The long run behaviour of linear dynamical systems is often studied by looking at eventual properties of matrices and recurrences that underlie the system. A basic problem in this setting is as follows: given a set of pairs of rational weights and matrices , does there exist an integer N s.t for all , (resp. ). We study this problem, its applications and its connections to linear recurrence sequences. Our first result is that for , the problem is as hard as the ultimate positivity of linear recurrences, a long standing open question (known to be -hard). Our second result is that for any , the problem reduces to ultimate positivity of linear recurrences. This yields upper bounds for several subclasses of matrices by exploiting known results on linear recurrence sequences. Our third result is a general reduction technique for a large class of problems (including the above) from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:BwyfMAYsbu0C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:fEOibwPWpKIC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",24,"T OCK. COM and IEEE TSE. In fact, ICSE 2014 was held in Hyderabad and POPL 2015 was held in Mumbai under the General Chairship of Pankaj Jalote and Sriram Rajamani, respectively. India also has its flagship annual conference called Innovations in Software Engineering (ISEC), which provides a platform for sharing experiences of various research groups.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&citation_for_view=LwG4hd8AAAAJ:tzM49s52ZIMC,http://www.cse.iitb.ac.in/~supratik
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Large scale machine learning and deep models are extremely data-hungry. Unfortunately, obtaining large amounts of labeled data is expensive, and training state-of-the-art models (with hyperparameter tuning) requires significant computing resources and time. Secondly, real-world data is noisy and imbalanced. As a result, several recent papers try to make the training process more efficient and robust. However, most existing work either focuses on robustness or efficiency, but not both. In this work, we introduce GLISTER, a GeneraLIzation based data Subset selecTion for Efficient and Robust learning framework. We formulate GLISTER as a mixed discrete-continuous bi-level optimization problem to select a subset of the training data, which maximizes the log-likelihood on a held-out validation set. We then analyze GLISTER for simple classifiers such as gaussian and multinomial naive-bayes, k-nearest neighbor classifier, and linear regression and show connections to submodularity. Next, we propose an iterative online algorithm GLISTER-ONLINE, which performs data selection iteratively along with the parameter updates, and can be applied to any loss-based learning algorithm. We then show that for a rich class of loss functions including cross-entropy, hinge-loss, squared-loss, and logistic-loss, the inner discrete data selection is an instance of (weakly) submodular optimization, and we analyze conditions for which GLISTER-ONLINE reduces the validation loss and converges. Finally, we propose GLISTER-ACTIVE, an extension to batch active learning, and we empirically demonstrate the performance of GLISTER on a wide range of tasks …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&citation_for_view=W1ZpREMAAAAJ:1yQoGdGgb4wC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"The great success of modern machine learning models on large datasets is contingent on extensive computational resources with high financial and environmental costs. One way to address this is by extracting subsets that generalize on par with the full data. In this work, we propose a general framework, GRAD-MATCH, which finds subsets that closely match the gradient of the\emph {training or validation} set. We find such subsets effectively using an orthogonal matching pursuit algorithm. We show rigorous theoretical and convergence guarantees of the proposed algorithm and, through our extensive experiments on real-world datasets, show the effectiveness of our proposed framework. We show that GRAD-MATCH significantly and consistently outperforms several recent data-selection algorithms and achieves the best accuracy-efficiency trade-off. GRAD-MATCH is available as a part of the CORDS toolkit:\url {https://github. com/decile-team/cords}.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&citation_for_view=W1ZpREMAAAAJ:kzcrU_BdoSEC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Automatic question generation (QG) is a useful yet challenging task in NLP. Recent neural network-based approaches represent the state-of-the-art in this task. In this work, we attempt to strengthen them significantly by adopting a holistic and novel generator-evaluator framework that directly optimizes objectives that reward semantics and structure. The {\it generator} is a sequence-to-sequence model that incorporates the {\it structure} and {\it semantics} of the question being generated. The generator predicts an answer in the passage that the question can pivot on. Employing the copy and coverage mechanisms, it also acknowledges other contextually important (and possibly rare) keywords in the passage that the question needs to conform to, while not redundantly repeating words. The {\it evaluator} model evaluates and assigns a reward to each predicted question based on its conformity to the {\it structure} of ground-truth questions. We propose two novel QG-specific reward functions for text conformity and answer conformity of the generated question. The evaluator also employs structure-sensitive rewards based on evaluation measures such as BLEU, GLEU, and ROUGE-L, which are suitable for QG. In contrast, most of the previous works only optimize the cross-entropy loss, which can induce inconsistencies between training (objective) and testing (evaluation) measures. Our evaluation shows that our approach significantly outperforms state-of-the-art systems on the widely-used SQuAD benchmark as per both automatic and human evaluation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&citation_for_view=W1ZpREMAAAAJ:tS2w5q8j5-wC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Multi-person 3D human pose estimation from a single image is a challenging problem, especially for in-the-wild settings due to the lack of 3D annotated data. We propose HG-RCNN, a Mask-RCNN based network that also leverages the benefits of the Hourglass architecture for multi-person 3D Human Pose Estimation. A two-staged approach is presented that first estimates the 2D keypoints in every Region of Interest (RoI) and then lifts the estimated keypoints to 3D. Finally, the estimated 3D poses are placed in camera-coordinates using weak-perspective projection assumption and joint optimization of focal length and root translations. The result is a simple and modular network for multi-person 3D human pose estimation that does not require any multi-person 3D pose dataset. Despite its simple formulation, HG-RCNN achieves the state-of-the-art results on MuPoTS-3D while also approximating the 3D pose in the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&citation_for_view=W1ZpREMAAAAJ:olpn-zPbct0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Neural network-based methods represent the state-of-the-art in question generation from text. Existing work focuses on generating only questions from text without concerning itself with answer generation. Moreover, our analysis shows that handling rare words and generating the most appropriate question given a candidate answer are still challenges facing existing approaches. We present a novel two-stage process to generate question-answer pairs from the text. For the first stage, we present alternatives for encoding the span of the pivotal answer in the sentence using Pointer Networks. In our second stage, we employ sequence to sequence models for question generation, enhanced with rich linguistic features. Finally, global attention and answer encoding are used for generating the question most relevant to the answer. We motivate and linguistically analyze the role of each component in our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&citation_for_view=W1ZpREMAAAAJ:WbkHhVStYXYC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Automatic question generation (QG) is a challenging problem in natural language understanding. QG systems are typically built assuming access to a large number of training instances where each instance is a question and its corresponding answer. For a new language, such training instances are hard to obtain making the QG problem even more challenging. Using this as our motivation, we study the reuse of an available large QG dataset in a secondary language (e.g. English) to learn a QG model for a primary language (e.g. Hindi) of interest. For the primary language, we assume access to a large amount of monolingual text but only a small QG dataset. We propose a cross-lingual QG model which uses the following training regime: (i) Unsupervised pretraining of language models in both primary and secondary languages and (ii) joint supervised training for QG in both languages. We demonstrate the efficacy of our proposed approach using two different primary languages, Hindi and Chinese. We also create and release a new question answering dataset for Hindi consisting of 6555 sentences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&citation_for_view=W1ZpREMAAAAJ:1qzjygNMrQYC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"In Web search, entity-seeking queries often trigger a special question answering (QA) system. It may use a parser to interpret the question to a structured query, execute that on a knowledge graph (KG), and return direct entity responses. QA systems based on precise parsing tend to be brittle: minor syntax variations may dramatically change the response. Moreover, KG coverage is patchy. At the other extreme, a large corpus may provide broader coverage, but in an unstructured, unreliable form. We present AQQUCN, a QA system that gracefully combines KG and corpus evidence. AQQUCN accepts a broad spectrum of query syntax, between well-formed questions to short “telegraphic” keyword sequences. In the face of inherent query ambiguities, AQQUCN aggregates signals from KGs and large corpora to directly rank KG entities, rather than commit to one semantic interpretation of the query. AQQUCN …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&citation_for_view=W1ZpREMAAAAJ:eJXPG6dFmWUC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Supervised machine learning based state-of-the-art computer vision techniques are in general data hungry. Their data curation poses the challenges of expensive human labeling, inadequate computing resources and larger experiment turn around times. Training data subset selection and active learning techniques have been proposed as possible solutions to these challenges. A special class of subset selection functions naturally model notions of diversity, coverage and representation and can be used to eliminate redundancy thus lending themselves well for training data subset selection. They can also help improve the efficiency of active learning in further reducing human labeling efforts by selecting a subset of the examples obtained using the conventional uncertainty sampling based techniques. In this work, we empirically demonstrate the effectiveness of two diversity models, namely the Facility-Location …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&citation_for_view=W1ZpREMAAAAJ:VOx2b1Wkg3QC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Knowledge graphs have become ubiquitous data sources and their utility has been amplified by the research on ability to answer carefully crafted questions over knowledge graphs. We investigate the problem of question generation (QG) over knowledge graphs wherein, the level of difficulty of the question can be controlled. We present an end-to-end neural network-based method for automatic generation of complex multi-hop questions over knowledge graphs. Taking a subgraph and an answer as input, our transformer-based model generates a natural language question. Our model incorporates difficulty estimation based on named entity popularity, and makes use of this estimation to generate difficulty-controllable questions. We evaluate our model on two recent multi-hop QA datasets. Our evaluation shows that our model is able to generate high-quality, fluent and relevant questions. We have …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&citation_for_view=W1ZpREMAAAAJ:XiVPGOgt02cC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Automatic question generation (QG) is a useful yet challenging task in NLP. Recent neural network-based approaches represent the state-of-the-art in this task. In this work, we attempt to strengthen them significantly by adopting a holistic and novel generator-evaluator framework that directly optimizes objectives that reward semantics and structure. The {\it generator} is a sequence-to-sequence model that incorporates the {\it structure} and {\it semantics} of the question being generated. The generator predicts an answer in the passage that the question can pivot on. Employing the copy and coverage mechanisms, it also acknowledges other contextually important (and possibly rare) keywords in the passage that the question needs to conform to, while not redundantly repeating words. The {\it evaluator} model evaluates and assigns a reward to each predicted question based on its conformity to the {\it structure} of ground-truth questions. We propose two novel QG-specific reward functions for text conformity and answer conformity of the generated question. The evaluator also employs structure-sensitive rewards based on evaluation measures such as BLEU, GLEU, and ROUGE-L, which are suitable for QG. In contrast, most of the previous works only optimize the cross-entropy loss, which can induce inconsistencies between training (objective) and testing (evaluation) measures. Our evaluation shows that our approach significantly outperforms state-of-the-art systems on the widely-used SQuAD benchmark as per both automatic and human evaluation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:HE397vMXCloC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"In the light of exponentially increasing video content, video summarization has attracted a lot of attention recently due to its ability to optimize time and storage. Characteristics of a good summary of a video depend on the particular domain under question. We propose a novel framework for domain specific video summarization. Given a video of a particular domain, our system can produce a summary based on what is important for that domain in addition to possessing other desired characteristics like representation, coverage, diversity etc. as suitable to that domain. Past related work has focused either on using supervised approaches for ranking the snippets to produce summary or on using unsupervised approaches of generating the summary as a subset of snippets with the above characteristics. We look at the joint problem of learning domain specific importance of segments as well as the desired summary …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:5Ul4iDaHHb8C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Analyzing the interactions between humans and objects from a video includes identification of the relationships between humans and the objects present in the video. It can be thought of as a specialized version of Visual Relationship Detection, wherein one of the objects must be a human. While traditional methods formulate the problem as inference on a sequence of video segments, we present a hierarchical approach, LIGHTEN, to learn visual features to effectively capture spatio-temporal cues at multiple granularities in a video. Unlike current approaches, LIGHTEN avoids using ground truth data like depth maps or 3D human pose, thus increasing generalization across non-RGBD datasets as well. Furthermore, we achieve the same using only the visual features, instead of the commonly used hand-crafted spatial features. We achieve state-of-the-art results in human-object interaction detection (88.9% and 92.6 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:eq2jaN3J8jMC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Scarcity of labeled data is a bottleneck for supervised learning models. A paradigm that has evolved for dealing with this problem is data programming. An existing data programming paradigm allows human supervision to be provided as a set of discrete labeling functions (LF) that output possibly noisy labels to input instances and a generative model for consolidating the weak labels. We enhance and generalize this paradigm by supporting functions that output a continuous score (instead of a hard label) that noisily correlates with labels. We show across five applications that continuous LFs are more natural to program and lead to improved recall. We also show that accuracy of existing generative models is unstable with respect to initialization, training epochs, and learning rates. We give control to the data programmer to guide the training process by providing intuitive quality guides with each LF. We propose an elegant method of incorporating these guides into the generative model. Our overall method, called CAGE, makes the data programming paradigm more reliable than other tricks based on initialization, sign-penalties, or soft-accuracy constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:tkaPQYYpVKoC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the various linguistic peculiarities present in the language. The Sanskrit language is lexically productive, undergoes euphonic assimilation of phones at the word boundaries and exhibits variations in spelling conventions and in pronunciations. In this work, we propose the first large scale study of automatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact of unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR dataset for Sanskrit, which faithfully captures several of the linguistic characteristics expressed by the language. We investigate the role of different acoustic model and language model units in ASR systems for Sanskrit. We also propose a new modelling unit, inspired by the syllable level unit selection, that captures character sequences from one vowel in the word to the next vowel. We also highlight the importance of choosing graphemic representations for Sanskrit and show the impact of this choice on word error rates (WER). Finally, we extend these insights from Sanskrit ASR for building ASR systems in two other Indic languages, Gujarati and Telugu. For both these languages, our experimental results show that the use of phonetic based graphemic representations in ASR results in performance improvements as compared to ASR systems that use native scripts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:35r97b3x0nAC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:Fu2w8maKXqMC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Multimodal IR, spanning text corpus, knowledge graph and images, called outside knowledge visual question answering (OKVQA), is of much recent interest. However, the popular data set has serious limitations. A surprisingly large fraction of queries do not assess the ability to integrate cross-modal information. Instead, some are independent of the image, some depend on speculation, some require OCR or are otherwise answerable from the image alone. To add to the above limitations, frequency-based guessing is very effective because of (unintended) widespread answer overlaps between the train and test folds. Overall, it is hard to determine when state-of-the-art systems exploit these weaknesses rather than really infer the answers, because they are opaque and their 'reasoning' process is uninterpretable. An equally important limitation is that the dataset is designed for the quantitative assessment only of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:tKAzc9rXhukC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"The paradigm of data programming, which uses weak supervision in the form of rules/labelling functions, and semi-supervised learning, which augments small amounts of labelled data with a large unlabelled dataset, have shown great promise in several text classification scenarios. In this work, we argue that by not using any labelled data, data programming based approaches can yield sub-optimal performances, particularly when the labelling functions are noisy. The first contribution of this work is an introduction of a framework, \model which is a semi-supervised data programming paradigm that learns a \emph{joint model} that effectively uses the rules/labelling functions along with semi-supervised loss functions on the feature space. Next, we also study \modelss which additionally does subset selection on top of the joint semi-supervised data programming objective and \emph{selects} a set of examples that can be used as the labelled set by \model. The goal of \modelss is to ensure that the labelled data can \emph{complement} the labelling functions, thereby benefiting from both data-programming as well as appropriately selected data for human labelling. We demonstrate that by effectively combining semi-supervision, data-programming, and subset selection paradigms, we significantly outperform the current state-of-the-art on seven publicly available datasets. \footnote{The source code is available at \url{https://github.com/ayushbits/Semi-Supervised-LFs-Subset-Selection}}",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:5awf1xo2G04C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"We work on the problem of recognizing license plates and street signs automatically in challenging conditions such as chaotic traffic. We leverage state-of-the-art text spotters to generate a large amount of noisy labeled training data. The data is filtered using a pattern derived from domain knowledge. We augment training and testing data with interpolated boxes and annotations that makes our training and testing robust. We further use synthetic data during training to increase the coverage of the training data. We train two different models for recognition. Our baseline is a conventional Convolution Neural Network (CNN) encoder followed by a Recurrent Neural Network (RNN) decoder. As our first contribution, we bypass the detection phase by augmenting the baseline with an Attention mechanism in the RNN decoder. Next, we build in the capability of training the model end-to-end on scenes containing license …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:Y5dfb0dijaUC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Automated anomaly detection is a useful task that can aid investigations and detect crimes. To this end, we present a model that can be used as a tool for anomaly detection in surveillance videos. Following an unsupervised approach, we use an autoencoder model trained to minimize the reconstruction error between the input and the generated output. We also augment the training of the auto-encoder with supervision in the form of user ratings per frame; higher user ratings reflect normal behaviour that the model is expected to faithfully reconstruct. On the other hand, lower rated frames are suspected to be anomalous. We analyze the output of the autoencoder on a standard dataset as well as two of our datasets that we have made public. We study the behavior of reconstruction error with and without supervision as well as the temporal coherence of the reconstruction error. Additionally, we use Grad-CAM to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:D_sINldO8mEC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Multi-label classification is crucial to several practical applications including document categorization, video tagging, targeted advertising etc. Training a multi-label classifier requires a large amount of labeled data which is often unavailable or scarce. Labeled data is then acquired by consulting multiple labelers---both human and machine. Inspired by ensemble methods, our premise is that labels inferred with high consensus among labelers, might be closer to the ground truth. We propose strategies based on interaction and active learning to obtain higher quality labels that potentially lead to greater consensus. We propose a novel formulation that aims to collectively optimize the cost of labeling, labeler reliability, label-label correlation and inter-labeler consensus. Evaluation on data labeled by multiple labelers (both human and machine) shows that our consensus output is closer to the ground truth when compared to the"" majority"" baseline. We present illustrative cases where it even improves over the existing ground truth. We also present active learning strategies to leverage our consensus model in interactive learning settings. Experiments on several real-world datasets (publicly available) demonstrate the efficacy of our approach in achieving promising classification results with fewer labeled data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:tOudhMTPpwUC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"With the goal of making deep learning more label-efficient, a growing number of papers have been studying active learning (AL) for deep models. However, there are a number of issues in the prevalent experimental settings, mainly stemming from a lack of unified implementation and benchmarking. Issues in the current literature include sometimes contradictory observations on the performance of different AL algorithms, unintended exclusion of important generalization approaches such as data augmentation and SGD for optimization, a lack of study of evaluation facets like the labeling efficiency of AL, and little or no clarity on the scenarios in which AL outperforms random sampling (RS). In this work, we present a unified re-implementation of state-of-the-art AL algorithms in the context of image classification via our new open-source AL toolkit DISTIL, and we carefully study these issues as facets of effective evaluation. On the positive side, we show that AL techniques are to more label-efficient compared to RS with the use of data augmentation. Surprisingly, when data augmentation is included, there is no longer a consistent gain in using BADGE, a state-of-the-art approach, over simple uncertainty sampling. We then do a careful analysis of how existing approaches perform with varying amounts of redundancy and number of examples per class. Finally, we provide several insights for AL practitioners to consider in future work, such as the effect of the AL batch size, the effect of initialization, the importance of retraining the model at every round, and other insights.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:uJ-U7cs_P_0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Natural language processing (NLP) tasks (e.g. question-answering in English) benefit from knowledge of other tasks (e.g. named entity recognition in English) and knowledge of other languages (e.g. question-answering in Spanish). Such shared representations are typically learned in isolation, either across tasks or across languages. In this work, we propose a meta-learning approach to learn the interactions between both tasks and languages. We also investigate the role of different sampling strategies used during meta-learning. We present experiments on five different tasks and six different languages from the XTREME multilingual benchmark dataset. Our meta-learned model clearly improves in performance compared to competitive baseline models that also include multi-task baselines. We also present zero-shot evaluations on unseen target languages to demonstrate the utility of our proposed model.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:UHK10RUVsp4C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"With ever-increasing dataset sizes, subset selection techniques are becoming increasingly important for a plethora of tasks. It is often necessary to guide the subset selection to achieve certain desiderata, which includes focusing or targeting certain data points, while avoiding others. Examples of such problems include: i) targeted learning, where the goal is to find subsets with rare classes or rare attributes on which the model is underperforming, and ii) guided summarization, where data (eg, image collection, text, document or video) is summarized for quicker human consumption with specific additional user intent. Motivated by such applications, we present PRISM, a rich class of PaRameterIzed Submodular information Measures. Through novel functions and their parameterizations, PRISM offers a variety of modeling capabilities that enable a trade-off between desired qualities of a subset like diversity or representation and similarity/dissimilarity with a set of data points. We demonstrate how PRISM can be applied to the two real-world problems mentioned above, which require guided subset selection. In doing so, we show that PRISM interestingly generalizes some past work, therein reinforcing its broad utility. Through extensive experiments on diverse datasets, we demonstrate the superiority of PRISM over the state-of-the-art in targeted learning and in guided image-collection summarization.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:zLWjf1WUPmwC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Generating syntactically and semantically valid and relevant questions from paragraphs is useful with many applications. Manual generation is a labour-intensive task, as it requires the reading, parsing and understanding of long passages of text. A number of question generation models based on sequence-to-sequence techniques have recently been proposed. Most of them generate questions from sentences only, and none of them is publicly available as an easy-to-use service. In this paper, we demonstrate ParaQG, a Web-based system for generating questions from sentences and paragraphs. ParaQG incorporates a number of novel functionalities to make the question generation process user-friendly. It provides an interactive interface for a user to select answers with visual insights on generation of questions. It also employs various faceted views to group similar questions as well as filtering techniques to eliminate unanswerable questions",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:bnK-pcrLprsC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Embedding large graphs in a low-dimensional space has proven useful in various applications. However, there is a limited focus on real-world networks that are dynamic in nature and continuously evolving with time. In this paper, we propose a novel adversarial algorithm to learn representation of dynamic networks. We leverage generative adversarial networks and recurrent networks to capture temporal and structural information. We conduct extensive experiments on the task of graph reconstruction, link prediction and graph prediction. Experimental results demonstrate consistent, stable, and better results against state-of-the-art methods in many cases.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:_B80troHkn4C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Supervised machine learning based state-of-the-art computer vision techniques are in general data hungry and pose the challenges of not having adequate computing resources and of high costs involved in human labeling efforts. Training data subset selection and active learning techniques have been proposed as possible solutions to these challenges respectively. A special class of subset selection functions naturally model notions of diversity, coverage and representation and they can be used to eliminate redundancy and thus lend themselves well for training data subset selection. They can also help improve the efficiency of active learning in further reducing human labeling efforts by selecting a subset of the examples obtained using the conventional uncertainty sampling based techniques. In this work we empirically demonstrate the effectiveness of two diversity models, namely the Facility-Location and Disparity-Min models for training-data subset selection and reducing labeling effort. We do this for a variety of computer vision tasks including Gender Recognition, Scene Recognition and Object Recognition. Our results show that subset selection done in the right way can add 2-3% in accuracy on existing baselines, particularly in the case of less training data. This allows the training of complex machine learning models (like Convolutional Neural Networks) with much less training data while incurring minimal performance loss.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"We consider the problem of multi-label classification where the labels lie in a hierarchy. However, unlike most existing works in hierarchical multi-label classification, we do not assume that the label-hierarchy is known. Encouraged by the recent success of hyperbolic embeddings in capturing hierarchical relations, we propose to jointly learn the classifier parameters as well as the label embeddings. Such a joint learning is expected to provide a twofold advantage: i) the classifier generalizes better as it leverages the prior knowledge of existence of a hierarchy over the labels, and ii) in addition to the label co-occurrence information, the label-embedding may benefit from the manifold structure of the input datapoints, leading to embeddings that are more faithful to the label hierarchy. We propose a novel formulation for the joint learning and empirically evaluate its efficacy. The results show that the joint learning improves over the baseline that employs label co-occurrence based pre-trained hyperbolic embeddings. Moreover, the proposed classifiers achieve state-of-the-art generalization on standard benchmarks. We also present evaluation of the hyperbolic embeddings obtained by joint learning and show that they represent the hierarchy more accurately than the other alternatives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:uLbwQdceFCQC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Data subset selection from a large number of training instances has been a successful approach toward efficient and cost-effective machine learning. However, models trained on a smaller subset may show poor generalization ability. In this paper, our goal is to design an algorithm for selecting a subset of the training data, so that the model can be trained quickly, without significantly sacrificing on accuracy. More specifically, we focus on data subset selection for regularized regression problems and provide a novel problem formulation which seeks to minimize the training loss with respect to both the trainable parameters and the subset of training data, subject to error bounds on the validation set. We tackle this problem using several technical innovations. First, we represent this problem with simplified constraints using the dual of the original training problem and show that the objective of this new representation is a monotone and -submodular function, for a wide variety of modeling choices. Such properties lead us to develop SELCON, an efficient majorization-minimization algorithm for data subset selection, that admits an approximation guarantee even when the training provides an imperfect estimate of the trained model. Finally, our experiments on several datasets show that SELCON trades off accuracy and efficiency more effectively than the current state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:z_wVstp3MssC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Automatic video summarization is still an unsolved problem due to several challenges. The currently available datasets either have very short videos or have few long videos of only a particular type. We introduce a new benchmarking video dataset called VISIOCITY (VIdeo SummarIzatiOn based on Continuity, Intent and DiversiTY) which comprises of longer videos across six different categories with dense concept annotations capable of supporting different flavors of video summarization and other vision problems. For long videos, human reference summaries necessary for supervised video summarization techniques are difficult to obtain. We explore strategies to automatically generate multiple reference summaries from indirect ground truth present in VISIOCITY. We show that these summaries are at par with human summaries. We also present a study of different desired characteristics of a good summary and demonstrate how it is normal to have two good summaries with different characteristics. Thus we argue that evaluating a summary against one or more human summaries and using a single measure has its shortcomings. We propose an evaluation framework for better quantitative assessment of summary quality which is closer to human judgment. Lastly, we present insights into how a model can be enhanced to yield better summaries. Sepcifically, when multiple diverse ground truth summaries can exist, learning from them individually and using a combination of loss functions measuring different characteristics is better than learning from a single combined (oracle) ground truth summary using a single loss function. We demonstrate the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:_Ybze24A_UAC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Automatic video summarization is still an unsolved problem due to several challenges. We take steps towards making it more realistic by addressing the following challenges. Firstly, the currently available datasets either have very short videos or have few long videos of only a particular type. We introduce a new benchmarking dataset called VISIOCITY which comprises of longer videos across six different categories with dense concept annotations capable of supporting different flavors of video summarization and other vision problems. Secondly, for long videos, human reference summaries, necessary for supervised video summarization techniques, are difficult to obtain. We present a novel recipe based on pareto optimality to automatically generate multiple reference summaries from indirect ground truth present in VISIOCITY. We show that these summaries are at par with human summaries. Thirdly, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:9vf0nzSNQJEC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Deep neural networks have seen great success in recent years; however, training a deep model is often challenging as its performance heavily depends on the hyper-parameters used. In addition, finding the optimal hyper-parameter configuration, even with state-of-the-art (SOTA) hyper-parameter optimization (HPO) algorithms, can be time-consuming, requiring multiple training runs over the entire datasetfor different possible sets of hyper-parameters. Our central insight is that using an informative subset of the dataset for model training runs involved in hyper-parameter optimization, allows us to find the optimal hyper-parameter configuration significantly faster. In this work, we propose AUTOMATA, a gradient-based subset selection framework for hyper-parameter tuning. We empirically evaluate the effectiveness of AUTOMATA in hyper-parameter tuning through several experiments on real-world datasets in the text, vision, and tabular domains. Our experiments show that using gradient-based data subsets for hyper-parameter tuning achieves significantly faster turnaround times and speedups of 3×-30× while achieving comparable performance to the hyper-parameters found using the entire dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:BUYA1_V_uYcC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Post-editing in Automatic Speech Recognition (ASR) entails automatically correcting common and systematic errors produced by the ASR system. The outputs of an ASR system are largely prone to phonetic and spelling errors. In this paper, we propose to use a powerful pre-trained sequence-to-sequence model, BART, further adaptively trained to serve as a denoising model, to correct errors of such types. The adaptive training is performed on an augmented dataset obtained by synthetically inducing errors as well as by incorporating actual errors from an existing ASR system. We also propose a simple approach to rescore the outputs using word level alignments. Experimental results on accented speech data demonstrate that our strategy effectively rectifies a significant number of ASR errors and produces improved WER results when compared against a competitive baseline.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:epqYDVWIO7EC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Sanskrit OCR documents have a lot of errors. Correcting those errors using conventional spell-checking approaches breaks down due to the limited vocabulary. This is because of high inflections of Sanskrit, where words are dynamically formed by Sandhi rules, Samāsa rules, Taddhita affixes, etc. Therefore, correcting OCR documents require huge efforts. In this paper, we present different machine learning approaches and various ways to improve features for ameliorating the error corrections in Sanskrit OCR documents. We simulated Subanta Prakaraṇam of VaiyākaraṇaSiddhāntaKaumudī for synthesizing off-the-shelf dictionary. Most of the methods we propose can also work for general Sanskrit word corrections.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:sSrBHYA8nusC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Texts in Indic Languages contain a large proportion of out-of-vocabulary (OOV) words due to frequent fusion using conjoining rules (of which there are around 4000 in Sanskrit). OCR errors further accentuate this complexity for the error correction systems. Variations of sub-word units such as n-grams, possibly encapsulating the context, can be extracted from the OCR text as well as the language text individually. Some of the sub-word units that are derived from the texts in such languages highly correlate to the word conjoining rules. Signals such as frequency values (on a corpus) associated with such sub-word units have been used previously with log-linear classifiers for detecting errors in Indic OCR texts. We explore two different encodings to capture such signals and augment the input to Long Short Term Memory (LSTM) based OCR correction models, that have proven useful in the past for jointly learning the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:J-pR_7NvFogC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"This paper addresses automatic summarization of videos in a unified manner. In particular, we propose a framework for multi-faceted summarization for extractive, query base and entity summarization (summarization at the level of entities like objects, scenes, humans and faces in the video). We investigate several summarization models which capture notions of diversity, coverage, representation and importance, and argue the utility of these different models depending on the application. While most of the prior work on submodular summarization approaches has focused on combining several models and learning weighted mixtures, we focus on the explainability of different models and featurizations, and how they apply to different domains. We also provide implementation details on summarization systems and the different modalities involved. We hope that the study from this paper will give insights into …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"With ever-increasing dataset sizes, subset selection techniques are becoming increasingly important for a plethora of tasks. It is often necessary to guide the subset selection to achieve certain desiderata, which includes focusing or targeting certain data points, while avoiding others. Examples of such problems include: i) targeted learning, where the goal is to find subsets with rare classes or rare attributes on which the model is under performing, and ii) guided summarization, where data (eg, image collection, text, document or video) is summarized for quicker human consumption with specific additional user intent. Motivated by such applications, we present PRISM, a rich class of PaRameterIzed Submodular information Measures. Through novel functions and their parameterizations, PRISM offers a variety of modeling capabilities that enable a trade-off between desired qualities of a subset like diversity or representation and similarity/dissimilarity with a set of data points. We demonstrate how PRISM can be applied to the two real-world problems mentioned above, which require guided subset selection. In doing so, we show that PRISM interestingly generalizes some past work, therein reinforcing its broad utility. Through extensive experiments on diverse datasets, we demonstrate the superiority of PRISM over the state-of-the-art in targeted learning and in guided image-collection summarization. PRISM is available as a part of the SUBMODLIB (https://github. com/decile-team/submodlib) and TRUST (https://github. com/decile-team/trust) toolkits.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:g3aElNc5_aQC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Datasets for training crowd counting deep networks are typically heavy-tailed in count distribution and exhibit discontinuities across the count range. As a result, the de facto statistical measures (MSE, MAE) exhibit large variance and tend to be unreliable indicators of performance across the count range. To address these concerns in a holistic manner, we revise processes at various stages of the standard crowd counting pipeline. To enable principled and balanced minibatch sampling, we propose a novel smoothed Bayesian sample stratification approach. We propose a novel cost function which can be readily incorporated into existing crowd counting deep networks to encourage strata-aware optimization. We analyze the performance of representative crowd counting approaches across standard datasets at per strata level and in aggregate. We analyze the performance of crowd counting approaches across …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:nrtMV_XWKgEC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"In this paper, we present a novel approach to the audio-visual video parsing (AVVP) task that demarcates events from a video separately for audio and visual modalities. The proposed parsing approach simultaneously detects the temporal boundaries in terms of start and end times of such events. We show how AVVP can benefit from the following techniques geared towards effective cross-modal learning: (i) adversarial training and skip connections (ii) global context aware attention and, (iii) self-supervised pretraining using an audio-video grounding objective to obtain cross-modal audio-video representations. We present extensive experimental evaluations on the Look, Listen, and Parse (LLP) dataset and show that we outperform the state-of-the-art Hybrid Attention Network (HAN) on all five metrics proposed for AVVP. We also present several ablations to validate the effect of pretraining, global attention and adversarial training.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:tzM49s52ZIMC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:ipzZ9siozwsC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"With the ever increasing growth of videos, automatic video summarization has become an important task which has attracted lot of interest in the research community. One of the challenges which makes it a hard problem to solve is presence of multiple ‘correct answers’. Because of the highly subjective nature of the task, there can be different “ideal” summaries of a video. Modelling user intent in the form of queries has been posed in literature as a way to alleviate this problem. The query-focused summary is expected to contain shots which are relevant to the query in conjunction with other important shots. For practical deployments in which very long videos need to be summarized, this need to capture user’s intent becomes all the more pronounced. In this work, we propose a simple two stage method which takes user query and video as input and generates a query-focused summary. Specifically, in the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:PR6Y55bgFSsC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"Introduction
Limited treatment options exist for COVID-19 infections; thus, attempts from complementary and alternative systems (CAM) of medicine are being explored as possible therapeutic options. Ayurcov is a formulation made of ingredients mentioned in Ayurveda. These constituents have proven antiviral, detoxifying, immune-modulating, and bio-enhancing properties. The present study was carried out to evaluate the therapeutic effect and safety of Ayurcov in patients with various severity states of COVID-19 infections.
Methods
A randomized, single blinded, controlled trial was carried out in adults diagnosed with mild-to-moderate, and severe COVID-19 infections confirmed by real time reverse transcriptase polymerase chain reaction (rRTPCR) test. The interventional group received three doses of ‘Ayurcov’. It is constituted of Haridra Churna (Curcuma longa), Go ark (Bos Indicus Distilled Urine), Sphatika (Alum …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:Z5m8FVwuT1cC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"We study submodular information measures as a rich framework for generic, query-focused, privacy sensitive, and update summarization tasks. While past work generally treats these problems differently ({\em e.g.}, different models are often used for generic and query-focused summarization), the submodular information measures allow us to study each of these problems via a unified approach. We first show that several previous query-focused and update summarization techniques have, unknowingly, used various instantiations of the aforesaid submodular information measures, providing evidence for the benefit and naturalness of these models. We then carefully study and demonstrate the modelling capabilities of the proposed functions in different settings and empirically verify our findings on both a synthetic dataset and an existing real-world image collection dataset (that has been extended by adding concept annotations to each image making it suitable for this task) and will be publicly released. We employ a max-margin framework to learn a mixture model built using the proposed instantiations of submodular information measures and demonstrate the effectiveness of our approach. While our experiments are in the context of image summarization, our framework is generic and can be easily extended to other summarization settings (e.g., videos or documents).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:LjlpjdlvIbIC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",24,"In this paper, we present a state-of-the-art system for audio event detection. The labels on the training (and evaluation) data specify the set of events occurring in each audio clip, but neither the time spans nor the order in which they occur. Specifically, our task of weakly supervised learning is the “Detection and Classification of Acoustic Scenes and Events (DCASE) 2017” challenge [5]. We use the winning entry in this challenge given by Xu et al.[10] as our starting point and identify several important modifications that allow us to improve on their results significantly. Our techniques pertain to aggregation and consolidation over time and frequency signals over a (temporal) sequence before decoding the labels. In general, our work is also relevant to other tasks involving learning from weak labeling of sequential data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&citation_for_view=W1ZpREMAAAAJ:4fKUyHm3Qg0C,http://www.cse.iitb.ac.in/~ganesh
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"We present CROSSGRAD, a method to use multi-domain training data to learn a classifier that generalizes to new domains. CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. CROSSGRAD parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other's objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and that (2) data augmentation is a more stable and accurate method than domain adversarial training.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&citation_for_view=LfF2zfQAAAAJ:fhZv66dCuXAC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by providing temporal scopes (start and end times) on each edge in the KG. While Question Answering over KG (KGQA) has received some attention from the research community, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored area. Lack of broad coverage datasets has been another factor limiting progress in this area. We address this challenge by presenting CRONQUESTIONS, the largest known Temporal KGQA dataset, clearly stratified into buckets of structural complexity. CRONQUESTIONS expands the only known previous dataset by a factor of 340x. We find that various state-of-the-art KGQA methods fall far short of the desired performance on this new dataset. In response, we also propose CRONKGQA, a transformer-based solution that exploits recent advances in Temporal KG embeddings, and achieves performance superior to all baselines, with an increase of 120% in accuracy over the next best performing method. Through extensive experiments, we give detailed insights into the workings of CRONKGQA, as well as situations where significant further improvements appear possible. In addition to the dataset, we have released our code as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:JjBZBFkNMTQC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"A recent state-of-the-art neural open information extraction (OpenIE) system generates extractions iteratively, requiring repeated encoding of partial outputs. This comes at a significant computational cost. On the other hand, sequence labeling approaches for OpenIE are much faster, but worse in extraction quality. In this paper, we bridge this trade-off by presenting an iterative labeling-based system that establishes a new state of the art for OpenIE, while extracting 10x faster. This is achieved through a novel Iterative Grid Labeling (IGL) architecture, which treats OpenIE as a 2-D grid labeling task. We improve its performance further by applying coverage (soft) constraints on the grid at training time. Moreover, on observing that the best OpenIE systems falter at handling coordination structures, our OpenIE system also incorporates a new coordination analyzer built with the same IGL architecture. This IGL based coordination analyzer helps our OpenIE system handle complicated coordination structures, while also establishing a new state of the art on the task of coordination analysis, with a 12.3 pts improvement in F1 over previous analyzers. Our OpenIE system, OpenIE6, beats the previous systems by as much as 4 pts in F1, while being much faster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:i9B0nK2ie9AC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"State-of-the-art knowledge base completion (KBC) models predict a score for every known or unknown fact via a latent factorization over entity and relation embeddings. We observe that when they fail, they often make entity predictions that are incompatible with the type required by the relation. In response, we enhance each base factorization with two type-compatibility terms between entity-relation pairs, and combine the signals in a novel manner. Without explicit supervision from a type catalog, our proposed modification obtains up to 7% MRR gains over base models, and new state-of-the-art results on several datasets. Further analysis reveals that our models better represent the latent types of entities and their embeddings also predict supervised types better than the embeddings fitted by baseline models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:lYbyOjaXH8MC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"Recent years have seen increasingly complex question-answering on knowledge bases (KBQA) involving logical, quantitative, and comparative reasoning over KB subgraphs. Neural Program Induction (NPI) is a pragmatic approach toward modularizing the reasoning process by translating a complex natural language query into a multi-step executable program. While NPI has been commonly trained with the ‘‘gold’’ program or its sketch, for realistic KBQA applications such gold programs are expensive to obtain. There, practically only natural language queries and the corresponding answers can be provided for training. The resulting combinatorial explosion in program space, along with extremely sparse rewards, makes NPI for KBQA ambitious and challenging. We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:4_yl7nwqy4oC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"In Web search, entity-seeking queries often trigger a special question answering (QA) system. It may use a parser to interpret the question to a structured query, execute that on a knowledge graph (KG), and return direct entity responses. QA systems based on precise parsing tend to be brittle: minor syntax variations may dramatically change the response. Moreover, KG coverage is patchy. At the other extreme, a large corpus may provide broader coverage, but in an unstructured, unreliable form. We present AQQUCN, a QA system that gracefully combines KG and corpus evidence. AQQUCN accepts a broad spectrum of query syntax, between well-formed questions to short “telegraphic” keyword sequences. In the face of inherent query ambiguities, AQQUCN aggregates signals from KGs and large corpora to directly rank KG entities, rather than commit to one semantic interpretation of the query. AQQUCN …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:IaRkJ05COeQC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"Temporal knowledge bases associate relational (s,r,o) triples with a set of times (or a single time instant) when the relation is valid. While time-agnostic KB completion (KBC) has witnessed significant research, temporal KB completion (TKBC) is in its early days. In this paper, we consider predicting missing entities (link prediction) and missing time intervals (time prediction) as joint TKBC tasks where entities, relations, and time are all embedded in a uniform, compatible space. We present TIMEPLEX, a novel time-aware KBC method, that also automatically exploits the recurrent nature of some relations and temporal interactions between pairs of relations. TIMEPLEX achieves state-of-the-art performance on both prediction tasks. We also find that existing TKBC models heavily overestimate link prediction performance due to imperfect evaluation mechanisms. In response, we propose improved TKBC evaluation protocols for both link and time prediction tasks, dealing with subtle issues that arise from the partial overlap of time intervals in gold instances and system predictions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:kGbpvR7Ecy8C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"While traditional systems for Open Information Extraction were statistical and rule-based, recently neural models have been introduced for the task. Our work builds upon CopyAttention, a sequence generation OpenIE model (Cui et. al., 2018). Our analysis reveals that CopyAttention produces a constant number of extractions per sentence, and its extracted tuples often express redundant information. We present IMoJIE, an extension to CopyAttention, which produces the next extraction conditioned on all previously extracted tuples. This approach overcomes both shortcomings of CopyAttention, resulting in a variable number of diverse extractions per sentence. We train IMoJIE on training data bootstrapped from extractions of several non-neural systems, which have been automatically filtered to reduce redundancy and noise. IMoJIE outperforms CopyAttention by about 18 F1 pts, and a BERT-based strong baseline by 2 F1 pts, establishing a new state of the art for the task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:rr29yNp9FasC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"Neural Program Induction (NPI) is a paradigm for decomposing high-level tasks such as complex question-answering over knowledge bases (KBQA) into executable programs by employing neural models. Typically, this involves two key phases: i) inferring input program variables from the highlevel task description, and ii) generating the correct program sequence involving these variables. Here we focus on NPI for Complex KBQA with only the final answer as supervision, and not gold programs. This raises major challenges; namely i) noisy query annotation in the absence of any supervision can lead to catastrophic forgetting while learning, ii) reward becomes extremely sparse owing to the noise. To deal with these, we propose a noise-resilient NPI model, Stable Sparse Reward based Programmer (SSRP) that evades noise-induced instability through continual retrospection and its comparison with current learning behavior. On complex KBQA datasets, SSRP performs at par with hand-crafted rule-based models when provided with gold program input, and in the noisy settings outperforms state-of-the-art models by a significant margin even with a noisier query annotator.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:uHQrz-U2knEC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"Code-switching, the interleaving of two or more languages within a sentence or discourse is pervasive in multilingual societies. Accurate language models for code-switched text are critical for NLP tasks. State-of-the-art data-intensive neural language models are difficult to train well from scarce language-labeled code-switched text. A potential solution is to use deep generative models to synthesize large volumes of realistic code-switched text. Although generative adversarial networks and variational autoencoders can synthesize plausible monolingual text from continuous latent space, they cannot adequately address code-switched text, owing to their informal style and complex interplay between the constituent languages. We introduce VACS, a novel variational autoencoder architecture specifically tailored to code-switching phenomena. VACS encodes to and decodes from a two-level hierarchical representation, which models syntactic contextual signals in the lower level, and language switching signals in the upper layer. Sampling representations from the prior and decoding them produced well-formed, diverse code-switched sentences. Extensive experiments show that using synthetic code-switched text with natural monolingual data results in significant (33.06%) drop in perplexity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:ysWPWRY3VgcC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"Modeling user engagement dynamics on social media has compelling applications in market trend analysis, user-persona detection, and political discourse mining. Most existing approaches depend heavily on knowledge of the underlying user network. However, a large number of discussions happen on platforms that either lack any reliable social network (news portal, blogs, Buzzfeed) or reveal only partially the inter-user ties (Reddit, Stackoverflow). Many approaches require observing a discussion for some considerable period before they can make useful predictions. In real-time streaming scenarios, observations incur costs. Lastly, most models do not capture complex interactions between exogenous events (such as news articles published externally) and in-network effects (such as follow-up discussions on Reddit) to determine engagement levels. To address the three limitations noted above, we propose a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:ace9KxS0p5UC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",57,"Many text mining tasks, such as clustering, classification, retrieval, and named entity linking, benefit from a measure of relatedness between entities in a knowledge graph. We present a thorough study of all entity relatedness measures in recent literature based on Wikipedia as the knowledge graph. To facilitate this study, we introduce a new dataset with human judgments of entity relatedness. No clear dominance is seen between measures based on textual similarity and graph proximity. Some of the better measures involve expensive global graph computations. We propose a new, space-efficient, computationally lightweight, two-stage framework for relatedness computation. In the first stage, a small weighted subgraph is dynamically grown around the two query entities; in the second stage, relatedness is derived based on computations on this subgraph. Our system shows better agreement with human judgment …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&citation_for_view=LfF2zfQAAAAJ:KUazKHuGu6AC,https://www.cse.iitb.ac.in/~soumen/
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Multi-modal sentiment analysis offers various challenges, one being the effective combination of different input modalities, namely text, visual and acoustic. In this paper, we propose a recurrent neural network based multi-modal attention framework that leverages the contextual information for utterance-level sentiment prediction. The proposed approach applies attention on multi-modal multi-utterance representations and tries to learn the contributing features amongst them. We evaluate our proposed approach on two multi-modal sentiment analysis benchmark datasets, viz. CMU Multi-modal Opinion-level Sentiment Intensity (CMU-MOSI) corpus and the recently released CMU Multi-modal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) corpus. Evaluation results show the effectiveness of our proposed approach with the accuracies of 82.31% and 79.80% for the MOSI and MOSEI datasets, respectively. These are approximately 2 and 1 points performance improvement over the state-of-the-art models for the datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&citation_for_view=vvg-pAkAAAAJ:xGWFX6Gbr9MC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Related tasks often have inter-dependence on each other and perform better when solved in a joint framework. In this paper, we present a deep multi-task learning framework that jointly performs sentiment and emotion analysis both. The multi-modal inputs (i.e., text, acoustic and visual frames) of a video convey diverse and distinctive information, and usually do not have equal contribution in the decision making. We propose a context-level inter-modal attention framework for simultaneously predicting the sentiment and expressed emotions of an utterance. We evaluate our proposed approach on CMU-MOSEI dataset for multi-modal sentiment and emotion analysis. Evaluation results suggest that multi-task learning framework offers improvement over the single-task framework. The proposed approach reports new state-of-the-art performance for both sentiment analysis and emotion analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&citation_for_view=vvg-pAkAAAAJ:hfzGNhXhx5MC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Fake news, rumor, incorrect information, and misinformation detection are nowadays crucial issues as these might have serious consequences for our social fabrics. The rate of such information is increasing rapidly due to the availability of enormous web information sources including social media feeds, news blogs, online newspapers etc. In this paper, we develop various deep learning models for detecting fake news and classifying them into the pre-defined fine-grained categories. At first, we develop models based on Convolutional Neural Network (CNN) and Bi-directional Long Short Term Memory (Bi-LSTM) networks. The representations obtained from these two models are fed into a Multi-layer Perceptron Model (MLP) for the final classification. Our experiments on a benchmark dataset show promising results with an overall accuracy of 44.87\%, which outperforms the current state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:rLGzs9wiiwIC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"With the enormous growth of Internet, more users have engaged in health communities such as medical forums to gather health-related information, to share experiences about drugs, treatments, diagnosis or to interact with other users with similar condition in communities. Monitoring social media platforms has recently fascinated medical natural language processing researchers to detect various medical abnormalities such as adverse drug reaction. In this paper, we present a benchmark setup for analyzing the sentiment with respect to users’ medical condition considering the information, available in social media in particular. To this end, we have crawled the medical forum website ‘patient. info’with opinions about medical condition self narrated by the users. We constrained ourselves to some of the popular domains such as depression, anxiety, asthma, and allergy. The focus is given on the identification of multiple forms of medical sentiments which can be inferred from users’ medical condition, treatment, and medication. Thereafter, a deep Convolutional Neural Network (CNN) based medical sentiment analysis system is developed for the purpose of evaluation. The resources are made available to the community through LRE map for further research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:_tF6a-HnqWAC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"We propose a multi-task ensemble framework that jointly learns multiple related problems. The ensemble model aims to leverage the learned representations of three deep learning models (i.e., CNN, LSTM and GRU) and a hand-crafted feature representation for the predictions. Through multi-task framework, we address four problems of emotion and sentiment analysis, i.e., “emotion classification & intensity ”, “ valence , arousal & dominance for emotion”, “ valence & arousal for sentiment”, and “ 3-class categorical & 5-class ordinal classification for sentiment”. The underlying problems cover two granularity (i.e., coarse-grained and fine-grained ) and a diverse range of domains (i.e., tweets , Facebook posts , news headlines , blogs , letters etc.). Experimental results suggest that the proposed multi-task framework outperforms the single-task frameworks in all experiments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:N6_Y7JlWxwsC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"In this paper, we hypothesize that sarcasm is closely related to sentiment and emotion, and thereby propose a multi-task deep learning framework to solve all these three problems simultaneously in a multi-modal conversational scenario. We, at first, manually annotate the recently released multi-modal MUStARD sarcasm dataset with sentiment and emotion classes, both implicit and explicit. For multi-tasking, we propose two attention mechanisms, viz. Inter-segment Inter-modal Attention (Ie-Attention) and Intra-segment Inter-modal Attention (Ia-Attention). The main motivation of Ie-Attention is to learn the relationship between the different segments of the sentence across the modalities. In contrast, Ia-Attention focuses within the same segment of the sentence across the modalities. Finally, representations from both the attentions are concatenated and shared across the five classes (ie, sarcasm, implicit sentiment, explicit sentiment, implicit emotion, explicit emotion) for multi-tasking. Experimental results on the extended version of the MUStARD dataset show the efficacy of our proposed approach for sarcasm detection over the existing state-of-the-art systems. The evaluation also shows that the proposed multi-task framework yields better performance for the primary task, ie, sarcasm detection, with the help of two secondary tasks, emotion and sentiment analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:w5CyTnyFq80C,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,Text summarization techniques become paramount in extracting relevant information from large databa-ses. Current paper attempts to build some extractive single document text summarization (ESDS) systems using multi-objective optimization (MOO) frameworks. Three techniques are proposed:(1) first is an integration of self-organizing map (SOM) and multi-objective differential evolution (MODE)(named as ESDS_SMODE)(2) second is based on multi-objective grey wolf optimizer (ESDS_MGWO) and (3) third is based on multi-objective water cycle algorithm (ESDS_MWCA). The sentences present in the document are first clustered utilizing the concept of multi-objective clustering. Two objective functions measuring compactness and separation of the sentence clusters in two different ways are optimized simultaneously using MOO framework. The proposed approach is able to automatically detect the number of …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:wyM6WWKXmoIC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Abstract Knowledge about protein–protein interactions is essential for understanding the biological processes such as metabolic pathways, DNA replication, and transcription etc. However, a majority of the existing Protein–Protein Interaction (PPI) systems are dependent primarily on the scientific literature, which is not yet accessible as a structured database. Thus, efficient information extraction systems are required for identifying PPI information from the large collection of biomedical texts. In this paper, we present a novel method based on attentive deep recurrent neural network, which combines multiple levels of representations exploiting word sequences and dependency path related information to identify protein–protein interaction (PPI) information from the text. We use the stacked attentive bi-directional long short term memory (Bi-LSTM) as our recurrent neural network to solve the PPI identification problem …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:R22Rs3tN8aoC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"In this paper, we propose a multilingual unsupervised NMT scheme which jointly trains multiple languages with a shared encoder and multiple decoders. Our approach is based on denoising autoencoding of each language and back-translating between English and multiple non-English languages. This results in a universal encoder which can encode any language participating in training into an inter-lingual representation, and language-specific decoders. Our experiments using only monolingual corpora show that multilingual unsupervised model performs better than the separately trained bilingual models achieving improvement of up to 1.48 BLEU points on WMT test sets. We also observe that even if we do not train the network for all possible translation directions, the network is still able to translate in a many-to-many fashion leveraging encoder’s ability to generate interlingual representation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:kO05sadLmrgC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"In recent times, multi-modal analysis has been an emerging and highly sought-after field at the intersection of natural language processing, computer vision, and speech processing. The prime objective of such studies is to leverage the diversified information,(eg, textual, acoustic and visual), for learning a model. The effective interaction among these modalities often leads to a better system in terms of performance. In this paper, we introduce a recurrent neural network based approach for the multi-modal sentiment and emotion analysis. The proposed model learns the inter-modal interaction among the participating modalities through an auto-encoder mechanism. We employ a context-aware attention module to exploit the correspondence among the neighboring utterances. We evaluate our proposed approach for five standard multi-modal affect analysis datasets. Experimental results suggest the efficacy of the proposed model for both sentiment and emotion analysis over various existing state-of-the-art systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:2Q0AJrNhS-QC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Automatically validating a research artefact is one of the frontiers in Artificial Intelligence (AI) that directly brings it close to competing with human intellect and intuition. Although criticised sometimes, the existing peer review system still stands as the benchmark of research validation. The present-day peer review process is not straightforward and demands profound domain knowledge, expertise, and intelligence of human reviewer (s), which is somewhat elusive with the current state of AI. However, the peer review texts, which contains rich sentiment information of the reviewer, reflecting his/her overall attitude towards the research in the paper, could be a valuable entity to predict the acceptance or rejection of the manuscript under consideration. Here in this work, we investigate the role of reviewer sentiment embedded within peer review texts to predict the peer review outcome. Our proposed deep neural architecture takes into account three channels of information: the paper, the corresponding reviews, and review’s polarity to predict the overall recommendation score as well as the final decision. We achieve significant performance improvement over the baselines (∼ 29% error reduction) proposed in a recently released dataset of peer reviews. An AI of this kind could assist the editors/program chairs as an additional layer of confidence, especially when non-responding/missing reviewers are frequent in present day peer review.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:4QKQTXcH0q8C,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Document clustering is the partitioning of a given collection of documents into various K- groups based on some similarity/dissimilarity criterion. This task has applications in scope detection of journals/conferences, development of some automated peer-review support systems, topic-modeling, latest cognitive-inspired works on text summarization, and classification of documents based on semantics, etc. In the current paper, a cognitive-inspired multi-objective automatic document clustering technique is proposed which is a fusion of self-organizing map (SOM) and multi-objective differential evolution approach. The variable number of cluster centers are encoded in different solutions of the population to determine the number of clusters from a data set in an automated way. These solutions undergo various genetic operations during evolution. The concept of SOM is utilized in designing new genetic operators …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:8VtEwCQfWZkC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"The significant rise in suicides is a major cause of concern in public health domain. Depression plays a major role in increasing suicide ideation among the individuals. Although most of the suicides can be avoided with prompt intercession and early diagnosis, it has been a serious challenge to detect the at-risk individuals. Our current work focuses on learning three closely related tasks, viz. depression detection, sentiment citation, and to investigate their impact in analysing the mental state of the victims. We extend the existing standard emotion annotated corpus of suicide notes in English, CEASE, with additional 2539 sentences collected from 120 new notes. We annotate the consolidated corpus with appropriate depression labels and multi-label emotion classes. We further leverage weak supervision to annotate the corpus with sentiment labels. We propose a deep multitask framework that features a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:OqYjx1B7R3oC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"In this paper, we assess the challenges for multi-domain, multi-lingual question answering, create necessary resources for benchmarking and develop a baseline model. We curate 500 articles in six different domains from the web. These articles form a comparable corpora of 250 English documents and 250 Hindi documents. From these comparable corpora, we have created 5, 495 question-answer pairs with the questions and answers, both being in English and Hindi. The question can be both factoid or short descriptive types. The answers are categorized in 6 coarse and 63 finer types. To the best of our knowledge, this is the very first attempt towards creating multi-domain, multi-lingual question answering evaluation involving English and Hindi. We develop a deep learning based model for classifying an input question into the coarse and finer categories depending upon the expected answer. Answers are extracted through similarity computation and subsequent ranking. For factoid question, we obtain an MRR value of 49. 10% and for short descriptive question, we obtain a BLEU score of 41. 37%. Evaluation of question classification model shows the accuracies of 90. 12% and 80. 30% for coarse and finer classes, respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:JH5k92_tO-AC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Transfer learning approaches for Neural Machine Translation (NMT) train a NMT model on the assisting-target language pair (parent model) which is later fine-tuned for the source-target language pair of interest (child model), with the target language being the same. In many cases, the assisting language has a different word order from the source language. We show that divergent word order adversely limits the benefits from transfer learning when little to no parallel corpus between the source and target language is available. To bridge this divergence, We propose to pre-order the assisting language sentence to match the word order of the source language and train the parent model. Our experiments on many language pairs show that bridging the word order gap leads to significant improvement in the translation quality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:KTwcwpFFj4wC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Code-mixing, the interleaving of two or more languages within a sentence or discourse is ubiquitous in multilingual societies. The lack of code-mixed training data is one of the major concerns for the development of end-to-end neural network-based models to be deployed for a variety of natural language processing (NLP) applications. A potential solution is to either manually create or crowd-source the code-mixed labelled data for the task at hand, but that requires much human efforts and often not feasible because of the language specific diversity in the code-mixed text. To circumvent the data scarcity issue, we propose an effective deep learning approach for automatically generating the code-mixed text from English to multiple languages without any parallel data. In order to train the neural network, we create synthetic code-mixed texts from the available parallel corpus by modelling various linguistic properties of code-mixing. Our codemixed text generator is built upon the encoder-decoder framework, where the encoder is augmented with the linguistic and task-agnostic features obtained from the transformer based language model. We also transfer the knowledge from a neural machine translation (NMT) to warm-start the training of code-mixed generator. Experimental results and in-depth analysis show the effectiveness of our proposed code-mixed text generation on eight diverse language pairs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:Weau3kkTRIMC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Getting manually labeled data in each domain is always an expensive and a time consuming task. Cross-domain sentiment analysis has emerged as a demanding concept where a labeled source domain facilitates a sentiment classifier for an unlabeled target domain. However, polarity orientation (positive or negative) and the significance of a word to express an opinion often differ from one domain to another domain. Owing to these differences, cross-domain sentiment classification is still a challenging task. In this paper, we propose that words that do not change their polarity and significance represent the transferable (usable) information across domains for cross-domain sentiment classification. We present a novel approach based on χ2 test and cosine-similarity between context vector of words to identify polarity preserving significant words across domains. Furthermore, we show that a weighted ensemble of the classifiers enhances the cross-domain classification performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:pYKElYtJMmwC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"We explore the use of two independent subsystems Byte Pair Encoding (BPE) and Morfessor as basic units for subword-level neural machine translation (NMT). We show that, for linguistically distant language-pairs Morfessor-based segmentation algorithm produces significantly better quality translation than BPE. However, for close language-pairs BPE-based subword-NMT may translate better than Morfessor-based subword-NMT. We propose a combined approach of these two segmentation algorithms Morfessor-BPE (M-BPE) which outperforms these two baseline systems in terms of BLEU score. Our results are supported by experiments on three language-pairs: English-Hindi, Bengali-Hindi and English-Bengali.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:9DLIHnF0jcYC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"The task of Dialogue Act Classification (DAC) that purports to capture communicative intent has been studied extensively. But these studies limit themselves to text. Non-verbal features (change of tone, facial expressions etc.) can provide cues to identify DAs, thus stressing the benefit of incorporating multi-modal inputs in the task. Also, the emotional state of the speaker has a substantial effect on the choice of the dialogue act, since conversations are often influenced by emotions. Hence, the effect of emotion too on automatic identification of DAs needs to be studied. In this work, we address the role of both multi-modality and emotion recognition (ER) in DAC. DAC and ER help each other by way of multi-task learning. One of the major contributions of this work is a new dataset-multimodal Emotion aware Dialogue Act dataset called EMOTyDA, collected from open-sourced dialogue datasets. To demonstrate the utility of EMOTyDA, we build an attention based (self, inter-modal, inter-task) multi-modal, multi-task Deep Neural Network (DNN) for joint learning of DAs and emotions. We show empirically that multi-modality and multi-tasking achieve better performance of DAC compared to uni-modal and single task DAC variants.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:q09DtPQ_434C,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"An essential component of any dialogue system is understanding the language which is known as spoken language understanding (SLU). Dialogue act classification (DAC), intent detection (ID) and slot filling (SF) are significant aspects of every dialogue system. In this paper, we propose a deep learning-based multi-task model that can perform DAC, ID and SF tasks together. We use a deep bi-directional recurrent neural network (RNN) with long short-term memory (LSTM) and gated recurrent unit (GRU) as the frameworks in our multi-task model. We use attention on the LSTM/GRU output for DAC and ID. The attention outputs are fed to individual task-specific dense layers for DAC and ID. The output of LSTM/GRU is fed to softmax layer for slot filling as well. Experiments on three datasets, i.e. ATIS, TRAINS and FRAMES, show that our proposed multi-task model performs better than the individual models as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:gnsKu8c89wgC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Fake news detection is a very prominent and essential task in the field of journalism. This challenging problem is seen so far in the field of politics, but it could be even more challenging when it is to be determined in the multi-domain platform. In this paper, we propose two effective models based on deep learning for solving fake news detection problem in online news contents of multiple domains. We evaluate our techniques on the two recently released datasets, namely FakeNews AMT and Celebrity for fake news detection. The proposed systems yield encouraging performance, outperforming the current handcrafted feature engineering based state-of-the-art system with a significant margin of 3.08% and 9.3% by the two models, respectively. In order to exploit the datasets, available for the related tasks, we perform cross-domain analysis (i.e. model trained on FakeNews AMT and tested on Celebrity and vice versa) to explore the applicability of our systems across the domains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:JavbeY_VQWIC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"A device receives documents and previously answered questions associated with a restricted domain, and processes the documents and the previously answered questions to generate a corpus of searchable information. The device receives a question associated with the restricted domain, and processes the question, with a machine learning model or a rule-based classifier model, to determine a classification type for the question. The device manipulates the question to generate a query from the question, and processes the query, with an expansion technique, to generate an expanded query. The device utilizes the expanded query, with the corpus of searchable information, to identify candidate answers to the question, and processes the candidate answers and the classification type for the question, with a deep learning model, to generate scored and ranked candidate answers to the question. The device …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:xyvS_IvSCKsC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"In this paper, we describe the creation of a resource-ASAP++-which is basically annotations of the Automatic Student Assessment Prize’s Automatic Essay Grading dataset. These annotations are scores for different attributes of the essays, such as content, word choice, organization, sentence fluency, etc. Each of these essays is scored by an annotator. We also report the results of each of the attributes using a Random Forest Classifier using a baseline set of attribute independent features as described by Zesch et al.(2015). We release and share this resource to facilitate further research into these attributes of essay grading.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:E7VqQtBCVmcC,http://www.cse.iitb.ac.in/~pb
Dr. Pushpak Bhattacharyya,"['Natural Language Processing', 'Machine Learning', 'Machine Translation', 'Cross Lingual IR', 'Word Sense Disambiguation']",52,"Efficient word representations play an important role in solving various problems related to Natural Language Processing (NLP), data mining, text mining etc. The issue of data sparsity poses a great challenge in creating efficient word representation model for solving the underlying problem. The problem is more intensified in resource-poor scenario due to the absence of sufficient amount of corpus. In this work, we propose to minimize the effect of data sparsity by leveraging bilingual word embeddings learned through a parallel corpus. We train and evaluate Long Short Term Memory (LSTM) based architecture for aspect level sentiment classification. The neural network architecture is further assisted by the handcrafted features for the prediction. We show the efficacy of the proposed model against state-of-the-art methods in two experimental setups i.e. multi-lingual and cross-lingual.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vvg-pAkAAAAJ&cstart=20&pagesize=80&citation_for_view=vvg-pAkAAAAJ:4e5Qn2KL_jwC,http://www.cse.iitb.ac.in/~pb
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Deep generative models have been praised for their ability to learn smooth latent representations of images, text, and audio, which can then be used to generate new, plausible data. Motivated by these success stories, there has been a surge of interest in developing deep generative models for automated molecule design. However, these models face several difficulties due to the unique characteristics of molecular graphs--their underlying structure is not Euclidean or grid-like, they remain isomorphic under permutation of the nodes' labels, and they come with a different number of nodes and edges. In this paper, we first propose a novel variational autoencoder for molecular graphs, whose encoder and decoder are specially designed to account for the above properties by means of several technical innovations. Moreover, in contrast with the state of the art, our decoder is able to provide the spatial coordinates of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&citation_for_view=hCbFmUUAAAAJ:x9HjRiAMpasC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"We investigate the problem of fair recommendation in the context of two-sided online platforms, comprising customers on one side and producers on the other. Traditionally, recommendation services in these platforms have focused on maximizing customer satisfaction by tailoring the results according to the personalized preferences of individual customers. However, our investigation reveals that such customer-centric design may lead to unfair distribution of exposure among the producers, which may adversely impact their well-being. On the other hand, a producer-centric design might become unfair to the customers. Thus, we consider fairness issues that span both customers and producers. Our approach involves a novel mapping of the fair recommendation problem to a constrained version of the problem of fairly allocating indivisible goods. Our proposed FairRec algorithm guarantees at least Maximin Share …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&citation_for_view=hCbFmUUAAAAJ:04dtUmz_MT0C,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Public shaming in online social networks and related online public forums like Twitter has been increasing in recent years. These events are known to have a devastating impact on the victim's social, political, and financial life. Notwithstanding its known ill effects, little has been done in popular online social media to remedy this, often by the excuse of large volume and diversity of such comments and, therefore, unfeasible number of human moderators required to achieve the task. In this paper, we automate the task of public shaming detection in Twitter from the perspective of victims and explore primarily two aspects, namely, events and shamers. Shaming tweets are categorized into six types: abusive, comparison, passing judgment, religious/ethnic, sarcasm/joke, and whataboutery, and each tweet is classified into one of these types or as nonshaming. It is observed that out of all the participating users who post …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&citation_for_view=hCbFmUUAAAAJ:RF4BjkDOTHkC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"In recent times, humanitarian organizations increasingly rely on social media to search for information useful for disaster response. These organizations have varying information needs ranging from general situational awareness (i.e., to understand a bigger picture) to focused information needs e.g., about infrastructure damage, urgent needs of affected people. This research proposes a novel approach to help crisis responders fulfill their information needs at different levels of granularities. Specifically, the proposed approach presents simple algorithms to identify sub-events and generate summaries of big volume of messages around those events using an Integer Linear Programming (ILP) technique. Extensive evaluation on a large set of real world Twitter dataset shows (a). our algorithm can identify important sub-events with high recall (b). the summarization scheme shows (6---30%) higher accuracy of our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:LYSM3I27WpsC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Microblogging sites like Twitter have become important sources of real-time information during disaster events. A large amount of valuable situational information is posted in these sites during disasters; however, the information is dispersed among hundreds of thousands of tweets containing sentiments and opinions of the masses. To effectively utilize microblogging sites during disaster events, it is necessary to not only extract the situational information from the large amounts of sentiments and opinions, but also to summarize the large amounts of situational information posted in real-time. During disasters in countries like India, a sizable number of tweets are posted in local resource-poor languages besides the normal English-language tweets. For instance, in the Indian subcontinent, a large number of tweets are posted in Hindi/Devanagari (the national language of India), and some of the information contained in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:f4T9rk490XkC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Microblogging sites like Twitter have become important sources of real-time information during disaster events. A large amount of valuable situational information is posted in these sites during disasters; however, the information is dispersed among hundreds of thousands of tweets containing sentiments and opinions of the masses. To effectively utilize microblogging sites during disaster events, it is necessary to not only extract the situational information from the large amounts of sentiments and opinions, but also to summarize the large amounts of situational information posted in real-time. During disasters in countries like India, a sizable number of tweets are posted in local resource-poor languages besides the normal English-language tweets. For instance, in the Indian subcontinent, a large number of tweets are posted in Hindi/Devanagari (the national language of India), and some of the information contained in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:eCFM_hdDfssC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"To help their users to discover important items at a particular time, major websites like Twitter, Yelp, TripAdvisor or NYTimes provide Top-K recommendations (e.g., 10 Trending Topics, Top 5 Hotels in Paris or 10 Most Viewed News Stories), which rely on crowdsourced popularity signals to select the items. However, different sections of a crowd may have different preferences, and there is a large silent majority who do not explicitly express their opinion. Also, the crowd often consists of actors like bots, spammers, or people running orchestrated campaigns. Recommendation algorithms today largely do not consider such nuances, hence are vulnerable to strategic manipulation by small but hyper-active user groups.
To fairly aggregate the preferences of all users while recommending top-K items, we borrow ideas from prior research on social choice theory, and identify a voting mechanism called Single Transferable …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:p9YawgimX9oC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Deep generative models have been praised for their ability to learn smooth latent representation of images, text, and audio, which can then be used to generate new, plausible data. However, current generative models are unable to work with graphs due to their unique characteristics—their underlying structure is not Euclidean or grid-like, they remain isomorphic under permutation of the nodes labels, and they come with a different number of nodes and edges. In this paper, we propose NeVAE, a novel variational autoencoder for graphs, whose encoder and decoder are specially designed to account for the above properties by means of several technical innovations. In addition, by using masking, the decoder is able to guarantee a set of local structural and functional properties in the generated graphs. Experiments reveal that our model is able to learn and mimic the generative process of several well-known random graph models and can be used to discover new molecules more effectively than several state of the art methods. Moreover, by utilizing Bayesian optimization over the continuous latent representation of molecules our model finds, we can also identify molecules that maximize certain desirable properties more effectively than alternatives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:KKiikWAUrRgC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:Ow2R9nchCv8C,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"The huge amount of tweets posted during a disaster event includes information about the present situation as well as the emotions/opinions of the masses. While looking through these tweets, we realized that a large amount of communal tweets, i.e., abusive posts targeting specific religious/racial groups are posted even during natural disasters-this paper focuses on such category of tweets, which is in sharp contrast to most of the prior research concentrating on extracting situational information. Considering the potentially adverse effects of communal tweets during disasters, in this paper, we develop a classifier to distinguish communal tweets from noncommunal ones, which performs significantly better than existing approaches. We also characterize the communal tweets posted during five recent disaster events, and the users who posted such tweets. Interestingly, we find that a large proportion of communal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:Q3_nmhWTCy0C,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"A large fraction of video content providers have adopted adaptive bitrate streaming over HTTP. The client player typically runs an adaptive bitrate (ABR) algorithm to decide upon the most optimal quality for the next few seconds of video playback. State-of-the-art ABR algorithms attempt to achieve an optimal trade-off among the competing objectives of high bitrate, less rebuffering, and high smoothness, in the face of unpredictable bandwidth variability. However, optimal bandwidth utilization does not necessarily ensure high quality of experience (QoE). Different users have different content preferences even within the same video, due to differences in team loyalties (in sport), character preferences (in movies and soaps), and so on. In this work, we present HotDASH, a system which enables opportune prefetching of user-preferred temporal video segments (called hotspots). HotDASH implements a prefetch module in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:q1ZQJjUA47MC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Decisions are increasingly taken by both humans and machine learning models. However, machine learning models are currently trained for full automation—they are not aware that some of the decisions may still be taken by humans. In this paper, we take a first step towards the development of machine learning models that are optimized to operate under different automation levels. More specifically, we first introduce the problem of ridge regression under human assistance and show that it is NP-hard. Then, we derive an alternative representation of the corresponding objective function as a difference of nondecreasing submodular functions. Building on this representation, we further show that the objective is nondecreasing and satisfies α-submodularity, a recently introduced notion of approximate submodularity. These properties allow a simple and efficient greedy algorithm to enjoy approximation guarantees at solving the problem. Experiments on synthetic and real-world data from two important applications—medical diagnosis and content moderation—demonstrate that the greedy algorithm beats several competitive baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:b2v3RnpdjZkC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"There are different modes of interaction with a software keyboard on a smartphone, such as typing and swyping. Patterns of such touch interactions on a keyboard may reflect emotions of a user. Since users may switch between different touch modalities while using a keyboard, therefore, automatic detection of emotion from touch patterns must consider both modalities in combination to detect the pattern. In this paper, we focus on identifying different features of touch interactions with a smartphone keyboard that lead to a personalized model for inferring user emotion. Since distinguishing typing and swyping activity is important to record the correct features, we designed a technique to correctly identify the modality. The ground truth labels for user emotion are collected directly from the user by periodically collecting self-reports. We jointly model typing and swyping features and correlate them with user provided self …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:UO6ax3c-pNsC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Microblogging platforms such as Twitter are widely used by eyewitnesses and affected people to post situational updates during mass convergence events such as natural and man-made disasters. These crisis-related messages disperse among multiple classes/categories such as infrastructure damage, shelter needs, information about missing, injured, and dead people. Moreover, we observe that sometimes people post information about their missing relatives and friends with personal details such as names and last seen location. The information requirements of different stakeholders (government, NGOs, and rescue workers) also vary a lot. This brings twofold challenges: 1) extracting important high-level situational updates from these messages, assigning them appropriate categories, and finally summarizing big trove of information in each category and 2) extracting small-scale time-critical sparse updates …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:HfY9tUF4VgMC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"A large population of users gets affected by sudden slowdown or shutdown of an enterprise application. System administrators and analysts spend considerable amount of time dealing with functional and performance bugs. These problems are particularly hard to detect and diagnose in most computer systems, since there is a huge amount of system generated supportability data (counters, logs etc.) that need to be analyzed. Most often, there isn't a very clear or obvious root cause. Timely identification of significant change in application behavior is very important to prevent negative impact on the service. In this paper, we present ADELE, an empirical, data-driven methodology for early detection of anomalies in data storage systems. The key feature of our solution is diligent selection of features from system logs and development of effective machine learning techniques for anomaly prediction. ADELE learns from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:w2Aknop99M4C,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"During a new disease outbreak, frustration and uncertainties among affected and vulnerable population increase. Affected communities look for known symptoms, prevention measures, and treatment strategies. On the other hand, health organizations try to get situational updates to assess the severity of the outbreak, known affected cases, and other details. Recent emergence of social media platforms such as Twitter provide convenient ways and fast access to disseminate and consume information to/from a wider audience. Research studies have shown potential of this online information to address information needs of concerned authorities during outbreaks, epidemics, and pandemics. In this work, we target three types of end-users (i) vulnerable population—people who are not yet affected and are looking for prevention related information (ii) affected population—people who are affected and looking …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:6HoeAlFIZOwC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Code-switching, the interleaving of two or more languages within a sentence or discourse is pervasive in multilingual societies. Accurate language models for code-switched text are critical for NLP tasks. State-of-the-art data-intensive neural language models are difficult to train well from scarce language-labeled code-switched text. A potential solution is to use deep generative models to synthesize large volumes of realistic code-switched text. Although generative adversarial networks and variational autoencoders can synthesize plausible monolingual text from continuous latent space, they cannot adequately address code-switched text, owing to their informal style and complex interplay between the constituent languages. We introduce VACS, a novel variational autoencoder architecture specifically tailored to code-switching phenomena. VACS encodes to and decodes from a two-level hierarchical representation, which models syntactic contextual signals in the lower level, and language switching signals in the upper layer. Sampling representations from the prior and decoding them produced well-formed, diverse code-switched sentences. Extensive experiments show that using synthetic code-switched text with natural monolingual data results in significant (33.06%) drop in perplexity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:kkSDTGFLcmwC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"The rate of mental health disorders is rising across the globe. While it significantly affects the quality of life, an early detection can prevent the fatal consequences. Existing literature suggests that mobile based sensing technology can be used to determine different mental health conditions like stress, bipolar disorder. In today's smartphone based communication, a significant portion is based on instant messaging apps like WhatsApp; thus providing the opportunity to unobtrusively monitor the text input interaction pattern to track mental state. We, in this paper, leverage on the text entry pattern to track multiple emotion states. We design, develop and implement an Android based smartphone keyboard EmoKey, which monitors user's typing pattern and determines four emotion states (happy, sad, stressed, relaxed) by developing an on-device, personalized machine learning model. We evaluate EmoKey with 22 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:07QC26MHY14C,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"The networked opinion diffusion in online social networks (OSN) is governed by the two genres of opinions-endogenous opinions that are driven by the influence of social contacts between users, and exogenous opinions which are formed by external effects like news, feeds etc. Such duplex opinion dynamics is led by users belonging to two categories- organic users who generally post endogenous opinions and extrinsic users who are susceptible to externalities, and mostly post the exogenous messages. Precise demarcation of endogenous and exogenous messages offers an important cue to opinion modeling, thereby enhancing its predictive performance. On the other hand, accurate user selection aids to detect extrinsic users, which in turn helps in opinion shaping. In this paper, we design CherryPick, a novel learning machinery that classifies the opinions and users by solving a joint inference task in message …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:c2LjitseEfMC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Recently, biomedical version of embeddings obtained from language models such as BioELMo have shown state-of-the-art results for the textual inference task in the medical domain. In this paper, we explore how to incorporate structured domain knowledge, available in the form of a knowledge graph (UMLS), for the Medical NLI task. Specifically, we experiment with fusing embeddings obtained from knowledge graph with the state-of-the-art approaches for NLI task (ESIM model). We also experiment with fusing the domain-specific sentiment information for the task. Experiments conducted on MedNLI dataset clearly show that this strategy improves the baseline BioELMo architecture for the Medical NLI task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:oFKsPyNwwpYC,http://www.facweb.iitkgp.ac.in/~niloy/
Niloy Ganguly,"['Artificial Intelligence', 'Social Computing', 'Natural Language Processing', 'Network Science', 'Machine Learning']",43,"Manually extracting relevant aspects and opinions from large volumes of user-generated text is a time-consuming process. Summaries, on the other hand, help readers with limited time budgets to quickly consume the key ideas from the data. State-of-the-art approaches for multi-document summarization, however, do not consider user preferences while generating summaries. In this work, we argue the need and propose a solution for generating personalized aspect-based opinion summaries from large collections of online tourist reviews. We let our readers decide and control several attributes of the summary such as the length and specific aspects of interest among others. Specifically, we take an unsupervised approach to extract coherent aspects from tourist reviews posted onTripAdvisor. We then propose an Integer Linear Programming (ILP) based extractive technique to select an informative subset of opinions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=hCbFmUUAAAAJ&cstart=20&pagesize=80&citation_for_view=hCbFmUUAAAAJ:DxlTmyU89zoC,http://www.facweb.iitkgp.ac.in/~niloy/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Hate speech is considered to be one of the major issues currently plaguing the online social media. With online hate speech culminating in gruesome scenarios like the Rohingya genocide in Myanmar, anti-Muslim mob violence in Sri Lanka, and the Pittsburgh synagogue shooting, there is a dire need to understand the dynamics of user interaction that facilitate the spread of such hateful content. In this paper, we perform the first study that looks into the diffusion dynamics of the posts made by hateful and non-hateful users on Gab (Gab.com). We collect a massive dataset of 341K users with 21M posts and investigate the diffusion of the posts generated by hateful and non-hateful users. We observe that the content generated by the hateful users tend to spread faster, farther and reach a much wider audience as compared to the content generated by normal users. We further analyze the hateful and non-hateful users …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:vDijr-p_gm4C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this paper, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (ie, hate, offensive or normal), the target community (ie, the community that has been the victim of hate speech/offensive speech in the post), and the rationales, ie, the portions of the post on which their labelling decision (as hate, offensive or normal) is based. We utilize existing state-of-the-art models and observe that even models that perform very well in classification do not score high on explainability metrics like model plausibility and faithfulness. We also observe that models, which utilize the human rationales for training, perform better in reducing unintended bias towards target communities. We have made our code and dataset public for other researchers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:a3BOlSfXSfwC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Hate content in social media is ever increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. However, in order to have a successful promotion of such counterspeech, one has to have a deep understanding of its dynamics in the online world. Lack of carefully curated data largely inhibits such understanding. In this paper, we create and release the first ever dataset for counterspeech using comments from YouTube. The data contains 13,924 manually annotated comments where the labels indicate whether a comment is a counterspeech or not. This data allows us to perform a rigorous measurement study characterizing the linguistic structure of counterspeech for the first time. This analysis results in various interesting insights such as: the counterspeech comments receive much more likes as compared to the noncounterspeech comments, for certain communities majority of the non-counterspeech comments tend to be hate speech, the different types of counterspeech are not all equally effective and the language choice of users posting counterspeech is largely different from those posting non-counterspeech as revealed by a detailed psycholinguistic analysis. Finally, we build a set of machine learning models that are able to automatically detect counterspeech in YouTube videos with an F1-score of 0.71. We also build …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:yB1At4FlUx8C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"In recent times, humanitarian organizations increasingly rely on social media to search for information useful for disaster response. These organizations have varying information needs ranging from general situational awareness (i.e., to understand a bigger picture) to focused information needs e.g., about infrastructure damage, urgent needs of affected people. This research proposes a novel approach to help crisis responders fulfill their information needs at different levels of granularities. Specifically, the proposed approach presents simple algorithms to identify sub-events and generate summaries of big volume of messages around those events using an Integer Linear Programming (ILP) technique. Extensive evaluation on a large set of real world Twitter dataset shows (a). our algorithm can identify important sub-events with high recall (b). the summarization scheme shows (6---30%) higher accuracy of our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:9Nmd_mFXekcC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Microblogging sites like Twitter have become important sources of real-time information during disaster events. A large amount of valuable situational information is posted in these sites during disasters; however, the information is dispersed among hundreds of thousands of tweets containing sentiments and opinions of the masses. To effectively utilize microblogging sites during disaster events, it is necessary to not only extract the situational information from the large amounts of sentiments and opinions, but also to summarize the large amounts of situational information posted in real-time. During disasters in countries like India, a sizable number of tweets are posted in local resource-poor languages besides the normal English-language tweets. For instance, in the Indian subcontinent, a large number of tweets are posted in Hindi/Devanagari (the national language of India), and some of the information contained in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:nrtMV_XWKgEC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"With the ongoing debate on 'freedom of speech' vs. 'hate speech,' there is an urgent need to carefully understand the consequences of the inevitable culmination of the two, i.e., 'freedom of hate speech' over time. An ideal scenario to understand this would be to observe the effects of hate speech in an (almost) unrestricted environment. Hence, we perform the first temporal analysis of hate speech on Gab.com, a social media site with very loose moderation policy. We first generate temporal snapshots of Gab from millions of posts and users. Using these temporal snapshots, we compute an activity vector based on DeGroot model to identify hateful users. The amount of hate speech in Gab is steadily increasing and the new users are becoming hateful at an increased and faster rate. Further, our analysis analysis reveals that the hate users are occupying the prominent positions in the Gab network. Also, the language …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:OcBU2YAGkTUC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Social media platforms usually tackle the proliferation of hate speech by blocking/suspending the message or account. One of the major drawback of such measures is the restriction of free speech. In this paper, we investigate the interaction of hatespeech and the responses that counter it (aka counter-speech). One of the prime contribution of this work is that we developed and released1 a dataset where we annotate pairs of hate and counter users.
We perform several lexical, linguistic and psycholinguistic analysis on these annotated accounts and observe that the couterspeakers of the target communities employ different strategies to tackle the hatespeech. The hate users seem to be more popular as we observe that they are more subjective, express more negative sentiment, tweet more and have more followers. While the hate users seem to use words more about envy, hate, negative emotion, swearing terms …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:PoWvk5oyLR8C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"In Twitter, there is a rising trend in abusive behavior which often leads to incivility. This trend is affecting users mentally and as a result they tend to leave Twitter and other such social networking sites thus depleting the active user base. In this paper, we study factors associated with incivility. We observe that the act of incivility is highly correlated with the opinion differences between the account holder (i.e., the user writing the incivil tweet) and the target (i.e., the user for whom the incivil tweet is meant for or targeted), toward a named entity. We introduce a character level CNN model and incorporate the entity-specific sentiment information for efficient incivility detection which significantly outperforms multiple baseline methods achieving an impressive accuracy of 93.3% (4.9% improvement over the best baseline). In a post-hoc analysis, we also study the behavioral aspects of the targets and account holders and try to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:0KyAp5RtaNEC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Entity linking (or Normalization) is an essential task in text mining that maps the entity mentions in the medical text to standard entities in a given Knowledge Base (KB). This task is of great importance in the medical domain. It can also be used for merging different medical and clinical ontologies. In this paper, we center around the problem of disease linking or normalization. This task is executed in two phases: candidate generation and candidate scoring. In this paper, we present an approach to rank the candidate Knowledge Base entries based on their similarity with disease mention. We make use of the Triplet Network for candidate ranking. While the existing methods have used carefully generated sieves and external resources for candidate generation, we introduce a robust and portable candidate generation scheme that does not make use of the hand-crafted rules. Experimental results on the standard benchmark NCBI disease dataset demonstrate that our system outperforms the prior methods by a significant margin.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:ILKRHgRFtOwC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"With the online proliferation of hate speech, there is an urgent need for systems that can detect such harmful content. In this paper, We present the machine learning models developed for the Automatic Misogyny Identification (AMI) shared task at EVALITA 2018. We generate three types of features: Sentence Embeddings, TF-IDF Vectors, and BOW Vectors to represent each tweet. These features are then concatenated and fed into the machine learning models. Our model came First for the English Subtask A and Fifth for the English Subtask B. We release our winning model for public use and it's available at https://github.com/punyajoy/Hateminers-EVALITA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&citation_for_view=F14FHsIAAAAJ:AvfA0Oy_GE0C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Microblogging platforms such as Twitter are widely used by eyewitnesses and affected people to post situational updates during mass convergence events such as natural and man-made disasters. These crisis-related messages disperse among multiple classes/categories such as infrastructure damage, shelter needs, information about missing, injured, and dead people. Moreover, we observe that sometimes people post information about their missing relatives and friends with personal details such as names and last seen location. The information requirements of different stakeholders (government, NGOs, and rescue workers) also vary a lot. This brings twofold challenges: 1) extracting important high-level situational updates from these messages, assigning them appropriate categories, and finally summarizing big trove of information in each category and 2) extracting small-scale time-critical sparse updates …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:kuK5TVdYjLIC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Scientific papers are complex and understanding the usefulness of these papers requires prior knowledge. Peer reviews are comments on a paper provided by designated experts on that field and hold a substantial amount of information, not only for the editors and chairs to make the final decision, but also to judge the potential impact of the paper. In this paper, we propose to use aspect-based sentiment analysis of scientific reviews to be able to extract useful information, which correlates well with the accept/reject decision.
While working on a dataset of close to 8k reviews from ICLR, one of the top conferences in the field of machine learning, we use an active learning framework to build a training dataset for aspect prediction, which is further used to obtain the aspects and sentiments for the entire dataset. We show that the distribution of aspect-based sentiments obtained from a review is significantly different for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:0N-VGjzr574C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Reducing hateful and offensive content in online social media pose a dual problem for the moderators. On the one hand, rigid censorship on social media cannot be imposed. On the other, the free flow of such content cannot be allowed. Hence, we require efficient abusive language detection system to detect such harmful content in social media. In this paper, we present our machine learning model, HateMonitor, developed for Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC), a shared task at FIRE 2019. We have used a Gradient Boosting model, along with BERT and LASER embeddings, to make the system language agnostic. Our model came at First position for the German sub-task A. We have also made our model public at https://github.com/punyajoy/HateMonitors-HASOC .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:LI9QrySNdTsC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Recently, biomedical version of embeddings obtained from language models such as BioELMo have shown state-of-the-art results for the textual inference task in the medical domain. In this paper, we explore how to incorporate structured domain knowledge, available in the form of a knowledge graph (UMLS), for the Medical NLI task. Specifically, we experiment with fusing embeddings obtained from knowledge graph with the state-of-the-art approaches for NLI task (ESIM model). We also experiment with fusing the domain-specific sentiment information for the task. Experiments conducted on MedNLI dataset clearly show that this strategy improves the baseline BioELMo architecture for the Medical NLI task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:TIZ-Mc8IlK0C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Aspect Sentiment Triplet Extraction (ASTE) deals with extracting opinion triplets, consisting of an opinion target or aspect, its associated sentiment, and the corresponding opinion term/span explaining the rationale behind the sentiment. Existing research efforts are majorly tagging-based. Among the methods taking a sequence tagging approach, some fail to capture the strong interdependence between the three opinion factors, whereas others fall short of identifying triplets with overlapping aspect/opinion spans. A recent grid tagging approach on the other hand fails to capture the span-level semantics while predicting the sentiment between an aspect-opinion pair. Different from these, we present a tagging-free solution for the task, while addressing the limitations of the existing works. We adapt an encoder-decoder architecture with a Pointer Network-based decoding framework that generates an entire opinion triplet at each time step thereby making our solution end-to-end. Interactions between the aspects and opinions are effectively captured by the decoder by considering their entire detected spans while predicting their connecting sentiment. Extensive experiments on several benchmark datasets establish the better efficacy of our proposed approach, especially in the recall, and in predicting multiple and aspect/opinion-overlapped triplets from the same review sentence. We report our results both with and without BERT and also demonstrate the utility of domain-specific BERT post-training for the task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:QD3KBmkZPeQC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Manually extracting relevant aspects and opinions from large volumes of user-generated text is a time-consuming process. Summaries, on the other hand, help readers with limited time budgets to quickly consume the key ideas from the data. State-of-the-art approaches for multi-document summarization, however, do not consider user preferences while generating summaries. In this work, we argue the need and propose a solution for generating personalized aspect-based opinion summaries from large collections of online tourist reviews. We let our readers decide and control several attributes of the summary such as the length and specific aspects of interest among others. Specifically, we take an unsupervised approach to extract coherent aspects from tourist reviews posted onTripAdvisor. We then propose an Integer Linear Programming (ILP) based extractive technique to select an informative subset of opinions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:FPJr55Dyh1AC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"We propose a framework using energy-based models for multiple structured prediction tasks in Sanskrit. Ours is an arc-factored model, similar to the graph-based parsing approaches, and we consider the tasks of word segmentation, morphological parsing, dependency parsing, syntactic linearization, and prosodification, a “prosody-level” task we introduce in this work. Ours is a search-based structured prediction framework, which expects a graph as input, where relevant linguistic information is encoded in the nodes, and the edges are then used to indicate the association between these nodes. Typically, the state-of-the-art models for morphosyntactic tasks in morphologically rich languages still rely on hand-crafted features for their performance. But here, we automate the learning of the feature …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:yMeIxYmEMEAC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"The task of relation extraction is about identifying entities and relations among them in free text for the enrichment of structured knowledge bases (KBs). In this paper, we present a comprehensive survey of this important research topic in natural language processing. Recently, with the advances made in the continuous representation of words (word embeddings) and deep neural architectures, many research works are published in the area of relation extraction. To help future research, we present a comprehensive review of the recently published research works in relation extraction. Previous surveys on this task covered only one aspect of relation extraction that is pipeline-based relation extraction approaches at the sentence level. In this survey, we cover sentence-level relation extraction to document-level relation extraction, pipeline-based approaches to joint extraction approaches, annotated datasets to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:gVv57TyPmFsC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"There is an abundance of digitised texts available in Sanskrit. However, the word segmentation task in such texts are challenging due to the issue of 'Sandhi'. In Sandhi, words in a sentence often fuse together to form a single chunk of text, where the word delimiter vanishes and sounds at the word boundaries undergo transformations, which is also reflected in the written text. Here, we propose an approach that uses a deep sequence to sequence (seq2seq) model that takes only the sandhied string as the input and predicts the unsandhied string. The state of the art models are linguistically involved and have external dependencies for the lexical and morphological analysis of the input. Our model can be trained ""overnight"" and be used for production. In spite of the knowledge lean approach, our system preforms better than the current state of the art by gaining a percentage increase of 16.79 % than the current state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:fEOibwPWpKIC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"With the exponential growth of online marketplaces and user-generated content therein, aspect-based sentiment analysis has become more important than ever. In this work, we critically review a representative sample of the models published during the past six years through the lens of a practitioner, with an eye towards deployment in production. First, our rigorous empirical evaluation reveals poor reproducibility: an average 4–5% drop in test accuracy across the sample. Second, to further bolster our confidence in empirical evaluation, we report experiments on two challenging data slices, and observe a consistent 12–55% drop in accuracy. Third, we study the possibility of transfer across domains and observe that as little as 10–25% of the domain-specific training dataset, when used in conjunction with datasets from other domains within the same locale, largely closes the gap between complete cross …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:Aul-kAQHnToC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Identification of potential Drug-Drug Interactions (DDI) for newly developed drugs is essential in public healthcare. Computational methods of DDI prediction rely on known interactions to learn possible interaction between drug pairs whose interactions are unknown. Past work has used various similarity measures of drugs to predict DDIs. In this paper, we propose an effective approach to DDI Prediction using rich drug representations utilizing multiple knowledge sources. We have used the Drug-Target Interaction (DTI) Network to learn an embedding of drugs by using the metapath2vec algorithm. We have also used drug representation gained from the rich chemical structure representation of drugs using Variational Auto-Encoder. The DDI prediction problem is modeled as a link prediction problem in the DDI network containing known interactions. We represent the nodes in the DDI network as their embeddings …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:-FonjvnnhkoC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"We investigate the use of word embeddings for query translation to improve precision in cross-language information retrieval (CLIR). Word vectors represent words in a distributional space such that syntactically or semantically similar words are close to each other in this space. Multilingual word embeddings are constructed in such a way that similar words across languages have similar vector representations. We explore the effective use of bilingual and multilingual word embeddings learned from comparable corpora of Indic languages to the task of CLIR.
We propose a clustering method based on the multilingual word vectors to group similar words across languages. For this we construct a graph with words from multiple languages as nodes and with edges connecting words with similar vectors. We use the Louvain method for community detection to find communities in this graph. We show that choosing target …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:Z5m8FVwuT1cC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the various linguistic peculiarities present in the language. The Sanskrit language is lexically productive, undergoes euphonic assimilation of phones at the word boundaries and exhibits variations in spelling conventions and in pronunciations. In this work, we propose the first large scale study of automatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact of unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR dataset for Sanskrit, which faithfully captures several of the linguistic characteristics expressed by the language. We investigate the role of different acoustic model and language model units in ASR systems for Sanskrit. We also propose a new modelling unit, inspired by the syllable level unit selection, that captures character sequences from one vowel in the word to the next vowel. We also highlight the importance of choosing graphemic representations for Sanskrit and show the impact of this choice on word error rates (WER). Finally, we extend these insights from Sanskrit ASR for building ASR systems in two other Indic languages, Gujarati and Telugu. For both these languages, our experimental results show that the use of phonetic based graphemic representations in ASR results in performance improvements as compared to ASR systems that use native scripts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:vDZJ-YLwNdEC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Generative models for dialog systems have gained much interest because of the recent success of RNN and Transformer based models in tasks like question answering and summarization. Although the task of dialog response generation is generally seen as a sequence-to-sequence (Seq2Seq) problem, researchers in the past have found it challenging to train dialog systems using the standard Seq2Seq models. Therefore, to help the model learn meaningful utterance and conversation level features, Sordoni et al. (2015b); Serban et al. (2016) proposed Hierarchical RNN architecture, which was later adopted by several other RNN based dialog systems. With the transformer-based models dominating the seq2seq problems lately, the natural question to ask is the applicability of the notion of hierarchy in transformer based dialog systems. In this paper, we propose a generalized framework for Hierarchical Transformer Encoders and show how a standard transformer can be morphed into any hierarchical encoder, including HRED and HIBERT like models, by using specially designed attention masks and positional encodings. We demonstrate that Hierarchical Encoding helps achieve better natural language understanding of the contexts in transformer-based models for task-oriented dialog systems through a wide range of experiments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:HeT0ZceujKMC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"In this paper, we develop a content-cum-user based deep learning framework DeepTagRec to recommend appropriate question tags on Stack Overflow. The proposed system learns the content representation from question title and body. Subsequently, the learnt representation from heterogeneous relationship between user and tags is fused with the content representation for the final tag prediction. On a very large-scale dataset comprising half a million question posts, DeepTagRec beats all the baselines; in particular, it significantly outperforms the best performing baseline TagCombine achieving an overall gain of 60.8% and 36.8% in precision@3 and recall@10 respectively. DeepTagRec also achieves 63% and 33.14% maximum improvement in exact-k accuracy and top-k accuracy respectively over TagCombine.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:EYYDruWGBe4C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"The configurational information in sentences of a free word order language such as Sanskrit is of limited use. Thus, the context of the entire sentence will be desirable even for basic processing tasks such as word segmentation. We propose a structured prediction framework that jointly solves the word segmentation and morphological tagging tasks in Sanskrit. We build an energy based model where we adopt approaches generally employed in graph based parsing techniques (McDonald et al., 2005a; Carreras, 2007). Our model outperforms the state of the art with an F-Score of 96.92 (percentage improvement of 7.06%) while using less than one-tenth of the task-specific training data. We find that the use of a graph based ap- proach instead of a traditional lattice-based sequential labelling approach leads to a percentage gain of 12.6% in F-Score for the segmentation task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:uc_IGeMz5qoC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Distributed representations of words learned from text have proved to be successful in various natural language processing tasks in recent times. While some methods represent words as vectors computed from text using predictive model (Word2vec) or dense count based model (GloVe), others attempt to represent these in a distributional thesaurus network structure where the neighborhood of a word is a set of words having adequate context overlap. Being motivated by recent surge of research in network embedding techniques (DeepWalk, LINE, node2vec etc.), we turn a distributional thesaurus network into dense word vectors and investigate the usefulness of distributional thesaurus embedding in improving overall word representation. This is the first attempt where we show that combining the proposed word representation obtained by distributional thesaurus embedding with the state-of-the-art word representations helps in improving the performance by a significant margin when evaluated against NLP tasks like word similarity and relatedness, synonym detection, analogy detection. Additionally, we show that even without using any handcrafted lexical resources we can come up with representations having comparable performance in the word similarity and relatedness tasks compared to the representations where a lexical resource has been used.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:j8SEvjWlNXcC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Social media platforms like Twitter, Gab, Facebook are available in the market to billions1 of users. These platforms allow users to share their ideas and opinions instantly almost with no cost. These have already been utilized by bad actors in the society to cause damage. Scenarios like the Rohingya genocide in Myanmar, anti-Muslim mob violence in Sri Lanka, and the Pittsburgh synagogue shooting can be linked to these platforms. Recently, hate speech is considered to be one of the major issues poisoning the online social media environment. To keep these platforms healthy there is a need to understand how these hateful content spread, how hateful users behave and finally, what could be an effective way to mitigate hate speech. In this article, we look at the recent advances and issues surrounding hate speech in online social media. We take three different perspectives - analysis & spread, detection, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:yqoGN6RLRZoC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Anonymity forms an integral and important part of our digital life. It enables us to express our true selves without the fear of judgment. In this paper, we investigate the different aspects of anonymity in the social Q&A site Quora. Quora allows users to explicitly post anonymous questions and such activity in this forum has become normative rather than a taboo. Through an analysis of millions of questions, we observe that at a global scale almost no difference manifests between the linguistic structure of the anonymous and the non-anonymous questions posted on Quora. We find that topical mixing at the global scale to be the primary reason for the absence. However, the differences start to feature once we “deep dive” and (topically) cluster the questions and compare them. In particular, we observe that the choice to post the question as anonymous is dependent on the user’s perception of anonymity and they often …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:zLWjf1WUPmwC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Neural sequence labelling approaches have achieved state of the art results in morphological tagging. We evaluate the efficacy of four standard sequence labelling models on Sanskrit, a morphologically rich, fusional Indian language. As its label space can theoretically contain more than 40,000 labels, systems that explicitly model the internal structure of a label are more suited for the task, because of their ability to generalise to labels not seen during training. We find that although some neural models perform better than others, one of the common causes for error for all of these models is mispredictions due to syncretism.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:XoXfffV-tXoC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"We propose a post-OCR text correction approach for digitising texts in Romanised Sanskrit. Owing to the lack of resources our approach uses OCR models trained for other languages written in Roman. Currently, there exists no dataset available for Romanised Sanskrit OCR. So, we bootstrap a dataset of 430 images, scanned in two different settings and their corresponding ground truth. For training, we synthetically generate training images for both the settings. We find that the use of copying mechanism (Gu et al., 2016) yields a percentage increase of 7.69 in Character Recognition Rate (CRR) than the current state of the art model in solving monotone sequence-to-sequence tasks (Schnober et al., 2016). We find that our system is robust in combating OCR-prone errors, as it obtains a CRR of 87.01% from an OCR output with CRR of 35.76% for one of the dataset settings. A human judgment survey performed on the models shows that our proposed model results in predictions which are faster to comprehend and faster to improve for a human than the other systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:EkHepimYqZsC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"We present CL Scholar, the ACL Anthology knowledge graph miner to facilitate high-quality search and exploration of current research progress in the computational linguistics community. In contrast to previous works, periodically crawling, indexing and processing of new incoming articles is completely automated in the current system. CL Scholar utilizes both textual and network information for knowledge graph construction. As an additional novel initiative, CL Scholar supports more than 1200 scholarly natural language queries along with standard keyword-based search on constructed knowledge graph. It answers binary, statistical and list based natural language queries. The current system is deployed at http://cnerg.iitkgp.ac.in/aclakg. We also provide REST API support along with bulk download facility. Our code and data are available at https://github.com/CLScholar.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:VLnqNzywnoUC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Hate speech is regarded as one of the crucial issues plaguing the online social media. The current literature on hate speech detection leverages primarily the textual content to find hateful posts and subsequently identify hateful users. However, this methodology disregards the social connections between users. In this paper, we run a detailed exploration of the problem space and investigate an array of models ranging from purely textual to graph based to finally semi-supervised techniques using Graph Neural Networks (GNN) that utilize both textual and graph-based features. We run exhaustive experiments on two datasets -- Gab, which is loosely moderated and Twitter, which is strictly moderated. Overall the AGNN model achieves 0.791 macro F1-score on the Gab dataset and 0.780 macro F1-score on the Twitter dataset using only 5% of the labeled instances, considerably outperforming all the other models …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:0CzhzZyukY4C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Morphologically rich languages seem to benefit from joint processing of morphology and syntax, as compared to pipeline architectures. We propose a graph-based model for joint morphological parsing and dependency parsing in Sanskrit. Here, we extend the Energy based model framework (Krishna et al., 2020), proposed for several structured prediction tasks in Sanskrit, in 2 simple yet significant ways. First, the framework’s default input graph generation method is modified to generate a multigraph, which enables the use of an exact search inference. Second, we prune the input search space using a linguistically motivated approach, rooted in the traditional grammatical analysis of Sanskrit. Our experiments show that the morphological parsing from our joint model outperforms standalone morphological parsers. We report state of the art results in morphological parsing, and in dependency parsing, both in standalone (with gold morphological tags) and joint morphosyntactic parsing setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:fFSKOagxvKUC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"The word ordering in a Sanskrit verse is often not aligned with its corresponding prose order. Conversion of the verse to its corresponding prose helps in better comprehension of the construction. Owing to the resource constraints, we formulate this task as a word ordering (linearisation) task. In doing so, we completely ignore the word arrangement at the verse side. kāvya guru, the approach we propose, essentially consists of a pipeline of two pretraining steps followed by a seq2seq model. The first pretraining step learns task-specific token embeddings from pretrained embeddings. In the next step, we generate multiple possible hypotheses for possible word arrangements of the input% using another pretraining step. We then use them as inputs to a neural seq2seq model for the final prediction. We empirically show that the hypotheses generated by our pretraining step result in predictions that consistently outperform predictions based on the original order in the verse. Overall, kāvya guru outperforms current state of the art models in linearisation for the poetry to prose conversion task in Sanskrit.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:KUbvn5osdkgC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"The compositionality degree of multiword expressions indicates to what extent the meaning of a phrase can be derived from the meaning of its constituents and their grammatical relations. Prediction of (non)-compositionality is a task that has been frequently addressed with distributional semantic models. We introduce a novel technique to blend hierarchical information with distributional information for predicting compositionality. In particular, we use hypernymy information of the multiword and its constituents encoded in the form of the recently introduced Poincar\'e embeddings in addition to the distributional information to detect compositionality for noun phrases. Using a weighted average of the distributional similarity and a Poincar\'e similarity function, we obtain consistent and substantial, statistically significant improvement across three gold standard datasets over state-of-the-art models based on distributional information only. Unlike traditional approaches that solely use an unsupervised setting, we have also framed the problem as a supervised task, obtaining comparable improvements. Further, we publicly release our Poincar\'e embeddings, which are trained on the output of handcrafted lexical-syntactic patterns on a large corpus.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:hMsQuOkrut0C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"YouTube is the leading social media platform for sharing videos. As a result, it is plagued with misleading content that includes staged videos presented as real footages from an incident, videos with misrepresented context and videos where audio/video content is morphed. We tackle the problem of detecting such misleading videos as a supervised classification task. We develop UCNet - a deep network to detect fake videos and perform our experiments on two datasets - VAVD created by us and publicly available FVC [8]. We achieve a macro averaged F-score of 0.82 while training and testing on a 70:30 split of FVC, while the baseline model scores 0.36. We find that the proposed model generalizes well when trained on one dataset and tested on the other.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:BwyfMAYsbu0C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,This paper aims towards building an automated conversational assistant to help customers in an e-commerce scenario. Our dataset consists of live chat messages between human agents and buyers. These chats belong to many different issue types and we build a multi-instance SVM classifier to automatically classify these chats into the corresponding issue types. We further use this insight to append the category information obtained from the classifier to an LSTM based architecture to be able to provide appropriate responses given an utterance by a human agent. We find that using class information along with the base dual encoder model helps in improving the quality of the retrieved responses in terms of BLEU scores. Human judgement experiments validate that using class information is able to bring out relevant messages in top-3 and top-5 responses much more number of times than the base …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:-_dYPAW6P2MC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"The task of Legal Statute Identification (LSI) aims to identify the legal statutes that are relevant to a given description of facts or evidence of a legal case. Existing methods only utilize the textual content of facts and legal articles to guide such a task. However, the citation network among case documents and legal statutes is a rich source of additional information, which is not considered by existing models. In this work, we take the first step towards utilising both the text and the legal citation network for the LSI task. We curate a large novel dataset for this task, including facts of cases from several major Indian Courts of Law, and statutes from the Indian Penal Code (IPC). Modeling the statutes and training documents as a heterogeneous graph, our proposed model LeSICiN can learn rich textual and graphical features, and can also tune itself to correlate these features. Thereafter, the model can be used to inductively predict links between test documents (new nodes whose graphical features are not available to the model) and statutes (existing nodes). Extensive experiments on the dataset show that our model comfortably outperforms several state-of-the-art baselines, by exploiting the graphical structure along with textual features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:lgwcVrK6X84C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"We propose an automated approach for semantic class identification of compounds in Sanskrit. It is essential to extract semantic information hidden in compounds for improving overall downstream Natural Language Processing (NLP) applications such as information extraction, question answering, machine translation, and many more. In this work, we systematically investigate the following research question: Can recent advances in neural network outperform traditional hand engineered feature based methods on the semantic level multi-class compound classification task for Sanskrit? Contrary to the previous methods, our method does not require feature engineering. For well-organized analysis, we categorize neural systems based on Multi-Layer Perceptron (MLP), Convolution Neural Network (CNN) and Long Short Term Memory (LSTM) architecture and feed input to the system from one of the possible levels, namely, word level, sub-word level, and character level. Our best system with LSTM architecture and FastText embedding with end-to-end training has shown promising results in terms of F-score (0.73) compared to the state of the art method based on feature engineering (0.74) and outperformed in terms of accuracy (77.68%).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:k8Z6L05lTy4C,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"A leaderboard is a tabular presentation of performance scores of the best competing techniques that address a specific scientific problem. Manually maintained leaderboards take time to emerge, which induces a latency in performance discovery and meaningful comparison. This can delay dissemination of best practices to non-experts and practitioners. Regarding papers as proxies for techniques, we present a new system to automatically discover and maintain leaderboards in the form of partial orders between papers, based on performance reported therein. In principle, a leaderboard depends on the task, data set, other experimental settings, and the choice of performance metrics. Often there are also tradeoffs between different metrics. Thus, leaderboard discovery is not just a matter of accurately extracting performance numbers and comparing them. In fact, the levels of noise and uncertainty around …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:evX43VCCuoAC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Recently, the supervised learning paradigm's surprisingly remarkable performance has garnered considerable attention from Sanskrit Computational Linguists. As a result, the Sanskrit community has put laudable efforts to build task-specific labeled data for various downstream Natural Language Processing (NLP) tasks. The primary component of these approaches comes from representations of word embeddings. Word embedding helps to transfer knowledge learned from readily available unlabelled data for improving task-specific performance in low-resource setting. Last decade, there has been much excitement in the field of digitization of Sanskrit. To effectively use such readily available resources, it is very much essential to perform a systematic study on word embedding approaches for the Sanskrit language. In this work, we investigate the effectiveness of word embeddings. We classify word embeddings in broad categories to facilitate systematic experimentation and evaluate them on four intrinsic tasks. We investigate the efficacy of embeddings approaches (originally proposed for languages other than Sanskrit) for Sanskrit along with various challenges posed by language.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:nVrZBo8bIpAC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Neural dependency parsing has achieved remarkable performance for many domains and languages. The bottleneck of massive labeled data limits the effectiveness of these approaches for low resource languages. In this work, we focus on dependency parsing for morphological rich languages (MRLs) in a low-resource setting. Although morphological information is essential for the dependency parsing task, the morphological disambiguation and lack of powerful analyzers pose challenges to get this information for MRLs. To address these challenges, we propose simple auxiliary tasks for pretraining. We perform experiments on 10 MRLs in low-resource settings to measure the efficacy of our proposed pretraining method and observe an average absolute gain of 2 points (UAS) and 3.6 points (LAS). Code and data available at: https://github.com/jivnesh/LCM",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:fbc8zXXH2BUC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Automatic Charge Identification (ACI) is the task of identifying the relevant charges given the facts of a situation and the statutory laws that define these charges, and is a crucial aspect of the judicial process. Existing works focus on learning charge-side representations by modeling relationships between the charges, but not much effort has been made in improving fact-side representations. We observe that only a small fraction of sentences in the facts actually indicates the charges. We show that by using a very small subset (< 3%) of fact descriptions annotated with sentence-level charges, we can achieve an improvement across a range of different ACI models, as compared to modeling just the main document-level task on a much larger dataset. Additionally, we propose a novel model that utilizes sentence-level charge labels as an auxiliary task, coupled with the main task of document-level charge identification in a multi-task learning framework. The proposed model comprehensively outperforms a large number of recent baselines for ACI. The improvement in performance is particularly noticeable for the rare charges which are known to be especially challenging to identify.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:LhH-TYMQEocC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"The distinction between sciences is becoming increasingly more artificial – an approach from one area can be easily applied to the other. More exciting research nowadays is happening perhaps at the interfaces of disciplines like Physics, Mathematics and Computer Science. How do these interfaces emerge and interact? For instance, is there a specific pattern in which these fields cite each other? In this article, we investigate a collection of more than 1.2 million papers from three different scientific disciplines – Physics, Mathematics, and Computer Science. We show how over a timescale the citation patterns from the core science fields (Physics, Mathematics) to the applied and fast-growing field of Computer Science have drastically increased. Further, we observe how certain subfields in these disciplines are shrinking while others are becoming tremendously popular. For instance, an intriguing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:tYavs44e6CUC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Summarization of legal case judgement documents is a challenging problem in Legal NLP. However, not much analyses exist on how different families of summarization models (e.g., extractive vs. abstractive) perform when applied to legal case documents. This question is particularly important since many recent transformer-based abstractive summarization models have restrictions on the number of input tokens, and legal documents are known to be very long. Also, it is an open question on how best to evaluate legal case document summarization systems. In this paper, we carry out extensive experiments with several extractive and abstractive summarization methods (both supervised and unsupervised) over three legal summarization datasets that we have developed. Our analyses, that includes evaluation by law practitioners, lead to several interesting insights on legal summarization in specific and long document summarization in general.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:L1USKYWJimsC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"The number of published articles in the field of materials science is growing rapidly every year. This comparatively unstructured data source, which contains a large amount of information, has a restriction on its re-usability, as the information needed to carry out further calculations using the data in it must be extracted manually. It is very important to obtain valid and contextually correct information from the online (offline) data, as it can be useful not only to generate inputs for further calculations, but also to incorporate them into a querying framework. Retaining this context as a priority, we have developed an automated tool, MatScIE (Material Science Information Extractor) that can extract relevant information from material science literature and make a structured database that is much easier to use for material simulations. Specifically, we extract the material details, methods, code, parameters, and structure from the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:ODE9OILHJdcC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Extensive literature demonstrates how the copying of references (links) can lead to the emergence of various structural properties (e.g., power-law degree distribution and bipartite cores) in bibliographic and other similar directed networks. However, it is also well known that the copying process is incapable of mimicking the number of directed triangles in such networks; neither does it have the power to explain the obsolescence of older papers. In this paper, we propose RefOrCite, a new model that allows for copying of both the references from (i.e., out-neighbors of) as well as the citations to (i.e., in-neighbors of) an existing node. In contrast, the standard copying model (CP) only copies references. While retaining its spirit, RefOrCite differs from the Forest Fire (FF) model in ways that makes RefOrCite amenable to mean-field analysis for degree distribution, triangle count, and densification. Empirically, RefOrCite …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:S16KYo8Pm5AC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"The task of learning a sentiment classification model that adapts well to any target domain, different from the source domain, is a challenging problem. Majority of the existing approaches focus on learning a common representation by leveraging both source and target data during training. In this paper, we introduce a two-stage training procedure that leverages weakly supervised datasets for developing simple lift-and-shift-based predictive models without being exposed to the target domain during the training phase. Experimental results show that transfer with weak supervision from a source domain to various target domains provides performance very close to that obtained via supervised training on the target domain itself.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:M7yex6snE4oC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"E-commerce customers express their purchase intents in several ways, some of which may use a different vocabulary than that of the product catalog. For example, the intent for ""women maternity gown"" is often expressed with the query, ""ladies pregnancy dress"". Search engines typically suffer from poor performance on such queries because of low overlap between query terms and specifications of the desired products. Past work has referred to these queries as vocabulary gap queries. In our experiments, we show that our technique significantly outperforms strong baselines and also show its real-world effectiveness with an online A/B experiment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:g3aElNc5_aQC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Recently, neural network architectures have outperformed traditional methods in biomedical named entity recognition. Borrowed from innovations in general text NER, these models fail to address two important problems of polysemy and usage of acronyms across biomedical text. We hypothesize that using a fully-contextualized model that uses contextualized representations along with context dependent transition scores in CRF can alleviate this issue and help further boost the tagger’s performance. Our experiments with this architecture have shown to improve state-of-the-art F1 score on 3 widely used biomedical corpora for NER. We also perform analysis to understand the specific cases where our contextualized model is superior to a strong baseline.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:L7CI7m0gUJcC,http://cse.iitkgp.ac.in/~pawang/
Pawan Goyal,"['Sanskrit Computational Linguistics', 'Natural Language Processing', 'Information Retrieval']",26,"Distinguishing lexical relations has been a long term pursuit in natural language processing (NLP) domain. Recently, in order to detect lexical relations like hypernymy, meronymy, co-hyponymy etc., distributional semantic models are being used extensively in some form or the other. Even though a lot of efforts have been made for detecting hypernymy relation, the problem of co-hyponymy detection has been rarely investigated. In this paper, we are proposing a novel supervised model where various network measures have been utilized to identify co-hyponymy relation with high accuracy performing better or at par with the state-of-the-art models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=F14FHsIAAAAJ&cstart=20&pagesize=80&citation_for_view=F14FHsIAAAAJ:35r97b3x0nAC,http://cse.iitkgp.ac.in/~pawang/
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Deep learning has evolved as a strong and efficient framework that can be applied to a broad spectrum of complex learning problems which were difficult to solve using the traditional machine learning techniques in the past. The advancement of deep learning has been so radical that today it can surpass human‐level performance. As a consequence, deep learning is being extensively used in most of the recent day‐to‐day applications. However, efficient deep learning systems can be jeopardised by using crafted adversarial samples, which may be imperceptible to the human eye, but can lead the model to misclassify the output. In recent times, different types of adversaries based on their threat model leverage these vulnerabilities to compromise a deep learning system where adversaries have high incentives. Hence, it is extremely important to provide robustness to deep learning algorithms against these …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&citation_for_view=2ELnl9IAAAAJ:-TLX1-BxFiYC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Physically Unclonable Functions (PUFs) promise to be a critical hardware primitive to provide unique identities to billions of connected devices in Internet of Things (IoTs). In traditional authentication protocols a user presents a set of credentials with an accompanying proof such as password or digital certificate. However, IoTs need more evolved methods as these classical techniques suffer from the pressing problems of password dependency and inability to bind access requests to the “things” from which they originate. Additionally, the protocols need to be lightweight and heterogeneous. Although PUFs seem promising to develop such mechanism, it puts forward an open problem of how to develop such mechanism without needing to store the secret challenge-response pair (CRP) explicitly at the verifier end. In this paper, we develop an authentication and key exchange protocol by combining the ideas of Identity …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&citation_for_view=2ELnl9IAAAAJ:BKYZGPsuSFYC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"The recently proposed Oblivious Cross-Tags (OXT) protocol (CRYPTO 2013) has broken new ground in designing efficient searchable symmetric encryption (SSE) protocol with support for conjunctive keyword search in a single-writer single-reader framework. While the OXT protocol offers high performance by adopting a number of specialised data-structures, it also trades-off security by leaking 'partial' database information to the server. Recent attacks have exploited similar partial information leakage to breach database confidentiality. Consequently, it is an open problem to design SSE protocols that plug such leakages while retaining similar efficiency. In this paper, we propose a new SSE protocol, called Hidden Cross-Tags (HXT), that removes 'Keyword Pair Result Pattern' (KPRP) leakage for conjunctive keyword search. We avoid this leakage by adopting two additional cryptographic primitives - Hidden Vector …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&citation_for_view=2ELnl9IAAAAJ:n8FNryW2AHIC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Ransomware can produce direct and controllable economic loss, which makes it one of the most prominent threats in cyber security. As per the latest statistics, more than half of malwares reported in Q1 of 2017 are ransomwares and there is a potent threat of a novice cybercriminals accessing ransomware-as-a-service. The concept of public-key based data kidnapping and subsequent extortion was introduced in 1996. Since then, variants of ransomware emerged with different cryptosystems and larger key sizes, the underlying techniques remained same. Though there are works in literature which proposes a generic framework to detect the crypto ransomwares, we present a two step unsupervised detection tool which when suspects a process activity to be malicious, issues an alarm for further analysis to be carried in the second step and detects it with minimal traces. The two step detection framework- RAPPER uses Artificial Neural Network and Fast Fourier Transformation to develop a highly accurate, fast and reliable solution to ransomware detection using minimal trace points. We also introduce a special detection module for successful identification of disk encryption processes from potential ransomware operations, both having similar characteristics but with different objective. We provide a comprehensive solution to tackle almost all scenarios (standard benchmark, disk encryption and regular high computational processes) pertaining to the crypto ransomwares in light of software security.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:H-3wYkpcA84C,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"This study investigates the kinked exponential growth, degree of association, and causation between economic growth, energy consumption, population, trade openness, and carbon dioxide (CO2) emissions in 25 upper middle-income group countries spanning data from 1985 to 2014. The study employed first-generation and second-generation unit root tests; prior to that, the cross-sectional dependence test is also applied and panel cointegration techniques, panel FMOLS and DOLS, and panel causality techniques are employed to test the degree of association and causation among the variables. The study reveals a long-run cointegration among the variables. Results of FMOLS declare that there are negative associations between economic growth and CO2 emissions, trade openness, and carbon dioxide emissions respectively, whereas it was found that there are positive relations between energy …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:E10ZYwHxBI8C,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"In this paper, we demonstrate practical fault attacks over a number of lattice-based schemes, in particular NewHope, Kyber, Frodo, Dilithium which are based on the hardness of the Learning with Errors (LWE) problem. One of the common traits of all the considered LWE schemes is the use of nonces as domain separators to sample the secret components of the LWE instance. We show that simple faults targeting the usage of nonce can result in a nonce-reuse scenario which allows key recovery and message recovery attacks. To the best of our knowledge, we propose the first practical fault attack on lattice-based Key encapsulation schemes secure in the CCA model. We perform experimental validation of our attack using Electromagnetic fault injection on reference implementations of the aforementioned schemes taken from the pqm4 library, a benchmarking and testing framework for post quantum …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:1pC5hbHeJ6IC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Elliptic curve-based cryptography (ECC) has become the automatic choice for public key cryptography due to its lightweightness compared to Rivest-Shamir-Adleman (RSA). The most important operation in ECC is elliptic curve scalar multiplication, and its efficient implementation has gathered significant attention in the research community. Fast implementation of ECC scalar multiplication is often desired for speed-critical applications such as runtime authentication in automated cars, web server certification, and so on. Such fast architectures are achieved by implementing ECC scalar multiplication in fields with pseudo-Mersenne prime or Solinas prime. In this paper, we aim to implement a fast implementation of ECC scalar multiplication for any generic Montgomery curve in Galois Field in p [GF(p)] without having the constraint of using any specialized modulus. We will show that the proposed ECC scalar …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:HevVnK7dagcC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"In the energy sector, IoT manifests in the form of next-generation power grids that provide enhanced electrical stability, efficient power distribution, and utilization. The primary feature of a Smart Grid is the presence of an advanced bi-directional communication network between the Smart meters at the consumer end and the servers at the Utility Operators. Smart meters are broadly vulnerable to attacks on communication and physical systems. We propose a secure and operationally asymmetric mutual authentication and key-exchange protocol for secure communication. Our protocol balances security and efficiency, delegates complex cryptographic operations to the resource-equipped servers, and carefully manages the workload on the resource-constrained Smart meter nodes using unconventional lightweight primitives such as Physically Unclonable Functions. We prove the security of the protocol using well …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:Z7R3Ocg27JUC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Dynamic searchable symmetric encryption (SSE) supports updates and keyword searches in tandem on outsourced symmetrically encrypted data, while aiming to minimize the information revealed to the (untrusted) host server. The literature on dynamic SSE has identified two crucial security properties in this regard-forward and backward privacy. Forward privacy makes it hard for the server to correlate an update operation with previously executed search operations. Backward privacy limits the amount of information learnt by the server about documents that have already been deleted from the database. To date, work on forward and backward private SSE has focused mainly on single keyword search. However, for any SSE scheme to be truly practical, it should at least support conjunctive keyword search. In this setting, most prior SSE constructions with sub-linear search complexity do not support dynamic databases. The only exception is the scheme of Kamara and Moataz (EUROCRYPT'17); however it only achieves forward privacy. Achieving both forward and backward privacy, which is the most desirable security notion for any dynamic SSE scheme, has remained open in the setting of conjunctive keyword search. In this work, we develop the first forward and backward private SSE scheme for conjunctive keyword searches. Our proposed scheme, called Oblivious Dynamic Cross Tags (or ODXT in short) scales to very large arbitrarily-structured databases (including both attribute-value and free-text databases). ODXT provides a realistic trade-off between performance and security by efficiently supporting fast updates and conjunctive keyword …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:eG7oJ4UONFcC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Malicious exploitation of faults for extracting secrets is one of the most practical and potent threats to modern cryptographic primitives. Interestingly, not every possible fault for a cryptosystem is maliciously exploitable, and evaluation of the exploitability of a fault is nontrivial. In order to devise precise defense mechanisms against such rogue faults, a comprehensive knowledge is required about the exploitable part of the fault space of a cryptosystem. Unfortunately, the fault space is diversified and of formidable size even while a single crypto-primitive is considered and traditional manual fault analysis techniques may often fall short to practically cover such a fault space within reasonable time. An automation for analyzing individual fault instances for their exploitability is thus inevitable. Such an automation is supposed to work as the core engine for analyzing the fault spaces of cryptographic primitives. In this paper, we propose an automation for evaluating the exploitability status of fault instances from block ciphers, mainly in the context of Differential Fault Analysis (DFA) attacks. The proposed framework is generic and scalable, which are perhaps the two most important features for covering diversified fault spaces of formidable size originating from different ciphers. As a proof-of-concept, we reconstruct some known attack examples on AES and PRESENT using the framework and finally analyze a recently proposed cipher GIFT [BPP+ 17] for the first time. It is found that the secret key of GIFT can be determined with 2 nibble fault instances injected consecutively at the beginning of the 25th and 23rd round with remaining key space complexity of 2^ 7.06.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:PuYkdpj8xa4C,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Fault attacks (FA) are one of the potent practical threats to modern cryptographic implementations. Over the years the FA techniques have evolved, gradually moving towards the exploitation of device-centric properties of the faults. In this paper, we exploit the fact that activation and propagation of a fault through a given combinational circuit (i.e., observability of a fault) is data-dependent. Next, we show that this property of combinational circuits leads to powerful Fault Template Attacks (FTA), even for implementations having dedicated protections against both power and fault-based vulnerabilities. The attacks found in this work are applicable even if the fault injection is made at the middle rounds of a block cipher, which are out of reach for most of the other existing fault analysis strategies. Quite evidently, they also work for a known-plaintext scenario. Moreover, the middle round attacks are entirely blind in the sense …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:b8m_4JuPjscC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Right from its introduction, fault attacks (FA) have been established to be one of the most practical threats to both public key and symmetric key based cryptosystems. Statistical Ineffective Fault Analysis (SIFA) is a recently proposed class of fault attacks introduced at CHES 2018. The fascinating feature of this attack is that it exploits the correct ciphertexts obtained during a fault injection campaign, instead of the faulty ciphertexts. SIFA has been shown to bypass almost all of the existing fault attack countermeasures even when they are combined with masking schemes for side-channel resistance. The goal of this work is to propose a countermeasure framework for SIFA. It has been observed that a randomized domain transformation of the intermediate computation combined with bit-level error correction can prevent SIFA attacks. The domain transformation (Transform) can be realized by standard masking schemes. In …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:YXPZ0dOdYS4C,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Ransomware can produce direct and controllable economic loss making it one of the most prominent threats in cybersecurity. According to the latest statistics, more than half of the malwares reported in Q1 of 2017 are ransomwares, and there is a potential threat of novice cybercriminals accessing ransomware-as-a-service. The concept of public-key based data kidnapping and subsequent extortion was first introduced in 1996. Since then, variants of ransomware emerged with different cryptosystems and larger key sizes; however, the underlying techniques remained the same. There are several works in the literature which propose a generic framework to detect these ransomwares; though, most of them target ransomwares having specific classes of the encryption algorithm. In addition to it, most of these methods either require Operating System (OS) kernel modification or have high detection latency. In this work …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:m44aUaJR3ikC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"The Internet-of-Things today gives rise to a number of applications that require lightweight cryptographic primitives, such as block ciphers for secure and efficient computation using very little resources. This paper addresses the open problem of design-for-security methodologies for constructing such lightweight block ciphers with combined protection against both side channel and fault attacks. We propose novel design strategies that, unlike existing methodologies, are equipped with target-specific design choices. Our first proposal is the incorporation of lightweight linear layers that combine good diffusion properties with fault attack resistance via fault space transformation. Our second proposal is to make S-Box choices using a new metric called the modified transparency order, so as to facilitate a lightweight masking strategy where the mask is only periodically refreshed. Our third and final proposal is to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:2mikiJ1VBVsC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Modern electronic systems become evermore complex, yet remain modular, with integrated circuits (ICs) acting as versatile hardware components at their heart. Electronic design automation (EDA) for ICs has focused traditionally on power, performance, and area. However, given the rise of hardware-centric security threats, we believe that EDA must also adopt related notions like secure by design and secure composition of hardware. Despite various promising studies, we argue that some aspects still require more efforts, for example: effective means for compilation of assumptions and constraints for security schemes, all the way from the system level down to the ""bare metal""; modeling, evaluation, and consideration of security-relevant metrics; or automated and holistic synthesis of various countermeasures, without inducing negative cross-effects.In this paper, we first introduce hardware security for the EDA …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:ddB7do2jUx8C,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Block ciphers are widely regarded as concrete realizations of pseudorandom permutations with established security features. However, their applicability outside the domain of encryption has not been explored so far. In this paper, we open up, for the first time, an entirely novel application of them to logic hiding. We show that a combinational circuit can always be embedded within a block cipher having a bit-permutation based diffusion layer, preserving the cipher structure and security properties. The functionality of the embedded circuit becomes transparent only on the application of a secret key, whereas a wrong key will cause behaviour that is uncorrelated to that of the circuit. As an immediate application, we propose a combinational logic-locking scheme. The proposed locking scheme is also found to be robust against the state-of-the-art (SAT-assisted and other) attacks on logic locks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:dyiPZ63SVtYC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Deep Learning has become a de-facto paradigm for various prediction problems including many privacy-preserving applications, where the privacy of data is a serious concern. There have been efforts to analyze and exploit information leakages from DNN to compromise data privacy. In this paper, we provide an evaluation strategy for such information leakages through DNN by considering a case study on CNN classifier. The approach utilizes low-level hardware information provided by Hardware Performance Counters and hypothesis testing during the execution of a CNN to produce alarms if there exists any information leakage on actual input.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:wE8AsS3ykUMC,http://cse.iitkgp.ac.in/~debdeep
Debdeep Mukhopadhyay,"['Cryptography', 'Side Channel Analysis', 'VLSI', 'Cellular Automata']",44,"Common Criteria (CC) and FIPS 140-3 are two popular side channel testing methodologies. Test Vector Leakage Assessment Methodology (TVLA), a potential candidate for FIPS, can detect the presence of side-channel information in leakage measurements. However, TVLA results cannot be used to quantify side-channel vulnerability and it is an open problem to derive its relationship with side channel attack success rate (SR), i.e., a common metric for CC. In this paper, we extend the TVLA testing beyond its current scope. Precisely, we derive a concrete relationship between TVLA and signal to noise ratio (SNR). The linking of the two metrics allows direct computation of success rate (SR) from TVLA for given choice of intermediate variable and leakage model and thus unify these popular side channel detection and evaluation metrics. An end-to-end methodology is proposed, which can be easily automated, to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2ELnl9IAAAAJ&cstart=20&pagesize=80&citation_for_view=2ELnl9IAAAAJ:qQc65DSaYXMC,http://cse.iitkgp.ac.in/~debdeep
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Hate speech is considered to be one of the major issues currently plaguing the online social media. With online hate speech culminating in gruesome scenarios like the Rohingya genocide in Myanmar, anti-Muslim mob violence in Sri Lanka, and the Pittsburgh synagogue shooting, there is a dire need to understand the dynamics of user interaction that facilitate the spread of such hateful content. In this paper, we perform the first study that looks into the diffusion dynamics of the posts made by hateful and non-hateful users on Gab (Gab.com). We collect a massive dataset of 341K users with 21M posts and investigate the diffusion of the posts generated by hateful and non-hateful users. We observe that the content generated by the hateful users tend to spread faster, farther and reach a much wider audience as compared to the content generated by normal users. We further analyze the hateful and non-hateful users …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&citation_for_view=lf7-deEAAAAJ:BHd7YmozNHgC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Hate speech is a challenging issue plaguing the online social media. While better models for hate speech detection are continuously being developed, there is little research on the bias and interpretability aspects of hate speech. In this paper, we introduce HateXplain, the first benchmark hate speech dataset covering multiple aspects of the issue. Each post in our dataset is annotated from three different perspectives: the basic, commonly used 3-class classification (ie, hate, offensive or normal), the target community (ie, the community that has been the victim of hate speech/offensive speech in the post), and the rationales, ie, the portions of the post on which their labelling decision (as hate, offensive or normal) is based. We utilize existing state-of-the-art models and observe that even models that perform very well in classification do not score high on explainability metrics like model plausibility and faithfulness. We also observe that models, which utilize the human rationales for training, perform better in reducing unintended bias towards target communities. We have made our code and dataset public for other researchers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&citation_for_view=lf7-deEAAAAJ:WmQWPPBrFVcC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Hate content in social media is ever increasing. While Facebook, Twitter, Google have attempted to take several steps to tackle the hateful content, they have mostly been unsuccessful. Counterspeech is seen as an effective way of tackling the online hate without any harm to the freedom of speech. Thus, an alternative strategy for these platforms could be to promote counterspeech as a defense against hate content. However, in order to have a successful promotion of such counterspeech, one has to have a deep understanding of its dynamics in the online world. Lack of carefully curated data largely inhibits such understanding. In this paper, we create and release the first ever dataset for counterspeech using comments from YouTube. The data contains 13,924 manually annotated comments where the labels indicate whether a comment is a counterspeech or not. This data allows us to perform a rigorous measurement study characterizing the linguistic structure of counterspeech for the first time. This analysis results in various interesting insights such as: the counterspeech comments receive much more likes as compared to the noncounterspeech comments, for certain communities majority of the non-counterspeech comments tend to be hate speech, the different types of counterspeech are not all equally effective and the language choice of users posting counterspeech is largely different from those posting non-counterspeech as revealed by a detailed psycholinguistic analysis. Finally, we build a set of machine learning models that are able to automatically detect counterspeech in YouTube videos with an F1-score of 0.71. We also build …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&citation_for_view=lf7-deEAAAAJ:JVJ6OkSwpHsC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Hate speech detection is a challenging problem with most of the datasets available in only one language: English. In this paper, we conduct a large scale analysis of multilingual hate speech in 9 languages from 16 different sources. We observe that in low resource setting, simple models such as LASER embedding with logistic regression performs the best, while in high resource setting BERT based models perform better. In case of zero-shot classification, languages such as Italian and Portuguese achieve good results. Our proposed framework could be used as an efficient solution for low-resource languages. These models could also act as good baselines for future multilingual hate speech detection tasks. We have made our code and experimental settings public for other researchers at https://github.com/punyajoy/DE-LIMIT.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&citation_for_view=lf7-deEAAAAJ:bxbQgRQgr4sC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"With the ongoing debate on 'freedom of speech' vs. 'hate speech,' there is an urgent need to carefully understand the consequences of the inevitable culmination of the two, i.e., 'freedom of hate speech' over time. An ideal scenario to understand this would be to observe the effects of hate speech in an (almost) unrestricted environment. Hence, we perform the first temporal analysis of hate speech on Gab.com, a social media site with very loose moderation policy. We first generate temporal snapshots of Gab from millions of posts and users. Using these temporal snapshots, we compute an activity vector based on DeGroot model to identify hateful users. The amount of hate speech in Gab is steadily increasing and the new users are becoming hateful at an increased and faster rate. Further, our analysis analysis reveals that the hate users are occupying the prominent positions in the Gab network. Also, the language …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&citation_for_view=lf7-deEAAAAJ:Ns2bVKt8YxIC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"The online hate speech is proliferating with several organization and countries implementing laws to ban such harmful speech. While these restrictions might reduce the amount of such hateful content, it does so by restricting freedom of speech. Thus, an promising alternative supported by several organizations is to counter such hate speech with more speech. In this paper, We analyze hate speech and the corresponding counters (aka counterspeech) on Twitter. We perform several lexical, linguistic and psycholinguistic analysis on these user accounts and obverse that counter speakers employ several strategies depending on the target community. The hateful accounts express more negative sentiments and are more profane. We also find that the hate tweets by verified accounts have much more virality as compared to a tweet by a non-verified account. While the hate users seem to use words more about envy, hate, negative emotion, swearing terms, ugliness, the counter users use more words related to government, law, leader. We also build a supervised model for classifying the hateful and counterspeech accounts on Twitter and obtain an F-score of 0.77. We also make our dataset public to help advance the research on hate speech.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&citation_for_view=lf7-deEAAAAJ:NRnkAyzcrGMC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"In Twitter, there is a rising trend in abusive behavior which often leads to incivility. This trend is affecting users mentally and as a result they tend to leave Twitter and other such social networking sites thus depleting the active user base. In this paper, we study factors associated with incivility. We observe that the act of incivility is highly correlated with the opinion differences between the account holder (i.e., the user writing the incivil tweet) and the target (i.e., the user for whom the incivil tweet is meant for or targeted), toward a named entity. We introduce a character level CNN model and incorporate the entity-specific sentiment information for efficient incivility detection which significantly outperforms multiple baseline methods achieving an impressive accuracy of 93.3% (4.9% improvement over the best baseline). In a post-hoc analysis, we also study the behavioral aspects of the targets and account holders and try to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:VFGfXyYpp08C,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"With the online proliferation of hate speech, there is an urgent need for systems that can detect such harmful content. In this paper, We present the machine learning models developed for the Automatic Misogyny Identification (AMI) shared task at EVALITA 2018. We generate three types of features: Sentence Embeddings, TF-IDF Vectors, and BOW Vectors to represent each tweet. These features are then concatenated and fed into the machine learning models. Our model came First for the English Subtask A and Fifth for the English Subtask B. We release our winning model for public use and it's available at https://github.com/punyajoy/Hateminers-EVALITA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:lDOOmgye57wC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Scientific papers are complex and understanding the usefulness of these papers requires prior knowledge. Peer reviews are comments on a paper provided by designated experts on that field and hold a substantial amount of information, not only for the editors and chairs to make the final decision, but also to judge the potential impact of the paper. In this paper, we propose to use aspect-based sentiment analysis of scientific reviews to be able to extract useful information, which correlates well with the accept/reject decision.
While working on a dataset of close to 8k reviews from ICLR, one of the top conferences in the field of machine learning, we use an active learning framework to build a training dataset for aspect prediction, which is further used to obtain the aspects and sentiments for the entire dataset. We show that the distribution of aspect-based sentiments obtained from a review is significantly different for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:XK2cf6JOk9AC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Social media often acts as breeding grounds for different forms of offensive content. For low resource languages like Tamil, the situation is more complex due to the poor performance of multilingual or language-specific models and lack of proper benchmark datasets. Based on this shared task, Offensive Language Identification in Dravidian Languages at EACL 2021, we present an exhaustive exploration of different transformer models, We also provide a genetic algorithm technique for ensembling different models. Our ensembled models trained separately for each language secured the first position in Tamil, the second position in Kannada, and the first position in Malayalam sub-tasks. The models and codes are provided.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:zJAXUfKFhq0C,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"WhatsApp is the most popular messaging app in the world. Due to its popularity, WhatsApp has become a powerful and cheap tool for political campaigning being widely used during the 2019 Indian general election, where it was used to connect to the voters on a large scale. Along with the campaigning, there have been reports that WhatsApp has also become a breeding ground for harmful speech against various protected groups and religious minorities. Many such messages attempt to instil fear among the population about a specific (minority) community. According to research on inter-group conflict, such ‘fear speech’ messages could have a lasting impact and might lead to real offline violence. In this paper, we perform the first large scale study on fear speech across thousands of public WhatsApp groups discussing politics in India. We curate a new dataset and try to characterize fear speech from this dataset …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:6DzZfY3qH5gC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Quora is one of the most popular community question & answer (Q&A) sites of recent times. However, with increasing question posts over time and the posts covering a wide range of topics (unlike focused Q&A sites like Stack Overflow), not all of them are getting answered. Measuring answerability (i.e., whether a question shall get answered or not) involves collecting expensive human judgment data that can differentiate the characteristics of an answered question from an unanswered (aka open) one. Factors to judge if a question would remain open include its subjectivity, openendedness, vagueness, ambiguity, and so on. It is difficult to collect such judgments for thousands of questions, requiring automatic framework to deal the issue of answerability of questions. In this paper, we quantify: 1) user-level and 2) question-level linguistic activities-that can nicely correspond to many of the judgment factors noted …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:3q5vy9RXY8EC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Reducing hateful and offensive content in online social media pose a dual problem for the moderators. On the one hand, rigid censorship on social media cannot be imposed. On the other, the free flow of such content cannot be allowed. Hence, we require efficient abusive language detection system to detect such harmful content in social media. In this paper, we present our machine learning model, HateMonitor, developed for Hate Speech and Offensive Content Identification in Indo-European Languages (HASOC), a shared task at FIRE 2019. We have used a Gradient Boosting model, along with BERT and LASER embeddings, to make the system language agnostic. Our model came at First position for the German sub-task A. We have also made our model public at https://github.com/punyajoy/HateMonitors-HASOC .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:6jAoOr-ogVAC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Algorithmic recommendations mediate interactions between millions of customers and products (in turn, their producers and sellers) on large e-commerce marketplaces like Amazon. In recent years, the producers and sellers have raised concerns about the fairness of black-box recommendation algorithms deployed on these marketplaces. Many complaints are centered around marketplaces biasing the algorithms to preferentially favor their own 'private label' products over competitors. These concerns are exacerbated as marketplaces increasingly de-emphasize or replace 'organic' recommendations with ad-driven 'sponsored' recommendations, which include their own private labels. While these concerns have been covered in popular press and have spawned regulatory investigations, to our knowledge, there has not been any public audit of these marketplace algorithms. In this study, we bridge this gap by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:5AlGpL-oHpAC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Hate speech is a serious issue that is currently plaguing the society and has been responsible for severe incidents such as the genocide of the Rohingya community in Myanmar. Social media has allowed people to spread such hateful content even faster. This is especially concerning for countries which lack hate speech detection systems. In this paper, using hate speech dataset in 9 languages from 16 different sources, we perform the first extensive evaluation of multilingual hate speech detection. We analyze the performance of different deep learning models in various scenarios. We observe that in low resource scenario LASER embedding with Logistic regression perform the best, whereas in high resource scenario, BERT based models perform much better. We also observe that simple techniques such as translating to English and using BERT, achieves competitive results in several languages. For …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:D_25heFg6JwC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"In this paper we propose a deep learning framework for sarcasm target detection in predefined sarcastic texts. Identification of sarcasm targets can help in many core natural language processing tasks such as aspect based sentiment analysis, opinion mining etc. To begin with, we perform an empirical study of the socio-linguistic features and identify those that are statistically significant in indicating sarcasm targets (p-values in the range (0.05, 0.001)). Finally, we present a deep-learning framework augmented with socio-linguistic features to detect sarcasm targets in sarcastic book-snippets and tweets. We achieve a huge improvement in the performance in terms of exact match and dice scores compared to the current state-of-the-art baseline.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:LwieBGrN4GEC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"With the online proliferation of hate speech, organizations and governments are trying to tackle this issue, without upsetting the ‘freedom of speech’. In this paper, we try to understand the temporal effects of allowing hate speech on a platform (Gab) as a norm (protected as freedom of speech). We observe that the amount of hate speech is steadily increasing, with new users being exposed to hate speech at a faster rate. We also observe that the language used by the Gab users are aligning more with the hateful users with time. We believe that the hate community is evolving a new language culture of their own in this unmoderated environment and the rest of the (benign) population is slowly getting adapted to this new language culture. Our work provides empirical observations to the HCI questions regarding the freedom of hate speech.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:o_fBUN_Or78C,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"In this paper, we develop a content-cum-user based deep learning framework DeepTagRec to recommend appropriate question tags on Stack Overflow. The proposed system learns the content representation from question title and body. Subsequently, the learnt representation from heterogeneous relationship between user and tags is fused with the content representation for the final tag prediction. On a very large-scale dataset comprising half a million question posts, DeepTagRec beats all the baselines; in particular, it significantly outperforms the best performing baseline TagCombine achieving an overall gain of 60.8% and 36.8% in precision@3 and recall@10 respectively. DeepTagRec also achieves 63% and 33.14% maximum improvement in exact-k accuracy and top-k accuracy respectively over TagCombine.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:-A4928QJj7oC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Social media platforms like Twitter, Gab, Facebook are available in the market to billions1 of users. These platforms allow users to share their ideas and opinions instantly almost with no cost. These have already been utilized by bad actors in the society to cause damage. Scenarios like the Rohingya genocide in Myanmar, anti-Muslim mob violence in Sri Lanka, and the Pittsburgh synagogue shooting can be linked to these platforms. Recently, hate speech is considered to be one of the major issues poisoning the online social media environment. To keep these platforms healthy there is a need to understand how these hateful content spread, how hateful users behave and finally, what could be an effective way to mitigate hate speech. In this article, we look at the recent advances and issues surrounding hate speech in online social media. We take three different perspectives - analysis & spread, detection, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:EfTNjLFZ3b0C,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"In this paper we demonstrate how code-switching patterns can be utilised to improve various downstream NLP applications. In particular, we encode different switching features to improve humour, sarcasm and hate speech detection tasks. We believe that this simple linguistic observation can also be potentially helpful in improving other similar NLP applications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:F_tUKv7nyWgC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Anonymity forms an integral and important part of our digital life. It enables us to express our true selves without the fear of judgment. In this paper, we investigate the different aspects of anonymity in the social Q&A site Quora. Quora allows users to explicitly post anonymous questions and such activity in this forum has become normative rather than a taboo. Through an analysis of millions of questions, we observe that at a global scale almost no difference manifests between the linguistic structure of the anonymous and the non-anonymous questions posted on Quora. We find that topical mixing at the global scale to be the primary reason for the absence. However, the differences start to feature once we “deep dive” and (topically) cluster the questions and compare them. In particular, we observe that the choice to post the question as anonymous is dependent on the user’s perception of anonymity and they often …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:xMZGxf1v-3YC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"To improve the experience of consumers, all social media, commerce and entertainment sites deploy Recommendation Systems (RSs) that aim to help users locate interesting content. These RSs are black-boxes - the way a chunk of information is filtered out and served to a user from a large information base is mostly opaque. No one except the parent company generally has access to the entire information required for auditing these systems - neither the details of the algorithm nor the user-item interactions are ever made publicly available for third-party auditors. Hence auditing RSs remains an important challenge, especially with the recent concerns about how RSs are affecting the views of the society at large with new technical jargons like “echo chambers”, “confirmation biases”, “filter bubbles” etc. in place. Many prior works have evaluated different properties of RSs such as diversity, novelty, etc. However, most …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:Nb0HLiwjfsIC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"We present CL Scholar, the ACL Anthology knowledge graph miner to facilitate high-quality search and exploration of current research progress in the computational linguistics community. In contrast to previous works, periodically crawling, indexing and processing of new incoming articles is completely automated in the current system. CL Scholar utilizes both textual and network information for knowledge graph construction. As an additional novel initiative, CL Scholar supports more than 1200 scholarly natural language queries along with standard keyword-based search on constructed knowledge graph. It answers binary, statistical and list based natural language queries. The current system is deployed at http://cnerg.iitkgp.ac.in/aclakg. We also provide REST API support along with bulk download facility. Our code and data are available at https://github.com/CLScholar.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:WTkkuPxyGkUC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Hate speech is regarded as one of the crucial issues plaguing the online social media. The current literature on hate speech detection leverages primarily the textual content to find hateful posts and subsequently identify hateful users. However, this methodology disregards the social connections between users. In this paper, we run a detailed exploration of the problem space and investigate an array of models ranging from purely textual to graph based to finally semi-supervised techniques using Graph Neural Networks (GNN) that utilize both textual and graph-based features. We run exhaustive experiments on two datasets -- Gab, which is loosely moderated and Twitter, which is strictly moderated. Overall the AGNN model achieves 0.791 macro F1-score on the Gab dataset and 0.780 macro F1-score on the Twitter dataset using only 5% of the labeled instances, considerably outperforming all the other models …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:eHo_KFcuhuIC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Wikipedia can easily be justified as a behemoth, considering the sheer volume of content that is added or removed every minute to its several projects. This creates an immense scope, in the field of natural language processing towards developing automated tools for content moderation and review. In this paper we propose Self Attentive Revision Encoder (StRE) which leverages orthographic similarity of lexical units toward predicting the quality of new edits. In contrast to existing propositions which primarily employ features like page reputation, editor activity or rule based heuristics, we utilize the textual content of the edits which, we believe contains superior signatures of their quality. More specifically, we deploy deep encoders to generate representations of the edits from its text content, which we then leverage to infer quality. We further contribute a novel dataset containing 21M revisions across 32K Wikipedia pages and demonstrate that StRE outperforms existing methods by a significant margin at least 17% and at most 103%. Our pretrained model achieves such result after retraining on a set as small as 20% of the edits in a wikipage. This, to the best of our knowledge, is also the first attempt towards employing deep language models to the enormous domain of automated content moderation and review in Wikipedia.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:zBCjByih94YC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Vertices with high betweenness and closeness centrality represent influential entities in a network. An important problem for time varying networks is to know a-priori, using minimal computation, whether the influential vertices of the current time step will retain their high centrality, in the future time steps, as the network evolves. In this paper, based on empirical evidences from several large real world time varying networks, we discover a certain class of networks where the highly central vertices are part of the innermost core of the network and this property is maintained over time. As a key contribution of this work, we propose novel heuristics to identify these networks in an optimal fashion and also develop a two-step algorithm for predicting high centrality vertices. Consequently, we show for the first time that for such networks, expensive shortest path computations in each time step as the network changes …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:ZM__uENUXnMC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Social media platforms usually tackle the proliferation of hate speech by blocking/suspending the message or account. One of the major drawback of such measures is the restriction of free speech. In this paper, we investigate the interaction of hatespeech and the responses that counter it (aka counter-speech). One of the prime contribution of this work is that we developed and released1 a dataset where we annotate pairs of hate and counter users.
We perform several lexical, linguistic and psycholinguistic analysis on these annotated accounts and observe that the couterspeakers of the target communities employ different strategies to tackle the hatespeech. The hate users seem to be more popular as we observe that they are more subjective, express more negative sentiment, tweet more and have more followers. While the hate users seem to use words more about envy, hate, negative emotion, swearing terms …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:kyHTWmgVackC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"The compositionality degree of multiword expressions indicates to what extent the meaning of a phrase can be derived from the meaning of its constituents and their grammatical relations. Prediction of (non)-compositionality is a task that has been frequently addressed with distributional semantic models. We introduce a novel technique to blend hierarchical information with distributional information for predicting compositionality. In particular, we use hypernymy information of the multiword and its constituents encoded in the form of the recently introduced Poincar\'e embeddings in addition to the distributional information to detect compositionality for noun phrases. Using a weighted average of the distributional similarity and a Poincar\'e similarity function, we obtain consistent and substantial, statistically significant improvement across three gold standard datasets over state-of-the-art models based on distributional information only. Unlike traditional approaches that solely use an unsupervised setting, we have also framed the problem as a supervised task, obtaining comparable improvements. Further, we publicly release our Poincar\'e embeddings, which are trained on the output of handcrafted lexical-syntactic patterns on a large corpus.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:EGhj4itiAA0C,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Providing easy and hassle-free product returns have become a norm for e-commerce companies. However, this flexibility on the part of the customer causes the respective e-commerce companies to incur heavy losses because of the delivery logistics involved and the eventual lower resale value of the product returned. In this paper, we consider data from one of the leading Indian e-commerce companies and investigate the problem of product returns across different lifestyle verticals. One of the striking observations from our measurements is that most of the returns take place for apparels/garments and the major reason for the return as cited by the customers is the “size/fit” issue. Here we develop, based on past purchase/return data, a model that given a user, a brand and a size of the product can predict whether the user is going to eventually return the product. The methodological novelty of our model is that it …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:5thYEm8kiqcC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"A leaderboard is a tabular presentation of performance scores of the best competing techniques that address a specific scientific problem. Manually maintained leaderboards take time to emerge, which induces a latency in performance discovery and meaningful comparison. This can delay dissemination of best practices to non-experts and practitioners. Regarding papers as proxies for techniques, we present a new system to automatically discover and maintain leaderboards in the form of partial orders between papers, based on performance reported therein. In principle, a leaderboard depends on the task, data set, other experimental settings, and the choice of performance metrics. Often there are also tradeoffs between different metrics. Thus, leaderboard discovery is not just a matter of accurately extracting performance numbers and comparing them. In fact, the levels of noise and uncertainty around …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:tvutLEwYQz8C,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Relation classification (sometimes called 'extraction') requires trustworthy datasets for fine-tuning large language models, as well as for evaluation. Data collection is challenging for Indian languages, because they are syntactically and morphologically diverse, as well as different from resource-rich languages like English. Despite recent interest in deep generative models for Indian languages, relation classification is still not well served by public data sets. In response, we present IndoRE, a dataset with 21K entity and relation tagged gold sentences in three Indian languages, plus English. We start with a multilingual BERT (mBERT) based system that captures entity span positions and type information and provides competitive monolingual relation classification. Using this system, we explore and compare transfer mechanisms between languages. In particular, we study the accuracy efficiency tradeoff between expensive gold instances vs. translated and aligned 'silver' instances. We release the dataset for future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:Xc8JtHQmRf8C,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"A book’s success/popularity depends on various parameters: extrinsic and intrinsic. In this paper, we study how the book reading characteristics might influence the popularity of a book. Towards this objective, we perform a cross-platform study of Goodreads entities and attempt to establish the connection between various Goodreads entities and the popular books (“Amazon best sellers”). We analyze the collective reading behavior on Goodreads platform and quantify various characteristic features of the Goodreads entities to identify differences between these Amazon best sellers (ABS) and the other non-best-selling books. We then develop a prediction model using the characteristic features to predict if a book shall become a best seller after 1 month (15 days) since its publication. On a balanced set, we are able to achieve a very high average accuracy of 88.72% (85.66%) for the prediction where the other …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:R8TPKZP7usQC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"This paper describes the systems developed for 1st and 2nd tasks of the 3rd Social Media Mining for Health Applications Shared Task at EMNLP 2018. The first task focuses on automatic detection of posts mentioning a drug name or dietary supplement, a binary classification. The second task is about distinguishing the tweets that present personal medication intake, possible medication intake and non-intake. We performed extensive experiments with various classifiers like Logistic Regression, Random Forest, SVMs, Gradient Boosted Decision Trees (GBDT) and deep learning architectures such as Long Short-Term Memory Networks (LSTM), jointed Convolutional Neural Networks (CNN) and LSTM architecture, and attention based LSTM architecture both at word and character level. We have also explored using various pre-trained embeddings like Global Vectors for Word Representation (GloVe), Word2Vec and task-specific embeddings learned using CNN-LSTM and LSTMs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:GO5CT2y9xrEC,http://cse.iitkgp.ac.in/~animeshm/
Animesh Mukherjee,"['Language dynamics', 'Complex systems and networks', 'web social media']",31,"Goodreads has launched the Readers Choice Awards since 2009 where users are able to nominate/vote books of their choice, released in the given year. In this work, we question if the number of votes that a book would receive (aka the popularity of the book) can be predicted based on the characteristics of various entities on Goodreads. We are successful in predicting the popularity of the books with high prediction accuracy (correlation coefficient ~0.61) and low RMSE (~1.25). User engagement and author's prestige are found to be crucial factors for book popularity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=lf7-deEAAAAJ&cstart=20&pagesize=80&citation_for_view=lf7-deEAAAAJ:Xxrp-jDxsD4C,http://cse.iitkgp.ac.in/~animeshm/
palash dey,"['Computational Social Choice', 'TCS']",12,"We give the first optimal bounds for returning the ℓ1-heavy hitters in a data stream of insertions, together with their approximate frequencies, closing a long line of work on this problem. For a stream of m items in { 1, 2, … , n} and parameters 0 < ε < φ ⩽ 1, let fi denote the frequency of item i, i.e., the number of times item i occurs in the stream. With arbitrarily large constant probability, our algorithm returns all items i for which fi ⩾ φ m, returns no items j for which fj ⩽ (φ −ε)m, and returns approximations f˜i with |f˜i − fi| ⩽ ε m for each item i that it returns. Our algorithm uses O(ε−1 log φ −1 + φ −1 log n + log log m) bits of space, processes each stream update in O(1) worst-case time, and can report its output in time linear in the output size. We also prove a lower bound, which implies that our algorithm is optimal up to a constant factor in its space complexity. A modification of our algorithm can be used to estimate the maximum …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:UebtZRa9Y70C,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"The Coalitional Manipulation problem has been studied extensively in the literature for many voting rules. However, most studies have focused on the complete information setting, wherein the manipulators know the votes of the non-manipulators. While this assumption is reasonable for purposes of showing intractability, it is unrealistic for algorithmic considerations. In most real-world scenarios, it is impractical to assume that the manipulators to have accurate knowledge of all the other votes. In this work, we investigate manipulation with incomplete information. In our framework, the manipulators know a partial order for each voter that is consistent with the true preference of that voter. In this setting, we formulate three natural computational notions of manipulation, namely weak, opportunistic, and strong manipulation. We say that an extension of a partial order is viable if there exists a manipulative vote for that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:hqOjcs7Dif8C,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Node similarity measures quantify how similar a pair of nodes are in a network. These similarity measures turn out to be an important fundamental tool for many real world applications such as link prediction in networks, recommender systems etc. An important class of similarity measures are local similarity measures. Two nodes are considered similar under local similarity measures if they have large overlap between their neighboring set of nodes. Manipulating node similarity measures via removing edges is an important problem. This type of manipulation, for example, hinders effectiveness of link prediction in terrorists networks. Fortunately, all the popular computational problems formulated around manipulating similarity measures turn out to be NP-hard. We, in this paper, provide fine grained complexity results of these problems through the lens of parameterized complexity. In particular, we show that some of these problems are fixed parameter tractable (FPT) with respect to various natural parameters whereas other problems remain intractable W[1]-hard and W[2]-hard in particular). Finally we show the effectiveness of our proposed FPT algorithms on real world datasets as well as synthetic networks generated using Barabasi-Albert and Erdos-Renyi models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:mB3voiENLucC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"In many practical scenarios, a population is divided into disjoint groups for better administration, e.g., electorates into political districts, employees into departments, students into school districts, and so on. However, grouping people arbitrarily may lead to biased partitions, raising concerns of gerrymandering in political districting, racial segregation in schools, etc. To counter such issues, in this paper, we conceptualize such problems in a voting scenario, and propose FAIR DISTRICTING problem to divide a given set of people having preference over candidates into k groups such that the maximum margin of victory of any group is minimized. We also propose the FAIR CONNECTED DISTRICTING problem which additionally requires each group to be connected. We show that the FAIR DISTRICTING problem is NP-complete for plurality voting even if we have only 3 candidates but admits polynomial time algorithms if we assume k to be some constant or everyone can be moved to any group. In contrast, we show that the FAIR CONNECTED DISTRICTING problem is NP-complete for plurality voting even if we have only 2 candidates and k = 2. Finally, we propose heuristic algorithms for both the problems and show their effectiveness in UK political districting and in lowering racial segregation in public schools in the US.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:hC7cP41nSMkC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Approval voting provides an opportunity for the agents to make a comment about every candidate, without incurring the overhead of determining a full ranking on the entire set of candidates. This makes approval voting a natural choice for many practical applications. In this work, we focus on the use of approval voting for selecting a committee in scenarios where we can have few outrageous voters whom we call outliers. More specifically, we study the computational complexity of the committee selection problem for commonly used approval-based voting rules in the presence of outliers. Our first result shows that outliers render the committee selection problem intractable for approval, net approval, and minisum approval voting rules. We next study the parameterized complexity of this problem with five natural parameters, namely the target score, the size of the committee (and its dual parameter namely the number of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:4TOpqqG69KYC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"We study the parameterized complexity of the Optimal Defense and Optimal Attack problems in voting. In both the problems, the input is a set of voter groups (every voter group is a district consisting of a set of votes) and two integers k a and k d corresponding to respectively the number of voter groups the attacker can attack and the number of voter groups the defender can defend. A voter group gets removed from the election if it is attacked but not defended. In the Optimal Defense problem, we want to know if it is possible for the defender to commit to a strategy of defending at most k d voter groups such that, no matter which k a voter groups the attacker attacks, the outcome of the election does not change. In the Optimal Attack problem, we want to know if it is possible for the attacker to commit to a strategy of attacking k a voter groups such that, no matter which k d voter groups the defender defends, the outcome of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:7PzlFSSx8tAC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"The Chamberlin-Courant and Monroe rules are fundamental and well-studied rules in the literature of multi-winner elections. The problem of determining if there exists a committee of size k that has a Chamberlin-Courant (respectively, Monroe) score of at most r is known to be NP-complete. We consider the following natural problems in this setting: a) given a committee S of size k as input, is it an optimal k-sized committee, and b) given a candidate c and a committee size k, does there exist an optimal k-sized committee that contains c? In this work, we resolve the complexity of both problems for the Chamberlin-Courant and Monroe voting rules in the settings of rankings as well as approval ballots. We show that verifying if a given committee is optimal is coNP-complete whilst the latter problem is complete for . We also demonstrate efficient algorithms for the second problem when the input consists of single-peaked rankings. Our contribution fills an essential gap in the literature for these important multi-winner rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:e5wmG9Sq2KIC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Studying complexity of various bribery problems has been one of the main research focus in computational social choice. In all the models of bribery studied so far, the briber has to pay every voter some amount of money depending on what the briber wants the voter to report and the briber has some budget at her disposal. Although these models successfully capture many real world applications, in many other scenarios, the voters may be unwilling to deviate too much from their true preferences. In this paper, we study the computational complexity of the problem of finding a preference profile which is as close to the true preference profile as possible and still achieves the briber’s goal subject to budget constraints. We call this problem Local Distance Restricted $ Bribery. We consider three important measures of distances, namely, swap distance, footrule distance, and maximum displacement distance, and resolve the complexity of the local distance restricted bribery problem for many common voting rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:dhFuZR0502QC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"In the Binary Networked Public Goods game, every player needs to decide if she participates in a public project whose utility is shared equally by the community. We study the problem of deciding if there exists a pure strategy Nash equilibrium (PSNE) in such games. The problem is already known to be NP-complete. We provide fine-grained analysis of this problem under the lens of parameterized complexity theory. We consider various natural graph parameters and show either W[1]-hardness or exhibit an FPT algorithm. We finally exhibit some special graph classes, for example path, cycle, bi-clique, complete graph, etc., which always have a PSNE if the utility function of the players are fully homogeneous.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:4JMBOYKVnBMC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Covert networks are social networks that often consist of harmful users. Social Network Analysis (SNA) has played an important role in reducing criminal activities (e.g., counter terrorism) via detecting the influential users in such networks. There are various popular measures to quantify how influential or central any vertex is in a network. As expected, strategic and influential miscreants in covert networks would try to hide herself and her partners (called {\em leaders}) from being detected via these measures by introducing new edges. Waniek et al. show that the corresponding computational problem, called Hiding Leader, is NP-Complete for the degree and closeness centrality measures. We study the popular core centrality measure and show that the problem is NP-Complete even when the core centrality of every leader is only . On the contrary, we prove that the problem becomes polynomial time solvable for the degree centrality measure if the degree of every leader is bounded above by any constant. We then focus on the optimization version of the problem and show that the Hiding Leader problem admits a factor approximation algorithm for the degree centrality measure. We complement it by proving that one cannot hope to have any factor approximation algorithm for any constant unless there is a factor polynomial time algorithm for the Densest -Subgraph problem which would be considered a significant breakthrough.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&citation_for_view=BkDCPiIAAAAJ:QIV2ME_5wuYC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Lu and Boutilier [22] proposed a novel approach based on “minimax regret” to use classical score based voting rules in the setting where preferences can be any partial (instead of complete) orders over the set of alternatives. We show here that such an approach is vulnerable to a new kind of manipulation which was not present in the classical (where preferences are complete orders) world of voting. We call this attack “manipulative elicitation.” More specifically, it may be possible to (partially) elicit the preferences of the agents in a way that makes some distinguished alternative win the election who may not be a winner if we elicit every preference completely. More alarmingly, we show that the related computational task is polynomial time solvable for a large class of voting rules which includes all scoring rules, maximin, Copeland α for every α∈[0, 1], simplified Bucklin voting rules, etc. We then show that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:aqlVkmm33-oC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Public schools in the United States offer tuition-free primary and secondary education to their students, and are divided into school districts funded by the local and state governments. Although the primary source of school district revenue is public money, several studies have pointed to the inequality in funding across different school districts. In this paper, we focus on the spatial geometry/distribution of such inequality, i.e., how the highly funded and lesser funded school districts are located relative to each other. Due to the major reliance on local property taxes for school funding, we find existing school district boundaries promoting financial segregation, with highly-funded school districts surrounded by lesser-funded districts and vice-versa.
To counter such issues, we formally propose the Fair Partitioning  problem to divide a given set of schools into k districts such that the spatial inequality in the district-level …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:J_g5lzvAfSwC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Elections involving a large voter population often lead to outcomes that surprise many. A better prediction of the true outcome helps reduce the adverse effect of surprise on the economy of a sizable population. This paper starts from the basic observation that individuals in the underlying population build estimates of the distribution of preferences of the whole population based on their immediate neighbors in the underlying social network. The outcome of the election leads to a surprise if these local estimates contradict the outcome of the election for some fixed voting rule. To get a quantitative understanding, we propose a novel mathematical model of the setting where the individuals in the population and their connections are described by a random graph with connection probabilities that are biased based on the preferences of the individuals. Each individual also has some estimate of the bias in their connections …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:4DMP91E08xMC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"In liquid democracy, each voter either votes herself or delegates her vote to some other voter. This gives rise to what is called a delegation graph. To decide the voters who eventually votes along with the subset of voters whose votes they give, we need to resolve the cycles in the delegation graph. This gives rise to the Resolve Delegation to MinMaxWeight problem where we need to find an acyclic sub-graph of the delegation graph such that the number of voters whose votes they give is bounded above by some integer . Putting a cap on the number of voters whose votes a voter gives enable the system designer restrict the power of any individual voter. The Resolve Delegation to MinMaxWeight problem is already known to be -hard. In this paper we study the parameterized complexity of this problem. We show that Resolve Delegation to MinMaxWeight is para- with respect to parameters , number …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:RHpTSmoSYBkC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Network robustness is a measure a network's ability to survive adversarial attacks. But not all parts of a network are equal. K-cores, which are dense subgraphs, are known to capture some of the key properties of many real-life networks. Therefore, previous work has attempted to model network robustness via the stability of its k-core. However, these approaches account for a single core value and thus fail to encode a global network resilience measure. In this paper, we address this limitation by proposing a novel notion of network resilience that is defined over all cores. In particular, we evaluate the stability of the network under node removals with respect to each node's initial core. Our goal is to compute robustness via a combinatorial problem: find b most critical nodes to delete such that the number of nodes that fall from their initial cores is maximized. One of our contributions is showing that it is NP-hard to achieve any polynomial factor approximation of the given objective. We also present a fine-grained complexity analysis of this problem under the lens of parameterized complexity theory for several natural parameters. Moreover, we show two applications of our notion of robustness: measuring the evolution of species and characterizing networks arising from different domains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:j3f4tGmQtD8C,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Ensuring fairness in machine learning algorithms is a challenging and important task. We consider the problem of clustering a set of points while ensuring fairness constraints. While there have been several attempts to capture group fairness in the k-clustering problem, fairness at an individual level is not well-studied. We introduce a new notion of individual fairness in k-clustering based on features that are not necessarily used for clustering. We show that this problem is NP-hard and does not admit a constant factor approximation. We then design a randomized algorithm that guarantees approximation both in terms of minimizing the clustering distance objective as well as individual fairness under natural restrictions on the distance metric and fairness constraints. Finally, our experimental results validate that our algorithm produces lower clustering costs compared to existing algorithms while being competitive in individual fairness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:lSLTfruPkqcC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Bribery in an election is one of the well-studied control problems in computational social choice. In this paper, we propose and study the safe bribery problem. Here the goal of the briber is to ask the bribed voters to vote in such a way that the briber never prefers the original winner (of the unbribed election) more than the new winner, even if the bribed voters do not fully follow the briber's advice. Indeed, in many applications of bribery, campaigning for example, the briber often has limited control on whether the bribed voters eventually follow her recommendation and thus it is conceivable that the bribed voters can either partially or fully ignore the briber's recommendation. We provide a comprehensive complexity theoretic landscape of the safe bribery problem for many common voting rules in this paper.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:2P1L_qKh6hAC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Predicting the winner of an election and estimating the margin of victory of that election are favorite problems both for news media pundits and computational social choice theorists. Since it is often infeasible to elicit the preferences of all the voters in a typical prediction scenario, a common algorithm used for predicting the winner and estimating the margin of victory is to run the election on a small sample of randomly chosen votes and predict accordingly. We analyze the performance of this algorithm for many commonly used voting rules. More formally, for predicting the winner of an election, we introduce the (ε, δ)-Winner Determination problem, where given an election E on n voters and m candidates in which the margin of victory is at least εn votes, the goal is to determine the winner with probability at least 1− δ where ε and δ are parameters with 0< ε, δ< 1. The margin of victory of an election is the smallest number …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:isC4tDSrTZIC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"We initiate the study of bribery problem in the context of gerrymandering and reverse gerrymandering. In our most general problem, the input is a set of voters having votes over a set of alternatives, a graph on the voters, a partition of voters into connected districts, cost of every voter for changing her district, a budget for the briber, and a favorite alternative of the briber. The briber needs to compute if the given partition can be modified so that (i) the favorite alternative of the briber wins the resulting election, (ii) the modification is budget feasible, and (iii) every new district is connected. We study four natural variants of the above problem -- the graph on voter being arbitrary vs complete graph (corresponds to removing connectedness requirement for districts) and the cost of bribing every voter being uniform vs non-uniform. We show that all the four problems are NP-complete even under quite restrictive scenarios. Hence our results show that district based elections are quite resistant under this new kind of electoral attack. We complement our hardness results with polynomial time algorithms in some other cases.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:IWHjjKOFINEC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"In kidney exchange programs, multiple patient-donor pairs each of whom are otherwise incompatible, exchange their donors to receive compatible kidneys. The Kidney Exchange problem is typically modelled as a directed graph where every vertex is either an altruistic donor or a pair of patient and donor; directed edges are added from a donor to its compatible patients. The computational task is to find if there exists a collection of disjoint cycles and paths starting from altruistic donor vertices of length at most l_c and l_p respectively that covers at least some specific number t of non-altruistic vertices (patients). We study parameterized algorithms for the kidney exchange problem in this paper. Specifically, we design FPT algorithms parameterized by each of the following parameters: (1) the number of patients who receive kidney, (2) treewidth of the input graph + max{l_p, l_c}, and (3) the number of vertex types in the input graph when l_p <= l_c. We also present interesting algorithmic and hardness results on the kernelization complexity of the problem. Finally, we present an approximation algorithm for an important special case of Kidney Exchange.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:35N4QoGY0k4C,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"With increasing environmental concerns, many big countries have started expanding rail infrastructure to increase the double-stacking of containers, which doubles the utilization of trains. However, double-stacking containers on wagons give rise to additional operational and safety constraints. These constraints need to be considered during load planning of trains at each terminal, when containers are selected from inventory and assigned to loading positions on wagons. The primary objective of double-stacking is to maximize the train’s utilization. When the planning horizon is restricted to only one train, the containers selected for the current train might negatively affect the utilization of future trains. Hence, it is important to plan multiple trains simultaneously. In this paper, we formulate a model for the load planning of trains, present its complexity proof and propose solution approaches to solve the model. Computational experiments conducted on real-life train instances show that the proposed approach effectively accounts for the utilization of the future train under different scenarios and produces near-optimal plans.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:70eg2SAEIzsC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"A preferential domain is a collection of sets of preferences which are linear orders over a set of alternatives. These domains have been studied extensively in social choice theory due to both its practical importance and theoretical elegance. Examples of some extensively studied preferential domains include single peaked, single crossing, Euclidean, etc. In this paper, we study the sample complexity of testing whether a given preference profile is close to some specific domain. We consider two notions of closeness: (a) closeness via preferences, and (b) closeness via alternatives. We further explore the effect of assuming that the {\em outlier} preferences/alternatives to be random (instead of arbitrary) on the sample complexity of the testing problem. In most cases, we show that the above testing problem can be solved with high probability for all commonly used domains by observing only a small number of samples (independent of the number of preferences, , and often the number of alternatives, ). In the remaining few cases, we prove either impossibility results or lower bound on the sample complexity. We complement our theoretical findings with extensive simulations to figure out the actual constant factors of our asymptotic sample complexity bounds.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:9ZlFYXVOiuMC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:Wp0gIr-vW9MC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Elections involving a very large voter population often lead to outcomes that surprise many. This is particularly important for the elections in which results affect the economy of a sizable population. A better prediction of the true outcome helps reduce the surprise and keeps the voters prepared. This paper starts from the basic observation that individuals in the underlying population build estimates of the distribution of preferences of the whole population based on their local neighborhoods. The outcome of the election leads to a surprise if these local estimates contradict the outcome of the election for some fixed voting rule. To get a quantitative understanding, we propose a simple mathematical model of the setting where the individuals in the population and their connections (through geographical proximity, social networks etc.) are described by a random graph with connection probabilities that are biased based on the preferences of the individuals. Each individual also has some estimate of the bias in their connections. We show that the election outcome leads to a surprise if the discrepancy between the estimated bias and the true bias in the local connections exceeds a certain threshold, and confirm the phenomenon that surprising outcomes are associated only with {\em closely contested elections}. We compare standard voting rules based on their performance on surprise and show that they have different behavior for different parts of the population. It also hints at an impossibility that a single voting rule will be less surprising for {\em all} parts of a population. Finally, we experiment with the UK-EU referendum (a.k.a.\ Brexit) dataset that attest …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:qxL8FJ1GzNcC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"The auction of a single indivisible item is one of the most celebrated problems in mechanism design with transfers. Despite its simplicity, it provides arguably the cleanest and most insightful results in the literature. When the information of the auction is available to every participant, Myerson [17] provided a seminal result to characterize the incentive-compatible auctions along with revenue optimality. However, such a result does not hold in an auction on a network, where the information of the auction is spread via the agents, and they need incentives to forward the information. In recent times, a few auctions (e.g., [10, 15]) were designed that appropriately incentivize the intermediate nodes on the network to promulgate the information to potentially more valuable bidders. In this paper, we provide a Myerson-like characterization of incentive-compatible auctions on a network and show that the currently known auctions fall within this larger class of randomized auctions. We obtain the structure of the revenue optimal auction for i.i.d. bidders on arbitrary trees. We discuss the possibilities of addressing more general settings. Through experiments, we show that auctions following this characterization can provide a higher revenue than the currently known auctions on networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:pqnbT2bcN3wC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"In the classical Binary Networked Public Goods (BNPG) game, a player can either invest in a public project or decide not to invest. Based on the decisions of all the players, each player receives a reward as per his/her utility function. However, classical models of BNPG game do not consider altruism, which players often exhibit and can significantly affect equilibrium behavior. Yu et al. [24] extended the classical BNPG game to capture the altruistic aspect of the players. We, in this paper, first study the problem of deciding the existence of a Pure Strategy Nash Equilibrium (PSNE) in a BNPG game with altruism. This problem is already known to be NP-complete. We complement this hardness result by showing that the problem admits efficient algorithms when the input network is either a tree or a complete graph. We further study the Altruistic Network Modification problem, where the task is to compute if a target strategy profile can be made a PSNE by adding or deleting a few edges. This problem is also known to be NP-complete. We strengthen this hardness result by exhibiting intractability results even for trees. A perhaps surprising finding of our work is that the above problem remains NP-hard even for bounded degree graphs when the altruism network is undirected, but becomes polynomial-time solvable when the altruism network is directed. We also show some results on computing an MSNE and some parameterized complexity results. In summary, our results show that it is much easier to predict how the players in a BNPG game will behave compared to how the players in a BNPG game can be made to behave in a desirable way.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:M05iB0D1s5AC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"In a district-based election, we apply a voting rule to decide the winners in each district, and a candidate who wins in a maximum number of districts is the winner of the election. We present efficient sampling-based algorithms to predict the winner of such district-based election systems in this paper. When is plurality and the margin of victory is known to be at least fraction of the total population, we present an algorithm to predict the winner. The sample complexity of our algorithm is . We complement this result by proving that any algorithm, from a natural class of algorithms, for predicting the winner in a district-based election when is plurality, must sample at least votes. We then extend this result to any voting rule . Loosely speaking, we show that we can predict the winner of a district-based election with an extra overhead of over the sample complexity of predicting the single-district winner under . We further extend our algorithm for the case when the margin of victory is unknown, but we have only two candidates. We then consider the median voting rule when the set of preferences in each district is single-peaked. We show that the winner of a district-based election can be predicted with samples even when the harmonious order in different districts can be different and even unknown. Finally, we also show some results for estimating the margin of victory of a district-based election within both additive and multiplicative error bounds.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:ldfaerwXgEUC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"We initiate the study of the gerrymandering problem when changing the district of a voter incurs a certain cost. In this problem, the input is a set of voters having votes over a set of alternatives, a graph on the voters, a partition of voters into connected districts, a cost of every voter for changing her district, a budget, and a target winner. We need to compute if the given partition can be modified so that (i) the target alternative wins the resulting election,(ii) the modification is budget feasible, and (iii) every new district is connected. We study four natural variants of the above problem–the graph on the voters being arbitrary vs complete graph (corresponds to removing the connectivity requirement fo1r districts) and the cost of moving every voter being uniform vs non-uniform. We show that all the four problems are NP-complete even under quite restrictive scenarios. Hence, our results show that district based elections are quite resistant under this new kind of electoral attack. We complement our intractability results by showing that two of our problems admit polynomial-time algorithms if the budget or the number of districts is a constant. We believe that our findings would help authorities to impose certain constraints, connectedness of districts for example, to make gerrymandering computationally harder.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:g5m5HwL7SMYC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"We introduce the notion of Distance Restricted Manipulation, where colluding manipulator (s) need to compute if there exist votes which make their preferred alternative win the election when their knowledge about the others' votes is a little inaccurate. We use the Kendall-Tau distance to model the manipulators' confidence in the non-manipulators' votes. To this end, we study this problem in two settings-one where the manipulators need to compute a manipulating vote that succeeds irrespective of perturbations in others' votes (Distance Restricted Pessimistic Manipulation), and the second where the manipulators need to compute a manipulating vote that succeeds for at least one possible vote profile of the others (Distance Restricted Optimistic Manipulation). We show that Distance Restricted Pessimistic Manipulation admits polynomial-time algorithms for every scoring rule, maximin, Bucklin, and simplified Bucklin …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:r0BpntZqJG4C,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"1. In a normal form game Γ=⟨ N,(Si) i∈ N,(ui) i∈ N⟩ if a pure strategy si∈ Si for some player i is strongly dominated by some mixed strategy σi∈∆(Si), then in every MSNE of the game, player i chooses the strategy si with probability 0.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:RYcK_YlVTxYC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"We consider the bit-probe complexity of the set membership problem: represent an n-element subset S of an m-element universe as a succinct bit vector so that membership queries of the form"" Is x∈ S"" can be answered using at most t probes into the bit vector. Let s (m, n, t)(resp. s_N (m, n, t)) denote the minimum number of bits of storage needed when the probes are adaptive (resp. non-adaptive). Lewenstein, Munro, Nicholson, and Raman (ESA 2014) obtain fully-explicit schemes that show that",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:_Qo2XoVZTnwC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"In any probability experiment, the set of all possible outcomes is often called sample space and denoted by Ω. We typically wish to study the probability of certain subsets of the sample space; these subsets are called event. It is important to note that it may not be possible to “talk about” probability of every subset of the sample space!
1.1 σ-Algebra and Probability Space:",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:-f6ydRqryjwC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"1. In a normal form game Γ=〈 N,(Si) i∈ N,(ui) i∈ N〉 if a pure strategy si∈ Si for some player i is strongly dominated by some mixed strategy σi∈∆(Si), then in every MSNE of the game, player i chooses the strategy si with probability 0.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:ZeXyd9-uunAC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Single Crossing Domain on Median Graphs:
▶ median graph: for any three vertices u, v, w and for any 3 shortest paths between pairs of them pu, v between u and v, pv, w between v and w, and pw, u between w and u, there is exactly one vertex common to 3 paths. Ex: tree, hypercube.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:mVmsd5A6BfQC,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:qUcmZB5y_30C,http://cse.iitkgp.ac.in/~palash/
palash dey,"['Computational Social Choice', 'TCS']",12,"Game theory is the field in mathematics which studies “games.” Intuitively speaking, a game is any “system” where there are multiple parties (called players of the game), the “outcome” depends on the actions that individual parties take, and different players derive different utilities from the outcome. Let us see some examples of game to have a better feel of the subject. Our first example is arguably the most important one for the students.
Example 1.0. 1 (Grading Game). Consider the “Algorithmic Game Theory” class in IIT Kharagpur. Suppose the instructor announces that the grading policy will be as follows—the top 10% of students get EX grade, next 20% get A, etc. Could you see the game that this grading policy induces? The players are the students in the class. The outcome of the system is the function which maps students to the grades that they get. Observe that the outcome of the system depends on the actions of all the players (also called action profile or strategy profile).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BkDCPiIAAAAJ&cstart=20&pagesize=80&citation_for_view=BkDCPiIAAAAJ:L8Ckcad2t8MC,http://cse.iitkgp.ac.in/~palash/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Deep neural networks are being used increasingly to automate data analysis and decision making, yet their decision-making process is largely unclear and is difficult to explain to the end users. In this paper, we address the problem of Explainable AI for deep neural networks that take images as input and output a class probability. We propose an approach called RISE that generates an importance map indicating how salient each pixel is for the model's prediction. In contrast to white-box approaches that estimate pixel importance using gradients or other internal network state, RISE works on black-box models. It estimates importance empirically by probing the model with randomly masked versions of the input image and obtaining the corresponding outputs. We compare our approach to state-of-the-art importance extraction methods using both an automatic deletion/insertion metric and a pointing metric based on human-annotated object segments. Extensive experiments on several benchmark datasets show that our approach matches or exceeds the performance of other methods, including white-box approaches. Project page: http://cs-people.bu.edu/vpetsiuk/rise/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&citation_for_view=L4yEk2UAAAAJ:MXK_kJrjxJIC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Learning to recognize actions from only a handful of labeled videos is a challenging problem due to the scarcity of tediously collected activity labels. We approach this problem by learning a two-pathway temporal contrastive model using unlabeled videos at two different speeds leveraging the fact that changing video speed does not change an action. Specifically, we propose to maximize the similarity between encoded representations of the same video at two different speeds as well as minimize the similarity between different videos played at different speeds. This way we use the rich supervisory information in terms oftime'that is present in otherwise unsupervised pool of videos. With this simple yet effective strategy of manipulating video playback rates, we considerably outperform video extensions of sophisticated state-of-the-art semi-supervised image recognition methods across multiple diverse benchmark datasets and network architectures. Interestingly, our proposed approach benefits from out-of-domain unlabeled videos showing generalization and robustness. We also perform rigorous ablations and analysis to validate our approach. Project page: https://cvir. github. io/TCL/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&citation_for_view=L4yEk2UAAAAJ:M3ejUd6NZC8C,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Light fidelity (LiFi) is an emerging communication technology, which utilizes the light-emitting diodes (LEDs) for high-speed wireless communications. Due to its huge unlicensed bandwidth, LiFi is capable of supporting high data rates. The quality of the LiFi channel fluctuates across the room due to interference, reflection from walls or blockage. On the other hand, WiFi is another wireless communication technology that is capable of providing moderate data rates with ubiquitous coverage. As the electromagnetic spectrum of LiFi does not overlap with WiFi, both of them can coexist to form a hybrid LiFi and WiFi network for seamless and high-throughput connectivity. The performance of a hybrid system significantly depends upon the access point (AP) assignment and resource allocation strategies. In this paper, a downlink hybrid system with one WiFi AP and four LiFi APs is considered, and a reinforcement learning …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&citation_for_view=L4yEk2UAAAAJ:Zph67rFs4hoC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"We address the problem of temporal activity detection in continuous, untrimmed video streams. This is a difficult task that requires extracting meaningful spatio-temporal features to capture activities, accurately localizing the start and end times of each activity. We introduce a new model, Region Convolutional 3D Network (R-C3D), which encodes the video streams using a three-dimensional fully convolutional network, then generates candidate temporal regions containing activities and finally classifies selected regions into specific activities. Computation is saved due to the sharing of convolutional features between the proposal and the classification pipelines. We further improve the detection performance by efficiently integrating an optical flow based motion stream with the original RGB stream. The two-stream network is jointly optimized by fusing the flow and RGB feature maps at different levels. Additionally, the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&citation_for_view=L4yEk2UAAAAJ:kNdYIx-mwKoC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Unsupervised domain adaptation which aims to adapt models trained on a labeled source domain to a completely unlabeled target domain has attracted much attention in recent years. While many domain adaptation techniques have been proposed for images, the problem of unsupervised domain adaptation in videos remains largely underexplored. In this paper, we introduce Contrast and Mix (CoMix), a new contrastive learning framework that aims to learn discriminative invariant feature representations for unsupervised video domain adaptation. First, unlike existing methods that rely on adversarial learning for feature alignment, we utilize temporal contrastive learning to bridge the domain gap by maximizing the similarity between encoded representations of an unlabeled video at two different speeds as well as minimizing the similarity between different videos played at different speeds. Second, we propose a novel extension to the temporal contrastive loss by using background mixing that allows additional positives per anchor, thus adapting contrastive learning to leverage action semantics shared across both domains. Moreover, we also integrate a supervised contrastive learning objective using target pseudo-labels to enhance discriminability of the latent space for video domain adaptation. Extensive experiments on several benchmark datasets demonstrate the superiority of our proposed approach over state-of-the-art methods. Project page: https://cvir. github. io/projects/comix.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&citation_for_view=L4yEk2UAAAAJ:Wp0gIr-vW9MC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Many interesting events in the real world are rare making preannotated machine learning ready videos a rarity in consequence. Thus, temporal activity detection models that are able to learn from a few examples are desirable. In this paper, we present a conceptually simple and general yet novel framework for few-shot temporal activity detection based on proposal regression which detects the start and end time of the activities in untrimmed videos. Our model is end-to-end trainable, takes into account the frame rate differences between few-shot activities and untrimmed test videos, and can benefit from additional few-shot examples. We experiment on three large scale benchmarks for temporal activity detection (ActivityNet1.2, ActivityNet1.3 and THUMOS14 datasets) in a few-shot setting. We also study the effect on performance of different amount of overlap with activities used to pretrain the video classification backbone and propose corrective measures for future works in this domain. Our code will be made available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&citation_for_view=L4yEk2UAAAAJ:KlAtU1dfN6UC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Supervised deep learning methods are enjoying enormous success in many practical applications of computer vision and have the potential to revolutionize robotics. However, the marked performance degradation to biases and imbalanced data questions the reliability of these methods. In this work we address these questions from the perspective of dataset imbalance resulting out of severe under-representation of annotated training data for certain classes and its effect on both deep classification and generation methods. We introduce a joint dataset repairment strategy by combining a neural network classifier with Generative Adversarial Networks (GAN) that makes up for the deficit of training examples from the under-representated class by producing additional training examples. We show that the combined training helps to improve the robustness of both the classifier and the GAN against severe class …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&citation_for_view=L4yEk2UAAAAJ:ULOm3_A8WrAC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Partial domain adaptation which assumes that the unknown target label space is a subset of the source label space has attracted much attention in computer vision. Despite recent progress, existing methods often suffer from three key problems: negative transfer, lack of discriminability, and domain invariance in the latent space. To alleviate the above issues, we develop a novel'Select, Label, and Mix'(SLM) framework that aims to learn discriminative invariant feature representations for partial domain adaptation. First, we present an efficient"" select"" module that automatically filters out the outlier source samples to avoid negative transfer while aligning distributions across both domains. Second, the"" label"" module iteratively trains the classifier using both the labeled source domain data and the generated pseudo-labels for the target domain to enhance the discriminability of the latent space. Finally, the"" mix"" module utilizes domain mixup regularization jointly with the other two modules to explore more intrinsic structures across domains leading to a domain-invariant latent space for partial domain adaptation. Extensive experiments on several benchmark datasets demonstrate the superiority of our proposed framework over state-of-the-art methods. Project page: https://cvir. github. io/projects/slm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&citation_for_view=L4yEk2UAAAAJ:YOwf2qJgpHMC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Deep Learning has become overly complicated and has enjoyed stellar success in solving several classical problems like image classification, object detection, etc. Several methods for explaining these decisions have been proposed. Black-box methods to generate saliency maps are particularly interesting due to the fact that they do not utilize the internals of the model to explain the decision. Most black-box methods perturb the input and observe the changes in the output. We formulate saliency map generation as a sequential search problem and leverage upon Reinforcement Learning (RL) to accumulate evidence from input images that most strongly support decisions made by a classifier. Such a strategy encourages to search intelligently for the perturbations that will lead to high-quality explanations. While successful black box explanation approaches need to rely on heavy computations and suffer from small sample approximation, the deterministic policy learned by our method makes it a lot more efficient during the inference. Experiments on three benchmark datasets demonstrate the superiority of the proposed approach in inference time over state-of-the-arts without hurting the performance. Project Page: https://cvir.github.io/projects/rexl.html",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&cstart=20&pagesize=80&citation_for_view=L4yEk2UAAAAJ:mVmsd5A6BfQC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Background
Brain herniation is one of the fatal outcomes of increased intracranial pressure (ICP). It is caused due to the presence of hematoma or tumor mass in the brain. Ideal midline (iML) divides the healthy brain into two (right and left) nearly equal hemispheres. In the presence of hematoma, the midline tends to shift from its original position to the contralateral side of the mass and thus develops a deformed midline (dML).
New method
In this study, a convolutional neural network (CNN) was used to predict the deformed left and right hemispheres. The proposed algorithm was validated with non-contrast computed tomography (NCCT) of (n = 45) subjects with two types of brain hemorrhages - epidural hemorrhage (EDH): (n = 5) and intra-parenchymal hemorrhage (IPH): (n = 40)).
Results
The method demonstrated excellent potential in automatically predicting MLS with the average errors of 1.29 mm by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&cstart=20&pagesize=80&citation_for_view=L4yEk2UAAAAJ:_kc_bZDykSQC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"The dynamic and evolutionary nature of service requirements in wireless networks has motivated the telecom industry to consider intelligent self-adapting Reinforcement Learning (RL) agents for controlling the growing portfolio of network services. Infusion of many new types of services is anticipated with future adoption of 6G networks, and sometimes these services will be defined by applications that are external to the network. An RL agent trained for managing the needs of a specific service type may not be ideal for managing a different service type without domain adaptation. We provide a simple heuristic for evaluating a measure of proximity between a new service and existing services, and show that the RL agent of the most proximal service rapidly adapts to the new service type through a well defined process of domain adaptation. Our approach enables a trained source policy to adapt to new situations with changed dynamics without retraining a new policy, thereby achieving significant computing and cost-effectiveness. Such domain adaptation techniques may soon provide a foundation for more generalized RL-based service management under the face of rapidly evolving service types.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&cstart=20&pagesize=80&citation_for_view=L4yEk2UAAAAJ:HDshCWvjkbEC,http://cse.iitkgp.ac.in/~adas/
Abir Das,"['Computer Vision', 'Machine Learning', 'Person Re-identification', 'Activity Detection']",16,"Generating natural language questions from visual scenes, known as Visual Question Generation (VQG), has been explored in the recent past where large amounts of meticulously labeled data provide the training corpus. However, in practice, it is not uncommon to have only a few images with question annotations corresponding to a few types of answers. In this paper, we propose a new and challenging Few-Shot Visual Question Generation (FS-VQG) task and provide a comprehensive benchmark to it. Specifically, we evaluate various existing VQG approaches as well as popular few-shot solutions based on meta-learning and self-supervised strategies for the FS-VQG task. We conduct experiments on two popular existing datasets VQG and Visual7w. In addition, we have also cleaned and extended the VQG dataset for use in a few-shot scenario, with additional image-question pairs as well as additional answer categories. We call this new dataset VQG-23. Several important findings emerge from our experiments, that shed light on the limits of current models in few-shot vision and language generation tasks. We find that trivially extending existing VQG approaches with transfer learning or meta-learning may not be enough to tackle the inherent challenges in few-shot VQG. We believe that this work will contribute to accelerating the progress in few-shot learning research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=L4yEk2UAAAAJ&cstart=20&pagesize=80&citation_for_view=L4yEk2UAAAAJ:7PzlFSSx8tAC,http://cse.iitkgp.ac.in/~adas/
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"The networked opinion diffusion in online social networks (OSN) is governed by the two genres of opinions-endogenous opinions that are driven by the influence of social contacts between users, and exogenous opinions which are formed by external effects like news, feeds etc. Such duplex opinion dynamics is led by users belonging to two categories- organic users who generally post endogenous opinions and extrinsic users who are susceptible to externalities, and mostly post the exogenous messages. Precise demarcation of endogenous and exogenous messages offers an important cue to opinion modeling, thereby enhancing its predictive performance. On the other hand, accurate user selection aids to detect extrinsic users, which in turn helps in opinion shaping. In this paper, we design CherryPick, a novel learning machinery that classifies the opinions and users by solving a joint inference task in message …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&citation_for_view=IixRsP0AAAAJ:Bg7qf7VwUHIC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Aspect Sentiment Triplet Extraction (ASTE) deals with extracting opinion triplets, consisting of an opinion target or aspect, its associated sentiment, and the corresponding opinion term/span explaining the rationale behind the sentiment. Existing research efforts are majorly tagging-based. Among the methods taking a sequence tagging approach, some fail to capture the strong interdependence between the three opinion factors, whereas others fall short of identifying triplets with overlapping aspect/opinion spans. A recent grid tagging approach on the other hand fails to capture the span-level semantics while predicting the sentiment between an aspect-opinion pair. Different from these, we present a tagging-free solution for the task, while addressing the limitations of the existing works. We adapt an encoder-decoder architecture with a Pointer Network-based decoding framework that generates an entire opinion triplet at each time step thereby making our solution end-to-end. Interactions between the aspects and opinions are effectively captured by the decoder by considering their entire detected spans while predicting their connecting sentiment. Extensive experiments on several benchmark datasets establish the better efficacy of our proposed approach, especially in the recall, and in predicting multiple and aspect/opinion-overlapped triplets from the same review sentence. We report our results both with and without BERT and also demonstrate the utility of domain-specific BERT post-training for the task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&citation_for_view=IixRsP0AAAAJ:DXE8ND7PrJAC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Manually extracting relevant aspects and opinions from large volumes of user-generated text is a time-consuming process. Summaries, on the other hand, help readers with limited time budgets to quickly consume the key ideas from the data. State-of-the-art approaches for multi-document summarization, however, do not consider user preferences while generating summaries. In this work, we argue the need and propose a solution for generating personalized aspect-based opinion summaries from large collections of online tourist reviews. We let our readers decide and control several attributes of the summary such as the length and specific aspects of interest among others. Specifically, we take an unsupervised approach to extract coherent aspects from tourist reviews posted onTripAdvisor. We then propose an Integer Linear Programming (ILP) based extractive technique to select an informative subset of opinions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&citation_for_view=IixRsP0AAAAJ:c59VksA5Vz4C,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Marked temporal point processes (MTPP) have emerged as a powerful framework to model the underlying generative mechanism of asynchronous events localized in continuous time. Most existing models and inference methods in MTPP framework consider only the complete observation scenario ie the event sequence being modeled is completely observed with no missing events–an ideal setting barely encountered in practice. A recent line of work which considers missing events uses supervised learning techniques which require a missing or observed label for each event. In this work, we provide a novel unsupervised model and inference method for MTPPs in presence of missing events. We first model the generative processes of observed events and missing events using two MTPPs, where the missing events are represented as latent random variables. Then we devise an unsupervised training method that jointly learns both the MTPPs by means of variational inference. Experiments with real datasets show that our modeling and inference frameworks can effectively impute the missing data among the observed events, which in turn enhances its predictive prowess.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&citation_for_view=IixRsP0AAAAJ:wUn16MOA3RoC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Data Subset selection for training learning models for a variety of tasks, has been widely studied in the literature of batch mode active learning. Recent works attempt to utilize the model specific signals in the deep learning context for computer vision tasks. Companies, in their bid to create safe autonomous driving models, train and test their models on billions of miles of driving data; not all of which may be valuable for a training task. In this paper, we study the problem of frame-subset selection from autonomous vehicle driving data, for the problem of semantic segmentation - which is a crucial component of the perception module in an autonomous driving system. We find that state of the art methods for deep active learning do not utilize pairwise similarity between incoming and existing frames. We explore both active learning settings, where labels for incoming points are not available, as well as frame selection …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&citation_for_view=IixRsP0AAAAJ:X0DADzN9RKwC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"The growth of big data in domains such as Earth Sciences, Social Networks, Physical Sciences, etc. has lead to an immense need for efficient and scalable linear algebra operations, e.g. Matrix inversion. Existing methods for efficient and distributed matrix inversion using big data platforms rely on LU decomposition based block-recursive algorithms. However, these algorithms are complex and require a lot of side calculations, e.g. matrix multiplication, at various levels of recursion. In this paper, we propose a different scheme based on Strassen's matrix inversion algorithm (mentioned in Strassen's original paper in 1969), which uses far fewer operations at each level of recursion. We implement the proposed algorithm, and through extensive experimentation, show that it is more efficient than the state of the art methods. Furthermore, we provide a detailed theoretical analysis of the proposed algorithm, and derive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&citation_for_view=IixRsP0AAAAJ:gVv57TyPmFsC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"This article presents a new fast, highly scalable distributed matrix multiplication algorithm on Apache Spark, called Stark , based on Strassen’s matrix multiplication algorithm. Stark preserves Strassen’s seven multiplications scheme in a distributed environment and thus achieves asymptotically faster execution time. It creates a distributed recursion tree of computation where each level of the tree corresponds to division and combination of distributed matrix blocks stored in the form of Resilient Distributed Datasets (RDDs). It processes each divide and combine step in parallel and memorises the sub-matrices by intelligently tagging matrix blocks in it. To the best of our knowledge, Stark is the first implementation of a distribute Strassen’s algorithm on Spark platform. We also report a detailed complexity analysis for the proposed algorithm, taking into account computation and communication costs. Experimental results …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&citation_for_view=IixRsP0AAAAJ:YTuZlYwrTOUC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Social networks, forums, and social media have emerged as global platforms for forming and shaping opinions on a broad spectrum of topics like politics, sports, and entertainment. Users (also called actors) often update their evolving opinions, influenced through discussions with other users. Theoretical models and their analysis on understanding opinion dynamics in social networks abound in the literature. However, these models are often based on concepts from statistical physics. Their goal is to establish specific phenomena like steady state consensus or bifurcation. Analysis of transient effects is largely avoided. Moreover, many of these studies assume that actors’ opinions are observed globally and synchronously, which is rarely realistic. In this article, we initiate an investigation into a family of novel data-driven influence models that accurately learn and fit realistic observations. We estimate and do not …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&citation_for_view=IixRsP0AAAAJ:g5Ck-dwhA_QC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Travel time estimation is a fundamental problem in transportation science with extensive literature. The study of these techniques has intensified due to availability of many publicly available large trip datasets. Recently developed deep learning based models have improved the generality and performance and have focused on estimating times for individual sub-trajectories and aggregating them to predict the travel time of the entire trajectory. However, these techniques ignore the road network information. In this work, we propose and study techniques for incorporating road networks along with historical trips' data into travel time prediction. We incorporate both node embeddings as well as road distance into the existing model. Experiments on large real-world benchmark datasets suggest improved performance, especially when the train data is small. As expected, the proposed method performs better than the baseline when there is a larger difference between road distance and Vincenty distance between start and end points.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:2v_ZtQDX9iAC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Recently, it has been shown that deep learning models are vulnerable to Trojan attacks. In the Trojan attacks, an attacker can install a backdoor during training to make the model misidentify samples contaminated with a small trigger patch. Current backdoor detection methods fail to achieve good detection performance and are computationally expensive. In this paper, we propose a novel trigger reverse-engineering based approach whose computational complexity does not scale up with the number of labels and is based on a measure that is both interpretable and universal across different networks and patch types. In experiments, we observe that our method achieves a perfect score in separating Trojan models from pure models, which is an improvement over the current state-of-the-art method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:jmjb1lOE9QIC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Environmental and climate models used for weather prediction require evenly spaced meteorological datasets at a very high spatial and temporal resolution to facilitate the analysis of recent climatic changes. However, due to the small number of weather stations available, often the data collected from them are scattered and inadequate for such model creation. For this reason, very high-resolution gridded meteorological surface is developed by interpolating the available scattered data points to fulfill the need of various ecological and climatic applications. Among various interpolation techniques, Ordinary Kriging (OK) is one of the most popular and widely used gridding methodologies with a sound statistical basis providing a possibility to obtain highly accurate results. However, OK interpolation on large unevenly spaced data points is computationally demanding and has a computational cost that scales as the cube …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:37UQlXuwjP4C,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Continuous-time prediction of self reported musical emotions is a challenging problem with many applications. However, there are relatively few studies on design of Deep learning models for the above problem. Existing methods for the same problem has used LSTMs, with modest success. In this work, we describe an attentive LSTM based approach for emotion prediction from music clips. We postulate that attending to specific regions in the past gives the model, a better chance of predicting the emotions evoked by present notes. We validate our model through extensive experimentation on the standard 1000 Songs for Emotional Analysis of Music dataset, which is annotated with arousal and valence values in continuous time. We find that the attentive models significantly improve the prediction performance of arousal and valence over vanilla LSTM, both in terms of R2 and Kendall-τ metrics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:wLxue7F8ec0C,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"This Letter presents the observation of the rare Z boson decay Z→ ψ ℓ+ ℓ−. Here, ψ represents contributions from direct J/ψ and ψ (2 S)→ J/ψ X, ℓ+ ℓ− is a pair of electrons or muons, and the J/ψ meson is detected via its decay to μ+ μ−. The sample of proton-proton collision data, collected by the CMS experiment at the LHC at a center-of-mass energy of 13 TeV, corresponds to an integrated luminosity of 35.9 fb− 1. The signal is observed with a significance in excess of 5 standard deviations. After subtraction of the ψ (2 S)→ J/ψ X contribution, the ratio of the branching fraction of the exclusive decay Z→ J/ψ ℓ+ ℓ− to the decay Z→ μ+ μ− μ+ μ− within a fiducial phase space is measured to be B (Z→ J/ψ ℓ+ ℓ−)/B (Z→ μ+ μ− μ+ μ−)= 0.67±0.18 (stat)±0.05 (syst).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:N4u4nq0IxgcC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Named entity disambiguation (NED) is a central problem in information extraction. The goal is to link entities in a knowledge graph (KG) to their mention spans in unstructured text. Each distinct mention span (like John Smith, Jordan or Apache) represents a multi-class classification task. NED can therefore be modeled as a multitask problem with tens of millions of tasks for realistic KGs. We initiate an investigation into neural representations, network architectures, and training protocols for multitask NED. Specifically, we propose a task-sensitive representation learning framework that learns mention dependent representations, followed by a common classifier. Parameter learning in our framework can be decomposed into solving multiple smaller problems involving overlapping groups of tasks. We prove bounds for excess risk, which provide additional insight into the problem of multi-task representation learning. While remaining practical in terms of training memory and time requirements, our approach outperforms recent strong baselines, on four benchmark data sets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:nVrZBo8bIpAC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Solar flares create adverse space weather impacting space-and Earth-based technologies. However, the difficulty of forecasting flares, and by extension severe space weather, is accentuated by the lack of any unique flare trigger or a single physical pathway. Studies indicate that multiple physical properties contribute to active region flare potential, compounding the challenge. Recent developments in machine learning (ML) have enabled analysis of higher-dimensional data leading to increasingly better flare forecasting techniques. However, consensus on high-performing flare predictors remains elusive. In the most comprehensive study to date, we conduct a comparative analysis of four popular ML techniques (k nearest neighbors, logistic regression, random forest classifier, and support vector machine) by training these on magnetic parameters obtained from the Helioseismic and Magnetic Imager on board the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:oTdOBqtIf_kC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Finding valuable training data points for deep neural networks has been a core research challenge with many applications. In recent years, various techniques for calculating the “value” of individual training datapoints have been proposed for explaining trained models. However, the value of a training datapoint also depends on other selected training datapoints - a notion which is not explicitly captured by existing methods. In this paper, we study the problem of selecting high-value subsets of training data. The key idea is to design a learnable framework for online subset selection, which can be learned using mini-batches of training data, thus making our method scalable. This results in a parameterised convex subset selection problem that is amenable to a differentiable convex programming paradigm, thus allowing us to learn the parameters of the selection model in an end-to-end training. Using this …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:iyewoVqAXLQC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Dynamic prediction of perceived emotions of music is a challenging problem with interesting applications. Utilization of relevant context in audio sequence is essential for effective prediction. Existing methods have used LSTMs with modest success. In this work we describe three attentive LSTM based approaches for dynamic emotion prediction from music clips. We validate our models through extensive experimentation on standard dataset annotated with arousal-valence values in continuous time, and choose the best performer. We find that the LSTM based attention models perform better than the state of the art transformers for the dynamic emotion prediction task, both in terms of R2 and Kendall-τ metrics. We explore individual smaller feature sets in search of a more effective one and to understand how different features contribute to perceived emotion. The spectral features are found to perform at par with the generic ComPare feature set [1]. Through attention map analysis we visualize how attention is distributed over music clips’ frames for emotion prediction. It is observed that the models attend to frames which contribute to changes in reported arousal-valence values and chroma to produce better emotion predictions, effectively capturing long-term dependencies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:naSTrk-c4S8C,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"In this paper, we describe a novel approach for navigation of a robot in a dynamic environment by exploiting the benefits of time series analysis of Long Short Term Memory (LSTM) architectures on obstacle trajectories. Most path planning algorithms consider the instantaneous position of the obstacles while generating the path, resulting in frequent re-planning and extended traversal time. However, moving obstacles more often than not tend to follow certain motion patterns in real life scenarios such as the motion of people on roads, building lobbies, shops, etc. In our algorithm, LSTM-based Dynamic Rapidly-exploring Random Trees star (LD-RRT*), obstacle trajectories are treated as sequences where their future position estimates are incorporated in the state validity checker of planning algorithms to generate an optimal path. Taking the future obstacle motion into account reduces the total traversal time and the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:43bX7VzcjpAC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"A networked opinion diffusion process that usually involves extensive spontaneous discussions between connected users, is often propelled by external sources of news or feeds recommended to them. In many applications like marketing design, or product launch, etc., corporations often post curated news or feeds on social media in order to steer the users’ opinions in a desired way. We call such scenarios as opinion shaping or opinion control whereby a few select users called control users post opinionated messages to drive the others’ opinions to reach a given state. In this paper, we propose SmartShape, an opinion control package that jointly selects the control users, as well as computes the optimum rate of control messages, thereby driving the networked opinion dynamics to the desired direction. Furthermore, our proposal also includes a robust shaping suit which makes our control framework resilient to stochastic fluctuations of opinion dynamics, originating from several sources of randomness. Experiments on several synthetic and real datasets gathered from Twitter, show that SmartShape can accurately determine the quality of a set of control users as well as shape the opinion dynamics more effectively than several baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:4X0JR2_MtJMC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Occurrences of catastrophes such as natural or man-made disasters trigger the spread of rumours over social media at a rapid pace. Presenting a trustworthy and summarized account of the unfolding event in near real-time to the consumers of such potentially unreliable information thus becomes an important task. In this work, we propose MTLTS, the first end-to-end solution for the task that jointly determines the credibility and summary-worthiness of tweets. Our credibility verifier is designed to recursively learn the structural properties of a Twitter conversation cascade, along with the stances of replies towards the source tweet. We then take a hierarchical multi-task learning approach, where the verifier is trained at a lower layer, and the summarizer is trained at a deeper layer where it utilizes the verifier predictions to determine the salience of a tweet. Different from existing disaster-specific summarizers, we model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:ndLnGcHYRF0C,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"This Letter presents the results of a search for pair-produced particles of masses above 100 GeV that each decay into at least four quarks. Using data collected by the CMS experiment at the LHC in 2015–2016, corresponding to an integrated luminosity of 38.2 fb− 1, reconstructed particles are clustered into two large jets of similar mass, each consistent with four-parton substructure. No statistically significant excess of data over the background prediction is observed in the distribution of average jet mass. Pair-produced squarks with dominant hadronic R-parity-violating decays into four quarks and with masses between 0.10 and 0.72 TeV are excluded at 95% confidence level. Similarly, pair-produced gluinos that decay into five quarks are also excluded with masses between 0.10 and 1.41 TeV at 95% confidence level. These are the first constraints that have been placed on pair-produced particles with masses …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:PQEM9vzQD9gC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"The cyclotron at Variable Energy Cyclotron Centre (VECC), Kolkata, has recentlyrecently completed its 40 years of operation in 2017. During the past four decades, VECC has been able to cross several milestones in exploring the properties of nuclei with the help of low energy light as well as heavy ions accelerated by the cyclotron. In this review, we endeavour to present an overall picture of the intense research activities in various branches of nuclear physics carried out in the past four decades using cyclotron, with special emphasis on the important achievements in each field.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:QVtou7C4vgoC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Aspect level sentiment classification (ALSC) is a difficult problem with state-of-the-art models showing less than 80% macro-F1 score on benchmark datasets. Existing models do not incorporate information on aspect-aspect relations in knowledge graphs (KGs), e.g. DBpedia. Two main challenges stem from inaccurate disambiguation of aspects to KG entities, and the inability to learn aspect representations from the large KGs in joint training with ALSC models. We propose AR-BERT, a novel two-level global-local entity embedding scheme that allows efficient joint training of KG-based aspect embeddings and ALSC models. A novel incorrect disambiguation detection technique addresses the problem of inaccuracy in aspect disambiguation. We also introduce the problem of determining mode significance in multi-modal explanation generation, and propose a two step solution. The proposed methods show a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:bVQMTfhMCi4C,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"This article investigates the dynamics of competition among organizations with unequal expertise. Multiagent reinforcement learning (MARL) has been used to simulate and understand the impact of various incentive schemes designed to offset such inequality. We design Touch-Mark, a game based on well-known multiagent particle environment, where two teams (weak and strong) with unequal but changing skill levels compete against each other. For training such a game, we propose a novel controller-assisted MARL algorithm C-MADDPG, which empowers each agent with an ensemble of policies along with a supervised controller that by selectively partitioning the sample space and triggers intelligent role division among the teammates. Using C-MADDPG as an underlying framework, we propose an incentive scheme for the weak team such that the final rewards of both teams become the same. We find that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:KS-xo-ZNxMsC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Automatic extraction of product attribute-value pairs from unstructured text like product descriptions is an important problem for e-commerce companies. The attribute schema typically varies from one category of products (which will be referred as vertical) to another. This leads to extreme annotation efforts for training of supervised deep sequence labeling models such as LSTM-CRF, and consequently not enough labeled data for some vertical-attribute pairs. In this work, we propose a technique for alleviating this problem by using annotated data from related verticals in a multi-task learning framework. Our approach relies on availability of similar attributes (labels) in another related vertical. Our model jointly learns the similarity between attributes of the two verticals along with the model parameters for the sequence tagging model. The main advantage of our approach is that it does not need any prior annotation of attribute similarity. Our system has been tested with datasets of size more than 10000 from a large e-commerce company in India. We perform detailed experiments to show that our method indeed increases the macro-F1 scores for attribute value extraction in general, and for labels with low training data in particular. We also report top labels from other verticals that contribute towards learning of particular labels.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:x21FZCSn4ZoC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"The networked opinion diffusion in online social networks is often governed by the two genres of opinions—endogenous opinions that are driven by the influence of social contacts among users, and exogenous opinions which are formed by external effects like news and feeds. Accurate demarcation of endogenous and exogenous messages offers an important cue to opinion modeling, thereby enhancing its predictive performance. In this article, we design a suite of unsupervised classification methods based on experimental design approaches, in which, we aim to select the subsets of events which minimize different measures of mean estimation error. In more detail, we first show that these subset selection tasks are NP-Hard. Then we show that the associated objective functions are weakly submodular, which allows us to cast efficient approximation algorithms with guarantees. Finally, we validate the efficacy of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:2vr6o8x5NLkC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Training vision-based Autonomous driving models is a challenging problem with enormous practical implications. One of the main challenges is the requirement of storage and processing of vast volumes of (possibly redundant) driving video data. In this paper, we study the problem of data-efficient training of autonomous driving systems. We argue that in the context of an edge-device deployment, multi-criteria online video frame subset selection is an appropriate technique for developing such frameworks. We study existing convex optimization based solutions and show that they are unable to provide solution with high weightage to loss of selected video frames. We design a novel multi-criteria online subset selection algorithm, TMCOSS, which uses a thresholded concave function of selection variables. Extensive experiments using driving simulator CARLA show that we are able to drop 80% of the frames, while succeeding to complete 100% of the episodes. We also show that TMCOSS improves performance on the crucial affordance'Relative Angle'during turns, on inclusion of bucket-specific relative angle loss (BL), leading to selection of more frames in those parts. TMCOSS also achieves an 80% reduction in number of training video frames, on real-world videos from the standard BDD and Cityscapes datasets, for the tasks of drivable area segmentation, and semantic segmentation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:WwIwg2wKZ0QC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Strassen's block-recursive matrix multiplication is amenable to parallelization via distributed recursion. Recently, distributed implementations of Strassen's algorithm using Big-data frameworks, e.g. Apache Spark have emerged for matrices of orders which are powers of 2. This paper studies an imple-mentation of distributed block-recursive matrix multiplication algorithm for matrices of arbitrary order with minimal zero padding. The conducted experiments show that our implementation has strong scalability with increasing matrix size enabling us to multiply large matrices with upto 21% less wall clock time than MLLib, the in-built matrix multiplication implementation in Spark. We report an interesting pattern in optimal block-size as a function of matrix size.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:m92CDrhVnKEC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"A large fraction of data generated via human activities such as online purchases, health records, spatial mobility, etc. can be represented as a sequence of events over a continuous-time. Learning deep learning models over these continuous-time event sequences is a non-trivial task as it involves modeling the ever-increasing event timestamps, inter-event time gaps, event types, and the influences between different events within and across different sequences. In recent years, neural enhancements to marked temporal point processes (MTPP) have emerged as a powerful framework to model the underlying generative mechanism of asynchronous events localized in continuous time. However, most existing models and inference methods in the MTPP framework consider only the complete observation scenario i.e., the event sequence being modeled is completely observed with no missing events – an ideal setting …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:3_LpOwP6eMYC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:M0leSnx2MbUC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Background
Clinical tests for diagnosis of any disease may be expensive, uncomfortable, time consuming and can have side effects e.g. barium swallow test for esophageal cancer. Although we can predict non-existence of esophageal cancer with near 100% certainty just using demographics, lifestyle, medical history information, and a few basic clinical tests but our objective is to devise a general methodology for customizing tests with user preferences to avoid expensive or uncomfortable tests.
Method
We propose to use classifiers trained from electronic medical records (EMR) for selection of tests. The key idea is to design classifiers with 100% false normal rates, possibly at the cost of higher false abnormal. We find kernel logistic regression to be most suitable for the task. We propose an algorithm for finding the best probability threshold for kernel LR, based on test set accuracy tuning with help of a validation data …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:F9fV5C73w3QC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Music has strong potential to convey and elicit emotions, which are dependent on both context and antecedent stimuli. However, there is little research available on the impact of antecedent musical stimuli on emotion perception in consequent musical pieces, when one listens to a sequence of music clips with insignificant time lag. This work attempts to (a) understand how the perception of one music clip is affected by the perception of its antecedent clip and (b) find if there are any inherent patterns in the way people respond when exposed to music in sequence, with special reference to Hindustani Classical Music (HCM). We call this phenomenon of varying perceptions, the perceptual contagion of emotion in music. Findings suggest, when happy clips are preceded by sad and calm clips, perceived happiness increases. When sad clips are preceded by happy and calm clips, perceived sadness increases …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:OzeSX8-yOCQC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"In this paper, we consider the problem of global change-point detection in event sequence data, where both the event distributions and change-points are assumed to be unknown. For this problem, we propose a Log-likelihood Ratio based Global Change-point Detector, which observes the entire sequence and detects a prespecified number of change-points. Based on the Transformer Hawkes Process (THP), a well-known neural TPP framework, we develop DCPD, a differentiable change-point detector, along with maintaining distinct intensity and mark predictor for each partition. Further, we propose a sliding-window-based extension of DCPD to improve its scalability in terms of the number of events or change-points with minor sacrifices in performance. Experiments on synthetic datasets explore the effects of run-time, relative complexity, and other aspects of distributions on various properties of our changepoint detectors, namely robustness, detection accuracy, scalability, etc. under controlled environments. Finally, we perform experiments on six real-world temporal event sequences collected from diverse domains like health, geographical regions, etc., and show that our methods either outperform or perform comparably with the baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:QaSi33NTfwYC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Team competition in multi-agent Markov games is an increasingly important setting for multi-agent reinforcement learning, due to its general applicability in modeling many real-life situations. Multi-agent actor-critic methods are the most suitable class of techniques for learning optimal policies in the team competition setting, due to their flexibility in learning agent-specific critic functions, which can also learn from other agents. In many real-world team competitive scenarios, the roles of the agents naturally emerge, in order to aid in coordination and collaboration within members of the teams. However, existing methods for learning emergent roles rely heavily on the Q-learning setup which does not allow learning of agent-specific Q-functions. In this paper, we propose RAC, a novel technique for learning the emergent roles of agents within a team that are diverse and dynamic. In the proposed method, agents also benefit from predicting the roles of the agents in the opponent team. RAC uses the actor-critic framework with role encoder and opponent role predictors for learning an optimal policy. Experimentation using 2 games demonstrates that the policies learned by RAC achieve higher rewards than those learned using state-of-the-art baselines. Moreover, experiments suggest that the agents in a team learn diverse and opponent-aware policies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:6ZzL7HXColQC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Data valuation and subset selection have emerged as valuable tools for application-specific selection of important training data. However, the efficiency-accuracy tradeoffs of state-of-the-art methods hinder their widespread application to many AI workflows. In this paper, we propose a novel 2-phase solution to this problem. Phase 1 selects representative checkpoints from an SGD-like training algorithm, which are used in phase-2 to estimate the approximate training data values, e.g. decrease in validation loss due to each training point. A key contribution of this paper is CheckSel, an Orthogonal Matching Pursuit-inspired online sparse approximation algorithm for checkpoint selection in the online setting, where the features are revealed one at a time. Another key contribution is the study of data valuation in the domain adaptation setting, where a data value estimator obtained using checkpoints from training trajectory in the source domain training dataset is used for data valuation in a target domain training dataset. Experimental results on benchmark datasets show the proposed algorithm outperforms recent baseline methods by up to 30% in terms of test accuracy while incurring a similar computational burden, for both standalone and domain adaptation settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:tz746QTLzJkC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Team-competition in multi-agent games is an important setting, where multi-agent actor-critic methods are the state-of-the-art methods. In many such scenarios, the roles for players naturally emerge, thus aiding in collaboration within the teams. However, exiting methods for the team-competition scenario do not attempt to learn such emergent roles. In this paper, we propose RAC, a new technique for learning emergent roles which are dynamic and diverse. RAC uses the actor-critic framework with role encoder and opponent role predictors, that are used in learning an optimal policy. The policies learned by RAC outperform state-of-the-art baselines in direct competitions. Extensive experimentation confirms the quality of learned roles, and utility of the different loss functions used.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:QoJ_w57xiyAC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Solar flares have a severe impact on near-Earth space weather due to the release of energy in the form of electromagnetic radiation bursts and energetic particles. They pose serious threats to satellites, astronaut health, communication systems, and other space reliant technologies. Therefore, forecasting solar flare has a growing demand in the space sciences. Recent advances in machine learning allow handling of high dimensional data and have shown potential in flare forecasting. Previous studies have shown that solar active region (AR) properties can be well constrained by several magnetic field parameters deduced from vector magnetogram data. We conduct a comparative analysis of four robust Machine learning models to classify the ARs based on their flaring capability by training them on magnetic features derived from Spaceweather HMI Active Region Patch (SHARP) data. We demonstrate that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:lg2tdxc6qMwC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Aspect level sentiment classification (ALSC) is a difficult problem with state-of-the-art models showing less than 80% macro-F1 score on benchmark datasets. Existing models do not incorporate information on aspect-aspect relations in knowledge graphs (KGs), eg DBpedia. Two main challenges stem from inaccurate disambiguation of aspects to KG entities, and the inability to learn aspect representations from the large KGs in joint training with ALSC models. We propose AR-BERT, a novel two-level global-local entity embedding scheme that allows efficient joint training of KG-based aspect embeddings and ALSC models. A novel incorrect disambiguation detection technique addresses the problem of inaccuracy in aspect disambiguation. We also introduce the problem of determining mode significance in multi-modal explanation generation, and propose a two step solution. The proposed methods show a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:pYKElYtJMmwC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Training vision-based Urban Autonomous driving models is a challenging problem, which is highly researched in recent times. Training such models is a data-intensive task requiring the storage and processing of vast volumes of (possibly redundant) driving video data. In this paper, we study the problem of developing data-efficient autonomous driving systems. In this context, we study the problem of multi-criteria online video frame subset selection. We study convex optimization-based solutions and show that they are unable to provide solutions with high weightage to the loss of selected video frames. We design a novel convex optimization-based multi-criteria online subset selection algorithm that uses a thresholded concave function of selection variables. We also propose and study a submodular optimization-based algorithm. Extensive experiments using the driving simulator CARLA show that we are able to drop 80% of the frames while succeeding to complete 100% of the episodes w.r.t. the model trained on 100% data, in the most difficult task of taking turns. This results in a training time of less than 30% compared to training on the whole dataset. We also perform detailed experiments on prediction performances of various affordances used by the Conditional Affordance Learning (CAL) model and show that our subset selection improves performance on the crucial affordance ""Relative Angle"" during turns.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:ji7lAbPyDbYC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Cholesky Decomposition is the primary approach which is used to solve Symmetric and Positive Definite (SPD) systems but is inherently iterative making it very difficult to parallelize as calculations at each partition require elements from other partitions. In this paper, we present two distributed block-recursive approaches to solve large SPD systems — the symmetric version of the state-of-the-art Strassen’s algorithm and Cholesky based inversion algorithm. We show experimentally that both the approaches have good scalability and Cholesky based approach is more efficient as it uses fewer matrix multiplications in each recursion level than Strassen based algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:eI34FqJmdUoC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Learning meaningful vector representations of nodes of a network has been a subject of intense study in the past few years, with various objectives such as node or link labeling, preserving higher order structures, etc. In this paper, we focus on reconstruction of adjacency matrix, which also leads to preservation of higher order structures, through spectral distance. Methodologically, existing techniques focus on construction of various neighborhoods based on the link-structure, but do not explicitly give importance to nonlinks. Our method, called the subspace learning method (SLM), is based on a simple observation that in addition to representations of neighbors sharing a common subspace, representations of non-neighbors should lie in each others' null-space. We devise an efficient, negative sampling based algorithm for learning the node representations. Experimental results on many real world benchmark …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:BzfGm06jWhQC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Aaboud, M., Aad, G., Abbott, B., et al. Combinations of single-top-quark production cross-section measurements and vertical bar f (LV) V (tb) vertical bar determinations at root s= 7 and 8 TeV with the ATLAS and CMS experiments [J]. JOURNAL OF HIGH ENERGY PHYSICS, 2019.
APA Aaboud, M.., Aad, G.., Abbott, B.., Abbott, DC., Abdinov, O..,... &Woods, N..(2019). Combinations of single-top-quark production cross-section measurements and vertical bar f (LV) V (tb) vertical bar determinations at root s= 7 and 8 TeV with the ATLAS and CMS experiments. JOURNAL OF HIGH ENERGY PHYSICS.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:I858iXPj1OkC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"An embedding technique is presented to estimate standard model it backgrounds from data with minimal simulation input. In the data, the muons are removed from reconstructed nn events and replaced with simulated tau leptons with the same kinematic properties. In this way, a set of hybrid events is obtained that does not rely on simulation except for the decay of the tau leptons. The challenges in describing the underlying event or the production of associated jets in the simulation are avoided. The technique described in this paper was developed for CMS. Its validation and the inherent uncertainties are also discussed. The demonstration of the performance of the technique is based on a sample of proton-proton collisions collected by CMS in 2017 at ?s = 13 TeV corresponding to an integrated luminosity o 41.5 fb-1. 2019 CERN for the benefit of the CMS collaboration. Published by IOP Publishing Ltd on behalf …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:ymY9cBF3mdcC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"Accurate modeling of information dynamics of online media across time has a wide variety of applications. For example, in Twitter, we can predict which hashtag may go viral against others; also in an e-commerce site like Amazon, reviews of a product over the time can help to identify which product will be preferred over others in future. The information dynamics follow a complex diffusion process and many factors reinforce each other. There are clearly two types of factors: (a) intra-item factors and (b) inter-item factors. Visibility indicates the ability of a piece of information to attract the attention of the users, against the background information. Therefore, apart from the individual information diffusion processes, the information visibility dynamics also involves a competition process, where each information diffusion process competes against others to draw the attention of users. Despite the fact that models of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:5bg8sr1QxYwC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"This paper presents combinations of inclusive and differential measurements of the charge asymmetry (AC) in top quark pair (tt) events with a lepton+ jets signature by the ATLAS and CMS Collaborations, using data from LHC proton-proton collisions at centreof-mass energies of 7 and 8 TeV. The data correspond to integrated luminosities of about 5 and 20 fb− 1 for each experiment, respectively. The resulting combined LHC measurements of the inclusive charge asymmetry are ALHC7",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:Og1tA8FjbJAC,http://cse.iitkgp.ac.in/~sourangshu
Sourangshu Bhattacharya,"['Machine Learning', 'Subset Selection', 'Big Data', 'Optimization']",13,"High-resolution gridded meteorological dataset of various environment variables, e.g., max–min land surface temperature, precipitation, humidity etc., are not easily available for most of the Earth’s surface. This imposes a bottleneck on the research ideas that require the gridded dataset for experimentation and testing. Such data are often expensive and thus cannot be used for academia and individual researchers. In this paper, we present SprIntMap, a Web service which allows users to fetch and process climatic datasets with different spatial interpolation methods and visualize and extract the resulting interpolated gridded data on-the-fly. The system facilitates access to NOAA’s a century-old archive which is one of the comprehensive sensor data archives in the world. Yet, it is challenging to obtain these large and noisy data and apply interpolation methods on it. SprIntMap consists of Google Map-based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=IixRsP0AAAAJ&cstart=20&pagesize=80&citation_for_view=IixRsP0AAAAJ:4xDN1ZYqzskC,http://cse.iitkgp.ac.in/~sourangshu
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Users frequently use search systems on the Web as well as online social media to learn about ongoing events and public opinion on personalities. Prior studies have shown that the top-ranked results returned by these search engines can shape user opinion about the topic (e.g., event or person) being searched. In case of polarizing topics like politics, where multiple competing perspectives exist, the political bias in the top search results can play a significant role in shaping public opinion towards (or away from) certain perspectives. Given the considerable impact that search bias can have on the user, we propose a generalizable search bias quantification framework that not only measures the political bias in ranked list output by the search system but also decouples the bias introduced by the different sources—input data and ranking system. We apply our framework to study the political bias in searches …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&citation_for_view=7TmKZv0AAAAJ:XiVPGOgt02cC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Microblogging sites like Twitter have become important sources of real-time information during disaster events. A large amount of valuable situational information is posted in these sites during disasters; however, the information is dispersed among hundreds of thousands of tweets containing sentiments and opinions of the masses. To effectively utilize microblogging sites during disaster events, it is necessary to not only extract the situational information from the large amounts of sentiments and opinions, but also to summarize the large amounts of situational information posted in real-time. During disasters in countries like India, a sizable number of tweets are posted in local resource-poor languages besides the normal English-language tweets. For instance, in the Indian subcontinent, a large number of tweets are posted in Hindi/Devanagari (the national language of India), and some of the information contained in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&citation_for_view=7TmKZv0AAAAJ:738O_yMBCRsC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&citation_for_view=7TmKZv0AAAAJ:tkaPQYYpVKoC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Summarization of legal case judgments is an important problem because the huge length and complexity of such documents make them difficult to read as a whole. Many summarization algorithms have been proposed till date, both for general text documents and a few specifically targeted to summarizing legal documents of various countries. However, to our knowledge, there has not been any systematic comparison of the performances of different algorithms in summarizing legal case documents. In this paper, we perform the first such systematic comparison of summarization algorithms applied to legal judgments. We experiment on a large set of Indian Supreme Court judgments, and a large variety of summarization algorithms including both unsupervised and supervised ones. We assess how well domain-independent summarization approaches perform on legal case judgments, and how approaches …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&citation_for_view=7TmKZv0AAAAJ:wbdj-CoPYUoC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Online forums and social media platforms are increasingly being used to discuss topics of varying polarities where different people take different stances. Several methodologies for automatic stance detection from text have been proposed in literature. To our knowledge, there has not been any systematic investigation towards their reproducibility, and their comparative performances. In this work, we explore the reproducibility of several existing stance detection models, including both neural models and classical classifier-based models. Through experiments on two datasets – (i) the popular SemEval microblog dataset, and (ii) a set of health-related online news articles – we also perform a detailed comparative analysis of various methods and explore their shortcomings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&citation_for_view=7TmKZv0AAAAJ:HE397vMXCloC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"The use of online social media for post-disaster situation analysis has recently become popular. However, utilizing information posted on social media has some potential hazards, one of which is rumor. For instance, on Twitter, thousands of verified and non-verified users post tweets to convey information, and not all information posted on Twitter is genuine. Some of them contain fraudulent and unverified information about different facts/incidents - such information are termed as rumors. Identification of such rumor tweets at early stage in the aftermath of a disaster is the main focus of the current work. To this end, a probabilistic model is adopted by combining prominent features of rumor propagation. Each feature has been coded individually in order to extract tweets that have at least one rumor propagation feature. In addition, content-based analysis has been performed to ensure the contribution of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:l7t_Zn2s7bgC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Automatically understanding the rhetorical roles of sentences in a legal case judgement is an important problem to solve, since it can help in several downstream tasks like summarization of legal judgments, legal search, and so on. The task is challenging since legal case documents are usually not well-structured, and these rhetorical roles may be subjective (as evident from variation of opinions between legal experts). In this paper, we address this task for judgments from the Supreme Court of India. We label sentences in 50 documents using multiple human annotators, and perform an extensive analysis of the human-assigned labels. We also attempt automatic identification of the rhetorical roles of sentences. While prior approaches towards this task used Conditional Random Fields over manually handcrafted features, we explore the use of deep neural models which do not require hand-crafting of features. Experiments show that neural models perform much better in this task than baseline methods which use handcrafted features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:tKAzc9rXhukC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Online Social Media, such as Twitter, Facebook and WhatsApp, are important sources of real-time information related to emergency events, including both natural calamities, man-made disasters, epidemics, and so on. There has been lot of recent work on designing information systems that would be useful for aiding post-disaster relief operations, as well as for pre-disaster preparedness. A special issue on “Exploitation of Social Media for Emergency Relief and Preparedness” was conducted for the journal Information Systems Frontiers. The objective of this special issue was to present a platform for dissemination of the empirical results of various technologies for extracting vital and actionable information from social media content in disaster situations. The papers included in this issue are expected to be the stepping stones for future explorations and technical innovations towards technologies meant for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:eq2jaN3J8jMC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Microblogging sites like Twitter are the important sources of real-time information during disaster/emergency events. During such events, the critical situational information posted is immersed in a lot of conversational content; hence, reliable methodologies are needed for extracting the meaningful information. In this paper, we focus on a particular application that is critical for efficient management of post-disaster relief operations - identifying tweets that inform about resource needs and resource availabilities. Two broad types of methodologies can be practically applied to identify such tweets during an ongoing disaster event: 1) supervised classification approaches, where the classifier models are trained on microblogs posted during prior events and applied on those posted during the ongoing event and 2) unsupervised pattern matching and information retrieval approaches that can be directly applied on the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:olpn-zPbct0C,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"We investigate whether off-the-shelf summarization algorithms can be combined to produce better quality summaries. To this end, we propose ensemble schemes that can combine the outputs of multiple base summarization algorithms, to produce summaries better than what is generated by any of the base algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:tOudhMTPpwUC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"During a disaster event, two types of information that are especially useful for coordinating relief operations are needs and availabilities of resources (e.g., food, water, medicines) in the affected region. Information posted on microblogging sites is increasingly being used for assisting post-disaster relief operations. In this context, two practical challenges are (i) to identify tweets that inform about resource needs and availabilities (termed as need-tweets and availability-tweets, respectively), and (ii) to automatically match needs with appropriate availabilities. While several works have addressed the first problem, there has been little work on automatically matching needs with availabilities. The few prior works that attempted matching only considered the resources, and no attempt has been made to understand other aspects of needs/availabilities that are essential for matching in practice. In this work, we develop a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:t6usbXjVLHcC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"As online social network (OSN) sites become increasingly popular, they are targeted by spammers who post malicious content on the sites. Hence, it is important to filter out spam accounts and spam posts from OSNs. There exist several prior works on spam classification on OSNs, which utilize various features to distinguish between spam and legitimate entities. The objective of this study is to improve such spam classification, by developing an attribute selection methodology that helps to find a smaller subset of the attributes which leads to better classification. Specifically, we apply the concepts of rough set theory to develop the attribute selection algorithm. We perform experiments over five different spam classification datasets over diverse OSNs and compare the performance of the proposed methodology with that of several baseline methodologies for attribute selection. We find that, for most of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:vRqMK49ujn8C,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"The huge amount of tweets posted during a disaster event includes information about the present situation as well as the emotions/opinions of the masses. While looking through these tweets, we realized that a large amount of communal tweets, i.e., abusive posts targeting specific religious/racial groups are posted even during natural disasters-this paper focuses on such category of tweets, which is in sharp contrast to most of the prior research concentrating on extracting situational information. Considering the potentially adverse effects of communal tweets during disasters, in this paper, we develop a classifier to distinguish communal tweets from noncommunal ones, which performs significantly better than existing approaches. We also characterize the communal tweets posted during five recent disaster events, and the users who posted such tweets. Interestingly, we find that a large proportion of communal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:08ZZubdj9fEC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"In the domain of legal information retrieval, an important challenge is to compute similarity between two legal documents. Precedents (statements from prior cases) play an important role in The Common Law system, where lawyers need to frequently refer to relevant prior cases. Measuring document similarity is one of the most crucial aspects of any document retrieval system which decides the speed, scalability and accuracy of the system. Text-based and network-based methods for computing similarity among case reports have already been proposed in prior works but not without a few pitfalls. Since legal citation networks are generally highly disconnected, network based metrics are not suited for them. Till date, only a few text-based and predominant embedding based methods have been employed, for instance, TF-IDF based approaches, Word2Vec (Mikolov et al. 2013) and Doc2Vec (Le and Mikolov …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:-_dYPAW6P2MC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"In countries like the US, European countries, Australia and Japan, user-generated content from microblogging sites is extensively used for crowdsourcing actionable information during disasters. However, there has been limited work in this direction in India. Moreover, there has been a limited attempt to verify the credibility of the information extracted from microblogs from other reliable sources. To this end, the FIRE 2018 Information Retrieval from Microblogs during Disasters (IRMiDis) track focused on the identification of factual or fact-checkable tweets and supporting news article for each fact-checkable tweets. The data consists of around 50, 000 microblogs (tweets) from Twitter and 6, 000 news articles, that were posted during the Nepal earthquake in April 2015. There were two tasks. The first task (Task 1) was to identify factual or fact-checkable tweets and the second task (Task 2) was to identify supporting news …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:OU6Ihb5iCvQC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Automatic summarization of legal case documents is an important and practical challenge. Apart from many domain-independent text summarization algorithms that can be used for this purpose, several algorithms have been developed specifically for summarizing legal case documents. However, most of the existing algorithms do not systematically incorporate domain knowledge that specifies what information should ideally be present in a legal case document summary. To address this gap, we propose an unsupervised summarization algorithm DELSumm which is designed to systematically incorporate guidelines from legal experts into an optimization setup. We conduct detailed experiments over case documents from the Indian Supreme Court. The experiments show that our proposed unsupervised method outperforms several strong baselines in terms of ROUGE scores, including both general summarization …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:XD-gHx7UXLsC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"While there has been a plethora of approaches for detecting disjoint communities from real-world complex networks, some methods for detecting overlapping community structures have also been recently proposed. In this work, we argue that, instead of developing separate approaches for detecting overlapping communities, a promising alternative is to infer the overlapping communities from multiple disjoint community structures. We propose an ensemble-based approach, called EnCoD, that leverages the solutions produced by various disjoint community detection algorithms to discover the overlapping community structure. Specifically, EnCoD generates a feature vector for each vertex from the results of the base algorithms and learns which features lead to detect densely connected overlapping regions in an unsupervised way. It keeps on iterating until the likelihood of each vertex belonging to its own community …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:bnK-pcrLprsC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"As the amount of user-generated textual content grows rapidly, text summarization algorithms are increasingly being used to provide users a quick overview of the information content. Traditionally, summarization algorithms have been evaluated only based on how well they match human-written summaries (e.g. as measured by ROUGE scores). In this work, we propose to evaluate summarization algorithms from a completely new perspective that is important when the user-generated data to be summarized comes from different socially salient user groups, e.g. men or women, Caucasians or African-Americans, or different political groups (Republicans or Democrats). In such cases, we check whether the generated summaries fairly represent these different social groups. Specifically, considering that an extractive summarization algorithm selects a subset of the textual units (e.g. microblogs) in the original data for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:AXPGKjj_ei8C,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Microblogging sites, notably Twitter, have become important sources of real-time situational information during emergency events. Since hundreds to thousands of microblogs (tweets) are generally posted on Twitter during an emergency event, manually going through every tweet is not feasible. Hence, summarization of microblogs posted during emergency events has become an important problem in recent years. Several summarization algorithms have been proposed in the literature, both for general document summarization, as well as specifically for summarization of microblogs. However, to our knowledge, there has not been any systematic analysis on which algorithms are more suitable for summarization of microblogs posted during disasters. In this work, we evaluate and compare the performance of 8 extractive summarization algorithms in the application of summarizing microblogs posted during …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:K3LRdlH-MEoC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Algorithmic recommendations mediate interactions between millions of customers and products (in turn, their producers and sellers) on large e-commerce marketplaces like Amazon. In recent years, the producers and sellers have raised concerns about the fairness of black-box recommendation algorithms deployed on these marketplaces. Many complaints are centered around marketplaces biasing the algorithms to preferentially favor their own 'private label' products over competitors. These concerns are exacerbated as marketplaces increasingly de-emphasize or replace 'organic' recommendations with ad-driven 'sponsored' recommendations, which include their own private labels. While these concerns have been covered in popular press and have spawned regulatory investigations, to our knowledge, there has not been any public audit of these marketplace algorithms. In this study, we bridge this gap by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:tzM49s52ZIMC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Online news media sites are emerging as the primary source of news for a large number of users. Due to a large number of stories being published in these media sites, users usually rely on news recommendation systems to find important news. In this work, we focus on automatically recommending news stories to all users of such media websites, where the selection is not influenced by a particular user’s news reading habit. When recommending news stories in such non-personalized manner, there are three basic metrics of interest—recency, importance (analogous to relevance in personalized recommendation) and diversity of the recommended news. Ideally, recommender systems should recommend the most important stories soon after they are published. However, the importance of a story only becomes evident as the story ages, thereby creating a tension between recency and importance. A …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:VL0QpB8kHFEC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"During a disaster event, it is essential to know about needs and availabilities of different types of resources, for coordinating relief operations. Microblogging sites are frequently used for aiding post-disaster relief operations, and there have been prior attempts to identify tweets that inform about resource needs and availabilities (termed as need-tweets and availability-tweets respectively). However, there has not been much attempt to effectively utilise such tweets. We introduce the problem of automatically matching need-tweets with appropriate availability-tweets, which is practically important for coordination of post-disaster relief operations. We also experiment with several methodologies for automatically matching need-tweets and availability-tweets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:Tiz5es2fbqcC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"We propose to evaluate extractive summarization algorithms from a completely new perspective. Considering that an extractive summarization algorithm selects a subset of the textual units in the input data for inclusion in the summary, we investigate whether this selection is fair. We use several summarization algorithms over datasets that have a sensitive attribute (e.g., gender, political leaning) associated with the textual units, and find that the generated summaries often have very different distributions of the said attribute. Specifically, some classes of the textual units are under-represented in the summaries according to the fairness notion of adverse impact. To our knowledge, this is the first work on fairness of summarization, and is likely to open up interesting research problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:XiSMed-E-HIC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Computing similarity between two legal case documents is a challenging task, for which text-based and network-based measures have been proposed in literature. All prior network-based similarity methods considered a precedent citation network among case documents only (PCNet). However, this approach misses an important source of legal knowledge - the hierarchy of legal statutes that are applicable in a given legal jurisdiction (e.g., country). We propose to augment the PCNet with the hierarchy of legal statutes, to form a heterogeneous network Hier-SPCNet. Experiments over a set of Indian Supreme Court case documents show that Hier-SPCNet enables significantly better document similarity estimation, as compared to existing approaches using PCNet. We also show that the proposed network-based method can complement text-based measures for better estimation of legal document similarity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:dTyEYWd-f8wC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Computing similarity between two legal documents is an important and challenging task in the domain of Legal Information Retrieval. Finding similar legal documents has many applications in downstream tasks, including prior-case retrieval, recommendation of legal articles, and so on. Prior works have proposed two broad ways of measuring similarity between legal documents - analyzing the precedent citation network, and measuring similarity based on textual content similarity measures. But there has not been a comprehensive comparison of these existing methods on a common platform. In this paper, we perform the first systematic analysis of the existing methods. In addition, we explore two promising new similarity computation methods - one text-based and the other based on network embeddings, which have not been considered till now.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:Y5dfb0dijaUC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"In recent years, we have witnessed a paradigm shift in news consumption. In traditional news media organizations, a small number of expert editors are responsible for selecting news stories that are consumed by all news readers (the audience). However, with the growing popularity of social media as a news consumption medium, a part of the editorial power of selecting news stories has shifted to the audience who select and share the stories that can reach a large number of consumers. In this paper, we analyze data from two popular news media sites-The New York Times and The Guardian, and characterize the considerable differences in the types of stories selected by the audience and expert news editors. We also find that story selections by audience vary significantly across different social media channels such as Twitter, Facebook, and email. We contextualize the differences utilizing media and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:W5xh706n7nkC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Microblogging sites are increasingly playing an important role in real-time disaster management. However, rumors and fake news often spread on such platforms, which if not detected, can derail the rescue operations. Therefore, it becomes imperative to verify some of the information posted on social media during disaster situations. To this end, it is necessary to correctly identify fact-checkable posts, so that their information content can be verified. In the present work, we address the problem of identifying fact-checkable posts on the Twitter microblogging site. We organized a shared task in the FIRE 2018 conference to study the problem of identification of fact-checkable tweets posted during a particular disaster event (the 2015 Nepal earthquake). This paper describes the dataset used in the shared task, and compares the performance of different methodologies for identifying fact-checkable tweets. We primarily …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:N5tVd3kTz84C,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Today, administering COVID-19 vaccines at a societal scale has been deemed as the most appropriate way to defend against the COVID-19 pandemic. This global vaccination drive naturally fueled a possibility of pro-vax and anti-vax users strongly expressing their supports and concerns regarding the vaccines in online social media platforms. Understanding this online discourse is crucial for policy makers. This understanding is likely to impact the success of vaccination drives and might even impact the final outcome of our fight against the pandemic. The goal of this work is to improve this understanding using the lens of Twitter-discourse data. We first develop a classifier to categorize users according to their vaccine-related stance with high precision (97%). Using this method we detect and investigate specific user-groups who posted about vaccines in pre-COVID and COVID times. We specifically identify distinct topics that these users talk about, and investigate how vaccine-related discourse has changed between pre-COVID times and COVID times. Finally, for the first time, we investigate the change of vaccine-related stances in Twitter users and shed light on potential reasons for such changes in stance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:uc_IGeMz5qoC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:epqYDVWIO7EC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"In a Common Law system, legal practitioners need frequent access to prior case documents that discuss relevant legal issues. Case documents are generally very lengthy, containing complex sentence structures, and reading them fully is a strenuous task even for legal practitioners. Having a concise overview of these documents can relieve legal practitioners from the task of reading the complete case statements. Legal catchphrases are (multi-word) phrases that provide a concise overview of the contents of a case document, and automated generation of catchphrases is a challenging problem in legal analytics. In this paper, we propose a novel supervised neural sequence tagging model for the extraction of catchphrases from legal case documents. Specifically, we show that incorporating document-specific information along with a sequence tagging model can enhance the performance of catchphrase …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:9Nmd_mFXekcC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"To improve the experience of consumers, all social media, commerce and entertainment sites deploy Recommendation Systems (RSs) that aim to help users locate interesting content. These RSs are black-boxes - the way a chunk of information is filtered out and served to a user from a large information base is mostly opaque. No one except the parent company generally has access to the entire information required for auditing these systems - neither the details of the algorithm nor the user-item interactions are ever made publicly available for third-party auditors. Hence auditing RSs remains an important challenge, especially with the recent concerns about how RSs are affecting the views of the society at large with new technical jargons like “echo chambers”, “confirmation biases”, “filter bubbles” etc. in place. Many prior works have evaluated different properties of RSs such as diversity, novelty, etc. However, most …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:5ugPr518TE4C,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"The task of Legal Statute Identification (LSI) aims to identify the legal statutes that are relevant to a given description of facts or evidence of a legal case. Existing methods only utilize the textual content of facts and legal articles to guide such a task. However, the citation network among case documents and legal statutes is a rich source of additional information, which is not considered by existing models. In this work, we take the first step towards utilising both the text and the legal citation network for the LSI task. We curate a large novel dataset for this task, including facts of cases from several major Indian Courts of Law, and statutes from the Indian Penal Code (IPC). Modeling the statutes and training documents as a heterogeneous graph, our proposed model LeSICiN can learn rich textual and graphical features, and can also tune itself to correlate these features. Thereafter, the model can be used to inductively predict links between test documents (new nodes whose graphical features are not available to the model) and statutes (existing nodes). Extensive experiments on the dataset show that our model comfortably outperforms several state-of-the-art baselines, by exploiting the graphical structure along with textual features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:EkHepimYqZsC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"The task of rhetorical role labeling is to assign labels (such as Fact, Argument, Final Judgement, etc.) to sentences of a court case document. Rhetorical role labeling is an important problem in the field of Legal Analytics, since it can aid in various downstream tasks as well as enhances the readability of lengthy case documents. The task is challenging as case documents are highly various in structure and the rhetorical labels are often subjective. Previous works for automatic rhetorical role identification (i) mainly used Conditional Random Fields over manually handcrafted features, and (ii) focused on certain law domains only (e.g., Immigration cases, Rent law), and a particular jurisdiction/country (e.g., US, Canada, India). In this work, we improve upon the prior works on rhetorical role identification by proposing novel Deep Learning models for automatically identifying rhetorical roles, which substantially …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:ipzZ9siozwsC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"User-generated content on online social media (OSM) platforms has become an important source of real-time information during emergency events. The SMERP workshop series aims to provide a forum for researchers working on utilizing OSM for emergency preparedness and aiding post-emergency relief operations. The workshop aims to bring together researchers from diverse fields - Information Retrieval, Data Mining and Machine Learning, Natural Language Processing, Social Network Analysis, Computational Social Science, Human Computer Interaction - who can potentially contribute to utilizing social media for emergency relief and preparedness. The first SMERP workshop was held in April 2017 in conjunction with the ECIR 2017 conference. This 2nd SMERP Workshop with The Web Conference 2018 includes two keynote talks, a peer-reviewed research paper track, and a panel discussion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:VOx2b1Wkg3QC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"The super-cyclonic storm “Amphan” hit Eastern India, specifically the state of West Bengal, Odisha and parts of Bangladesh in May 2020 and caused severe damage to the regions. In this study, we aim to understand the self-reported effects of this natural disaster on residents of the state of West Bengal. To that end, we conducted an online survey to understand the effects of the cyclone. In total, 201 participants (spanning five districts) from the worst-affected state of West Bengal participated in the survey. This report describes our findings from the survey, with respect to the damages caused by the cyclone, how it affected the population in various districts of West Bengal, and how prepared the authorities were in responding to the disaster. We found that the participants were most adversely affected in this disaster due to disruption of services like electricity, phone and internet (as opposed to uprooting of trees and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:7T2F9Uy0os0C,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Topic-specific social media forums such as Reddit have become popular platforms for users discussing health-related information as well as for scientific analysis of that information. Such discussions among users have been found to be effective in providing useful insights and assistance in many healthcare applications. This study focuses on one such application, where we utilize Reddit posts related to drug addiction and substance abuse, in order to help the addicted people. We observe some linguistic differences in the posts as users gradually move from the addicted stage to more and more advanced recovery stages. We then classify user-posts on Reddit as to be indicative of drug addiction or of different stages of recovery of the user. By annotating Reddit posts with the help of standard social and health psychology literature, we develop a Machine Learning classifier based on linguistic features, to classify the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:j8SEvjWlNXcC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Automatic Charge Identification (ACI) is the task of identifying the relevant charges given the facts of a situation and the statutory laws that define these charges, and is a crucial aspect of the judicial process. Existing works focus on learning charge-side representations by modeling relationships between the charges, but not much effort has been made in improving fact-side representations. We observe that only a small fraction of sentences in the facts actually indicates the charges. We show that by using a very small subset (< 3%) of fact descriptions annotated with sentence-level charges, we can achieve an improvement across a range of different ACI models, as compared to modeling just the main document-level task on a much larger dataset. Additionally, we propose a novel model that utilizes sentence-level charge labels as an auxiliary task, coupled with the main task of document-level charge identification in a multi-task learning framework. The proposed model comprehensively outperforms a large number of recent baselines for ACI. The improvement in performance is particularly noticeable for the rare charges which are known to be especially challenging to identify.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:SdhP9T11ey4C,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Microblogging sites like Twitter and Weibo have been shown to provide important real-time information during epidemics and disease outbreaks. During such situations, different types of stakeholders look for different types of information, such as symptoms, prevention, treatment schemes, death reports, and many more. Additionally, lots of personal opinions, sentiments are also posted on social media along with factual contents. In this work, we propose a method to automatically classify tweets posted during an epidemic into various informative categories. To this end, we utilize features derived from a medical knowledge base (UMLS) as well as features based on syntactic and lexical structure of tweets. We apply the classifier over tweets related to several diseases (Ebola, Dengue, and MERS), and show that, the proposed approach yields better classification performance as compared to earlier works. We also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:Mojj43d5GZwC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Summarization of legal case judgement documents is a challenging problem in Legal NLP. However, not much analyses exist on how different families of summarization models (e.g., extractive vs. abstractive) perform when applied to legal case documents. This question is particularly important since many recent transformer-based abstractive summarization models have restrictions on the number of input tokens, and legal documents are known to be very long. Also, it is an open question on how best to evaluate legal case document summarization systems. In this paper, we carry out extensive experiments with several extractive and abstractive summarization methods (both supervised and unsupervised) over three legal summarization datasets that we have developed. Our analyses, that includes evaluation by law practitioners, lead to several interesting insights on legal summarization in specific and long document summarization in general.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:4MWp96NkSFoC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"In last few years ,microblogging sites like Twitter have been evolved as a repository of critical situational information during various mass emergencies. However, messages posted on microblogging sites often contain non-actionable information such as sympathy and prayer for victims. Moreover, messages sometimes contain rumors and overstated facts. In such situations, identification of tweets that report some relevant and actionable information is extremely important for effective coordination of post-disaster relief operations. Thus, efficient IR methodologies are required to identify such critical information. Additionally, cross-verification of such critical information is a practical necessity to ensure the trustworthiness. To this end, we organized the ‘Information Retrieval from Microblogs during Disasters (IRMiDis)’ shared task with the FIRE conference for consecutive 3 years (2016, 2017 and 2018). In each year’s …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:JoZmwDi-zQgC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"In recent times, microblogging sites such as Twitter have become popular communication platforms for exchanging information. From the point of view of individual user, a reasonably active Twitter user can easily get hundreds of microblogs (tweets) in his/her timeline every day. In addition, a large number of the tweets contain fundamentally the same information, because of retweeting and re-posting. These huge amounts of repetitive data may cause data over-burden for the users, and no user can effectively process so much data. In this situation, methodologies to manage the data over-burden should be developed. One of the effective methods for managing the data over-burden on Twitter is to cluster semantically similar tweets into groups, with the goal that a user may see just a couple of tweets in each group. In this work, various graph clustering approaches based on dimension reduction are proposed for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:JQOojiI6XY0C,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"The Web has several information sources on which an ongoing event is discussed. To get a complete picture of the event, it is important to retrieve information from multiple sources. We propose a novel neural network based model which integrates the embeddings from multiple sources, and thus retrieves information from them jointly, %all the sources together, as opposed to combining multiple retrieval results. The importance of the proposed model is that no document-aligned comparable data is needed. Experiments on posts related to a particular event from three different sources - Facebook, Twitter and WhatsApp - exhibit the efficacy of the proposed model.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:WbkHhVStYXYC,https://sites.google.com/site/saptarshighosh/
Saptarshi Ghosh,"['Computational Social Science', 'Legal analytics', 'Algorithmic bias and fairness']",35,"Natural Language Processing in the legal domain been benefited hugely by the emergence of Transformer-based Pre-trained Language Models (PLMs) pre-trained on legal text. There exist PLMs trained over European and US legal text, most notably LegalBERT. However, with the rapidly increasing volume of NLP applications on Indian legal documents, and the distinguishing characteristics of Indian legal text, it has become necessary to pre-train LMs over Indian legal text as well. In this work, we introduce transformer-based PLMs pre-trained over a large corpus of Indian legal documents. We also apply these PLMs over several benchmark legal NLP tasks over Indian legal documents, namely, Legal Statute Identification from facts, Semantic segmentation of court judgements, and Court Judgement Prediction. Our experiments demonstrate the utility of the India-specific PLMs developed in this work.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=7TmKZv0AAAAJ&cstart=20&pagesize=80&citation_for_view=7TmKZv0AAAAJ:ML0RJ9NH7IQC,https://sites.google.com/site/saptarshighosh/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Two of the fundamental tasks in image understanding using text are caption generation and visual question answering (Antol et al., 2015; Xiong et al., 2016). This work presents an intermediate knowledge structure that can be used for both tasks to obtain increased interpretability. We call this knowledge structure Scene Description Graph (SDG), as it is a directed labeled graph, representing objects, actions, regions, as well as their attributes, along with inferred concepts and semantic (from KM-Ontology (Clark et al., 2004)), ontological (i.e. superclass, hasProperty), and spatial relations. Thereby a general architecture is proposed in which a system can represent both the content and underlying concepts of an image using an SDG. The architecture is implemented using generic visual recognition techniques and commonsense reasoning to extract graphs from images. The utility of the generated SDGs is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:P5F9QuxV20EC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Many vision and language tasks require commonsense reasoning beyond data-driven image and natural language processing. Here we adopt Visual Question Answering (VQA) as an example task, where a system is expected to answer a question in natural language about an image. Current state-of-the-art systems attempted to solve the task using deep neural architectures and achieved promising performance. However, the resulting systems are generally opaque and they struggle in understanding questions for which extra knowledge is required. In this paper, we present an explicit reasoning layer on top of a set of penultimate neural network based systems. The reasoning layer enables reasoning and answering questions where additional knowledge is required, and at the same time provides an interpretable interface to the end users. Specifically, the reasoning layer adopts a Probabilistic Soft Logic (PSL) based engine to reason over a basket of inputs: visual relations, the semantic parse of the question, and background ontological knowledge from word2vec and ConceptNet. Experimental analysis of the answers and the key evidential predicates generated on the VQA dataset validate our approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:CHSYGLWDkRkC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Deep learning based data-driven approaches have been successfully applied in various image understanding applications ranging from object recognition, semantic segmentation to visual question answering. However, the lack of knowledge integration as well as higher-level reasoning capabilities with the methods still pose a hindrance. In this work, we present a brief survey of a few representative reasoning mechanisms, knowledge integration methods and their corresponding image understanding applications developed by various groups of researchers, approaching the problem from a variety of angles. Furthermore, we discuss upon key efforts on integrating external knowledge with neural networks. Taking cues from these efforts, we conclude by discussing potential pathways to improve reasoning capabilities.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:SP6oXDckpogC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Pre-trained Transformer-based neural architectures have consistently achieved state-of-the-art performance in the Natural Language Inference (NLI) task. Since NLI examples encompass a variety of linguistic, logical, and reasoning phenomena, it remains unclear as to which specific concepts are learnt by the trained systems and where they can achieve strong generalization. To investigate this question, we propose a taxonomic hierarchy of categories that are relevant for the NLI task. We introduce TAXINLI, a new dataset, that has 10k examples from the MNLI dataset (Williams et al., 2018) with these taxonomic labels. Through various experiments on TAXINLI, we observe that whereas for certain taxonomic categories SOTA neural models have achieved near perfect accuracies - a large jump over the previous models - some categories still remain difficult. Our work adds to the growing body of literature that shows the gaps in the current NLI systems and datasets through a systematic presentation and analysis of reasoning categories.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:p2g8aNsByqUC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"For tasks involving language and vision, the current state-of-the-art methods tend not to leverage any additional information that might be present to gather relevant (commonsense) knowledge. A representative task is Visual Question Answering where large diagnostic datasets have been proposed to test a system's capability of answering questions about images. The training data is often accompanied by annotations of individual object properties and spatial locations. In this work, we take a step towards integrating this additional privileged information in the form of spatial knowledge to aid in visual reasoning. We propose a framework that combines recent advances in knowledge distillation (teacher-student framework), relational reasoning and probabilistic logical languages to incorporate such knowledge in existing neural networks for the task of Visual Question Answering. Specifically, for a question posed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:UxriW0iASnsC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"The uncertainty associated with human perception is often reduced by one’s extensive prior experience and knowledge. Current datasets and systems do not emphasize the necessity and benefit of using such knowledge. In this work, we propose the task of solving a genre of image-puzzles (“image riddles”) that require both capabilities involving visual detection (including object, activity recognition) and, knowledge-based or commonsense reasoning. Each puzzle involves a set of images and the question “what word connects these images?”. We compile a dataset of over 3k riddles where each riddle consists of 4 images and a groundtruth answer. The annotations are validated using crowd-sourced evaluation. We also define an automatic evaluation metric to track future progress. Our task bears similarity with the commonly known IQ tasks such as analogy solving, sequence filling that are often used to test intelligence. We develop a Probabilistic Reasoning-based approach that utilizes commonsense knowledge about words and phrases to answer these riddles with a reasonable accuracy. Our approach achieves some promising results for these riddles and provides a strong baseline for future attempts. We make the entire dataset and related materials publicly available to the community (bit. ly/22f9Ala).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:KxtntwgDAa4C,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"The recent state-of-the-art natural language understanding (NLU) systems often behave unpredictably, failing on simpler reasoning examples. Despite this, there has been limited focus on quantifying progress towards systems with more predictable behavior. We think that reasoning capability-wise behavioral summary is a step towards bridging this gap. We create a CheckList test-suite (184K examples) for the Natural Language Inference (NLI) task, a representative NLU task. We benchmark state-of-the-art NLI systems on this test-suite, which reveals fine-grained insights into the reasoning abilities of BERT and RoBERTa. Our analysis further reveals inconsistencies of the models on examples derived from the same template or distinct templates but pertaining to same reasoning capability, indicating that generalizing the models' behavior through observations made on a CheckList is non-trivial. Through an user-study, we find that users were able to utilize behavioral information to generalize much better for examples predicted from RoBERTa, compared to that of BERT.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:tS2w5q8j5-wC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Pre-trained multilingual language models are gaining popularity due to their cross-lingual zero-shot transfer ability, but these models do not perform equally well in all languages. Evaluating task-specific performance of a model in a large number of languages is often a challenge due to lack of labeled data, as is targeting improvements in low performing languages through few-shot learning. We present a tool-LITMUS Predictor-that can make reliable performance projections for a fine-tuned task-specific model in a set of languages without test and training data, and help strategize data labeling efforts to optimize performance and fairness objectives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:4fKUyHm3Qg0C,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Multilingual language models achieve impressive zero-shot accuracies in many languages in complex tasks such as Natural Language Inference (NLI). Examples in NLI (and equivalent complex tasks) often pertain to various types of sub-tasks, requiring different kinds of reasoning. Certain types of reasoning have proven to be more difficult to learn in a monolingual context, and in the crosslingual context, similar observations may shed light on zero-shot transfer efficiency and few-shot sample selection. Hence, to investigate the effects of types of reasoning on transfer performance, we propose a category-annotated multilingual NLI dataset and discuss the challenges to scale monolingual annotations to multiple languages. We statistically observe interesting effects that the confluence of reasoning types and language similarities have on transfer performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:tOudhMTPpwUC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Symbolic Mathematical tasks such as integration often require multiple well-defined steps and understanding of sub-tasks to reach a solution. To understand Transformers' abilities in such tasks in a fine-grained manner, we deviate from traditional end-to-end settings, and explore a step-wise polynomial simplification task. Polynomials can be written in a simple normal form as a sum of monomials which are ordered in a lexicographic order. For a polynomial which is not necessarily in this normal form, a sequence of simplification steps is applied to reach the fully simplified (i.e., in the normal form) polynomial. We propose a synthetic Polynomial dataset generation algorithm that generates polynomials with unique proof steps. Through varying coefficient configurations, input representation, proof granularity, and extensive hyper-parameter tuning, we observe that Transformers consistently struggle with numeric multiplication. We explore two ways to mitigate this: Curriculum Learning and a Symbolic Calculator approach (where the numeric operations are offloaded to a calculator). Both approaches provide significant gains over the vanilla Transformers-based baseline.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:u9iWguZQMMsC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Natural Language Inference (NLI) is considered a representative task to test natural language understanding (NLU). In this work, we propose an extensible framework to collectively yet categorically test diverse Logical reasoning capabilities required for NLI (and by extension, NLU). Motivated by behavioral testing, we create a semi-synthetic large test-bench (363 templates, 363k examples) and an associated framework that offers following utilities: 1) individually test and analyze reasoning capabilities along 17 reasoning dimensions (including pragmatic reasoning), 2) design experiments to study cross-capability information content (leave one out or bring one in); and 3) the synthetic nature enable us to control for artifacts and biases. The inherited power of automated test case instantiation from free-form natural language templates (using CheckList), and a well-defined taxonomy of capabilities enable us to extend to (cognitively) harder test cases while varying the complexity of natural language. Through our analysis of state-of-the-art NLI systems, we observe that our benchmark is indeed hard (and non-trivial even with training on additional resources). Some capabilities stand out as harder. Further fine-grained analysis and fine-tuning experiments reveal more insights about these capabilities and the models -- supporting and extending previous observations. Towards the end we also perform an user-study, to investigate whether behavioral information can be utilised to generalize much better for some models compared to others.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:vRqMK49ujn8C,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"In some embodiments, a knowledge graph generation system extracts noun-phrases from sentences of a knowledge corpora and determines the relations between the noun-phrases based on a relation classifier that is configured to predict a relation between a pair of entities without restricting the entities to a set of named entities. The knowledge graph generation system further generates a sub-graph for each of the sentences based on the noun-phrases and the determined relations. Nodes or entities of the sub-graph represent the non-phrases in the sentence and edges represent the relations between the noun-phrases connected by the respective edges. The knowledge graph generation system merges the sub-graphs to generate the knowledge graph for the knowledge corpora.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:XiSMed-E-HIC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Online behaviors of consumers and marketers generate massive marketing data, which ever more sophisticated models attempt to turn into insights and aid decisions by marketers. Yet, in making decisions human managers bring to bear marketing knowledge which reside outside of data and models. Thus, it behooves creation of an automated marketing knowledge base that can interact with data and models. Currently, marketing knowledge is dispersed in large corpora, but no definitive knowledge base for marketing exists. Out of the two broad aspects of marketing knowledge - representation and reasoning - this treatise focuses on the former. Specifically, we focus on creation of marketing knowledge graph from corpora, which requires identification of entities and relations. The relation identification task is particularly challenging in marketing, because of the non-factoid nature of much marketing knowledge, and the difficulty of forming rules that govern relations. Specifically, we define a set of relations to capture marketing knowledge, propose a pipeline for creating the knowledge graph from text and propose a rule-guided semi-supervised relation prediction algorithm to extract relations between marketing entities from sentences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&citation_for_view=2shiHpwAAAAJ:uWQEDVKXjbEC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Topic-sensitive query set expansion is an important area of research that aims to improve search results for information retrieval. It is particularly crucial for queries related to sensitive and emerging topics. In this work, we describe a method for query set expansion about emerging topics using vector space interpolation. We use a transformer model called OPTIMUS, which is suitable for vector space manipulation due to its variational autoencoder nature. One of our proposed methods–Dirichlet interpolation shows promising results for query expansion. Our methods effectively generate new queries about the sensitive topic by incorporating set-level diversity, which is not captured by traditional sentence-level augmentation methods such as paraphrasing or back-translation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&cstart=20&pagesize=80&citation_for_view=2shiHpwAAAAJ:8AbLer7MMksC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Multilingual evaluation benchmarks usually contain limited high-resource languages and do not test models for specific linguistic capabilities. CheckList is a template-based evaluation approach that tests models for specific capabilities. The CheckList template creation process requires native speakers, posing a challenge in scaling to hundreds of languages. In this work, we explore multiple approaches to generate Multilingual CheckLists. We device an algorithm–Template Extraction Algorithm (TEA) for automatically extracting target language CheckList templates from machine translated instances of a source language templates. We compare the TEA CheckLists with CheckLists created with different levels of human intervention. We further introduce metrics along the dimensions of cost, diversity, utility, and correctness to compare the CheckLists. We thoroughly analyze different approaches to creating CheckLists in Hindi. Furthermore, we experiment with 9 more different languages. We find that TEA followed by human verification is ideal for scaling Checklist-based evaluation to multiple languages while TEA gives a good estimates of model performance. We release the code of TEA and the CheckLists created at aka. ms/multilingualchecklist",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&cstart=20&pagesize=80&citation_for_view=2shiHpwAAAAJ:geHnlv5EZngC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Systems and methods for natural language processing (NLP) are described. The systems may be trained by identifying training data including clean data and noisy data; predicting annotation information using an artificial neural network (ANN); computing a loss value for the annotation information using a weighted loss function that applies a first weight to the clean data and at least one second weight to the noisy data; and updating the ANN based on the loss value. The noisy data may be obtained by identifying a set of unannotated sentences in a target domain, delexicalizing the set of unannotated sentences, finding similar sentences in a source domain, filling at least one arbitrary value in the similar delexicalized sentences, generating annotation information for the similar delexicalized sentences using an annotation model for the source domain, and applying a heuristic mapping to produce annotation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&cstart=20&pagesize=80&citation_for_view=2shiHpwAAAAJ:738O_yMBCRsC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"The Natural Language Inference (NLI) task often requires reasoning over multiple steps to reach the conclusion. While the necessity of generating such intermediate steps (instead of a summary explanation) has gained popular support, it is unclear how to generate such steps without complete end-to-end supervision and how such generated steps can be further utilized. In this work, we train a sequence-to-sequence model to generate only the next step given an NLI premise and hypothesis pair (and previous steps); then enhance it with external knowledge and symbolic search to generate intermediate steps with only next-step supervision. We show the correctness of such generated steps through automated and human verification. Furthermore, we show that such generated steps can help improve end-to-end NLI task performance using simple data augmentation strategies, across multiple public NLI datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&cstart=20&pagesize=80&citation_for_view=2shiHpwAAAAJ:sSrBHYA8nusC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Efficient code snippet search using natural language queries can be a great productivity tool for developers (beginners and professionals alike). Recently neural code search has been popular, where a neural method is used to embed both the query (NL) and the code snippet (PL) into a common representation space; which is further used to obtain the most relevant PL satisfying the intent in the query. Transformers-based pre-trained language models (such as CodeBERT, GraphCodeBERT, UniXCoder) have been especially effective to learn such representation. These models often make mistakes such as retrieving snippets with incorrect data types, and incorrect method names or signatures; even when exposed to the underlying structural information of the code (such as Abstract Syntax Tree and other static analysis outputs) during pre-training. The generalization ability beyond the training data is also limited (as the code retrieval datasets vary in the ways NL-PL pairs are collected). In this work, we propose a structure-aware hard negative sampling method and a mastering-rate based curriculum learning technique (SYNC) that enhances the pre-trained representation using both soft (random) and the (synthesized) hard negative samples. Our experiments on three state-of-the-art pre-trained language models for programming languages, over four Python code retrieval datasets, show the efficacy of the approach (under both in-distribution and out-of-distribution settings).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&cstart=20&pagesize=80&citation_for_view=2shiHpwAAAAJ:5Ul4iDaHHb8C,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Deep learning (DL) has made rapid progress in the last decade, with neural network-based language and vision models achieving state-of-the-art performance in various tasks. Yet purely data-driven neural network models exhibit several issues impacting real-world deployment of such models adversely. These include reliance on large quantities of training data, poor robustness, lack of generalization, poor explainability, and glaring gaps in implicit and commonsense knowledge. The availability of rich structured (or semi-structured) knowledge sources has spurred the research community into exploring Knowledge Injection in Neural Networks (KINN) as a means of mitigating the above-mentioned challenges. This has led to the development of hybrid AI systems that combine the purely data-driven learning of the neural network models with an infusion of knowledge from external sources. Such KINN systems …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&cstart=20&pagesize=80&citation_for_view=2shiHpwAAAAJ:l7t_Zn2s7bgC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Navigating a collection of documents can be facilitated by obtaining a human-understandable concept hierarchy with links to the content. This is a non-trivial task for two reasons. First, defining concepts that are understandable by an average consumer and yet meaningful for a large variety of corpora is hard. Second, creating semantically meaningful yet intuitive hierarchical representation is hard, and can be task dependent. We present out system Navigation. ai which automatically processes a document collection, induces a concept hierarchy using Wikipedia and presents an interactive interface that helps user navigate to individual paragraphs using concepts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&cstart=20&pagesize=80&citation_for_view=2shiHpwAAAAJ:OU6Ihb5iCvQC,https://adityasomak.github.io/
Somak Aditya,"['Knowledge Representation', 'Commonsense Reasoning', 'Natural Language Processing', 'Natural Language Understanding', 'Visual Reasoning']",11,"Image Understanding is a long-established discipline in computer vision, which encompasses a body of advanced image processing techniques, that are used to locate ("" where""), characterize and recognize ("" what"") objects, regions, and their attributes in the image. However, the notion of"" understanding""(and the goal of artificial intelligent machines) goes beyond factual recall of the recognized components and includes reasoning and thinking beyond what can be seen (or perceived).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2shiHpwAAAAJ&cstart=20&pagesize=80&citation_for_view=2shiHpwAAAAJ:dshw04ExmUIC,https://adityasomak.github.io/
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"With advancements in technology, the automotive industry is experiencing a paradigm shift from assisted driving to highly automated driving. However, autonomous driving systems are highly safety critical in nature and need to be thoroughly tested for a diverse set of conditions before being commercially deployed. Due to the huge complexities involved with Advanced Driver Assistance Systems (ADAS) and Automated Driving Systems (ADS), traditional software testing methods have well-known limitations. They also fail to cover the infinite number of adverse conditions that can occur due to a slight change in the interactions between the environment and the system. Hence, it is important to identify test conditions that push the vehicle under test to breach its safe boundaries. Hazard Based Testing (HBT) methods, inspired by Systems-Theoretic Process Analysis (STPA), identify such parameterized test conditions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&citation_for_view=Pw4jS9sAAAAJ:48xauSegjOkC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"Malicious exploitation of faults for extracting secrets is one of the most practical and potent threats to modern cryptographic primitives. Interestingly, not every possible fault for a cryptosystem is maliciously exploitable, and evaluation of the exploitability of a fault is nontrivial. In order to devise precise defense mechanisms against such rogue faults, a comprehensive knowledge is required about the exploitable part of the fault space of a cryptosystem. Unfortunately, the fault space is diversified and of formidable size even while a single crypto-primitive is considered and traditional manual fault analysis techniques may often fall short to practically cover such a fault space within reasonable time. An automation for analyzing individual fault instances for their exploitability is thus inevitable. Such an automation is supposed to work as the core engine for analyzing the fault spaces of cryptographic primitives. In this paper, we propose an automation for evaluating the exploitability status of fault instances from block ciphers, mainly in the context of Differential Fault Analysis (DFA) attacks. The proposed framework is generic and scalable, which are perhaps the two most important features for covering diversified fault spaces of formidable size originating from different ciphers. As a proof-of-concept, we reconstruct some known attack examples on AES and PRESENT using the framework and finally analyze a recently proposed cipher GIFT [BPP+ 17] for the first time. It is found that the secret key of GIFT can be determined with 2 nibble fault instances injected consecutively at the beginning of the 25th and 23rd round with remaining key space complexity of 2^ 7.06.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&citation_for_view=Pw4jS9sAAAAJ:8xutWZnSdmoC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"Characterizing the fault space of a cipher to filter out a set of faults potentially exploitable for fault attacks (FA), is a problem with immense practical value. A quantitative knowledge of the exploitable fault space is desirable in several applications, such as security evaluation, cipher construction and implementation, design, testing of countermeasures, and so on. In this paper, we investigate this problem in the context of block ciphers. The formidable size of the fault space of a block cipher mandates the use of an automation strategy to solve this problem, which should be able to characterize each individual fault instance quickly. On the other hand, the automation strategy is expected to be applicable to most of the block cipher constructions. Existing techniques for automated fault attacks do not satisfy both of these goals simultaneously, and hence are not directly applicable in the context of exploitable fault …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:Ehil0879vHcC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"Recent advances in Reinforcement Learning (RL) combined with Deep Learning (DL) have demonstrated impressive performance in complex tasks, including autonomous driving. The use of RL agents in autonomous driving leads to a smooth human-like driving experience, but the limited interpretability of Deep Reinforcement Learning (DRL) creates a verification and certification bottleneck. Instead of relying on RL agents to learn complex tasks, we propose HPRL - Hierarchical Program-triggered Reinforcement Learning, which uses a hierarchy consisting of a structured program along with multiple RL agents, each trained to perform a relatively simple task. The focus of verification shifts to the master program under simple guarantees from the RL agents, leading to a significantly more interpretable and verifiable implementation as compared to a complex RL agent. The evaluation of the framework is demonstrated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:jFemdcug13IC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"A systematic investigation on the structural and magnetic properties of an Fe-doped MnNiGe alloy with nominal composition MnNi 0.75 Fe 0.25 Ge has been performed. Temperature dependent x-ray diffraction studies indicate a clear structural phase transition (martensitic type) from the high temperature hexagonal austenite phase (space group P6 3/mmc) to the low temperature orthorhombic martensite phase (space group Pnma). Interestingly, about 1.4% of the high temperature hexagonal phase has been observed at 15 K, which is well below the martensitic phase transition (MPT) temperature. The studied alloy is found to be ferromagnetic in nature at the lowest temperature of measurement and the saturation moment increases in the presence of external hydrostatic pressure (P). In addition, it shows a significantly large conventional (negative) magnetocaloric effect with an adiabatic entropy change () of about …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:prdVHNxh-e8C,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"Heating ventilation and air conditioning (HVAC) systems usually account for the highest percentage of overall energy usage in large-sized smart building infrastructures. The performance of HVAC control systems for large buildings strongly depend on the outside environment, building architecture, and (thermal) zone usage pattern of the building. In large buildings, HVAC system with multiple air handling units (AHUs) is required to fulfill the cooling/heating requirements.
In the present work, we propose an energy-aware building resource allocation and economic model predictive control (eMPC) framework for multi-AHU-based HVAC system. The energy consumption of a multi-AHU-based HVAC system significantly depends on how long the AHUs are running, which again is governed by the zone usage demands. Our approach comprises a two-step hierarchical technique where we first minimize the running time of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:WHdLCjDvYFkC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"Redundancy based countermeasures against fault attacks are a popular choice in security-critical commercial products, owing to its high fault coverage and applications to safety/reliability. In this paper, we propose a combined attack on such countermeasures. The attack assumes a random byte/nibble fault model with existence of side-channel leakage of the final comparison, and no knowledge of the faulty ciphertext. Unlike the previously proposed biased/multiple fault attack, we just need to corrupt one computation branch. Both analytical and experimental evaluation of this attack strategy is presented on software implementations of two state-of-the-art block ciphers, AES and PRESENT, on an ATmega328P microcontroller, via side-channel measurements and a laser-based fault injection. Moreover, this work establishes that even without the knowledge of the faulty ciphertexts, one can still perform differential fault …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:gKiMpY-AVTkC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"Accurate prediction of solar irradiance is difficult because of the uncertainties in weather parameters. In this paper we present a forecasting model for solar irradiance based on historical data analysis and meteorological features, with the help of deep neural networks. A unique feature of the method is the use of historical trends of solar irradiance, which significantly improves the accuracy of our prediction model. We have validated the performance of our model using the data obtained from National Solar Radiation Database (NSRDB). As an application, the forecasted irradiance values are used to predict the power output of a photovoltaic (PV) plant set up in Kharagpur, India, within a low margin of error.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:Bg7qf7VwUHIC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"Detailed structural and magnetic investigations have been performed on two equally Fe-doped MnCoGe alloys of nominal compositions MnFeCoGe and MnCoFeGe. The presence of martensitic phase transition (MPT) in both alloys is clear from the temperature variation of structural and magnetic properties. The nature of MPT is found to be complete in the Mn site Fe-doped alloy. On the other hand, a partial nature of the MPT is observed for the Co site Fe-doped alloy. The application of external hydrostatic pressure hardly affects the magnetic and structural transition temperatures. Both alloys show a significant amount of the magnetocaloric effect in ambient as well as in high pressure situation around their magnetic and structural transition regions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:L1USKYWJimsC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"The traditional body of literature on analog testing deals with propagation of faults to the output nets of the circuit. Often the set of detectable faults remains unsatisfactory because suitable stimuli cannot be found for propagating certain faults to the output. Existing technology supports capturing of the state of internal nets of a circuit, thereby enhancing the scope of detecting faults by observing their effect on internal nets. This approach is feasible only if the number of internal nets probed by the built-in test structure is very few. This paper presents a structured approach that identifies the sensitive nets, namely a well chosen small subset of internal nets that are affected by these faults. We utilize the speed of DC analysis and some common behavioral aspects of analog signals to find out this subset. We report dramatic improvement in fault coverage on several circuits including benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:ALROH1vI_8AC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,"Assessment of the security provided by a fault attack countermeasure is challenging, given that a protected cipher may leak the key if the countermeasure is not designed correctly. This paper proposes, for the first time, a statistical framework to detect information leakage in fault attack countermeasures. Based on the concept of non-interference, we formalize the leakage for fault attacks and provide a t-test based methodology for leakage assessment. One major strength of the proposed framework is that leakage can be detected without the complete knowledge of the countermeasure algorithm, solely by observing the faulty ciphertext distributions. Experimental evaluation over a representative set of countermeasures establishes the efficacy of the proposed methodology.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:wMgC3FpKEyYC,http://cse.iitkgp.ac.in/~pallab
Pallab Dasgupta,"['Formal Methods', 'Design Automation', 'Artificial Intelligence']",20,In current practice a formal analysis of hybrid system models is assertion-based. The work presented here is based on features that look beyond functional correctness toward a quantitative evaluation of behavioral attributes. A feature defines a real-valued evaluation function over a specific set of traces. This paper describes an improved method for the interpretation of features over hybrid automata models. It further demonstrates how satisfiability modulo theory solvers can be used for extracting behavioral traces corresponding to corner cases of a feature. Results are demonstrated on examples from the control and circuit domains.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Pw4jS9sAAAAJ&cstart=20&pagesize=80&citation_for_view=Pw4jS9sAAAAJ:tH6gc1N1XXoC,http://cse.iitkgp.ac.in/~pallab
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"In the energy sector, IoT manifests in the form of next-generation power grids that provide enhanced electrical stability, efficient power distribution, and utilization. The primary feature of a Smart Grid is the presence of an advanced bi-directional communication network between the Smart meters at the consumer end and the servers at the Utility Operators. Smart meters are broadly vulnerable to attacks on communication and physical systems. We propose a secure and operationally asymmetric mutual authentication and key-exchange protocol for secure communication. Our protocol balances security and efficiency, delegates complex cryptographic operations to the resource-equipped servers, and carefully manages the workload on the resource-constrained Smart meter nodes using unconventional lightweight primitives such as Physically Unclonable Functions. We prove the security of the protocol using well …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:ldfaerwXgEUC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Modern electronic systems become evermore complex, yet remain modular, with integrated circuits (ICs) acting as versatile hardware components at their heart. Electronic design automation (EDA) for ICs has focused traditionally on power, performance, and area. However, given the rise of hardware-centric security threats, we believe that EDA must also adopt related notions like secure by design and secure composition of hardware. Despite various promising studies, we argue that some aspects still require more efforts, for example: effective means for compilation of assumptions and constraints for security schemes, all the way from the system level down to the ""bare metal""; modeling, evaluation, and consideration of security-relevant metrics; or automated and holistic synthesis of various countermeasures, without inducing negative cross-effects.In this paper, we first introduce hardware security for the EDA …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:ns9cj8rnVeAC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"For many embedded systems, such as automotive electronic systems, security has become a pressing challenge. Limited resources and tight timing constraints often make it difficult to apply even lightweight authentication and intrusion detection schemes, especially when retrofitting existing designs. Moreover, traditional hard deadline assumption is insufficient to describe control tasks that have certain degrees of robustness and can tolerate some deadline misses while satisfying functional properties such as stability. In this work, we explore feasible weakly-hard constraints on control tasks, and then leverage the scheduling flexibility from those allowed misses to enhance system's capability for accommodating security monitoring tasks. We develop a co-design approach that 1) sets feasible weakly-hard constraints on control tasks based on quantitative analysis, ensuring the satisfaction of control stability and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:M05iB0D1s5AC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Heating ventilation and air conditioning (HVAC) systems usually account for the highest percentage of overall energy usage in large-sized smart building infrastructures. The performance of HVAC control systems for large buildings strongly depend on the outside environment, building architecture, and (thermal) zone usage pattern of the building. In large buildings, HVAC system with multiple air handling units (AHUs) is required to fulfill the cooling/heating requirements.
In the present work, we propose an energy-aware building resource allocation and economic model predictive control (eMPC) framework for multi-AHU-based HVAC system. The energy consumption of a multi-AHU-based HVAC system significantly depends on how long the AHUs are running, which again is governed by the zone usage demands. Our approach comprises a two-step hierarchical technique where we first minimize the running time of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:HoB7MX3m0LUC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"We consider the problem of securing a given control loop implementation of a cyber-physical system (CPS) in the presence of Man-in-the-Middle attacks on data exchange between plant and controller over a compromised network. To this end, there exists various detection schemes which provide mathemat¬ical guarantees against such attacks for the theoretical control model. However, such guarantees may not hold for the actual control software implementation. In this article, we propose a formal approach towards synthesizing attack detectors with varying thresholds which can prevent performance degrading stealthy attacks while minimizing false alarms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:RYcK_YlVTxYC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"We consider the problem of provably securing a given control loop implementation in the presence of adversarial interventions on data exchange between plant and controller. Such interventions can be thwarted using continuously operating monitoring systems and also cryptographic techniques, both of which consume network and computational resources. We provide a principled approach for intentional skipping of control loop executions which may qualify as a useful control-theoretic countermeasure against stealthy attacks which violate message integrity and authenticity. As can be seen, such an approach helps in lowering the resource consumption caused by monitoring/cryptographic security measures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:zA6iFVUQeVQC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Given the widespread deployment of cyber-physical systems and their safety-critical nature, reliability and security guarantees offered by such systems are of paramount importance. While the security of such systems against sensor attacks have garnered significant attention from researchers in recent times, improving the reliability of a control software implementation against transient environmental disturbances need to be investigated further. Scalable formal methods for verification of actual control performance guarantee offered by software implementations of control laws in the face of sensory faults have been explored in recent work [20]. However, the formal verification of the improvement of system reliability by incorporating sensor fault mitigation techniques like Kalman filtering [29] and sensor fusion [18, 52] remains to be explored. Moreover, system designers face complex tradeoff choices for deciding upon …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:pqnbT2bcN3wC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Modern-day heterogeneous embedded computing platforms integrate processing elements (PE) with varying compute capabilities on the same die. While such platforms help in delivering high-throughput computation with low power budgets, it also exposes the possibility of violating the thermal envelope. Sustained thermal envelope violation degrades the reliability of the PEs. This work presents an OpenCL run-time extension which adaptively tunes parameters of heterogeneous multicores in order to respect a given temperature constraint without violating real-time deadlines. The feedback-oriented iterative behavior of the proposed run-time extension helps in cancelling out core-level temperature constraint violations which may happen due to dynamic task injection in plug-n-play embedded computing platforms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:NaGl4SEjCO4C,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Recent trends in real-time applications have raised the demand for high-throughput embedded platforms with integrated CPU-GPU based Systems-On-Chip (SoCs). The enhanced performance of such SoCs, however, comes at the cost of increased power consumption, resulting in significant heat dissipation and high on-chip temperatures. The prolonged occurrences of high on-chip temperature can cause accelerated in-circuit ageing, which severely degrades the long-term performance and reliability of the chip. Violation of thermal constraints leads to on-board dynamic thermal management kicking-in, which may result in timing unpredictability for real-time tasks due to transient performance degradation. Recent work in adaptive software design have explored this issue from a control theoretic stand-point, striving for smooth thermal envelopes by tuning the core frequency.
Existing techniques do not handle …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:1sJd4Hv_s6UC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Vehicular ad-hoc networks (VANET) are often assumed in cooperative driving scenarios, such as vehicle platooning, in order to achieve better control quality and enhanced autonomy. The increased connectivity and software programmability required for this features exposes new attack surfaces, escalating vehicular security risks and potentially compromising the safety of road users. Given the safety critical nature of such applications, the ability to verify the authenticity and integrity of the communicated data as well as to detect malicious driving behaviors is of paramount importance. In practice, such assurances are hard to derive since carefully crafted stealthy attack signals aimed at violating safety properties, e.g. safe inter-vehicle distance, are difficult to distinguish from normal operation if only data from on-board sensors is used by the detection system. To cope with the problem of detecting stealthy attacks on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&citation_for_view=XJI3nYIAAAAJ:a0OBvERweLwC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Delivering driving comfort in this age of connected mobility is one of the primary goals of semi-autonomous perception systems increasingly being used in modern automotives. The performance of such perception systems is a function of execution rate which demands on-board platform-level support. With the advent of GPGPU compute support in automobiles, there exists an opportunity to adaptively enable higher execution rates for such Advanced Driver Assistant System tasks (ADAS tasks) subject to different vehicular driving contexts. This can be achieved through a combination of program level locality optimizations such as kernel fusion, thread coarsening and core-level DVFS techniques while keeping in mind their effects on task-level deadline requirements and platform-level thermal reliability. In this communication, we present a future-proof, learning-based adaptive scheduling framework that strives to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:P5F9QuxV20EC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"This contribution introduces the notion of cyber-physical systems (CPSs) and presents the questions which the corresponding Special Issue on CPS Education is trying to answer. For this special issue, it provides an overview of the article selection process and the finally selected papers. -Peter Marwedel, TU Dortmund.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:dfsIfKJdRG4C,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Executing a set of control loops over a shared multi-hop (wireless) control network (MCN) requires careful co-scheduling of the control tasks and the routing of sensory/actuation messages over the MCN. In this work, we establish pattern guided aperiodic execution of control loops as a resource-aware alternative to traditional fully periodic executions of a set of embedded control loops sharing a computation and the communication infrastructure. We provide a satisfiability modulo theory–based co-design framework that synthesizes loop execution patterns having optimized control cost as the underlying scheduling scheme together with the associated routing solution over the MCN. The routing solution implements the timed movement of the sensory/actuation messages of the control loops, generated according to those loop execution patterns. From the given settling time requirement of the control loops, we compute …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:RGFaLdJalmkC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"This letter summarizes the established vulnerability analysis techniques for cyber physical control software and highlights the possibility of employing lightweight security measures in conjunction with reachability analysis for such systems. We propose a possible cyber physical control system implementation methodology, which leverages the dependence of control performance on the choice of security measure adopted and the resulting platform level vulnerability.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:_Qo2XoVZTnwC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"With the emerging migration of automotive and other distributed control platforms from federated to integrated architectures, the need for optimal utilization of ECU (electronic control unit) bandwidth will become a key requirement in the implementation of embedded control features. This paper advocates the partitioning of the operating space of the plant and the use of minimal sampling rates in each partition without compromising the overall quality of control. At the heart of the proposed methodology are our algorithms that enable the choice of the partitions and the sampling rate for each partition. We demonstrate the efficacy of our methods on two case studies, namely an anti-lock braking system and a lane departure warning system. We also study the use of a supervisory controller that controls the switching among sampling rates for a combination of the two features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:M3NEmzRMIkIC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"In recent years, the transitioning of conventional power grid system into the smart grid infrastructure has made the power distribution network more susceptible towards faults and physical attacks. In this context, we discuss recently proposed Manipulation-of-Demand via IoT attack, False Data Injection Attacks and Electric Fault Attacks. These attacks directly or indirectly can lead to localized blackout, falsified load forecasting, imbalance in demand-response system, generator tripping, frequency instability and loss of equipment etc. To detect and trace back to the source of such attacks, in this paper we inspect the potential of the promising permissioned blockchain technology which is designed for digital transaction, but has been extended to authenticate and assure integrity of real power consumption information in a seem-less manner. This information can be picked up from the smart meters, however the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:dshw04ExmUIC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Embedded control systems are prevalent in a multitude of domains such as automotive, avionics, industrial control etc. For such systems, robustness against non‐idealities of the compute platform created by situations such as hardware level transient faults (memory errors, sensor reading errors), network packet drops, late arrival of messages etc., is needed to be ensured at the design level. In traditional regular periodic execution of control loops, such guarantees are obtained by oversampling the plant, which requires extra rounds of sensing, control law computation, and actuation. One possible measure for reducing such over‐provisioning of computing and communication resources is allowing occasional drops in the execution leading to better resource management as well as energy efficiency. This work showcases a methodology for deriving window‐based bounds on possible drops in control loop executions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:GnPB-g6toBAC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Smart metering is a mechanism through which fine-grained electricity usage data of consumers is collected periodically in a smart grid. However, a growing concern in this regard is that the leakage of consumers' consumption data may reveal their daily life patterns as the state-of-the-art metering strategies lack adequate security and privacy measures. Many proposed solutions have demonstrated how the aggregated metering information can be transformed to obscure individual consumption patterns without affecting the intended semantics of smart grid operations. In this paper, we expose a complete break of such an existing privacy preserving metering scheme [10] by determining individual consumption patterns efficiently, thus compromising its privacy guarantees. The underlying methodol-ogy of this scheme allows us to - i) retrieve the lower bounds of the privacy parameters and ii) establish a relationship …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:bnK-pcrLprsC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Deep Reinforcement Learning (DRL) has been successfully applied to learn policies for safety-critical systems with unknown model dynamics in simulation. DRL controllers though optimal in terms of reward, do not provide any safety and stability guarantees. With reliance on model information, safety conditions can be expressed as Control Barrier Functions (CBFs) and performance objectives can be expressed as Control Lyapunov Functions (CLFs) for real-time optimization-based controllers. In this work, we use an amalgamation of model-free RL and model-based controllers to establish safety and stability. We first design CLF, CBF Quadratic Programs (QPs) for different driving manoeuvres on nominal vehicle dynamics. Reinforcement Learning (RL) agents are trained to learn policies for the actual vehicle with enhanced dynamics. In order to incorporate safety and stability while retaining optimal behaviour we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:LPZeul_q3PIC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Thermal efficient resource mapping and scheduling techniques are particularly important for mobile processors because of limited opportunities for external cooling. In mobile processors such as the ones using ARM's big.LITTLE architectures, the cores of either the big or the LITTLE processor cannot be individually voltage/frequency scaled. However, we show that by forcing all the application threads to a single core, and not having any workload on the other cores of a processor, there is still considerable thermal benefit. This is counterintuitive since all the cores run at the same frequency. We show real measurements and discuss what impact this has on thermal-aware scheduling for such multicore processors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:SP6oXDckpogC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"In the past decade, high performance compute capabilities exhibited by heterogeneous GPGPU platforms have led to the popularity of data parallel programming languages such as CUDA and OpenCL. Developing high performance parallel programming solutions using such languages involve a steep learning curve due to the complexity of the underlying heterogeneous compute devices and their impact on performance. This has led to the emergence of several High Performance Computing frameworks which provide high-level abstractions for easing the development of data-parallel applications on heterogeneous platforms. However, the scheduling decisions undertaken by such frameworks only exploit coarse-grained concurrency in data parallel applications. In this paper, we propose PySchedCL, a framework which explores fine-grained concurrency aware scheduling decisions that harness the power of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:cFHS6HbyZ2cC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Building loads consume roughly 40% of the energy produced in developed countries, a significant part of which is invested towards building temperature-control infrastructure. Therein, renewable resource-based microgrids offer a greener and cheaper alternative. This communication explores the possible co-design of microgrid power dispatch and building HVAC (heating, ventilation and air conditioning system) actuations with the objective of effective temperature control under minimised operating cost. For this, we attempt control designs with various levels of abstractions based on information available about microgrid and HVAC system models using the Deep Reinforcement Learning (DRL) technique. We provide control architectures that consider model information ranging from completely determined system models to systems with fully unknown parameter settings and illustrate the advantages of DRL for the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:KxtntwgDAa4C,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"While wired networks provide a reliable platform for networked cyber-physical systems (CPS), there is an increasing demand for CPS built upon wireless networks. However, wireless connectivity also implies varying and unpredictable end-to-end delays due to packet loss, interference by concurrently transmitting nodes or the necessity to forward packets via one or many intermediate nodes. This is typically accounted for by designing controllers for the worst-case end-to-end delay. This guarantees stability also when the largest possible delay occurs. However, the delays observed during normal operation are significantly below the worst-case. As a result of the overly pessimistic controller design, the control performance becomes unnecessarily low. In this work, for the first time, we present a generic technique to handle varying end-to-end delays in wireless CPS.
While maintaining a stable operation, our technique …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:D03iK_w7-QYC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Increased dependence on networked, software based control has escalated the vulnerabilities of Cyber Physical Systems (CPSs). Detection and monitoring components developed leveraging dynamical systems theory are often employed as lightweight security measures for protecting such safety critical CPSs against false data injection attacks. However, existing approaches do not correlate attack scenarios with parameters of detection systems. In the present work, we propose a Reinforcement Learning (RL) based framework which adaptively sets the parameters of such detectors based on experience learned from attack scenarios, maximizing detection rate and minimizing false alarms in the process while attempting performance preserving control actions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:abG-DnoFyZgC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Given that building loads consume roughly 40% of the energy produced in developed countries, smart buildings with local renewable resources offer a viable alternative towards achieving a greener future. Building temperature control strategies typically employ detailed physical models which require a significant amount of time, information and finesse. Even then, due to unknown building parameters and related inaccuracies, future power demands by the building loads are difficult to estimate. This creates unique challenges in the domain of microgrid economic power dispatch for satisfying building power demands through efficient control and scheduling of renewable and non-renewable local resources in conjunction with supply from the main grid. In this work, we estimate the real-time uncertainties in building loads using Gaussian Process (GP) learning and establish the effectiveness of run time model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:nb7KW1ujOQ8C,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"A large fraction of bugs discovered in the design flow of embedded control software (ECS) arises from the control software's interaction with the plant it controls. Traditional formal analysis approaches using interleaved controller-plant reach-set analysis grossly overapproximate the reachable states and does not scale. In this letter, we examine a verification approach that considers a control system with the (possibly nonlinear) plant dynamics and mode switches specified along with the actual control software implementation. Given this input, we generate a bounded-time safety verification problem encoded as satisfiability modulo theories (SMTs) constraints. We leverage δ-decidability over Reals to achieve scalability while verifying the control software.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:yD5IFk8b50cC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Bug traces serve as references for patching a microprocessor design after a bug has been found. Unless the root cause of a bug has been detected and patched, variants of the bug may return through alternative bug traces, following a different sequence of micro‐architectural events. To avoid such a situation, the verification engineer must think of every possible way in which the bug may return, which is a complex problem for a modern microprocessor. This study proposes a methodology which gleans high‐level descriptions of the micro‐architectural steps and uses them in an artificial Intelligence planning framework to find alternative pathways through which a bug may return. The plans are then translated to simulation test cases which explore these potential bug scenarios. The planning tool essentially automates the task of the verification engineer towards exploring possible alternative sequences of micro …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:fPk4N6BV_jEC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"The increasing demand for mapping diverse embedded features onto shared electronic control units has brought about novel ways to co-design control tasks and their schedules. These techniques replace traditional implementations of control with new methods, such as pattern-based scheduling of control tasks and adaptive sharing of bandwidth among control loops through orchestration of their execution patterns. In the current practice of control design, once the static execution schedule is prepared for control tasks, no further control-related optimization is attempted for improving the control performance. We introduce, for the first time, an algorithmic mechanism that re-engineers a recurrent control task by enforcing switching between multiple control laws, which are designed for compensating the non-uniform gaps between successive executions of the control task. We establish that such post-processing of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:rO6llkc54NcC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Thunderstorm overshooting is rare but not an unusual phenomenon in a metropolitan of India, Kolkata (22.57° N; 88.36° E) during the pre-monsoon months (April–May). An attempt is made in this study to identify the important parameters differentiating the thunderstorms in overshooting and non-overshooting categories through data analytics from 2000 to 2015. The present investigation on parametric classification would facilitate in estimating the predictability of thunderstorms with overshooting which subsequently might assist in operational forecast of thunderstorm severity over Kolkata. The altitudes of lifting condensation level (LCL), wind shear, bulk Richardson number (BRN), gust speed, boundary layer characteristics and their correlation with thunderstorm cloud top height (CTH) and also their variation and distribution during overshooting (OTS) and non-overshooting (TS) thunderstorms are analyzed in this …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:b0M2c_1WBrUC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Performance of control loops often degrade due to various possible environmental disturbances in the control platform, like late arrival of sensor data, or corrupted readings due to transient noise. Such failures usually manifest as drops in control loop execution leading to unavailability of fresh control signals. In the existing literature, there is an absence of analytical methods which can compute the required patterns of control execution such that the performance of associated control loops remain satisfactory in the presence of such platform level timing uncertainties. We consider such platform level uncertainties as a collection of window based <m, k>-firm specifications and synthesize an <m, k>-firm based input specification for the execution patterns of the loops, so that performance can be provably ensured. Our methodology leverages Buchi automata for modeling platform uncertainties as <m, k>-firm constraints …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:NMxIlDl6LWMC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"As the design paradigm shifts from federated to integrated architecture in the automotive domain [1], scheduling of real time tasks becomes increasingly important to utilize the computation resources of integrated architectures. In addition to having real time deadlines, automotive tasks like Anti-lock Braking System (ABS) that are safety critical in nature, also demand high reliability against transient fault induced soft errors [2] which silently corrupts the results. Existing reliability aware scheduling strategies are offline and real time dynamic scheduling strategies are not reliability aware. This is an initial attempt to bridge this gap and propose reliability aware online scheduling strategies for periodic, aperiodic, and sporadic real time tasks. We also propose a suitable approach to guarantee the maximum load that can be successfully scheduled by the proposed strategies for a heterogeneous architecture.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:bEWYMUwI8FkC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Modern vehicles contain a multitude of electronic control units that implement software features controlling most of the operational, entertainment, connectivity, and safety aspects of the vehicle. However, with security requirements often being an afterthought in automotive software development, incorporation of such software features with intra- and inter-vehicular connectivity requirements often opens up new attack surfaces. Demonstrations of such security vulnerabilities in past reports and literature bring in the necessity to formally analyze how secure automotive control systems really are against adversarial attacks. Modern vehicles often incorporate onboard monitoring systems that test the sanctity of data samples communicated among controllers and detect possible attack/noise insertion scenarios. The performance of such monitors against security threats also needs to be verified.
In this work, we outline a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:mvPsJ3kp5DgC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Smart metering is a mechanism through which fine-grained power consumption profiles of the consumers are collected periodically in a Smart grid. However, a growing concern in this regard is that the leakage of consumers’ consumption data may reveal their daily life patterns as the state-of-the-art metering strategies lack adequate security and privacy measures. Since Smart grid communication infrastructure supports low bandwidth, it prohibits the usage of computation-intensive cryptographic solutions. Among different privacy-preserving smart meter streaming methods, data manipulation techniques can easily be implemented in smart meters and do not require installing any storage devices or alternative energy sources. While these proposals are attractive to the privacy-aware smart meter design community, rigorous security evaluations of such schemes highlight their infeasibility by determining individual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:kRWSkSYxWN8C,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Modern data intensive Cyber-physical Systems ubiquitously employ heterogeneous multiprocessor systems-on chips (MPSoCs) for real-time sensing, computation, and actuation. The low foot-print of such SoCs often leads to high operating temperatures beyond acceptable limits. In this context, conventional thermal management techniques such as Operating System (OS) governed frequency scaling result in drastic degradation of the quality of experience and violation of real-time requirements. In this work, we propose an analytical thermal model for heterogeneous CPU-GPU embedded platforms and demonstrate a Model Predictive Control (MPC) based scheduling strategy with a novel heuristics-based optimization technique that leverages information about future kernels to judiciously choose suitable task mapping options for minimization of the platform's peak (or maximum) temperature to prolong chip's life …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:wbdj-CoPYUoC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"We present an ongoing work on countermeasure design against timing attacks specific to real-time safety-critical Cyber Physical Systems (CPS). Such attacks use timing side channels exposed due to worst-case response time based deterministic scheduling decisions. We propose a methodology to partially nullify this determinism by skipping certain control task executions and related data transmissions. As a proof of concept, we demonstrate how such strategic randomization makes it difficult to launch stealthy timing attacks on controller area network (CAN) based systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:1qzjygNMrQYC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Recent developments in the smart mobility domain have transformed automobiles into networked transportation agents helping realize new age, large-scale intelligent transportation systems (ITS). The motivation behind such networked transportation is to improve road safety as well as traffic efficiency. In this setup, vehicles can share information about their speed and/or acceleration values among themselves and infrastructures can share traffic signal data with them. This enables the connected vehicles (CVs) to stay informed about their surroundings while moving. However, the inter-vehicle communication channels significantly broaden the attack surface. The inter-vehicle network enables an attacker to remotely launch attacks. An attacker can create collision as well as hamper performance by reducing the traffic efficiency. Thus, security vulnerabilities must be taken into consideration in the early phase of CVs' …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:5ugPr518TE4C,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,Adjusting the remote electrical tilt (RET) of antennas is one of the important actions targeting run-time optimization of key performance indicators (KPIs) related to service quality in wireless self-organizing networks (SONs). Reinforcement learning (RL) is one of the preferred Machine Learning methods for automating the choice of RET for all the antennas managed by a company in a region. The automated system should ensure that the system will operate within a safe region to maintain a minimum defined service quality. The safe region of operation is typically customizable based on the targeted service quality at any point in time. This customizable nature of the safe region necessitates automated learning of adaptive safety shields for steering the RL agent away from unsafe regions. This paper presents an adaptive safety shield framework that is capable of learning such shields during the training phase of the RL …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:q3oQSFYPqjQC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Modern Cyber-Physical Systems (CPSs) are often designed as networked, software-based controller implementations which have been found to be vulnerable to network-level and physical level attacks. A number of research works have proposed CPS-specific attack detection schemes as well as techniques for attack resilient controller design. However, such schemes also incur platform-level overheads. In this regard, some recent works have leveraged the use of skips in control execution to enhance the resilience of a CPS against false data injection (FDI) attacks. In this paper, we provide an analytical discussion on when and how skipping a control execution can improve the resilience of the system against FDI attacks while maintaining the control performance requirement. We also propose a methodology to synthesize such optimal control execution patterns. To the best of our knowledge, no previous work has provided any quantitative analysis about the trade-off between attack resilience and control performance for such aperiodic control execution. Finally, we evaluate the proposed method on several safety-critical CPS benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:eflP2zaiRacC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"In the past decade, heterogeneous multicore architectures with support for Single Instruction Multiple Thread (SIMT) style computing have become the standard platform of choice for scheduling HPC applications. Here, applications are typically modelled as a set of data-parallel tasks with dependencies represented in the form of a directed acyclic graph (DAG). The relevant execution time information for each constituent task in the DAG is known beforehand and is leveraged by scheduling algorithms (List or Cluster based) to ascertain near-optimal schedules at runtime. However, given an online setting, where applications are submitted by multiple users and the types of applications are not restrictive, the chances of knowing execution time information for every program are highly unlikely. In this context, we propose a class of intelligent algorithms for heterogeneous CPU-GPU platforms that leverage static analysis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:5Ul4iDaHHb8C,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Recent developments in the smart mobility domain have transformed automobiles into networked transportation agents helping realize new age, large-scale intelligent transportation systems (ITS). The motivation behind such networked transportation is to improve road safety as well as traffic efficiency. In this setup, vehicles can share information about their speed and/or acceleration values among themselves and infrastructures can share traffic signal data with them. This enables the connected vehicles (CVs) to stay informed about their surroundings while moving. However, the inter-vehicle communication channels significantly broaden the attack surface. The inter-vehicle network enables an attacker to remotely launch attacks. An attacker can create collision as well as hamper performance by reducing the traffic efficiency. Thus, security vulnerabilities must be taken into consideration in the early phase of the development cycle of CVs. To the best of our knowledge, there exists no such automated simulation tool using which engineers can verify the performance of CV prototypes in the presence of an attacker. In this work, we present an automated tool flow that facilitates false data injection attack synthesis and simulation on customizable platoon structure and vehicle dynamics. This tool can be used to simulate as well as design and verify control-theoretic light-weight attack detection and mitigation algorithms for CVs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:fQNAKQ3IYiAC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Neural Network (NN) based real-time inferencing tasks are often co-scheduled on GPGPU-style edge platforms. Existing works advocate using different NN parameters for the same detection task in different environments. However, realizing such approaches remains challenging, given accelerator devices’ limited on-chip memory capacity. As a solution, we propose a multi-pass, time- and space-aware scheduling infrastructure for embedded platforms with GPU accelerators. The framework manages the residency of NN parameters in the limited on-chip memory while simultaneously dispatching relevant compute operations. The mapping decisions for memory operations and compute operations to the underlying resources of the platform are first determined in an offline manner. For this, we proposed a constraint solver-assisted scheduler that optimizes for schedule makespan. This is followed by memory optimization passes …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:V3AGJWp-ZtQC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Increased dependence on networked, software-based control has escalated the vulnerabilities of Cyber-Physical Systems (CPSs). Detection and monitoring components developed leveraging dynamical systems theory are often employed as lightweight security measures for protecting such safety-critical CPSs against false data injection attacks. However, existing approaches do not correlate attack scenarios with parameters of detection systems. In this work, we propose real-time attack detection and mitigation strategies for safety-critical CPSs. A Reinforcement Learning (RL) based framework is presented which adaptively sets the parameters of such detectors based on experience learned from attack scenarios. The detection system is provided with a suitable training environment to learn how to maximize the detection rate while minimizing false alarms. Along with the objective of attack detection, our framework …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:K3LRdlH-MEoC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"▶ An optimization technique applied to a group of GPU kernels to increase efficiency by decreasing execution time, power consumption▶ GPU kernels cannot be scheduled once launched in device▶ Kernel fusion can rearrange and schedule the kernels from the host side▶ Kernels using the same or different data array (s) can be replaced with a single kernel call",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:XiVPGOgt02cC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"Advanced Driver-Assistance Systems (ADAS) is one of the primary drivers behind increasing levels of autonomy, driving comfort in this age of connected mobility. However, the performance of such systems is a function of execution rate which demands on-board platform-level support. With GPGPU platforms making their way into automobiles, there exists an opportunity to adaptively support high execution rates for ADAS tasks by exploiting architectural heterogeneity, keeping in mind thermal reliability and long-term platform aging. We propose a future-proof, learning-based adaptive scheduling framework that leverages Reinforcement Learning to discover suitable scenario based task-mapping decisions for accommodating increased task-level throughput requirements.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:lSLTfruPkqcC,http://cse.iitkgp.ac.in/~soumya/
soumyajit dey,"['Formal Methods', 'Computer Architecture']",9,"In recent years, the conventional power grid system has been streamlined towards Smart grid infrastructure that empowers two-way communication between the consumers and the utility providers. This however also makes the grid more susceptible towards faults as well as physical and cyber attacks. In this work, we propose a Physically Unclonable Function (PUF) and Blockchain based detection and prevention mechanism to secure the Smart grid system against such faults and adversarial threats. In this context, we discuss a recently proposed Manipulation of demand via IoT (MadIoT) attacks, False Data Injection Attacks (FDIA) via Smart meters and Electric Fault Attacks (EFA) on Smart grid which can lead to localized blackout, falsified load forecasting, imbalance in demand-response, generator tripping, frequency instability and loss of equipment. To detect these threats and to trace back to the source of such …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XJI3nYIAAAAJ&cstart=20&pagesize=80&citation_for_view=XJI3nYIAAAAJ:3s1wT3WcHBgC,http://cse.iitkgp.ac.in/~soumya/
Satrajit ghosh,"['Cryptography', 'Secure Computation']",7,"This work introduces novel techniques to improve the translation between arithmetic and binary data types in secure multi-party computation. We introduce a new approach to performing these conversions using what we call extended doubly-authenticated bits (edaBits), which correspond to shared integers in the arithmetic domain whose bit decomposition is shared in the binary domain. These can be used to considerably increase the efficiency of non-linear operations such as truncation, secure comparison and bit-decomposition.
Our edaBits are similar to the daBits technique introduced by Rotaru et al. (Indocrypt 2019). However, we show that edaBits can be directly produced much more efficiently than daBits, with active security, while enabling the same benefits in higher-level applications. Our method for generating edaBits involves a novel cut-and-choose technique that may be of independent interest, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DC6eaGYAAAAJ&citation_for_view=DC6eaGYAAAAJ:XiSMed-E-HIC,https://satcrypt.github.io/
Satrajit ghosh,"['Cryptography', 'Secure Computation']",7,"Threshold private set intersection enables Alice and Bob who hold sets and of size n to compute the intersection if the sets do not differ by more than some threshold parameter . In this work, we investigate the communication complexity of this problem and we establish the first upper and lower bounds. We show that any protocol has to have a communication complexity of . We show that an almost matching upper bound of can be obtained via fully homomorphic encryption. We present a computationally more efficient protocol based on weaker assumptions, namely additively homomorphic encryption, with a communication complexity of . For applications like biometric authentication, where a given fingerprint has to have a large intersection with a fingerprint from a database, our protocols may result in significant communication savings.
Prior to this work, all previous …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DC6eaGYAAAAJ&citation_for_view=DC6eaGYAAAAJ:p2g8aNsByqUC,https://satcrypt.github.io/
Satrajit ghosh,"['Cryptography', 'Secure Computation']",7,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DC6eaGYAAAAJ&citation_for_view=DC6eaGYAAAAJ:u9iWguZQMMsC,https://satcrypt.github.io/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Social media platforms provide an inexpensive communication medium that allows anyone to publish content and anyone interested in the content can obtain it. However, this same potential of social media provide space for discourses that are harmful to certain groups of people. Examples of these discourses include bullying, offensive content, and hate speech. Out of these discourses hate speech is rapidly recognized as a serious problem by authorities of many countries. In this paper, we provide the first of a kind systematic large-scale measurement and analysis study of explicit expressions of hate speech in online social media. We aim to understand the abundance of hate speech in online social media, the most common hate expressions, the effect of anonymity on hate speech, the sensitivity of hate speech and the most hated groups across regions. In order to achieve our objectives, we gather traces from two …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&citation_for_view=AUllGoAAAAAJ:8k81kl-MbHgC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Internet companies track users' online activity to make inferences about their interests, which are then used to target ads and personalize their web experience. Prior work has shown that existing privacy-protective tools give users only a limited understanding and incomplete picture of online tracking. We present Tracking Transparency, a privacy-preserving browser extension that visualizes examples of long-term, longitudinal information that third-party trackers could have inferred from users' browsing. The extension uses a client-side topic modeling algorithm to categorize pages that users visit and combines this with data about the web trackers encountered over time to create these visualizations. We conduct a longitudinal field study in which 425 participants use one of six variants of our extension for a week. We find that, after using the extension, participants have more accurate perceptions of the extent of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&citation_for_view=AUllGoAAAAAJ:qxL8FJ1GzNcC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"While hierarchical namespaces such as filesystems and repositories have long been used to organize data, the rapid increase in data production places increasing strain on users who wish to make use of the data. So called ""data lakes"" embrace the storage of data in its natural form, integrating and organizing in a Pay-as-you-go fashion. While this model defers the upfront cost of integration, the result is that data is unusable for discovery or analysis until it is processed. Thus, data scientists are forced to spend significant time and energy on mundane tasks such as data discovery, cleaning, integration, and management -- when this is neglected, ""data lakes"" become ""data swamps.""
Prior work suggests that pure computational methods for resolving issues with the data discovery and management components are insufficient. Here, we provide evidence to confirm this hypothesis, showing that methods such as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&citation_for_view=AUllGoAAAAAJ:MXK_kJrjxJIC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"When users post on social media, they protect their privacy by choosing an access control setting that is rarely revisited. Changes in users' lives and relationships, as well as social media platforms themselves, can cause mismatches between a post's active privacy setting and the desired setting. The importance of managing this setting combined with the high volume of potential friend-post pairs needing evaluation necessitate a semi-automated approach. We attack this problem through a combination of a user study and the development of automated inference of potentially mismatched privacy settings. A total of 78 Facebook users reevaluated the privacy settings for five of their Facebook posts, also indicating whether a selection of friends should be able to access each post. They also explained their decision. With this user data, we designed a classifier to identify posts with currently incorrect sharing settings. This …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&citation_for_view=AUllGoAAAAAJ:4TOpqqG69KYC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Most social platforms offer mechanisms allowing users to delete their posts, and a significant fraction of users exercise this right to be forgotten. However, ironically, users’ attempt to reduce attention to sensitive posts via deletion, in practice, attracts unwanted attention from stalkers specifically to those (deleted) posts. Thus, deletions may leave users more vulnerable to attacks on their privacy in general. Users hoping to make their posts forgotten face a “damned if I do, damned if I don’t” dilemma. Many are shifting towards ephemeral social platform like Snapchat, which will deprive us of important user-data archival. In the form of intermittent withdrawals, we present, Lethe, a novel solution to this problem of (really) forgetting the forgotten. If the next-generation social platforms are willing to give up the uninterrupted availability of non-deleted posts by a very small fraction, Lethe provides privacy to the deleted posts over long durations. In presence of Lethe, an adversarial observer becomes unsure if some posts are permanently deleted or just temporarily withdrawn by Lethe; at the same time, the adversarial observer is overwhelmed by a large number of falsely flagged undeleted posts. To demonstrate the feasibility and performance of Lethe, we analyze large-scale real data about users’ deletion over Twitter and thoroughly investigate how to choose time duration distributions for alternating between temporary withdrawals and resurrections of non-deleted posts. We find a favorable trade-off between privacy, availability and adversarial overhead in different settings for users exercising their right to delete. We show that, even against an ultimate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&citation_for_view=AUllGoAAAAAJ:ULOm3_A8WrAC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Today, administering COVID-19 vaccines at a societal scale has been deemed as the most appropriate way to defend against the COVID-19 pandemic. This global vaccination drive naturally fueled a possibility of pro-vax and anti-vax users strongly expressing their supports and concerns regarding the vaccines in online social media platforms. Understanding this online discourse is crucial for policy makers. This understanding is likely to impact the success of vaccination drives and might even impact the final outcome of our fight against the pandemic. The goal of this work is to improve this understanding using the lens of Twitter-discourse data. We first develop a classifier to categorize users according to their vaccine-related stance with high precision (97%). Using this method we detect and investigate specific user-groups who posted about vaccines in pre-COVID and COVID times. We specifically identify distinct topics that these users talk about, and investigate how vaccine-related discourse has changed between pre-COVID times and COVID times. Finally, for the first time, we investigate the change of vaccine-related stances in Twitter users and shed light on potential reasons for such changes in stance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&citation_for_view=AUllGoAAAAAJ:R3hNpaxXUhUC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Browser cookies are ubiquitous in the web ecosystem today. Although these cookies were initially introduced to preserve user-specific state in browsers, they have now been used for numerous other purposes, including user profiling and tracking across multiple websites. This paper sets out to understand and quantify the different uses for cookies, and in particular, the extent to which targeting and advertising, performance analytics and other uses which only serve the website and not the user add to overall cookie volumes. We start with 31 million cookies collected in Cookiepedia, which is currently the most comprehensive database of cookies on the Web. Cookiepedia provides a useful four-part categorisation of cookies into strictly necessary, performance, functionality and targeting/advertising cookies, as suggested by the UK International Chamber of Commerce. Unfortunately, we found that, Cookiepedia data …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:hC7cP41nSMkC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Many social media sites permit users to delete, edit, anonymize, or otherwise modify past posts. These mechanisms enable users to protect their privacy, but also to essentially change the past. We investigate perceptions of the necessity and acceptability of these mechanisms. Drawing on boundary-regulation theories of privacy, we first identify how users who reshared or responded to a post could be impacted by its retrospective modification. These mechanisms can cause boundary turbulence by recontextualizing past content and limiting accountability. In contrast, not permitting modification can lessen privacy and perpetuate harms of regrettable content. To understand how users perceive these mechanisms, we conducted 15 semi-structured interviews. Participants deemed retrospective modification crucial for fixing past mistakes. Nonetheless, they worried about the potential for deception through selective changes or removal. Participants were aware retrospective modification impacts others, yet felt these impacts could be minimized through context-aware usage of markers and proactive notifications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:qUcmZB5y_30C,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Over-sharing poorly-worded thoughts and personal information is prevalent on online social platforms. In many of these cases, users regret posting such content. To retrospectively rectify these errors in users' sharing decisions, most platforms offer (deletion) mechanisms to withdraw the content, and social media users often utilize them. Ironically and perhaps unfortunately, these deletions make users more susceptible to privacy violations by malicious actors who specifically hunt post deletions at large scale. The reason for such hunting is simple: deleting a post acts as a powerful signal that the post might be damaging to its owner. Today, multiple archival services are already scanning social media for these deleted posts. Moreover, as we demonstrate in this work, powerful machine learning models can detect damaging deletions at scale. Towards restraining such a global adversary against users' right to be forgotten, we introduce Deceptive Deletion, a decoy mechanism that minimizes the adversarial advantage. Our mechanism injects decoy deletions, hence creating a two-player minmax game between an adversary that seeks to classify damaging content among the deleted posts and a challenger that employs decoy deletions to masquerade real damaging deletions. We formalize the Deceptive Game between the two players, determine conditions under which either the adversary or the challenger provably wins the game, and discuss the scenarios in-between these two extremes. We apply the Deceptive Deletion mechanism to a real-world task on Twitter: hiding damaging tweet deletions. We show that a powerful global adversary can be …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:IWHjjKOFINEC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"The super-cyclonic storm “Amphan” hit Eastern India, specifically the state of West Bengal, Odisha and parts of Bangladesh in May 2020 and caused severe damage to the regions. In this study, we aim to understand the self-reported effects of this natural disaster on residents of the state of West Bengal. To that end, we conducted an online survey to understand the effects of the cyclone. In total, 201 participants (spanning five districts) from the worst-affected state of West Bengal participated in the survey. This report describes our findings from the survey, with respect to the damages caused by the cyclone, how it affected the population in various districts of West Bengal, and how prepared the authorities were in responding to the disaster. We found that the participants were most adversely affected in this disaster due to disruption of services like electricity, phone and internet (as opposed to uprooting of trees and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:QIV2ME_5wuYC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Today online social media sites function as the medium of expression for billions of users. As a result, aside from conventional social media sites like Facebook and Twitter, platform designers introduced many alternative social media platforms (e.g., 4chan, Whisper, Snapchat, Mastodon) to serve specific userbases. Among these platforms, anonymous social media sites like Whisper and 4chan hold a special place for researchers. Unlike conventional social media sites, posts on anonymous social media sites are not associated with persistent user identities or profiles. Thus, these anonymous social media sites can provide an extremely interesting data-driven lens into the effects of anonymity on online user behavior. However, to the best of our knowledge, currently there are no publicly available datasets to facilitate research efforts on these anonymity effects.
To that end, in this paper, we aim to publicly release the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:mVmsd5A6BfQC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"This study performs an initial exploration of cultural differences in social media disclosure behaviors. We focus on what U.S. and India users disclose about interpersonal relationships on Twitter, a popular social networking platform that has gained enormous traction outside the U.S. We developed a taxonomy of words representing interpersonal relationships and then collected all tweets containing these words (~4.5 million tweets) uploaded from India and the U.S. over a one-month period of time. We found that Indian tweets about others tend to be statistically significantly more positive and uncover differences in how they tweet about various relationships (family, friends, others) in comparison to U.S. users. Drawing on theories of collectivism and individualism, we discuss how different cultural attitudes may explain these behaviors. We present implications for research and for designing to support cultural norms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:7PzlFSSx8tAC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"The ever-increasing cohort of cryptocurrency users saw a sharp increase in different types of crypto-wallets in the past decade. However, different wallets are non-uniformly adopted in the population today; Specifically, emerging multi-device wallets, even with improved security and availability guarantees over their counterparts, are yet to receive proportionate attention and adoption. This work presents a data-driven investigation into the perceptions of cryptocurrency users towards multi-device wallets today, using a survey of255crypto-wallet users. Our results revealed two significant groups within our participants—Newbies and Non-newbies. These two groups statistically significantly differ in their usage of crypto-wallets. However, both of these groups were concerned with the possibility of their keys getting compromised and yet are unfamiliar with the guarantees offered by multi-device wallets. After educating the participants about the more secure multi-device wallets, around 70% of the participants preferred them; However, almost one-third of participants were still not comfortable using them. Our qualitative analysis revealed a gap between the actual security guarantees and mental models for these participants—they were afraid that using multi-device wallets will result in losing control over keys (and in effect funds) due to the distribution of key shares. We also investigated the preferred default settings for crypto-wallets across our participants, since multi-device wallets allow a wide range of key-share distribution settings. In the distributed server settings of the multi-device wallets, the participants preferred a smaller number of reputed servers …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:_Qo2XoVZTnwC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Today, intelligent voice assistant (VA) software like Amazon's Alexa, Google's Voice Assistant (GVA) and Apple's Siri have millions of users. These VAs often collect and analyze huge user data for improving their functionality. However, this collected data may contain sensitive information (eg, personal voice recordings) that users might not feel comfortable sharing with others and might cause significant privacy concerns. To counter such concerns, service providers like Google present their users with a personal data dashboard (called'My Activity Dashboard'), allowing them to manage all voice assistant collected data. However, a real-world GVA-data driven understanding of user perceptions and preferences regarding this data (and data dashboards) remained relatively unexplored in prior research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:HDshCWvjkbEC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:dhFuZR0502QC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Most social platforms offer mechanisms allowing users to delete their posts, and a significant fraction of users exercise this right to be forgotten. However, ironically, users' attempt to reduce attention to sensitive posts via deletion, in practice, attracts unwanted attention from stalkers specifically to those (deleted) posts. Thus, deletions may leave users more vulnerable to attacks on their privacy in general. Users hoping to make their posts forgotten face a ""damned if I do, damned if I don't"" dilemma. Many are shifting towards ephemeral social platform like Snapchat, which will deprive us of important user-data archival. In the form of intermittent withdrawals, we present, Lethe, a novel solution to this problem of (really) forgetting the forgotten. If the next-generation social platforms are willing to give up the uninterrupted availability of non-deleted posts by a very small fraction, Lethe provides privacy to the deleted posts over long durations. In presence of Lethe, an adversarial observer becomes unsure if some posts are permanently deleted or just temporarily withdrawn by Lethe; at the same time, the adversarial observer is overwhelmed by a large number of falsely flagged un-deleted posts. To demonstrate the feasibility and performance of Lethe, we analyze large-scale real data about users' deletion over Twitter and thoroughly investigate how to choose time duration distributions for alternating between temporary withdrawals and resurrections of non-deleted posts. We find a favorable trade-off between privacy, availability and adversarial overhead in different settings for users exercising their right to delete. We show that, even against an ultimate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:KlAtU1dfN6UC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Laws like GDPR in the EU mandated all websites operating in their jurisdiction to obtain users’ informed consent before tracking those users and collecting their data. Today, this is achieved by showing users cookie consent notices. These notices are ubiquitous (often permeating the geographical boundaries of GDPR enforcement), even though their exact user interface (UI) designs vary. These designs are provided by Consent Management Platforms (CMPs) to different websites, effectively resulting in a handful of cookie consent notice designs being shown to a majority of internet users. Naturally, not all designs are uniformly liked by the users. Thus the first step of improving cookie consent notice UI design and moving to a better consent mechanism is to understand whether users prefer one design over another in the wild and why. To answer these questions, in this work, we conduct an in the wild comparative …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:JV2RwH3_ST0C,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Throughout the pandemic, digital contact tracing using smartphone applications (or apps) has been endorsed by many authorities across the globe as a tool to limit the spread of COVID-19. Consequently, to deploy contact tracing in large populations, multiple contact tracing apps have been developed and deployed globally. However, due to the relative recency of the COVID-19 pandemic as well as the suddenness of the need for contact tracing at this scale, app designers are often left with no systematic guidelines. Designers today lack guidelines on what factors might affect perceptions and adoption of their apps. They also lack a knowledgebase of features that could be appropriate to include in their app for a given context. To address this gap, we conducted a review of the academic literature on attitudes towards and adoption of COVID-19 response apps, as well as a feature review of a diverse set of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:r0BpntZqJG4C,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"In recent years, social platforms are heavily used by individuals to share their thoughts and personal information. However, due to regret over time about posting inappropriate social content, embarrassment, or even life or relationship changes, some past posts might also pose serious privacy concerns for them. To cope with these privacy concerns, social platforms offer deletion mechanisms that allow users to remove their contents. Quite naturally, these deletion mechanisms are really useful for removing past posts as and when needed. However, these same mechanisms also leave the users potentially vulnerable to attacks by adversaries who specifically seek the users' damaging content and exploit the act of deletion as a strong signal for identifying such content. Unfortunately, today user experiences and contextual expectations regarding such attacks on deletion privacy and deletion privacy in general are not well understood.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:TQgYirikUcIC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"The 10th International Conference on Security, Privacy and Applied Cryptography Engineering 2020 (SPACE 2020) was held on December 17–20, 2020. This annual event is devoted to various aspects of security, privacy, applied cryptography, and cryptographic engineering. This is a challenging field, requiring expertise from diverse domains, ranging from mathematics and computer science to circuit design. It was first planned to host the conference at IIT Kharagpur, India, but it took place online due to the worldwide pandemic crisis.
This year we received 48 submissions from many different countries, mainly from Asia and Europe. The submissions were evaluated based on their significance, novelty, technical quality, and relevance to the SPACE conference. The submissions were reviewed in a double-blind mode by at least three members of the Program Committee, which consisted of 52 members from all over …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:L8Ckcad2t8MC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Passwords are the most common mechanism for authenticating users online. However, studies have shown that users find it difficult to create and manage secure passwords. To that end, passphrases are often recommended as a usable alternative to passwords, which would potentially be easy to remember and hard to guess. However, as we show, user-chosen passphrases fall short of being secure, while state-of-the-art machine-generated passphrases are difficult to remember. In this work, we aim to tackle the drawbacks of the systems that generate passphrases for practical use. In particular, we address the problem of generating secure and memorable passphrases and compare them against user chosen passphrases in use. We identify and characterize 72, 999 user-chosen in-use unique English passphrases from prior leaked password databases. Then we leverage this understanding to create a novel framework for measuring memorability and guessability of passphrases. Utilizing our framework, we design MASCARA, which follows a constrained Markov generation process to create passphrases that optimize for both memorability and guessability. Our evaluation of passphrases shows that MASCARA-generated passphrases are harder to guess than in-use user-generated passphrases, while being easier to remember compared to state-of-the-art machine-generated passphrases. We conduct a two-part user study with crowdsourcing platform Prolific to demonstrate that users have highest memory-recall (and lowest error rate) while using MASCARA passphrases. Moreover, for passphrases of length desired by the users, the recall rate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:NaGl4SEjCO4C,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Non-financial incentives in the form of awards often act as a driver of positive reinforcement and elevation of social status in the offline world. The elevated social status results in people becoming more active, aligning to a change in the communities' expectations. However, the impact in terms of longevity of social influence and community acceptance of leaders of these incentives in the form of awards are not well-understood in the online world. Our work aims to shed light on the impact of these awards on the awardee and the community. We focus on three large subreddits with a snapshot of 219K posts and 5.8 million comments contributed by 88K Reddit users who received 14,146 awards. Our work establishes that the behaviour of awardees change statistically significantly for a short time after getting an award; however, the change is ephemeral since the awardees return to their pre-award behaviour within days …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:HoB7MX3m0LUC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Privacy concerns around sharing personal health information are frequently cited as hindering COVID-19 contact tracing app adoption. We conducted a nationally representative survey of 304 adults in the United States to investigate their attitudes towards sharing two types of COVID-19 health status (COVID-19 Diagnosis, Exposure to COVID-19) with three different audiences (Anyone, Frequent Contacts, Occasional Contacts). Using the Internet User’s Information Privacy Concern (IUIPC) scale, we were able to identify the effect of different types of privacy concerns on sharing this information with various audiences. We found that privacy concerns around data Collection predicted lower willingness to share either type of health status to all of these audiences. However, desire for Control and for Awareness of data practices increased willingness to share health information with certain audiences. We discuss the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:blknAaTinKkC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Today, participating in discussions on online forums is extremely commonplace and these discussions have started rendering a strong influence on the overall opinion of online users. Naturally, twisting the flow of the argument can have a strong impact on the minds of naive users, which in the long run might have socio-political ramifications, for example, winning an election or spreading targeted misinformation. Thus, these platforms are potentially highly vulnerable to malicious players who might act individually or as a cohort to breed fallacious arguments with a motive to sway public opinion. Ad hominem arguments are one of the most effective forms of such fallacies. Although a simple fallacy, it is effective enough to sway public debates in offline world and can be used as a precursor to shutting down the voice of opposition by slander. In this work, we take a first step in shedding light on the usage of ad hominem fallacies in the wild. First, we build a powerful ad hominem detector with high accuracy (F1 more than 83%, showing a significant improvement over prior work), even for datasets for which annotated instances constitute a very small fraction. We then used our detector on 265k arguments collected from the online debate forum - CreateDebate. Our crowdsourced surveys validate our in-the-wild predictions on CreateDebate data (94% match with manual annotation). Our analysis revealed that a surprising 31.23% of CreateDebate content contains ad hominem fallacy, and a cohort of highly active users post significantly more ad hominem to suppress opposing views. Then, our temporal analysis revealed that ad hominem argument usage …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:M3NEmzRMIkIC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:4DMP91E08xMC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"Online archives, including social media and cloud storage, store vast troves of personal data accumulated over many years. Recent work suggests that users feel the need to retrospectively manage security and privacy for this huge volume of content. However, few mechanisms and systems help these users complete this daunting task. To that end, we propose the creation of usable retrospective data management mechanisms, outlining our vision for a possible architecture to address this challenge.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:_kc_bZDykSQC,https://cse.iitkgp.ac.in/~mainack/
Mainack Mondal,"['Online privacy management', 'usable privacy and security', 'HCI', 'systems', 'data science']",17,"The normative model of contextual integrity (CI) equips individuals to reason about privacy requirements and violations in online systems. However, a subsequent step is the enforcement of CI in online systems via privacy-management mechanisms. In this work, we first investigate the suitability of access control, the dominant privacy management model in online platforms, in filling this role. We argue that access control is insufficient for enforcing CI because it does not consider the set of expected recipients for a piece of content. To that end, we identify the privacy model of exposure control as an extension of access control to better enforce CI. We discuss the effectiveness of exposure control in better enforcing CI and describe a generic prediction-based framework for controlling exposure in online systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=AUllGoAAAAAJ&cstart=20&pagesize=80&citation_for_view=AUllGoAAAAAJ:kNdYIx-mwKoC,https://cse.iitkgp.ac.in/~mainack/
Bhargab B. Bhattacharya,"['VLSI Design and Test', 'Image Processing', 'Digital Geometry', 'Microfluidics']",33,"Bone cancer originates from bone and rapidly spreads to the rest of the body affecting the patient. A quick and preliminary diagnosis of bone cancer begins with the analysis of bone X-ray or MRI image. Compared to MRI, an X-ray image provides a low-cost diagnostic tool for diagnosis and visualization of bone cancer. In this paper, a novel technique for the assessment of cancer stage and grade in long bones based on X-ray image analysis has been proposed. Cancer-affected bone images usually appear with a variation in bone texture in the affected region. A fusion of different methodologies is used for the purpose of our analysis. In the proposed approach, we extract certain features from bone X-ray images and use support vector machine (SVM) to discriminate healthy and cancerous bones. A technique based on digital geometry is deployed for localizing cancer-affected regions. Characterization of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=udxFQnwAAAAJ&cstart=20&pagesize=80&citation_for_view=udxFQnwAAAAJ:qe6vwMD2xtsC,https://www.researchgate.net/profile/Bhargab_Bhattacharya
Bhargab B. Bhattacharya,"['VLSI Design and Test', 'Image Processing', 'Digital Geometry', 'Microfluidics']",33,"Block ciphers are widely regarded as concrete realizations of pseudorandom permutations with established security features. However, their applicability outside the domain of encryption has not been explored so far. In this paper, we open up, for the first time, an entirely novel application of them to logic hiding. We show that a combinational circuit can always be embedded within a block cipher having a bit-permutation based diffusion layer, preserving the cipher structure and security properties. The functionality of the embedded circuit becomes transparent only on the application of a secret key, whereas a wrong key will cause behaviour that is uncorrelated to that of the circuit. As an immediate application, we propose a combinational logic-locking scheme. The proposed locking scheme is also found to be robust against the state-of-the-art (SAT-assisted and other) attacks on logic locks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=udxFQnwAAAAJ&cstart=20&pagesize=80&citation_for_view=udxFQnwAAAAJ:dAp6zn-oMfAC,https://www.researchgate.net/profile/Bhargab_Bhattacharya
Bhargab B. Bhattacharya,"['VLSI Design and Test', 'Image Processing', 'Digital Geometry', 'Microfluidics']",33,"Microfluidic chips are now being increasingly used for fast and cost-effective implementation of biochemical protocols. Sample preparation involves dilution and mixing of fluids in certain ratios, which are needed for most of the protocols. On a digital microfluidic biochip (DMFB), these tasks are usually automated as a sequence of droplet mix-split steps. In the most widely used (1:1) mix-split operation for DMFBs, two equal-volume droplets are mixed followed by a split operation, which, ideally, should produce two daughter-droplets of equal volume (balanced splitting). However, because of uncertain variabilities in fluidic operations, the outcome of droplet-split operations often becomes erroneous, i.e., they may cause unbalanced splitting. As a result, the concentration factor (CF) of each constituent fluid in the mixture may become erroneous during sample preparation. All traditional approaches aimed to recover from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=udxFQnwAAAAJ&cstart=20&pagesize=80&citation_for_view=udxFQnwAAAAJ:silx2ntsSuwC,https://www.researchgate.net/profile/Bhargab_Bhattacharya
Bhargab B. Bhattacharya,"['VLSI Design and Test', 'Image Processing', 'Digital Geometry', 'Microfluidics']",33,"The active matrix (AM)-based architecture offers many advantages over conventional digital electrowetting-on-dielectric (EWOD) microfluidic biochips, such as the capability of handling variable-size droplets, more flexible droplet movement, and precise control over droplet navigation. However, a major challenge in choosing the routing paths is to decide when the droplets are to be reshaped depending on the congestion of the intended path, or split- and route sub droplets,and merging them at their respective destinations. As the number of microelectrodes in AM-EWOD chips is large, the path selection problem becomes further complicated. In this article, we propose a negotiation-guided flow based on routing of subdroplets that obviates the explicit need for deciding when the droplets are to be manipulated, yet fully utilizing the power of droplet reshaping, splitting, and merging them to facilitate their journey. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=udxFQnwAAAAJ&cstart=20&pagesize=80&citation_for_view=udxFQnwAAAAJ:wvYxNZNCP7wC,https://www.researchgate.net/profile/Bhargab_Bhattacharya
Bhargab B. Bhattacharya,"['VLSI Design and Test', 'Image Processing', 'Digital Geometry', 'Microfluidics']",33,"With the advent of rapidly evolving nanoelectronic systems, compact implementation of versatile and dense network-on-chips (NoCs) on a die has emerged as technology-of-choice for multicore computing. However, because of the increased density, NoCs often suffer from various types of manufacturing faults, which degrade the yield and jeopardize the reliability of the overall system. For example, short-channel faults in an NoC often cause system-level failures that may have significant impact on its performance. This paper proposes a cluster-based distributed scheme for online testing of short faults in NoC channels. The proposed algorithm detects both intra and interchannel short faults and identifies the underlying faulty channel-wires connected to a node. The nodes in a cluster-set are appropriately scheduled to reduce test time. The approach scales to larger NoCs irrespective of size of the network and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=udxFQnwAAAAJ&cstart=20&pagesize=80&citation_for_view=udxFQnwAAAAJ:HJSXoJQnj-YC,https://www.researchgate.net/profile/Bhargab_Bhattacharya
Bhargab B. Bhattacharya,"['VLSI Design and Test', 'Image Processing', 'Digital Geometry', 'Microfluidics']",33,"The insistent trend in today's nanoscale technology, to keep abreast of the Moore's law, has been continually opening up newer challenges to circuit designers. With rapid downscaling of integration, the intricacies involved in the manufacturing process have escalated significantly. Concomitantly, the nature of defects in silicon chips has become more complex and unpredictable, adding further difficulty in circuit testing and diagnosis. The volume of test data has surged and the parameters that govern testing of integrated circuits have increased not only in dimension but also in the complexity of their correlation. Evidently, the current scenario serves as a pertinent platform to explore new test solutions based on machine learning. In this survey, we look at various recent advances in this evolving domain in the context of digital logic testing and diagnosis.
This article is categorized under:
Algorithmic Development > …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=udxFQnwAAAAJ&cstart=20&pagesize=80&citation_for_view=udxFQnwAAAAJ:oPLKW5k6eA4C,https://www.researchgate.net/profile/Bhargab_Bhattacharya
Bhargab B. Bhattacharya,"['VLSI Design and Test', 'Image Processing', 'Digital Geometry', 'Microfluidics']",33,"Digital circuits are often prone to suffer from uncertain timing, inadequate sensor feedback, limited controllability of past states or inability of initializing memory-banks, and erroneous behavior of analog-to-digital converters, which may produce an unknown ( ) logic value at various circuit nodes. Additionally, many design bugs that are identified during the post-silicon validation phase manifest themselves as -values. The presence of such -sources on certain primary or secondary inputs of a logic circuit may cause loss of fault-coverage of a test set, which, in turn, may impact its reliability and robustness. In this paper, we provide a mechanism for predicting the sensitivity of -sources in terms of loss of fault-coverage, on the basis of learning only a few structural features of the circuit that are easy to extract from the netlist. We show that the -sources can be graded satisfactorily according to their …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=udxFQnwAAAAJ&cstart=20&pagesize=80&citation_for_view=udxFQnwAAAAJ:Xz60mAmATU4C,https://www.researchgate.net/profile/Bhargab_Bhattacharya
Bhargab B. Bhattacharya,"['VLSI Design and Test', 'Image Processing', 'Digital Geometry', 'Microfluidics']",33,"Sample preparation is a fundamental preprocessing step needed in almost all biochemical assays and is conveniently automated on a microfluidic lab-on-chip. In digital microfluidics, it is accomplished by a sequence of droplet-mix-split steps on a biochip. Many real-life applications require a sample with multiple concentration factors (CFs). Existing algorithms, while producing multi-CF targets, attempt to share the mix-split steps in order to reduce reactant-cost and sample-preparation time. However, all prior approaches have two limitations: 1) sharing of intermediate droplets can be best effected only when all required target CFs are known a priori and 2) the processing time may vary depending on the allowable error-tolerance in target-CFs. In this paper, we present a cost-effective solution to multi-CF-dilution on-demand, by using only one (or two) mix-split step(s). In order to service dynamically arriving requests of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=udxFQnwAAAAJ&cstart=20&pagesize=80&citation_for_view=udxFQnwAAAAJ:DrR-2ekChdkC,https://www.researchgate.net/profile/Bhargab_Bhattacharya
Bhargab B. Bhattacharya,"['VLSI Design and Test', 'Image Processing', 'Digital Geometry', 'Microfluidics']",33,"Active-Matrix (AM) technology is currently being used to implement a superior class of EWOD-based biochips, which consist of a dense 2D-array of microelectrodes. These chips offer many advantages over conventional biochips such as the capability of handling variable-size droplets, more flexibility in droplet movement, precise control over droplet navigation, and as a sequel, ease of implementing complex bioprotocols on-chip. However, the new technology poses a number of challenges concerning droplet routing. In order to enhance routability, we propose, in this paper, a multi-level hierarchical approach that takes appropriate decisions on droplet splitting and reshaping. Compared to the most recent routing methods used for EWOD, the proposed multi-level router reduces maximum latest-arrivaltime by an average 18% and achieves 7% less average latest-arrival-time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=udxFQnwAAAAJ&cstart=20&pagesize=80&citation_for_view=udxFQnwAAAAJ:xGWFX6Gbr9MC,https://www.researchgate.net/profile/Bhargab_Bhattacharya
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Physically Unclonable Functions (PUFs) are widely adopted in various lightweight authenticating devices due to their unique fingerprints - providing uniform, unpredictable and reliable nature of responses. However, with the growth of machine learning (ML) attacks in recent times, it is imperative that the PUFs need to be resilient to such modeling attacks as well. Consequently, analyzing the learnability of PUFs has initiated a new branch of study leading to establishing provable guarantees (and PAC-learnability) of various PUF designs. However, these derivations are often carried out manually while implementing the design and thereby cannot automatically adjust the changes in PUF designs or its various compositions. In this paper, for the first time, we present an automated framework, called PUF-G, to reason about the PAC-learnability of PUF designs from an architectural level. To enable this, we propose a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&citation_for_view=nYazw20AAAAJ:R3hNpaxXUhUC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Most cipher implementations are vulnerable to a class of cryptanalytic attacks known as fault injection attacks. To reveal the secret key, these attacks make use of faults induced at specific locations during the execution of the cipher. Countermeasures for fault injection attacks require these vulnerable locations in the implementation to be first identified and then protected. However, both these steps are difficult and error-prone and, hence, it requires considerable expertise to design efficient countermeasures. Incorrect or insufficient application of the countermeasures would cause the implementation to remain vulnerable, while inefficient application of the countermeasures could lead to significant performance penalties to achieve the desired fault-attack resistance. In this paper, we present a novel framework called SAFARI for automatically synthesizing fault-attack resistant implementations of block ciphers. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&citation_for_view=nYazw20AAAAJ:mVmsd5A6BfQC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"In this work, we prove that Interpose PUF is learnable in the PAC model. First, we show that Interpose PUF can be approximated by a Linear Threshold Function~(LTF), assuming the interpose bit to be random. We translate the randomness in the interpose bit to classification noise of the hypothesis. Using classification noise model, we prove that the resultant LTF can be learned with number of labelled examples~(challenge response pairs) polynomial in the number of stages and PAC model parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&citation_for_view=nYazw20AAAAJ:IWHjjKOFINEC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Online detection of cyber-attacks on IoT devices is extremely difficult due to the limited battery and computational power available in these devices. An alternate approach is to shrink the attack surface in order to reduce the threat of attack. This would require that the device undergo more stringent security tests before deployment. Formal verification is a promising tool that can be used to not only detect potential vulnerabilities but also provide guarantees of security. This chapter reviews several security issues that plague IoT devices such as functional correctness of implementations, programming bugs, side-channel analysis, and hardware Trojans. In each of these cases, we discuss state-of-the-art mechanisms that use formal verification tools to detect the vulnerability much before the device is deployed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&citation_for_view=nYazw20AAAAJ:Wp0gIr-vW9MC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Fault attacks are potent physical attacks on crypto-devices. A single fault injected during encryption can reveal the cipher's secret key. In a hardware realization of an encryption algorithm, only a tiny fraction of the gates is exploitable by such an attack. Finding these vulnerable gates has been a manual and tedious task requiring considerable expertise. In this paper, we propose SOLOMON, the first automatic fault attack vulnerability detection framework for hardware designs. Given a cipher implementation, either at RTL or gate-level, SOLOMON uses formal methods to map vulnerable regions in the cipher algorithm to specific locations in the hardware thus enabling targeted countermeasures to be deployed with much lesser overheads. We demonstrate the efficacy of the SOLOMON framework using three ciphers: AES, CLEFIA, and Simon.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&citation_for_view=nYazw20AAAAJ:dhFuZR0502QC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Fault injection attacks are one of the most powerful forms of cryptanalytic attacks on ciphers. A single, precisely injected fault during the execution of a cipher like the AES, can completely reveal the key within a few milliseconds. Software implementations of ciphers, therefore, need to be thoroughly evaluated for such attacks. In recent years, automated tools have been developed to perform these evaluations. These tools either work on the cipher algorithm or on their implementations. Tools that work at the algorithm level can provide a comprehensive assessment of fault attack vulnerability for different fault attacks and with different fault models. Their application is, however, restricted because every realization of the cipher has unique vulnerabilities. On the other hand, tools that work on cipher implementations have a much wider application but are often restricted by the range of fault attacks and the number of fault models they can evaluate.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&citation_for_view=nYazw20AAAAJ:L8Ckcad2t8MC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"The S-PUF and S n -PUF designs (proposed in IN-DOCRYPT2019) are one of the contemporary composite strong PUF candidates of the Delay-PUF family that exhibit two distinguishing and notable attributes – (i) it is one of the few PUF constructions which is guided by theoretical analysis of the Strict Avalanche Criteria (SAC) property and not by ad-hoc choices; and (ii) though its construction is quite similar to XOR PUFs, it has very good reliability property unlike the former design due to the introduction of Maiorana-McFarland (M-M) Bent Function. These make S n -PUF to be a very good candidate for strong PUF proposals and an interesting target from the point of view of attackers. In this work, we testify that a novel reliability based machine learning attack can be launched in this architecture against the original authors’ claim. Though it is challenging to launch a classical or reliability based ML attack directly, we leverage …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&citation_for_view=nYazw20AAAAJ:TFP_iSt0sucC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"In this paper, we propose a novel concept named Physically Related Function (PReF) which are devices with hardware roots of trust. It enables secure key-exchange with no pre-established/embedded secret keys. This work is motivated by the need to perform key-exchange between lightweight resource-constrained devices. We present a proof-of-concept realization of our contributions in hardware using FPGAs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&citation_for_view=nYazw20AAAAJ:RHpTSmoSYBkC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"In this paper, we present a novel formal analysis scheme considering that the fabrication of a batch of PUFs is equivalent to drawing random instances of Boolean mappings. We model PUFs as black-box Boolean functions of dimension and show combinatorially that random designs of such functions exhibit correlation-spectra which can be used to characterize random and thus good designs of PUFs. We first develop theoretical results to quantize the correlation values and subsequently find the expected number of pairs of such Boolean functions which should belong in different regions of the spectra. We extend the concept of correlation to PUFs and theoretically prove that a randomly chosen sample of PUFs and Boolean functions follow the same distribution. In addition to this, we show through extensive experimental results that a randomly chosen sample of such PUFs also resembles the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&citation_for_view=nYazw20AAAAJ:9ZlFYXVOiuMC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Mixed-signal components, such as low dropouts (LDOs) and phase locked loops (PLLs), are widely used inside the on-chip power management fabric of low power integrated system-on-chip (SoC) designs. The digital brain of the power management logic that is responsible for regulating the power delivery to different power domains in the chip has to consider the real time latencies of the analog components, which otherwise leads to functional errors in the domains being driven. The latencies may be viewed as contracts between the digital and the analog. This article presents an approach for generating assertions for protecting such mixed-signal latency contracts and using them to rule out timing bugs in the power management logic. Our tool flow enables the verification of the power management fabric, combining a novel mixed-signal assertion checking method in a simulation setting, and a full formal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:-f6ydRqryjwC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Coverage monitoring has become increasingly significant for analog designs considering the life cycle of analog design IPs that are first designed and verified in isolation and then used in a wide variety of contexts in one or more integrated circuits. The behavioral artifacts relevant for coverage in the analog and mixed signal (AMS) domain are very different from the digital domain, and is the primary motivation behind the proposed tool, CoveRT. This paper introduces the AMS coverage primitives, the challenges in monitoring the coverage by handshaking with the simulation platform, and the salient features of our methodology. To the best of our knowledge, CoveRT is the first AMS coverage monitoring tool of its kind which works with commercial simulators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:hC7cP41nSMkC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Depending on the relative position of the input and output stages of the feed forward loops, the FF-APUFs architectures can be categorized as–(a) Nested,(b) Overlap,(c) Cascade, and (d) Separate. Figure 5 depicts all the four configurations assuming only two feed forward loops.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:HDshCWvjkbEC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"This paper initiates the study of “Cryptophasia in Hardware” – a phenomenon that allows hardware circuits/devices with no pre-established secret keys to securely exchange secret information over insecure communication networks. The study of cryptophasia is motivated by the need to establish secure communication channels between lightweight resource-constrained devices incapable of securely storing cryptographic keys and/or executing resource-intensive cryptographic protocols. In this paper, we introduce a novel concept called Physically Related Functions (PReFs) that can exchange secret information in a secure and authenticated manner over insecure networks. This function can be visualized as an abstraction of Strong Physically Unclonable Functions (PUFs). Strong PUFs have the limitation in communicating between two identical devices, an issue that we address in the definition of PReFs. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:O3NaXMp0MMsC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Interpose PUF~(iPUF) is a strong PUF construction that was shown to be vulnerable against empirical machine learning as well as PAC learning attacks. In this work, we extend the PAC Learning results of Interpose PUF to prove that the variants of iPUF are also learnable in the PAC model under the Linear Threshold Function representation class.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:M3NEmzRMIkIC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"In this research work, we aim to formalize the analysis of Physically Unclonable Functions (PUF) constructions. First, we present a testability analysis scheme that leverages the correlation spectra properties of Boolean functions to assess the quality of a collection of PUF instances of the same make by comparing its correlation spectra with that of a collection of known good PUF instances. Further, in the research, we propose a CAD framework that automatically assesses the learnability of a PUF construction in the PAC Learning model. To represent a PUF design, we propose a formal PUF representation language capable of representing any PUF construction or composition upfront. Next, we present a non-linearity assisted reliability based ML attack on a contemporary PUF construction, named S n -PUF. We leverage the non-linearity of the Bent function to launch a reliability-based ML attack, that is able to break …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:isC4tDSrTZIC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"In this work, we prove that Multiplexer PUF~(MPUF) and -PUF are learnable in the PAC model. First, we show that both the designs can be represented as a function of Linear Threshold Functions. We show that the noise sensitivity of -MPUF and -PUF can be bounded by and respectively. Finally, we show that as a result of bounded noise sensitivity, both the designs can be accurately approximated using low degree algorithm. Also, the number of labelled examples~(challenge-response pairs) required by the algorithm is polynomial in the input length and PAC model parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:bEWYMUwI8FkC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"A large fraction of bugs discovered in the design flow of embedded control software (ECS) arises from the control software's interaction with the plant it controls. Traditional formal analysis approaches using interleaved controller-plant reach-set analysis grossly overapproximate the reachable states and does not scale. In this letter, we examine a verification approach that considers a control system with the (possibly nonlinear) plant dynamics and mode switches specified along with the actual control software implementation. Given this input, we generate a bounded-time safety verification problem encoded as satisfiability modulo theories (SMTs) constraints. We leverage δ-decidability over Reals to achieve scalability while verifying the control software.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:TQgYirikUcIC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Coverage monitoring is fundamental to design verification. Coverage artifacts are well developed for digital integrated circuits and these aim to cover the discrete state space and logical behaviors of the design. Analog designers are similarly concerned with the operating regions of the design and its response to an infinite and dense input space. Analog variables can influence each other in far more complex ways as compared to digital variables, consequently, the notion of cross coverage, as introduced in the analog context for the first time in this paper, is of high importance in analog design verification. This paper presents the formal syntax and semantics of analog cross coverage artifacts, the methods for evaluating them using our tool kit, and most importantly, the insights that can be gained from such cross coverage analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:ZeXyd9-uunAC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Testability of digital ICs rely on the principle of controllability and observability. Adopting conventional techniques like scan-chains open up avenues for attacks, and hence cannot be adopted in a straight-forward manner for security chips. Furthermore, testing becomes incredibly challenging for the promising class of hardware security primitives, called PUFs, which offer unique properties like unclonability, unpredictibility, uniformity, uniqueness, and yet easily computable. However, the definition of PUF itself poses a challenge on test engineers, simply because it has no golden response for a given input, often called challenge. In this paper, we develop a novel test strategy considering that the fabrication of a batch of PUFs is equivalent to drawing random instances of Boolean mappings. We hence model the PUFs as black-box Boolean functions of dimension , and show combinatorially that random designs of such functions exhibit correlation-spectra which can be used to characterize random and thus {\em good} designs of PUFs. We first develop theoretical results to quantize the correlation values, and subsequently the expected number of pairs of such Boolean functions which should belong to a given spectra. In addition to this, we show through extensive experimental results that a randomly chosen sample of such PUFs also resemble the correlation-spectra property of the overall PUF population. Interestingly, we show through experimental results on FPGAs that when the PUFs are infected by faults the usual randomness tests for the PUF outputs such as uniformity, fail to detect any aberration. However, the spectral-pattern is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:4DMP91E08xMC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"The weakest link in cryptosystems is quite often due to the implementation rather than the mathematical underpinnings. A vast majority of attacks in the recent past have targeted programming flaws and bugs to break security systems. Due to the complexity, empirically verifying such systems is practically impossible, while manual verification as well as testing do not provide adequate guarantees.
In this article, we leverage model checking techniques to prove the functional correctness of an elliptic curve cryptography (ECC) library with respect to its formal specification. We demonstrate how the huge state space of the C library can be aptly verified using a hierarchical assume-guarantee verification strategy. To test the scalability of this approach, we verify the correctness of five MST-specified elliptic curve implementations. We also verify the newer curve25519 elliptic curve, which is finding multiple applications, due …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:aqlVkmm33-oC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Due to the increasing complexity in the power management logic of low-power designs, formal validation of the architectural power intent, comprising of both digital and analog power management features, is becoming a crucial task. Consequently, the formal verification frontier has also been extended, in recent times, to ensure the correctness for analog as well as digital power intent. The quality of verification can be evaluated by formal coverage analysis which can be determined from the reachability of safe global power states by the power manager. This article proposes a novel formal method for computing the coverage of architectural power states for power management logic having analog components like LDOs and PLLs. The efficacy of the proposed method has been shown using an industry level case-study.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:qxL8FJ1GzNcC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Besides enormous research efforts in the design of Physically Unclonable Functions (PUFs), its vulnerabilities are still being exploited using machine learning (ML) based model-building attacks. Due to inherent complicacy in exploring and manually converging to a strong PUF composition, the challenge of building ML-attack resistant PUFs continues. Hence, it becomes imperative to develop an automated framework that can formally assess the learnability of different PUF constructions and compositions to guide the designer to explore resilient PUFs. In this work, we present an automated analysis framework (PARLE-G), to formally represent and evaluate the Probably Approximately Correct (PAC) learnability of PUF constructions and their compositions. A high-level specification language PUF-G has been developed to structurally represent any PUF composition comprising a specified set of primitive components …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:NaGl4SEjCO4C,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"With increasing design complexity, the portability of tests across different designs and platforms becomes a key criterion for accelerating verification closure. The Portable Test and Stimulus Standard (PSS) is an emerging industry standard prepared by Accellera for system-on-chip verification and testing. It provides language constructs to create a target-agnostic representation of stimulus and test scenarios reused by various users across many levels of integration. In this article, we present CoVerPlan, a comprehensive verification framework built to explore the power of action inferencing on test models written in PSS. The proposed verification framework leverages a Boolean satisfiability problem planner to unwind the actual verification flow from the PSS specifications and automatically synthesizes target-specific constraint-random testbenches and formal assertions. CoVerPlan also carries out assertion-based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:NMxIlDl6LWMC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"With the rapid advancement and increased use of deep learning models in image identification, security becomes a major concern to their deployment in safety-critical systems. Since the accuracy and robustness of deep learning models are primarily attributed from the purity of the training samples, therefore the deep learning architectures are often susceptible to adversarial attacks. Adversarial attacks are often obtained by making subtle perturbations to normal images, which are mostly imperceptible to humans, but can seriously confuse the state-of-the-art machine learning models. We propose a framework, named APuDAE, leveraging Denoising AutoEncoders (DAEs) to purify these samples by using them in an adaptive way and thus improve the classification accuracy of the target classifier networks that have been attacked. We also show how using DAEs adaptively instead of using them directly, improves classification accuracy further and is more robust to the possibility of designing adaptive attacks to fool them. We demonstrate our results over MNIST, CIFAR-10, ImageNet dataset and show how our framework (APuDAE) provides comparable and in most cases better performance to the baseline methods in purifying adversaries. We also design adaptive attack specifically designed to attack our purifying model and demonstrate how our defense is robust to that.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:YFjsv_pBGBYC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Component-based design paradigm is of paramount importance due to prolific growth in the complexity of modern-day systems. Since the components are developed primarily by multi-party vendors and often assembled to realize the overall system, it is an onus of the designer to certify both the functional and non-functional requirements of such systems. Several of the earlier works concentrated on formally analyzing the behavioral correctness, safety, security, reliability and robustness of such compositional systems. However, the assurance for quality measures of such systems is also considered as an important parameter for their acceptance. Formalization of quality measures is still at an immature state and often dictated by the user satisfaction. This paper presents a novel compositional framework for reliable quality analysis of component-based systems from the formal quality specifications of its constituent components. The proposed framework enables elegant and generic computation methods for quality attributes of various component-based system structures. In addition to this, we provide a formal query-driven quality assessment and design exploration framework which enables the designer to explore various component structures and operating setups and finally converge into better acceptable systems. A detailed case-study is presented over a component-based system structure to show the efficacy and practicality of our proposed framework.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:hMod-77fHWUC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Coverage is a key indicator for verification progress, verification closure, and verification sign-off in an integrated circuit design. The notion of coverage management, namely, the use of coverage information across the design hierarchy to identify verification loopholes, is well understood in the digital context, but requires considerable disambiguation in the analog/mixed-signal (AMS) context. This article develops the core artifacts of AMS coverage and presents a comprehensive coverage management approach based on our tool, CoveRT. Our results, gleaned from live industrial designs, demonstrate the benefits of AMS coverage management across the design hierarchy, both in terms of identifying verification gaps, as well as in finding design bugs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:JV2RwH3_ST0C,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Periodic signals and recurrent events are very common in Analog and Mixed-Signal (AMS) behaviours. Tracking attributes related to frequency and recurrent behaviours is an integral part of the verification coverage plan for AMS designs. It is straight-forward to validate periodic artefacts in a signal, such as frequency or duty cycle, when a reference value is provided. From a CAD perspective, the difficulty arises when a reference is not provided, and more so when a static reference does not exist. In this paper, we propose a novel methodology to compute various artefacts of a periodic signal algorithmically in absence of prior information regarding the periodic nature of the signal. We propose to encode the signal using a window-based partitioned sequence of literals and then operate over this sequence to glean out the relevant periodic artefacts. Our experiments performed on waveforms collected from industrial test …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:GnPB-g6toBAC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Multi-Agent Path Finding (MAPF) is the problem of finding collision-free paths for multiple agents from their start locations to end locations. We consider an extension to this problem, Precedence Constrained Multi-Agent Path Finding (PC-MAPF), wherein agents are assigned a sequence of planning tasks that contain precedence constraints between them. PC-MAPF has various applications, for example in multi-agent pickup and delivery problems where some objects might require multiple agents to collaboratively pickup and move them in unison. Precedence constraints also arise in warehouse assembly problems where before a manufacturing task can begin, its input resources must be manufactured and delivered. We propose a novel algorithm, Precedence Constrained Conflict Based Search (PC-CBS), which finds makespan-optimal solutions for this class of problems. PC-CBS utilizes a Precedence-Constrained Task-Graph to define valid intervals for each planning task and updates them when precedence conflicts are encountered. We benchmark the performance of this algorithm over various warehouse assembly, and multi-agent pickup and delivery tasks, and use it to evaluate the sub-optimality of a recently proposed efficient baseline.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:maZDTaKrznsC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Physically Unclonable Functions~(PUFs) with large challenge space~(also called Strong PUFs) are promoted for usage in authentications and various other cryptographic and security applications. In order to qualify for these cryptographic applications, the Boolean functions realized by PUFs need to possess a high non-linearity~(NL). However, with a large challenge space~(usually bits), measuring NL by classical techniques like Walsh transformation is computationally infeasible. In this paper, we propose the usage of a heuristic-based measure called non-homomorphicity test which estimates the NL of Boolean functions with high accuracy in spite of not needing access to the entire challenge-response set. We also combine our analysis with a technique used in linear cryptanalysis, called Piling-up lemma, to measure the NL of popular PUF compositions. As a demonstration to justify the soundness of the metric, we perform extensive experimentation by first estimating the NL of constituent Arbiter/Bistable Ring PUFs using the non-homomorphicity test, and then applying them to quantify the same for their XOR compositions namely XOR Arbiter PUFs and XOR Bistable Ring PUF. Our findings show that the metric explains the impact of various parameter choices of these PUF compositions on the NL obtained and thus promises to be used as an important objective criterion for future efforts to evaluate PUF designs. While the framework is not representative of the machine learning robustness of PUFs, it can be a useful complementary tool to analyze the cryptanalytic strengths of PUF primitives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:ns9cj8rnVeAC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"With the rapid advancement and increased use of deep learning models in image identification, security becomes a major concern to their deployment in safety-critical systems. Since the accuracy and robustness of deep learning models are primarily attributed from the purity of the training samples, therefore the deep learning architectures are often susceptible to adversarial attacks. Adversarial attacks are often obtained by making subtle perturbations to normal images, which are mostly imperceptible to humans, but can seriously confuse the state-of-the-art machine learning models. What is so special in the slightest intelligent perturbations or noise additions over normal images that it leads to catastrophic classifications by the deep neural networks? Using statistical hypothesis testing, we find that Conditional Variational AutoEncoders (CVAE) are surprisingly good at detecting imperceptible image perturbations. In this paper, we show how CVAEs can be effectively used to detect adversarial attacks on image classification networks. We demonstrate our results over MNIST, CIFAR-10 dataset and show how our method gives comparable performance to the state-of-the-art methods in detecting adversaries while not getting confused with noisy images, where most of the existing methods falter.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:k_IJM867U9cC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Exploring the limits of an Analog and Mixed Signal (AMS) circuit by driving appropriate inputs has been a serious challenge to the industry. Doing an exhaustive search of the entire input state space is a time-consuming exercise and the returns to efforts ratio is quite low. In order to meet time-to-market requirements, often suboptimal coverage results of an integrated circuit (IC) are leveraged. Additionally, no standards have been defined which can be used to identify a target in the continuous state space of analog domain such that the searching algorithm can be guided with some heuristics. In this report, we elaborate on two approaches for tackling this challenge - one is based on frequency domain analysis of the circuit, while the other applies the concept of Bayesian optimization. We have also presented our results by applying the two approaches on an industrial LDO and a few AMS benchmark circuits.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:iH-uZ7U-co4C,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"In order to cope up with the growing performance demands, rapid increase in the transistor density in modern on-chip cores has made power dissipation a primary concern for the chip-designers. Chip temperature surpasses thermal limits at multiple hot-spots which significantly affects its performance and reliability. This work explores the possibility of readjusting the task schedules intelligently under real-time constraints, so that the on-chip power and thermal profiles remain within admissible limits. Our target platform is a homogeneous multicore environment with Dynamic Voltage and Frequency Scaling (DVFS) capabilities. We use multi-objective optimization techniques to restrict power dissipation under thermal constraints. We also use Reinforcement Learning (RL) using Proximal Policy Optimization (PPO) to readjust task schedules based on a set of proposed reward functions and energy optimization …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:4JMBOYKVnBMC,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"The design of the power management logic (PML) of complex low-power system-on-chip (SoC) designs is rooted in the expected workload patterns in the target architecture. The increasing functionality of SoCs is complimented by increasingly diverse usage patterns among its users, leading to a situation where the same device is power efficient for some user and power inefficient for others. This letter positions the potential benefits of personalizing the PML in SoCs leveraging that the global power management strategy resides in firmware.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:hFOr9nPyWt4C,http://cse.iitkgp.ac.in/~aritrah/
Aritra Hazra,"['Formal Methods', 'Design Verification', 'Computer-Aided Design', 'Electronic Design Automation']",10,"Reliability and fault tolerance are critical attributes of embedded cyber-physical systems that require a high safety-integrity level. For such systems, the use of formal functional safety specifications has been strongly advocated in most industrial safety standards, but reliability and fault tolerance have traditionally been treated as platform issues. We believe that addressing reliability and fault tolerance at the functional safety level widens the scope for resource optimization, targeting those functionalities that are safety-critical, rather than the entire platform. Moreover, for software based control functionalities, temporal redundancies have become just as important as replication of physical resources, and such redundancies can be modeled at the functional specification level. The ability to formally model functional reliability at a specification level enables early estimation of physical resources and computation bandwidth requirements. In this paper we propose, for the first time, a resource estimation methodology from a formal functional safety specification augmented by reliability annotations. The proposed reliability specification is overlaid on the safety-critical functional specification and our methodology extracts a constraint satisfaction problem for determining the optimal set of resources for meeting the reliability target for the safety-critical behaviors. We use SMT (Satisfiability Modulo Theories) / ILP (Integer Linear Programming) solvers at the back end to solve the optimization problem, and demonstrate the feasibility of our methodology on a Satellite Launch Vehicle Navigation, Guidance and Control (NGC) System.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nYazw20AAAAJ&cstart=20&pagesize=80&citation_for_view=nYazw20AAAAJ:qUcmZB5y_30C,http://cse.iitkgp.ac.in/~aritrah/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"We study exact algorithms for Euclidean TSP in R d . In the early 1990s algorithms with n O(√n) running time were presented for the planar case, and some years later an algorithm with n O(n1-1/d) running time was presented for any d ≥ 2. Despite significant interest in subexponential exact algorithms over the past decade, there has been no progress on Euclidean TSP, except for a lower bound stating that the problem admits no 2 O (n 1-1/d-ε ) algorithm unless ETH fails. Up to constant factors in the exponent, we settle the complexity of Euclidean TSP by giving a 2 O(n1-1/d) algorithm and by showing that a 2 o(n1-1/d) algorithm does not exist unless ETH fails.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&citation_for_view=TIz3qpUAAAAJ:hqOjcs7Dif8C,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"Given a 1.5-dimensional terrain T, also known as an x-monotone polygonal chain, the Terrain Guarding problem seeks a set of points of minimum size on T that guards all of the points on T. Here, we say that a point p guards a point q if no point of the line segment pq is strictly below T. The Terrain Guarding problem has been extensively studied for over 20 years. In 2005 it was already established that this problem admits a constant-factor approximation algorithm (SODA 2005). However, only in 2010 King and Krohn (SODA 2010) finally showed that Terrain Guarding is NP-hard. In spite of the remarkable developments in approximation algorithms for Terrain Guarding, next to nothing is known about its parameterized complexity. In particular, the most intriguing open questions in this direction ask whether, if parameterized by the size k of a solution guard set, it admits a subexponential-time algorithm and whether it is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&citation_for_view=TIz3qpUAAAAJ:3fE2CSJIrl8C,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"A rectilinear Steiner tree for a set K of points in the plane is a tree that connects k using horizontal and vertical lines. In the Rectilinear Steiner Tree problem, the input is a set K={z1,z2,…, zn} of n points in the Euclidean plane (R2), and the goal is to find a rectilinear Steiner tree for k of smallest possible total length. A rectilinear Steiner arborescence for a set k of points and a root r ∈ K is a rectilinear Steiner tree T for K such that the path in T from r to any point z ∈ K is a shortest path. In the Rectilinear Steiner Arborescence problem, the input is a set K of n points in R2, and a root r ∈ K, and the task is to find a rectilinear Steiner arborescence for K, rooted at r of smallest possible total length. In this article, we design deterministic algorithms for these problems that run in 2O(√ nlog n) time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&citation_for_view=TIz3qpUAAAAJ:0EnyYjriUFMC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"In this paper, we study the query complexity of parameterized decision and optimization versions of {\sc Hitting-Set}, {\sc Vertex Cover}, {\sc Packing} , \match{} and {\sc Max-Cut}. The main focus is the query complexity of {\sc Hitting Set}. In doing so, we use an oracle known as \bis{} introduced by Beame et al.~\cite{BeameHRRS18} and its generalizations to hypergraphs. The query models considered are the \gpis{} and \gpise{} oracles : (i) the \gpis{} oracle takes as input pairwise disjoint non-empty vertex subsets in a hypergraph and answers whether there is a hyperedge with vertices in each , (ii) the \gpise{} oracle takes the same input and returns a hyperedge that has vertices in each ; NULL, otherwise. The \gpis{} and \gpise{} oracles are used for the decision and optimization versions of the problems, respectively. For , we refer \gpis{} and \gpise{} as \bis{} and \bise{}, respectively. We use color coding and queries to the oracles to generate subsamples from the hypergraph, that retain some structural properties of the original hypergraph. We use the stability of the sunflowers in a non-trivial way to do so.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&citation_for_view=TIz3qpUAAAAJ:Y0pCki6q_DkC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"Given a graph , a -open neighborhood conflict-free coloring or -ONCF-coloring is a vertex coloring such that for each vertex there is a vertex in that is uniquely colored from the rest of the vertices in . When we replace by the closed neighborhood , then we call such a coloring a -closed neighborhood conflict-free coloring or simply -CNCF-coloring. In this paper, we study the NP-hard decision questions of whether for a constant an input graph has a -ONCF-coloring or a -CNCF-coloring. We will study these two problems in the parameterized setting. First of all, we study running time bounds on fixed-parameter tractable algorithms for these problems when parameterized by treewidth. We improve the existing upper bounds, and also provide lower bounds on the running time under the exponential time hypothesis and the strong exponential time hypothesis. Second, we study the kernelization complexity of both …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&citation_for_view=TIz3qpUAAAAJ:KlAtU1dfN6UC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"The Terrain Guarding problem is a well-known variant of the famous Art Gallery problem. Only second to Art Gallery, it is the most well-studied visibility problem in Discrete and Computational Geometry, which has also attracted attention from the viewpoint of Parameterized complexity. In this paper, we focus on the parameterized complexity of Terrain Guarding (both discrete and continuous) with respect to two natural parameters. First we show that, when parameterized by the number r of reflex vertices in the input terrain, the problem has a polynomial kernel. We also show that, when parameterized by the number c of minima in the terrain, Discrete Orthogonal Terrain Guarding has an XP algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&citation_for_view=TIz3qpUAAAAJ:qxL8FJ1GzNcC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"A harmonious coloring of a graph is a partitioning of its vertex set into parts such that, there are no edges inside each part, and there is at most one edge between any pair of parts. It is known that finding a minimum harmonious coloring number is NP-hard even in special classes of graphs like trees and split graphs. We initiate a study of parameterized and exact exponential time complexity of harmonious coloring. We consider various parameterizations like by solution size, by above or below known guaranteed bounds and by the vertex cover number of the graph. While the problem has a simple quadratic kernel when parameterized by the solution size, our main result is that the problem is fixed-parameter tractable when parameterized by the size of a vertex cover of the graph. This is shown by reducing the problem to multiple instances of fixed variable integer linear programming. We also observe that it is W [1 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&citation_for_view=TIz3qpUAAAAJ:IjCSPb-OGe4C,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"The study of parameterized streaming complexity on graph problems was initiated by Fafianie et al. (MFCS’14) and Chitnis et al. (SODA’15 and SODA’16). In this work, we initiate a systematic study of parameterized streaming complexity of graph deletion problems – -Subgraph deletion, -Minor deletion in the four most well-studied streaming models: the (edge arrival), (dynamic edge arrival), (vertex arrival) and Al (adjacency list) models. Our main conceptual contribution is to overcome the obstacles to efficient parameterized streaming algorithms by utilizing the power of parameterization. We focus on the vertex cover size K as the parameter for the parameterized graph deletion problems we consider. At the same time, most of the previous work in parameterized streaming complexity was restricted to the Ea (edge arrival) or Dea (dynamic edge arrival) models. In this work, we consider the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:Zph67rFs4hoC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"We study the Steiner Tree problem on unit disk graphs. Given a n vertex unit disk graph G, a subset of t vertices and a positive integer k, the objective is to decide if there exists a tree T in G that spans over all vertices of R and uses at most k vertices from . The vertices of R are referred to as terminals and the vertices of as Steiner vertices. First, we show that the problem is NP-hard. Next, we prove that the Steiner Tree problem on unit disk graphs can be solved in time. We also show that the Steiner Tree problem on unit disk graphs parameterized by k has an FPT algorithm with running time . In fact, the algorithms are designed for a more general class of graphs, called clique-grid graphs Fomin (Discret. Comput. Geometry 62(4):879–911, 2019). We mention that the algorithmic results can be made to work for Steiner Tree problem on disk graphs with bounded aspect ratio. Finally …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:M3ejUd6NZC8C,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"Winning lottery tickets refer to sparse subgraphs of deep neural networks which have classification accuracy close to the original dense networks. Resilient connectivity properties of such sparse networks play an important role in their performance. The attempt is to identify a sparse and yet well-connected network to guarantee unhindered information flow. Connectivity in a graph is best characterized by its spectral expansion property. Ramanujan graphs are robust expanders which lead to sparse but highly-connected networks, and thus aid in studying the winning tickets. A feedforward neural network consists of a sequence of bipartite graphs representing its layers. We analyze the Ramanujan graph property of such bipartite layers in terms of their spectral characteristics using the Cheeger’s inequality for irregular graphs. It is empirically observed that the winning ticket networks preserve the Ramanujan graph property and achieve a high accuracy even when the layers are sparse. Accuracy and robustness to noise start declining as many of the layers lose the property. Next we find a robust winning lottery ticket by pruning individual layers while retaining their respective Ramanujan graph property. This strategy is observed to improve the performance of existing network pruning algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:9ZlFYXVOiuMC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"Given metric spaces (X, DX) and (Y, DY), an embedding F: X → Y is an injective mapping from X to Y. Expansion eF and contraction cF of an embedding F: X → Y are defined as
eF = maxx;1, x2 (≠ x1) ∈ X DY(F(x1), F(x2))/ DX(x1, x2) and cF = maxx1, x2 (≠ x1) ∈ X DX(x1, x2)/DY(F(x1), F(x2)),
respectively, and distortion dF is defined as dF= eF ⋅ cF. Observe that dF ≥ 1. An embedding F : X → Y is noncontracting if cF ≤ 1. When d=1, then F is isometry.
The Metric Embedding problem takes as input two metric spaces (X,DX) and (Y,DY), and a positive integer d. The objective is to determine whether there is an embedding F: X → Y such that dF ≤ d. Such an embedding is called a distortion d embedding. The bijective Metric Embedding problem is a special case of the Metric Embedding problem where ∣X∣ = ∣Y∣. In parameterized complexity, the Metric Embedding problem, in full generality, is known to be W …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:u-x6o8ySG0sC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"Given a graph G and a pair (F1, F2) of graph families, the function GDISJG,F1,F2 takes as input, two induced subgraphs G1 and G2 of G, such that G1 ∈ F1 and G2 ∈ F2 and returns 1 if V(G1)∩ V(G2)=∅ and 0 otherwise. We study the communication complexity of this problem in the two-party model. In particular, we look at pairs of hereditary graph families. We show that the communication complexity of this function, when the two graph families are hereditary, is sublinear if and only if there are finitely many graphs in the intersection of these two families. Then, using concepts from parameterized complexity, we obtain nuanced upper bounds on the communication complexity of GDISJG, F1, F2. A concept related to communication protocols is that of a (F1, F2)-separating family of a graph G. A collection F of subsets of V(G) is called a (F1,F2)-separating family for G, if for any two vertex disjoint induced subgraphs G1 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:kNdYIx-mwKoC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"Conflict-free coloring of hypergraphs is a very well studied question of theoretical and practical interest. For a hypergraph , a conflict-free coloring of refers to a vertex coloring where every hyperedge has a vertex with a unique color, distinct from all other vertices in the hyperedge. In this paper, we initiate a study of a natural maximization version of this problem, namely, Max-CFC: For a given hypergraph and a fixed , color the vertices of using colors so that the number of hyperedges that are conflict-free colored is maximized. By previously known hardness results for conflict-free coloring, this maximization version is NP-hard. We study this problem in the context of both exact and parameterized algorithms. In the parameterized setting, we study this problem with respect to a natural parameter---the solution size. In particular, the question we study is the following: p-CFC: For a given hypergraph, can we conflict-free …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:zYLM7Y9cAGgC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"The b-Exact Multicover problem takes a universe U of n elements, a family of m subsets of U, a function and a positive integer k, and decides whether there exists a subfamily(set cover) of size at most k such that each element u ∈ U is covered by exactly dem(u) sets of . The b-Exact Coverage problem also takes the same input and decides whether there is a subfamily such that there are at least k elements that satisfy the following property: u ∈ U is covered by exactly dem(u) sets of . Both these problems are known to be NP-complete. In the parameterized setting, when parameterized by k, b-Exact Multicover is W[1]-hard even when b = 1. While b-Exact Coverage is FPT under the same parameter, it is known to not admit a polynomial kernel under standard complexity-theoretic assumptions, even when b = 1. In this paper, we investigate these two problems under the assumption that every …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:mVmsd5A6BfQC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"In the Graph bipartization (or Odd Cycle Transversal) problem, the objective is to decide whether a given graph G can be made bipartite by the deletion of k vertices for some given k. The parameterized complexity of Odd Cycle Transversal was resolved in the breakthrough paper of Reed, Smith and Vetta [Operations Research Letters, 2004], who developed an algorithm running in time O (3 k k m n). The question of improving the dependence on the input size to linear, which was another long standing open problem in the area, was resolved by Iwata et al.[SICOMP 2016] and Ramanujan and Saurabh [TALG 2017], who presented O (4 k (m+ n)) and 4 k k O (1)(m+ n) algorithms respectively. In this paper, we obtain a faster algorithm that runs in time 3 k k O (1)(m+ n) and hence preserves the linear dependence on the input size while nearly matching the dependence on k incurred by the algorithm of Reed, Smith and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:YOwf2qJgpHMC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"The study of parameterized streaming complexity on graph problems was initiated by Fafianie et al. (MFCS'14) and Chitnis et al. (SODA'15 and SODA'16). Simply put, the main goal is to design streaming algorithms for parameterized problems such that space is enough, where is an arbitrary computable function depending only on the parameter . However, in the past few years, very few positive results have been established. Most of the graph problems that do have streaming algorithms of the above nature are ones where localized checking is required, like Vertex Cover or Maximum Matching parameterized by the size of the solution we are seeking. Many important parameterized problems that form the backbone of traditional parameterized complexity are known to require bits for any streaming algorithm; e.g., Feedback Vertex Set, Even/Odd Cycle Transversal, Triangle Deletion or the more general -Subgraph Deletion when parameterized by solution size . Our main conceptual contribution is to overcome the obstacles to efficient parameterized streaming algorithms by utilizing the power of parameterization. To the best of our knowledge, this is the first work in parameterized streaming complexity that considers structural parameters instead of the solution size as a parameter. We focus on the vertex cover size as the parameter for the parameterized graph deletion problems we consider. At the same time, most of the previous work in parameterized streaming complexity was restricted to the EA (edge arrival) or DEA (dynamic edge arrival) models. In this work, we consider the above mentioned graph deletion …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:aqlVkmm33-oC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"Given a symmetric lxl matrix M=(m_ {i, j}) with entries in {0, 1,*}, a graph G and a function L: V (G)-> 2^{[l]}(where [l]={1, 2,..., l}), a list M-partition of G with respect to L is a partition of V (G) into l parts, say, V_1, V_2,..., V_l such that for each i, j in {1, 2,..., l},(i) if m_ {i, j}= 0 then for any u in V_i and v in V_j, uv not in E (G),(ii) if m_ {i, j}= 1 then for any (distinct) u in V_i and v in V_j, uv in E (G),(iii) for each v in V (G), if v in V_i then i in L (v). We consider the Deletion to List M-Partition problem that takes as input a graph G, a list function L: V (G)-> 2^[l] and a positive integer k. The aim is to determine whether there is a k-sized set S subseteq V (G) such that GS has a list M-partition. Many important problems like Vertex Cover, Odd Cycle Transversal, Split Vertex Deletion, Multiway Cut and Deletion to List Homomorphism are special cases of the Deletion to List M-Partition problem. In this paper, we provide a classification of the parameterized complexity of Deletion to List M-Partition, parameterized by k,(a) when M is of order at most 3, and (b) when M is of order 4 with all diagonal entries belonging to {0, 1}.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:ULOm3_A8WrAC,http://cse.iitkgp.ac.in/~skolay/
Sudeshna Kolay,"['Parameterized Complexity', 'Computational Geometry']",11,"The Point Hyperplane Cover problem in takes as input a set of n points in and a positive integer k. The objective is to cover all the given points with a set of at most k hyperplanes. The D-Polynomial Points Hitting Set (D-Polynomial Points HS) problem in takes as input a family of D-degree polynomials from a vector space in , and determines whether there is a set of at most k points in that hit all the polynomials in . For both problems, we exhibit tight kernels where k is the parameter.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=TIz3qpUAAAAJ&cstart=20&pagesize=80&citation_for_view=TIz3qpUAAAAJ:UeHWp8X0CEIC,http://cse.iitkgp.ac.in/~skolay/
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Although, the usefulness of the machine learning (ML) technique in predicting future outcomes has been established in different domains of applications (e.g., heath care), its exploration in predicting accidents in occupational safety domain is almost new. This necessitates the investigation of ML techniques in predicting accidents. But, ML-based algorithms cannot produce the best performance until its parameters are properly tuned or optimized. Moreover, only the selection of efficient optimized classifier may not fulfil the overall decision-making purposes as it cannot explain the inter-relationships among the factors behind the occurrence of accidents. Hence, in addition to prediction, decision-making rules are required to be extracted from the accident data. Considering the above-mentioned issues, in this research, optimized machine learning algorithms have been applied to predict the accident outcomes such as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&citation_for_view=5bXSZPYAAAAJ:BAanoTsO0WEC,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"The traditional databases are not capable of handling unstructured data and high volumes of real-time datasets. Diverse datasets are unstructured lead to big data, and it is laborious to store, manage, process, analyze, visualize, and extract the useful insights from these datasets using traditional database approaches. However, many technical aspects exist in refining large heterogeneous datasets in the trend of big data. This paper aims to present a generalized view of complete big data system which includes several stages and key components of each stage in processing the big data. In particular, we compare and contrast various distributed file systems and MapReduce-supported NoSQL databases concerning certain parameters in data management process. Further, we present distinct distributed/cloud-based machine learning (ML) tools that play a key role to design, develop and deploy data models …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&citation_for_view=5bXSZPYAAAAJ:M_lZXyI38BkC,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Object detection and tracking is one of the most important and challenging branches in computer vision, and have been widely applied in various fields, such as health-care monitoring, autonomous driving, anomaly detection, and so on. With the rapid development of deep learning (DL) networks and GPU’s computing power, the performance of object detectors and trackers has been greatly improved. To understand the main development status of object detection and tracking pipeline thoroughly, in this survey, we have critically analyzed the existing DL network-based methods of object detection and tracking and described various benchmark datasets. This includes the recent development in granulated DL models. Primarily, we have provided a comprehensive overview of a variety of both generic object detection and specific object detection models. We have enlisted various comparative results for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:NZNkWSpQBv0C,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Contemporary deep learning based semantic inpainting can be approached from two directions. First, and the more explored, approach is to train an offline deep regression network over the masked pixels with an additional refinement by adversarial training. This approach requires a single feed-forward pass for inpainting at inference. Another promising, yet unexplored approach is to first train a generative model to map a latent prior distribution to natural image manifold and during inference time search for the best-matching prior to reconstruct the signal. The primary aversion towards the latter genre is due to its inference time iterative optimization and difficulty to scale to higher resolution. In this paper, going against the general trend, we focus on the second paradigm of inpainting and address both of its mentioned problems. Most importantly, we learn a data driven parametric network to directly predict a matching prior for a given masked image. This converts an iterative paradigm to a single feed forward inference pipeline with around 800X speedup. We also regularize our network with structural prior (computed from the masked image itself) which helps in better preservation of pose and size of the object to be inpainted. Moreover, to extend our model for sequence reconstruction, we propose a recurrent net based grouped latent prior learning. Finally, we leverage recent advancements in high resolution GAN training to scale our inpainting network to 256X256. Experiments (spanning across resolutions from 64X64 to 256X256) conducted on SVHN, Standford Cars, CelebA, CelebA-HQ and ImageNet image datasets, and FaceForensics video …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:S2WlVNSe3u4C,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"In this article, two new models, namely granulated RCNN (G-RCNN) and multi-class deep SORT (MCD-SORT), for object detection and tracking, respectively from videos are developed. Object detection has two stages: object localization (region of interest RoI) and classification. G-RCNN is an improved version of the well-known Fast RCNN and Faster RCNN for extracting RoIs by incorporating the unique concept of granulation in a deep convolutional neural network. Granulation with spatio-temporal information enables more accurate extraction of RoIs (object regions) in unsupervised mode. Compared to Fast and Faster RCNNs, G-RCNN uses (i) granules (clusters) formed over the pooling feature map, instead of its all feature values, in defining RoIs, (ii) only the positive RoIs during training, instead of the whole RoI-map, (iii) videos directly as input, rather than static images, and (iv) only the objects in RoIs …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:hKjooKYXoHIC,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Hydrological impacts of global climate change on regional scale are generally assessed by downscaling large-scale climatic variables, simulated by General Circulation Models (GCMs), to regional, small-scale hydrometeorological variables like precipitation, temperature, etc. In this study, we propose a new statistical downscaling model based on Recurrent Neural Network with Long Short-Term Memory which captures the spatio-temporal dependencies in local rainfall. The previous studies have used several other methods such as linear regression, quantile regression, kernel regression, beta regression, and artificial neural networks. Deep neural networks and recurrent neural networks have been shown to be highly promising in modeling complex and highly non-linear relationships between input and output variables in different domains and hence we investigated their performance in the task of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:cBPnxVikjH8C,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Normalized Difference Vegetation Index (NDVI) is widely used as an efficient indicator of vegetation cover. Here we assess the possibility of using NDVI as an indicator of groundwater storage. We used groundwater level (GWL) obtained from in situ groundwater observation wells (n > 15,000) in India in 2005–2013. Good correlation (r > 0.6) is observed between NDVI and GWL in natural vegetation‐covered areas, that is, forest lands, shrubs, and grasslands. We apply artificial neural network and support vector machine approaches to investigate the relationship between GWL and NDVI using both of the parameters as input. Artificial neural network‐ and support vector machine‐simulated GWL matches very well with observed GWL, particularly in naturally vegetated areas. Thus, we interpret that NDVI may be used as a suitable indicator of groundwater storage conditions in certain areas where the water table is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:DquSII9TDu4C,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Ultrasound imaging is generally employed for real-time investigation of internal anatomy of the human body for disease identification. Delineation of the anatomical boundary of organs and pathological lesions is quite challenging due to the stochastic nature of speckle intensity in the images, which also introduces visual fatigue for the observer. This paper introduces a fully convolutional neural network based method to segment organ and pathologies in ultrasound volume by learning the spatial-relationship between closely related classes in the presence of stochastically varying speckle intensity. We propose a convolutional encoder-decoder like framework with (i) feature concatenation across matched layers in encoder and decoder and (ii) index passing based unpooling at the decoder for semantic segmentation of ultrasound volumes. We have experimentally evaluated the performance on publicly available …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:0ngZmJvimKcC,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Automatic processing of figurative languages is gaining popularity in NLP community for their ubiquitous nature and increasing volume. In this era of web 2.0, automatic analysis of sarcasm and metaphors is important for their extensive usage. Metaphors are a part of figurative language that compares different concepts, often on a cognitive level. Many approaches have been proposed for automatic detection of metaphors, even using sequential models or neural networks. In this paper, we propose a method for detection of metaphors at the token level using a hybrid model of Bidirectional-LSTM and CRF. We used fewer features, as compared to the previous state-of-the-art sequential model. On experimentation with VUAMC, our method obtained an F-score of 0.674.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:TGkaJS32XoUC,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"The study of climatic variables that govern the Indian summer monsoon has been widely explored. In this work, we use a non-linear deep learning-based feature reduction scheme for the discovery of skilful predictors for monsoon rainfall with climatic variables from various regions of the globe. We use a stacked autoencoder network along with two advanced machine learning techniques to forecast the Indian summer monsoon. We show that the predictors such as the sea surface temperature and zonal wind can predict the Indian summer monsoon one month ahead, whereas the sea level pressure can predict ten months before the season. Further, we also show that the predictors derived from a combination of climatic variables can outperform the predictors derived from an individual variable. The stacked autoencoder model with combined predictors of sea surface temperature and sea level pressure can predict …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:wBLCggQE-ToC,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Ultrasound (US) is widely used as a low-cost alternative to computed tomography or magnetic resonance and primarily for preliminary imaging. Since speckle intensity in US images is inherently stochastic, readers are often challenged in their ability to identify the pathological regions in a volume of a large number of images. This paper introduces a generalized approach for volumetric segmentation of structures in US images and volumes. We employ an iterative random walks (IRW) solver, a random forest learning model, and a gradient vector flow (GVF) based interframe belief propagation technique for achieving cross-frame volumetric segmentation. At the start, a weak estimate of the tissue structure is obtained using estimates of parameters of a statistical mechanics model of US tissue interaction. Ensemble learning of these parameters further using a random forest is used to initialize the segmentation pipeline …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:8VtEwCQfWZkC,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"In this paper, we introduce a system named Portable Personality Recognizer (PPR), which classifies the personality of an individual using his/her transitions of affective states. This work attempts to reveal the latent relationship between emotions and personality of a person. Here, we train a hidden Markov model (HMM) with observable emotional states viz. Happiness (H), Anger (A), Surprise (S) and Disgust (D) and the hidden traits viz. Psychoticism (P), Extraversion (E) and Neuroticism (N). Based on the model, the system estimates the personality as Psychotic, Extravert or Neurotic. It does so by capturing the facial images of an individual using a visible and a thermal camera to decide the present affective state of the person. The emotion classification is carried out using fused eigenfeatures from the visible and blood perfused thermal images. The emotional state changes are observed using the trained HMM to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:J3LtWjKFLicC,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Co-morbid disease condition refers to the simultaneous presence of one or more diseases along with the primary disease. A patient suffering from co-morbid diseases possess more mortality risk than with a disease alone. So, it is necessary to predict co-morbid disease pairs. In past years, though several methods have been proposed by researchers for predicting the co-morbid diseases, not much work is done in prediction using knowledge graph embedding using tensor factorization. Moreover, the complex-valued vector-based tensor factorization is not being used in any knowledge graph with biological and biomedical entities. We propose a tensor factorization based approach on biological knowledge graphs. Our method introduces the concept of complex-valued embedding in knowledge graphs with biological entities. Here, we build a knowledge graph with disease-gene associations and their corresponding …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:X5YyAB84Iw4C,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"The convergence of spectroscopy and imaging technologies, emerge into a single sensing technology i.e., provides spatial and spectral information of the objects under investigation. The hyperspectral technique is one of the popular techniques used in numerous fields of study to determine size, shape, texture, material composition, morphology and external defects. The main advantage of this sensing technology lies in the fact that it is capable not only makes direct assessment of the material under study but also it can indicate the spatial distribution of the selected parameters. The aim of this paper is to present a detailed outline of the principles, background, acquisition methods, component descriptions and recent advances of the hyperspectral imaging systems for laboratory and industrial environments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:hefNtdE4IMkC,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Hyperspectral imaging is one of the promising remote sensing techniques. This technique records the spatial and spectral information of the object under study. Consequently, it has been gaining momentum in a number of Earth observing applications. The aim of this paper is to present the current trends of hyperspectral sensing from different platforms and instruments for various applications. For Earth observation, mobile platforms are discussed which include spaceborne, airborne, ground-based sensing, unmanned aerial system, and underwater vehicle-based. Under these different sensing platforms, hyperspectral imaging instruments are presented that have been developed by various public and private organizations in the past with some specific goals.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:aDl3D7KC1E4C,http://cse.iitkgp.ac.in/~pabitra
Pabitra Mitra,"['Machine learning', 'pattern recognition', 'data mining', 'information retrieval']",45,"Biometric recognition is a trending technology that uses unique characteristics data to identify or verify/authenticate security applications. Amidst the classically used biometrics, voice and face attributes are the most propitious for prevalent applications in day-to-day life because they are easy to obtain through restrained and user-friendly procedures. The pervasiveness of low-cost audio and face capture sensors in smartphones, laptops, and tablets has made the advantage of voice and face biometrics more exceptional when compared to other biometrics. For many years, acoustic information alone has been a great success in automatic speaker verification applications. Meantime, the last decade or two has also witnessed a remarkable ascent in face recognition technologies. Nonetheless, in adverse unconstrained environments, neither of these techniques achieves optimal performance. Since audio-visual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5bXSZPYAAAAJ&cstart=20&pagesize=80&citation_for_view=5bXSZPYAAAAJ:vxA22ZmNLkoC,http://cse.iitkgp.ac.in/~pabitra
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"There are different modes of interaction with a software keyboard on a smartphone, such as typing and swyping. Patterns of such touch interactions on a keyboard may reflect emotions of a user. Since users may switch between different touch modalities while using a keyboard, therefore, automatic detection of emotion from touch patterns must consider both modalities in combination to detect the pattern. In this paper, we focus on identifying different features of touch interactions with a smartphone keyboard that lead to a personalized model for inferring user emotion. Since distinguishing typing and swyping activity is important to record the correct features, we designed a technique to correctly identify the modality. The ground truth labels for user emotion are collected directly from the user by periodically collecting self-reports. We jointly model typing and swyping features and correlate them with user provided self …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&citation_for_view=mQ57itUAAAAJ:SeFeTyx0c_EC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Network embedding, that aims to learn low-dimensional vector representation of nodes such that the network structure is preserved, has gained significant research attention in recent years. However, most state-of-the-art network embedding methods are computationally expensive and hence unsuitable for representing nodes in billion-scale networks. In this paper, we present LouvainNE, a hierarchical clustering approach to network embedding. Precisely, we employ Louvain, an extremely fast and accurate community detection method, to build a hierarchy of successively smaller subgraphs. We obtain representations of individual nodes in the original graph at different levels of the hierarchy, then we aggregate these representations to learn the final embedding vectors. Our theoretical analysis shows that our proposed algorithm has quasi-linear run-time and memory complexity. Our extensive experimental …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&citation_for_view=mQ57itUAAAAJ:bFI3QPDXJZMC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"A large population of users gets affected by sudden slowdown or shutdown of an enterprise application. System administrators and analysts spend considerable amount of time dealing with functional and performance bugs. These problems are particularly hard to detect and diagnose in most computer systems, since there is a huge amount of system generated supportability data (counters, logs etc.) that need to be analyzed. Most often, there isn't a very clear or obvious root cause. Timely identification of significant change in application behavior is very important to prevent negative impact on the service. In this paper, we present ADELE, an empirical, data-driven methodology for early detection of anomalies in data storage systems. The key feature of our solution is diligent selection of features from system logs and development of effective machine learning techniques for anomaly prediction. ADELE learns from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&citation_for_view=mQ57itUAAAAJ:NMxIlDl6LWMC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"The rate of mental health disorders is rising across the globe. While it significantly affects the quality of life, an early detection can prevent the fatal consequences. Existing literature suggests that mobile based sensing technology can be used to determine different mental health conditions like stress, bipolar disorder. In today's smartphone based communication, a significant portion is based on instant messaging apps like WhatsApp; thus providing the opportunity to unobtrusively monitor the text input interaction pattern to track mental state. We, in this paper, leverage on the text entry pattern to track multiple emotion states. We design, develop and implement an Android based smartphone keyboard EmoKey, which monitors user's typing pattern and determines four emotion states (happy, sad, stressed, relaxed) by developing an on-device, personalized machine learning model. We evaluate EmoKey with 22 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&citation_for_view=mQ57itUAAAAJ:ldfaerwXgEUC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Identification of influential users in online social networks allows to facilitate efficient information diffusion to a large part of the network and thus benefiting diverse applications including viral marketing, disease control, and news dissemination. Existing methods have mainly relied on the network structure only for the detection of influential users. In this paper, we enrich this approach by proposing a fast, efficient, and unsupervised algorithm SmartInf to detect a set of influential users by identifying anchor nodes from a temporal sequence of retweets in Twitter cascades. Such anchor nodes provide important signatures of tweet diffusion across multiple diffusion localities and, hence, act as precursors for detection of influential nodes. 1 The set of influential nodes identified by SmartInf has the capacity to expose the tweet to a large and diverse population, when targeted as seeds thereby maximizing the influence spread …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&citation_for_view=mQ57itUAAAAJ:pqnbT2bcN3wC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Smartphones provide the capability to perform in-situ sampling of human behavior using Experience Sampling Method (ESM). Designing an ESM schedule involves probing the user repeatedly at suitable moments to collect self-reports. Timely probe generation to collect high fidelity user responses while keeping probing rate low is challenging. In mobile-based ESM, timeliness of the probe is also impacted by user's availability to respond to self-report request. Thus, a good ESM design must consider - probing frequency , timely self-report collection , and notifying at opportune moment to ensure high response quality . We propose a two-phase ESM design, where the first phase (a) balances between probing frequency and self-report timeliness, and (b) in parallel, constructs a predictive model to identify opportune probing moments. The second phase uses this model to further improve response quality by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&citation_for_view=mQ57itUAAAAJ:M05iB0D1s5AC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Event-based online social platforms, such as Meetup and Plancast, have experienced increased popularity and rapid growth in recent years. In EBSN setup, selecting suitable venues for hosting events, which can attract a great turnout, is a key challenge. In this paper, we present a deep learning based venue recommendation system DeepVenue which provides context driven venue recommendations for the Meetup event-hosts to host their events. The crux of the proposed model relies on the notion of similarity between multiple Meetup entities such as events, venues, groups, etc. We develop deep learning techniques to compute a compact descriptor for each entity, such that two entities (say, venues) can be compared numerically. Notably, to mitigate the scarcity of venue related information in Meetup, we leverage on the cross domain knowledge transfer from popular LBSN service Yelp to extract rich venue …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:fPk4N6BV_jEC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"The growth in the market for cab companies like Uber has opened the door to high-income options for drivers. However, in order to boost their income, drivers many a time resort to accepting trips which increases their stress resulting in poor driving quality and accidents in serious cases. Every driver handles stress differently and the trip recommendation thus needs to be on a personalized level. In this paper, we explore historical trip data to compute the driving stress and its impact on various driving behavioral features, captured through vehicle-mounted GPS and inertial sensors. We utilize a Multi-task Learning based Neural Network model to learn both the common features and the personalized features from the driving data to predict the stress level of a driver. We further establish a causal relationship between the stress level of a driver and his driving behavior. Finally, we develop a trip recommendation system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:HoB7MX3m0LUC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Passenger comfort is a major factor influencing a commuter's decision to avail public transport. Existing studies suggest that factors like overcrowding, jerkiness, traffic congestion etc. correlate well to passenger's (dis)comfort. An online survey conducted with more than 300 participants from 12 different countries reveals that different personalized and context dependent factors influence passenger comfort during a travel by public transport. Leveraging on these findings, we identify correlations between comfort level and these dynamic parameters, and implement a smartphone based application, ComfRide, which recommends the most comfortable route based on user's preference honoring her travel time constraint. We use a 'Dynamic Input/Output Automata' based composition model to capture both the wide varieties of comfort choices from the commuters and the impact of environment on the comfort parameters …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:YFjsv_pBGBYC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"In an organization, individuals preferto form various formal and informal groups for mutual interactions. Therefore, ubiquitous identification of such groups and understanding their dynamics are important to monitor activities, behaviors, and well-being of the individuals. In this paper, we develop a lightweight, yet near-accurate, methodology, called GroupSense, to identify various interacting groups based on collective sensing through users' smartphones. Group detection from sensor signals is not straightforward because users in proximity may not always be under the same group. Therefore, we use acoustic context extracted from audio signals to infer the interaction pattern among the subjects in proximity. We have developed an unsupervised and lightweight mechanism for user group detection by taking cues from network science and measuring the cohesivity of the detected groups regarding modularity. Taking …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:M3NEmzRMIkIC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Characteristics of typing on smartphone keyboards among different individuals can elicit emotion, similar to speech prosody or facial expressions. Existing works on typing based emotion recognition rely on feature engineering to build machine learning models, while recent speech and facial expression based techniques have shown the efficacy of learning the features automatically. Therefore, in this work, we explore the effectiveness of such learning models in keyboard interaction based emotion detection. In this paper, we propose an end-to-end framework, which first uses a sequence-based encoding method to automatically learn the representation from raw keyboard interaction pattern and subsequently uses this representation to train a multi-task learning based neural network (MTL-NN)to identify different emotions. We carry out a 3-week in-the-wild study involving 24 participants using a custom keyboard …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:yD5IFk8b50cC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Typing based interfaces are common across many mobile applications, especially messaging apps. To reduce the difficulty of typing using keyboard applications on smartphones, smartwatches with restricted space, several techniques, such as auto-complete, auto-suggest, are implemented. Although helpful, these techniques do add more cognitive load on the user. Hence beyond the importance to improve the word recommendations, it is useful to understand the pattern of use of auto-suggestions during typing. Among several factors that may influence use of auto-suggest, the role of emotion has been mostly overlooked, often due to the difficulty of unobtrusively inferring emotion. With advances in affective computing, and ability to infer user's emotional states accurately, it is imperative to investigate how auto-suggest can be guided by emotion aware decisions. In this work, we investigate correlations between user …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:35N4QoGY0k4C,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Network embedding, that learns low-dimensional node representations in a graph such that the network structure is preserved, has gained significant attention in recent years. Most state-of-the-art embedding methods have mainly designed algorithms for representing nodes in unsigned social networks. Moreover, recent embedding approaches designed for the sparse real-world signed networks have several limitations, especially in the presence of a vast majority of disconnected node pairs with opposite polarities towards their common neighbors. In this paper, we propose sign2vec, a deep learning based embedding model designed to represent nodes in a sparse signed network. sign2vec leverages on signed random walks to capture the higher-order neighborhood relationships between node pairs, irrespective of their connectivity. We design a suitable objective function to optimize the learned node …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:g5m5HwL7SMYC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"In day to day life, people meet strangers while commuting in public transports, roaming around in a shopping mall, waiting at airport boarding areas etc., and thus form passively encountering groups. Detection and analysis of such groups are essential for providing services like targeted advertisements, supply chain management, information broadcasting and so on. However, identifying such groups is challenging because of the underlying dynamics, where an encounter between two subjects is entirely instantaneous without having a specific pattern. This problem has two steps - (a) identification of subjects in proximity and (b) detecting groups from the proximity information. In this paper, we develop an unsupervised model to identify subjects in proximity based on WiFi signal information and assign a proximity score to each pair of subjects based on a novel metric defining the degree of proximity. With the help of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:70eg2SAEIzsC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"With the increase in road fatalities due to various factors like aggressive driving and road rage, quantifying and monitoring the stress level of a driver is an important task for the preparation of driving rosters for the cab companies. Stress monitoring using physiological sensors is a costly and obstructive task, while stress factors impact differently for different individuals based on their personality traits. In this paper, we develop a learning-based model to predict the stress level of a driver and its effect on his driving behavior, solely based on spatio-temporal driving data collected through GPS and inertial sensors. We further establish a correlation between the stress level of a driver and his driving behavior; thus, we develop a complete system to infer stress profiling and its impact on driving behavior based on spatio-temporal driving data. The model has been tested over a publicly available dataset with 6 drivers for 500 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:ns9cj8rnVeAC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Annotated IMU sensor data from smart devices and wearables are essential for developing supervised models for fine-grained human activity recognition, albeit generating sufficient annotated data for diverse human activities under different environments is challenging. Existing approaches primarily use human-in-the-loop based techniques, including active learning; however, they are tedious, costly, and time-consuming. Leveraging the availability of acoustic data from embedded microphones over the data collection devices, in this paper, we propose LASO, a multimodal approach for automated data annotation from acoustic and locomotive information. LASO works over the edge device itself, ensuring that only the annotated IMU data is collected, discarding the acoustic data from the device itself, hence preserving the audio-privacy of the user. In the absence of any pre-existing labeling information, such an auto-annotation is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:CHSYGLWDkRkC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"In an Experience Sampling Method (ESM) based emotion self-report collection study, engaging participants for a long period is challenging due to the repetitiveness of answering self-report probes. This often impacts the self-report collection as participants dropout in between or respond with arbitrary responses. Self-reflection (or commonly known as analyzing past activities to operate more efficiently in the future) has been effectively used to engage participants in logging physical, behavioral, or psychological data for Quantified Self (QS) studies. This motivates us to apply self-reflection to improve the emotion self-report collection procedure. We design, develop, and deploy a self-reflection interface and augment it with a smartphone keyboard-based emotion self-report collection application. The interface provides feedback to the users regarding the relation between typing behavior and self-reported emotions. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:abG-DnoFyZgC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Although public transport vehicles such as buses have always been an economical means of commuting in the cities of many developing countries, it is always considered as a secondary mode of transport owing to poor infrastructure, chaotic and reckless driving habits, and absence of any proper information system in buses. Based on rigorous experiments carried out over a period of two years and multiple surveys, we have tried to learn the problems faced by bus commuters. As a solution, in this article, we develop a novel energy-efficient system which would help commuters navigate through their journey safely. Along with making them aware of any upcoming points of concerns (PoCs) such as sudden bumps, sharp turns, and bad roads, we also inform commuters about the expected time of arrival at the destination. The system makes use of several landmarks such as speed breakers, turns, and bus stops on a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:_xSYboBqXhAC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Businesses are one of the major stakeholders of the location-based social network (LBSN) platform. Predicting popularity of businesses in LBSN can help in future business planning and design of effective marketing strategies for business owners. In this paper, we introduce four simple modalities that serve as prime indicators of business popularity, namely, (a) social influence, (b) geographical proximity, (c) customer preference and (d) textual content of tips and reviews posted for a business and investigate their role on business popularity. Characterizing business popularity is ambiguous as there exist different viewpoints to measure popularity. We propose a principled methodology to properly label the popular and unpopular businesses by systematically defining popularity metrics specific to business categories. Social influence essentially represents the peer pressure for visiting certain businesses and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:NaGl4SEjCO4C,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Recent context detection techniques in smartphones leverage on the embedded motion sensors, which in turn increases the potential of side-channel attacks. We in this paper propose an alternative modality for obtaining mobility context using smartphone keyboard interaction patterns using a personalized framework. Experimental results show that the framework can predict the mobility context at an average F1 score (both micro and macro) greater than 0.6 across all subjects.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:GnPB-g6toBAC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Shift of research interest is an inherent part of a scientific career. Accordingly, researchers tend to migrate from one field of research to another. In this paper, we systematically study the publication records of more than 200, 000 researchers working in Computer Science domain and propose a simple algorithm to identify the migrating researchers. Just like human migration, this kind of research field migration is driven by various latent factors. Inspired by the classical theories of human migration, here we present a theoretical framework which models the decision-making processes of the individual migrating researchers and helps us to derive those latent factors. We further investigate the impact of these key factors in regulating a researcher’s decision to migrate to a specific research field and observe the effect of such migration on her career. We note that in general publication quantity & quality, collaborator profile, fields’ popularity contribute to a researcher’s decision of field-migration. Importantly, effects of migration are not only limited to just one individual’s career but also extend to the prospect of the research fields associated with it. Despite few initial capacity issues, field migration in general contribute in flourishing the research field people migrate into, in long term.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:ZHo1McVdvXMC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Typing characteristics on smartphones can provide clues for emotion detection. Collecting large volumes of typing data is also easy on smartphones. This motivates the use of Deep Neural Network (DNN) to determine emotion states from smartphone typing. In this work, we developed a DNN model based on typing features to predict four emotion states (happy, sad, stressed, relaxed) and investigate its performance on a smartphone. The evaluation of the model in a 3-week study with 15 participants reveals that it can reliably detect emotions with an average accuracy of 80% with peak CPU utilization less than 15%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:BqipwSGYUEgC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Annotating on-road driving behavior is essential for various applications like app-cabs, behavior-based insurance, etc. However, existing platforms for driving behavior analysis mainly focus on the impacts of different on-road maneuvers taken by a driver. This paper establishes that analyzing the causes behind the driving maneuvers is essential to characterize the driving behavior correctly. Accordingly, we develop DriveIn, a smartphone-based pervasive sensing system that explores both causes and impacts of driving maneuvers from video, GPS, and inertial sensor data to score a driver based on a thorough understanding of their on-road driving behavior. We evaluate DriveIn with datasets for three countries and observe that a score obtained by considering such causality factors provides a better insight into the driving behavior compared to the naive approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:738O_yMBCRsC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Recently “network science” has been bridging various disciplines like mathematics, physics, biology, chemistry, computer science, ecology, and the social sciences. This is mainly due to its wide perspective in modeling the structure and dynamics of complex systems, both natural and man-made, with different, large, or even multiple scales. Some examples include genetic networks, food web, trade networks, the World Wide Web (WWW), collaboration networks, power grids, and air traffic networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:3s1wT3WcHBgC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Keyboard interaction patterns on a smartphone is the input for many intelligent emotion-aware applications, such as adaptive interface, optimized keyboard layout, automatic emoji recommendation in IM applications. The simplest approach, called the Experience Sampling Method (ESM), is to systematically gather self-reported emotion labels from users, which act as the ground truth labels, and build a supervised prediction model for emotion inference. However, as manual self-reporting is fatigue-inducing and attention-demanding, the self-report requests are to be scheduled at favorable moments to ensure high fidelity response. We, in this paper, perform fine-grain keyboard interaction analysis to determine suitable probing moments. Keyboard interaction patterns, both cadence, and latency between strokes, nicely translate to frequency and time domain analysis of the patterns. In this paper, we perform a 3-week …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:nb7KW1ujOQ8C,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Groups in online social networks witness continuous evolution by loss of existing members and gain of new members. In this paper, we present a study of group split in Meetup, where a major fraction of members leave the existing group together and join a newly formed group. We identify pivotal group members, called splitters, playing key roles in group split by influencing the existing members to leave the group. We provide an in-depth analysis of the empirical data to reveal key motivating factors leading to a group split and its subsequent impact. Finally, we develop a prediction model for early detection of splitters, as well as the group members likely to be influenced by the splitter to leave the group.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:NhqRSupF_l8C,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"This paper investigates the role of mentions on tweet propagation. We propose a novel tweet propagation model based on a multiplex network framework which allows to analyze the effects of mentioning on final retweet count. The basic bricks of this model are supported by a comprehensive study of multiple real datasets, and simulations of the model show a nice agreement with the empirically observed tweet popularity. Studies and experiments also reveal that follower count, retweet rate and profile similarity are important factors for gaining tweet popularity and allow to better understand the impact of the mention strategies on the retweet count. Interestingly, we experimentally identify a critical retweet rate regulating the role of mention on the tweet popularity. Finally, our data-driven simulations demonstrate that the proposed mention recommendation heuristic Easy-Mention outperforms the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:JV2RwH3_ST0C,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"In today's world, we are having enough user name and passwords to remember; often causing accounts to be locked due to forgetting them. Here, we propose a different perspective of login, where you only need to remember your recent activities on the smartphones, which will be posed in such a way that a genuine user could easily answer. The proposed system will collect the events happening on the phone and put intelligent algorithms to generate challenges specific to user. The challenge-response will give a score to the user, where a threshold is set to allow or disallow user from entering into the system. The proposed model uses machine learning based techniques to learn user's behavior and creates a continuously improving user profile. The system found to be effective with 85% accuracy, where out of 30 real world test users 26 could easily able to authenticate themselves.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:pyW8ca7W8N0C,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Twitter is currently a popular microblogging platform for the dissemination of information by users in the form of messages such as tweets. Such tweets are shared with followers of the seed user who in turn may reshare it with their own set of followers. Long chain of such retweets form cascades. In this paper, we aim to estimate the influence tree of cascades denoting the who-influenced-whom relationship among retweeting users by leveraging on temporal pattern of its retweets. We use a principled methodology to construct the ground truth influence trees of cascades using standard diffusion models. We define diverse structural metrics to quantify the structural characteristics of different influence trees. Based on empirical observations from ground truth, we develop CasCon, an unsupervised model that leverages on temporal pattern of retweets obtained from time series of cascades and underlying follower network …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:J_g5lzvAfSwC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Monitoring students’ engagement and understanding their learning pace in a virtual classroom becomes challenging in the absence of direct eye contact between the students and the instructor. Continuous monitoring of eye gaze and gaze gestures may produce inaccurate outcomes when the students are allowed to do productive multitasking, such as taking notes or browsing relevant content. This paper proposes Stungage – a software wrapper over existing online meeting platforms to monitor students’ engagement in real-time by utilizing the facial video feeds from the students and the instructor coupled with a local on-device analysis of the presentation content. The crux of Stungage is to identify a few opportunistic moments when the students should visually focus on the presentation content if they can follow the lecture. We investigate these instances and analyze the students’ visual, contextual, and cognitive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:Tiz5es2fbqcC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Monitoring driving behavior is essential to ensure on-road safety. Although driving is a collective, cooperative task among the drivers of the neighboring vehicles, existing platforms for driving behavior analysis solely rely on different on-road maneuvers taken by a driver. By analyzing a large volume of publicly available data over two countries and in-house collected data, this paper argues that analyzing driving behavior needs treatment over different factors which compel a driver to take maneuvers that are otherwise recommended to be avoided. Consequently, we develop DriBe. This smartphone-based pervasive sensing system utilizes video, GPS, and inertial sensor data to investigate the causes and consequences of driving maneuvers to score a driver based on a thorough understanding of their on-road driving behavior. Considering that the causality factors are very much specific to a particular driving …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:8AbLer7MMksC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"An individual’s cognitive and functional abilities are commonly assessed through physical and mental status examination, observational performance measures, surveys and proxy reports of symptoms. These strategies are not ideal for early impairment detection as the individual needs to be present physically at the clinic to avail the assessments, especially for older adults who require assistance from a caregiver, and experience mobility, cognitive and functional disabilities from neurodegenerative disorders. Moreover, these strategies rely on self-reporting and proxy reports for evaluation which often leads to under-reporting of symptoms and decrease the validity of these measures. We argue that an early assessment of functional, and cognitive health impairment can be obtained from the individual’s daily activities captured through accelerometry. In this work, we postulate to learn high-level motion related …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:WbkHhVStYXYC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Educational systems have witnessed a rapid transformation from the traditional physical classroom to the online teaching mode due to the COVID-19 pandemic. This sudden shift throws two significant questions to the educational policymakers and system designers. (1) How can an instructor improve the teaching performance over an online teaching platform? (2) How does the instructor understand the students’ learning pace? For answering these questions, we propose a platform in this paper that analyzes the real-time presentation video and the facial video feeds from the instructor as well as the students to explore the visual engagement of the student towards the lecture contents. However, this is challenging as the students may get involved in various multitasking instances, such as taking notes or browsing relevant reading materials. The crux of this paper is to understand a few real-time opportunistic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:uWQEDVKXjbEC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Event-based social networking platforms such as Meetup have recently witnessed a huge growth. However, with the rise in the volume of groups and events, making individual events attractive has become increasingly challenging for its organizers. As a result, we find that events hosted by groups of same category at similar venues and similar times, also widely differ in their popularity. Data study reveals that the topics specified in textual descriptions of events may be key to their popularity. In this paper, we introduce a novel concept of topical micro-categories in the context of EBSNs for accurately characterizing events, such that events belonging to the same micro-category exhibit similar popularity profile. We develop a principled method to detect such micro-categories from the textual descriptions of individual events. Our experiments reveal the significance of the detected micro-categories in determining the popularity of associated Meetup events and groups. We also investigate the effectiveness of the micro-categories in a real-world application scenario by developing a recommendation model; this model recommends relevant micro-categories to a group for hosting its future events with enhanced popularity. Notably, our model achieves an average NDCG score of around 0.75 showing a straight 5% improvement over the best performing competing method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:dshw04ExmUIC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"The COVID-19 pandemic directly impacts educational systems worldwide. Although the online mode of education is the most viable solution under this scenario, it introduces new challenges to the course instructors. Primarily in the low and middle-economy countries, the majority of instructors do not have access to touch-enabled devices like tablets to mimic board-works, from where students can generate the class-notes. Pertaining to these constraints, in this paper, we propose an online note-generation system – Note-on-Watch, using community-off-the-shelf smartwatches and smartphones, leveraging the rapid and huge penetration of these devices across these countries. In Note-on-Watch, the instructor writes a text over a vertical board while wearing the smartwatch, and the locomotive data from the smartwatch is captured over a smartphone to regenerate the text to mimic on-device writing. We implement a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:P5F9QuxV20EC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Driving is a complex task carried out under the influence of diverse spatial objects and their temporal interactions. Therefore, a sudden fluctuation in driving behavior can be due to either a lack of driving skill or the effect of various on-road spatial factors such as pedestrian movements, peer vehicles' actions, etc. Therefore, understanding the context behind a degraded driving behavior just-in-time is necessary to ensure on-road safety. In this paper, we develop a system called \ourmethod{} that exploits the information acquired from a dashboard-mounted edge-device to understand the context in terms of micro-events from a diverse set of on-road spatial factors and in-vehicle driving maneuvers taken. \ourmethod{} uses the live in-house testbed and the largest publicly available driving dataset to generate human interpretable explanations against the unexpected driving events. Also, it provides a better insight with an improved similarity of \% over hours of driving data than the existing driving behavior characterization techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:fQNAKQ3IYiAC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Smartphone keyboard interaction based emotion detection systems are used widely to provide value-added services such as mental health monitoring, keyboard layout optimization, guided response generation. At the core of these services lie a machine learning model, which automatically infers emotion based on keyboard interaction pattern. To train these models, the emotion ground truth labels are typically collected as emotion self-report by conducting an Experience Sampling Method (ESM) based study. However, as responding to repetitive self-report probes is time-consuming and fatigue-inducing, efficient self-report collection approaches are essential that avoid probing at inopportune moments and reduce survey fatigue. To address this problem, we propose an active learning based framework, ALOE (Active Learning based Opportunistic Experience Sampling for Emotion Self-report Collection) that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:LPZeul_q3PIC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Commuter comfort in cab rides affects driver rating as well as the reputation of ride-hailing firms like Uber/Lyft. Existing research has revealed that commuter comfort not only varies at a personalized level but also is perceived differently on different trips for the same commuter. Furthermore, there are several factors, including driving behavior and driving environment, affecting the perception of comfort. Automatically extracting the perceived comfort level of a commuter due to the impact of the driving behavior is crucial for a timely feedback to the drivers, which can help them to meet the commuter’s satisfaction. In light of this, we surveyed around 200 commuters who usually take such cab rides and obtained a set of features that impact comfort during cab rides. Following this, we develop a system Ridergo which collects smartphone sensor data from a commuter, extracts the spatial time series feature from the data, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:UxriW0iASnsC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"In recent years, non-invasive human activity recognition (HAR) has gathered huge momentum using locomotive sensors. However, for effective HAR, there is a need for a significant volume of annotated data. Typically, the conventional practices for gathering HAR annotations have relied on human annotators. Nevertheless, the growing volume of data often leads to the collection of shallow annotations, which in most cases ignore the fine-grained micro-activities that constitute any complex activities of daily living (ADL). Understanding this, we, in this paper, try to develop the framework AmicroN that can automatically generate micro-activity annotations using locomotive signatures. To achieve this, in the backend, AmicroN applies change-point detection for the precise detection of activity boundaries followed by zero-shot learning with verb attributes to identify the unseen micro-activities without any external supervision …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:4fKUyHm3Qg0C,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"This demo presents AmicroN which automatically generates fine-grained annotations using locomotive signatures. In the backend, AmicroN exploits short-duration macro labels already present in a pre-annotated dataset. It uses zero-shot learning to identify the finer micro-activities present within a coarse-grain macro-activity label.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:tS2w5q8j5-wC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Severe road accidents are reported regularly across the globe due to drivers getting distracted while using their smartphones. To prevent such fatalities, one possible approach is to make the smartphone intelligent enough to detect whether it is being used by the driver, thus providing restricted access to the applications while driving. However, this problem is challenging as the driver can behave like an adversary to fool the system; therefore, additional devices or forward communication cannot be used. This paper proposes a novel approach of smartphone localization within a car by exploiting the ambient mechanical noise within the vehicle. We utilize the periodic nature of such mechanical noises to develop a simple yet satisfactorily accurate approach, called Blah, that can utilize the acoustic properties from the ambient mechanical noise within the car to detect whether the driver or the passenger is using the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:5Ul4iDaHHb8C,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Multiuser activity recognition has been the core of different context-aware services. However, the development of such services is often plagued by the dearth of multiuser datasets. This paper presents a strategy for generating synthetic multiuser datasets by augmenting existing real-life datasets. The described strategy exploits pre-cise time synchronization and well-known audio augmentation approaches to generate a multimodal activity recognition dataset with locomotive and acoustic signatures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:tOudhMTPpwUC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Keystroke or typing dynamics represent two key facets - rhythm corresponds to spectral-domain characteristics and timing corresponds to time-domain behavior, which are created when a person types. The presence of inherent time-domain and frequency-domain characteristics in smartphone keyboard interactions motivate us to perform a comparative analysis of time-domain and frequency-domain features for emotion detection. We design, and develop an Android-based data collection application, which collects keyboard interaction logs and emotion self-reports (happy, sad, stressed, relaxed) from 18 subjects in a 3-week in-the-wild study. For the time-domain analysis, we extract a set of time-domain features and construct Random Forest-based personalized model; whereas for the spectral-domain analysis, first transform the interaction details into frequency-domain using DFT (Discrete Fourier Transform) and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:K3LRdlH-MEoC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Emotions have an enormous impact on our momentary performance, health, and way of relating to others, hence on the quality of a persons’ life. In particular, the experience of unpleasant (or pleasant) emotions is directly related to an individual’s well-being. Emotions are influenced by subjective experiences and memories and the context the individual is in, and it seems almost impossible to measure this phenomenon objectively, reliably, and validly. Indeed, capturing human emotional states has been a challenging task for researchers for decades, leading to numerous theories about emotions, moods, and feelings. Specifically, psychometrics focuses on the theory and techniques of psychological measurements, including the QoL measurements. The emerging field of affective computing promises to overcome some methodological difficulties that lead to limitations in traditional methods of psychometrics. Affective computing is the study of technologies that can quantitatively measure human emotion from different clues. It is based on the hypothesis that an individual’s digital footprint is highly correlated with their perceptions, feelings, and resulting behaviors and that extracting and analyzing this data collected",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:XiSMed-E-HIC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"The rapid usage of smartphones while driving is a significant concern leading to distracted driving behavior, causing severe accidents, as listed out by the US National Highway Traffic Safety Administration. Assessing the smartphone’s location inside the car is advantageous to such applications. Existing studies try to locate the smartphone using external equipment, such as camera, Bluetooth, network jammers, etc. [1–3]. However, the drivers can tamper with such external equipment, being the adversary for such a system. This poster aims to find out the relative position of a smartphone inside a car blindly without any specialized external hardware. We leverage the acoustic properties inside a running vehicle to locate whether the driver or a passenger uses the smartphone.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:p2g8aNsByqUC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"This paper presents a smartwatch-based application, called WatchScribe, to convert any wall writing to virtual board-works. Users can scribe anything over this virtual whiteboard with zero-bootstrapping by mimicking the writing on the wall with a pen. Transcribing wall-writing with a smartwatch is challenging because of two reasons. (a) As the smartwatch's orientation changes continuously due to wrist movements, the pen's locus is different from that of the smartwatch. (b) There are events when the user lifts the pen from the whiteboard and starts at a different position to draw the next stroke. WatchScribe leverages locomotive data from a smartwatch to estimate the pen's locus using an unsupervised method. Further, it uses a lightweight approach to extract the writing micro-gestures from the estimated pen's locus and reproduces a real-time transcription of the wall-writing. We apply qualitative human-driven and novel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:SP6oXDckpogC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Human activities within smart infrastructures generate a vast amount of IMU data from the wearables worn by individuals. Many existing studies rely on such sensory data for human activity recognition (HAR); however, one of the major bottlenecks is their reliance on pre-annotated or labeled data. Manual human-driven annotations are neither scalable nor efficient, whereas existing auto-annotation techniques heavily depend on video signatures. Still, video-based auto-annotation needs high computation resources and has privacy concerns when the data from a personal space, like a smart-home, is transferred to the cloud. This paper exploits the acoustic signatures generated from human activities to label the wearables' IMU data at the edge, thus mitigating resource requirement and data privacy concerns. We utilize acoustic-based pre-trained HAR models for cross-modal labeling of the IMU data even when two individuals perform simultaneous but different activities under the same environmental context. We observe that non-overlapping acoustic gaps exist with a high probability during the simultaneous activities performed by two individuals in the environment's acoustic context, which helps us resolve the overlapping activity signatures to label them individually. A principled evaluation of the proposed approach on two real-life in-house datasets further augmented to create a dual occupant setup, shows that the framework can correctly annotate a significant volume of unlabeled IMU data from both individuals with an accuracy of () and (), respectively, for a workshop and a kitchen environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:OU6Ihb5iCvQC,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Recent advances in acoustic sensing have led to the rapid proliferation in the deployment of microphones in smart-environments. This, in turn, has allowed the infrastructure to capture various types of ambient noise as a part of the contextual information. In this paper, we explore one such possibility of using acoustic signatures generated by human activities to distinguish individuals performing the activities continuously. We achieve this by developing an automated machine learning-based framework, trained on basic acoustic features, that can identify the users from the acoustic signatures generated by their activities. However, developing such a system has several associated challenges. This paper identifies those challenges and performs a preliminary evaluation of the system to determine the current approach's limitations and possible future directions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:KxtntwgDAa4C,http://cse.iitkgp.ac.in/~bivasm/
Bivas Mitra,"['Social networks', 'Data science', 'Socio-mobile applications']",19,"Most of the latest context-based applications capture the mobility of a user using Inertial Measurement Unit (IMU) sensors like accelerometer and gyroscope which do not need explicit user-permission for application access. Although these sensors provide highly accurate mobility context information, existing studies have shown that they can lead to undesirable leakage of location information. To evade this breach of location privacy, many of the state-of-the-art studies suggest to impose stringent restrictions over the usage of IMU sensors. However, in this paper, we show that typing and smartphone engagement patterns can act as an alternative modality to sniff the mobility context of a user, even if the IMU sensors are not sampled at all. We develop an adversarial framework, named ConType, which exploits the signatures exposed by typing and smartphone engagement patterns to track the mobility of a user …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mQ57itUAAAAJ&cstart=20&pagesize=80&citation_for_view=mQ57itUAAAAJ:b0M2c_1WBrUC,http://cse.iitkgp.ac.in/~bivasm/
