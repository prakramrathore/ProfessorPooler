Professor Name,Interests,h-index,Citations,Year,Abstracts,Link,Home_page
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2023,"The multi-sentential long sequence textual data unfolds several interesting research directions pertaining to natural language processing and generation. Though we observe several high-quality long-sequence datasets for English and other monolingual languages, there is no significant effort in building such resources for code-mixed languages such as Hinglish (code-mixing of Hindi-English). In this paper, we propose a novel task of identifying multi-sentential code-mixed text (MCT) from multilingual articles. As a use case, we leverage multilingual articles from two different data sources and build a first-of-its-kind multi-sentential code-mixed Hinglish dataset i.e., MUTANT. We propose a token-level language-aware pipeline and extend the existing metrics measuring the degree of code-mixing to a multi-sentential framework and automatically identify MCT in the multilingual articles. The MUTANT dataset comprises 67k articles with 85k identified Hinglish MCTs. To facilitate future research, we make the publicly available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:BUYA1_V_uYcC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2022,"Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:AvfA0Oy_GE0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2022,"Scientific documents contain tables that list important information in a concise fashion. Structure and content extraction from tables embedded within PDF research documents is a very challenging task due to the existence of visual features like spanning cells and content features like mathematical symbols and equations. Most existing table structure identification methods tend to ignore these academic writing features. In this paper, we adapt the transformer-based language modeling paradigm for scientific table structure and content extraction. Specifically, the proposed model converts a tabular image to its corresponding LaTeX source code. Overall, we outperform the current state-of-the-art baselines and achieve an exact match accuracy of 70.35 and 49.69% on table structure and content extraction, respectively. Further analysis demonstrates that the proposed models efficiently identify the number of rows and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:ipzZ9siozwsC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2022,"Stock market investors debate and heavily discuss stock ideas, investing strategies, news and market movements on social media platforms. The discussions are significantly longer in length and require extensive domain expertise for understanding. In this paper, we curate such discussions and construct a first-of-its-kind of abstractive summarization dataset. Our curated dataset consists of 7888 Reddit posts and manually constructed summaries for 400 posts. We robustly evaluate the summaries and conduct experiments on SOTA summarization tools to showcase their limitations. We plan to make the dataset publicly available. The sample dataset is available here: https://dhyeyjani. github. io/RSMC",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:7T2F9Uy0os0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2022,"Tsunamis, power blackouts, and distribution systems failure drastically affect the networked infrastructure systems which further affect a countries economy. Moreover, if these systems reach critical thresholds, they may experience disproportionate losses in the system’s functionality. Here we propose an approach to identify the critical thresholds and observe the presence of warning regions for real-world transportation systems. While attack tolerance of networked systems has been intensively studied for the disruptions originating from a single point of failure, there have been instances where real-world systems are subject to concurrent disruptions at multiple locations. We determine the entire robustness characteristics of transportation networks of disparate architecture subject to disruptions of varying sizes. Using United States Airspace Airport network and Indian Railways Network data, and synthetic networks as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:UHK10RUVsp4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2022,"Language models are increasingly becoming popular in AI-powered scientific IR systems. This paper evaluates popular scientific language models in handling (i) short-query texts and (ii) textual neighbors. Our experiments showcase the inability to retrieve relevant documents for a short-query text even under the most relaxed conditions. Additionally, we leverage textual neighbors, generated by small perturbations to the original text, to demonstrate that not all perturbations lead to close neighbors in the embedding space. Further, an exhaustive categorization yields several classes of orthographically and semantically related, partially related, and completely unrelated neighbors. Retrieval performance turns out to be more influenced by the surface form rather than the semantics of the text.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:W5xh706n7nkC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2022,"Computers are devices that execute precise instructions provided to them using various programming languages. However, the idea of delivering instructions to a computer through natural language could vastly simplify the act of programming as a specific task. Generating code from high-level descriptions for a given program is a significantly challenging task and has been an active area of research in the natural language processing domain. In this paper, we present a novel feedback-based deep learning approach for synthesizing code from human-specified descriptions. Inspired by the dual-learning mechanism, our framework uses a feedback loss to produce more consistent and robust predictions. We show how our approach fares empirically on standard code generation datasets and achieves state-of-the-art results on the NAPS (Natural Program Synthesis) dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:uLbwQdceFCQC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2022,"Several studies in the fields of Artificial Intelligence and Natural Language Processing have been conducted on Music Synthesis. However, due to the limited availability of structured datasets, the field of Indian Classical Music remains unexplored. Additionally, the considerable influence of western music in the past decade has adversely affected the market and demand for Indian Classical Music. In this work, we propose a model to generate music for Indian Classical Music, specifically Carnatic Music, by leveraging the structured nature of Indian Carnatic Music. We build a dataset of Classical Indian Music with paired lyrics and melody to map melody with notes to extract features. Generative Adversarial Networks (GANs) are proven to be very effective for music generation in several research works. We experiment with GANs and Auto Encoder (Variational AE and Conditional VAE) on classical lyrics. The curated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:JQOojiI6XY0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2022,"This tutorial will elaborate on various available resources for the natural language generation (NLG) tasks in code-mixed languages. We will also discuss the adaptability, limitations, and challenges with various evaluation metrics for the code-mixed NLG. In addition, we will put forward a set of open research questions pertaining to the tasks, resources, experiments, and metrics for the code-mixed NLG.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:hkOj_22Ku90C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Comparing research papers is a conventional method to demonstrate progress in experimental research. We present COMPARE, a taxonomy and a dataset of comparison discussions in peer reviews of research papers in the domain of experimental deep learning. From a thorough observation of a large set of review sentences, we build a taxonomy of categories in comparison discussions and present a detailed annotation scheme to analyze this. Overall, we annotate 117 reviews covering 1,800 sentences. We experiment with various methods to identify comparison sentences in peer reviews and report a maximum F1 Score of 0.49. We also pretrain two language models specifically on ML, NLP, and CV paper abstracts and reviews to learn informative representations of peer reviews. The annotated dataset and the pretrained models are available at https://github.com/shruti-singh/COMPARE.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:ZuybSZzF8UAC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Nowadays, researchers have moved to platforms like Twitter to spread information about their ideas and empirical evidence. Recent studies have shown that social media affects the scientific impact of a paper. However, these studies only utilize the tweet counts to represent Twitter activity. In this paper, we propose TweetPap, a large-scale dataset that introduces temporal information of citation/tweets and the metadata of the tweets to quantify and understand the discourse of scientific papers on social media. The dataset is publicly available at https://github.com/lingo-iitgn/TweetPap.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:_B80troHkn4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"In this shared task, we seek the participating teams to investigate the factors influencing the quality of the code-mixed text generation systems. We synthetically generate code-mixed Hinglish sentences using two distinct approaches and employ human annotators to rate the generation quality. We propose two subtasks, quality rating prediction and annotators' disagreement prediction of the synthetic Hinglish dataset. The proposed subtasks will put forward the reasoning and explanation of the factors influencing the quality and human perception of the code-mixed text.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:WqliGbK-hY8C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Code-mixing is a phenomenon of mixing words and phrases from two or more languages in a single utterance of speech and text. Due to the high linguistic diversity, code-mixing presents several challenges in evaluating standard natural language generation (NLG) tasks. Various widely popular metrics perform poorly with the code-mixed NLG tasks. To address this challenge, we present a metric independent evaluation pipeline MIPE that significantly improves the correlation between evaluation metrics and human judgments on the generated code-mixed text. As a use case, we demonstrate the performance of MIPE on the machine-generated Hinglish (code-mixing of Hindi and English languages) sentences from the HinGE corpus. We can extend the proposed evaluation strategy to other code-mixed language pairs, NLG tasks, and evaluation metrics with minimal to no effort.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:eq2jaN3J8jMC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Text generation is a highly active area of research in the computational linguistic community. The evaluation of the generated text is a challenging task and multiple theories and metrics have been proposed over the years. Unfortunately, text generation and evaluation are relatively understudied due to the scarcity of high-quality resources in code-mixed languages where the words and phrases from multiple languages are mixed in a single utterance of text and speech. To address this challenge, we present a corpus (HinGE) for a widely popular code-mixed language Hinglish (code-mixing of Hindi and English languages). HinGE has Hinglish sentences generated by humans as well as two rule-based algorithms corresponding to the parallel Hindi-English sentences. In addition, we demonstrate the inefficacy of widely-used evaluation metrics on the code-mixed data. The HinGE dataset will facilitate the progress of natural language generation research in code-mixed languages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:SdhP9T11ey4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Automatic code synthesis from natural language descriptions is a challenging task. We witness massive progress in developing code generation systems for domain-specific languages (DSLs) employing sequence-to-sequence deep learning techniques in the recent past. In this paper, we specifically experiment with \textsc{AlgoLisp} DSL-based generative models and showcase the existence of significant dataset bias through different classes of adversarial examples. We also experiment with two variants of Transformer-based models that outperform all existing \textsc{AlgoLisp} DSL-based code generation baselines. Consistent with the current state-of-the-art systems, our proposed models, too, achieve poor performance under adversarial settings. Therefore, we propose several dataset augmentation techniques to reduce bias and showcase their efficacy using robust experimentation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:dTyEYWd-f8wC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"We present TweeNLP, a one-stop portal that organizes Twitter's natural language processing (NLP) data and builds a visualization and exploration platform. It curates 19,395 tweets (as of April 2021) from various NLP conferences and general NLP discussions. It supports multiple features such as TweetExplorer to explore tweets by topics, visualize insights from Twitter activity throughout the organization cycle of conferences, discover popular research papers and researchers. It also builds a timeline of conference and workshop submission deadlines. We envision TweeNLP to function as a collective memory unit for the NLP community by integrating the tweets pertaining to research papers with the NLPExplorer scientific literature search engine. The current system is hosted at http://nlpexplorer.org/twitter/CFP .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:JoZmwDi-zQgC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Code-mixing is a frequent communication style among multilingual speakers where they mix words and phrases from two different languages in the same utterance of text or speech. Identifying and filtering code-mixed text is a challenging task due to its co-existence with monolingual and noisy text. Over the years, several code-mixing metrics have been extensively used to identify and validate code-mixed text quality. This paper demonstrates several inherent limitations of code-mixing metrics with examples from the already existing datasets that are popularly used across various experiments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:eMMeJKvmdy0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Multilingualism refers to the high degree of proficiency in two or more languages in the written and oral communication modes. It often results in language mixing, a.k.a. code-mixing, when a multilingual speaker switches between multiple languages in a single utterance of a text or speech. This paper discusses the current state of the NLP research, limitations, and foreseeable pitfalls in addressing five real-world applications for social good crisis management, healthcare, political campaigning, fake news, and hate speech for multilingual societies. We also propose futuristic datasets, models, and tools that can significantly advance the current research in multilingual NLP applications for the societal good. As a representative example, we consider English-Hindi code-mixing but draw similar inferences for other language pairs",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:tkaPQYYpVKoC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"The increasing use of dialogue agents makes it extremely desirable for them to understand and acknowledge the implied emotions to respond like humans with empathy. Chatbots using traditional techniques analyze emotions based on the context and meaning of the text and lack the understanding of emotions expressed through face. Emojis representing facial expressions present a promising way to express emotions. However, none of the AI systems utilizes emojis for empathetic conversation generation. We propose, SentEmojiBot, based on the SentEmoji dataset, to generate empathetic conversations with a combination of emojis and text. Evaluation metrics show that the BERT-based model outperforms the vanilla transformer model. A user study indicates that the dialogues generated by our model were understandable and adding emojis improved empathetic traits in conversations by 9.8%",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:PELIpwtuRlgC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Air pollution is a global challenge for cities across the globe. Understanding the public perception of air pollution can help policymakers engage better with the public and appropriately introduce policies. Accurate public perception can also help people to identify the health risks of air pollution and act accordingly. Unfortunately, current techniques for determining perception are not scalable: it involves surveying few hundred people with questionnaire-based surveys. Using the advances in natural language processing (NLP), we propose a more scalable solution called Vartalaap to gauge public perception of air pollution via the microblogging social network Twitter. We curated a dataset of more than 1.2M tweets discussing Delhi-specific air pollution. We find that (unfortunately) the public is supportive of unproven mitigation strategies to reduce pollution, thus risking their health due to a false sense of security. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:WA5NYHcadZ8C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Projection of changes in extreme indices of climate variables such as temperature and precipitation are critical to assess the potential impacts of climate change on human-made and natural systems, including critical infrastructures and ecosystems. While impact assessment and adaptation planning rely on high-resolution projections (typically in the order of a few kilometers), state-of-the-art Earth System Models (ESMs) are available at spatial resolutions of few hundreds of kilometers. Current solutions to obtain high-resolution projections of ESMs include downscaling approaches that consider the information at a coarse-scale to make predictions at local scales. Complex and non-linear interdependence among local climate variables (e.g., temperature and precipitation) and large-scale predictors (e.g., pressure fields) motivate the use of neural network-based super-resolution architectures. In this work, we present …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:uWQEDVKXjbEC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Relational databases are prevalent in handling large and complex databases; however, writing the SQL queries can be a tedious task for databases. Recent studies for automating the task of translating natural language text to SQL query are not robust to queries having multi-table dependencies. Also, considering the lack of such research in scientific domain, we introduce ACL-SQL, a dataset with complex queries depending on up to five tables and benchmark the dataset on a simple approach. Evaluation shows that our approach is reasonably precise and can be adopted for practical applications. The dataset and codes are available at https://github.com/rohitshantarampatil/sql-nlp.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:5ugPr518TE4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"In this work, we propose to construct a Genealogical Tree of research papers. A Genealogy tree of research papers is a tree-like structure that captures information diffusion (transfer of genes) from parent papers to its citations (children). The nodes in the tree denote papers, and the edges represent the information passed from one generation to the other. A genealogy tree can be leveraged to understand better any research topic’s lineage and any specific paper’s influence",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:1qzjygNMrQYC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"A reverse dictionary is a tool that solves the Tip-of-the-Tongue problem by predicting the target word given a meaning or description. This paper proposes a modified Continuous Bag-Of-Words (CBOW) model inspired by the Recurrent Neural Network (RNN), to implement a reverse dictionary. The model possesses the merits of both the CBOW model and RNN while stripping away the complexity associated with RNN. We evaluate the model by measuring accuracy based on the top-2 predictions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:V3AGJWp-ZtQC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Recommendation Systems are widely deployed for all kinds of services across various websites to enhance user experience. However, existing systems do not make efficient use of text data associated with products and users, available as reviews and blogs to relate them better. Many recent works have tried to improve the accuracy of rating prediction. However, very few works have attempted to justify the reason for a particular recommendation. Explaining the recommendation would help in gaining the trust of the user, and lend the system human-like credibility. In this paper, we propose a model that can recommend movies and generate a reasoning text to help the user understand why a film was recommended to them. We use three parallel neural networks with an enhanced BERT Embedding for Aspect Based Sentiment Analysis (ABSA) to predict rating. The Seq2Seq transformer model is used to generate the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:kRWSkSYxWN8C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Tables present important information concisely in many scientific documents. Visual features like mathematical symbols, equations, and spanning cells make structure and content extraction from tables embedded in research documents difficult. This paper discusses the dataset, tasks, participants’ methods, and results of the ICDAR 2021 Competition on Scientific Table Image Recognition to LaTeX. Specifically, the task of the competition is to convert a tabula r image to its corresponding  source code. We proposed two subtasks. In Subtask 1, we ask the participants to reconstruct the  structure code from an image. In Subtask 2, we ask the participants to reconstruct the  content code from an image. This report describes the datasets and ground truth specification, details the performance evaluation metrics used, presents the final results, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:9vf0nzSNQJEC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2021,"Information Extraction (IE) from the tables present in scientific articles is challenging due to complicated tabular representations and complex embedded text. This paper presents TabLeX, a large-scale benchmark dataset comprising table images generated from scientific articles. TabLeX consists of two subsets, one for table structure extraction and the other for table content extraction. Each table image is accompanied by its corresponding LaTeX source code. To facilitate the development of robust table IE tools, TabLeX contains images in different aspect ratios and in a variety of fonts. Our analysis sheds light on the shortcomings of current state-of-the-art table extraction models and shows that they fail on even simple table images. Towards the end, we experiment with a transformer-based existing baseline to report performance scores. In contrast to the static benchmarks, we plan to augment this dataset …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:Mojj43d5GZwC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:J-pR_7NvFogC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"WhatsApp Messenger is one of the most popular channels for spreading information with a current reach of more than 180 countries and 2 billion people. Its widespread usage has made it one of the most popular media for information propagation among the masses during any socially engaging event. In the recent past, several countries have witnessed its effectiveness and influence in political and social campaigns. We observe a high surge in information and propaganda flow during election campaigning. In this paper, we explore a high-quality large-scale user-generated dataset curated from WhatsApp comprising of 281 groups, 31,078 unique users, and 223,404 messages shared before, during, and after the Indian General Elections 2019, encompassing all major Indian political parties and leaders. In addition to the raw noisy user-generated data, we present a fine-grained annotated dataset of 3,848 messages that will be useful to understand the various dimensions of WhatsApp political campaigning. We present several complementary insights into the investigative and sensational news stories from the same period. Exploratory data analysis and experiments showcase several exciting results and future research opportunities. To facilitate reproducible research, we make the anonymized datasets available in the public domain.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:eflP2zaiRacC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"The entire world is engulfed in the fight against the COVID-19 pandemic, leading to a significant surge in research experiments, government policies, and social media discussions. A multi-modal information access and data visualization platform can play a critical role in supporting research aimed at understanding and developing preventive measures for the pandemic. In this paper, we present a multi-faceted AI-based search and visualization engine, CovidExplorer. Our system aims to help researchers understand current state-of-the-art COVID-19 research, identify research articles relevant to their domain, and visualize real-time trends and statistics of COVID-19 cases. In contrast to other existing systems, CovidExplorer also brings in India-specific topical discussions on social media to study different aspects of COVID-19. The system, demo video, and the datasets are available at http://covidexplorer.in.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:u9iWguZQMMsC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Complex systems have been successfully modeled as networks exhibiting the varying extent of randomness and nonrandomness. Network scientists contemplate randomness as one of the most desirable characteristics for real complex systems’ efficient performance. However, the current methodologies for randomness (or nonrandomness) quantification are nontrivial. In this article, we empirically showcase severe limitations associated with the state-of-the-art graph spectral-based quantification approaches. Addressing these limitations led to the proposal of a novel spectrum-based methodology that leverages configuration models as a reference network to quantify the nonrandomness in a given candidate network. Besides, we derive mathematical formulations for demonstrating the dependence of nonrandomness on three structural properties: modularity, clustering, and the highest degree node’s growth rate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:K3LRdlH-MEoC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Network structures in a wide array of systems such as social networks, transportation, power and water distribution infrastructures, and biological and ecological systems can exhibit critical thresholds or tipping points beyond which there are disproportionate losses in the system functionality. There is growing concern over tipping points and failure tolerance of such systems as tipping points can lead to an abrupt loss of intended functionality and possibly non-recoverable states. While attack tolerance of networked systems has been intensively studied for the disruptions originating from a single point of failure, there have been instances where real-world systems are subject to simultaneous or sudden onset of concurrent disruption at multiple locations. Using open-source data from the United States Airspace Airport network and Indian Railways Network, and random networks as prototype class of systems, we study their responses to synthetic attack strategies of varying sizes. For both types of networks, we observe the presence of warning regions, which serve as a precursor to the tipping point. Further, we observe the statistically significant relationships between network robustness and size of simultaneous distribution, which generalizes to the networks with different topological attributes for random failures and targeted attacks. We show that our approach can determine the entire robustness characteristics of networks of disparate architecture subject to disruptions of varying sizes. Our approach can serve as a paradigm to understand the tipping point in real-world systems, and the principle can be extended to other disciplines to address critical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:OU6Ihb5iCvQC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"High solicitation for publishing a paper in scientific journals has led to the emergence of a large number of open-access predatory publishers. They fail to provide a rigorous peer-review process, thereby diluting the quality of research work and charge high article processing fees. Identification of such publishers has remained a challenge due to the vast diversity of the scholarly publishing ecosystem. Earlier works utilises only the objective features such as metadata. In this work, we aim to explore the possibility of identifying predatory behaviour through text-based features. We propose PredCheck, a four-step classificaton pipeline. The first classifier identifies the subject of the paper using TF-IDF vectors. Based on the subject of the paper, the Doc2Vec embeddings of the text are found. These embeddings are then fed into a Naive Bayes classifier that identifies the text to be predatory or non-predatory. Our pipeline …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:dshw04ExmUIC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Understanding the topical evolution in industrial innovation is a challenging problem. With the advancement in the digital repositories in the form of patent documents, it is becoming increasingly more feasible to understand the innovation secrets - 'catchphrases' - of organizations. However, searching and understanding this enormous textual information is a natural bottleneck. In this paper, we propose an unsupervised method for the extraction of catchphrases from the abstracts of patents granted by the U.S. Patent and Trademark Office over the years. Our proposed system achieves substantial improvement, both in terms of precision and recall, against state-of-the-art techniques. As a second objective, we conduct an extensive empirical study to understand the temporal evolution of the catchphrases across various organizations. We also show how the overall innovation evolution in the form of introduction of newer …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:CHSYGLWDkRkC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Automatic scientific keyphrase extraction is a challenging problem facilitating several downstream scholarly tasks like search, recommendation, and ranking. In this paper, we introduce SEAL, a scholarly tool for automatic keyphrase extraction and classification. The keyphrase extraction module comprises two-stage neural architecture composed of Bidirectional Long Short-Term Memory cells augmented with Conditional Random Fields. The classification module comprises of a Random Forest classifier. We extensively experiment to showcase the robustness of the system. We evaluate multiple state-of-the-art baselines and show a significant improvement. The current system is hosted at http://lingo.iitgn.ac.in:5000/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:b0M2c_1WBrUC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"We introduce an AI-enabled portal that presents an excellent visualization of Mahatma Gandhi's life events by constructing temporal and spatial social networks from the Gandhian literature. Applying an ensemble of methods drawn from NLTK, Polyglot and Spacy we extract the key persons and places that find mentions in Gandhi's written works. We visualize these entities and connections between them based on co-mentions within the same time frame as networks in an interactive web portal. The nodes in the network, when clicked, fire search queries about the entity and all the information about the entity presented in the corresponding book from which the network is constructed, are retrieved and presented back on the portal. Overall, this system can be used as a digital and user-friendly resource to study Gandhian literature.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:EUQCXRtRnyEC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Song lyrics convey a meaningful story in a creative manner with complex rhythmic patterns. Researchers have been successful in generating and analyisng lyrics for poetry and songs in English and Chinese. But there are no works which explore the Hindi language datasets. Given the popularity of Hindi songs across the world and the ambiguous nature of romanized Hindi script, we propose Bollyrics, an automatic lyric generator for romanized Hindi songs. We propose simple techniques to capture rhyming patterns before and during the model training process in Hindi language. The dataset and codes are available publicly at https://github.com/lingo-iitgn/Bollyrics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:xtRiw3GOFMkC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Code-mixing is the phenomenon of using multiple languages in the same utterance of a text or speech. It is a frequently used pattern of communication on various platforms such as social media sites, online gaming, product reviews, etc. Sentiment analysis of the monolingual text is a well-studied task. Code-mixing adds to the challenge of analyzing the sentiment of the text due to the non-standard writing style. We present a candidate sentence generation and selection based approach on top of the Bi-LSTM based neural classifier to classify the Hinglish code-mixed text into one of the three sentiment classes positive, negative, or neutral. The proposed approach shows an improvement in the system performance as compared to the Bi-LSTM based neural classifier. The results present an opportunity to understand various other nuances of code-mixing in the textual data, such as humor-detection, intent classification, etc.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:1sJd4Hv_s6UC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Code-mixing is the phenomenon of using more than one language in a sentence. It is a very frequently observed pattern of communication on social media platforms. Flexibility to use multiple languages in one text message might help to communicate efficiently with the target audience. But, it adds to the challenge of processing and understanding natural language to a much larger extent. This paper presents a parallel corpus of the 13,738 code-mixed English-Hindi sentences and their corresponding translation in English. The translations of sentences are done manually by the annotators. We are releasing the parallel corpus to facilitate future research opportunities in code-mixed machine translation. The annotated corpus is available at https://doi.org/10.5281/zenodo.3605597.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:_xSYboBqXhAC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Extensive literature demonstrates how the copying of references (links) can lead to the emergence of various structural properties (e.g., power-law degree distribution and bipartite cores) in bibliographic and other similar directed networks. However, it is also well known that the copying process is incapable of mimicking the number of directed triangles in such networks; neither does it have the power to explain the obsolescence of older papers. In this paper, we propose RefOrCite, a new model that allows for copying of both the references from (i.e., out-neighbors of) as well as the citations to (i.e., in-neighbors of) an existing node. In contrast, the standard copying model (CP) only copies references. While retaining its spirit, RefOrCite differs from the Forest Fire (FF) model in ways that makes RefOrCite amenable to mean-field analysis for degree distribution, triangle count, and densification. Empirically, RefOrCite …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:f2IySw72cVMC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"The task of learning a sentiment classification model that adapts well to any target domain, different from the source domain, is a challenging problem. Majority of the existing approaches focus on learning a common representation by leveraging both source and target data during training. In this paper, we introduce a two-stage training procedure that leverages weakly supervised datasets for developing simple lift-and-shift-based predictive models without being exposed to the target domain during the training phase. Experimental results show that transfer with weak supervision from a source domain to various target domains provides performance very close to that obtained via supervised training on the target domain itself.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:abG-DnoFyZgC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Research and innovation is an important agenda for any company to remain competitive in the market. The relationship between innovation and revenue is a key metric for companies to decide on the amount to be invested for future research. Two important parameters to evaluate innovation are the quantity and quality of scientific papers and patents. Our work studies the relationship between innovation and patenting activities for several Fortune 500 companies over a period of time. We perform a comprehensive study of the patent citation dataset available in the Reed Technology Index collected from the US Patent Office. We observe several interesting relations between parameters like the number of (i) patent applications, (ii) patent grants, (iii) patent citations and Fortune 500 ranks of companies. We also study the trends of these parameters varying over the years and derive causal explanations for these with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:bFI3QPDXJZMC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2020,"Understanding the current research trends, problems, and their innovative solutions remains a bottleneck due to the ever-increasing volume of scientific articles. In this paper, we propose NLPExplorer, a completely automatic portal for indexing, searching, and visualizing Natural Language Processing (NLP) research volume. NLPExplorer presents interesting insights from papers, authors, venues, and topics. In contrast to previous topic modelling based approaches, we manually curate five course-grained non-exclusive topical categories namely Linguistic Target (Syntax, Discourse, etc.), Tasks (Tagging, Summarization, etc.), Approaches (unsupervised, supervised, etc.), Languages (English, Chinese, etc.) and Dataset types (news, clinical notes, etc.). Some of the novel features include a list of young popular authors, popular URLs and datasets, list of topically diverse papers and recent popular papers …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:D03iK_w7-QYC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,"Network modeling is a challenging task due to non-trivial evolution dynamics. We introduce multiple-selection-procedure with ‘N’ possible growth mechanisms (MSP-N). In MSP-N, an incoming node chooses a single option among N available options to link to pre-existing nodes. Some of the potential options, in case of social networks, can be standard preferential or random attachment and node aging or fitness. In this paper, we discuss a specific case, MSP-2, and shows its efficacy in reconstructing several non-trivial characteristic properties of social networks, including networks with power-law degree distribution, power-law with an exponential decay (exponential cut-off), and exponential degree distributions. We evaluate the proposed evolution mechanism over two real-world networks and observe that the generated networks highly resembles the degree distribution of the real-world networks. Besides, several other network properties such as high clustering and triangle count, low spectral radius, and community structure, of the generated networks are significantly closer to the real-world networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:pyW8ca7W8N0C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,"Understanding scholarly articles is a key ingredient of impressive research recipe. Scholarly articles keep the scientific community up to date with the current research and development results and ideas. With the tremendous advancement in Internet infrastructure, we are witnessing an ongoing explosion in scholarly information that is generated. In this thesis, we attempt to introduce, study and solve some of the challenges emanating from scholarly volume overload. In particular, we look into three different dimensions:(i) metadata, structure, bibliography and experimental performance extraction from scholarly articles,(ii) designing network-assisted aging growth models for evolving citation networks with novel proposal of temporal summaries, and (iii) leveraging textual and network information to design long-term scientific impact prediction frameworks. While the first objective is related to the curation of scientific …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:t6usbXjVLHcC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:nb7KW1ujOQ8C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,"A biography of a person is the detailed description of several life events including his education, work, relationships and death. Wikipedia, the free web-based encyclopedia, consists of millions of manually curated biographies of eminent politicians, film and sports personalities, etc. However, manual curation efforts, even though efficient, suffers from significant delays. In this work, we propose an automatic biography generation framework BioGen. BioGen generates a short collection of biographical sentences clustered into multiple events of life. Evaluation results show that biographies generated by BioGen are significantly closer to manually written biographies in Wikipedia. A working model of this framework is available at nlpbiogen.herokuapp.com/home/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:cFHS6HbyZ2cC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,"Recent advancements in Internet and Mobile infrastructure have resulted in the development of faster and efficient platforms of communication. These platforms include speech, facial and text-based conversational mediums. Majority of these are text-based messaging platforms. Development of Chatbots that automatically understand latent emotions in the textual message is a challenging task. In this paper, we present an automatic emotion detection system that aims to detect the emotion of a person textually conversing with a chatbot. We explore deep learning techniques such as CNN and LSTM based neural networks and outperformed the baseline score by 14%. The trained model and code are kept in public domain.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:dfsIfKJdRG4C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,"Abstract—India is an agro-based economy and proper information about agricultural practices is the key to optimal agricultural growth and output. In order to answer the queries of the farmer, we have build an agricultural chatbot based on the dataset from Kisan Call Center. This system is robust enough to answer queries related to weather, market rates, plant protection and government schemes. This system is available 24* 7, can be accessed through any electronic device and the information is delivered with the ease of understanding. The system is based on a sentence embedding model which gives an accuracy of 56%. After eliminating synonyms and incorporating entity extraction, the accuracy jumps to 86%. With such a system, farmers can progress towards easier information about farming related practices and hence a better agricultural output. The job of the Call Center workforce would be made easier and the hard work of various such workers can be redirected to a better goal.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:P5F9QuxV20EC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:p2g8aNsByqUC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,"The distinction between sciences is becoming increasingly more artificial – an approach from one area can be easily applied to the other. More exciting research nowadays is happening perhaps at the interfaces of disciplines like Physics, Mathematics and Computer Science. How do these interfaces emerge and interact? For instance, is there a specific pattern in which these fields cite each other? In this article, we investigate a collection of more than 1.2 million papers from three different scientific disciplines – Physics, Mathematics, and Computer Science. We show how over a timescale the citation patterns from the core science fields (Physics, Mathematics) to the applied and fast-growing field of Computer Science have drastically increased. Further, we observe how certain subfields in these disciplines are shrinking while others are becoming tremendously popular. For instance, an intriguing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:a0OBvERweLwC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,"Digital advancement in scholarly repositories has led to the emergence of a large number of open access predatory publishers that charge high article processing fees from authors but fail to provide necessary editorial and publishing services. Identifying and blacklisting such publishers has remained a research challenge due to the highly volatile scholarly publishing ecosystem. This paper presents a data-driven approach to study how potential predatory publishers are evolving and bypassing several regularity constraints. We empirically show the close resemblance of predatory publishers against reputed publishing groups. In addition to verifying standard constraints, we also propose distinctive signals gathered from network-centric properties to understand this evolving ecosystem better. To facilitate reproducible research, we shall make all the codes and the processed dataset available in the public …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:fPk4N6BV_jEC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2019,"A leaderboard is a tabular presentation of performance scores of the best competing techniques that address a specific scientific problem. Manually maintained leaderboards take time to emerge, which induces a latency in performance discovery and meaningful comparison. This can delay dissemination of best practices to non-experts and practitioners. Regarding papers as proxies for techniques, we present a new system to automatically discover and maintain leaderboards in the form of partial orders between papers, based on performance reported therein. In principle, a leaderboard depends on the task, data set, other experimental settings, and the choice of performance metrics. Often there are also tradeoffs between different metrics. Thus, leaderboard discovery is not just a matter of accurately extracting performance numbers and comparing them. In fact, the levels of noise and uncertainty around …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:UebtZRa9Y70C,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2018,"We present CL Scholar, the ACL Anthology knowledge graph miner to facilitate high-quality search and exploration of current research progress in the computational linguistics community. In contrast to previous works, periodically crawling, indexing and processing of new incoming articles is completely automated in the current system. CL Scholar utilizes both textual and network information for knowledge graph construction. As an additional novel initiative, CL Scholar supports more than 1200 scholarly natural language queries along with standard keyword-based search on constructed knowledge graph. It answers binary, statistical and list based natural language queries. The current system is deployed at http://cnerg.iitkgp.ac.in/aclakg. We also provide REST API support along with bulk download facility. Our code and data are available at https://github.com/CLScholar.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:ZHo1McVdvXMC,http://mayank4490.github.io/
Mayank Singh,"['NLP', 'Data Mining', 'Machine Learning']",11,470,2018,"With the exponential growth of research volume in the recent decades, academic entities like articles, authors, venues, organisations, fields etc. have evolved qualitatively and quantitatively. The scientific community has always been demanding for better algorithms, metrics and features for ranking and categorization of academic entities leading to one of the interesting and well researched problem of understanding and estimating the popularity of these academic entities. We study several interesting factors that influence the popularity of research articles. Specifically, we utilize information generated immediately after the publication to estimate its long-term popularity. This generated information includes both network-based and content-based information. We also propose the first plausible network-driven models for obsolescence in the context of research paper citations, based on a natural notion of relay-linking. Our model is based on a surprising inversion or undoing of triangle completion, where an old node relays a citation to a younger follower in its immediate vicinity. We show that our proposed models remarkably better fit with real bibliographic data. We also demonstrate the development of ConfAssist which is a novel conflict resolution framework that can assist experts to resolve conflicts in deciding whether a conference is a top-tier or not by expressing how (dis) similar the conference is to other well accepted top-tier/non top-tier conferences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U2NUj90AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=U2NUj90AAAAJ:kzcrU_BdoSEC,http://mayank4490.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2023,"According to the World Health Organisation (WHO), 235 million people suffer from respiratory illnesses which causes four million deaths annually. Regular lung health monitoring can lead to prognoses about deteriorating lung health conditions. This article presents our system SpiroMask that retrofits a microphone in consumer-grade masks (N95 and cloth masks) for continuous lung health monitoring. We evaluate our approach on 48 participants (including 14 with lung health issues) and find that we can estimate parameters such as lung volume and respiration rate within the approved error range by the American Thoracic Society (ATS). Further, we show that our approach is robust to sensor placement inside the mask.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:kuK5TVdYjLIC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2023,"Air pollution kills around 7 million people annually, and approximately 2.4 billion people are exposed to hazardous air pollution. Accurate, fine-grained air quality (AQ) monitoring is essential to control and reduce pollution. However, AQ station deployment is sparse, and thus air quality inference for unmonitored locations is crucial. Conventional interpolation methods fail to learn the complex AQ phenomena. This work demonstrates that Deep Gaussian Process models (DGPs) are a promising model for the task of AQ inference. We implement Doubly Stochastic Variational Inference, a DGP algorithm, and show that it performs comparably to the state-of-the-art models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:oNZyr7d5Mn4C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"Non-intrusive load monitoring (NILM) or energy disaggregation aims to break down total household energy consumption into constituent appliances. Prior work has shown that providing an energy breakdown can help people save up to 15\% of energy. In recent years, deep neural networks (deep NNs) have made remarkable progress in the domain of NILM. In this paper, we demonstrate the performance of Gaussian Processes (GPs) for NILM. We choose GPs due to three main reasons: i) GPs inherently model uncertainty; ii) equivalence between infinite NNs and GPs; iii) by appropriately designing the kernel we can incorporate domain expertise. We explore and present the challenges of applying our GP approaches to NILM.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:WZBGuue-350C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"Non-intrusive load monitoring (NILM) refers to the task of disaggregating total household power consumption into the constituent appliances. In recent years, various neural network (NN) based approaches have emerged as state-of-the-art for NILM. In conventional settings, NN(s) provide point estimates for appliance power. In this paper, we explore the question - can we learn models that tell when they are unsure? Or, in other words, can we learn models that provide uncertainty estimates? We explore recent advances in uncertainty for NN(s), evaluate 14 model variants on the publicly available REDD dataset, and find that our models can accurately estimate uncertainty without compromising on traditional metrics. We also find that different appliances in their different states have varying performance of uncertainty. We also propose ""recalibration"" methods and find they can improve the uncertainty estimation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:k8Z6L05lTy4C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"Gaussian processes are Bayesian non-parametric models used in many areas. In this work, we propose a Non-stationary Heteroscedastic Gaussian process model which can be learned with gradient-based techniques. We demonstrate the interpretability of the proposed model by separating the overall uncertainty into aleatoric (irreducible) and epistemic (model) uncertainty. We illustrate the usability of derived epistemic uncertainty on active learning problems. We demonstrate the efficacy of our model with various ablations on multiple datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:kz9GbA2Ns4gC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"The computational resources required to train a model have been increasing since the inception of deep networks. Training neural networks on massive datasets have become a challenging and time-consuming task. So, there arises a need to reduce the dataset without compromising the accuracy. In this paper, we present novel variations of an earlier approach called reduction through homogeneous clustering for reducing dataset size. The proposed methods are based on the idea of partitioning the dataset into homogeneous clusters and selecting images that contribute significantly to the accuracy. We propose two variations: Geometrical Homogeneous Clustering for Image Data Reduction (GHCIDR) and Merged-GHCIDR upon the baseline algorithm - Reduction through Homogeneous Clustering (RHC) to achieve better accuracy and training time. The intuition behind GHCIDR involves selecting data points by cluster weights and geometrical distribution of the training set. Merged-GHCIDR involves merging clusters having the same labels using complete linkage clustering. We used three deep learning models- Fully Connected Networks (FCN), VGG1, and VGG16. We experimented with the two variants on four datasets- MNIST, CIFAR10, Fashion-MNIST, and Tiny-Imagenet. Merged-GHCIDR with the same percentage reduction as RHC showed an increase of 2.8%, 8.9%, 7.6% and 3.5% accuracy on MNIST, Fashion-MNIST, CIFAR10, and Tiny-Imagenet, respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:LI9QrySNdTsC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"In this paper, we present novel variations of an earlier approach called homogeneous clustering algorithm for reducing dataset size. The intuition behind the approaches proposed in this paper is to partition the dataset into homogeneous clusters and select some images which contribute significantly to the accuracy. Selected images are the proper subset of the training data and thus are human-readable. We propose four variations upon the baseline algorithm-RHC. The intuition behind the first approach, RHCKON, is that the boundary points contribute significantly towards the representation of clusters. It involves selecting k farthest and one nearest neighbour of the centroid of the clusters. In the following two approaches (KONCW and CWKC), we introduce the concept of cluster weights. They are based on the fact that larger clusters contribute more than smaller sized clusters. The final variation is GHCIDR which selects points based on the geometrical aspect of data distribution. We performed the experiments on two deep learning models- Fully Connected Networks (FCN) and VGG1. We experimented with the four variants on three datasets- MNIST, CIFAR10, and Fashion-MNIST. We found that GHCIDR gave the best accuracy of 99.35%, 81.10%, and 91.66% and a training data reduction of 87.27%, 32.34%, and 76.80% on MNIST, CIFAR10, and Fashion-MNIST respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:lmc2jWPfTJgC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"Air pollution killed 1.67M people in India in 2019. Previous work has shown that accurate public perception can help people identify the health risks of air pollution and act accordingly. News media influence how the public defines a social problem. However, news media analysis on air pollution has been on a small scale and regional. In this work, we gauge print news media response to air pollution in India on a larger scale. We curated a dataset of 17.4K news articles on air pollution from two leading English daily newspapers spanning 11 years. We performed exploratory data analysis and topic modeling to reveal the news media response to air pollution. Our study shows that, although air pollution is a year-long problem in India, the news media limelight on the issue is periodic (temporal bias). News media prefer to focus on the air pollution issue of metropolitan cities rather than the cities which are worst hit by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:MLfJN-KU85MC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"In India, residential power consumption accounts for a quarter of the country’s total consumption. With increasing disposable income and living standards and indeed warming conditions, demand for cooling through the use of air conditioners, is expected to rise and with it the peak demand. There is a new opportunity to manage the growth of this demand by first identifying the contribution of various end-uses to peak demand and supporting uptake of energy efficient equipment and influencing behavior concerning the use of cooling equipment. The information that is currently available from conventional meters and the frequency of collection is not sufficient to enable such analyses. With the help of high-frequency data from smart meters, electricity utilities can identify customers driving the peak demand and respond suitably. We demonstrate this with the help of data from 93 smart meters deployed in a sample of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:tuHXwOkdijsC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:b1wdh0AR-JQC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"The development of the fashion industry has increased the demand for customised and meticulously designed clothes. This poses a challenge to fashion designers who need to create novel clothing designs based on the requirements specified by the customers. This work presents a generative adversarial network (GAN) based text-to-image synthesis model for fabricating intricate Indian apparel designs. We introduce an architecture that strategically combines multiple trained GAN models for a streamlined text-to-image generation. Existing fashion datasets with elaborate image descriptions cater to western fashion only. We have extracted traditional Indian images like kurtis, kurtas, etc., and then combined with an existing dataset to create an Indian Fashion dataset of around 16000 images with their corresponding text descriptions. On carrying out elaborate testing on our dataset we have achieved good visual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:gsN89kCJA0AC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"Respiration rate is a vital sign to predict cardiac arrest, apnea, dyspnea and lung ailments. Past research has largely focused on sensing respiration rate in a controlled environment with participants at rest. But disease prognosis requires continuous everyday-life monitoring of respiration rate. In this work, we demonstrate how CO2 sensor placed inside N95 mask can detect respiration rate during motion as well as rest with a better or comparable performance compared to previous work. Our system weighs 16 grams, runs uninterrupted for 2 hours, generalises across participants, does not require any learning algorithm and is reproducible.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:M7yex6snE4oC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2022,"Air pollution is a global problem and severely impacts human health. Fine-grained air quality (AQ) monitoring is important in mitigating air pollution. However, existing AQ station deployments are sparse. Conventional interpolation techniques fail to learn the complex AQ phenomena. Physics-based models require domain knowledge and pollution source data for AQ modeling. In this work, we propose a Gaussian processes based approach for estimating AQ. The important features of our approach are: a) a non-stationary (NS) kernel to allow input depended smoothness of fit; b) a Hamming distance-based kernel for categorical features; and c) a locally periodic kernel to capture temporal periodicity. We leverage batch-wise training to scale our approach to a large amount of data. Our approach outperforms the conventional baselines and a state-of-the-art neural attention-based approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:TIZ-Mc8IlK0C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2021,"Non-intrusive load monitoring (NILM) involves separating the household aggregate energy consumption into constituent appliances. In 2014, a toolkit called NILMTK was released towards making NILM reproducible. Subsequently, in 2019, an improved version called NILMTK-contrib, focused on experiments and ease of adding new algorithms was released. Since then, there have been significant advances in neural networks for various applications, and in the NILM domain. In this paper, we implement five recent neural network architectures for NILM in NILMTK-contrib and benchmark against existing algorithms. Further, in this paper, we also implement a dataset parser for a publicly available dataset called IDEAL containing 255 homes with 39 homes having appliance data. We find that the new algorithms are comparable or better than the state-of-the-art over a subset of the appliances.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:tYavs44e6CUC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2021,"Air pollution is a global challenge for cities across the globe. Understanding the public perception of air pollution can help policymakers engage better with the public and appropriately introduce policies. Accurate public perception can also help people to identify the health risks of air pollution and act accordingly. Unfortunately, current techniques for determining perception are not scalable: it involves surveying few hundred people with questionnaire-based surveys. Using the advances in natural language processing (NLP), we propose a more scalable solution called Vartalaap to gauge public perception of air pollution via the microblogging social network Twitter. We curated a dataset of more than 1.2M tweets discussing Delhi-specific air pollution. We find that (unfortunately) the public is supportive of unproven mitigation strategies to reduce pollution, thus risking their health due to a false sense of security. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:g3aElNc5_aQC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2021,"Deep learning-based innovations, particularly GANs, have recently shown great success in fashion modelling for various use cases such as pose and face generation. A famous work, FashionGAN[1], can generate images with modified clothing as per natural language description and uses the DeepFashion dataset, which primarily contains clothing styles of the Western countries. Currently, no dataset caters to Indian style and clothing. Hence, we present a dataset of 12k images and descriptions pertaining to the Indian culture as well as a baseline approach with this work. Deep learning-based innovations in the Indian Fashion context are a relatively new area of research, and we hope our work will be a starting point for other researchers. Code and Dataset: https://github.com/ronakkaoshik42/Generative_fashion",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:hMsQuOkrut0C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Non-intrusive load monitoring (NILM) or energy disaggregation refers to the task of estimating the appliance power consumption given the aggregate power consumption readings. Recent state-of-the-art neural networks based methods are computation and memory intensive, and thus not suitable to run on ""edge devices"". Recent research has proposed various methods to compress neural networks without significantly impacting accuracy. In this work, we study different neural network compression schemes and their efficacy on the state-of-the-art neural network NILM method. We additionally propose a multi-task learning-based architecture to compress models further. We perform an extensive evaluation of these techniques on two publicly available datasets and find that we can reduce the memory and compute footprint by a factor of up to 100 without significantly impacting predictive performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:EYYDruWGBe4C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"In this notes paper, we present an open problem to the Buildsys community: energy data super-resolution, referring to the task of estimating the power consumption of a home at a higher resolution given the low-resolution power consumption. Super-resolution is especially useful when the smart meters collect data at a very low-sampling rate owing to a plethora of issues such as bandwidth, pricing, old hardware, among others. The problem is motivated by the success of image super resolution in the computer vision community. In this paper, we formally introduce the problem and present baseline methods and the algorithms we used to ""solve"" this problem. We evaluate the performance of the algorithms on a real-world dataset and discuss the results. We also discuss what makes this problem hard and why a trivial baseline is hard to beat.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:vbGhcppDl1QC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Sensing is central to the SenSys and related communities. However, fine-grained spatial sensing remains a challenge despite recent advancements, owing to cost, maintenance, among other factors. Thus, estimating the sensed phenomenon at unmonitored locations and strategically installing sensors is of prime importance. In this work, we introduce Polire - an open-source tool that provides a suite of algorithms for spatial interpolation and near-field passive sensor placements. We replicate two existing papers on these two tasks to show the efficacy of Polire. We believe that Polire is an essential step towards lowering entry barriers towards sensing and scientific reproducibility.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:ILKRHgRFtOwC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"COVID-19 has severely impacted millions of lives around the world. In this note, we explore the impact of COVID-19 on the electricity consumption of 93 households across two tier-2 cities in India. Given the work from home restrictions, we would expect electricity consumption to increase as people spend more time at home. Contrary to the expectations, we found that electricity consumption decreased during the lockdown as compared to previous years. On further follow-up with households, we found several reasons for decreased usage: i) inability to get air conditioners serviced due to movement restriction, ii) advisories on minimising AC usage, and iii) reducing energy to compensate for reduced income.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:L7CI7m0gUJcC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Large scale campus deployments in the past have resulted in energy conservation measures, data validation, and software architectures. Inspired by the success and learnings from such previous deployments, we present our work on deployment involving sensing various aspect of campus sustainability like water, electricity, solar produce, air quality, and parking lot occupancy. Our full deployment spanned more 171 days. We used 469 sensors, collecting a maximum of 190 MB of data daily. We discuss the deployment challenges and the learnings obtained from them. We address the data collection challenges by providing best practices measures and provide insights from the installation of wireless radio communication modules. Our deployment can act as a reconnaissance guide for campus deployment, especially in developing countries.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:p__nRnzSRKYC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Given the pandemic and the high air pollution in large parts of the world, masks have become ubiquitous. In this poster, we present our vision and work-in-progress (WIP) towards leveraging the ubiquity of masks for health sensing and persuasion. We envision masks to monitor health-related parameters such as i) temperature; ii) lung activity, among others. We also envision that retrofitting masks with sensors and display to show localized pollution can create awareness about air pollution. In this WIP, we present a smart mask, Naqaab1, that measures forced vital capacity (FVC) of the lung using a retrofitted microphone. We evaluated the measured lung parameter on eight persons using an Incentive Spirometer2 and found that our smart mask accurately measures incentive lung capacity. Naqaab also measures pollution exposure and indicates via different LED colours. We envision using such a system for eco …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:4MWp96NkSFoC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Ambient fine particulate (PM2.5) is the most significant risk factor for premature death, shortening life expectancy at birth by 1.5 to 1.9 years [2]. 91% of the world's population lives in areas where air pollution exceeds safety limits1. 99% of the people in countries like India, Pakistan, Nepal, and Bangladesh experience ambient exposures of PM2.5 exceeding 75 μg/m3 to 100 μg/m3 [3]. My Ph.D. thesis will be on understanding the perception of air pollution among people using social media data. I also intend to develop a wearable air pollution exposure monitor and design an air pollution visualisation tool to reduce the entry barrier for air pollution research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:ML0RJ9NH7IQC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"91% of the world's population lives in areas where air pollution exceeds safety limits1. Research has focused on monitoring ambient air pollution, but individual exposure to air pollution is not equal to ambient and is thus important to measure. Our work (in progress) measures individual exposures of different categories of people on an academic campus. We highlight some anecdotal findings and surprising insights from monitoring, such as a) Indoor CO2 concentration of 1.8 times higher than the permissible limit. Over 10 times the WHO limit of PM2.5 exposure during b) construction-related activities, and c) cooking (despite the use of exhaust). We also found that during transit, the PM2.5 exposure is at least two times higher than indoor. Our current work though in progress, already shows important findings affecting different people associated with an academic campus. In the future, we plan to do a more exhaustive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:Z5m8FVwuT1cC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Recent years have seen a decline in air quality across the planet, with studies suggesting that air pollution is a significant cause of death. Governments have set up large scale air quality monitoring stations to aid them in formulating policies for air quality. However, these air quality stations are expensive to install, and have thus been often sparsely deployed. Motivated by sparse air quality monitoring and the expensive cost of air quality monitoring stations, we propose an active learning based solution to recommend locations to install air quality monitoring stations. We use a Gaussian Processes based approach for this purpose, motivated by their ability to encode prior knowledge using custom kernels. We demonstrate via extensive experimentation that our proposed approach outperforms several baselines on a publicly available dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:vDijr-p_gm4C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Research shows that providing an appliance-wise energy breakdown can help users save up to 15% of their energy bills. Non-intrusive load monitoring (NILM) or energy disaggregation is the task of estimating the household energy measured at the aggregate level for each constituent appliances in the household. The problem was first was introduced in the 1980s by Hart. Over the past three decades, NILM has been an extensively researched topic by researchers. NILMTK was introduced in 2014 to the NILM community in order to motivate reproducible research. Even after the introduction of the NILMTK toolkit to the community, there has been a little contribution of recent state-of-the-art algorithms back to the toolkit. In this paper, we propose a new disaggregation API, which further simplifies the process for the rapid comparison of different state-of-the-art algorithms across a wide range of datasets and algorithms. We also propose a new rewrite for writing the new disaggregation algorithms for NILMTK, which is similar to Scikitlearn. We demonstrate the power of the new API by conducting various complex experiments using the API.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:uWiczbcajpAC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Many modern machine learning algorithms have a large number of hyperparameters. To effectively use these algorithms, we need to pick good hyperparameter values. In this article, we talk about Bayesian Optimization, a suite of techniques often used to tune hyperparameters. More generally, Bayesian Optimization can be used to optimize any black-box function.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:epqYDVWIO7EC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Motivation Studies have shown that consumers of electricity can save up 15% of their bills when provided with a detailed appliance wise feedback [1]. Energy super-resolution refers to estimating energy usage at a higher-sampling rate from the lower sampling rate. We mainly focus on predicting the hourly reading of a home, using the daily usage (which can be noted down by the users from the meter). This predicted usage can be used by the consumers to identify the times of the day, which are contributing more to electricity usage and help them optimize their usage. This is analogous to image superresolution, where the zooming out factor equals 24. Problem definition",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:zLWjf1WUPmwC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Motivation: Recent years have seen a decline in air quality across the planet, with studies suggesting that a significant proportion of global population has reduced life expectancy by up to 4 years [1, 2, 5]. To tackle this increasing growth in air pollution and its adverse effects, governments across the world have set up air quality monitoring stations that measure concentrations of various pollutants like NO2, SO2 and PM2. 5, of which PM2. 5 especially has significant health impact and is used for measuring air quality. One major issue with the deployment of these stations is the massive cost involved. Owing to the high installation and maintenance costs, the spatial resolution of air quality monitoring is generally poor. In this current work, we propose active learning methods to choose the next location to install an air quality monitor, motivated by sparse spatial air quality monitoring and expensive sensing equipment …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:EkHepimYqZsC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Motivation: Air pollution is measured by the amount of PM2. 5 the air contains. These are fine particles with a diameter less than 2.5 micrometres that can penetrate deep into the lungs and trigger severe respiratory diseases. The concentration of PM2. 5 in the air can be measured using ground-based monitoring stations, but there is a considerable deficit in the number of stations required for reliable measurements as air quality varies spatially and temporally across a given region. Given the non-trivial costs of installing and maintaining ground-based PM2. 5 sensors, previous research has looked at using satellite retrievals for estimating PM2. 5 data from visual features.
Problem Statement: The goal is to predict PM2. 5 from aerosol optical thickness (AOT), which is a measure of how much light is attenuated by the aerosols (eg haze, smoke particles, desert dust) as it passes the atmosphere. Previous studies have …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:ipzZ9siozwsC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"Motivation From 2010 to 2040, the world’s total energy requirement will increase by 56%[1]. Solar energy is among the largest sources of renewable energy in the world. At the current rate, by 2050, solar energy will contribute approximately 20% of the total energy requirement in the world [2]. One of the drawbacks with solar energy is its high dependence on various meteorological conditions such as temperature, humidity, cloud cover; due to which the produced energy is highly volatile and intermittent. Accurately forecasting solar energy production is an important step towards reducing reliance on non-renewable resources.
Problem Statement Our aim is to accurately forecast the solar produce yt+ K, K timestamps in the future given historical solar produce {y1, y2,..., yt} and historical and forecasted meteorological data,{M1, M2,..., Mt,.., Mt+ K}, where M∈ Rd corresponding to d meteo-",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:uc_IGeMz5qoC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2020,"India loses 35% of the annual crop yield due to plant diseases. Early detection of plant diseases remains difficult due to the lack of lab infrastructure and expertise. In this paper, we explore the possibility of computer vision approaches for scalable and early plant disease detection. The lack of availability of sufficiently large-scale non-lab data set remains a major challenge for enabling vision based plant disease detection. Against this background, we present PlantDoc: a dataset for visual plant disease detection. Our dataset contains 2,598 data points in total across 13 plant species and up to 17 classes of diseases, involving approximately 300 human hours of effort in annotating internet scraped images. To show the efficacy of our dataset, we learn 3 models for the task of plant disease classification. Our results show that modelling using our dataset can increase the classification accuracy by up to 31%. We believe …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:0KyAp5RtaNEC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2019,"Non-intrusive load monitoring (NILM) or energy disaggregation involves separating the household energy measured at the aggregate level into constituent appliances. The NILM toolkit (NILMTK) was introduced in 2014 towards making NILM research reproducible. NILMTK has served as the reference library for data set parsers and reference benchmark algorithm implementations. However, few publications presenting algorithmic contributions within the field went on to contribute implementations back to the toolkit. This work presents a demonstration of a new version of NILMTK [2] which has a rewrite of the disaggregation API and a new experiment API which lower the barrier to entry for algorithm developers and simplify the definition of algorithm comparison experiments. This demo also marks the release of NILMTK-contrib: a new repository containing NILMTK-compatible implementations of 3 benchmarks and 9 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:nrtMV_XWKgEC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2019,"Non-intrusive load monitoring (NILM) or energy disaggregation is the task of separating the household energy measured at the aggregate level into constituent appliances. In 2014, the NILM toolkit (NILMTK) was introduced in an effort towards making NILM research reproducible. Despite serving as the reference library for data set parsers and reference benchmark algorithm implementations, few publications presenting algorithmic contributions within the field went on to contribute implementations back to the toolkit. This paper describes two significant contributions to the NILM community in an effort towards reproducible state-of-the-art research: i) a rewrite of the disaggregation API and a new experiment API which lower the barrier to entry for algorithm developers and simplify the definition of algorithm comparison experiments, and ii) the release of NILMTK-contrib; a new repository containing NILMTK-compatible …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:uJ-U7cs_P_0C,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2019,"Residential homes constitute roughly one-fourth of the total energy usage worldwide. Providing appliance-level energy breakdown has been shown to induce positive behavioral changes that can reduce energy consumption by 15%. Existing approaches for energy breakdown either require hardware installation in every target home or demand a large set of energy sensor data available for model training. However, very few homes in the world have installed sub-meters (sensors measuring individual appliance energy); and the cost of retrofitting a home with extensive sub-metering eats into the funds available for energy saving retrofits. As a result, strategically deploying sensing hardware to maximize the reconstruction accuracy of sub-metered readings in non-instrumented homes while minimizing deployment costs becomes necessary and promising. In this work, we develop an active learning solution based on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:j8SEvjWlNXcC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2019,"Residential buildings constitute roughly one-fourth of the total energy use across the globe. Numerous studies have shown that providing an energy breakdown increases residents' awareness of energy use and can help save up to 15% energy. A significant amount of prior work has looked into source-separation techniques collectively called non-intrusive load monitoring (NILM), and most prior NILM research has leveraged high-frequency household aggregate data for energy breakdown. However, in practice most smart meters only sample hourly or once every 15 minutes, and existing NILM techniques show poor performance at such a low sampling rate.
In this paper, we propose a TreeCNN model for energy breakdown on low frequency data. There are three key insights behind the design of our model: i) households consume energy with regular temporal patterns, which can be well captured by filters learned …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:fEOibwPWpKIC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2018,"Buildings across the world contribute about one-third of the total energy consumption. Studies report that anomalies in energy consumption caused by faults and abnormal appliance usage waste up to 20% of energy in buildings. Recent works leverage smart meter data to find such anomalies; however, such works do not identify the appliance causing the anomaly. Moreover, most of these works are not real-time and report the anomaly at the end of the day. In this paper, we propose a technique named Rimor that addresses these limitations. Rimor predicts the energy consumption of a home using historical energy data and contextual information and flags an anomaly when the actual energy consumption deviates significantly from the predicted consumption. Further, it identifies anomalous appliance(s) by using easy-to-collect appliance power ratings. We evaluated it on four real-world energy datasets containing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:-_dYPAW6P2MC,https://nipunbatra.github.io/
Nipun Batra,"['Computational sustainability', 'Smart buildings', 'Energy disaggregation', 'NILM', 'Air quality']",19,1469,2018,"Homes constitute roughly one-third of the total energy usage worldwide. Providing an energy breakdown–energy consumption per appliance, can help save up to 15% energy. Given the vast differences in energy consumption patterns across different regions, existing energy breakdown solutions require instrumentation and model training for each geographical region, which is prohibitively expensive and limits the scalability. In this paper, we propose a novel region independent energy breakdown model via statistical transfer learning. Our key intuition is that the heterogeneity in homes and weather across different regions most significantly impacts the energy consumption across regions; and if we can factor out such heterogeneity, we can learn region independent models or the homogeneous energy breakdown components for each individual appliance. Thus, the model learnt in one region can be transferred to another region. We evaluate our approach on two US cities having distinct weather from a publicly available dataset. We find that our approach gives better energy breakdown estimates requiring the least amount of instrumented homes from the target region, when compared to the state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=rFGzHlIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=rFGzHlIAAAAJ:tKAzc9rXhukC,https://nipunbatra.github.io/
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2022,"A real-valued set function is (additively) approximately submodular if it satisfies the submodularity conditions with an additive error. Approximate submodularity arises in many settings, especially in machine learning, where the function evaluation might not be exact. In this paper we study how close such approximately submodular functions are to truly submodular functions. We show that an approximately submodular function defined on a ground set of n elements is O (n 2) pointwise-close to a submodular function. This result also provides an algorithmic tool that can be used to adapt existing submodular optimization algorithms to approximately submodular functions. To complement, we show an Ω (n) lower bound on the distance to submodularity. These results stand in contrast to the case of approximate modularity, where the distance to modularity is a constant, and approximate convexity, where the distance to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:yeKNu01O_4gC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2022,"Infectious or contagious diseases can be transmitted from one person to another through social contact networks. In today’s interconnected global society, such contagion processes can cause global public health hazards, as exemplified by the ongoing Covid-19 pandemic. It is therefore of great practical relevance to investigate the network transmission of contagious diseases from the perspective of statistical inference. An important and widely studied boundary condition for contagion processes over networks is the so-called epidemic threshold. The epidemic threshold plays a key role in determining whether a pathogen introduced into a social contact network will cause an epidemic or die out. In this paper, we investigate epidemic thresholds from the perspective of statistical network inference. We identify two major challenges that are caused by high computational and sampling complexity of the epidemic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:wE8AsS3ykUMC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2022,"In this paper we present coresets for Fair Regression with Statistical Parity (SP) constraints and for Individually Fair Clustering. Due to the fairness constraints, the classical coreset definition is not enough for these problems. We first define coresets for both the problems. We show that to obtain such coresets, it is sufficient to sample points based on the probabilities dependent on combination of sensitivity score and a carefully chosen term according to the fairness constraints. We give provable guarantees with relative error in preserving the cost and a small additive error in preserving fairness constraints for both problems. Since our coresets are much smaller in size as compared to n, the number of points, they can give huge benefits in computational costs (from polynomial to polylogarithmic in n), especially when n≫ d, where d is the input dimension. We support our theoretical claims with experimental evaluations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:YXPZ0dOdYS4C,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2022,"With its rising fatality rates, oral cancer is one of the most concerning public health issues. To reduce disease-related mortality and morbidity, advancements in screening and detection are critical. Finding specific biomarkers is one of the most successful approaches for screening, diagnosing, and staging this dreadful disease. In this study differentially expressed genes associated with oral cancer were analyzed using RNASeq to find the potential biomarkers. Functional enrichment of upregulated genes found that 253 genes were present in the plasma membrane. Three clusters were formed using KMean Clustering from the PPI networks, and highly connected hub genes were identified from each cluster. Eventually, expression and survival analyses of hub genes were performed using The Cancer Genome Atlas (TCGA) database targeting Head and Neck Squamous Cell Carcinoma. Among those genes, expression levels of eight genes SLC2A1, ITGA6, LAMC2, COL1A2, COL1A1, TNC, THY1, and CD276 have significantly changed in Head and Neck Squamous cell carcinoma. There are reports that suggest these genes were significantly dysregulated in Oral Squamous cell carcinoma and can be explored further as potential biomarkers for margin clearance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:TuM7UPshZo8C,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2022,"We present algorithms that create coresets in an online setting for clustering problems based on a wide subset of Bregman divergences. Notably, our coresets have a small additive error, similar in magnitude to the gap between expected and empirical loss (Bachem et. al. 2017), and take update time for every incoming point where is the dimension of the point. Our first algorithm gives online coresets of size for -clusterings according to any -similar Bregman divergence. We further extend this algorithm to show the existence of non-parametric coresets, where the coreset size is independent of , the number of clusters, for the same subclass of Bregman divergences. Our non-parametric coresets also function as coresets for non-parametric versions of the Bregman clustering like DP-Means. While these coresets provide additive error guarantees, they are significantly smaller for high dimensional data than the (relative-error) coresets obtained in (Bachem et. al 2015) for DP-Means--- for the input of size our coresets grow as while being independent of as opposed to for points in $\~R^d$ (Bachem et. al 2015). We also present experiments to compare the performance of our algorithms with other sampling techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:b8m_4JuPjscC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2021,"We address the problem of modeling bursty diffusion of text-based events over a social network of user nodes. The purpose is to recover, disentangle and analyze overlapping social conversations from the perspective of user-topic preferences, user-user connection strengths and, importantly, topic transitions. For this, we propose a Dual-Network Hawkes Process (DNHP), which executes over a graph whose nodes are user-topic pairs, and closeness of nodes is captured using topic-topic, a user-user, and user-topic interactions. No existing Hawkes Process model captures such multiple interactions simultaneously. Additionally, unlike existing Hawkes Process based models, where event times are generated first, and event topics are conditioned on the event times, the DNHP is more faithful to the underlying social process by making the event times depend on interacting (user, topic) pairs. We develop a Gibbs …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:pcWPcJyQGiUC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2021,"Aims
To assess whether chemotherapy response score (CRS) is associated with surgical end-result in interval debulking surgery (IDS) for tubo-ovarian cancer patients and determine its prognostic significance.
Background
CRS is a histopathological three-tier score for assessing tumour regression in omentectomy specimens after neoadjuvant chemotherapy (NACT), and original study concluded that prognostically, CRS is more important than completeness of cytoreduction (CC) in IDS. This has not been proved by other validation studies. There is a conflict in evidence regarding significance of improvement of overall survival (OS) with CRS-3 in available literature. Evidence of association of CRS with radiological and biochemical (CA-125 decline) response is lacking and conflicting.
Methods
Patients who underwent …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:WsFh9Szeq2wC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2021,"Curriculum learning is a training strategy that sorts the training examples by some measure of their difficulty and gradually exposes them to the learner to improve the network performance. Motivated by our insights from implicit curriculum ordering, we first introduce a simple curriculum learning strategy that uses statistical measures such as standard deviation and entropy values to score the difficulty of data points for real image classification tasks. We empirically show its improvements in performance with convolutional and fully-connected neural networks on multiple real image datasets. We also propose and study the performance of a dynamic curriculum learning algorithm. Our dynamic curriculum algorithm tries to reduce the distance between the network weight and an optimal weight at any training step by greedily sampling examples with gradients that are directed towards the optimal weight. Further, we use our algorithms to discuss why curriculum learning is helpful.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:lL5f5cZgq8MC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2021,"Low-latency gravitational wave search pipelines such as GstLAL take advantage of low-rank factorization of the template matrix via singular value decomposition (SVD). With unprecedented improvements in detector bandwidth and sensitivity in advanced-LIGO and Virgo detectors, one expects several orders of magnitude increase in the size of template banks. This poses a formidable computational challenge in factorizing huge template matrices. Previously, [in Kulkarni et al. [6]], we introduced the idea of random projection (RP)-based matrix factorization as a computationally viable alternative to SVD, applicable for large template banks. This follow-up paper demonstrates the application of a block-wise randomized matrix factorization (RMF) algorithm for computing low-rank factorizations at a preset average fractional loss of SNR. This new scheme is shown to be more efficient in the context of the LLOID framework of the GstLAL search pipeline. Further, it is well-known that for huge template banks, the total computational cost of the search is dominated by reconstructing the detection statistic compared to that of filtering the data. However, optimizing the reconstruction cost has not been addressed satisfactorily so far in the available literature. We show that it is possible to approximately reconstruct the time-series of the matched-filter detection statistic at a fraction of the total cost using the matching pursuit algorithm. Combining the two algorithms presented in this paper can handle online searches involving large template banks more efficiently. We have analyzed the total computational cost in detail and offer various tips for optimally applying the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:xEMdJR0kL_sC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2020,"We present algorithms that create coresets in an online setting for clustering problems according to a wide subset of Bregman divergences. Notably, our coresets have a small additive error, similar in magnitude to the lightweight coresets Bachem et. al. 2018, and take update time for every incoming point where is dimension of the point. Our first algorithm gives online coresets of size for -clusterings according to any -similar Bregman divergence. We further extend this algorithm to show existence of a non-parametric coresets, where the coreset size is independent of , the number of clusters, for the same subclass of Bregman divergences. Our non-parametric coresets are larger by a factor of ( is number of points) and have similar (small) additive guarantee. At the same time our coresets also function as lightweight coresets for non-parametric versions of the Bregman clustering like DP-Means. While these coresets provide additive error guarantees, they are also significantly smaller (scaling with as opposed to for points in $\~R^d$) than the (relative-error) coresets obtained in Bachem et. al. 2015 for DP-Means. While our non-parametric coresets are existential, we give an algorithmic version under certain assumptions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:qt-6tCTBDsQC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2020,"We study the effect of norm based regularization on the size of coresets for regression problems. Specifically, given a matrix with and a vector and , we analyze the size of coresets for regularized versions of regression of the form . Prior work has shown that for ridge regression (where ) we can obtain a coreset that is smaller than the coreset for the unregularized counterpart ie least squares regression\cite {avron2017sharper}. We show that when , no coreset for regularized regression can have size smaller than the optimal coreset of the unregularized version. The well known lasso problem falls under this category and hence does not allow a coreset smaller than the one for least squares regression. We propose a modified version of the lasso problem and obtain for it a coreset of size smaller than the least square regression. We empirically show that the modified version of lasso also induces sparsity in solution, similar to the original lasso. We also obtain smaller coresets for regression with regularization. We extend our methods to multi response regularized regression. Finally, we empirically demonstrate the coreset performance for the modified lasso and the regression with regularization.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:bFuYayV9R1gC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2020,"Factorizing tensors has recently become an important optimization module in a number of machine learning pipelines, especially in latent variable models. We show how to do this efficiently in the streaming setting. Given a set of vectors, each in , we present algorithms to select a sublinear number of these vectors as coreset, while guaranteeing that the CP decomposition of the -moment tensor of the coreset approximates the corresponding decomposition of the -moment tensor computed from the full data. We introduce two novel algorithmic techniques: online filtering and kernelization. Using these two, we present four algorithms that achieve different tradeoffs of coreset size, update time and working space, beating or matching various state of the art algorithms. In the case of matrices (2-ordered tensor), our online row sampling algorithm guarantees relative error spectral approximation. We show applications of our algorithms in learning single topic modeling.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:0qX8s2k1IRwC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2020,"We address the problem of large scale real-time classification of content posted on social networks, along with the need to rapidly identify novel spam types. Obtaining manual labels for user-generated content using editorial labeling and taxonomy development lags compared to the rate at which new content type needs to be classified. We propose a class of hierarchical clustering algorithms that can be used both for efficient and scalable real-time multiclass classification as well as in detecting new anomalies in user-generated content. Our methods have low query time, linear space usage, and come with theoretical guarantees with respect to a specific hierarchical clustering cost function (Dasgupta, 2016). We compare our solutions against a range of classification techniques and demonstrate excellent empirical performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:KYgttONoxcsC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2019,"Guanine nucleotide binding proteins are characterized by a structurally and mechanistically conserved GTP-binding domain, indispensable for binding GTP. The G domain comprises of five adjacent consensus motifs called G boxes, which are separated by amino acid spacers of different lengths. Several G proteins, discovered over time, are characterized by diverse function and sequence. This sequence diversity is also observed in the G box motifs (specifically the G5 box) as well as the inter-G box spacer length. The Spacers and Mismatch Algorithm (SMA) introduced in this study, can predict G-domains in a given G protein sequence, based on user-specified constraints for approximate G-box patterns and inter-box gaps in each G protein family. The SMA parameters can be customized as more G proteins are discovered and characterized structurally. Family-specific G box motifs including the less characterized G5 motif as well as G domain boundaries were predicted with higher precision. Overall, our analysis suggests the possible classification of G protein families based on family-specific G box sequences and lengths of inter-G box spacers.
Significance Statement
It is difficult to define the boundaries of a G domain as well as predict G boxes and important GTP-binding residues of a G protein, if structural information is not available. Sequence alignment and phylogenetic methods are often unsuccessful, given the sequence diversity across G protein families. SMA is a unique method which uses approximate pattern matching as well as inter-motif separation constraints to predict the locations of G-boxes. It is able to predict all G boxes including …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:f13iAvnbnnYC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2019,"Random projection (RP) is a powerful dimension reduction technique widely used in analysis of high dimensional data. We demonstrate how this technique can be used to improve the computational efficiency of gravitational wave searches from compact binaries of neutron stars or black holes. Improvements in low-frequency response and bandwidth due to detector hardware upgrades pose a data analysis challenge in the advanced LIGO era as they result in increased redundancy in template databases and longer templates due to a higher number of signal cycles in band. The RP-based methods presented here address both these issues within the same broad framework. We first use RP for an efficient, singular value decomposition-inspired template matrix factorization and develop a geometric intuition for why this approach works. We then use RP to calculate approximate time-domain correlations in a lower …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:Wqn_fehR_TUC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2019,"Near isometric orthogonal embeddings to lower dimensions are a fundamental tool in data science and machine learning. In this paper, we present the construction of such embeddings that minimizes the maximum distortion for a given set of points. We formulate the problem as a non convex constrained optimization problem. We first construct a primal relaxation and then use the theory of Lagrange duality to create a dual relaxation. We also suggest a polynomial time algorithm based on the theory of convex optimization to solve the dual relaxation provably. We provide a theoretical upper bound on the approximation guarantees for our algorithm, which depends only on the spectral properties of the dataset. We experimentally demonstrate the superiority of our algorithm compared to baselines in terms of the scalability and the ability to achieve lower distortion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:dj1AAMDQi3QC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2018,"Social media conversations unfold based on complex interactions between users, topics and time. While recent models have been proposed to capture network strengths between users, users' topical preferences and temporal patterns between posting and response times, interaction patterns between topics has not been studied. We propose the Hidden Markov Hawkes Process (HMHP) that incorporates topical Markov Chains within Hawkes processes to jointly model topical interactions along with user-user and user-topic patterns. We propose a Gibbs sampling algorithm for HMHP that jointly infers the network strengths, diffusion paths, the topics of the posts as well as the topic-topic interactions. We show using experiments on real and semi-synthetic data that HMHP is able to generalize better and recover the network strengths, topics and diffusion paths more accurately than state-of-the-art baselines. More …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:43LB_KcVqeAC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2018,"In this paper, we show that for a fixed k, there is an NC algorithm that separates the graphs of rank-width at most k from those with rank-width at least 3 k+ 1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:Q_E8KsG3g9MC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2018,"Increased bandwidth and improved sensitivity at low frequencies in the advanced LIGO/Virgo detectors have led to a vast increase in the number of templates against which data is cross correlated. It has also resulted in longer template waveforms. Both of these effects have amplified the computational cost of the gravitational wave (GW) searches from compact binary systems by several orders of magnitude. In a seminal work, Hanna, Canon et al. have validated the use of the singular value decomposition (SVD) method to deal with a large number of templates. However, performing SVD on large matrices in situ has severe memory and logistical challenges. Random matrix factorization is an efficient technique for low-rank approximation of such large template matrices, where the templates are randomly projected into a much lower dimensional space. The basis vectors in the projected space are obtained by QR …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:pYRxIbzCxX0C,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2018,"Compact-binary coalescences are an important class of sources for the advanced-LIGO detectors. Improved sensitivity at low frequencies and increased bandwidth of the advanced-LIGO and Virgo detectors has resulted in a vast increase in the number of templates to cover the deemed parameter space covering target mass and spin ranges. Further, it has also led to longer template waveforms used for matched-filtering based searches. These in-turns amplify the computational cost of the gravitational wave searches by several orders of magnitude. Random matrix factorization is an efficient technique for the low-rank approximation of a given large template matrix by projecting the template waveforms into a much lower dimensional space. We report the application of such a technique to reduce the high computational costs of adv-LIGO CBC searches. We demonstrate that one can efficiently factorize large template …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:kiex5tMzGo8C,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2018,"Introduction: Adnexal torsion contributes to 2.7-7.4% of all gynaecological emergencies and delayed or misdiagnosis results in loss of ovarian function. Diagnosis is not straight forward, both clinically and radiologically, and it can be confused with a number of other surgical and gynaecological emergencies. Aim: The aim of the present study was to correctly identify ovarian torsion among different cyst accidents, its overall incidence, the types of surgery involved and the histopathological diagnoses of the twisted adnexal masses in a prospective observation over two years. Materials and Methods: The clinical scoring was used in one group (n= 14) and its reliability was assessed in correct identification of adnexal torsion by comparing with another group without the scoring (n= 12). This scoring was developed in an Institute in Paris in (2000-04) using logistic regression model to select a combination of five best …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:QlnOKEPDpKwC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2018,"Named entity disambiguation (NED) is a central problem in information extraction. The goal is to link entities in a knowledge graph (KG) to their mention spans in unstructured text. Each distinct mention span (like John Smith, Jordan or Apache) represents a multi-class classification task. NED can therefore be modeled as a multitask problem with tens of millions of tasks for realistic KGs. We initiate an investigation into neural representations, network architectures, and training protocols for multitask NED. Specifically, we propose a task-sensitive representation learning framework that learns mention dependent representations, followed by a common classifier. Parameter learning in our framework can be decomposed into solving multiple smaller problems involving overlapping groups of tasks. We prove bounds for excess risk, which provide additional insight into the problem of multi-task representation learning. While remaining practical in terms of training memory and time requirements, our approach outperforms recent strong baselines, on four benchmark data sets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:S0CDQJw8Yr4C,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2018,"Many modern applications of AI such as web search, mobile browsing, image processing, and natural language processing rely on finding similar items from a large database of complex objects. Due to the very large scale of data involved (e.g., users’ queries from commercial search engines), computing such near or nearest neighbors is a non-trivial task, as the computational cost grows significantly with the number of items. To address this challenge, we adopt Locality Sensitive Hashing (a.k.a, LSH) methods and evaluate four variants in a distributed computing environment (specifically, Hadoop). We identify several optimizations which improve performance, suitable for deployment in very large scale settings. The experimental results demonstrate our variants of LSH achieve the robust performance with better recall compared with “vanilla” LSH, even when using the same amount of space.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:plAW456RD7MC,http://sites.google.com/site/anirbandasgupta
Anirban Dasgupta,"['algorithms', 'data mining', 'social networks']",21,3669,2018,"The classic Mallows model is a widely-used tool to realize distributions on per-mutations. Motivated by common practical situations, in this paper, we generalize Mallows to model distributions on top-k lists by using a suitable distance measure between top-k lists. Unlike many earlier works, our model is both analytically tractable and computationally efficient. We demonstrate this by studying two basic problems in this model, namely, sampling and reconstruction, from both algorithmic and experimental points of view.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=plJC8R0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=plJC8R0AAAAJ:uoeYKOKFegwC,http://sites.google.com/site/anirbandasgupta
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2023,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:tS2w5q8j5-wC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,"The game of rendezvous with adversaries is a game on a graph played by two players: Facilitator and Divider. Facilitator has two agents and Divider has a team of agents. While the initial positions of Facilitator's agents are fixed, Divider gets to select the initial positions of his agents. Then, they take turns to move their agents to adjacent vertices (or stay put) with Facilitator's goal to bring both her agents at same vertex and Divider's goal to prevent it. The computational question of interest is to determine if Facilitator has a winning strategy against Divider with agents. Fomin, Golovach, and Thilikos [WG, 2021] introduced this game and proved that it is PSPACE-hard and co-W[2]-hard parameterized by the number of agents. This hardness naturally motivates the structural parameterization of the problem. The authors proved that it admits an FPT algorithm when parameterized by the modular width and the number of allowed rounds. However, they left open the complexity of the problem from the perspective of other structural parameters. In particular, they explicitly asked whether the problem admits an FPT or XP-algorithm with respect to the treewidth of the input graph. We answer this question in the negative and show that Rendezvous is co-NP-hard even for graphs of constant treewidth. Further, we show that the problem is co-W[1]-hard when parameterized by the feedback vertex set number and the number of agents, and is unlikely to admit a polynomial kernel when parameterized by the vertex cover number and the number of agents. Complementing these hardness results, we show that the Rendezvous is FPT when parameterized by both …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:738O_yMBCRsC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,"The Eternal Vertex Cover problem is a dynamic variant of the vertex cover problem. We have a two player game in which guards are placed on some vertices of a graph. In every move, one player (the attacker) attacks an edge. In response to the attack, the second player (the defender) moves some of the guards along the edges of the graph in such a manner that at least one guard moves along the attacked edge. If such a movement is not possible, then the attacker wins. If the defender can defend the graph against an infinite sequence of attacks, then the defender wins.
The minimum number of guards with which the defender has a winning strategy is called the eternal vertex cover number of the graph G. On general graphs, the computational problem of determining the minimum eternal vertex cover number is -hard and admits a 2-approximation algorithm and an exponential kernel. The complexity of the problem …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:OU6Ihb5iCvQC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,التقسيم الثلاثي للحديث عند أهل السنّة (أبناء العامّة). أدعية لدفع السحر والعين. أصحاب الفيل أصحاب السبت أصحاب الرس أصحاب الأيكة أصحاب الأعراف أصحاب الأخدود التشققات والندب على ثمار الفلفل الطلاق اسس الحياة المشتركة بين الزوجين نـشـوء سـوق العـمـلات الأوربـيـة Euro Dollar Market والعوامـل المساعـدة لتطويـر التمـويـل الدولـي الطفل والحاجة الى الحرية تـشكـيـل دعائـم النـظام الاقتـصادي العـالـمي الخطر الكامن في عدم الإجابة عن أسئلة الطفل,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:l7t_Zn2s7bgC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,"We introduce a generalization of ""Solo Chess"", a single-player variant of the game that can be played on chess.com. The standard version of the game is played on a regular 8 x 8 chessboard by a single player, with only white pieces, using the following rules: every move must capture a piece, no piece may capture more than 2 times, and if there is a King on the board, it must be the final piece. The goal is to clear the board, i.e, make a sequence of captures after which only one piece is left. We generalize this game to unbounded boards with pieces, each of which have a given number of captures that they are permitted to make. We show that Generalized Solo Chess is NP-complete, even when it is played by only rooks that have at most two captures remaining. It also turns out to be NP-complete even when every piece is a queen with exactly two captures remaining in the initial configuration. In contrast, we show that solvable instances of Generalized Solo Chess can be completely characterized when the game is: a) played by rooks on a one-dimensional board, and b) played by pawns with two captures left on a 2D board. Inspired by Generalized Solo Chess, we also introduce the Graph Capture Game, which involves clearing a graph of tokens via captures along edges. This game subsumes Generalized Solo Chess played by knights. We show that the Graph Capture Game is NP-complete for undirected graphs and DAGs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:UxriW0iASnsC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,The maximum leaf number l (G) of a graph G is the largest number of tree leaves in any of its spanning trees.(The corresponding smallest number of leaves is known as the minimum leaf number.),https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:SP6oXDckpogC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,"Number sequences, like Fibonacci, Fermat, Markov, Euler, Bernoulli, etc., have been popular in exemplifying a variety of scientific phenomena. Here, we explore the Catalan numbers in the context of ABm step polymerisation and develop a framework to derive its alternative closed form expression. Our approach harnesses the concepts of combinatorics and graph theory, in conjunction with kinetics of AB2 polymerisation to obtain the chain length distribution that directly gives the closed-form expression of Catalan number expressed as a bivariate distribution function. Furthermore, we validate our expression by comparing first 5000 Catalan numbers obtained from its traditional closed-form. As an offshoot, we discuss “pathwidth”, a construct used in graph theory, as a better metrics for describing topology of polymer chains. The framework developed in this work can be extended to ABm step polymerisation and thus, facilitates topological characterisation of hyperbranched polymers (HPs) that ultimately, dictates their structure-property relationships.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:dshw04ExmUIC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,"The b-Exact Multicover problem takes a universe U of n elements, a family of m subsets of U, a function and a positive integer k, and decides whether there exists a subfamily(set cover) of size at most k such that each element u ∈ U is covered by exactly dem(u) sets of . The b-Exact Coverage problem also takes the same input and decides whether there is a subfamily such that there are at least k elements that satisfy the following property: u ∈ U is covered by exactly dem(u) sets of . Both these problems are known to be NP-complete. In the parameterized setting, when parameterized by k, b-Exact Multicover is W[1]-hard even when b = 1. While b-Exact Coverage is FPT under the same parameter, it is known to not admit a polynomial kernel under standard complexity-theoretic assumptions, even when b = 1. In this paper, we investigate these two problems under the assumption that every …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:xtRiw3GOFMkC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,"We study the computational complexity of finding fair allocations of indivisible goods in the setting where a social network on the agents is given. Notions of fairness in this context are “localized”, that is, agents are only concerned about the bundles allocated to their neighbors, rather than every other agent in the system. We comprehensively address the computational complexity of finding locally envy-free and Pareto efficient allocations in the setting where the agents have binary valuations for the goods and the underlying social network is modeled by an undirected graph. We study the problem in the framework of parameterized complexity.
We show that the problem is computationally intractable even in fairly restricted scenarios, for instance, even when the underlying graph is a path. We show NP-hardness for settings where the graph has only two distinct valuations among the agents. We demonstrate W …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:P5F9QuxV20EC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,"Eternal Vertex Cover problem is a dynamic variant of the vertex cover problem. We have a two player game in which guards are placed on some vertices of a graph. In every move, one player (the attacker) attacks an edge. In response to the attack, the second player (defender) moves the guards along the edges of the graph in such a manner that at least one guard moves along the attacked edge. If such a movement is not possible, then the attacker wins. If the defender can defend the graph against an infinite sequence of attacks, then the defender wins. The minimum number of guards with which the defender has a winning strategy is called the Eternal Vertex Cover Number of the graph G. On general graphs, the computational problem of determining the minimum eternal vertex cover number is NP-hard and admits a 2-approximation algorithm and an exponential kernel. The complexity of the problem on bipartite graphs is open, as is the question of whether the problem admits a polynomial kernel. We settle both these questions by showing that Eternal Vertex Cover is NP-hard and does not admit a polynomial compression even on bipartite graphs of diameter six. This result also holds for split graphs. We also show that the problem admits a polynomial time algorithm on the class of cobipartite graphs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:KxtntwgDAa4C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,"The game of rendezvous with adversaries is a game on a graph played by two players: Facilitator and Divider. Facilitator has two agents and Divider has a team of k ≥ 1 agents. While the initial positions of Facilitator’s agents are fixed, Divider gets to select the initial positions of his agents. Then, they take turns to move their agents to adjacent vertices (or stay put) with Facilitator’s goal to bring both her agents at same vertex and Divider’s goal to prevent it. The computational question of interest is to determine if Facilitator has a winning strategy against Divider with k agents. Fomin, Golovach, and Thilikos [WG, 2021] introduced this game and proved that it is PSPACE-hard and co-W[2]-hard parameterized by the number of agents. This hardness naturally motivates the structural parameterization of the problem. The authors proved that it admits an FPT algorithm when parameterized by the modular width and the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:vRqMK49ujn8C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2022,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:p2g8aNsByqUC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2021,"Imbalance is a classical graph layout problem with several applications, particularly in graph drawing. The imbalance of a layout σ is determined by how well-balanced the neighbors of the vertices are in σ. In the present work, we study the problem of Imbalance parameterized by the twin cover of a graph. We show that Imbalance is XP parameterized by twin cover, and FPT when parameterized by the twin cover and the size of the largest clique outside the twin cover. In contrast, we introduce a notion of succinct representations of graphs in terms of their twin cover and demonstrate that Imbalance is NP-hard in the setting of succinct representations, even for graphs that have a twin cover of size one.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:pyW8ca7W8N0C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2021,"Topological features of polymer chains have been used as the key controlling mechanism for the physicochemical properties of hyperbranched polymers (HPs) and, therefore, provide a significant impetus to determine their branching characteristics. Single monomer methodology (SMM) involving ABm step polymerization has been one of the routes to synthesize both compact and segmented HPs. Here, we explore Catalan and half-Catalan numbers in the context of ABm step polymerization to deduce the structural information of HPs. Our approach harnesses the concepts of combinatorics and graph theory to calculate the exact numbers of isomeric, branched and linear, structures of polymer chains. We also demonstrate that the extent of branching of a polymer chain can be measured via pathwidth and establish its bounds as a function of its length. We believe that our findings can be leveraged to design and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:1sJd4Hv_s6UC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2021,"We study the parameterized complexity of the Optimal Defense and Optimal Attack problems in voting. In both the problems, the input is a set of voter groups (every voter group is a district consisting of a set of votes) and two integers k a and k d corresponding to respectively the number of voter groups the attacker can attack and the number of voter groups the defender can defend. A voter group gets removed from the election if it is attacked but not defended. In the Optimal Defense problem, we want to know if it is possible for the defender to commit to a strategy of defending at most k d voter groups such that, no matter which k a voter groups the attacker attacks, the outcome of the election does not change. In the Optimal Attack problem, we want to know if it is possible for the attacker to commit to a strategy of attacking k a voter groups such that, no matter which k d voter groups the defender defends, the outcome of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:2P1L_qKh6hAC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2021,"We study fair resource allocation under a connectedness constraint wherein a set of indivisible items are arranged on a path and only connected subsets of items may be allocated to the agents. An allocation is deemed fair if it satisfies equitability up to one good (EQ1), which requires that agents' utilities are approximately equal. We show that achieving EQ1 in conjunction with well-studied measures of economic efficiency (such as Pareto optimality, non-wastefulness, maximum egalitarian or utilitarian welfare) is computationally hard even for binary additive valuations. On the algorithmic side, we show that by relaxing the efficiency requirement, a connected EQ1 allocation can be computed in polynomial time for any given ordering of agents, even for general monotone valuations. Interestingly, the allocation computed by our algorithm has the highest egalitarian welfare among all allocations consistent with the given ordering. On the other hand, if efficiency is required, then tractability can still be achieved for binary additive valuations with interval structure. On our way, we strengthen some of the existing results in the literature for other fairness notions such as envy-freeness up to one good (EF1), and also provide novel results for negatively-valued items or chores.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:abG-DnoFyZgC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2021,"In the past few decades, the utility of hyperbranched polymers in coatings, drug and gene delivery, additives etc. has provided significant impetus to design molecular architectures with a broad range of physicochemical properties. One of the methods to synthesize these branched polymers is via step polymerization using-type multifunctional monomer. Here, we use combinatorics within the framework of graph theory to obtain structural information about branched polymers. Specifically, we establish one-to-one correspondence between polymer chains and tree data structures and develop various metrics to calculate the exact quantities of isomorphic/non-isomorphic and branched/linear polymer chains. Further, we use the traditional kinetic models to validate our findings. Our approach can be harnessed not only to determine the exact quantity of the hyperbranched polymers formed during synthesis but also be …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:CHSYGLWDkRkC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2021,"We consider the problem of distributing a collection of indivisible objects among agents in a manner that satisfies some desirable notions of fairness and efficiency. We allow agents to “share” goods in order to achieve efficiency and fairness goals which may be otherwise impossible to attain. In this context, our goal is to find allocations that minimize the “amount of sharing”. We follow up on recent work demonstrating that finding fair allocations with minimum sharing is tractable when valuations are non-degenerate, a notion which captures scenarios that are “far from identical”. This result holds for any fixed number of agents. We show that the usefulness of non-degeneracy does not scale to the setting of many agents. In particular, we demonstrate that the problem of finding fractionally Pareto optimal and envy-free allocations is NP-complete even for instances with constant degeneracy and no sharing. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:EUQCXRtRnyEC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2020,"We study the question of finding a set of at most k edges, whose removal makes the input n-vertex graph a disjoint union of s-clubs (graphs of diameter s). Komusiewicz and Uhlmann [DAM 2012] showed that Cluster Edge Deletion (ie, for the case of 1-clubs (cliques)), cannot be solved in time 2 o (k) n O (1) unless the Exponential Time Hypothesis (ETH) fails. But, Fomin et al.[JCSS 2014] showed that if the number of cliques in the output graph is restricted to d, then the problem (d-Cluster Edge Deletion) can be solved in time O (2 O (d k)+ m+ n). We show that assuming ETH, there is no algorithm solving 2-Club Cluster Edge Deletion in time 2 o (k) n O (1). Further, we show that the same lower bound holds in the case of s-Club d-Cluster Edge Deletion for any s≥ 2 and d≥ 2.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:QIV2ME_5wuYC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2020,"In a vertex-colored graph, an edge is happy if its endpoints have the same color. Similarly, a vertex is happy if all its incident edges are happy. Motivated by the computation of homophily in social networks, we consider the algorithmic aspects of the following Maximum Happy Edges (k-MHE) problem: given a partially k-colored graph G and an integer ℓ, find an extended full k-coloring of G making at least ℓ edges happy. When we want to make ℓ vertices happy on the same input, the problem is known as Maximum Happy Vertices (k-MHV). We perform an extensive study into the complexity of the problems, particularly from a parameterized viewpoint. For every k≥ 3, we prove both problems can be solved in time 2 n n O (1). Moreover, by combining this result with a linear vertex kernel of size (k+ ℓ) for k-MHE, we show that the edge-variant can be solved in time 2 ℓ n O (1). In contrast, we prove that the vertex-variant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:bFI3QPDXJZMC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2020,"This Special Issue contains eleven articles—surveys and research papers—that represent fresh and ambitious new directions in the area of Parameterized Complexity. They provide ground-breaking research at the frontiers of knowledge, and they contribute to bridging the gap between theory and practice. The scope and impact of the field continues to increase. Promising avenues and new research challenges are highlighted in this Special Issue.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:_xSYboBqXhAC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2020,"In this paper, we study the Shortest Color Spanning t-Intervals problem, and related generalizations, namely Smallest Color Spanning t-Squares and Smallest Color Spanning t-Circles. The generic setting is the following: we are given n points in the plane (or on a line), each colored with one of k colors. For each color i we also have a demand s i. Given a budget t, we are required to find at most t objects (for example, intervals, squares, circles, etc.) that cover at least s i points of color i. Typically, the goal is to minimize the maximum perimeter or area. We provide exact algorithms for these problems for the cases of intervals, circles and squares, generalizing several known results. In the case of intervals, we provide a comprehensive understanding of the complexity landscape of the problem after taking several natural parameters into account. Given that the problem turns out to be W [1]-hard parameterized by the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:blknAaTinKkC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2020,"Given a set R of red points and a set B of blue points in the plane, the Red-Blue point separation problem asks if there are at most k lines that separate R from B, that is, each cell induced by the lines of the solution is either empty or monochromatic (containing points of only one color). A common variant of the problem is when the lines are required to be axis-parallel. The problem is known to be NP-complete for both scenarios, and W[1]-hard parameterized by k in the former setting and FPT in the latter. We demonstrate a polynomial-time algorithm for the special case when the points lie on a circle. Further, we also demonstrate the W-hardness of a related problem in the axis-parallel setting, where the question is if there are p horizontal and q vertical lines that separate R from B. The hardness here is shown in the parameter p.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:f2IySw72cVMC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2020,"The Chamberlin-Courant and Monroe rules are fundamental and well-studied rules in the literature of multi-winner elections. The problem of determining if there exists a committee of size k that has a Chamberlin-Courant (respectively, Monroe) score of at most r is known to be NP-complete. We consider the following natural problems in this setting: a) given a committee S of size k as input, is it an optimal k-sized committee, and b) given a candidate c and a committee size k, does there exist an optimal k-sized committee that contains c? In this work, we resolve the complexity of both problems for the Chamberlin-Courant and Monroe voting rules in the settings of rankings as well as approval ballots. We show that verifying if a given committee is optimal is coNP-complete whilst the latter problem is complete for . We also demonstrate efficient algorithms for the second problem when the input consists of single-peaked rankings. Our contribution fills an essential gap in the literature for these important multi-winner rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:a0OBvERweLwC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2020,"We consider the problem of protecting and manipulating elections by recounting and changing ballots, respectively. Our setting involves a plurality-based election held across multiple districts, and the problem formulations are based on the model proposed recently by [Elkind et al., IJCAI 2019]. It turns out that both of the manipulation and protection problems are NP-complete even in fairly simple settings. We study these problems from a parameterized perspective with the goal of establishing a more detailed complexity landscape. The parameters we consider include the number voters, and the budgets of the attacker and the defender. While we observe fixed-parameter tractability when parameterizing by number of voters, our main contribution is a demonstration of parameterized hardness when working with the budgets of the attacker and the defender.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:D03iK_w7-QYC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2020,"We consider the minimum power spanning tree (MPST) problem with general and unit demands from a parameterized perspective. The case of unit demands is equivalent to the problem of finding a spanning tree with the smallest possible vertex cover (MCST). We show that MPST is W[1]-hard when parameterized by the vertex cover of the input graph, and is W[2]-hard when parameterized by the solution size—the latter holds even in the case of unit demands. For the special case of unit demands, however, we demonstrate an FPT algorithm when parameterized by treewidth. In the context of kernelization, we show that even MCST is unlikely to admit a polynomial kernel under standard complexity-theoretic assumptions when parameterized by the vertex cover of the input graph.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:yD5IFk8b50cC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2019,"Approval voting provides an opportunity for the agents to make a comment about every candidate, without incurring the overhead of determining a full ranking on the entire set of candidates. This makes approval voting a natural choice for many practical applications. In this work, we focus on the use of approval voting for selecting a committee in scenarios where we can have few outrageous voters whom we call outliers. More specifically, we study the computational complexity of the committee selection problem for commonly used approval-based voting rules in the presence of outliers. Our first result shows that outliers render the committee selection problem intractable for approval, net approval, and minisum approval voting rules. We next study the parameterized complexity of this problem with five natural parameters, namely the target score, the size of the committee (and its dual parameter namely the number of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:JV2RwH3_ST0C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2019,"The Firefighting problem is defined as follows. At time t= 0, a fire breaks out at a vertex of a graph. At each time step t≥ 1, a firefighter permanently defends (protects) an unburned vertex, and the fire then spreads to all undefended neighbors from the vertices on fire. This process stops when the fire cannot spread anymore. The goal is to find a sequence of vertices for the firefighter that maximizes the number of saved (non burned) vertices. The Firefighting problem turns out to be NP-hard even when restricted to bipartite graphs or trees of maximum degree three. We study the parameterized complexity of the Firefighting problem for various structural parameterizations. All our parameters measure the distance to a graph class (in terms of vertex deletion) on which the Firefighting problem admits a polynomial-time algorithm. To begin with, we show that the problem is W [1]-hard when parameterized by the size of a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:lSLTfruPkqcC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2019,"We address the parameterized complexity of Max Colorable Induced Subgraph on perfect graphs. The problem asks for a maximum sized q-colorable induced subgraph of an input graph G. Yannakakis and Gavril (Inf Process Lett 24:133–137, 1987) showed that this problem is NP-complete even on split graphs if q is part of input, but gave an algorithm on chordal graphs. We first observe that the problem is W[2]-hard when parameterized by q, even on split graphs. However, when parameterized by , the number of vertices in the solution, we give two fixed-parameter tractable algorithms.
The first algorithm runs in time where t is the number of maximal independent sets of the input graph.
The second algorithm runs in time on graph classes where the maximum independent set of an induced subgraph can be found in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:SeFeTyx0c_EC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2019,"We consider the problem of matching reconfiguration, where we are given two matchings and in a graph G and the goal is to determine if there exists a sequence of matchings , such that , all consecutive matchings differ by exactly two edges (specifically, any matching is obtained from the previous one by the addition and deletion of one edge), and . It is known that the existence of such a sequence can be determined in polynomial time [5].
We extend the study of reconfiguring matchings to account for the length of the reconfiguration sequence. We show that checking if we can reconfigure to in at most steps is NP-hard, even when the graph is unweighted, bipartite, and the maximum degree is four, and the matchings and are maximum matchings. We propose two simple algorithmic approaches, one of which improves on the brute-force running time …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:GnPB-g6toBAC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2019,"The notion of robustness in the context of committee elections was introduced by Bredereck et al. [SAGT 2018] [2] to capture the impact of small changes in the input preference orders, depending on the voting rules used. They show that for certain voting rules, such as Chamberlin-Courant, checking if an election instance is robust, even to the extent of a small constant, is computationally hard. More specifically, it is NP-hard to determine if one swap in any of the votes can change the set of winning committees with respect to the Chamberlin-Courant voting rule. Further, the problem is also -hard when parameterized by the size of the committee, k. We complement this result by suggesting an algorithm that is in with respect to k. We also show that on nearly-structured profiles, the problem of robustness remains NP-hard. We also address the case of approval ballots, where we show a hardness result …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:M3NEmzRMIkIC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2019,"Consider a fixed voting rule. In the Possible President problem, we are given an election where the candidates are partitioned into parties, and the problem is to determine if, given a party, it is possible for every party to nominate a candidate such that the nominee from is a winner of the election that is obtained by restricting the votes to the nominated candidates. In previous work on this problem, proposed by [10], it was established that Possible President is NP-hard even when the voting rule is Plurality and the election is restricted to single-peaked votes. In this contribution, we initiate a study of the parameterized complexity of the problem. Our main result is that for a natural choice of parameter (namely the number of parties), the problem is W [2]-hard in general but is FPT on the 1D-Euclidean domain. On the other hand, if we parameterize by the size of the largest party, we encounter para-NP-hardness even on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:cFHS6HbyZ2cC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2019,"We consider a natural variant of the well-known Feedback Vertex Set problem, namely the problem of deleting a small subset of vertices or edges to a full binary tree. This version of the problem is motivated by real-world scenarios that are best modeled by full binary trees. We establish that both the edge and vertex deletion variants of the problem are -hard. This stands in contrast to the fact that deleting edges to obtain a forest or a tree is equivalent to the problem of finding a minimum cost spanning tree, which can be solved in polynomial time. We also establish that both problems are by the standard parameter.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:dfsIfKJdRG4C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2019,"We consider variants and generalizations of the dominating set problem on special classes of graphs, specifically, graphs that are a small distance from a tractable class. Here, our focus is mainly on the problems of domination and efficient domination (a variant where we want every vertex to be dominated uniquely) and their respective generalizations to -distance domination.
We consider graphs which are at most vertices away from the following classes: edgless graphs, cluster graphs, split graphs, and complements of bipartite graphs. For the newly introduced parameter CBDS, we show that Dominating Set is W[2]-hard , while in contrast, is FPT for . For this parameter, Efficient Dominating Set turns out to be FPT as well. We generalize known results for Dominating Set parameterized by CVD to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:4OULZ7Gr8RgC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2019,"An edge Hamiltonian path of a graph is a permutation of its edge set where every pair of consecutive edges have a vertex in common. Unlike the seemingly related problem of finding an Eulerian walk, the edge Hamiltonian path is known to be a -hard problem, even on fairly restricted classes of graphs. We introduce a natural optimization variant of the notion of an edge Hamiltonian path, which seeks the longest sequence of distinct edges with the property that every consecutive pair of them has a vertex in common. We call such a sequence of edges an edge-linked path, and study the parameterized complexity of the problem of finding edge-linked paths with at least k edges. We show that the problem is FPT when parameterized by k, and unlikely to admit a polynomial kernel even on connected graphs.
On the other hand, we show that the problem admits a Turing kernel of polynomial size. To the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:fPk4N6BV_jEC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2018,"The colorful components framework is motivated by applications emerging from computational biology. A vertex-colored graph G is said to be colorful if every color appears exactly once. The general goal is to remove a collection of edges from an undirected vertex-colored graph G such that in the resulting graph H all the connected components are colorful. We want H to optimize an appropriate objective function. Two natural functions involve deleting the smallest number of edges (which we refer to as Colorful Components) and maximizing the number of edges in the transitive closure of the remaining components (which we refer to as MEC).
These problems are well-studied from the point of view of classical complexity, approximation algorithms, and parameterized algorithms. We complement and improve on some of the results in the literature concerning MEC and Colorful Components. In the context …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:O3NaXMp0MMsC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2018,"The Coalitional Manipulation problem has been studied extensively in the literature for many voting rules. However, most studies have focused on the complete information setting, wherein the manipulators know the votes of the non-manipulators. While this assumption is reasonable for purposes of showing intractability, it is unrealistic for algorithmic considerations. In most real-world scenarios, it is impractical to assume that the manipulators to have accurate knowledge of all the other votes. In this work, we investigate manipulation with incomplete information. In our framework, the manipulators know a partial order for each voter that is consistent with the true preference of that voter. In this setting, we formulate three natural computational notions of manipulation, namely weak, opportunistic, and strong manipulation. We say that an extension of a partial order is viable if there exists a manipulative vote for that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:iH-uZ7U-co4C,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2018,"Consider a graph and a coloring c of vertices with colors from . A vertex v is said to be happy with respect to c if for all neighbors u of v. Further, an edge (u, v) is happy if . Given a partial coloring c of V, the Maximum Happy Vertex (Edge) problem asks for a total coloring of V extending c to all vertices of V that maximizes the number of happy vertices (edges). Both problems are known to be NP-hard in general even when , and is polynomially solvable when . In [IWOCA 2016] it was shown that both problems are polynomially solvable on trees, and for arbitrary k, it was shown that MHE is NP-hard on planar graphs and is parameterized by the number of precolored vertices and branchwidth.
We continue the study of this problem from a parameterized perspective. Our focus is on both structural and standard parameterizations. To begin with, we establish that the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:ZHo1McVdvXMC,http://www.neeldhara.com/
Neeldhara Misra,"['Theoretical Computer Science', 'Parameterized Algorithms', 'Graph Theory']",14,784,2018,"Two Dots is a popular single-player puzzle video game for iOS and Android. A level of this game consists of a grid of colored dots. The player connects two or more adjacent dots, removing them from the grid and causing the remaining dots to fall, as if influenced by gravity. One special move, which is frequently a game-changer, consists of connecting a cycle of dots: this removes all the dots of the given color from the grid. The goal is to remove a certain number of dots of each color using a limited number of moves. The computational complexity of Two Dots has already been addressed in [Misra, FUN 2016], where it has been shown that the general version of the problem is NP-complete. Unfortunately, the known reductions produce Two Dots levels having both a large number of colors and many columns. This does not completely match the spirit of the game, where, on the one hand, only few colors are allowed, and on the other hand, the grid of the game has only a constant number of columns. In this paper, we partially fill this gap by assessing the computational complexity of Two Dots instances having a small number of colors or columns. More precisely, we show that Two Dots is hard even for instances involving only 3 colors or 2 columns. As a contrast, we also prove that the problem can be solved in polynomial-time on single-column instances with a constant number of goals.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XFgieDYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=XFgieDYAAAAJ:u_35RYKgDlwC,http://www.neeldhara.com/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2023,"Reconstructing images using brain signals of imagined visuals may provide an augmented vision to the disabled, leading to the advancement of Brain-Computer Interface (BCI) technology. The recent progress in deep learning has boosted the study area of synthesizing images from brain signals using Generative Adversarial Networks (GAN). In this work, we have proposed a framework for synthesizing the images from the brain activity recorded by an electroencephalogram (EEG) using small-size EEG datasets. This brain activity is recorded from the subject's head scalp using EEG when they ask to visualize certain classes of Objects and English characters. We use a contrastive learning method in the proposed framework to extract features from EEG signals and synthesize the images from extracted features using conditional GAN. We modify the loss function to train the GAN, which enables it to synthesize 128x128 images using a small number of images. Further, we conduct ablation studies and experiments to show the effectiveness of our proposed framework over other state-of-the-art methods using the small EEG dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:1taIhTC69MYC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Point cloud segmentation and classification are some of the primary tasks in 3D computer vision with applications ranging from augmented reality to robotics. However, processing point clouds using deep learning-based algorithms is quite challenging due to the irregular point formats. Voxelization or 3D grid-based representation are different ways of applying deep neural networks to this problem. In this paper, we propose PointResNet, a residual block-based approach. Our model directly processes the 3D points, using a deep neural network for the segmentation and classification tasks. The main components of the architecture are: 1) residual blocks and 2) multi-layered perceptron (MLP). We show that it preserves profound features and structural information, which are useful for segmentation and classification tasks. The experimental evaluations demonstrate that the proposed model produces the best results for segmentation and comparable results for classification in comparison to the conventional baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:FiytvqdAVhgC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Graph convolution networks (GCNs) have been enormously successful in learning representations over several graph-based machine learning tasks. Specific to learning rich node representations, most of the methods have solely relied on the homophily assumption and have shown limited performance on the heterophilous graphs. While several methods have been developed with new architectures to address heterophily, we argue that by learning graph representations across two spaces i.e., topology and feature space GCNs can address heterophily. In this work, we experimentally demonstrate the performance of the proposed GCN framework over semi-supervised node classification task on both homophilous and heterophilous graph benchmarks by learning and combining representations across the topological and the feature spaces.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:IaI1MmNe2tcC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Conventional 3D convolutional neural networks (CNNs) are computationally expensive, memory intensive, prone to overfitting, and most importantly, there is a need to improve their feature learning capabilities. To address these issues, we propose spatio-temporal short-term Fourier transform (STFT) blocks, a new class of convolutional blocks that can serve as an alternative to the 3D convolutional layer and its variants in 3D CNNs. An STFT block consists of non-trainable convolution layers that capture spatially and/or temporally local Fourier information using an STFT kernel at multiple low frequency points, followed by a set of trainable linear weights for learning channel correlations. The STFT blocks significantly reduce the space-time complexity in 3D CNNs. In general, they use 3.5 to 4.5 times less parameters and 1.5 to 1.8 times less computational costs when compared to the state-of-the-art methods. Furthermore …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:PaBasH6fAo0C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"In this paper, we present a Fast Motion Deblurring-Conditional Generative Adversarial Network (FMD-cGAN) that helps in blind motion deblurring of a single image. FMD-cGAN delivers impressive structural similarity and visual appearance after deblurring an image. Like other deep neural network architectures, GANs also suffer from large model size (parameters) and computations. It is not easy to deploy the model on resource constraint devices such as mobile and robotics. With the help of MobileNet  based architecture that consists of depthwise separable convolution, we reduce the model size and inference time, without losing the quality of the images. More specifically, we reduce the model size by 3–60x compare to the nearest competitor. The resulting compressed Deblurring cGAN faster than its closest competitors and even qualitative and quantitative results outperform various recently proposed state-of-the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:jL-93Qbq4QoC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Deep neural networks have enormous representational power which has lead them to overfit on most datasets. Thus, regularizing them is important in order to reduce overfitting and to enhance their generalization capability. This paper studies the operation of channel patch shuffle as a regularization technique in deep convolutional networks. We propose a novel regularization technique called ShuffieBlock where we show that randomly shuffling small patches or blocks between channels significantly improves their performance. The patches to be shuffled are picked from the same spatial locations in the feature maps such that a patch, when transferred from one channel to another, acts as a structured noise for the later channel. The ShuffieBlock module is easy to implement and improves the performance of several baseline networks for the task of image classification on CIFAR and ImageNet datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:LdasjJ6CEcoC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Automatic plot extraction involves understanding and inferring the data distribution and therefore, extracting individual line plots from an image containing multiple 2D line plots. It is an important problem having many real-world applications. The existing methods for addressing this problem involve a significant amount of human intervention. To minimize this intervention, we propose APEX-Net, a deep learning based framework with novel loss functions for solving the plot extraction problem. Further, we introduce APEX-1M - a new large scale dataset that contains both the plot images and the raw data. We demonstrate the performance of APEX-Net on the APEX-1M test set and show that it obtains impressive accuracy. We also show visual results of our network on unseen plot images and demonstrate that it extracts the shape of the plots to a great extent. Finally, we develop a GUI for plot extraction that can benefit …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:yqoGN6RLRZoC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Graph convolutional networks (GCNs) have achieved impressive performance in learning from graph-structured data. Although GCN and its variants have shown promising results, they continue to remain shallow as their performance drops with an increasing number of layers - a problem popularly known as oversmoothing. This work introduces a simple yet effective idea of feature gating over graph convolution layers to facilitate deeper graph neural networks and address oversmoothing. The proposed feature gating is easy to implement without changing the underlying network architecture and is broadly applicable to GCN and almost any of its variants. Further, we demonstrate the use of feature gating in assigning importance to node features and the nodes for the node classification task. Quantitative analysis on real-world datasets shows that feature gating paves the way for constructing deeper GCNs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:v1_lew4L6wgC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Photometric stereo is a method to obtain surface normals of an object using its images captured under varying illumination directions. The existing deep learning-based methods require multiple images of an object captured using complex image acquisition systems. In this work, we propose a deep learning framework to perform three tasks jointly: (i) lighting estimation, (ii) image relighting, and (iii) surface normal estimation, all from a single input image of an object with non-Lambertian surface and general reflectance. The network explicitly segregates global geometric features and local lighting-specific features of the object from a single image. The local features resemble attached shadows, shadings, and specular highlights, providing valuable lighting estimation and relighting cues. The global features capture the lighting-independent geometric attributes that effectively guide the surface normal estimation. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:U4n9YNQMCAIC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Estimating 3D surface normals through photometric stereo has been of great interest in computer vision research. Despite the success of existing traditional and deep learning-based methods, it is still challenging due to: (i) the requirement of three or more differently illuminated images, (ii) the inability to model unknown general reflectance, and (iii) the requirement of accurate 3D ground truth surface normals and known lighting information for training. In this work, we attempt to address an under-explored problem of photometric stereo using just two differently illuminated images, referred to as the PS2 problem. It is an intermediate case between a single image-based reconstruction method like Shape from Shading (SfS) and the traditional Photometric Stereo (PS), which requires three or more images. We propose an inverse rendering-based deep learning framework, called DeepPS2, that jointly performs surface …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:j7_hQOaDUrUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"The fidelity of a pose transfer system depends on its ability to generate realistic images of a person under novel poses while preserving the desired human attributes (like face, hairstyle, and clothes). However, the visual fidelity is often compromised as the existing methods fail to extract rich appearance and pose features since they propagate the pose and the appearance information through the same pathway. Also, the repeated downsampling in these pathways leads to the loss of finer details, thus producing blurry results. Further, these methods use vanilla convolution that treats all the pixels as important and fail to focus primarily on significant regions needed for the desired transformation. This work proposes an appearance-consistent human pose transfer framework that progressively transforms the person in the source image to the desired target pose using the information from three pathways: an image …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:43bX7VzcjpAC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"We present Deep Mesh Denoising Network (DMD-Net), an end-to-end deep learning framework, for solving the mesh denoising problem. DMD-Net consists of a Graph Convolutional Neural Network in which aggregation is performed in both the primal as well as the dual graph. This is realized in the form of an asymmetric two-stream network, which contains a primal-dual fusion block that enables communication between the primal-stream and the dual-stream. We develop a Feature Guided Transformer (FGT) paradigm, which consists of a feature extractor, a transformer, and a denoiser. The feature extractor estimates the local features, that guide the transformer to compute a transformation, which is applied to the noisy input mesh to obtain a useful intermediate representation. This is further processed by the denoiser to obtain the denoised mesh. Our network is trained on a large scale dataset of 3D objects. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:zCSUwVk65WsC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Due to hardware constraints, standard off-the-shelf digital cameras suffers from low dynamic range (LDR) and low frame per second (FPS) outputs. Previous works in high dynamic range (HDR) video reconstruction uses sequence of alternating exposure LDR frames as input, and align the neighbouring frames using optical flow based networks. However, these methods often result in motion artifacts in challenging situations. This is because, the alternate exposure frames have to be exposure matched in order to apply alignment using optical flow. Hence, over-saturation and noise in the LDR frames results in inaccurate alignment. To this end, we propose to align the input LDR frames using a pre-trained video frame interpolation network. This results in better alignment of LDR frames, since we circumvent the error-prone exposure matching step, and directly generate intermediate missing frames from the same …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:ubry08Y2EpUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Handwritten document image binarization is challenging due to high variability in the written content and complex background attributes such as page style, paper quality, stains, shadow gradients, and non-uniform illumination. While the traditional thresholding methods do not effectively generalize on such challenging real-world scenarios, deep learning-based methods have performed relatively well when provided with sufficient training data. However, the existing datasets are limited in size and diversity. This work proposes LS-HDIB - a large-scale handwritten document image binarization dataset containing over a million document images that span numerous real-world scenarios. Additionally, we introduce a novel technique that uses a combination of adaptive thresholding and seamless cloning methods to create the dataset with accurate ground truths. Through an extensive quantitative and qualitative …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:lgwcVrK6X84C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"Autonomous assembly of objects is an essential task in robotics and 3D computer vision. It has been studied extensively in robotics as a problem of motion planning, actuator control and obstacle avoidance. However, the task of developing a generalized framework for assembly robust to structural variants remains relatively unexplored. In this work, we tackle this problem using a recurrent graph learning framework considering inter-part relations and the progressive update of the part pose. Our network can learn more plausible predictions of shape structure by accounting for priorly assembled parts. Compared to the current state-of-the-art, our network yields up to 10% improvement in part accuracy and up to 15% improvement in connectivity accuracy on the PartNet dataset. Moreover, our resulting latent space facilitates exciting applications such as shape recovery from the point-cloud components. We conduct extensive experiments to justify our design choices and demonstrate the effectiveness of the proposed framework.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:buQ7SEKw-1sC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"While recent learning-based methods have been observed to be superior for several vision-related applications, their potential in generating artistic effects has not been explored much. One such exciting application is Shadow Art-a unique form of sculptural art that produces artistic effects through 2D shadows cast by a 3D sculpture. In this work, we revisit shadow art using differentiable rendering-based optimization frameworks to obtain the 3D sculpture from a set of shadow (binary) images and their corresponding projection information. Specifically, we discuss shape optimization through voxel as well as mesh-based differentiable renderers. Our choice of using differentiable rendering for generating shadow art sculptures can be attributed to its ability to learn the underlying 3D geometry solely from image data, thus reducing the dependence on 3D ground truth. The qualitative and quantitative results demonstrate the potential of the proposed framework in generating complex 3D sculptures that transcend the ones seen in contemporary art pieces using just a set of shadow images as input. Further, we demonstrate the generation of 3D sculptures to cast shadows of faces, animated movie characters, and the applicability of the proposed framework to sketch-based 3D reconstruction of the underlying shapes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:BJbdYPG6LGMC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2022,"We consider the generic deep image enhancement problem where an input image is transformed into a perceptually better-looking image. The methods mostly fall into two categories: training with prior examples methods and training with no-prior examples methods. Recently, Deep Internal Learning solutions to image enhancement in training with no-prior examples setup are gaining attention. We perform image enhancement using a deep internal learning framework. Our Deep Internal Learning for Image Enhancement framework (DILIE) enhances content features and style features and preserves semantics in the enhanced image. To validate the results, we use structure similarity and perceptual error, which is efficient in measuring the unrealistic deformation present in the images. We show that DILIE framework outputs good quality images for hazy and noisy image enhancement tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:ODE9OILHJdcC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,"The prime goal of digital imaging techniques is to reproduce the realistic appearance of a scene. Low Dynamic Range (LDR) cameras are incapable of representing the wide dynamic range of the real-world scene. The captured images turn out to be either too dark (underexposed) or too bright (overexposed). Specifically, saturation in overexposed regions makes the task of reconstructing a High Dynamic Range (HDR) image from single LDR image challenging. In this paper, we propose a deep learning based approach to recover details in the saturated areas while reconstructing the HDR image. We formulate this problem as an image-to-image (I2I) translation task. To this end, we present a novel conditional GAN (cGAN) based framework trained in an end-to-end fashion over the HDR-REAL and HDR-SYNTH datasets. Our framework uses an overexposed mask obtained from a pre-trained segmentation model to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:wMgC3FpKEyYC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,"High dynamic range (HDR) videos provide a more visually realistic experience than the standard low dynamic range (LDR) videos. Despite having significant progress in HDR imaging, it is still a challenging task to capture high-quality HDR video with a conventional off-the-shelf camera. Existing approaches rely entirely on using dense optical flow between the neighboring LDR sequences to reconstruct an HDR frame. However, they lead to inconsistencies in color and exposure over time when applied to alternating exposures with noisy frames. In this paper, we propose an end-to-end GAN-based framework for HDR video reconstruction from LDR sequences with alternating exposures. We first extract clean LDR frames from noisy LDR video with alternating exposures with a denoising network trained in a self-supervised setting. Using optical flow, we then align the neighboring alternating-exposure frames to a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:QD3KBmkZPeQC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,Point cloud is one of the widely used techniques for representing and storing 3D geometric data. In the past several methods have been proposed for processing point clouds. Methods such as PointNet and FoldingNet have shown promising results for tasks like 3D shape classification and segmentation. This work proposes a tree-structured autoencoder framework to generate robust embeddings of point clouds by utilizing hierarchical information using graph convolution. We perform multiple experiments to assess the quality of embeddings generated by the proposed encoder architecture and visualize the t-SNE map to highlight its ability to distinguish between different object classes. We further demonstrate the applicability of the proposed framework in applications like: 3D point cloud completion and Single image-based 3D reconstruction.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:uDGL6kOW6j0C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,"3D point cloud completion problem deals with completing the shape from partial points. The problem finds its application in many vision-related applications. Here, structure plays an important role. Most of the existing approaches either do not consider structural information or consider structure at the decoder only. For maintaining the structure, it is also necessary to maintain the position of the available 3D points. However, most of the approaches lack the aspect of maintaining the available structural position. In this paper, we propose to employ stacked auto-encoder in conjunction a with shared Multi-Layer Perceptron (MLP). MLP converts each 3D point into a feature vector and the stacked auto-encoder helps in maintaining the available structural position of the input points. Further, it explores the redundancy present in the feature vector. It aids to incorporate coarse to fine scale information that further helps in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:F1b5ZUV5XREC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,"Deep neural networks have enormous representational power which leads them to overfit on most datasets. Thus, regularizing them is important in order to reduce overfitting and enhance their generalization capabilities. Recently, channel shuffle operation has been introduced for mixing channels in group convolutions in resource efficient networks in order to reduce memory and computations. This paper studies the operation of channel shuffle as a regularization technique in deep convolutional networks. We show that while random shuffling of channels during training drastically reduce their performance, however, randomly shuffling small patches between channels significantly improves their performance. The patches to be shuffled are picked from the same spatial locations in the feature maps such that a patch, when transferred from one channel to another, acts as structured noise for the later channel. We call this method ""ShuffleBlock"". The proposed ShuffleBlock module is easy to implement and improves the performance of several baseline networks on the task of image classification on CIFAR and ImageNet datasets. It also achieves comparable and in many cases better performance than many other regularization methods. We provide several ablation studies on selecting various hyperparameters of the ShuffleBlock module and propose a new scheduling method that further enhances its performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:cK4Rrx0J3m0C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,"Many computer vision tasks could be formulated as image feature learning tasks where the objective is to perform image restoration or image synthesis. Image restoration is an ill-posed problem aiming to restore an image from a corrupted observation. The image synthesis task is related to synthesizing a new image while preserving various properties such as image context and object structure. The deep learning framework to perform image restoration and image synthesis without using paired samples for training was not explored until 2017. Recently, we have witnessed various research frameworks that are able to perform such tasks without using paired samples. By paired samples, we mean a training dataset consisting of pairs of source and target images, eg, a clean and noisy image pair for image denoising.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:r_AWSJRzSzQC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,"Semantic segmentation is one of the most popular tasks in computer vision. Its applications span from medical image analysis to self driving cars and beyond. For a given image, in semantic segmentation, we generate masks of image segments corresponding to each type or class. However, these segmented maps may either segment a region properly but assign it to a different class or they may have a possibly poor segmented region identification. Hence there is a need to visualize the regions of importance in an image for a given class. Class Activation Maps (CAMs) are popularly used in the classification task to understand the correlation of a class and the regions in an image that correspond to it. We propose a new framework to model the semantic segmentation task as an end to end classification task. This can be used with any deep learning based segmentation network. Using this, we visualize the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:2tRrZ1ZAMYUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,"The camera sensors often fail to capture all the brightness intensities present in the visible spectrum of light. This is due to the limited dynamic range of the sensor elements. When bright light falls on a camera sensor, it is not appropriately measured. The recorded brightness values that fall outside the sensor’s dynamic range are stored as the minimum or maximum value depending on the bit-depth of the sensor. This results in a loss of information and undesirable artifacts in the form of blown-out areas, referred to as over- and under-exposed regions. In this study, we propose to detect these areas in an image using deep learning tools. Our approach uses semantic segmentation to mark the under, over, and correctly exposed regions in the image. We have created a new dataset containing 4928 images to train and test the performance of the model using a pre-trained state-of-the-art model architecture and re …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:Bg7qf7VwUHIC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,"Recently, there is a vast interest in developing image feature learning methods that are independent of the training data, such as deep image prior, InGAN, SinGAN, and DCIL. These methods are unsupervised and are used to perform low-level vision tasks such as image restoration, image editing, and image synthesis. In this work, we proposed a new training data-independent framework, called Deep Contextual Features Learning (DeepCFL), to perform image synthesis and image restoration based on the semantics of the input image. The contextual features are simply the high dimensional vectors representing the semantics of the given image. DeepCFL is a single image GAN framework that learns the distribution of the context vectors from the input image. We show the performance of contextual learning in various challenging scenarios: outpainting, inpainting, and restoration of randomly removed pixels. DeepCFL is applicable when the input source image and the generated target image are not aligned. We illustrate image synthesis using DeepCFL for the task of image resizing.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:fbc8zXXH2BUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2021,"One of the major challenges of style transfer is the appropriate image features supervision between the output image and the input images (style and content). An efficient strategy would be to define an object map between the objects of the style and the content images. However, such a mapping is not well established when there are semantic objects of different types and numbers in the style and the content images. It also leads to content mismatch in the style transfer output, which could reduce the visual quality of the results. We propose an object-based style transfer approach, called DeepObjStyle, for the style supervision in the training data-independent framework. DeepObjStyle preserves the semantics of the objects and achieves better style transfer in the challenging scenario when the style and the content images have a mismatch of image features. We also perform style transfer of images containing a word cloud to demonstrate that DeepObjStyle enables an appropriate image features supervision. We validate the results using quantitative comparisons and user studies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:u-coK7KVo8oC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"In this work, we have proposed a novel computational photography application to generate a Graphics Interchange Format (GIF) image corresponding to High Dynamic Range (HDR) scene involving motion. Though HDR image and GIF image are prevalent in the computational photography community for a long time, according to our literature survey, this is the maiden attempt to combine them in a single framework. Like most other HDR image generation algorithms, the first step in the proposed framework is to capture a sequence of multi-exposure (−2EV, 0EV, 2EV) low dynamic range (LDR) images. The decided exposures (−2EV, 0EV, 2EV) are varied in a round-robin fashion, and continuous frames are captured to get adequate information about the motion of the scene. The next step is to combine sets of three consecutive multi-exposure LDR images to generate HDR images. Further, we take two …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:AHdEip9mkN0C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"Consider a set of n images of a scene with dynamic objects captured with a static or a handheld camera. Let the temporal order in which these images are captured be unknown. There can be n! possibilities for the temporal order in which these images could have been captured. In this work, we tackle the problem of temporally sequencing the unordered set of images of a dynamic scene captured with a hand-held camera. We propose a convolutional block which captures the spatial information through 2D convolution kernel and captures the temporal information by utilizing the differences present among the feature maps extracted from the input images. We evaluate the performance of the proposed approach on the dataset extracted from a standard action recognition dataset, UCF101. We show that the proposed approach outperforms the state-of-the-art methods by a significant margin. We show that the network generalizes well by evaluating it on a dataset extracted from the DAVIS dataset, a dataset meant for video object segmentation, when the same network was trained with a dataset extracted from UCF101, a dataset meant for action recognition.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:IRz6iEL74y4C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"Reflection symmetry is a very commonly occurring feature in both natural and man-made objects, which helps in understanding objects better and makes them visually pleasing. Detection of reflection symmetry is a fundamental problem in the field of computer vision and computer graphics which aids in understanding and representing reflective symmetric objects. In this work, we attempt the problem of detecting the 3D global reflection symmetry of a 3D object represented as a point cloud. The main challenge is to handle outliers, missing parts, and perturbations from the perfect reflection symmetry. We propose a descriptor-free approach, in which, we pose the problem of reflection symmetry detection as an optimization problem and provide a closed-form solution. We show that the proposed method achieves state-of-the-art performance on the standard dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:DUooU5lO8OsC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"Consider a set of images of a scene captured from multiple views with some missing regions in each image. In this work, we propose a convolutional neural network (CNN) architecture which fills the missing regions in one image using the information present in the remaining images. The network takes the set of images and their corresponding binary maps as inputs and generates an image with the completed missing regions. The binary map indicates the missing regions present in the corresponding image. The network is trained using an adversarial approach and is observed to generate sharp output images qualitatively. We evaluate the performance of the proposed approach on the dataset extracted from the standard dataset, MVS-Synth.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:QYdC8u9Cj1oC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"Traditional 3D convolutions are computationally expensive, memory intensive, and due to large number of parameters, they often tend to overfit. On the other hand, 2D CNNs are less computationally expensive and less memory intensive than 3D CNNs and have shown remarkable results in applications like image classification and object recognition. However, in previous works, it has been observed that they are inferior to 3D CNNs when applied on a spatio-temporal input. In this work, we propose a convolutional block which extracts the spatial information by performing a 2D convolution and extracts the temporal information by exploiting temporal differences, i.e., the change in the spatial information at different time instances, using simple operations of shift, subtract and add without utilizing any trainable parameters. The proposed convolutional block has same number of parameters as of a 2D convolution kernel of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:NyGDZy8z5eUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"In this work, we address the problem of extracting high dimensional, soft semantic feature descriptors for every pixel in an image using a deep learning framework. Existing methods rely on a metric learning objective called multi-class N-pair loss, which requires pairwise comparison of positive examples (same class pixels) to all negative examples (different class pixels). Computing this loss for all possible pixel pairs in an image leads to a high computational bottleneck. We show that this huge computational overhead can be reduced by learning this metric based on superpixels. This also conserves the global semantic context of the image, which is lost in pixel-wise computation because of the sampling to reduce comparisons. We design an end-to-end trainable network with a loss function and give a detailed comparison of two feature extraction methods: pixel-based and superpixel-based. We also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:sJsF-0ZLhtgC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"Consider a set of images of a scene consisting of moving objects captured using a hand-held camera. In this work, we propose an algorithm which takes this set of multi-view images as input, detects the dynamic objects present in the scene, and replaces them with the static regions which are being occluded by them. The proposed algorithm scans the reference image in the row-major order at the pixel level and classifies each pixel as static or dynamic. During the scan, when a pixel is classified as dynamic, the proposed algorithm replaces that pixel value with the corresponding pixel value of the static region which is being occluded by that dynamic region. We show that we achieve artifact-free removal of dynamic objects in multi-view images of several real-world scenes. To the best of our knowledge, we propose the first method which simultaneously detects and removes the dynamic objects present in multi-view images.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:IUKN3-7HHlwC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"Recently, there is a vast interest in developing methods which are independent of the training samples such as deep image prior, zero-shot learning, and internal learning. The methods above are based on the common goal of maximizing image features learning from a single image despite inherent technical diversity. In this work, we bridge the gap between the various unsupervised approaches above and propose a general framework for image restoration and image retargeting. We use contextual feature learning and internal learning to improvise the structure similarity between the source and the target images. We perform image resize application in the following setups: classical image resize using super-resolution, a challenging image resize where the low-resolution image contains noise, and content-aware image resize using image retargeting. We also provide comparisons to the relevant state-of-the-art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:OTTXONDVkokC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"Human pose estimation is a well-known problem in computer vision to locate joint positions. Existing datasets for learning of poses are observed to be not challenging enough in terms of pose diversity, object occlusion and view points. This makes the pose annotation process relatively simple and restricts the application of the models that have been trained on them. To handle more variety in human poses, we propose the concept of fine-grained hierarchical pose classification, in which we formulate the pose estimation as a classification task, and propose a dataset, Yoga-82, for large-scale yoga pose recognition with 82 classes. Yoga-82 consists of complex poses where fine annotations may not be possible. To resolve this, we provide hierarchical labels for yoga poses based on the body configuration of the pose. The dataset contains a three-level hierarchy including body positions, variations in body positions, and the actual pose names. We present the classification accuracy of the state-of-the-art convolutional neural network architectures on Yoga-82. We also present several hierarchical variants of DenseNet in order to utilize the hierarchical labels.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:mlAyqtXpCwEC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"Blind motion deblurring involves reconstructing a sharp image from an observation that is blurry. It is a problem that is ill-posed and lies in the categories of image restoration problems. The training data-based methods for image deblurring mostly involve training models that take a lot of time. These models are data-hungry i.e., they require a lot of training data to generate satisfactory results. Recently, there are various image feature learning methods developed which relieve us of the need for training data and perform image restoration and image synthesis, e.g., DIP, InGAN, and SinGAN. SinGAN is a generative model that is unconditional and could be learned from a single natural image. This model primarily captures the internal distribution of the patches which are present in the image and is capable of generating samples of varied diversity while preserving the visual content of the image. Images generated from the model are very much like real natural images. In this paper, we focus on blind motion deblurring through SinGAN architecture.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:WJVC3Jt7v1AC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2020,"In this paper, we propose a new convolutional layer called Depthwise-STFT Separable layer that can serve as an alternative to the standard depthwise separable convolutional layer. The construction of the proposed layer is inspired by the fact that the Fourier coefficients can accurately represent important features such as edges in an image. It utilizes the Fourier coefficients computed (channelwise) in the 2D local neighborhood (e.g., 3 × 3) of each position of the input map to obtain the feature maps. The Fourier coefficients are computed using 2D Short Term Fourier Transform (STFT) at multiple fixed low frequency points in the 2D local neighborhood at each position. These feature maps at different frequency points are then linearly combined using trainable pointwise (1 × 1) convolutions. We show that the proposed layer outperforms the standard depthwise separable layer based models on the CIFAR-10 and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:a9-T7VOCCH8C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"High dynamic range (HDR) image generation from a single exposure low dynamic range (LDR) image has been made possible due to the recent advances in Deep Learning. Various feed-forward Convolutional Neural Networks (CNNs) have been proposed for learning LDR to HDR representations. To better utilize the power of CNNs, we exploit the idea of feedback, where the initial low level features are guided by the high level features using a hidden state of a Recurrent Neural Network. Unlike a single forward pass in a conventional feed-forward network, the reconstruction from LDR to HDR in a feedback network is learned over multiple iterations. This enables us to create a coarse-to-fine representation, leading to an improved reconstruction at every iteration. Various advantages over standard feed-forward networks include early reconstruction ability and better reconstruction quality with fewer network …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:umqufdRvDiIC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Person re-identification aims to associate images of the same person over multiple non-overlapping camera views at different times. Depending on the human operator, manual re-identification in large camera networks is highly time consuming and erroneous. Automated person re-identification is required due to the extensive quantity of visual data produced by rapid inflation of large scale distributed multi-camera systems. The state-of-the-art works focus on learning and factorize person appearance features into latent discriminative factors at multiple semantic levels. We propose Deep Parallel Feature Consensus Network (DeepPFCN), a novel network architecture that learns multi-scale person appearance features using convolutional neural networks. This model factorizes the visual appearance of a person into latent discriminative factors at multiple semantic levels. Finally consensus is built. The feature …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:6yz0xqPARnAC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:FAceZFleit8C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Extensive use of text labels and symbols available in the digital media for interpretation and communication of information has gained a lot of attention in the era of digital media. Access of the images with scene text in it through different display devices tend to deform the scene text region while resizing for better viewing experience. We propose an image retargeting operator, which is aware of the scene text present in the image. We perform the normal seam carving depending on the content of the image for the non-text region. We find the target size of each scene text region during the seam carving process. Having the location and the size of the scene text region in the retargeted image, we perform content-aware warping for every scene text region in the image. We evaluate the performance of the proposed scene text aware image retargeting operator using image retargeting quality assessment metric for visual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:sNmaIFBj_lkC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"The process of rendering high dynamic range (HDR) images to be viewed on conventional displays is called tone mapping. However, tone mapping introduces distortions in the final image which may lead to visual displeasure. To quantify these distortions, we introduce a novel no-reference quality assessment technique for these tone mapped images. This technique is composed of two stages. In the first stage, we employ a convolutional neural network (CNN) to generate quality aware maps (also known as distortion maps) from tone mapped images by training it with the ground truth distortion maps. In the second stage, we model the normalized image and distortion maps using an Asymmetric Generalized Gaussian Distribution (AGGD). The parameters of the AGGD model are then used to estimate the quality score using support vector regression (SVR). We show that the proposed technique delivers competitive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:YohjEiUPhakC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Reflection symmetry is one of the most commonly occurring and prominent visual attributes present in the real world. With an increase in the display devices of different sizes and aspect ratios, the images captured from the real world need to be resized to fit to the display device. In this paper, we propose a novel image retargeting approach which preserves the reflection symmetry present in the image during the image retargeting process. We detect the symmetry region present in the image using symmetry axis detection and object proposals. We propose a novel framework for finding an optimized reflected seam for the least energy seam defined by the seam carving approach. The symmetry axis and the symmetric object are preserved by adding or removing a seam and its reflected counterpart together. We show better preservation of symmetry axis, preservation of shape of the symmetric object, and quality of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:PoWvk5oyLR8C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Many real-world solutions for image restoration are learning-free and based on handcrafted image priors such as self-similarity. Recently, deep-learning methods that use training data have achieved state-of-the-art results in various image restoration tasks (e.g., super-resolution and inpainting). Ulyanov et al. bridge the gap between these two families of methods (CVPR 18). They have shown that learning-free methods perform close to the state-of-the-art learning-based methods (approximately 1 PSNR). Their approach benefits from the encoder-decoder network. In this paper, we propose a framework based on the multi-level extensions of the encoder-decoder network, to investigate interesting aspects of the relationship between image restoration and network construction independent of learning. Our framework allows various network structures by modifying the following network components: skip links …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:mNrWkgRL2YcC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"In this paper, we propose Rectified Local Phase Unit (ReLPU), which is an efficient and trainable convolutional layer that utilizes phase information computed locally in a window for every pixel location of the input image. The ReLPU layer is based on applying the Rectified Linear Unit (ReLU) activation function on the local phase information extracted by computing the local Fourier transform of the input image at multiple low frequency points. The ReLPU layer, when used at the top of the segmentation network U-Net, is observed to improve the performance of the baseline U-Net model. We demonstrate this using the task of segmenting blood vessels in fundus images of two standard datasets, DRIVE and STARE, achieving state-of-the-art results. An important feature of the ReLPU layer is that it is trainable which allows it to choose the best frequency points for computing local Fourier transform and to selectively give …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:xtoqd-5pKcoC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Reflection symmetry is ubiquitous in nature and plays an important role in object detection and recognition tasks. Most of the existing methods for symmetry detection extract and describe each keypoint using a descriptor and a mirrored descriptor. Two keypoints are said to be mirror symmetric key-points if the original descriptor of one keypoint and the mirrored descriptor of the other keypoint are similar. However, these methods suffer from the following issue. The background pixels around the mirror symmetric pixels lying on the boundary of an object can be different. Therefore, their descriptors can be different. However, the boundary of a symmetric object is a major component of global reflection symmetry. We exploit the estimated boundary of the object and describe a boundary pixel using only the estimated normal of the boundary segment around the pixel. We embed the symmetry axes in a graph as cliques to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:Dip1O2bNi0gC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Display of images on different display devices having varied size and aspect ratio requires one to resize them. Many attempts have been made to perform content‐aware image retargeting while generating an image compatible with a target display size. Seam carving is one of the image retargeting operators which alters the size of an image by removing least energy pixels. However, it requires high computational time in order to perform retargeting. In this study, the authors accelerate the naive seam carving process by removal or insertion of multiple pixel wide batch seam in a single iteration rather than a single pixel wide seam. Along with the energy of pixels to be removed, inserted energy after the removal of a batch seam is also minimised in order to prevent the inclusion of false edges. The width of a batch seam is a critical factor which is made adaptive during the retargeting process to preserve the energy of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:k8Z6L05lTy4C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"A scene can be divided into two parts: static and dynamic. The parts of the scene which do not admit any motion are static regions, while moving objects correspond to dynamic regions. In this work, we tackle the challenging task of identifying dynamic objects present in the CrowdCam images. Our approach exploits the coherency present in the natural images and utilizes the epipolar geometry present between a pair of images to achieve this objective. It does not require a dynamic object to be present in all the given images. We show that the proposed approach obtains state-of-the-art accuracy on standard datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:FPJr55Dyh1AC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Content-aware image retargeting methods address the resizing of an image to be displayed on devices having different aspect ratios and resolutions. Seam carving method is an effective image retargeting method which suffers from high computational complexity. It requires one to find one-pixel wide minimum energy path in either vertical or horizontal direction, called seam, to reduce the image size by one pixel. In this paper, we propose an acceleration of the seam carving method by expanding the width of the seam making it multiple-pixel wide seam carving. The two types of energies: one corresponding to the pixels to be removed and another corresponding to the pixels across the multiple-pixel wide seam, increase as the width of the seam increases. In order to prevent the increase in these energies, we make the width of the seam adaptive as a function of the number of iterations. We find the width of a seam …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:lmc2jWPfTJgC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,We propose an algorithm to detect approximate reflection symmetry present in a set of volumetrically distributed points belonging to ℝ d containing a distorted reflection symmetry pattern. We pose the problem of detecting approximate reflection symmetry as the problem of establishing correspondences between the points which are reflections of each other and we determine the reflection symmetry transformation. We formulate an optimization framework in which the problem of establishing the correspondences amounts to solving a linear assignment problem and the problem of determining the reflection symmetry transformation amounts to solving an optimization problem on a smooth Riemannian product manifold. The proposed approach estimates the symmetry from the geometry of the points and is descriptor independent. We evaluate the performance of the proposed approach on the standard benchmark …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:HbR8gkJAVGIC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Recognizing facial expressions is one of the central problems in computer vision. Temporal image sequences have useful spatio-temporal features for recognizing expressions. In this paper, we propose a new 3D Convolution Neural Network (CNN) that can be trained end-to-end for facial expression recognition on temporal image sequences without using facial landmarks. More specifically, a novel 3D convolutional layer that we call Local Binary Volume (LBV) layer is proposed. The LBV layer, when used with our newly proposed LBVCNN network, achieve comparable results compared to state-of-the-art landmark-based or without landmark-based models on image sequences from CK+, Oulu-CASIA, and UNBC McMaster shoulder pain datasets. Furthermore, our LBV layer reduces the number of trainable parameters by a significant amount when compared to a conventional 3D convolutional layer. As a matter of fact, when compared to a 3x3x3 conventional 3D convolutional layer, the LBV layer uses 27 times less trainable parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:cWzG1nlazyYC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Traditional 3D Convolutional Neural Networks (CNNs) are computationally expensive, memory intensive, prone to overfit, and most importantly, there is a need to improve their feature learning capabilities. To address these issues, we propose Rectified Local Phase Volume (ReLPV) block, an efficient alternative to the standard 3D convolutional layer. The ReLPV block extracts the phase in a 3D local neighborhood (eg, 3x3x3) of each position of the input map to obtain the feature maps. The phase is extracted by computing 3D Short Term Fourier Transform (STFT) at multiple fixed low frequency points in the 3D local neighborhood of each position. These feature maps at different frequency points are then linearly combined after passing them through an activation function. The ReLPV block provides significant parameter savings of at least, 3^ 3 to 13^ 3 times compared to the standard 3D convolutional layer with the filter sizes 3x3x3 to 13x13x13, respectively. We show that the feature learning capabilities of the ReLPV block are significantly better than the standard 3D convolutional layer. Furthermore, it produces consistently better results across different 3D data representations. We achieve state-of-the-art accuracy on the volumetric ModelNet10 and ModelNet40 datasets while utilizing only 11% parameters of the current state-of-the-art. We also improve the state-of-the-art on the UCF-101 split-1 action recognition dataset by 5.68%(when trained from scratch) while using only 15% of the parameters of the state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:HIFyuExEbWQC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Competitive diving is a well recognized aquatic sport in which a person dives from a platform or a springboard into the water. Based on the acrobatics performed during the dive, diving is classified into a finite set of action classes which are standardized by FINA. In this work, we propose an attention guided LSTM-based neural network architecture for the task of diving classification. The network takes the frames of a diving video as input and determines its class. We evaluate the performance of the proposed model on a recently introduced competitive diving dataset, Diving48. It contains over 18000 video clips which covers 48 classes of diving. The proposed model outperforms the classification accuracy of the state-of-the-art models in both 2D and 3D frameworks by 11.54% and 4.24%, respectively. We show that the network is able to localize the diver in the video frames during the dive without being trained with such a supervision.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:dBIO0h50nwkC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Person re-identification aims to associate images of the same person over multiple dis-joint camera views at different times. Depending on the human operator, manual re-identification in a large set of camera networks is highly time consuming and erroneous. Automated person re-identification is required because of the extensive quality of visual data produced by fast inflation of large scale distributed multicamera systems. The state-of-the-art works focus on learning and factorize person appearance features into latent discriminative factors at multiple semantic levels. We propose Deep Parallel Feature Consensus Network (DeepPFCN), a novel network architecture that learns multi-scale person appearance features using convolutional neural networks and factorizes the visual feature of a person into latent discriminative factors at multiple semantic levels and after that consensus is achieved. The feature representations learned by DeepPFCN are more robust for the person reidentification task, as we learn discriminative multi-scale features and maximize multi-scale feature fusion selections in multi-scale image inputs. We further, exploit average and max-pooling in separate scales for the person-specific task to discriminate features globally and locally. We illustrate the re-identification benefits of the proposed DeepPFCN model over the state-of-the-art re-identification methods on three benchmark datasets-Market1501, DukeMTMCreID, and CUHK03. We have achieved mAP results of 75.8%, 64.3%, and 52.6% respectively on these benchmark datasets.
Rath Yatra is celebrated in Ahmedabad every year with a procession throughout …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:86PQX7AUzd4C,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"The resizing of stereo images while preserving salient content and geometric consistency between the image pair is an essential problem to be addressed for 3D visualization. Existing stereo image retargeting techniques are observed to be incurring salient object deformation. In this paper, we formulate a seam carving method to perform stereo image retargeting using graph-cuts having node size as the number of pixels in one of the stereo images. We define the object map with depth ordering of each object from the camera. The seams are allowed to pass along the object-object occlusion boundary at depth discontinuity in order to prevent salient object deformation. We propose adaptive occlusion boundary weights as a function of an object area to be occluded to preserve small objects. The seam passing through object-object occlusion boundary in one image may not follow the exact boundary in the other …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:PVjk1bu6vJQC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"In the past years, there have been several attempts for the task of object localization in an image. However, most of the algorithms for object localization have been either supervised or weakly supervised. The work presented in this paper is based on the localization of a single object instance, in an image, in a fully unsupervised manner. Initially, from the input image, object proposals are generated where the proposal score for each of these proposals is calculated using a saliency map. Next, a graph by the GIST feature similarity between each pair of proposals is constructed. Density-based spatial clustering of applications with noise (DBSCAN) is used to make clusters of proposals based on GIST similarity, which eventually helps us in the final localization of the object. The setup is evaluated on two challenging benchmark datasets - PASCAL VOC 2007 dataset and object discovery dataset. The performance of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:VaXvl8Fpj5cC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2019,"Consider a set of n images of a dynamic scene captured using multiple hand-held devices. The order in which these images are captured is unknown. For n images, there can be n! possible arrangements, which makes this problem extremely challenging. In this work, we address the problem of sequencing such a set of unordered images in its temporal order. We propose an LSTM-based deep neural network which addresses this problem in an end-to-end manner. The network takes the set of images as input and outputs their order of capture. We formulate the problem as a sequence-to-sequence mapping task, in which each image is mapped to its position in the ordered sequence. We do not provide any other information to the network apart from the input images. We show that the proposed approach obtains the state-of-the-art results on the standard dataset. Further, we show through experimental results that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:tuHXwOkdijsC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2018,"Over-segmentation of an image into superpixels has become a useful tool for solving various problems in image processing and computer vision. Reflection symmetry is quite prevalent in both natural and man-made objects and is an essential cue in understanding and grouping the objects in natural scenes. Existing algorithms for estimating superpixels do not preserve the reflection symmetry of an object which leads to different sizes and shapes of superpixels across the symmetry axis. In this work, we propose an algorithm to over-segment an image through the propagation of reflection symmetry evident at the pixel level to superpixel boundaries. In order to achieve this goal, we first find the reflection symmetry in the image and represent it by a set of pairs of pixels which are mirror reflections of each other. We partition the image into superpixels while preserving this reflection symmetry through an iterative algorithm. We compare the proposed method with state-of-the-art superpixel generation methods and show the effectiveness in preserving the size and shape of superpixel boundaries across the reflection symmetry axes. We also present two applications, symmetry axes detection and unsupervised symmetric object segmentation, to illustrate the effectiveness of the proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:tYavs44e6CUC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2018,"Techniques to learn hash codes which can store and retrieve large dimensional multimedia data efficiently have attracted broad research interests in the recent years. With rapid explosion of newly emerged concepts and online data, existing supervised hashing algorithms suffer from the problem of scarcity of ground truth annotations due to the high cost of obtaining manual annotations. Therefore, we propose an algorithm to learn a hash function from training images belonging to ‘seen’ classes which can efficiently encode images of ‘unseen’ classes to binary codes. Specifically, we project the image features from visual space and semantic features from semantic space into a common Hamming subspace. Earlier works to generate hash codes have tried to relax the discrete constraints on hash codes and solve the continuous optimization problem. However, it often leads to quantization errors. In this work, we use …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:ILKRHgRFtOwC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2018,"DiversePatel, DiptibenaspectRaman, Shanmuganathan ratios of display devices require adaptation of the image content to be displayed on them. Image retargeting pertains to changing the size of an image to adapt to the aspect ratio and spatial resolution of the display device. This is achieved while preserving the salient or important information and thereby reducing visible artifacts in the retargeted image. Seam carving techniques remove or insert least energy seams, one pixel wide paths from top to bottom or left to right of an image, iteratively in order to achieve the target display size. These techniques highly depend on an energy measure of a pixel in an image. Here, we propose a novel technique of defining energy of a pixel, also known as significance map, using object proposal boxes with the probability of objects being present. Object proposal boxes are modeled using the Gaussian kernels. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:4X0JR2_MtJMC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2018,"In computer vision and graphics, various types of symmetries are extensively studied since symmetry present in objects is a fundamental cue for understanding the shape and the structure of objects. In this work, we detect the intrinsic reflective symmetry in triangle meshes where we have to find the intrinsically symmetric point for each point of the shape. We establish correspondences between functions defined on the shapes by extending the functional map framework and then recover the point-to-point correspondences. Previous approaches using the functional map for this task find the functional correspondences matrix by solving a non-linear optimization problem which makes them slow. In this work, we propose a closed form solution for this matrix which makes our approach faster. We find the closed-form solution based on our following results. If the given shape is intrinsically symmetric, then the shortest length geodesic between two intrinsically symmetric points is also intrinsically symmetric. If an eigenfunction of the Laplace-Beltrami operator for the given shape is an even (odd) function, then its restriction on the shortest length geodesic between two intrinsically symmetric points is also an even (odd) function. The sign of a low-frequency eigenfunction is the same on the neighboring points. Our method is invariant to the ordering of the eigenfunctions and has the least time complexity. We achieve the best performance on the SCAPE dataset and comparable performance with the state-of-the-art methods on the TOSCA dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:foquWX3nUaYC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2018,"In a photograph, we lose the three-dimensional nature of a scene. The simplest and the most common way of mathematically modelling this is through the projective transformation (see [1],[2],[3] and [4]). The non-invertible projective transformation transforms lines to lines but does not preserve most shapes and properties. In the instance of parallel lines-the projective transformation does not conserve parallelism. Most shapes and their properties readily change in projective transformations. From the facts mentioned above, we can notice properties concerning shapes transformation under a projective transform. We assume the pinhole camera model to analyse the projective transform. Consider a circle lying on a plane perpendicular to the camera sensor. Consider two tangents to the circle at points A and B that are diametrically opposite.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:MLfJN-KU85MC,http://people.iitgn.ac.in/~shanmuga/
Shanmuganathan Raman,"['Computer Vision', 'Deep Learning', 'Computational Photography', 'Computer Graphics']",18,1070,2018,"This paper addresses the problem of unsupervised object localization in an image. Unlike previous supervised and weakly supervised algorithms that require bounding box or image level annotations for training classifiers, we propose a simple yet effective technique for localization using iterative spectral clustering. This iterative spectral clustering approach along with appropriate cluster selection strategy in each iteration naturally helps in searching of object region in the image. In order to estimate the final localization window, we group the proposals obtained from the iterative spectral clustering step based on the perceptual similarity, and average the coordinates of the proposals from the top scoring groups. We benchmark our algorithm on challenging datasets like Object Discovery and PASCAL VOC 2007, achieving an average CorLoc percentage of 51% and 35% respectively which is comparable to various …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3YWptB8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3YWptB8AAAAJ:kuK5TVdYjLIC,http://people.iitgn.ac.in/~shanmuga/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2022,"To prevent applications from leaking users' private data to attackers, researchers have developed runtime information flow control (IFC) mechanisms. Most existing approaches are either based on taint tracking or multi-execution, and the same technique is used to protect the entire application. However, today's applications are typically composed of multiple components from heterogenous and unequally trusted sources. The goal of this paper is to develop a framework to enable the flexible composition of IFC enforcement mechanisms. More concretely, we focus on reactive programs, which is an abstract model for event-driven programs including web and mobile applications. We formalize the semantics of existing IFC enforcement mechanisms with well-defined interfaces for composition, define knowledge-based security guarantees that can precisely quantify the effect of implicit leaks from taint tracking, and prove …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:qxL8FJ1GzNcC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2022,"The Noise protocol framework defines a succinct notation and execution framework for a large class of 59+ secure channel protocols, some of which are used in popular applications such as WhatsApp and WireGuard. We present a verified implementation of a Noise protocol compiler that takes any Noise protocol, and produces an optimized C implementation with extensive correctness and security guarantees. To this end, we formalize the complete Noise stack in F*, from the low-level cryptographic library to a high-level API. We write our compiler also in F*, prove that it meets our formal specification once and for all, and then specialize it on-demand for any given Noise protocol, relying on a novel technique called hybrid embedding. We thus establish functional correctness, memory safety and a form of side-channel resistance for the generated C code for each Noise protocol. We propagate these guarantees to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:_kc_bZDykSQC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2022,"The Noise protocol framework defines a succinct notation and execution framework for a large class of 59+ secure channel protocols, some of which are used in popular applications such as WhatsApp and WireGuard. We present a verified implementation of a Noise protocol compiler that takes any Noise protocol, and produces an optimized C implementation with extensive correctness and security guarantees. To this end, we formalize the complete Noise stack in F*, from the low-level cryptographic library to a high-level API. We write our compiler also in F*, prove that it meets our formal specification once and for all, and then specialize it on-demand for any given Noise protocol, relying on a novel technique called hybrid embedding. We thusa establish functional correctness, memory safety and a form of side-channel resistance for the generated C code for each Noise protocol. We propagate these guarantees to the high-level API, using defensive dynamic checks to prevent incorrect uses of the protocol. Finally, we formally state and prove the security of our Noise code, by building on a symbolic model of cryptography in F*, and formally link high-level API security goals stated in terms of security levels to low-level cryptographic guarantees. Ours are the first comprehensive verification results for a protocol compiler that targets C code and the first verified implementations of any Noise protocol. We evaluate our framework by generating implementations for all 59 Noise protocols and by comparing the size, performance, and security of our verified code against other (unverified) implementations and prior security analyses of Noise.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:aqlVkmm33-oC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2021,"is a recently proposed formal verification framework for the symbolic security analysis of cryptographic protocol code written in the programming language. Unlike automated symbolic provers, accounts for advanced protocol features like unbounded loops and mutable recursive data structures as well as low-level implementation details like protocol state machines and message formats, which are often at the root of real-world attacks. Protocols modeled in can be executed, and hence, tested, and they can even interoperate with real-world counterparts. extends a long line of research on using dependent type systems but takes a fundamentally new approach by explicitly modeling the global trace-based semantics within the framework, hence bridging the gap between trace-based and type-based protocol analyses. With this, one can uniformly, precisely, and soundly model, for the first time using …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:Zph67rFs4hoC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2021,"DY* is a recently proposed formal verification framework for the symbolic security analysis of cryptographic protocol code written in the F* programming language. Unlike automated symbolic provers, DY* accounts for advanced protocol features like unbounded loops and mutable recursive data structures as well as low-level implementation details like protocol state machines and message formats, which are often at the root of real-world attacks. Protocols modeled in DY* can be executed, and hence, tested, and they can even interoperate with real-world counterparts. DY* extends a long line of research on using dependent type systems but takes a fundamentally new approach by explicitly modeling the global trace-based semantics within the framework, hence bridging the gap between trace-based and type-based protocol analyses. With this, one can uniformly, precisely, and soundly model, for the first time using dependent types, long-lived mutable protocol state, equational theories, fine-grained dynamic corruption, and trace-based security properties like forward secrecy and post-compromise security. In this paper, we provide a tutorial-style introduction to DY*: We illustrate how to model and prove the security of the ISO-DH protocol, a simple key exchange protocol based on Diffie-Hellman.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:YOwf2qJgpHMC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2021,"The ACME certificate issuance and management protocol, standardized as IETF RFC 8555, is an essential element of the web public key infrastructure (PKI). It has been used by Let's Encrypt and other certification authorities to issue over a billion certificates, and a majority of HTTPS connections are now secured with certificates issued through ACME. Despite its importance, however, the security of ACME has not been studied at the same level of depth as other protocol standards like TLS 1.3 or OAuth. Prior formal analyses of ACME only considered the cryptographic core of early draft versions of ACME, ignoring many security-critical low-level details that play a major role in the 100 page RFC, such as recursive data structures, long-running sessions with asynchronous sub-protocols, and the issuance for certificates that cover multiple domains.
We present the first in-depth formal security analysis of the ACME …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:KlAtU1dfN6UC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2021,"We present , a new formal verification framework for the symbolic security analysis of cryptographic protocol code written in the programming language. Unlike automated symbolic provers, our framework accounts for advanced protocol features like unbounded loops and mutable recursive data structures, as well as low-level implementation details like protocol state machines and message formats, which are often at the root of real-world attacks. Our work extends a long line of research on using dependent type systems for this task, but takes a fundamentally new approach by explicitly modeling the global trace-based semantics within the framework, hence bridging the gap between trace-based and type-based protocol analyses. This approach enables us to uniformly, precisely, and soundly model, for the first time using dependent types, long-lived mutable protocol state, equational theories, fine-grained dynamic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:0EnyYjriUFMC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2021,"Information flow type systems enforce the security property of noninterference by detecting unauthorized data flows at compile-time. However, they require precise type annotations, making them difficult to use in practice as much of the legacy infrastructure is written in untyped or dynamically-typed languages. Gradual typing seamlessly integrates static and dynamic typing, providing the best of both approaches, and has been applied to information flow control, where information flow monitors are derived from gradual security types. Prior work on gradual information flow typing uncovered tensions between noninterference and the dynamic gradual guarantee- the property that less precise security type annotations in a program should not cause more runtime errors.This paper re-examines the connection between gradual information flow types and information flow monitors to identify the root cause of the tension …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:8k81kl-MbHgC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:M3ejUd6NZC8C,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2021,"Home automation rules that allow users to connect smart home devices using trigger-action programs (TAP) can interact in subtle and unexpected ways. Determining whether these rules are free of undesirable behavior is challenging; so researchers have developed tools to analyze rules and assist users. However, it is unclear whether users need such tools, and what help they need from such tools. To answer this question, we performed a user study where half of the participants were given our custom analysis tool SafeTAP and the other half were not. We found that users are not good at finding issues in their TAP rules, despite perceiving such tasks as easy. The user study also indicates that users would like to check their rules every time they make rule changes. Therefore, we designed a novel incremental symbolic model checking (SMC) algorithm, which extends the basic SMC algorithm of SafeTAP. SafeTAPΔ only performs analysis caused by the addition or removal of rules and reports only new violations that have not already been reported to the user. We evaluate the performance of SafeTAPΔ and show that incremental checking on average improves the performance by 6X when adding new rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:MXK_kJrjxJIC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2021,"Information flow control (IFC) has been extensively studied as an approach to mitigate information leaks in applications. A vast majority of existing work in this area is based on static analysis. However, some applications, especially on the Web, are developed using dynamic languages like JavaScript where static analyses for IFC do not scale well. As a result, there has been a growing interest in recent years to develop dynamic or runtime information flow analysis techniques. In spite of the advances in the field, runtime information flow analysis has not been at the helm of information flow security, one of the reasons being that the analysis techniques and the security property related to them (non-interference) over-approximate information flows (particularly implicit flows), generating many false positives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:5nxA0vEk-isC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2021,"The risk posed by high-profile data breaches has raised the stakes for adhering to data access policies for many organizations, but the complexity of both the policies themselves and the applications that must obey them raises significant challenges. To mitigate this risk, fine-grained audit of access to private data has become common practice, but this is a costly, time-consuming, and error-prone process.We propose an approach for automating much of the work required for fine-grained audit of private data access. Starting from the assumption that the auditor does not have an explicit, formal description of the correct policy, but is able to decide whether a given policy fragment is partially correct, our approach gradually infers a policy from audit log entries. When the auditor determines that a proposed policy fragment is appropriate, it is added to the system's mechanized policy, and future log entries to which the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:hqOjcs7Dif8C,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2020,"Database-backed applications rely on inlined policy checks to process users' private and confidential data in a policy-compliant manner as traditional database access control mechanisms cannot enforce complex policies. However, application bugs due to missed checks are common in such applications, which result in data breaches. While separating policy from code is a natural solution, many data protection policies specify restrictions based on the context in which data is accessed and how the data is used. Enforcing these restrictions automatically presents significant challenges, as the information needed to determine context requires a tight coupling between policy enforcement and an application's implementation.
We present Estrela, a framework for enforcing contextual and granular data access policies. Working from the observation that API endpoints can be associated with salient contextual information …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:ufrVoPGSRksC,http://people.iitgn.ac.in/~abhishek/
Abhishek Bichhawat,"['Language-based Security', 'Program Analysis and Verification']",6,141,2020,"Information flow type systems enforce the security property of noninterference by detecting unauthorized data flows at compile-time. However, they require precise type annotations, making them difficult to use in practice as much of the legacy infrastructure is written in untyped or dynamically-typed languages. Gradual typing seamlessly integrates static and dynamic typing, providing the best of both approaches, and has been applied to information flow control, where information flow monitors are derived from gradual security types. Prior work on gradual information flow typing uncovered tensions between noninterference and the dynamic gradual guarantee -- the property that less precise security type annotations in a program should not cause more runtime errors. This paper re-examines the connection between gradual information flow types and information flow monitors to identify the root cause of the tension between the gradual guarantees and noninterference. We develop runtime semantics for a simple imperative language with gradual information flow types that provides both noninterference and gradual guarantees. We leverage a proof technique developed for FlowML and reduce noninterference proofs to preservation proofs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=qJavKW4AAAAJ&sortby=pubdate&citation_for_view=qJavKW4AAAAJ:_FxGoFyzp5QC,http://people.iitgn.ac.in/~abhishek/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",8,343,2022,"In this work we describe a novel approach for modeling, analysis and verification of database-accessing applications that use the ORM (Object Relational Mapping) paradigm. Rather than directly analyze ORM code to check specific properties, our approach infers a general-purpose relational algebra summary of each controller in the application. This summary can then be fed into any off-the-shelf relational algebra solver to check for properties or specifications given by a developer. The summaries can also aid program understanding, and may have other applications. We have implemented our approach as a prototype tool that works for 'Spring' based MVC applications. A preliminary evaluation reveals that the approach is efficient, and gives good results while checking a set of properties given by human subjects.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&sortby=pubdate&citation_for_view=fZq9W2cAAAAJ:HDshCWvjkbEC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",8,343,2021,"The synthesis of maximally-permissive controllers in infinite-state systems has many practical applications. Such controllers directly correspond to maximal winning strategies in logically specified infinite-state two-player games. In this paper, we introduce a tool called GenSys which is a fixed-point engine for computing maximal winning strategies for players in infinite-state safety games. A key feature of GenSys is that it leverages the capabilities of existing off-the-shelf solvers to implement its fixed point engine. GenSys outperforms state-of-the-art tools in this space by a significant margin. Our tool has solved some of the challenging problems in this space, is scalable, and also synthesizes compact controllers. These controllers are comparatively small in size and easier to comprehend. GenSys is freely available for use and is available under an open-source license.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&sortby=pubdate&citation_for_view=fZq9W2cAAAAJ:L8Ckcad2t8MC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",8,343,2021,"Buffer-overruns are a prevalent vulnerability in software libraries and applications. Fuzz testing is one of the effective techniques to detect vulnerabilities in general. Greybox fuzzers such as AFL automatically generate a sequence of test inputs for a given program using a fitness-guided search process. A recently proposed approach in the literature introduced a buffer-overrun specific fitness metric called ""headroom"", which tracks how close each generated test input comes to exposing the vulnerabilities. That approach showed good initial promise, but is somewhat imprecise and expensive due to its reliance on conservative points-to analysis. Inspired by the approach above, in this paper we propose a new ground-up approach for detecting buffer-overrun vulnerabilities. This approach uses an extended version of ASAN (Address Sanitizer) that runs in parallel with the fuzzer, and reports back to the fuzzer test inputs that happen to come closer to exposing buffer-overrun vulnerabilities. The ASAN-style instrumentation is precise as it has no dependence on points-to analysis. We describe in this paper our approach, as well as an implementation and evaluation of the approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&sortby=pubdate&citation_for_view=fZq9W2cAAAAJ:TQgYirikUcIC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",8,343,2021,"Asynchronous message-passing systems are employed frequently to implement distributed mechanisms, protocols, and processes. This paper addresses the problem of precise data flow analysis for such systems. To obtain good precision, data flow analysis needs to somehow skip execution paths that read more messages than the number of messages sent so far in the path, as such paths are infeasible at run time. Existing data flow analysis techniques do elide a subset of such infeasible paths, but have the restriction that they admit only finite abstract analysis domains. In this paper we propose a generalization of these approaches to admit infinite abstract analysis domains, as such domains are commonly used in practice to obtain high precision. We have implemented our approach, and have analyzed its performance on a set of 14 benchmarks. On these benchmarks our tool obtains significantly higher precision compared to a baseline approach that does not elide any infeasible paths and to another baseline that elides infeasible paths but admits only finite abstract domains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&sortby=pubdate&citation_for_view=fZq9W2cAAAAJ:7PzlFSSx8tAC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",8,343,2020,"Greybox fuzzing is an automated test-input generation technique that aims to uncover program errors by searching for bug-inducing inputs using a fitness-guided search process. Existing fuzzing approaches are primarily coverage-based. That is, they regard a test input that covers a new region of code as being fit to be retained. However, a vulnerability at a program location may not get exhibited in every execution that happens to visit to this program location; only certain program executions that lead to the location may expose the vulnerability. In this paper, we introduce a unified fitness metric called headroom, which can be used within greybox fuzzers, and which is explicitly oriented towards searching for test inputs that come closer to exposing vulnerabilities.
We have implemented our approach by enhancing AFL, which is a production quality fuzzing tool. We have instantiated our approach to detecting buffer …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&sortby=pubdate&citation_for_view=fZq9W2cAAAAJ:IWHjjKOFINEC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",8,343,2020,"Innovations in Software Engineering Conference (ISEC) is the flagship annual conference of iSoft, which is an arm of ACM India and serves as the India chapter of ACM SIGSOFT. The 13th edition of ISEC is to be held at IIITDM Jabalpur during the period February 27-29 2020, and will hold a PhD Symposium. The objective of the PhD Symposium is to provide for a forum for junior as well senior level PhD students working in the field of software engineering to present their work in a friendly setting, to get feedback on their direction from experts, to present posters about their work to the ISEC attendees, and to interact and network with each other. This report summarizes the motivation for this symposium and the plan for the event, and lists the full set of accepted submissions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&sortby=pubdate&citation_for_view=fZq9W2cAAAAJ:hC7cP41nSMkC,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",8,343,2019,"Verifying whether a procedure is observationally pure (that is, it always returns the same result for the same input argument) is challenging when the procedure uses mutable (private) global variables, e.g., for memoization, and when the procedure is recursive.
We present a deductive verification approach for this problem. Our approach encodes the procedure’s code as a logical formula, with recursive calls being modeled using a mathematical function symbol assuming that the procedure is observationally pure. Then, a theorem prover is invoked to check whether this logical formula agrees with the function symbol referred to above in terms of input-output behavior for all arguments. We prove the soundness of this approach.
We then present a conservative approximation of the first approach that reduces the verification problem to one of checking whether a quantifier-free formula is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&sortby=pubdate&citation_for_view=fZq9W2cAAAAJ:hFOr9nPyWt4C,http://www.csa.iisc.ernet.in/~raghavan/
Raghavan Komondoor,"['Programming Languages', 'Software Engineering', 'Formal Methods']",8,343,2018,"Object sensitivity analysis is a well-known form of context-sensitive points-to analysis. This analysis is parameterized by a bound on the names of symbolic objects associated with each allocation site. In this paper, we propose a novel approach based on object sensitivity analysis that takes as input a set of client queries, and tries to answer them using an initial round of inexpensive object sensitivity analysis that uses a low object-name length bound at all allocation sites. For the queries that are answered unsatisfactorily, the approach then pin points ""bad"" points-to facts, which are the ones that are responsible for the imprecision. It then employs a form of program slicing to identify allocation sites that are potentially causing these bad points-to facts to be generated. The approach then runs object sensitivity analysis once again, this time using longer names for just these allocation sites, with the objective of resolving …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=fZq9W2cAAAAJ&sortby=pubdate&citation_for_view=fZq9W2cAAAAJ:9ZlFYXVOiuMC,http://www.csa.iisc.ernet.in/~raghavan/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2023,"We consider the measurement model where and, hence, are random variables and is an a priori known tall matrix. At each time instance, a sample of one of 's coordinates is available, and the goal is to estimate via these samples. However, the challenge is that a small but unknown subset of 's coordinates are controlled by adversaries with infinite power: they can return any real number each time they are queried for a sample. For such an adversarial setting, we propose the first asynchronous online algorithm that converges to almost surely. We prove this result using a novel differential inclusion based two-timescale analysis. Two key highlights of our proof include: (a) the use of a novel Lyapunov function for showing that is the unique global attractor for our algorithm's limiting dynamics, and (b) the use of martingale and stopping time theory to show that our algorithm's iterates are almost surely bounded.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:738O_yMBCRsC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2023,"Despite the popularity of policy gradient methods, they are known to suffer from large variance and high sample complexity. To mitigate this, we introduce SoftTreeMax -- a generalization of softmax that takes planning into account. In SoftTreeMax, we extend the traditional logits with the multi-step discounted cumulative reward, topped with the logits of future states. We consider two variants of SoftTreeMax, one for cumulative reward and one for exponentiated reward. For both, we analyze the gradient variance and reveal for the first time the role of a tree expansion policy in mitigating this variance. We prove that the resulting variance decays exponentially with the planning horizon as a function of the expansion policy. Specifically, we show that the closer the resulting state transitions are to uniform, the faster the decay. In a practical implementation, we utilize a parallelized GPU-based simulator for fast and efficient tree search. Our differentiable tree-based policy leverages all gradients at the tree leaves in each environment step instead of the traditional single-sample-based gradient. We then show in simulation how the variance of the gradient is reduced by three orders of magnitude, leading to better sample complexity compared to the standard policy gradient. On Atari, SoftTreeMax demonstrates up to 5x better performance in a faster run time compared to distributed PPO. Lastly, we demonstrate that high reward correlates with lower variance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:XiSMed-E-HIC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2023,"Frieze showed that the expected weight of the minimum spanning tree (MST) of the uniformly weighted graph converges to . Recently, this result was extended to a uniformly weighted simplicial complex, where the role of the MST is played by its higher-dimensional analogue -- the Minimum Spanning Acycle (MSA). In this work, we go beyond and look at the histogram of the weights in this random MSA -- both in the bulk and in the extremes. In particular, we focus on the `incomplete' setting, where one has access only to a fraction of the potential face weights. Our first result is that the empirical distribution of the MSA weights asymptotically converges to a measure based on the shadow -- the complement of graph components in higher dimensions. As far as we know, this result is the first to explore the connection between the MSA weights and the shadow. Our second result is that the extremal weights converge to an inhomogeneous Poisson point process. A interesting consequence of our two results is that we can also state the distribution of the death times in the persistence diagram corresponding to the above weighted complex, a result of interest in applied topology.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:pyW8ca7W8N0C,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2022,"Evolution Strategy (ES) is a powerful black-box optimization technique based on the idea of natural evolution. In each of its iterations, a key step entails ranking candidate solutions based on some fitness score. For an ES method in Reinforcement Learning (RL), this ranking step requires evaluating multiple policies. This is presently done via on-policy approaches: each policy's score is estimated by interacting several times with the environment using that policy. This leads to a lot of wasteful interactions since, once the ranking is done, only the data associated with the top-ranked policies is used for subsequent learning. To improve sample efficiency, we propose a novel off-policy alternative for ranking, based on a local approximation for the fitness function. We demonstrate our idea in the context of a state-of-the-art ES method called the Augmented Random Search (ARS). Simulations in MuJoCo tasks show that, compared to the original ARS, our off-policy variant has similar running times for reaching reward thresholds but needs only around 70% as much data. It also outperforms the recent Trust Region ES. We believe our ideas should be extendable to other ES methods as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:OU6Ihb5iCvQC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2022,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:NhqRSupF_l8C,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2022,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:UxriW0iASnsC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2022,"A search engine maintains local copies of different web pages to provide quick search results. This local cache is kept up-to-date by a web crawler that frequently visits these different pages to track changes in them. Ideally, the local copy should be updated as soon as a page changes on the web. However, finite bandwidth availability and server restrictions limit how frequently different pages can be crawled. This brings forth the following optimization problem: maximize the freshness of the local cache subject to the crawling frequencies being within prescribed bounds. While tractable algorithms do exist to solve this problem, these either assume the knowledge of exact page change rates or use inefficient methods such as MLE for estimating the same. We address this issue here.
We provide three novel schemes for online estimation of page change rates, all of which have extremely low running times per iteration …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:SeFeTyx0c_EC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2021,"The topological study of existing random simplicial complexes is non-trivial and has led to several seminal works. However, the applicability of such studies is limited since a single parameter usually governs the randomness in these models. With this in mind, we focus here on the topology of the recently proposed multi-parameter random simplicial complex. In particular, we introduce a dynamic variant of this model and look at how its topology evolves. In this dynamic setup, the temporal evolution of simplices is determined by stationary and possibly non-Markovian processes with a renewal structure. Special cases of this setup include the dynamic versions of the clique complex and the Linial–Meshulam complex. Our key result concerns the regime where the face-count of a particular dimension dominates. We show that the Betti number corresponding to this dimension and the Euler characteristic satisfy a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:4OULZ7Gr8RgC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:xtRiw3GOFMkC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2021,"In Multi-Agent Reinforcement Learning (MARL), multiple agents interact with a common environment, as also with each other, for solving a shared problem in sequential decision-making. It has wide-ranging applications in gaming, robotics, finance, communication, etc. In this work, we derive a novel law of iterated logarithm for a family of distributed nonlinear stochastic approximation schemes that is useful in MARL. In particular, our result describes the convergence rate on almost every sample path where the algorithm converges. This result is the first of its kind in the distributed setup and provides deeper insights than the existing ones, which only discuss convergence rates in the expected or the CLT sense. Importantly, our result holds under significantly weaker assumptions: neither the gossip matrix needs to be doubly stochastic nor the stepsizes square summable. As an application, we show that, for the stepsize with the distributed TD (0) algorithm with linear function approximation has a convergence rate of as; for the type stepsize, the same is as These decay rates do not depend on the graph depicting the interactions among the different agents.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:abG-DnoFyZgC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2020,"For providing quick and accurate results, a search engine maintains a local snapshot of the entire web. And, to keep this local cache fresh, it employs a crawler for tracking changes across various web pages. However, finite bandwidth availability and server restrictions impose some constraints on the crawling frequency. Consequently, the ideal crawling rates are the ones that maximise the freshness of the local cache and also respect the above constraints.
Azar et al. [2] recently proposed a tractable algorithm to solve this optimisation problem. However, they assume the knowledge of the exact page change rates, which is unrealistic in practice. We address this issue here. Specifically, we provide two novel schemes for online estimation of page change rates. Both schemes only need partial information about the page change process, i.e., they only need to know if the page has changed or not since the last crawled …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:cFHS6HbyZ2cC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2020,"A weighted complex is a simplicial complex of dimension in which each face is assigned a real-valued weight. We derive three key results here concerning persistence diagrams and minimal spanning acycles (MSAs) of such complexes. First, we establish an equivalence between the MSA face-weights and \emph{death times} in the persistence diagram. Next, we show a novel stability result for the MSA face-weights which, due to our first result, also holds true for the death and birth times, separately. Our final result concerns a perturbation of a mean-field model of randomly weighted complexes. The face weights here are perturbation of some i.i.d. distribution while all the lower-dimensional faces have a weight of . If the perturbations decay sufficiently quickly, we show that suitably scaled extremal nearest face-weights, face-weights of the MSA, and the associated death times converge to an inhomogeneous Poisson point process. This result completely characterizes the extremal points of persistence diagrams and MSAs. The point process convergence and the asymptotic equivalence of three point processes are new for any weighted random complex model, including even the non-perturbed case. Lastly, as a consequence of our stability result, we show that Frieze's limit for random minimal spanning trees and the recent extension to random MSAs by Hino and Kanazawa also hold in suitable noisy settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:g5m5HwL7SMYC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2020,"Policy evaluation in reinforcement learning is often conducted using two-timescale stochastic approximation, which results in various gradient temporal difference methods such as GTD (0), GTD2, and TDC. Here, we provide convergence rate bounds for this suite of algorithms. Algorithms such as these have two iterates, θ n and w n, which are updated using two distinct stepsize sequences, α n and β n, respectively. Assuming α n= n− α and β n= n− β with 1> α> β> 0, we show that, with high probability, the two iterates converge to their respective solutions θ* and w* at rates given by∥ θ n-θ*∥= Õ (n− α/2) and∥ w n-w*∥= Õ (n− β/2); here, Õ hides logarithmic terms. Via comparable lower bounds, we show that these bounds are, in fact, tight. To the best of our knowledge, ours is the first finite-time analysis which achieves these rates. While it was known that the two timescale components decouple asymptotically, our results depict this phenomenon more explicitly by showing that it in fact happens from some finite time onwards. Lastly, compared to existing works, our result applies to a broader family of stepsizes, including non-square summable ones.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:dfsIfKJdRG4C,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2019,"Given an ordinary differential equation (ODE) and its perturbation, the Alekseev formula expresses the solutions of the latter in terms related to the former. By exploiting this formula and a new concentration inequality for martingale-differences, we develop a novel approach for analyzing nonlinear stochastic approximation (SA). This approach is useful for studying a SA’s behavior close to a locally asymptotically stable equilibrium (LASE) of its limiting ODE; this LASE need not be the limiting ODE’s only attractor. As an application, we obtain a new concentration bound for nonlinear SA. That is, given ϵ > and that the current iterate is in a neighborhood of a LASE, we provide an estimate for (i) the time required to hit the ϵ-ball of this LASE, and (ii) the probability that after this time the iterates are indeed within this ϵ-ball and stay there thereafter. The latter estimate can also be viewed as the “lock-in” probability …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:M05iB0D1s5AC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2018,"Random field excursions is an increasingly vital topic within data analysis in medicine, cosmology, materials science, etc. This work is the first detailed study of their Betti numbers in the so-called `sparse' regime. Specifically, we consider a piecewise constant Gaussian field whose covariance function is positive and satisfies some local, boundedness, and decay rate conditions. We model its excursion set via a Cech complex. For Betti numbers of this complex, we then prove various limit theorems as the window size and the excursion level together grow to infinity. Our results include asymptotic mean and variance estimates, a vanishing to non-vanishing phase transition with a precise estimate of the transition threshold, and a weak law in the non-vanishing regime. We further obtain a Poisson approximation and a central limit theorem close to the transition threshold. Our proofs combine extreme value theory and combinatorial topology tools.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:70eg2SAEIzsC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2018,"Two-timescale Stochastic Approximation (SA) algorithms are widely used in Reinforcement Learning (RL). Their iterates have two parts that are updated using distinct stepsizes. In this work, we develop a novel recipe for their finite sample analysis. Using this, we provide a concentration bound, which is the first such result for a two-timescale SA. The type of bound we obtain is known as “lock-in probability”. We also introduce a new projection scheme, in which the time between successive projections increases exponentially. This scheme allows one to elegantly transform a lock-in probability into a convergence rate result for projected two-timescale SA. From this latter result, we then extract key insights on stepsize selection. As an application, we finally obtain convergence rates for the projected two-timescale RL algorithms GTD (0), GTD2, and TDC.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:pqnbT2bcN3wC,https://sites.google.com/site/gugancth/
Gugan Thoppe | गुगन थोप्पे,"['Stochastic Approximation', 'Learning Algorithms', 'Random Topology']",8,419,2018,"TD (0) is one of the most commonly used algorithms in reinforcement learning. Despite this, there is no existing finite sample analysis for TD (0) with function approximation, even for the linear case. Our work is the first to provide such results. Existing convergence rates for Temporal Difference (TD) methods apply only to somewhat modified versions, eg, projected variants or ones where stepsizes depend on unknown problem parameters. Our analyses obviate these artificial alterations by exploiting strong properties of TD (0). We provide convergence rates both in expectation and with high-probability. The two are obtained via different approaches that use relatively unknown, recently developed stochastic approximation techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=X5zV3s8AAAAJ&sortby=pubdate&citation_for_view=X5zV3s8AAAAJ:ZHo1McVdvXMC,https://sites.google.com/site/gugancth/
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2023,"The extremum graph is a succinct representation of the Morse decomposition of a scalar field. It has increasingly become a useful data structure that supports topological feature‐directed visualization of 2D/3D scalar fields, and enables dimensionality reduction together with exploratory analysis of high‐dimensional scalar fields. Current methods that employ the extremum graph compute it either using a simple sequential algorithm for computing the Morse decomposition or by computing the more detailed Morse–Smale complex. Both approaches are typically limited to two and three‐dimensional scalar fields. We describe a GPU–CPU hybrid parallel algorithm for computing the extremum graph of scalar fields in all dimensions. The proposed shared memory algorithm utilizes both fine‐grained parallelism and task parallelism to achieve efficiency. An open source software library, tachyon, that implements the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:djft3U1LymYC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2023,"Electronic transitions in molecules due to the absorption or emission of light is a complex quantum mechanical process. Their study plays an important role in the design of novel materials. A common yet challenging task in the study is to determine the nature of electronic transitions, namely which subgroups of the molecule are involved in the transition by donating or accepting electrons, followed by an investigation of the variation in the donor-acceptor behavior for different transitions or conformations of the molecules. In this paper, we present a novel approach for the analysis of a bivariate field and show its applicability to the study of electronic transitions. This approach is based on two novel operators, the continuous scatterplot (CSP) lens operator and the CSP peel operator, that enable effective visual analysis of bivariate fields. Both operators can be applied independently or together to facilitate analysis. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:0urtJCGzaFQC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2022,"Isosurfaces are an important tool for analysis and visualization of univariate scalar fields. Earlier works have demonstrated the presence of interesting isosurfaces at isovalues close to critical values. This motivated the development of efficient methods for computing individual components of isosurfaces restricted to a region of interest. Generalization of isosurfaces to fiber surfaces and critical points to Jacobi sets has resulted in new approaches for analyzing bivariate scalar fields. Unlike isosurfaces, there exists no output sensitive method for computing fiber surfaces. Existing methods traverse through all the tetrahedra in the domain. In this paper, we propose the use of the Jacobi set to identify fiber surface components of interest and present an output sensitive approach for its computation. The Jacobi edges are used to initiate the search towards seed tetrahedra that contain the fiber surface, thereby reducing the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:w5CyTnyFq80C,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2022,"We present a pipeline for the interactive visual analysis and exploration of molecular electronic transition ensembles. Each ensemble member is specified by a molecular configuration, the charge transfer between two molecular states, and a set of physical properties. The pipeline is targeted towards theoretical chemists, supporting them in comparing and characterizing electronic transitions by combining automatic and interactive visual analysis. A quantitative feature vector characterizing the electron charge transfer serves as the basis for hierarchical clustering as well as for the visual representations. The interface for the visual exploration consists of four components. A dendrogram provides an overview of the ensemble. It is augmented with a level of detail glyph for each cluster. A scatterplot using dimensionality reduction provides a second visualization, highlighting ensemble outliers. Parallel coordinates show …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:VBDT71xRUdcC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2022,"The Morse-Smale complex is a well studied topological structure that represents the gradient flow behavior between critical points of a scalar function. It supports multi-scale topological analysis and visualization of feature-rich scientific data. Several parallel algorithms have been proposed towards the fast computation of the 3D Morse-Smale complex. Its computation continues to pose significant algorithmic challenges. In particular, the non-trivial structure of the connections between the saddle critical points are not amenable to parallel computation. This paper describes a fine grained parallel algorithm for computing the Morse-Smale complex and a GPU implementation (gMSC). The algorithm first determines the saddle-saddle reachability via a transformation into a sequence of vector operations, and next computes the paths between saddles by transforming it into a sequence of matrix operations. Computational …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:DwFgw5hZUzMC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2022,"This article presents a robust Morse theory-based framework for segmenting 3D X-ray computed tomography image (CT) and computing the fabric, relative arrangement of particles, of granular ensembles. The framework includes an algorithm for computing the segmentation, a data structure for storing the segmentation and representing both individual particles and the connectivity network, and visualizations of topological descriptors of the CT image that enable interactive exploration. The Morse theory-based framework produces superior quality segmentation of a granular ensemble as compared to prior approaches based on the watershed transform. The accuracy of the connectivity network also improves. Further, the framework supports the efficient computation of various distribution statistics on the segmentation and the connectivity network. Such a comprehensive characterization and quantification of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:puFLaqDw8dcC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2022,"The Bay of Bengal (BoB) fosters several monsoon depressions and cyclones, playing a crucial role in the Asian summer and winter monsoons. The capacity of the bay to remain warm and energize such weather systems is attributed to its strong vertical stratification sustained by the large freshwater input into the bay. River runoff and rainfall into the northern bay in contrast to the high salinity water intrusion in the south creates a strong north–south salinity gradient. Here, we present a visual analysis tool to trace the path of the high salinity core (HSC) entering into the BoB from the Arabian Sea. We introduce two feature definitions that represent the movement and shape of the HSC, and algorithms to track their evolution over time. The two feature representations, namely fronts and skeletons, are based on geometric and topological analysis of the HSC. The method is validated via comparison with well established …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:ibZ2AwG9z6wC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2022,"Topological Data Analysis has become, over the last few years, an established framework for the extraction and analysis of subtle structural patterns in complex data. It has been successfully applied in a variety of application fields, including quantum chemistry, astrophysics, fluid dynamics, combustion, material sciences, biology, and data science. In particular, the genericity, efficiency, and robustness of topological methods have made them particularly well suited for the multi-scale, interactive analysis and visualization of the structural information of data.
Despite their rising mainstream popularity, topological methods still face a number of challenges, including, for instance efficient computational methods for large-scale time-varying data, the characterization of noise and uncertainty, or the support of novel emerging data types such as ensemble data or high-dimensional point clouds.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:mS4qin7VKjkC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2021,"Comparative analysis of scalar fields is an important problem with various applications including feature-directed visualization and feature tracking in time-varying data. Comparing topological structures that are abstract and succinct representations of the scalar fields lead to faster and meaningful comparison. While there are many distance or similarity measures to compare topological structures in a global context, there are no known measures for comparing topological structures locally. While the global measures have many applications, they do not directly lend themselves to fine-grained analysis across multiple scales. We define a local variant of the tree edit distance and apply it towards local comparative analysis of merge trees with support for finer analysis. We also present experimental results on time-varying scalar fields, 3D cryo-electron microscopy data, and other synthetic data sets to show the utility of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:WgvcDLhf7hwC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2021,"Electronic transitions in molecules due to absorption or emission of light is a complex quantum mechanical process. Their study plays an important role in the design of novel materials. A common yet challenging task in the study is to determine the nature of those electronic transitions, i.e. which subgroups of the molecule are involved in the transition by donating or accepting electrons, followed by an investigation of the variation in the donor-acceptor behavior for different transitions or conformations of the molecules. In this paper, we present a novel approach towards the study of electronic transitions based on the visual analysis of a bivariate field, namely the electron density in the hole and particle Natural Transition Orbital (NTO). The visual analysis focuses on the continuous scatter plots (CSPs) of the bivariate field linked to their spatial domain. The method supports selections in the CSP visualized as fiber …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:4uoR24qA-WYC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2021,The study of electronic transitions within a molecule connected to the absorption or emission of light is a common task in the process of the design of new materials. The transitions are complex quantum mechanical processes and a detailed analysis requires a breakdown of these processes into components that can be interpreted via characteristic chemical properties. We approach these tasks by providing a detailed analysis of the electron density field. This entails methods to quantify and visualize electron localization and transfer from molecular subgroups combining spatial and abstract representations. The core of our method uses geometric segmentation of the electronic density field coupled with a graph‐theoretic formulation of charge transfer between molecular subgroups. The design of the methods has been guided by the goal of providing a generic and objective analysis following fundamental concepts …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:T_0gP6tLVL0C,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2021,"In topological data analysis and visualization, topological descriptors such as persistence diagrams, merge trees, contour trees, Reeb graphs, and Morse–Smale complexes play an essential role in capturing the shape of scalar field data. We present a state‐of‐the‐art report on scalar field comparison using topological descriptors. We provide a taxonomy of existing approaches based on visualization tasks associated with three categories of data: single fields, time‐varying fields, and ensembles. These tasks include symmetry detection, periodicity detection, key event/feature detection, feature tracking, clustering, and structure statistics. Our main contributions include the formulation of a set of desirable mathematical and computational properties of comparative measures, and the classification of visualization tasks and applications that are enabled by these measures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:qYOp8iumCsAC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2021,"Topology driven methods for analysis of scalar fields often begin with an exploration of an abstract topological structure such as the merge tree. Such abstractions are hard to interpret and time-consuming, particularly for feature-rich data. Current visualization schemes often place less emphasis on enriching user experience, human perception, or interaction. In this work, we aim to bridge that gap by utilizing treemaps towards effective topological analysis. We present mergemaps, a treemap based interactive design, to better understand merge trees. To aid the perceptual understanding of large merge trees, we provide fusing and diffusing operations to reduce its hierarchical size while preserving topological features. We show multiple examples where our design leads to easy interpretations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:EsrhoZGmrkoC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2020,"The Morse-Smale complex is a well studied topological structure that represents the gradient flow behavior of a scalar function. It supports multi-scale topological analysis and visualization of large scientific data. Its computation poses significant algorithmic challenges when considering large scale data and increased feature complexity. Several parallel algorithms have been proposed towards the fast computation of the 3D Morse-Smale complex. The non-trivial structure of the saddle-saddle connections are not amenable to parallel computation. This paper describes a fine grained parallel method for computing the Morse-Smale complex that is implemented on a GPU. The saddle-saddle reachability is first determined via a transformation into a sequence of vector operations followed by the path traversal, which is achieved via a sequence of matrix operations. Computational experiments show that the method …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:sYWwZaPVD1oC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2020,"The alpha complex, a subset of the Delaunay triangulation, has been extensively used as the underlying representation for biomolecular structures. We propose a GPU-based parallel algorithm for the computation of the alpha complex, which exploits the knowledge of typical spatial distribution and sizes of atoms in a biomolecule. Unlike existing methods, this algorithm does not require prior construction of the Delaunay triangulation. The algorithm computes the alpha complex in two stages. The first stage proceeds in a bottom-up fashion and computes a superset of the edges, triangles, and tetrahedra belonging to the alpha complex. The false positives from this estimation stage are removed in a subsequent pruning stage to obtain the correct alpha complex. Computational experiments on several biomolecules demonstrate the superior performance of the algorithm, up to a factor of 50 when compared to existing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:SgM-ki2adj0C,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2020,"In time-varying scientific datasets, the temporal evolution of interesting topological features is commonly displayed and explored using isosurfaces and tracking graphs. However, the visual representation of such tracking graphs supports only few interactive capabilities. Further, they capture information at a high level that requires specification of carefully chosen parameter values. To bridge this gap, we propose persistenceBundles, a flexible visualization metaphor that utilizes a hierarchical edge-bundling approach for visualizing tracked features using persistence hierarchies, and implicitly allows for intuitive interaction schemes. We demonstrate the effectiveness of our approach using the viscous finger dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:PklR0melJeUC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2020,"A new method for identifying Rossby wave packets (RWPs) using 6-hourly data from the ERA-Interim is presented. The method operates entirely in the spatial domain and relies on the geometric and topological properties of the meridional wind field to identify RWPs. The method represents RWPs as nodes and edges of a dual graph instead of the more common envelope representation. This novel representation allows access to both RWP phase and amplitude information. Local maxima and minima of the meridional wind field are collected into groups. Each group, called a υ -max cluster or υ -min cluster of the meridional wind field, represents a potential wave component. Nodes of the dual graph represent a υ -max cluster or υ -min cluster. Alternating υ -max clusters and υ -min clusters are linked by edges of the dual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:-fu4zM_6qcIC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2020,"A new method for identifying Rossby wave packets (RWPs) using 6-hourly data from the ERA-Interim is presented. The method operates entirely in the spatial domain and relies on the geometric and topological properties of the meridional wind field to identify RWPs. The method represents RWPs as nodes and edges of a dual graph instead of the more common envelope representation. This novel representation allows access to both RWP phase and amplitude information. Local maxima and minima of the meridional wind field are collected into groups. Each group, called a υ-max cluster or υ-min cluster of the meridional wind field, represents a potential wave component. Nodes of the dual graph represent a υ-max cluster or υ-min cluster. Alternating υ-max clusters and υ-min clusters are linked by edges of the dual graph, called the RWP association graph. Amplitude and discrete gradient-based filtering applied on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:R6EwkKsDylYC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2020,"Critical weather applications such as cyclone tracking require online visualization simultaneously performed with the simulations so that the scientists can provide real-time guidance to decision makers. However, resource constraints such as slow networks can hinder online remote visualization. In this work, we have developed an adaptive framework for efficient online remote visualization of critical weather applications. We present three algorithms, namely, most-recent, auto-clustering and adaptive, for reducing lag between the simulation and visualization times. Using experiments with different network configurations, we find that the adaptive algorithm strikes a good balance in providing reduced lags and visualizing most representative frames, with up to 72% smaller lag than auto-clustering, and 37% more representative than most-recent for slow networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:uWy0R8PweswC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2020,"Topological structures such as the merge tree provide an abstract and succinct representation of scalar fields. They facilitate effective visualization and interactive exploration of feature-rich data. A merge tree captures the topology of sub-level and super-level sets in a scalar field. Estimating the similarity between merge trees is an important problem with applications to feature-directed visualization of time-varying data. We present an approach based on tree edit distance to compare merge trees. The comparison measure satisfies metric properties, it can be computed efficiently, and the cost model for the edit operations is both intuitive and captures well-known properties of merge trees. Experimental results on time-varying scalar fields, 3D cryo electron microscopy data, shape data, and various synthetic datasets show the utility of the edit distance towards a feature-driven analysis of scalar fields.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&sortby=pubdate&citation_for_view=yePyztMAAAAJ:ZYsTHYU9jrMC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2019,"A wide range of data that appear in scientific experiments and simulations are multivariate or multifield in nature, consisting of multiple scalar fields. Topological feature search of such data aims to reveal important properties useful to the domain scientists. It has been shown in recent works that a single scalar field is insufficient to capture many important topological features in the data, instead one needs to consider topological relationships between multiple scalar fields. In the current paper, we propose a novel method of finding similarity between two multifield data by comparing their respective fiber component distributions. Given a time-varying multifield data, the method computes a metric plot for each pair of histograms at consecutive time stamps to understand the topological changes in the data over time. We validate the method using real and synthetic data. The effectiveness of the proposed method is shown by its ability to capture important topological features that are not always possible to detect using the individual component scalar fields.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yePyztMAAAAJ:k8to_Y4Q4_EC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2019,"Topological methods for data analysis have proven to be useful in multiple contexts ranging from exploring molecular surfaces to understanding cyclones. While abstract topological representations are powerful, they are still yet to gain widespread popularity, because their interpretation requires background in algebraic topology and Morse theory. To this extent, multiple attempts have been made to provide user interfaces that convey topological information in an intuitive manner. In this work, we aim at improving the understanding of a topological abstraction called merge tree.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yePyztMAAAAJ:e0LTWoPxLYMC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2019,"Topology based analysis and feature tracking is a well studied area. In this work, we focus exclusively on a dataset called the von Kármán street, and apply topology-based methods to understand its vortices. For this analysis, we adapt the recently proposed edit distance between merge trees. We discern several interesting results. One, we observe spatial periodicity between the vortices, alternating every half-cycle. Two, we observe a distinct difference in spatial probability of vortex regions during a half-cycle. Further, we compare the accuracy of our spatial probability with an off-the-shelf machine learning approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yePyztMAAAAJ:w0odbtu79TwC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2019,"This report documents the program and the outcomes of Dagstuhl Seminar 19212"" Topology, Computation and Data Analysis"". The seminar brought together researchers with mathematical and computational backgrounds in addressing emerging directions within computational topology for data analysis in practice. This seminar was designed to be a followup event after a very successful Dagstuhl Seminar (17292; July 2017). The list of topics and participants were updated to keep the discussions diverse, refreshing, and engaging. This seminar facilitated close interactions among the attendees with the aim of accelerating the convergence between mathematical and computational thinking in the development of theories and scalable algorithms for data analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yePyztMAAAAJ:bbjcffOLshcC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2018,The contour tree represents the topology of level sets of a scalar function. Nodes of the tree correspond to critical level sets and arcs of the tree represent a collection of topologically equivalent level sets connecting two critical level sets. The augmented contour tree contains degree-2 nodes on the arcs that represent regular level sets. The degree-2 nodes correspond to regular points of the scalar function and other critical points that do not affect the number of level set components. The augmented contour tree is significantly larger in size and requires more effort to compute when compared to the contour tree. Applications of the contour tree to data exploration and visualization require the augmented contour tree. Current approaches propose algorithms to compute the contour tree and the augmented contour tree from scratch. Precomputing and storing the large augmented contour tree will not be necessary if the …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yePyztMAAAAJ:4tNoA7Af41QC,https://www.csa.iisc.ac.in/~vijayn
Vijay Natarajan,"['Scientific visualization', 'computational topology', 'geometry processing']",19,940,2018,"Analyzing depressions plays an important role in meteorology, especially in the study of cyclones. In particular, the study of the temporal evolution of cyclones requires a robust depression tracking framework. To cope with this demand we propose a pipeline for the exploration of cyclones and their temporal evolution. This entails a generic framework for their identification and tracking. The fact that depressions and cyclones are not well-defined objects and their shape and size characteristics change over time makes this task especially challenging. Our method combines the robustness of topological approaches and the detailed tracking information from optical flow analysis. At first cyclones are identified within each time step based on well-established topological concepts. Then candidate tracks are computed from an optical flow field. These tracks are clustered within a moving time window to distill dominant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yePyztMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yePyztMAAAAJ:qSd0DAb9jMoC,https://www.csa.iisc.ac.in/~vijayn
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2023,"This book provides a concise but comprehensive guide to representation, which forms the core of Machine Learning (ML). State-of-the-art practical applications involve a number of challenges for the analysis of high-dimensional data. Unfortunately, many popular ML algorithms fail to perform, in both theory and practice, when they are confronted with the huge size of the underlying data. Solutions to this problem are aptly covered in the book. In addition, the book covers a wide range of representation techniques that are important for academics and ML practitioners alike, such as Locality Sensitive Hashing (LSH), Distance Metrics and Fractional Norms, Principal Components (PCs), Random Projections and Autoencoders. Several experimental results are provided in the book to demonstrate the discussed techniques’ effectiveness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:sJPMR1oEGYQC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2022,"This chapter deals with linear representations. Here, each new feature is a linear combination of the given input features. Even feature selection may be viewed as a special case of the linear representation schemes. We specifically consider, in this chapter, various types of feature selection schemes, principal components, random projections and non-negative matrix factorization.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:BOlwja0KXvYC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2022,"Most of the practical data sets are high-dimensional. A major difficulty with classifying such data is involved not only in terms of the computational demands but also in terms of classification performance. It is very obvious when the learning algorithms are dependent on distances. In this chapter, we present the difficulties and possible solutions to deal with such high-dimensional data classification.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:ijdKiLOsEJMC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2022,"In this chapter we deal with various nonlinear feature extraction schemes. In nonlinear feature extraction, the extracted features may be viewed as nonlinear combinations of the originally given features. Two popular neural network architectures employed are self-organizing map (SOM) and autoencoder (AE). We examine both of them in this chapter.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:dAp6zn-oMfAC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"Usual relations between entities could be captured using graphs; but those of a higher-order -- more so between two different types of entities (which we term ""left"" and ""right"") -- calls for a ""bipartite hypergraph"". For example, given a left set of symptoms and right set of diseases, the relation between a set subset of symptoms (that a patient experiences at a given point of time) and a subset of diseases (that he/she might be diagnosed with) could be well-represented using a bipartite hyperedge. The state-of-the-art in embedding nodes of a hypergraph is based on learning the self-attention structure between node-pairs from a hyperedge. In the present work, given a bipartite hypergraph, we aim at capturing relations between node pairs from the cross-product between the left and right hyperedges, and term it a ""cross-attention"" (CAT) based model. More precisely, we pose ""bipartite hyperedge link prediction"" as a set-matching (SETMAT) problem and propose a novel neural network architecture called CATSETMAT for the same. We perform extensive experiments on multiple bipartite hypergraph datasets to show the superior performance of CATSETMAT, which we compare with multiple techniques from the state-of-the-art. Our results also elucidate information flow in self- and cross-attention scenarios.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:LK8CI43ZvvMC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"The problem of link prediction is of active interest. The main approach to solving the link prediction problem is based on heuristics such as Common Neighbors (CN) -- more number of common neighbors of a pair of nodes implies a higher chance of them getting linked. In this article, we investigate this problem in the presence of higher-order relations. Surprisingly, it is found that CN works very well, and even better in the presence of higher-order relations. However, as we prove in the current work, this is due to the CN-heuristic overestimating its prediction abilities in the presence of higher-order relations. This statement is proved by considering a theoretical model for higher-order relations and by showing that AUC scores of CN are higher than can be achieved from the model. Theoretical justification in simple cases is also provided. Further, we extend our observations to other similar link prediction algorithms such as Adamic Adar. Finally, these insights are used to propose an adjustment factor by taking into conscience that a random graph would only have a best AUC score of 0.5. This adjustment factor allows for a better estimation of generalization scores.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:zUl2_INMlC4C,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"Multi Agent Path Finding (MAPF) requires identification of conflict free paths for agents which could be point-sized or with dimensions. In this paper, we propose an approach for MAPF for spatially-extended agents. These find application in real world problems like Convoy Movement Problem, Train Scheduling etc. Our proposed approach, Decentralised Multi Agent Path Finding (DeMAPF), handles MAPF as a sequence of pathplanning and allocation problems which are solved by two sets of agents Travellers and Routers respectively, over multiple iterations. The approach being decentralised allows an agent to solve the problem pertinent to itself, without being aware of other agents in the same set. This allows the agents to be executed on independent machines, thereby leading to scalability to handle large sized problems. We prove, by comparison with other distributed approaches, that the approach leads to a faster convergence to a conflict-free solution, which may be suboptimal, with lesser memory requirement.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:jtI9f0ekYq0C,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"Graph classification has been a classical problem of interest in machine learning and data mining because of its role in biological and social network analysis. Due to the recent success of graph neural networks for node classification and representation, researchers started extending them for the entire graph classification purpose. The main challenge is to represent the whole graph by a single vector which can be used to classify the graph in an end-to-end fashion. Global pooling, where node representations are directly aggregated to form the graph representation and more recently hierarchical pooling, where the whole graph is converted to a smaller graph through a set of hierarchies, are proposed in the literature. Though hierarchical pooling shows promising results for graph classification, it looses a significant amount of information in the hierarchical architecture. To address this, we propose a novel hybrid …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:oPLKW5k6eA4C,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"Graphs are non-euclidean structures that can represent many relational data efficiently. Many studies have proposed the convolution and the pooling operators on the non-euclidean domain. The graph convolution operators have shown astounding performance on various tasks such as node representation and classification. For graph classification, different pooling techniques are introduced, but none of them has considered both neighborhood of the node and the long-range dependencies of the node. In this paper, we propose a novel graph pooling layer R2POOL, which balances the structure information around the node as well as the dependencies with far away nodes. Further, we propose a new training strategy to learn coarse to fine representations. We add supervision at only intermediate levels to generate predictions using only intermediate-level features. For this, we propose the concept of an alignment …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:SxCCDk4iOpsC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"Bundle recommendation – recommending a group of products in place of individual products to customers is gaining attention day by day. It presents two interesting challenges – (1) how to personalize and recommend existing bundles to users, and (2) how to generate personalized novel bundles targeting specific users. Recently, few models have been proposed for modeling the bundle recommendation problem. However, they have the following shortcomings. First, they do not consider the higher-order relationships amongst the entities (users, items and bundles). Second, they do not model the relative influence of items present in the bundles, which is crucial in defining such bundles. In this work, we propose GRAM-SMOT – a graph attention-based framework to address the above challenges. Further, we define a loss function based on the metric-learning approach to learn the embeddings of entities …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:s9ia6_kGH2AC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"Networks play a pivotal role in representing relational data. Network analysis is gaining importance because of its relevance to several real-life applications. We deal with an introduction to social and information networks and their representations in this chapter. We introduce network embeddings followed by Matrix Factorization approaches. Further, we examine related datasets, evaluation metrics, and the downstream machine learning tasks. An introduction to one of the most influential developments in the recent times, word2vec and its role in embeddings, and categories of embeddings is also provided.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:zwpXiJ37cpgC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"There are several applications where an embedding or a low-dimensional representation of the entire graph is required. This chapter deals with such representations which are called graph embeddings. We consider various state-of-the-art graph pooling techniques that are important in this context. We also consider graph level analysis tasks including graph classification, and graph visualization. We also compare them using several benchmark evaluation datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:-yGd096yOn8C,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"Downstream ML tasks can exploit the low-dimensional node embeddings by using them as the inputs to traditional machine learning models. These node-level downstream tasks include node classification, node clustering, recommendation, link prediction, and visualization. In this chapter, we discuss node embedding techniques. These techniques are based on one of random walk, matrix factorization, or deep learning. Further, some algorithms learn representations in an unsupervised setting while others learn in a supervised setting. We finally present comparison of these algorithms according to their performance on downstream tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:EsEWqaRxkBgC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"This chapter deals with a brief introduction to deep learning. We deal with the perceptron classifier and its training. We then deal with feedforward networks and the multilayer perceptron (MLP). Training MLP using the well-known backpropagation algorithm is examined. An introduction to convolutional neural networks (CNNs), recurrent neural networks (RNNs), Long Short-TermMemory (LSTM), and autoencoders is provided.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:unp9ATQDT5gC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2021,"Cross-Domain Collaborative Filtering (CDCF) provides a way to alleviate data sparsity and cold-start problems present in recommendation systems by exploiting the knowledge from related domains. Existing CDCF models are either based on matrix factorization or deep neural networks. Independent use of either of the techniques in isolation may result in suboptimal performance for the prediction task. Also, most of the existing models face challenges particularly in handling diversity between domains and learning complex non-linear relationships that exist amongst entities (users/items) within and across domains. In this work, we propose an end-to-end neural network model – NeuCDCF, to address these challenges in a cross-domain setting. More importantly, NeuCDCF is based on a wide and deep framework and learns the representations jointly using both matrix factorization and deep neural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:qwy9JoKyICEC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Graph neural networks (GNNs) are able to achieve state-of-the-art performance for node representation and classification in a network. But, most of the existing GNNs can be applied to simple graphs, where an edge connects only a pair of nodes. Studies have shown that hypergraphs are effective to model real-world relationships which are of higher order in nature. Recently, graph neural networks are proposed for hypergraphs, but they implicitly use clique or star expansions to convert the hypergraph to a simple graph, or use computationally expensive hypergraph Laplacian.In this work, we propose a novel hypergraph neural network for semi-supervised hypernode classification, which operates directly on the hypergraphs with varying hyperedge sizes. Within each layer, it indirectly works on the line graph of the given hypergraph, without actually forming the line graph explicitly. Moreover, it also employs a self …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:RtRctb2lSbAC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Graph neural networks (GNNs) gain significant interest in the domain of network representation learning. To obtain a graph level vector representation from individual node embeddings, hierarchical pooling algorithms are proposed in the recent literature which adhere the hierarchical structure of an input graph. A major limitation for most of the existing supervised GNNs is their dependency on large number of graph labels (often 80%-90%) to train the parameters of the neural architecture. But obtaining labels of a large number of graphs is expensive for real world applications. So in this work, we propose an unsupervised hierarchical neural network, referred as GraPHmax, for obtaining graph level representation. We propose the concept of periphery representation and show its effectiveness to obtain discriminative features of an input graph. Further, inspired by the concepts from self-supervised learning, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:mel-f30kHHgC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"This book deals with network representation learning. It deals with embedding nodes, edges, subgraphs and graphs. There is a growing interest in understanding complex systems in different domains including health, education, agriculture and transportation. Such complex systems are analyzed by modeling, using networks that are aptly called complex networks. Networks are becoming ubiquitous as they can represent many real-world relational data, for instance, information networks, molecular structures, telecommunication networks and protein–protein interaction networks. Analysis of these networks provides advantages in many fields such as recommendation (recommending friends in a social network), biological field (deducing connections between proteins for treating new diseases) and community detection (grouping users of a social network according to their interests) by leveraging the latent information of networks. An active and important area of current interest is to come out with algorithms that learn features by embedding nodes or (sub) graphs into a vector space. These tasks come under the broad umbrella of representation learning. A representation learning model learns a mapping function that transforms the graphs' structure information to a low-/high-dimension vector space maintaining all the relevant properties.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:YB4bud6kWLwC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Path finding problems involve identification of a plan for conflict free movement of agents over a common road network. Most approaches to this problem handle the agents as point objects, wherein the size of the agent is significantly smaller than the road on which it travels. In this paper, we consider spatially extended agents which have a size comparable to the length of the road on which they travel. An optimal multi agent path finding approach for spatially-extended agents was proposed in the eXtended Conflict Based Search (XCBS) algorithm. As XCBS resolves only a pair of conflicts at a time, it results in deeper search trees in case of cascading or multiple (more than two agent) conflicts at a given location. This issue is addressed in eXtended Conflict Based Search with Awareness (XCBS-A) in which an agent uses awareness of other agents' plans to make its own plan. In this paper, we explore XCBS-A in greater detail, we theoretically prove its completeness and empirically demonstrate its performance with other algorithms in terms of variances in road characteristics, agent characteristics and plan characteristics. We demonstrate the distributive nature of the algorithm by evaluating its performance when distributed over multiple machines. XCBS-A generates a huge search space impacting its efficiency in terms of memory; to address this we propose an approach for memory-efficiency and empirically demonstrate the performance of the algorithm. The nature of XCBS-A is such that it may lead to suboptimal solutions, hence the final contribution of this paper is an enhanced approach, XCBS-Local Awareness (XCBS-LA) which we prove will …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:c1e4I3QdEKYC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Network (or graph) embedding is the task to map the nodes of a graph to a lower dimensional vector space, such that it preserves the graph properties and facilitates the downstream network mining tasks. Real world networks often come with (community) outlier nodes, which behave differently from the regular nodes of the community. These outlier nodes can affect the embedding of the regular nodes, if not handled carefully. In this paper, we propose a novel unsupervised graph embedding approach (called DMGD) which integrates outlier and community detection with node embedding. We extend the idea of deep support vector data description to the framework of graph embedding when there are multiple communities present in the given network, and an outlier is characterized relative to its community. We also show the theoretical bounds on the number of outliers detected by DMGD. Our formulation boils down to an interesting minimax game between the outliers, community assignments and the node embedding function. We also propose an efficient algorithm to solve this optimization framework. Experimental results on both synthetic and real world networks show the merit of our approach compared to state-of-the-arts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:SAZ1SQo2q1kC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Graph neural networks get significant attention for graph representation and classification in machine learning community. Attention mechanism applied on the neighborhood of a node improves the performance of graph neural networks. Typically, it helps to identify a neighbor node which plays more important role to determine the label of the node under consideration. But in real world scenarios, a particular subset of nodes together, but not the individual pairs in the subset, may be important to determine the label of the graph. To address this problem, we introduce the concept of subgraph attention for graphs. On the other hand, hierarchical graph pooling has been shown to be promising in recent literature. But due to noisy hierarchical structure of real world graphs, not all the hierarchies of a graph play equal role for graph classification. Towards this end, we propose a graph classification algorithm called SubGattPool which jointly learns the subgraph attention and employs two different types of hierarchical attention mechanisms to find the important nodes in a hierarchy and the importance of individual hierarchies in a graph. Experimental evaluation with different types of graph classification algorithms shows that SubGattPool is able to improve the state-of-the-art or remains competitive on multiple publicly available graph classification datasets. We conduct further experiments on both synthetic and real world graph datasets to justify the usefulness of different components of SubGattPool and to show its consistent performance on other downstream tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:__bU50VfleQC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Graph neural networks got significant attention for graph representation and classification in machine learning community. Different types of neighborhood aggregation and pooling strategies have been proposed in the literature. In this work, we introduce a higher order hierarchical GNN algorithm (SubGattPool) by employing (i) an attention mechanism which learns the importance and aggregates neighboring subgraphs of a node instead of first-order neighbors, and (ii) a hierarchical pooling strategy which learns the importance of different hierarchies in a GNN. SubGattPool is able to achieve state-of-the-art graph classification performance on multiple real-world datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:nPT8s1NX_-sC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Usual networks lossily (if not incorrectly) represent higher-order relations, which calls for complex structures such as hypergraphs to be used instead. Akin to the link prediction problem in graphs, we deal with hyperlink (higher-order link) prediction in hypergraphs. With a handful of solutions in the literature that seem to have merely scratched the surface, we provide improvements for the same. Motivated by observations in recent literature, we first formulate a “clique-closure” hypothesis (viz., hyperlinks are more likely to be formed from nearcliques rather than from non-cliques), test it on real hypergraphs, and then exploit it for our very problem. In the process, we generalize hyperlink prediction on two fronts:(1) from small-sized to arbitrary-sized hyperlinks, and (2) from a couple of domains to a handful. We perform experiments (both the hypothesis-test as well as the hyperlink prediction) on multiple real datasets, report results, and provide both quantitative and qualitative arguments favouring better performances wrt the state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:MIg0yeAD4ggC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Deep representation learning on non-Euclidean data types, such as graphs, has gained significant attention in recent years. Invent of graph neural networks has improved the state-of-the-art for both node and the entire graph representation in a vector space. However, for the entire graph representation, most of the existing graph neural networks are trained on a graph classification loss in a supervised way. But obtaining labels of a large number of graphs is expensive for real world applications. Thus, we aim to propose an unsupervised graph neural network to generate a vector representation of an entire graph in this paper. For this purpose, we combine the idea of hierarchical graph neural networks and mutual information maximization into a single framework. We also propose and use the concept of periphery representation of a graph and show its usefulness in the proposed algorithm which is referred as GraPHmax. We conduct thorough experiments on several real-world graph datasets and compare the performance of GraPHmax with a diverse set of both supervised and unsupervised baseline algorithms. Experimental results show that we are able to improve the state-of-the-art for multiple graph level tasks on several real-world datasets, while remain competitive on the others.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:C33y2ycGS3YC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Network representation learning and node classification in graphs got significant attention due to the invent of different types graph neural networks. Graph convolution network (GCN) is a popular semi-supervised technique which aggregates attributes within the neighborhood of each node. Conventional GCNs can be applied to simple graphs where each edge connects only two nodes. But many modern days applications need to model high order relationships in a graph. Hypergraphs are effective data types to handle such complex relationships. In this paper, we propose a novel technique to apply graph convolution on hypergraphs with variable hyperedge sizes. We use the classical concept of line graph of a hypergraph for the first time in the hypergraph learning literature. Then we propose to use graph convolution on the line graph of a hypergraph. Experimental analysis on multiple real world network datasets shows the merit of our approach compared to state-of-the-arts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:eAlLMO4JVmQC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Attributed network embedding is the task to learn a lower dimensional vector representation of the nodes of an attributed network, which can be used further for downstream network mining tasks. Nodes in a network exhibit community structure and most of the network embedding algorithms work well when the nodes, along with their attributes, adhere to the community structure of the network. But real life networks come with community outlier nodes, which deviate significantly in terms of their link structure or attribute similarities from the other nodes of the community they belong to. These outlier nodes, if not processed carefully, can even affect the embeddings of the other nodes in the network. Thus, a node embedding framework for dealing with both the link structure and attributes in the presence of outliers in an unsupervised setting is practically important. In this work, we propose a deep unsupervised …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:RJOyoaXV5v8C,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Network representation learning (also known as Graph embedding) is a technique to map the nodes of a network to a lower dimensional vector space. Random walk based representation techniques are found to be efficient as they can easily preserve different orders of proximities between the nodes in the embedding space. Most of the social networks now-a-days have some content (or attributes) associated with each node. These attributes can provide complementary information along with the link structure of the network. But in a real life network, the information carried by the link structure and that by the attributes vary significantly over the nodes. Most of the existing unsupervised attributed network embedding algorithms do not distinguish between the link structure and the attributes of a node depending on their informativeness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:T_ojBgVMvoEC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"While graphs capture pairwise relations between entities, hypergraphs deal with higher-order ones, thereby ensuring losslessness. However, in hyperlink (i.e., higher-order link) prediction, where hyperlinks and non-hyperlinks are treated as “positive” and “negative” classes respectively, hypergraphs suffer from the problem of extreme class imbalance. Given this context, “negative sampling”—under-sampling the negative class of non-hyperlinks—becomes mandatory for performing hyperlink prediction. No prior work on hyperlink prediction deals with this problem. In this work, which is the first of its kind, we deal with this problem in the context of hyperlink prediction. More specifically, we leverage graph sampling techniques for sampling non-hyperlinks in hyperlink prediction. Our analysis clearly establishes the effect of random sampling, which is the norm in both link- as well as hyperlink-prediction. Further …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:AYInfyleIOsC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Exploiting heterogeneous information networks (HIN) to top-N recommendation has been shown to alleviate the data sparsity problem present in recommendation systems. This requires careful effort in extracting relevant knowledge from HIN. However, existing models in this setting have the following shortcomings. Mainly, they are not end-to-end, which puts the burden on the system to first learn similarity or commuting matrix offline using some manually selected meta-paths before we train for the top-N recommendation objective. Further, they do not attentively extract user-specific information from HIN, which is essential for personalization. To address these challenges, we propose an end-to-end neural network model – GAMMA (Graph and Multi-view Memory Attention mechanism). We aim to replace the offline meta-path based similarity or commuting matrix computation with a graph attention …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:isU91gLudPYC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2020,"Social recommendation systems typically combine extra information like a social network with the user-item interaction network in order to alleviate data sparsity issues. This also helps in making more accurate and personalized recommendations. However, most of the existing systems work under the assumption that all socially connected users have equal influence on each other in a social network, which is not true in practice. Further, estimating the quantum of influence that exists among entities in a user-item interaction network is essential when only implicit ratings are available. This has been ignored even in many recent state-of-the-art models such as SAMN (Social Attentional Memory Network) and DeepSoR (Deep neural network model on Social Relations). Many a time, capturing a complex relationship between the entities (users/items) is essential to boost the performance of a recommendation system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:YlPif8NxrbYC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2019,"Network representation learning has traditionally been used to find lower dimensional vector representations of the nodes in a network. However, there are very important edge driven mining tasks of interest to the classical network analysis community, which have mostly been unexplored in the network embedding space. For applications such as link prediction in homogeneous networks, vector representation (i.e., embedding) of an edge is derived heuristically just by using simple aggregations of the embeddings of the end vertices of the edge. Clearly, this method of deriving edge embedding is suboptimal and there is a need for a dedicated unsupervised approach for embedding edges by leveraging edge properties of the network. Towards this end, we propose a novel concept of converting a network to its weighted line graph which is ideally suited to find the embedding of edges of the original network. We further derive a novel algorithm to embed the line graph, by introducing the concept of collective homophily. To the best of our knowledge, this is the first direct unsupervised approach for edge embedding in homogeneous information networks, without relying on the node embeddings. We validate the edge embeddings on three downstream edge mining tasks. Our proposed optimization framework for edge embedding also generates a set of node embeddings, which are not just the aggregation of edges. Further experimental analysis shows the connection of our framework to the concept of node centrality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:eGYfIraVYiQC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2019,"The concepts of centrality and diversity are highly important in search algorithms, and play central roles in applications of artificial intelligence (AI), machine learning (ML), social networks, and pattern recognition. This work examines the significance of centrality and diversity in representation, regression, ranking, clustering, optimization, and classification. The text is designed to be accessible to a broad readership. Requiring only a basic background in undergraduate-level mathematics, the work is suitable for senior undergraduate and graduate students, as well as researchers working in machine learning, data mining, social networks, and pattern recognition.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:X9ykpCP0fEIC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2019,"Cross-Domain Collaborative Filtering (CDCF) provides a way to alleviate data sparsity and cold-start problems present in recommendation systems by exploiting the knowledge from related domains. Existing CDCF models are either based on matrix factorization or deep neural networks. Either of the techniques in isolation may result in suboptimal performance for the prediction task. Also, most of the existing models face challenges particularly in handling diversity between domains and learning complex non-linear relationships that exist amongst entities (users/items) within and across domains. In this work, we propose an end-to-end neural network model -- NeuCDCF, to address these challenges in a cross-domain setting. More importantly, NeuCDCF follows a wide and deep framework and it learns the representations combinedly from both matrix factorization and deep neural networks. We perform experiments on four real-world datasets and demonstrate that our model performs better than state-of-the-art CDCF models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:JWITY9-sCbMC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2019,"Attributed network embedding has received much interest from the research community as most of the networks come with some content in each node, which is also known as node attributes. Existing attributed network approaches work well when the network is consistent in structure and attributes, and nodes behave as expected. But real world networks often have anomalous nodes. Typically these outliers, being relatively unexplainable, affect the embeddings of other nodes in the network. Thus all the downstream network mining tasks fail miserably in the presence of such outliers. Hence an integrated approach to detect anomalies and reduce their overall effect on the network embedding is required.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:sA9dB-pw3HoC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:wLxue7F8ec0C,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2019,"This chapter addresses one of the research issues connected with the outlier detection problem, namely dimensionality of the data. More specifically, the focus is on detecting outliers embedded in subspaces of high dimensional categorical data. To this effect, some algorithms for unsupervised selection of feature subsets in categorical data domain are furnished here. A detailed discussion on devising necessary measures for assessing the relevance and redundancy of categorical attributes/features is presented. Experimental study of these algorithms on benchmark categorical data sets explores the efficacy of these algorithms towards outlier detection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:G1UMdFYMoxkC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2019,"The topic of identifying objects that stand out from the norm in a data set is an exciting one in the field of data mining. Detecting such objects, known as outliers, is important for many applications such as fraud detection, network analysis, etc. Given the significance of outlier detection in real life scenarios, we chose to focus on this challenging research topic in this book. Contents of this book are mainly derived from the research work carried out towards Ph. D. thesis of the first author at Indian Institute of Science (IISc), Bangalore, under the supervision of the co-authors. The book itself is the outcome of the recommendation made by Prof. Lakhmi C. Jain, University of Canberra, suggesting us to produce a monograph based on our understanding of this research area.
The first part of the book touches upon the significant aspects of the problem that are useful in carrying out further research on related issues. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:Wq2b2clWBLsC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2019,"Cross-Domain Collaborative Filtering (CDCF) mitigates data sparsity and cold-start issues present in conventional recommendation systems by exploiting and transferring knowledge from related domains. Leveraging user-generated tags (e.g. ancient-literature, military-history) for bridging the related domains is becoming a popular way for enhancing personalized recommendations. However, existing tag based models bridge the domains based on common tags between domains and their co-occurrence frequencies. This results in capturing the syntax similarities between the tags and ignoring the semantic similarities between them. In this work, to address these, we propose TagEmbedSVD, a tag-based CDCF model to cross-domain setting. TagEmbedSVD makes use of the pre-trained word embeddings (word2vec) for tags to enhance personalized recommendations in the cross-domain setting. Empirical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:ghEM2AJqZyQC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2019,"Extended Conflict-Based Search (XCBS) is a distributed agent-based approach which has been used for path finding and scheduling of spatially extended agents on a traversable network. The algorithm arrives at an optimal schedule while resolving conflicts between pairs of agents one at a time. In this chapter, we propose XCBS with Awareness wherein a conflicting agent plan is resolved with respect to the proposed route plan of other agents. The approach allows multiple conflicts to be resolved simultaneously, avoids cascading conflicts in the new plans and shows an improved efficiency in terms of nodes explored and time taken to arrive at the solution.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:jSAVyFp_754C,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2018,"Measuring influence, through centrality measures, has been a center-piece of research in the analysis of complex social networks, such as finding coherent communities (clusters) and locating trend setters (prototypes) in viral marketing. Even though there exists a few axiomatic frameworks associated with some specific forms of influence measures in the literature, these formal frameworks are not generic in nature in terms of characterizing the space of influence measures for complex social networks. To address this research gap, we propose a generic axiomatic framework, in this paper, to capture most of the key intrinsic properties of any influence measure in networks. We further analyze certain popular centrality measures using this framework. Interestingly, our analysis reveals that none of the centrality measures considered satisfies all the desirable axioms. We finally conclude this paper by stating an appealing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:SIv7DqKytYAC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2018,"We study the problem of within network classification, where given a partially labeled network, we infer the labels of the remaining nodes based on the link structure. Conventional loss functions penalize a node based on a function of its predicted label and target label. Such loss functions under-perform while learning on a network having overlapping classes. In relational setting, even though the ground truth is not known for the unlabeled nodes, some evidence is present in the form of labeling acquired by the nodes in their neighborhood. We propose a structural loss function for learning in networks based on the hypothesis that loss is induced when a node fails to acquire a label that is consistent with the labels of the majority of the nodes in its neighborhood. We further combine this with a novel semantic regularizer, which we call homophily regularizer, to capture the smooth transition of discriminatory power and behavior of semantically similar nodes. The proposed structural loss along with the regularizer permits relaxation labeling. Through extensive comparative study on different real-world datasets, we found that our method improves over the state-of-the-art approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:DyXnQzXoVgIC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2018,"Network representation learning (also known as information network embedding) has been the central piece of research in social and information network analysis for the last couple of years. An information network can be viewed as a linked structure of a set of entities. A set of linked web pages and documents, a set of users in a social network are common examples of information network. Network embedding learns low dimensional representations of the nodes, which can further be used for downstream network mining applications such as community detection or node clustering. Information network representation techniques traditionally use only the link structure of the network. But in real world networks, nodes come with additional content such as textual descriptions or associated images. This content is semantically correlated with the network structure and hence using the content along with the topological structure of the network can facilitate the overall network representation. In this paper, we propose Sac2Vec, a network representation technique that exploits both the structure and content. We convert the network into a multi-layered graph and use random walk and language modeling technique to generate the embedding of the nodes. Our approach is simple and computationally fast, yet able to use the content as a complement to structure and vice-versa. We also generalize the approach for networks having multiple types of content in each node. Experimental evaluations on four real world publicly available datasets show the merit of our approach compared to state-of-the-art algorithms in the domain.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:FiDNX6EVdGUC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2018,"Analysis and visualization of an information network can be facilitated better using an appropriate embedding of the network. Network embedding learns a compact low-dimensional vector representation for each node of the network, and uses this lower dimensional representation for different network analysis tasks. Only the structure of the network is considered by a majority of the current embedding algorithms. However, some content is associated with each node, in most of the practical applications, which can help to understand the underlying semantics of the network. It is not straightforward to integrate the content of each node in the current state-of-the-art network embedding methods. In this paper, we propose a nonnegative matrix factorization based optimization framework, namely FSCNMF which considers both the network structure and the content of the nodes while learning a lower dimensional representation of each node in the network. Our approach systematically regularizes structure based on content and vice versa to exploit the consistency between the structure and content to the best possible extent. We further extend the basic FSCNMF to an advanced method, namely FSCNMF++ to capture the higher order proximities in the network. We conduct experiments on real world information networks for different types of machine learning applications such as node clustering, visualization, and multi-class classification. The results show that our method can represent the network significantly better than the state-of-the-art algorithms and improve the performance across all the applications that we consider.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:HhcuHIWmDEUC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2018,"In the past, hybrid recommender systems have shown the power of exploiting relationships amongst objects which directly or indirectly effect the recommendation task. However, the effect of all relations is not equal, and choosing their right balance for a recommendation problem at hand is non-trivial. We model these interactions using a Heterogeneous Information Network, and propose a systematic framework for learning their influence weights for a given recommendation task. Further, we address the issue of redundant results, which is very much prevalent in recommender systems. To alleviate redundancy in recommendations we use Vertex Reinforced Random Walk (a non-Markovian random walk) over a heterogeneous graph. It works by boosting the transitions to the influential nodes, while simultaneously shrinking the weights of others. This helps in discouraging recommendation of multiple influential nodes …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:pAkWuXOU-OoC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2018,"This paper is on the two parameter Laplace type Bimodal distribution. After discussing distributional properties, order statistics were developed and discussed. Inferential aspects were discussed and estimates of the parameters were obtained through Method of Moments and Maximum Likelihood Estimation techniques. Minimum unbiased estimator of the location parameter and best linear unbiased estimator of the location and scale parameter were also obtained.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:-6RzNnnwWf8C,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2018,This paper is on the mixtures of Laplace and Laplace type bimodal distribution with the probability p and 1-p respectively. In addition to the distribution properties and inferential aspects studied the same distribution was applied to the real-life data on the manpower planning of an organization under the two different promotional policies namely promotion by seniority and promotion by random.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:D_tqNUsBuKoC,https://www.csa.iisc.ac.in/~mnm/
Narasimha Murty M/ M. N. Murty/M. N. Narasimha Murthy,"['pattern recognition', 'data mining', 'machine learning', 'information retrieval', 'topic models']",19,7313,2018,"Data clustering plays a very important role in Data mining, machine learning and Image processing areas. As modern day databases have inherent uncertainties, many uncertainty-based data clustering algorithms have been developed in this direction. These algorithms are fuzzy c-means, rough c-means, intuitionistic fuzzy c-means and the means like rough fuzzy c-means, rough intuitionistic fuzzy c-means which base on hybrid models. Also, we find many variants of these algorithms which improve them in different directions like their Kernelised versions, possibilistic versions, and possibilistic Kernelised versions. However, all the above algorithms are not effective on big data for various reasons. So, researchers have been trying for the past few years to improve these algorithms in order they can be applied to cluster big data. The algorithms are relatively few in comparison to those for datasets of reasonable size …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=VQZTmpcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=VQZTmpcAAAAJ:OBSaB-F7qqsC,https://www.csa.iisc.ac.in/~mnm/
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2023,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:GnPB-g6toBAC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2023,"Even before the eyes move, visual sensitivity improves at the target of the planned eye movement. Yet, it is unknown if such ""presaccadic"" benefits are merely sensory, or also influence decisional processes. We teased apart these contributions with signal detection theory, and discovered a surprising absence of presaccadic benefits in visual change detection tasks. Participants planned and executed saccades while concurrently detecting and localizing either orientation or contrast changes. Spatial choice bias reliably improved presaccadically but, surprisingly, without a concomitant increase in perceptual sensitivity. Additional investigation with an orientation estimation task, and a Bayesian ""variable precision"" model, revealed that sensory precision increased at the saccade target, but only for the most recent of two successive stimuli. Moreover, the recent stimulus perceptually biased feature estimates of the prior stimulus, rendering accurate change detection even more challenging. Our results uncover novel perceptual and decisional mechanisms that mediate presaccadic change detection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:NMxIlDl6LWMC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2022,"Selective attention produces systematic effects on neural states. It is unclear whether, conversely, momentary fluctuations in neural states have behavioral significance for attention. We investigated this question in the human brain with a cognitive brain-machine interface (cBMI) for tracking electrophysiological steady-state visually evoked potentials (SSVEPs) in real-time. Discrimination accuracy (d’) was significantly higher when target stimuli were triggered at high, versus low, SSVEP power states. Target and distractor SSVEP power was uncorrelated across the hemifields, and target d’ was unaffected by distractor SSVEP power states. Next, we trained participants on an auditory neurofeedback paradigm to generate biased, cross-hemispheric competitive interactions between target and distractor SSVEPs. The strongest behavioral effects emerged when competitive SSVEP dynamics unfolded at a timescale …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:M3NEmzRMIkIC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2022,"Visual working memory (WM) is known to exhibit attractor dynamics, wherein mnemonic representations drift toward discrete, stable attractor states [1, 2]. Maintenance in WM is also accompanied by specific patterns of synchronization and desynchronization in parieto-occipital alpha-band (8-12 Hz) oscillations [3]. Yet, the link between alpha desynchronization and attractor dynamics in WM remains unexplored. We tested n= 24 human participants on a visual WM task involving delayed (~ 2500 ms) reporting of a retro-cued grating’s orientation. Although grating orientations were uniformly distributed across trials, participants’ orientation reports systematically favored the nearest diagonal orientations and were biased away from cardinal orientations, indicating stable and unstable fixed points (attractors) at these orientations, respectively. We investigated the behavioral and neural correlates of these attractor dynamics …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:blknAaTinKkC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2022,"We present a biologically inspired recurrent neural network (RNN) that efficiently detects changes in natural images. The model features sparse, topographic connectivity (st-RNN), closely modeled on the circuit architecture of a “midbrain attention network.” We deployed the st-RNN in a challenging change blindness task, in which changes must be detected in a discontinuous sequence of images. Compared with a conventional RNN, the st-RNN learned 9x faster and achieved state-of-the-art performance with 15x fewer connections. An analysis of low-dimensional dynamics revealed putative circuit mechanisms, including a critical role for a global inhibitory (GI) motif, for successful change detection. The model reproduced key experimental phenomena, including midbrain neurons' sensitivity to dynamic stimuli, neural signatures of stimulus competition, as well as hallmark behavioral effects of midbrain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:k_IJM867U9cC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2022,"Reliable outlier detection is critical for real-world applications of deep learning models. Likelihoods produced by deep generative models, although extensively studied, have been largely dismissed as being impractical for outlier detection. For one, deep generative model likelihoods are readily biased by low-level input statistics. Second, many recent solutions for correcting these biases are computationally expensive or do not generalize well to complex, natural datasets. Here, we explore outlier detection with a state-of-the-art deep autoregressive model: PixelCNN++. We show that biases in PixelCNN++ likelihoods arise primarily from predictions based on local dependencies. We propose two families of bijective transformations that we term ""shaking"" and ""stirring"", which ameliorate low-level biases and isolate the contribution of long-range dependencies to the PixelCNN++ likelihood. These transformations are computationally inexpensive and readily applied at evaluation time. We evaluate our approaches extensively with five grayscale and six natural image datasets and show that they achieve or exceed state-of-the-art outlier detection performance. In sum, lightweight remedies suffice to achieve robust outlier detection on images with deep generative models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:TFP_iSt0sucC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2022,"Diffusion magnetic resonance imaging and tractography enable the estimation of anatomical connectivity in the human brain, in vivo. Yet, without ground-truth validation, different tractography algorithms can yield widely varying connectivity estimates. Although streamline pruning techniques mitigate this challenge, slow compute times preclude their use in big-data applications. We present ‘Regularized, Accelerated, Linear Fascicle Evaluation’ (ReAl-LiFE), a GPU-based implementation of a state-of-the-art streamline pruning algorithm (LiFE), which achieves >100× speedups over previous CPU-based implementations. Leveraging these speedups, we overcome key limitations with LiFE’s algorithm to generate sparser and more accurate connectomes. We showcase ReAl-LiFE’s ability to estimate connections with superlative test–retest reliability, while outperforming competing approaches. Moreover, we predicted …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:j3f4tGmQtD8C,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2022,"Deep networks often make confident, yet, incorrect, predictions when tested with outlier data that is far removed from their training distributions. Likelihoods computed by deep generative models (DGMs) are a candidate metric for outlier detection with unlabeled data. Yet, previous studies have shown that DGM likelihoods are unreliable and can be easily biased by simple transformations to input data. Here, we examine outlier detection with variational autoencoders (VAEs), among the simplest of DGMs. We propose novel analytical and algorithmic approaches to ameliorate key biases with VAE likelihoods. Our bias corrections are sample-specific, computationally inexpensive, and readily computed for various decoder visible distributions. Next, we show that a well-known image pre-processing technique--contrast stretching--extends the effectiveness of bias correction to further improve outlier detection. Our approach achieves state-of-the-art accuracies with nine grayscale and natural image datasets, and demonstrates significant advantages--both with speed and performance--over four recent, competing approaches. In summary, lightweight remedies suffice to achieve robust outlier detection with VAEs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:RHpTSmoSYBkC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2021,"Despite possessing the capacity for selective attention, we often fail to notice the obvious. We investigated participants’ (n = 39) failures to detect salient changes in a change blindness experiment. Surprisingly, change detection success varied by over two-fold across participants. These variations could not be readily explained by differences in scan paths or fixated visual features. Yet, two simple gaze metrics–mean duration of fixations and the variance of saccade amplitudes–systematically predicted change detection success. We explored the mechanistic underpinnings of these results with a neurally-constrained model based on the Bayesian framework of sequential probability ratio testing, with a posterior odds-ratio rule for shifting gaze. The model’s gaze strategies and success rates closely mimicked human data. Moreover, the model outperformed a state-of-the-art deep neural network (DeepGaze II) with predicting human gaze patterns in this change blindness task. Our mechanistic model reveals putative rational observer search strategies for change detection during change blindness, with critical real-world implications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:dhFuZR0502QC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2021,"Deep networks often make confident, yet incorrect, predictions when tested with outlier data that is far removed from their training distributions. Likelihoods computed by deep generative models are a candidate metric for outlier detection with unlabeled data. Yet, previous studies have shown that such likelihoods are unreliable and can be easily biased by simple transformations to input data. Here, we examine outlier detection with variational autoencoders (VAEs), among the simplest class of deep generative models. First, we show that a theoreticallygrounded correction readily ameliorates a key bias with VAE likelihood estimates. The bias correction is model-free, sample-specific, and accurately computed with the Bernoulli and continuous Bernoulli visible distributions. Second, we show that a well-known preprocessing technique, contrast normalization, extends the effectiveness of bias correction to natural image datasets. Third, we show that the variance of the likelihoods computed over an ensemble of VAEs also enables robust outlier detection. We perform a comprehensive evaluation of our remedies with nine (grayscale and natural) image datasets, and demonstrate significant advantages, in terms of both speed and accuracy, over four other state-of-the-art methods. Our lightweight remedies are biologically inspired and may serve to achieve efficient outlier detection with many types of deep generative models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:BqipwSGYUEgC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2020,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:e5wmG9Sq2KIC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2020,"We thank Friedrich et al.(1) for their keen interest in our study (2) and for highlighting additional examples of asymmetries in visually guided behavior and brain connectivity across several vertebrate classes. The superior colliculus (SC), or its nonmammalian homolog, the optic tectum (OT), is, indeed, an evolutionarily conserved vertebrate midbrain structure (3, 4). The SC/OT is spatiotopically organized and multilayered and exhibits strong anatomical and functional homology across vertebrates (3, 5). Superficial layers of the SC/OT receive visual inputs, whereas intermediate layers receive multisensory inputs (3, 5). SC/OT intermediate layers also receive inputs from the forebrain (3). For example, in nonhuman primates, SC/OT intermediate layers receive inputs from frontal and parietal cortex, including the frontal eye field and lateral intraparietal area (5). Similarly, in birds, gazerelated forebrain areas project to the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:TQgYirikUcIC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2020,"Flexible functional interactions among brain regions mediate critical cognitive functions. Such interactions can be measured using functional magnetic resonance imaging (fMRI) data either with instantaneous (zero-lag) or lag-based (time-lagged) functional connectivity. Because the fMRI hemodynamic response is slow, and is sampled at a timescale (seconds) several orders of magnitude slower than the underlying neural dynamics (milliseconds), simulation studies have shown that lag-based fMRI functional connectivity, measured with approaches like Granger–Geweke causality (GC), provides spurious and unreliable estimates of underlying neural interactions. Experimental verification of this claim is challenging because neural ground truth connectivity is often unavailable concurrently with fMRI recordings. Here we demonstrate that, despite these widely held caveats, GC networks estimated from fMRI …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:7PzlFSSx8tAC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2019,"Functional magnetic resonance imaging (fMRI) enables measuring human brain activity, in vivo. Yet, the fMRI hemodynamic response unfolds over very slow timescales (< 0.1-1 Hz), orders of magnitude slower than millisecond timescales of neural spiking. It is unclear, therefore, if slow dynamics as measured with fMRI are relevant for cognitive function. We investigated this question with a novel application of Gaussian Process Factor Analysis (GPFA) and machine learning to fMRI data. We analyzed slowly sampled (1.4 Hz) fMRI data from 1000 healthy human participants (Human Connectome Project database), and applied GPFA to reduce dimensionality and extract smooth latent dynamics. GPFA dimensions with slow (< 1 Hz) characteristic timescales identified, with high accuracy (> 95%), the specific task that each subject was performing inside the fMRI scanner. Moreover, functional connectivity between slow GPFA latents accurately predicted inter-individual differences in behavioral scores across a range of cognitive tasks. Finally, infra-slow (< 0.1 Hz) latent dynamics predicted CDR (Clinical Dementia Rating) scores of individual patients, and identified patients with mild cognitive impairment (MCI) who would progress to develop Alzheimer’s dementia (AD). Slow and infra-slow brain dynamics may be relevant for understanding the neural basis of cognitive function, in health and disease.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:qUcmZB5y_30C,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2019,"Neural mechanisms of attention are extensively studied in the neocortex; comparatively little is known about how subcortical regions contribute to attention. The superior colliculus (SC) is an evolutionarily conserved, subcortical (midbrain) structure that has been implicated in controlling visuospatial attention. Yet how the SC contributes mechanistically to attention remains unknown. We investigated the role of the SC in attention, combining model-based psychophysics, diffusion imaging, and tractography in human participants. Specifically, we asked whether the SC contributes to enhancing sensitivity (d′) to attended information, or whether it contributes to biasing choices (criteria) in favor of attended information. We tested human participants on a multialternative change detection task, with endogenous spatial cueing, and quantified sensitivity and bias with a recently developed multidimensional signal detection …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:ZeXyd9-uunAC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2019,"Attention can be directed endogenously, based on task-relevant goals, or captured exogenously, by salient stimuli. While recent studies have shown that endogenous attention can facilitate behavior through dissociable sensitivity (sensory) and choice bias (decisional) mechanisms, it is unknown if exogenous attention also operates through dissociable sensitivity and bias mechanisms. We tested human participants on a multialternative change detection task with exogenous attention cues, which preceded or followed change events in close temporal proximity. Analyzing participants’ behavior with a multidimensional signal detection model revealed clear dissociations between exogenous cueing effects on sensitivity and bias. While sensitivity was, overall, lower at the cued location compared to other locations, bias was highest at the cued location. With an appropriately designed post-cue control condition, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:L8Ckcad2t8MC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2019,"Endogenous cueing of attention enhances sensory processing of the attended stimulus (perceptual sensitivity) and prioritizes information from the attended location for guiding behavioral decisions (spatial choice bias). Here, we test whether sensitivity and bias effects of endogenous spatial attention are under the control of common or distinct mechanisms. Human observers performed a multialternative visuospatial attention task with probabilistic spatial cues. Observers’ behavioral choices were analyzed with a recently developed multidimensional signal detection model (the m-ADC model). The model effectively decoupled the effects of spatial cueing on sensitivity from those on spatial bias and revealed striking dissociations between them. Sensitivity was highest at the cued location and not significantly different among uncued locations, suggesting a spotlight-like allocation of sensory resources at the cued …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:IWHjjKOFINEC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2019,"Brain processes occur at various timescales, ranging from milliseconds (neurons) to minutes and hours (behavior). Characterizing functional coupling among brain regions at these diverse timescales is key to understanding how the brain produces behavior. Here, we apply instantaneous and lag-based measures of conditional linear dependence, based on Granger-Geweke causality (GC), to infer network connections at distinct timescales from functional magnetic resonance imaging (fMRI) data. Due to the slow sampling rate of fMRI, it is widely held that GC produces spurious and unreliable estimates of functional connectivity when applied to fMRI data. We challenge this claim with simulations and a novel machine learning approach. First, we show, with simulated fMRI data, that instantaneous and lag-based GC identify distinct timescales and complementary patterns of functional connectivity. Next, we analyze …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:YFjsv_pBGBYC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:hMod-77fHWUC,http://cns.iisc.ac.in/sridhar
Devarajan Sridharan,"['neuroscience', 'cognition', 'psychophysics', 'computation']",12,1795,2019,"Diffusion imaging and tractography enable mapping structural connections in the human brain, in-vivo. Linear Fascicle Evaluation (LiFE) is a state-of-the-art approach for pruning spurious connections in the estimated structural connectome, by optimizing its fit to the measured diffusion data. Yet, LiFE imposes heavy demands on computing time, precluding its use in analyses of large connectome databases. Here, we introduce a GPU-based implementation of LiFE that achieves 50-100x speedups over conventional CPU-based implementations for connectome sizes of up to several million fibers. Briefly, the algorithm accelerates generalized matrix multiplications on a compressed tensor through efficient GPU kernels, while ensuring favorable memory access patterns. Leveraging these speedups, we advance LiFE’s algorithm by imposing a regularization constraint on estimated fiber weights during connectome pruning. Our regularized, accelerated, LiFE algorithm (“ReAl-LiFE”) estimates sparser connectomes that also provide more accurate fits to the underlying diffusion signal. We demonstrate the utility of our approach by classifying pathological signatures of structural connectivity in patients with Alzheimer’s Disease (AD). We estimated million fiber whole-brain connectomes, followed by pruning with ReAl-LiFE, for 90 individuals (45 AD patients and 45 healthy controls). Linear classifiers, based on support vector machines, achieved over 80% accuracy in classifying AD patients from healthy controls based on their ReAl-LiFE pruned structural connectomes alone. Moreover, classification based on the ReAl-LiFE pruned connectome outperformed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5ij8Y9YAAAAJ&sortby=pubdate&citation_for_view=5ij8Y9YAAAAJ:4DMP91E08xMC,http://cns.iisc.ac.in/sridhar
Jayant Haritsa,['Database Systems'],16,795,2022,"Synthesizing data using declarative formalisms has been persuasively advocated in contemporary data generation frameworks. In particular, they specify operator output volumes through row-cardinality constraints. However, thus far, adherence to these volumetric constraints has been limited to the Filter and Join operators. A critical deficiency is the lack of support for the Projection operator, which is at the core of basic SQL constructs such as Distinct, Union and Group By. The technical challenge here is that cardinality unions in multi-dimensional space, and not mere summations, need to be captured in the generation process. Further, dependencies across different data subspaces need to be taken into account.
We address the above lacuna by presenting PiGen, a dynamic data generator that incorporates Projection cardinality constraints in its ambit. The design is based on a projection subspace division strategy …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:Ak0FvsSvgGUC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2021,"We investigate a new query reverse-engineering problem of unmasking SQL queries hidden within database applications. The diverse use-cases for this problem range from resurrecting legacy code to query rewriting. As a first step in addressing the unmasking challenge, we present UNMASQUE, an active-learning extraction algorithm that can expose a basal class of hidden warehouse queries. A special feature of our design is that the extraction is non-invasive wrt the application, examining only the results obtained from repeated executions on databases derived with a combination of data mutation and data generation techniques. Further, potent optimizations are incorporated to minimize the extraction overheads. A detailed evaluation over applications hosting hidden SQL queries, or their imperative versions, demonstrates that UNMASQUE correctly and efficiently extracts these queries.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:lvd772isFD0C,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:gKiMpY-AVTkC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2021,"A core requirement of database engine testing is the ability to generate synthetic databases that exhibit a desired set of characteristics. Expressing these characteristics through declarative formalisms has been advocated in contemporary testing frameworks. In particular, specifying operator output volumes through row-cardinality constraints has received considerable attention. However, thus far, adherence to these volumetric constraints has been limited to only the Filter and Join operators. A critical deficiency is the lack of support for the Projection operator, which forms the core of basic SQL constructs such as Distinct, Union and Group By. The technical challenge here is that cardinality unions in multi-dimensional space, and not mere summations, need to be captured in the generation process. Further, dependencies across different data subspaces need to be taken into account.
In this paper, we address the above lacuna by presenting PiGen, a dynamic data generator that incorporates Projection cardinality constraints in its ambit. The design is based on a projection subspace division strategy which supports the expression of constraints using optimized linear programming formulations. Further, techniques of symmetric refinement and workload decomposition are introduced to handle constraints across different projection subspaces. Finally, PiGen supports dynamic generation, where data is generated on-demand during query processing, making it amenable to Big Data environments. A detailed evaluation on TPC-DS-based query workloads demonstrates that PiGen can accurately and efficiently model Projection outcomes, representing an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:5MTHONV0fEkC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2021,"Generating synthetic databases that capture essential data characteristics of client databases is a common requirement for database vendors. We recently proposed Hydra, a workload-aware and scale-free data regenerator that provides statistical fidelity on the volumetric similarity metric. A limitation, however, is that it suffers poor accuracy on unseen queries. In this paper, we present HF-Hydra (HiFi-Hydra), which extends Hydra to provide better support to unseen queries through (a) careful choices among the candidate synthetic databases and (b) incorporation of metadata constraints. Our experimental study validates the improved fidelity and efficiency of HF-Hydra.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:u-coK7KVo8oC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2021,"We investigate a new query reverse-engineering problem of unmasking SQL queries hidden within database applications. The diverse use-cases for this problem range from resurrecting legacy code to query rewriting. As a first step in addressing the unmasking challenge, we present UNMASQUE, an active-learning extraction algorithm that can expose a basal class of hidden warehouse queries. A special feature of our design is that the extraction is non-invasive wrt the application, examining only the results obtained from repeated executions on databases derived with a combination of data mutation and data generation techniques. Further, potent optimizations, such as table minimization and sampling, are incorporated to reduce extraction overheads. A detailed evaluation over applications hosting hidden SQL queries, or their imperative versions, demonstrates that UNMASQUE correctly and efficiently extracts these queries.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:Aul-kAQHnToC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2020,"Given a database instance and a populated result, query reverse-engineering attempts to identify candidate SQL queries that produce this result on the instance. A variant of this problem arises when a ground-truth is additionally available, but hidden within an opaque database application. In this demo, we present UN-MASQUE, an extraction algorithm that is capable of precisely identifying a substantive class of such hidden queries. A hallmark of its design is that the extraction is completely non-invasive to the application. Specifically, it only examines the results obtained from application executions on databases derived with a combination of data mutation and data generation techniques, thereby achieving platform-independence. Further, potent optimizations, such as database size reduction to a few rows, are incorporated to minimize the extraction overheads. The demo showcases these features on both …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:Ehil0879vHcC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2020,"A popular approach to hosting Keyword Search Systems (KWS) on relational DBMS platforms is to employ the Candidate Network framework. The quality of a Candidate Network-based search is critically dependent on the scoring function used to rank the relevant answers. In this paper, we first demonstrate, through detailed empirical and conceptual analysis studies, that the Labrador scoring function provides the best user relevance among contemporary Candidate Network scoring functions.
Efficiently incorporating the Labrador function, however, is rendered difficult due to its Result Set Dependent (RSD) characteristic, wherein the distribution of keywords in the query results influences the ranking. To address this RSD challenge ►We investigate two mechanisms ►(a) a simple wrapper approach that leverages existing RDBMS functionalities through an SQL wrapper ►And (b) a more sophisticated operator …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:3htObqc8RwsC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2019,"NOVEMBER 2019| VOL. 62| NO. 11| COMMUNICATIONS OF THE ACM 49 hot topics india region expressive power comes great challenges.” In this article, we have highlighted a few recent successes in tackling these challenges, but there remain rich opportunities for further contributions to the field. Productive future work areas include extending the holistic optimization concept to new domains (for example, machine learning), and leveraging query and data characteristics to deliver tighter robustness guarantees.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:OcBU2YAGkTUC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2019,"Robust query processing with strong performance guarantees is an extremely desirable objective in the design of industrial-strength database engines. However, it has proved to be a largely intractable and elusive challenge in spite of sustained efforts spanning several decades. The good news is that in recent times, there have been a host of exciting technical advances, at different levels in the database architecture, that collectively promise to materially address this problem. In this tutorial, we will present these novel research approaches, characterize their strengths and limitations, and enumerate open technical problems that remain to be solved to make robust query processing a contemporary reality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:bKqednn6t2AC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2019,"Prior solutions for securely handling SQL range predicates in outsourced cloud-resident databases have primarily focused on passive attacks in the Honest-but-Curious adversarial model, where the server is only permitted to observe the encrypted query processing. We consider here a significantly more powerful adversary, wherein the server can launch an active attack by clandestinely issuing specific range queries via collusion with a few compromised clients. The security requirement in this environment is that data values from a plaintext domain of size N should not be leaked to within an interval of size H. Unfortunately, all prior encryption schemes for range predicate evaluation are easily breached with only O (log2ψ) range queries, where ψ= N/H. To address this lacuna, we present SPLIT, a new encryption scheme where the adversary requires exponentially more–O (ψ)–range queries to breach the interval constraint, and can therefore be easily detected by standard auditing mechanisms. The novel aspect of SPLIT is that each value appearing in a rangesensitive column is first segmented into two parts. These segmented parts are then independently encrypted using a layered composition of a Secure Block Cipher with the Order-Preserving Encryption and Prefix-Preserving Encryption schemes, and the resulting ciphertexts are stored in separate tables. At query processing time, range predicates are rewritten into an equivalent set of table-specific sub-range predicates, and the disjoint union of their results forms the query answer. A detailed evaluation of SPLIT on benchmark database queries indicates that its execution times are well …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:vDZJ-YLwNdEC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2019,"A popular approach to hosting Keyword Search Systems (KWS) on relational DBMS platforms is to employ the Candidate Network framework. The quality of a Candidate Network-based search is critically dependent on the scoring function used to rank the relevant answers. In this paper, we first demonstrate, through a detailed empirical study, that the Labrador scoring function provides the best user relevance among contemporary Candidate Network scoring functions.
Efficiently incorporating the Labrador function, however, is rendered difficult due to its Result Set Dependent (RSD) characteristic, wherein the distribution of keywords in the query results influences the ranking. In this paper, we investigate addressing the RSD challenge through inclusion of custom operators within the database engine. Specifically, we propose and evaluate an operator called Root Rank, which performs result ranking in the root of the query execution plan.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:QYdC8u9Cj1oC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2018,"Prior solutions for securely handling SQL range predicates in outsourced Cloud-resident databases have primarily focused on passive attacks in the Honest-but-Curious adversarial model, where the server is only permitted to observe the encrypted query processing. We consider here a significantly more powerful adversary, wherein the server can launch an active attack by clandestinely issuing specific range queries via collusion with a few compromised clients. The security requirement in this environment is that data values from a plaintext domain of size N should not be leaked to within an interval of size . Unfortunately, all prior encryption schemes for range predicate evaluation are easily breached with only range queries, where . To address this lacuna, we present SPLIT, a new encryption scheme where the adversary requires exponentially more——range queries to breach the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:SpbeaW3--B0C,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2018,"The 2016 VLDB Conference was held in New Delhi, India, during September 5–9, 2016. We received a record number of 719 research submissions, of which around 16% were accepted for presentation by the Program Committee. From these high-quality manuscripts, a Best Papers Committee consisting of Jignesh Patel, Jeffrey D. Ullman, and Gerhard Weikum, selected six outstanding papers and also picked the best paper award for the conference. We invited the authors of the six selected papers to submit an extended version for consideration in this Special Issue, and they all accepted our call. The reviewers for the manuscripts were a mix of those who had reviewed the conference versions, as well as additional experts who reviewed only the journal submissions. After two rounds of reviewing, all six papers were accepted for publication in this issue, covering a diverse spectrum of topics ranging from core …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:IUKN3-7HHlwC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2018,"To address the classical selectivity estimation problem in database systems, a radically different query processing technique called PlanBouquet was proposed in 2014. In this approach, the estimation process is completely abandoned and replaced with a calibrated selectivity discovery mechanism. The beneficial outcome is that provable guarantees are obtained on worst-case execution performance, thereby facilitating robust query processing. An improved version of PlanBouquet, called SpillBound (SB), which significantly accelerates the selectivity discovery process, and provides platform-independent performance guarantees, was presented two years ago.
Notwithstanding its benefits, a limitation of SpillBound is that its guarantees are predicated on expending enormous preprocessing efforts during query compilation, making it suitable only for canned queries that are invoked repeatedly. In this paper, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:_5tno0g5mFcC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2018,"Methods, systems, and computer program products for securely processing range predicates on cloud databases are provided herein. A computer-implemented method includes separately encrypting a set of plain text data using two or more encryption functions, thereby producing an encrypted domain comprising at least two distinct groups of encrypted data items; converting a range query over plain text data items into a query over at least one of the distinct groups of encrypted data items; and combining results from the query over the distinct groups of encrypted data items, thereby generating a final encrypted result to the range query.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:_FM0Bhl9EiAC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2018,"A core requirement of database engine testing is the ability to create synthetic versions of the customer's data warehouse at the vendor site. Prior work on synthetic data regeneration suffers from critical limitations with regard to (a) scaling to large data volumes, (b) handling complex query workloads, and (c) producing data on demand. In this demo, we present HYDRA, a workload-dependent dynamic data regenerator, that materially addresses these limitations. It introduces the concept of dynamic regeneration by constructing a minuscule memory-resident database summary that can on-the-fly regenerate databases of arbitrary size during query execution. Further, since the data is generated in memory, the velocity of generation can be closely regulated. Finally, to complement dynamic regeneration, Hydra also ensures that the process of summary construction is data-scale-free.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:mlAyqtXpCwEC,http://dsl.cds.iisc.ac.in/~haritsa
Jayant Haritsa,['Database Systems'],16,795,2018,"A core requirement of database engine testing is the ability to create synthetic versions of the customer’s data warehouse at the vendor site. A rich body of work exists on synthetic database regeneration, but suffers critical limitations with regard to:(a) maintaining statistical fidelity to the client’s query processing, and/or (b) scaling to large data volumes. In this paper, we present HYDRA, a workload-dependent database regenerator that leverages a declarative approach to data regeneration to assure volumetric similarity, a crucial aspect of statistical fidelity, and materially improves on the prior art by adding scale, dynamism and functionality. Specifically, Hydra uses an optimized linear programming (LP) formulation based on a novel regionpartitioning approach. This spatial strategy drastically reduces the LP complexity, enabling it to handle query workloads on which contemporary techniques fail. Second, Hydra …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=dc626ewAAAAJ&sortby=pubdate&citation_for_view=dc626ewAAAAJ:NXb4pA-qfm4C,http://dsl.cds.iisc.ac.in/~haritsa
Bhavana Kanukurthi,['Cryptography'],10,262,2022,"Sealed bid auctions are used to allocate a resource among a set of interested parties. Traditionally, auctions need the presence of a trusted auctioneer to whom the bidders provide their private bid values. Existence of such a trusted party is not an assumption easily realized in practice. Generic secure computation protocols can be used to remove a trusted party. However, generic techniques result in inefficient protocols, and typically do not provide fairness -- that is, a corrupt party can learn the output and abort the protocol thereby preventing other parties from learning the output.
At CRYPTO 2009, Miltersen, Nielsen and Triandopoulos~\citeC:MilNieTri09, introduced the problem of building auctions that are secure against rational bidders. Such parties are modeled as self-interested agents who care more about maximizing their utility than about learning information about bids of other agents. To realize this, they …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&sortby=pubdate&citation_for_view=QYNU5jMAAAAJ:0EnyYjriUFMC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,262,2022,"Leakage resilient secret sharing (LRSS) allows a dealer to share a secret amongst n parties such that any authorized subset of the parties can recover the secret from their shares, while an adversary that obtains shares of any unauthorized subset of parties along with bounded leakage from the other shares learns no information about the secret. Non-malleable secret sharing (NMSS) provides a guarantee that even shares that are tampered by an adversary will reconstruct to either the original message or something independent of it.
The most important parameter of LRSS and NMSS schemes is the size of each share. For LRSS, in the local leakage model (i.e., when the leakage functions on each share are independent of each other and bounded), Srinivasan and Vasudevan (CRYPTO 2019), gave a scheme for threshold access structures with share size of approximately , where is the number of bits of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&sortby=pubdate&citation_for_view=QYNU5jMAAAAJ:hqOjcs7Dif8C,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,262,2022,"At ITCS 2010, Dziembowski, Pietrzak, and Wichs introduced Non-malleable Codes (NMCs) which protect against tampering of a codeword of a given message into the codeword of a related message. A well-studied model of tampering is the 2-split-state model where the codeword consists of two independently tamperable states. As with standard error-correcting codes, it is of great importance to build codes with high rates.
Following a long line of work, Aggarwal and Obremski (FOCS 2020) showed the first constant rate non-malleable code in the 2−split state model; however, this constant was a minuscule 10−6! In this work, we build a Non-malleable Code with rate 1/3. This nearly matches the rate 1/2 lower bound for this model due to Cheraghchi and Guruswami (ITCS 2014). Our construction is simple, requiring just an inner-product extractor, a seeded extractor, and an affine-evasive function.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&sortby=pubdate&citation_for_view=QYNU5jMAAAAJ:UebtZRa9Y70C,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,262,2021,"We introduce Adaptive Extractors, which unlike traditional randomness extractors, guarantee security even when an adversary obtains leakage on the source after observing the extractor output. We make a compelling case for the study of such extractors by demonstrating their use in obtaining adaptive leakage in secret sharing schemes.
Specifically, at FOCS 2020, Chattopadhyay, Goodman, Goyal, Kumar, Li, Meka, Zuckerman, built an adaptively secure leakage resilient secret sharing scheme (LRSS) with both rate and leakage rate being , where is the number of parties. In this work, we build an adaptively secure LRSS that offers an interesting trade-off between rate, leakage rate, and the total number of shares from which an adversary can obtain leakage. As a special case, when considering t-out-of-n secret sharing schemes for threshold (constant ), we build a scheme with a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&sortby=pubdate&citation_for_view=QYNU5jMAAAAJ:LkGwnXOMwfcC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,262,2021,"Non-malleable secret sharing (NMSS) schemes, introduced by Goyal and Kumar (STOC 2018), ensure that a secret can be distributed into shares (for some ), such that any (a parameter ) shares can be reconstructed to recover the secret , any shares doesn't leak information about and even if the shares that are used for reconstruction are tampered, it is guaranteed that the reconstruction of these tampered shares will either result in the original or something independent of . Since their introduction, non-malleable secret sharing schemes sparked a very impressive line of research. In this work, we introduce a feature of local reconstructability in NMSS, which allows reconstruction of any portion of a secret by reading just a few locations of the shares. This is a useful feature, especially when the secret is long or when the shares are stored in a distributed manner on a communication network. In this work, we give a compiler that takes in any non-malleable secret sharing scheme and compiles it into a locally reconstructable non-malleable secret sharing scheme. To secret share a message consisting of blocks of length each, our scheme would only require reading bits (in addition to a few more bits, whose quantity is independent of and ) from each party's share (of a reconstruction set) to locally reconstruct a single block of the message. We show an application of our locally reconstructable non-malleable secret sharing scheme to a computational non-malleable secure message transmission scheme in the pre-processing model, with an improved communication complexity, when transmitting multiple …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&sortby=pubdate&citation_for_view=QYNU5jMAAAAJ:roLk4NBRz8UC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,262,2020,"Non-malleable codes (NMCs), introduced by Dziembowski, Pietrzak and Wichs (ITCS 2010), provide a powerful guarantee in scenarios where the classical notion of error-correcting codes cannot provide any guarantee: a decoded message is either the same or completely independent of the underlying message, regardless of the number of errors introduced into the codeword. Informally, NMCs are defined with respect to a family of tampering functions and guarantee that any tampered codeword decodes either to the same message or to an independent message, so long as it is tampered using a function . One of the well-studied tampering families for NMCs is the t-split-state family, where the adversary tampers each of the t“states” of a codeword, arbitrarily but independently. Cheraghchi and Guruswami (TCC 2014) obtain a rate-1 non-malleable code for the case where with n being the codeword length and, in (ITCS 2014), show an upper …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&sortby=pubdate&citation_for_view=QYNU5jMAAAAJ:YsMSGLbcyi4C,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,262,2019,"Non-malleable Codes give us the following property: their codewords cannot be tampered into codewords of related messages. Privacy Amplification allows parties to convert their weak shared secret into a fully hidden, uniformly distributed secret key, while communicating on a fully tamperable public channel. In this work, we show how to construct a constant round privacy amplification protocol from any augmented split-state non-malleable code. Existentially, this gives us another primitive (in addition to optimal non-malleable extractors) whose optimal construction would solve the long-standing open problem of building constant round privacy amplification with optimal entropy loss and min-entropy requirement. Instantiating our code with the current best known NMC gives us an 8-round privacy amplification protocol with entropy loss and min-entropy requirement , where is the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&sortby=pubdate&citation_for_view=QYNU5jMAAAAJ:ufrVoPGSRksC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,262,2018,"Non-malleable Codes (NMCs), introduced by Dziembowski, Peitrzak and Wichs (ITCS 2010), serve the purpose of preventing “related tampering” of encoded messages. The most popular tampering model considered is the 2-split-state model where a codeword consists of 2 states, each of which can be tampered independently. While NMCs in the 2-split state model provide the strongest security guarantee, despite much research in the area we only know how to build them with poor rate ( , where n is the codeword length). However, in many applications of NMCs one only needs to be able to encode randomness i.e., security is not required to hold for arbitrary, adversarially chosen messages. For example, in applications of NMCs to tamper-resilient security, the messages that are encoded are typically randomly generated secret keys. To exploit this, in this work, we introduce the notion of “Non-malleable …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&sortby=pubdate&citation_for_view=QYNU5jMAAAAJ:eQOLeE2rZwMC,http://drona.csa.iisc.ernet.in/~bhavana/
Bhavana Kanukurthi,['Cryptography'],10,262,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=QYNU5jMAAAAJ&sortby=pubdate&citation_for_view=QYNU5jMAAAAJ:5nxA0vEk-isC,http://drona.csa.iisc.ernet.in/~bhavana/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2023,"We consider the problem of control in the setting of reinforcement learning (RL), where model information is not available. Policy gradient algorithms are a popular solution approach for this problem and are usually shown to converge to a stationary point of the value function. In this paper, we propose two policy Newton algorithms that incorporate cubic regularization. Both algorithms employ the likelihood ratio method to form estimates of the gradient and Hessian of the value function using sample trajectories. The first algorithm requires an exact solution of the cubic regularized problem in each iteration, while the second algorithm employs an efficient gradient descent-based approximation to the cubic regularized problem. We establish convergence of our proposed algorithms to a second-order stationary point (SOSP) of the value function, which results in the avoidance of traps in the form of saddle points. In particular, the sample complexity of our algorithms to find an -SOSP is , which is an improvement over the state-of-the-art sample complexity of .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:zGdJYJv2LkUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2023,"We present in this paper a family of generalized simultaneous perturbation stochastic approximation (G-SPSA) estimators that estimate the gradient of the objective using noisy function measurements, but where the number of function measurements and the form of the gradient estimator is guided by the desired estimator bias. In particular, estimators with more function measurements are seen to result in lower bias. We provide an analysis of convergence of generalized SPSA, and point to possible future directions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:wvYxNZNCP7wC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2023,"We consider the problem of finding the optimal value of n in the n-step temporal difference (TD) algorithm. We find the optimal n by resorting to the model-free optimization technique of simultaneous perturbation stochastic approximation (SPSA). We adopt a one-simulation SPSA procedure that is originally for continuous optimization to the discrete optimization framework but incorporates a cyclic perturbation sequence. We prove the convergence of our proposed algorithm, SDPSA, and show that it finds the optimal value of n in n-step TD. Through experiments, we show that the optimal value of n is achieved with SDPSA for any arbitrary initial value of the same.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:jSAVyFp_754C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2023,"Large road networks overflowing with vehicles have called for increased traffic congestion, the impact of which is felt on an everyday basis and across different dimensions like decreased traveller satisfaction, increased fuel usage and increased air pollution among many other troubles. Improved traffic control strategies that can self-learn to adapt their decisioning in response to dynamic changes in the traffic flows and are capable of mitigating overall network congestion as opposed to localized congestion at intersections, are of great importance in mitigating traffic congestion. Traffic control strategies which were rule-based or historical-demand based were over-simplified and could not scale to large real-world road networks. To effectively control traffic congestion at scale, the need for co-operation and communication between the different intersections of a large road network is crucial. Multi-agent reinforcement …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:PkcyUWeTMh0C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"During initial iterations of training in most Reinforcement Learning (RL) algorithms, agents perform a significant number of random exploratory steps. In the real world, this can limit the practicality of these algorithms as it can lead to potentially dangerous behavior. Hence safe exploration is a critical issue in applying RL algorithms in the real world. This problem has been recently well studied under the Constrained Markov Decision Process (CMDP) Framework, where in addition to single-stage rewards, an agent receives single-stage costs or penalties as well depending on the state transitions. The prescribed cost functions are responsible for mapping undesirable behavior at any given time-step to a scalar value. The goal then is to find a feasible policy that maximizes reward returns while constraining the cost returns to be below a prescribed threshold during training as well as deployment. We propose an On-policy Model-based Safe Deep RL algorithm in which we learn the transition dynamics of the environment in an online manner as well as find a feasible optimal policy using the Lagrangian Relaxation-based Proximal Policy Optimization. We use an ensemble of neural networks with different initializations to tackle epistemic and aleatoric uncertainty issues faced during environment model learning. We compare our approach with relevant model-free and model-based approaches in Constrained RL using the challenging Safe Reinforcement Learning benchmark-the Open AI Safety Gym. We demonstrate that our algorithm is more sample efficient and results in lower cumulative hazard violations as compared to constrained model-free …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:TlpoogIpr_IC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,We revisit the standard formulation of tabular actor-critic algorithm as a two time-scale stochastic approximation with value function computed on a faster time-scale and policy computed on a slower time-scale. This emulates policy iteration. We begin by observing that reversal of the time scales will in fact emulate value iteration and is a legitimate algorithm. We compare the two empirically with and without function approximation (with both linear and nonlinear function approximators) and observe that our proposed critic-actor algorithm performs better empirically though with a marginal increase in the computational cost.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:SnGPuo6Feq8C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"The infinite horizon setting is widely adopted for problems of reinforcement learning (RL). These invariably result in stationary policies that are optimal. In many situations, finite horizon control problems are of interest and for such problems, the optimal policies are time-varying in general. Another setting that has become popular in recent times is of Constrained Reinforcement Learning, where the agent maximizes its rewards while also aims to satisfy certain constraint criteria. However, this setting has only been studied in the context of infinite horizon MDPs where stationary policies are optimal. We present, for the first time, an algorithm for constrained RL in the Finite Horizon Setting where the horizon terminates after a fixed (finite) time. We use function approximation in our algorithm which is essential when the state and action spaces are large or continuous and use the policy gradient method to find the optimal policy. The optimal policy that we obtain depends on the stage and so is time-dependent. To the best of our knowledge, our paper presents the first policy gradient algorithm for the finite horizon setting with constraints. We show the convergence of our algorithm to an optimal policy. We further present a sample complexity result for our algorithm in the unconstrained (i.e., the regular finite horizon MDP) setting. We also compare and analyze the performance of our algorithm through experiments and show that our algorithm performs better than other well known algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:69ZgNCALVd0C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"Applying reinforcement learning (RL) methods for real world applications pose multiple challenges - the foremost being safety of the system controlled by the learning agent and the learning efficiency. An RL agent learns to control a system by exploring the available actions in various operating states. In some states, when the RL agent exercises an exploratory action, the system may enter unsafe operation, which can lead to safety hazards both for the system as well as for humans supervising the system. RL algorithms thus must learn to control the system respecting safety. In this work, we formulate the safe RL problem in the constrained off-policy setting that facilitates safe exploration by the RL agent. We then develop a sample efficient algorithm utilizing the cross-entropy method. The proposed algorithm’s safety performance is evaluated numerically on benchmark RL problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:HJSXoJQnj-YC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"Learning the value function of a given policy from data samples is an important problem in Reinforcement Learning. TD is a popular class of algorithms to solve this problem. However, the weights assigned to different -step returns in TD , controlled by the parameter , decrease exponentially with increasing . In this paper, we present a -schedule procedure that generalizes the TD algorithm to the case when the parameter could vary with time-step. This allows flexibility in weight assignment, i.e., the user can specify the weights assigned to different -step returns by choosing a sequence . Based on this procedure, we propose an on-policy algorithm - TD schedule, and two off-policy algorithms - GTD -schedule and TDC -schedule, respectively. We provide proofs of almost sure convergence for all three algorithms under a general Markov noise framework.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:3bvyWxjaHKcC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"In this paper, we consider the stochastic iterative counterpart of the value iteration scheme wherein only noisy and possibly biased approximations of the Bellman operator are available. We call this counterpart the approximate value iteration (AVI) scheme. Neural networks are often used as function approximators, in order to counter Bellman’s curse of dimensionality. In this paper, they are used to approximate the Bellman operator. Because neural networks are typically trained using sample data, errors and biases may be introduced. The design of AVI accounts for implementations with biased approximations of the Bellman operator and sampling errors. We present verifiable sufficient conditions under which AVI is stable (almost surely bounded) and converges to a fixed point of the approximate Bellman operator. To ensure the stability of AVI, we present three different yet related sets of sufficient conditions that are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:6yz0xqPARnAC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"In this paper, we present a stochastic gradient algorithm for minimizing a smooth objective function that is an expectation over noisy cost samples and only the latter are observed for any given parameter. Our algorithm employs a gradient estimation scheme with random perturbations, which are formed using the truncated Cauchy distribution from the unit sphere. We analyze the bias and variance of the proposed gradient estimator. Our algorithm is found to be particularly useful in the case when the objective function is non-convex, and the parameter dimension is high. From an asymptotic convergence analysis, we establish that our algorithm converges almost surely to the set of stationary points of the objective function and obtain the asymptotic convergence rate. We also show that our algorithm avoids unstable equilibria, implying convergence to local minima. Further, we perform a non-asymptotic convergence analysis of our algorithm. In particular, we establish here a non-asymptotic bound for finding an -stationary point of the non-convex objective function. Finally, we demonstrate numerically through simulations that the performance of our algorithm outperforms GSF, SPSA and RDSA by a significant margin over a few non-convex settings and further validate its performance over convex (noisy) objectives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:rTD5ala9j4wC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"Learning optimal behavior from existing data is one of the most important problems in Reinforcement Learning (RL). This is known as “off-policy control” in RL where an agent's objective is to compute an optimal policy based on the data obtained from the given policy (known as the behavior policy). As the optimal policy can be very different from the behavior policy, learning optimal behavior is very hard in the “off-policy” setting compared to the “on-policy” setting where new data from the policy updates is typically utilized in learning. This work proposes an off-policy natural actor-critic algorithm that utilizes state-action distribution correction for handling the off-policy behavior and the natural policy gradient for sample efficiency. The existing natural gradient-based actor-critic algorithms with convergence guarantees require fixed features for approximating both policy and value functions. This often leads to sub-optimal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:FiDNX6EVdGUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"Gradient temporal difference (Gradient TD) algorithms are a popular class of stochastic approximation (SA) algorithms used for policy evaluation in reinforcement learning. Here, we consider Gradient TD algorithms with an additional heavy ball momentum term and provide choice of step size and momentum parameter that ensures almost sure convergence of these algorithms asymptotically. In doing so, we decompose the heavy ball Gradient TD iterates into three separate iterates with different step sizes. We first analyze these iterates under one-timescale SA setting using results from current literature. However, the one-timescale case is restrictive and a more general analysis can be provided by looking at a three-timescale decomposition of the iterates. In the process we provide the first conditions for stability and convergence of general three-timescale SA. We then prove that the heavy ball Gradient TD algorithm is convergent using our three-timescale SA analysis. Finally, we evaluate these algorithms on standard RL problems and report improvement in performance over the vanilla algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:w0F2JDEymm0C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"Nannapaneni, RajasekharKulkarni, Raghavendra V.Bhatnagar, ShalabhSince the inception of machine learning (ML) era, the objective has always been to achieve human-level intelligence so that machines can perform cognitive level tasks. Reinforcement learning (RL) can guide an agent how to act in the world. The interface to a reinforcement learning agent is much broader than just data; it can be the entire environment. The invent of deep learning (DL) architectures has facilitated the tackling of high-dimensional problems as they act as good function approximators. In this work, the capabilities of reinforcement learning are analyzed and integrated with DL to form deep reinforcement learning (DRL) so that their combined learning potential of high-dimensional state space is possible. The deep reinforcement learning is applied on vehicular traffic control system which has a high-dimensional state space. An in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:YsrPvlHIBpEC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"Recent works in Reinforcement Learning (RL) combine model-free (Mf)-RL algorithms with model-based (Mb)-RL approaches to get the best from both: asymptotic performance of Mf-RL and high sample-efficiency of Mb-RL. Inspired by these works, we propose a hierarchical framework that integrates online learning for the Mb-trajectory optimization with off-policy methods for the Mf-RL. In particular, two loops are proposed, where the Dynamic Mirror Descent based Model Predictive Control (DMD-MPC) is used as the inner loop Mb-RL to obtain an optimal sequence of actions. These actions are in turn used to significantly accelerate the outer loop Mf-RL. We show that our formulation is generic for a broad class of MPC based policies and objectives, and includes some of the well-known Mb-Mf approaches. We finally introduce a new algorithm: Mirror-Descent Model Predictive RL (M-DeMoRL), which uses Cross …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:-nhnvRiOwuoC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"We consider the problem of two-player zero-sum games. This problem is formulated as a min–max Markov game in this article. The solution of this game, which is the min–max payoff, starting from a given state is called the min–max value of the state. In this article, we compute the solution of the two-player zero-sum game, utilizing the technique of successive relaxation that has been successfully applied in this article to compute a faster value iteration algorithm in the context of Markov decision processes. We extend the concept of successive relaxation to the setting of two-player zero-sum games. We show that, under a special structure on the game, this technique facilitates faster computation of the min–max value of the states. We then derive a generalized minimax Q-learning algorithm, which computes the optimal policy when the model information is not known. Finally, we prove the convergence of the proposed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:HGTzPopzzJcC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"In this paper, we use concepts from supervisory control theory of discrete event systems to propose a method to learn optimal control policies for a finite-state Markov Decision Process (MDP) in which (only) certain sequences of actions are deemed unsafe (respectively safe). We assume that the set of action sequences that are deemed unsafe and/or safe are given in terms of a finite-state automaton; and propose a supervisor that disables a subset of actions at every state of the MDP so that the constraints on action sequence are satisfied. Then we present a version of the Q-learning algorithm for learning optimal policies in the presence of non-Markovian action-sequence and state constraints, where we use the development of reward machines to handle the state constraints. We illustrate the method using an example that captures the utility of automata-based methods for non-Markovian state and action specifications for reinforcement learning and show the results of simulations in this setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:mUJArPsKIAAC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2022,"Traffic congestion is an omnipresent and serious problem that impacts people around the world on a daily basis. It requires solutions that can adapt to the changing traffic environments and reduce traffic congestion not only across local intersections but also across the global road network. Traditional traffic control strategies suffer from being too simplistic and moreover, they cannot scale to real-world dynamics. Multiagent reinforcement learning is being widely researched to develop intelligent transportation systems where the different intersections on a road network co-operate to ease vehicle delay and traffic congestion. Most of the literature on using Multiagent reinforcement learning methods for traffic signal control is focussed on applying multi-agent Q learning and discrete-action based control methods. In this paper, we propose traffic signal control using Multiagent Twin Delayed Deep Deterministic Policy Gradients (MATD3). The proposed control strategy is evaluated by exposing it to different time-varying traffic flows on simulation of road networks created on the traffic simulation platform SUMO. We observe that our method is robust to the different kinds of traffic flows and consistently outperforms the state-of-the-art counterparts by significantly reducing the average vehicle delay and queue length.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:ziOE8S1-AIUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2021,"This paper presents the first sufficient conditions that guarantee the stability and almost sure convergence of -timescale stochastic approximation (SA) iterates. It extends the existing results on One-timescale and Two-timescale SA iterates with a martingale noise to timescale recursions using the ordinary differential equation (ODE) based method. As an application of our results, we study SA algorithms with an added heavy ball momentum term in the context of Gradient Temporal Difference (GTD) algorithms. We show that, when the momentum parameters are chosen in a certain way, the schemes are stable and convergent to the same solution using our proposed results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:F2UWTTQJPOcC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2021,"In this paper, with a view toward fast deployment of locomotion gaits in low-cost hardware, we use a linear policy for realizing end-foot trajectories in the quadruped robot, Stoch 2. In particular, the parameters of the end-foot trajectories are shaped via a linear feedback policy that takes the torso orientation and the terrain slope as inputs. The corresponding desired joint angles are obtained via an inverse kinematics solver and tracked via a PID control law. Augmented Random Search, a model-free and a gradient-free learning algorithm is used to train this linear policy. Simulation results show that the resulting walking is robust to terrain slope variations and external pushes. This methodology is not only computationally light-weight but also uses minimal sensing and actuation capabilities in the robot, thereby justifying the approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:-7ulzOJl1JYC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2021,"Value iteration is a fixed point iteration technique utilized to obtain the optimal value function and policy in a discounted reward Markov decision process (MDP). Here, a contraction operator is constructed and applied repeatedly to arrive at the optimal solution. Value iteration is a first-order method and, therefore, it may take a large number of iterations to converge to the optimal solution. Successive relaxation is a popular technique that can be applied to solve a fixed point equation. It has been shown in the literature that under a special structure of the MDP, successive overrelaxation technique computes the optimal value function faster than standard value iteration. In this article, we propose a second-order value iteration procedure that is obtained by applying the Newton–Raphson method to the successive relaxation value iteration scheme. We prove the global convergence of our algorithm to the optimal solution …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:HhcuHIWmDEUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2021,"In this letter we provide several informative tight error bounds when using value function approximators for the risk-sensitive cost setting for a given policy represented using exponential utility. The novelty of our approach is that we make use of the irreducibility of the underlying Markov chain (resulting in better bounds using Perron–Frobenius eigenvectors) to derive new bounds whereas the earlier work used primarily the spectral variation bound which holds for any matrix, hence did not make use of the irreducibility. All our bounds have a perturbation term for large state spaces. We also present examples where we show that the new bounds perform 90-100% better than the earlier proposed spectral variation bound.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:PyEswDtIyv0C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2021,"Zeroth Order Bayesian Optimization (ZOBO) methods optimize an unknown function based on its black-box evaluations at the query locations. Unlike most optimization procedures, ZOBO methods fail to utilize gradient information even when it is available. On the other hand, First Order Bayesian Optimization (FOBO) methods exploit the available gradient information to arrive at better solutions faster. However, the existing FOBO methods do not utilize a crucial information that the gradient is zero at the optima. Further, the inherent sequential nature of the FOBO methods incur high computational cost limiting their wide applicability. To alleviate the aforementioned difficulties of FOBO methods, we propose a relaxed statistical model to leverage the gradient information that directly searches for points where gradient vanishes. To accomplish this, we develop novel acquisition algorithms that search for global …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:AXkvAH5U_nMC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2021,"This article compiles several aspects of the dynamics of stochastic approximation algorithms with Markov iterate-dependent noise when the iterates are not known to be stable beforehand. We achieve the same by extending the lock-in probability (i.e., the probability of convergence of the iterates to a specific attractor of the limiting ordinary differential equation (o.d.e.) given that the iterates are in its domain of attraction after a sufficiently large number of iterations (say) ) framework to such recursions. Specifically, with the more restrictive assumption of Markov iterate-dependent noise supported on a bounded subset of the Euclidean space, we give a lower bound for the lock-in probability . We use these results to prove almost sure convergence of the iterates to the specified attractor when the iterates satisfy an asymptotic tightness condition. The novelty of our approach is that if the state space of the Markov …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:QyXJ3EUuO1IC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2021,"In this work, we consider the problem of computing optimal actions for Reinforcement Learning (RL) agents in a co-operative setting, where the objective is to optimize a common goal. However, in many real-life applications, in addition to optimizing the goal, the agents are required to satisfy certain constraints specified on their actions. Under this setting, the objective of the agents is to not only learn the actions that optimize the common objective but also meet the specified constraints. In recent times, the Actor-Critic algorithm with an attention mechanism has been successfully applied to obtain optimal actions for RL agents in multi-agent environments. In this work, we extend this algorithm to the constrained multi-agent RL setting. The idea here is that optimizing the common goal and satisfying the constraints may require different modes of attention. By incorporating different attention modes, the agents can select useful information required for optimizing the objective and satisfying the constraints separately, thereby yielding better actions. Through experiments on benchmark multi-agent environments, we show the effectiveness of our proposed algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:MAUkC_7iAq8C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"Reinforcement learning (RL) methods learn optimal decisions in the presence of a stationary environment. However, the stationary assumption on the environment is very restrictive. In many real world problems like traffic signal control, robotic applications, etc., one often encounters situations with non-stationary environments, and in these scenarios, RL methods yield sub-optimal decisions. In this paper, we thus consider the problem of developing RL methods that obtain optimal decisions in a non-stationary environment. The goal of this problem is to maximize the long-term discounted reward accrued when the underlying model of the environment changes over time. To achieve this, we first adapt a change point algorithm to detect change in the statistics of the environment and then develop an RL algorithm that maximizes the long-run reward accrued. We illustrate that our change point method detects change in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:WC9gN4BGCRcC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"We consider the problem of energy management in microgrid networks. A microgrid is capable of generating power from a renewable resource and is responsible for handling the demands of its dedicated customers. Owing to the variable nature of renewable generation and the demands of the customers, it becomes imperative that each microgrid optimally manages its energy. This involves intelligently scheduling the demands at the customer side, selling (when there is a surplus) and buying (when there is a deficit) the power from its neighboring microgrids depending on its current and future needs. In this work, we formulate the problems of demand and battery scheduling, energy trading and dynamic pricing (where we allow the microgrids to decide the price of the transaction depending on their current configuration of demand and renewable energy) in the framework of stochastic games. Subsequently, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:-mN3Mh-tlDkC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"Hindsight Experience Replay (HER) is one of the efficient algorithm to solve Reinforcement Learning tasks related to sparse rewarded environments.But due to its reduced sample efficiency and slower convergence HER fails to perform effectively. Natural gradients solves these challenges by converging the model parameters better. It avoids taking bad actions that collapse the training performance. However updating parameters in neural networks requires expensive computation and thus increase in training time. Our proposed method solves the above mentioned challenges with better sample efficiency and faster convergence with increased success rate. A common failure mode for DDPG is that the learned Q-function begins to dramatically overestimate Q-values, which then leads to the policy breaking, because it exploits the errors in the Q-function. We solve this issue by including Twin Delayed Deep Deterministic Policy Gradients(TD3) in HER. TD3 learns two Q-functions instead of one and it adds noise tothe target action, to make it harder for the policy to exploit Q-function errors. The experiments are done with the help of OpenAis Mujoco environments. Results on these environments show that our algorithm (TDHER+KFAC) performs better inmost of the scenarios",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:jFemdcug13IC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"Asynchronous stochastic approximations (SAs) are an important class of model-free algorithms, tools, and techniques that are popular in multiagent and distributed control scenarios. To counter Bellman's curse of dimensionality, such algorithms are coupled with function approximations. Although the learning/control problem becomes more tractable, function approximations affect stability and convergence. In this article, we present verifiable sufficient conditions for stability and convergence of asynchronous SAs with biased approximation errors. The theory developed herein is used to analyze policy gradient methods and noisy value iteration schemes. Specifically, we analyze the asynchronous approximate counterparts of the policy gradient (A2PG) and value iteration (A2VI) schemes. It is shown that the stability of these algorithms is unaffected by biased approximation errors, provided that they are asymptotically …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:fFSKOagxvKUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"In this paper we design hybrid control policies for hybrid systems whose mathematical models are unknown. Our contributions are threefold. First, we propose a framework for modelling the hybrid control design problem as a single Markov Decision Process (MDP). This result facilitates the application of off-the-shelf algorithms from Reinforcement Learning (RL) literature towards designing optimal control policies. Second, we model a set of benchmark examples of hybrid control design problem in the proposed MDP framework. Third, we adapt the recently proposed Proximal Policy Optimisation (PPO) algorithm for the hybrid action space and apply it to the above set of problems. It is observed that in each case the algorithm converges and finds the optimal policy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:rHJHxKgnXwkC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"We consider an industrial internet-of-things (IIoT) system with multiple IoT devices, a user equipment (UE), together with a base station (BS) that receives the UE and IoT data. To circumvent the issue of numerous IoT-to-BS connections and to conserve IoT devices' energies, the UE serves as a relay to forward the IoT data to the BS. The UE employs frame-based uplink transmissions, wherein it shares few slots of every frame to relay the IoT data. The IIoT system experiences a transmission failure called outage when IoT data is not transmitted. The unsent UE data is stored in the UE's buffer and is discarded after the storage time exceeds the age threshold. As the UE and IoT devices share the transmission slots, trade-offs exist between system outages and aged UE data loss. To resolve system outage-data ageing challenge, we provide model-free reinforcement learning (RL)-based policies for slot-sharing between …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:6_hjMsCP8ZoC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"With the research into development of quadruped robots picking up pace, learning based techniques are being explored for developing locomotion controllers for such robots. A key problem is to generate leg trajectories for continuously varying target linear and angular velocities, in a stable manner. In this paper, we propose a two pronged approach to address this problem. First, multiple simpler policies are trained to generate trajectories for a discrete set of target velocities and turning radius. These policies are then augmented using a higher level neural network for handling the transition between the learned trajectories. Specifically, we develop a neural network based filter that takes in target velocity, radius and transforms them into new commands that enable smooth transitions to the new trajectory. This transformation is achieved by learning from expert demonstrations. An application of this is the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:SjuI4pbJlxcC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"We present a new deep reinforcement learning algorithm using the technique of successive over-relaxation (SOR) in Deep Q-networks (DQNs). The new algorithm, named SOR-DQN, uses modified targets in the DQN framework with the aim of accelerating training. This work is motivated by the problem of auto-scaling resources for cloud applications, for which existing algorithms suffer from issues such as slow convergence, poor performance during the training phase and non-scalability. For the above problem, SOR-DQN achieves significant improvements over DQN on both synthetic and real datasets. We also study the generalization ability of the algorithm to multiple tasks by using it to train agents playing Atari video games.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:q-HalDI95KYC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"Option-critic learning is a general-purpose reinforcement learning (RL) framework that aims to address the issue of long term credit assignment by leveraging temporal abstractions. However, when dealing with extended timescales, discounting future rewards can lead to incorrect credit assignments. In this work, we address this issue by extending the hierarchical option-critic policy gradient theorem for the average reward criterion. Our proposed framework aims to maximize the long-term reward obtained in the steady-state of the Markov chain defined by the agent's policy. Furthermore, we use an ordinary differential equation based approach for our convergence analysis and prove that the parameters of the intra-option policies, termination functions, and value functions, converge to their corresponding optimal values, with probability one. Finally, we illustrate the competitive advantage of learning options, in the average reward setting, on a grid-world environment with sparse rewards.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:PaBasH6fAo0C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"The review paper is providing the brief idea of photonic Crystal Cavities (PCCs) structures and their applications for biosensing devices. The paper presents the review of different PCC structures with modified properties of sensing. For several optical sensing applications, different PCC structure with properties are described in details. The conclusion of reported work and result demonstrated that miniaturization of optical biosensors is possible by the different PCC structure. This PCC structure has flexibility in structure for different sensing applications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:1Ye0OR6EYb4C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2020,"In this letter, we derive a generalization of the Speedy Q-learning (SQL) algorithm that was proposed in the Reinforcement Learning (RL) literature to handle slow convergence of Watkins' Q-learning. In most RL algorithms such as Q-learning, the Bellman equation and the Bellman operator play an important role. It is possible to generalize the Bellman operator using the technique of successive relaxation. We use the generalized Bellman operator to derive a simple and efficient family of algorithms called Generalized Speedy Q-learning (GSQL-w) and analyze its finite time performance. We show that GSQL-w has an improved finite time performance bound compared to SQL for the case when the relaxation parameter w is greater than 1. This improvement is a consequence of the contraction factor of the generalized Bellman operator being less than that of the standard Bellman operator. Numerical experiments are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:LdasjJ6CEcoC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In this paper, with a view toward fast deployment of learned locomotion gaits in low-cost hardware, we generate a library of walking trajectories, namely, forward trot, backward trot, side-step, and turn in our custom-built quadruped robot, Stoch 2, using reinforcement learning. There are existing approaches that determine optimal policies for each time step, whereas we determine an optimal policy, in the form of end-foot trajectories, for each half walking step i.e., swing phase and stance phase. The way-points for the foot trajectories are obtained from a linear policy, i.e., a linear function of the states of the robot, and cubic splines are used to interpolate between these points. Augmented Random Search, a model-free and gradient-free learning algorithm is used to learn the policy in simulation. This learned policy is then deployed on hardware, yielding a trajectory in every half walking step. Different locomotion patterns are learned in simulation by enforcing a preconfigured phase shift between the trajectories of different legs. The transition from one gait to another is achieved by using a low-pass filter for the phase, and the sim-to-real transfer is improved by a linear transformation of the states obtained through regression.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:FiytvqdAVhgC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"Extreme quantile is a very influential and powerful performance measure in high risk environments like financial markets, targeted advertising and high frequency trading. Extreme quantiles are defined as the threshold in the range of the performance values of the system being monitored beyond which the probability is extremely low. Unfortunately, the estimation of extreme quantiles is usually accompanied by high variance. We provide an incremental, single pass and adaptive variance reduction technique to estimate extreme quantiles. We further provide additional theoretical and empirical analysis pertaining to the effectiveness of our approach. Our experiments show considerable performance improvement over other widely popular algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:Ade32sEp0pkC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In any industrial or software system, predicting future values of measurable parameters well in advance is of utmost importance for avoiding disruptions. The historical data on system parameters measured at regular time intervals can be leveraged to address this long horizon prediction problem. However, complex interdependencies between the parameters and the need for avoiding false recommendations pose challenges in this prediction task. An equally challenging and useful exercise is to identify the 'important' parameters and optimize them in order to attain good system performance. This paper describes a generic framework, along with specific methods, for this data analytics problem and presents a case study on a large-scale enterprise system. The proposed method combines techniques from machine learning, causal analysis, time-series analysis and stochastic optimization to achieve accurate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:yxmsSjX2EkcC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In this paper, we accomplish two tasks:(1) We provide an alternate proof for the quantile estimation algorithm proposed under a fully relaxed setting. The convergence of the quantile estimation method is guaranteed under two necessary conditions: the stability of the iterates and the differentiability of the expected linear residual function. We literally remove these two assumptions and propose a differential inclusion based analysis. (2) We further propose a much improved quantile estimation algorithm by considering the asymmetrically weighted quadratic residual function along with double averaging.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:Br1UauaknNIC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"This paper presents our method for enabling a UAV quadrotor, equipped with a monocular camera, to autonomously avoid collisions with obstacles in unstructured and unknown indoor environments. When compared to obstacle avoidance in ground vehicular robots, UAV navigation brings in additional challenges because the UAV motion is no more constrained to a well-defined indoor ground or street environment. Unlike ground vehicular robots, a UAV has to navigate across more types of obstacles - for e.g., objects like decorative items, furnishings, ceiling fans, sign-boards, tree branches, etc., are also potential obstacles for a UAV. Thus, methods of obstacle avoidance developed for ground robots are clearly inadequate for UAV navigation. Current control methods using monocular images for UAV obstacle avoidance are heavily dependent on environment information. These controllers do not fully retain and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:fbc8zXXH2BUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"Learning the value function of a given policy (target policy) from the data samples obtained from a different policy (behavior policy) is an important problem in Reinforcement Learning (RL). This problem is studied under the setting of off-policy prediction. Temporal Difference (TD) learning algorithms are a popular class of algorithms for solving the prediction problem. TD algorithms with linear function approximation are shown to be convergent when the samples are generated from the target policy (known as on-policy prediction). However, it has been well established in the literature that off-policy TD algorithms under linear function approximation diverge. In this work, we propose a convergent on-line off-policy TD algorithm under linear function approximation. The main idea is to penalize the updates of the algorithm in a way as to ensure convergence of the iterates. We provide a convergence analysis of our algorithm. Through numerical evaluations, we further demonstrate the effectiveness of our algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:MpfHP-DdYjUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"Elasticity is an attractive feature of cloud computing, that enables increasing or decreasing the resources allocated to an application in order to adapt to changes in the workload. To efficiently utilize elasticity of clouds, the decisions on resource allocation need to be made algorithmically, adaptively and in real-time. The resource provisioning algorithm must also consider the performance requirements of the application as specified in the Service Level Agreement between the cloud provider and the client. In this paper, we present a reinforcement learning based algorithm that addresses the issues of slow convergence and lack of scalability in classical approaches such as Q-learning. We use the technique of adaptive tile coding and workload forecasting to ensure efficient utilization of resources. The effectiveness of the proposed method as compared to static, threshold-based and other reinforcement learning based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:hsZV8lGYWTMC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In this paper, we explore a specific form of deep reinforcement learning (D-RL) technique for quadrupedal walking—trajectory based policy search via deep policy networks. Existing approaches determine optimal policies for each time step, whereas we propose to determine an optimal policy for each walking step. We justify our approach based on the fact that animals including humans use “low” dimensional trajectories at the joint level to realize walking. We will construct these trajectories by using Bézier polynomials, with the coefficients being determined by a parameterized policy. In order to maintain smoothness of the trajectories during step transitions, hybrid invariance conditions are also applied. The action is computed at the beginning of every step, and a linear PD control law is applied to track at the individual joints. After each step, reward is computed, which is then used to update the new policy …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:cK4Rrx0J3m0C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In this work, we provide a simulation framework to perform systematic studies on the effects of spinal joint compliance and actuation on bounding performance of a 16-DOF quadruped spined robot Stoch 2. Fast quadrupedal locomotion with active spine is an extremely hard problem, and involves a complex coordination between the various degrees of freedom. Therefore, past attempts at addressing this problem have not seen much success. Deep-Reinforcement Learning seems to be a promising approach, after its recent success in a variety of robot platforms, and the goal of this paper is to use this approach to realize the aforementioned behaviors. With this learning framework, the robot reached a bounding speed of 2.1m /s with a maximum Froude number of 2. Simulation results also show that use of active spine, indeed, increased the stride length, improved the cost of transport, and also reduced the natural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:jgBuDB5drN8C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In this paper, we propose multi-timescale, sequential algorithms for deterministic optimization which can find high-quality solutions. The algorithms fundamentally track the well-known derivative-free model-based search methods in an efficient and resourceful manner with additional heuristics to accelerate the scheme. Our approaches exhibit competitive performance on a selected few global optimization benchmark problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:nRpfm8aw39MC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"We introduce deterministic perturbation (DP) schemes for the recently proposed random directions stochastic approximation, and propose new first-order and second-order algorithms. In the latter case, these are the first second-order algorithms to incorporate DPs. We show that the gradient and/or Hessian estimates in the resulting algorithms with DPs are asymptotically unbiased, so that the algorithms are provably convergent. Furthermore, we derive convergence rates to establish the superiority of the first-order and second-order algorithms, for the special case of a convex and quadratic optimization problem, respectively. Numerical experiments are used to validate the theoretical results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:GFxP56DSvIMC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"An appealing feature of cloud computing is elasticity, that allows shrinking or expanding the resources allocated to an application in order to adjust to workload variations. The resource provisioning algorithm must also adhere to the performance requirements specified in the Service Level Agreement between the cloud provider and the client who runs the application. While the use of Reinforcement learning algorithms such as Q-learning has been proposed already to address this problem, those suffer from slow convergence and scalability issues. In this paper, we explore methods for overcoming such challenges and ensuring effective resource utilization. Preliminary experiments on CloudSim platform demonstrate the superiority of some of these methods over static, threshold-based and other reinforcement learning based allocation schemes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:v1_lew4L6wgC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In a discounted reward Markov decision process (MDP), the objective is to find the optimal value function, i.e., the value function corresponding to an optimal policy. This problem reduces to solving a functional equation known as the Bellman equation and a fixed point iteration scheme known as the value iteration is utilized to obtain the solution. In literature, a successive over-relaxation (SOR)-based value iteration scheme is proposed to speed-up the computation of the optimal value function. The speed-up is achieved by constructing a modified Bellman equation that ensures faster convergence to the optimal value function. However, in many practical applications, the model information is not known and we resort to reinforcement learning (RL) algorithms to obtain optimal policy and value function. One such popular algorithm is Q -learning. In this letter, we propose SOR Q -learning. We first derive a modified fixed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:CaZNVDsoPx4C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the “Stoch”. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:Aul-kAQHnToC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"One of the popular measures of central tendency that provides better representation and interesting insights of the data compared to the other measures like mean and median is the metric mode. If the analytical form of the density function is known, mode is an argument of the maximum value of the density function and one can apply optimization techniques to find the mode. In many of the practical applications, the analytical form of the density is not known and only the samples from the distribution are available. Most of the techniques proposed in the literature for estimating the mode from the samples assume that all the samples are available beforehand. Moreover, some of the techniques employ computationally expensive operations like sorting. In this letter, we provide a computationally effective, online iterative algorithm that estimates the mode of a unimodal smooth density given only the samples generated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:NyGDZy8z5eUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In this paper, we analyze the behavior of stochastic approximation schemes with set-valued maps in the absence of a stability guarantee. We prove that after a large number of iterations, if the stochastic approximation process enters the domain of attraction of an attracting set, it gets locked into the attracting set with high probability. We demonstrate that the above-mentioned result is an effective instrument for analyzing stochastic approximation schemes in the absence of a stability guarantee, by using it to obtain an alternate criterion for convergence in the presence of a locally attracting set for the mean field and by using it to show that a feedback mechanism, which involves resetting the iterates at regular time intervals, stabilizes the scheme when the mean field possesses a globally attracting set, thereby guaranteeing convergence. The results in this paper build on the works of Borkar, Andrieu et al., and Chen et al …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:HtEfBTGE9r8C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In cooperative stochastic games multiple agents work towards learning joint optimal actions in an unknown environment to achieve a common goal. In many real-world applications, however, constraints are often imposed on the actions that can be jointly taken by the agents. In such scenarios the agents aim to learn joint actions to achieve a common goal (minimizing a specified cost function) while meeting the given constraints (specified via certain penalty functions). In this paper, we consider the relaxation of the constrained optimization problem by constructing the Lagrangian of the cost and penalty functions. We propose a nested actor-critic solution approach to solve this relaxed problem. In this approach, an actor-critic scheme is employed to improve the policy for a given Lagrange parameter update on a faster timescale as in the classical actor-critic architecture. A meta actor-critic scheme using this faster timescale policy updates is then employed to improve the Lagrange parameters on the slower timescale. Utilizing the proposed nested actor-critic schemes, we develop three Nested Actor-Critic (N-AC) algorithms. Through experiments on constrained cooperative tasks, we show the effectiveness of the proposed algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:lgwcVrK6X84C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:ALROH1vI_8AC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In this paper, we present a complete description of the hardware design and control architecture of our custom built quadruped robot, called the Stoch. Our goal is to realize a robust, modular, and a reliable quadrupedal platform, using which various locomotion behaviors are explored. This platform enables us to explore different research problems in legged locomotion, which use both traditional and learning based techniques. We discuss the merits and limitations of the platform in terms of exploitation of available behaviours, fast rapid prototyping, reproduction and repair. Towards the end, we will demonstrate trotting, bounding behaviors, and preliminary results in turning. In addition, we will also show various gait transitions i.e., trot-to-turn and trot-to-bound behaviors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:AHdEip9mkN0C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"In this paper, we propose two efficient and stable adaptive sampling algorithms for policy evaluation in reinforcement learning under linear function approximation. The computational complexities of the algorithms scale quadratically and linearly on the number of features respectively. The empirical analysis shows that the algorithms converge to the neighbourhood of the fixed point of the projected Bellman equation faster than the respective state-of-the-art algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:ubry08Y2EpUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,"Requesters in crowdsourcing marketplaces would like to efficiently allocate a fixed budget, among the set of tasks to be completed, which are of varying difficulty levels. The uncertainty in the arrival and departure of workers and the diversity in their skill levels add to the challenge, as minimizing the overall completion time is also an important concern. Current literature focuses on sequential allocation of tasks, i.e., task assignment to one worker at a time, or assumes the task difficulties to be known in advance. In this paper, we study the problem of efficient budget allocation under dynamic worker pool in crowdsourcing. Specifically, we consider binary labeling tasks for which the budget allocation problem can be cast as one of finding the optimal policy for a Markov decision process. We present a mathematical framework for modeling the problem and propose a class of algorithms for obtaining its solution …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:gKiMpY-AVTkC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:43bX7VzcjpAC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"The Stochastic optimization (SO) problem consists of optimizing an objective function in the presence of noise. Most of the solution techniques in SO estimate gradients from noise corrupted observations of the objective and adjust parameters of the objective along the direction of the estimated gradients to obtain locally optimal solutions. Two prominent algorithms in SO namely Random Direction Kiefer-Wolfowitz (RDKW) and Simultaneous Perturbation Stochastic Approximation (SPSA) obtain noisy gradient estimates by randomly perturbing all the parameters simultaneously. This forces the search direction to be random in these algorithms and presents one with additional noise on top of the noise incurred from the samples of the objective. For better convergence properties, the idea of using deterministic perturbations instead of randomized perturbations for gradient estimation has also been studied. Two specific …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:a9-T7VOCCH8C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"This paper considers two important problems - on the supply-side and demand-side respectively and studies both in a unified framework. On the supply side, we study the problem of energy sharing among microgrids with the goal of maximizing profit obtained from selling power while at the same time not deviating much from the customer demand. On the other hand, under shortage of power, this problem becomes one of deciding the amount of power to be bought with dynamically varying prices. On the demand side, we consider the problem of optimally scheduling the time-adjustable demand - i.e., of loads with flexible time windows in which they can be scheduled. While previous works have treated these two problems in isolation, we combine these problems together and provide a unified Markov decision process (MDP) framework for these problems. We then apply the Q-learning algorithm, a popular model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:HIFyuExEbWQC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"We are interested in understanding stability (almost sure boundedness) of stochastic approximation algorithms (SAs) driven by a “controlled Markov” process. Analyzing this class of algorithms is important, since many reinforcement learning (RL) algorithms can be cast as SAs driven by a “controlled Markov” process. In this paper, we present easily verifiable sufficient conditions for stability and convergence of SAs driven by a “controlled Markov” process. Many RL applications involve continuous state spaces. While our analysis readily ensures stability for such continuous state applications, traditional analyses do not. As compared to literature, our analysis presents a two-fold generalization: 1) the Markov process may evolve in a continuous state space and 2) the process need not be ergodic under any given stationary policy. Temporal difference (TD) learning is an important policy evaluation method in RL. The theory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:9Nmd_mFXekcC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"In this paper, we provide two new stable online algorithms for the problem of prediction in reinforcement learning, i.e., estimating the value function of a model-free Markov reward process using the linear function approximation architecture and with memory and computation costs scaling quadratically in the size of the feature set. The algorithms employ the multi-timescale stochastic approximation variant of the very popular cross entropy optimization method which is a model based search method to find the global optimum of a real-valued function. A proof of convergence of the algorithms using the ODE method is provided. We supplement our theoretical results with experimental comparisons. The algorithms achieve good performance fairly consistently on many RL benchmark problems with regards to computational efficiency, accuracy and stability.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:LhH-TYMQEocC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"Simulation-based, model-free solutions to Markov Decision Processes (MDPs) using the algorithm Least Squares Policy Iteration (LSPI) have been applied to multiple practical settings and in several variants. An optimal policy in an MDP is that policy, or a description of which action to take in a state of the MDP, which performs best according to a given metric such as infinite-horizon d iscounted c ost. A s imulation-based a lgorithm f or an M DP o btains the optimal policy for an MDP in a model-free manner, ie without requiring to know apriori any transition probabilities of the MDP under any policy. This work proposes LSPI-CAS, a version of LSPI for compact action-sets, thus avoiding the discretization of the available action set in a state and thereby improving control over the system. Regular LSPI works by repeatedly picking the current best action in a state x from a finite feasible set of actions Ax, requiring finding a minimum over| Ax| values. Our variant uses two kinds of parametrization, a feature vector φ (x) for the state called the actor, and ϕ (x, a) for the state-action pair which is the critic. LSPI-CAS employs a stochastic gradient algorithm called Simultaneous Perturbation Stochastic Approximation (SPSA) to update the actor in each iteration. Regular LSPI has a module named Least-Squares Q-Value (LSQ) which we employ as critic to evaluate perturbed policy iterates, and further update the policy iterate in direction of improving performance. Our algorithm is for infinite-horizon discounted-cost/reward MDPs, the case of finite-horizon compact-action set MDPs having been solved in an earlier work. Numerical results on three settings, a. control of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:otzGkya1bYkC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"Simulation-based, model-free solutions to Markov Decision Processes (MDPs) using the algorithm Least Squares Policy Iteration (LSPI) have been applied to multiple practical settings and in several variants. An optimal policy in an MDP is that policy, or a description of which action to take in a state of the MDP, which performs best according to a given metric such as infinite-horizon d iscounted c ost. A s imulation-based a lgorithm f or a n M DP o btains the optimal policy for an MDP in a model-free manner, i.e. without requiring to know apriori any transition probabilities of the MDP under any policy. This work proposes LSPI-CAS, a version of LSPI for compact action-sets, thus avoiding the discretization of the available action set in a state and thereby improving control over the system. Regular LSPI works by repeatedly picking the current best action in a state x from a finite feasible set of actions Ax, requiring finding a minimum over |Ax| values. Our variant uses two kinds of parametrization, a feature vector f(x) for the state called the actor, and ?(x, a) for the state-action pair which is the critic. LSPI-CAS employs a stochastic gradient algorithm called Simultaneous Perturbation Stochastic Approximation (SPSA) to update the actor in each iteration. Regular LSPI has a module named Least-Squares Q-Value (LSQ) which we employ as critic to evaluate perturbed policy iterates, and further update the policy iterate in direction of improving performance. Our algorithm is for infinite-horizon discounted-cost/reward MDPs, the case of finite-horizon compact-action set MDPs having been solved in an earlier work. Numerical results on three settings, a. control of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:LgRImbQfgY4C,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"In this paper, we consider a modified version of the control problem in a model free Markov decision process (MDP) setting with large state and action spaces. The control problem most commonly addressed in the contemporary literature is to find an optimal policy which maximizes the value function, i.e., the long run discounted reward of the MDP. The current settings also assume access to a generative model of the MDP with the hidden premise that observations of the system behaviour in the form of sample trajectories can be obtained with ease from the model. In this paper, we consider a modified version, where the cost function is the expectation of a non-convex function of the value function without access to the generative model. Rather, we assume that a sample trajectory generated using a priori chosen behaviour policy is made available. In this restricted setting, we solve the modified control …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:OcBU2YAGkTUC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"Recently, a dynamic adaptive queue management with random dropping (AQMRD) scheme has been developed to capture the time-dependent variation of average queue size by incorporating the rate of change of average queue size as a parameter. A major issue with AQMRD is the choice of parameters. In this paper, a novel online stochastic approximation based optimization scheme is proposed to dynamically tune the parameters of AQMRD and which is also applicable for other active queue management (AQM) algorithms. Our optimization scheme significantly improves the throughput, average queue size, and loss-rate in relation to other AQM schemes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:mlAyqtXpCwEC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"In this paper we study the asymptotic behaviour of stochastic approximation schemes with set-valued drift function and non-additive iterate-dependent Markov noise. We show that a linearly interpolated trajectory of such a recursion is an asymptotic pseudotrajectory for the flow of a limiting differential inclusion obtained by averaging the set-valued drift function of the recursion w.r.t. the stationary distributions of the Markov noise. The limit set theorem by Benaim is then used to characterize the limit sets of the recursion in terms of the dynamics of the limiting differential inclusion. We then state two variants of the Markov noise assumption under which the analysis of the recursion is similar to the one presented in this paper. Scenarios where our recursion naturally appears are presented as applications. These include controlled stochastic approximation, subgradient descent, approximate drift problem and analysis of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:M7yex6snE4oC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"We consider the problem of tracking an intruder using a network of wireless sensors. For tracking the intruder at each instant, the optimal number and the right configuration of sensors has to be powered. As powering the sensors consumes energy, there is a trade off between accurately tracking the position of the intruder at each instant and the energy consumption of sensors. This problem has been formulated in the framework of partially observable Markov decision process (POMDP). Even for the state-of-the-art algorithm in the literature, the curse of dimensionality renders the problem intractable. In this letter, we formulate the intrusion detection (ID) problem with a suitable state-action space in the framework of POMDP and develop a reinforcement learning algorithm utilizing the upper confidence tree search method to solve the ID problem. Through simulations, we show that our algorithm performs and scales …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:9c2xU6iGI7YC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"The objective of this paper is to design an efcient wireless energy harvesting (WEH) system to eliminate the problem to continuous charging of a battery operated electronics devices. Most of the devices are battery operated so charging of a battery time to time is serious issue. This WEH system receives the Radio Frequency (RF) and Microwave frequency signals present in the atmosphere and converting it into DC signal so that it can stores in Capacitor or charges a battery for utilize the power. For this RF energy harvesting purposes 21 antenna array structure of the coplanar monopole antenna is presented. This structure shows the gain of 10.2 dBi and 83% efciency. This structure is designed for resonating on multiple bands (Radio, GSM, ISM, and UWB). It is useful for this application because it covers almost all useful bands in the maximum capturing area. The antenna can be connected directly to an RF-DC …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:yMeIxYmEMEAC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"We present for the first time an asymptotic convergence analysis of two time-scale stochastic approximation driven by “controlled” Markov noise. In particular, the faster and slower recursions have nonadditive controlled Markov noise components in addition to martingale difference noise. We analyze the asymptotic behavior of our framework by relating it to limiting differential inclusions in both time scales that are defined in terms of the ergodic occupation measures associated with the controlled Markov processes. Finally, we present a solution to the off-policy convergence problem for temporal-difference learning with linear function approximation, using our results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:tH6gc1N1XXoC,https://www.csa.iisc.ac.in/~shalabh/
Shalabh Bhatnagar,"['Stochastic systems', 'control', 'simulation', 'optimization']",23,3401,2018,"The cross entropy (CE) method is a model based search method to solve optimization problems where the objective function has minimal structure. The Monte-Carlo version of the CE method employs the naive sample averaging technique which is inefficient, both computationally and space wise. We provide a novel stochastic approximation version of the CE method, where the sample averaging is replaced with incremental geometric averaging. This approach can save considerable computational and storage costs. Our algorithm is incremental in nature and possesses additional attractive features such as accuracy, stability, robustness and convergence to the global optimum for a particular class of objective functions. We evaluate the algorithm on a variety of global optimization benchmark problems and the results obtained corroborate our theoretical findings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cj3fJJsbjAoC&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=cj3fJJsbjAoC:OR75R8vi5nAC,https://www.csa.iisc.ac.in/~shalabh/
Vinod Ganapathy,['Security and Privacy'],17,971,2023,"This paper concerns the Hyperledger Fabric permissioned blockchain system. This system is in popular use in several enterprise settings, where each participating corporate entity may have sensitive business-related data whose confidentiality it wishes to protect. Fabric provides the channel abstraction that ensures that channel data (e.g., data stored in that channel's ledger, or data transmitted via the network to members of that channel) are only accessible to members of that channel. Unfortunately, as we show in this paper, the channel abstraction only offers data protection under the implicit assumption that all system components in the permissioned blockchain are trustworthy. This assumption may not hold in the presence of compromised container nodes, on which several blockchain-related components execute, or malicious business users inside any one of the participating corporate entities. Under such …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:N5tVd3kTz84C,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2022,"As e-commerce companies begin to consider using delivery drones for customer fulfillment, there are growing concerns around citizen privacy. Drones are equipped with cameras, and the video feed from these cameras is often required as part of routine navigation, be it for semi autonomous or fully-autonomous drones. Footage of ground-based citizens may be captured in this video feed, thereby leading to privacy concerns. This paper presents Privadome, a system that implements the vision of a virtual privacy dome centered around the citizen. Privadome is designed to be integrated with city-scale regulatory authorities that oversee delivery drone operations and realizes this vision through two components, PD-MPC and PD-ROS. PD-MPC allows citizens equipped with a mobile device to identify drones that have captured their footage. It uses secure two-party computation to achieve this goal without compromising the privacy of the citizen's location. PD-ROS allows the citizen to communicate with such drones and obtain an audit trail showing how the drone uses their footage and determine if privacy-preserving steps are taken to sanitize the footage. An experimental evaluation of Privadome using our prototype implementations of PD-MPC and PD-ROS shows that the system scales to near-term city-scale delivery drone deployments (hundreds of drones). We show that with PD-MPC the mobile data usage on the citizen's mobile device is comparable to that of routine activities on the device, such as streaming videos. We also show that the workflow of PD-ROS consumes a modest amount of additional CPU resources and power on our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:PELIpwtuRlgC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2021,"In FaaS workflows, a set of functions implement application logic by interacting and exchanging data among themselves. Contemporary FaaS platforms execute each function of a workflow in separate containers. When functions in a workflow interact, the resulting latency slows execution. Faastlane minimizes function interaction latency by striving to execute functions of a workflow as threads within a single process of a container instance, which eases data sharing via simple load/store instructions. For FaaS workflows that operate on sensitive data, Faastlane provides lightweight thread-level isolation domains using Intel Memory Protection Keys (MPK). While threads ease sharing, implementations of languages such as Python and Node. js (widely used in FaaS applications) disallow concurrent execution of threads. Faastlane dynamically identifies opportunities for parallelism in FaaS workflows and fork processes (instead of threads) or spawns new container instances to concurrently execute parallel functions of a workflow. We implemented Faastlane atop Apache OpenWhisk and show that it accelerates workflow instances by up to 15×, and reduces function interaction latency by up to 99.95% compared to OpenWhisk.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:Y5dfb0dijaUC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2021,"GPUs are now commonly available in most modern computing platforms. They are increasingly being adopted in cloud platforms and data centers due to their immense computing capability. In response to this growth in usage, manufacturers continuously try to improve GPU hardware by adding new features. However, this increase in usage and the addition of utility-improving features can create new, unexpected attack channels. In this paper, we show that two such features-unified virtual memory (UVM) and multi-process service (MPS)-primarily introduced to improve the programmability and efficiency of GPU kernels have an unexpected consequence-that of creating a novel covert-timing channel via the GPU's translation lookaside buffer (TLB) hierarchy. To enable this covert channel, we first perform experiments to understand the characteristics of TLBs present on a GPU. The use of UVM allows fine-grained …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:eMMeJKvmdy0C,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2021,"A method for preventing a side channel attack by executing an enclave on a remote computing device. The method comprises configuring the enclave based on configuration parameters defined by a computing device. A page created in first enclave cache memory in the remote computing device and adding virtual page address information and page security attributes corresponding to the page in a second enclave cache memory, and an encrypted log entry is created in a protected memory of the remote computing device. The enclave is initiated by comparing the log entry and a second hash key generated by the remote computing device. A new page of pre-defined size is dynamically added to the first enclave cache memory after initiation of the enclave. The enclave is executed based on a successful validation of a size of the page created in first enclave cache memory to be equal to the pre-defined page size.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:AXPGKjj_ei8C,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2020,"Intel’s SGX architecture offers clients of public cloud computing platforms the ability to create hardware-protected enclaves whose contents are protected from privileged system software. However, SGX relies on system software for enclave memory management. In a sequence of recent papers, researchers have demonstrated that this reliance allows a malicious OS/hypervisor to snoop on the page addresses being accessed from within an enclave via various channels. This page address stream can then be used to infer secrets if the enclave’s page access pattern depends upon the secret and this constitutes an important class of side-channels.
We propose SGXL, a hardware-software co-designed system that significantly increases the difficulty of any page address-based side-channels through the use of large pages. A large page maps address ranges at a much larger granularity than the default page size (at …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:HE397vMXCloC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2020,"The Intel Security Guard Extensions (SGX) architecture enables the abstraction of enclaved execution, using which an application can protect its code and data from powerful adversaries, including system software that executes with the highest processor privilege. While the Intel SGX architecture exports an ISA with low-level instructions that enable applications to create enclaves, the task of writing applications using this ISA has been left to the software community.
We consider the problem of porting legacy applications to SGX enclaves. In the approximately four years to date since the Intel SGX became commercially available, the community has developed three different models to port applications to enclaves---the library OS, the library wrapper, and the instruction wrapper models.
In this paper, we conduct an empirical evaluation of the merits and costs of each model. We report on our attempt to port a handful …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:olpn-zPbct0C,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2020,"We present Privaros, a framework to enforce privacy policies on drones. Privaros is designed for commercial delivery drones, such as the ones that will likely be used by Amazon Prime Air. Such drones visit various host airspaces, each of which may have different privacy requirements. Privaros uses mandatory access control to enforce the policies of these hosts on guest delivery drones. Privaros is tailored for ROS, a middleware popular in many drone platforms. This paper presents the design and implementation of Privaros's policy-enforcement mechanisms, describes how policies are specified, and shows that policy specification can be integrated with India's Digital Sky portal. Our evaluation shows that a drone running Privaros can robustly enforce various privacy policies specified by hosts, and that its core mechanisms only marginally increase communication latency and power consumption.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:bnK-pcrLprsC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2020,"Machine learning models are increasingly being deployed in practice. Machine Learning as a Service (MLaaS) providers expose such models to queries by third-party developers through application programming interfaces (APIs). Prior work has developed model extraction attacks, in which an attacker extracts an approximation of an MLaaS model by making black-box queries to it. We design ActiveThief–a model extraction framework for deep neural networks that makes use of active learning techniques and unannotated public datasets to perform model extraction. It does not expect strong domain knowledge or access to annotated data on the part of the attacker. We demonstrate that (1) it is possible to use ActiveThief to extract deep classifiers trained on a variety of datasets from image and text domains, while querying the model with as few as 10-30% of samples from public datasets,(2) the resulting model exhibits a higher transferability success rate of adversarial examples than prior work, and (3) the attack evades detection by the state-of-the-art model extraction detection method, PRADA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:V3AGJWp-ZtQC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2020,"On public cloud computing platforms, cloud providers own and administer the system software (eg, the BIOS, the OS, and/or the hypervisor) that manages the computing infrastructure. A malicious actor can leverage this system software to compromise the integrity and confidentiality of data and code of the clients of public computing infrastructures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:t6usbXjVLHcC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2019,"Commercial and end-user drones come equipped with a wide array of sensors. Unregulated use of such drones in public airspaces poses a serious threat to the privacy of citizens. We make the case for restricted spaces for drones, which are geographic areas for which a host can specify its privacy policies. Guest drones must prove to the host that they are in compliance with the host's policies before entering the restricted space. We then make the case for an information-flow control-based policy enforcement framework on drones, and sketch the design of a prototype framework atop the Robot Operating System (ROS).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:D_sINldO8mEC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2018,"We were fortunate to receive financial support for the conference from Sonata Software, IISc Bangalore, and Microsoft Research India. We are thankful to Omprakash Subbarao (Sonata Software), Y. Narahari (IISc Bangalore), and the team of Chiranjib Bhattacharyya (IISc Bangalore), Sriram Rajamani, Satish Sangameswaran, and Christina Gould-Sandhu (Microsoft Research India) for providing financial sponsorship. We also appreciate the support of Springer, in particular Alfred Hofmann and Anna Kramer, in publishing the proceedings as well as the monetary support for the conference. We would also like to acknowledge EasyChair for their conference management system, which was freely used to manage the process of paper submissions and reviews.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:BrmTIyaxlBUC,http://www.csa.iisc.ac.in/~vg
Vinod Ganapathy,['Security and Privacy'],17,971,2018,"Many security and forensic analyses rely on the ability to fetch memory snapshots from a target machine. To date, the security community has relied on virtualization, external hardware or trusted hardware to obtain such snapshots. These techniques either sacrifice snapshot consistency or degrade the performance of applications executing atop the target. We present SnipSnap, a new snapshot acquisition system based on on-package DRAM technologies that offers snapshot consistency without excessively hurting the performance of the target's applications. We realize SnipSnap and evaluate its benefits using careful hardware emulation and software simulation, and report our results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wrzZzwYAAAAJ&sortby=pubdate&citation_for_view=wrzZzwYAAAAJ:K3LRdlH-MEoC,http://www.csa.iisc.ac.in/~vg
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2023,"In Two-dimensional Bin Packing (2BP), we are given n rectangles as input and our goal is to find an axis-aligned nonoverlapping packing of these rectangles into the minimum number of unit square bins. 2BP admits no APTAS and the current best approximation ratio is 1.406 by Bansal and Khan (ACM-SIAM symposium on discrete algorithms (SODA), pp 13–25, 2014. https://doi.org/10.1137/1.9781611973402.2). A well-studied variant of 2BP is Guillotine Two-dimensional Bin Packing (G2BP), where rectangles must be packed in such a way that every rectangle in the packing can be obtained by applying a sequence of end-to-end axis-parallel cuts, also called guillotine cuts. Bansal et al. (Symposium on foundations of computer science (FOCS). IEEE, pp 657–666, 2005. https://doi.org/10.1109/SFCS.2005.10) gave an APTAS for G2BP. Let be the smallest constant such that for every set I of items, the number of bins in the optimal solution to G2BP for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:ZzlSgRqYykMC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2023,"Set cover and hitting set are fundamental problems in combinatorial optimization which are well-studied in the offline, online, and dynamic settings. We study the geometric versions of these problems and present new online and dynamic algorithms for them. In the online version of set cover (resp. hitting set), sets (resp.~ points) are give points (resp.~ sets) arrive online, one-by-one. In the dynamic versions, points (resp. sets) can arrive as well as depart. Our goal is to maintain a set cover (resp. hitting set), minimizing the size of the computed solution. For online set cover for (axis-parallel) squares of arbitrary sizes, we present a tight -competitive algorithm. In the same setting for hitting set, we provide a tight -competitive algorithm, assuming that all points have integral coordinates in . No online algorithm had been known for either of these settings, not even for unit squares (apart from the known online algorithms for arbitrary set systems). For both dynamic set cover and hitting set with -dimensional hyperrectangles, we obtain -approximation algorithms with worst-case update time. This partially answers an open question posed by Chan et al. [SODA'22]. Previously, no dynamic algorithms with polylogarithmic update time were known even in the setting of squares (for either of these problems). Our main technical contributions are an \emph{extended quad-tree }approach and a \emph{frequency reduction} technique that reduces geometric set cover instances to instances of general set cover with bounded frequency.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:zCSUwVk65WsC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2023,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:43bX7VzcjpAC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"Ranking algorithms find extensive usage in diverse areas such as web search, employment, college admission, voting, etc. The related rank aggregation problem deals with combining multiple rankings into a single aggregate ranking. However, algorithms for both these problems might be biased against some individuals or groups due to implicit prejudice or marginalization in the historical data. We study ranking and rank aggregation problems from a fairness or diversity perspective, where the candidates (to be ranked) may belong to different groups and each group should have a fair representation in the final ranking. We allow the designer to set the parameters that define fair representation. These parameters specify the allowed range of the number of candidates from a particular group in the top- positions of the ranking. Given any ranking, we provide a fast and exact algorithm for finding the closest fair ranking for the Kendall tau metric under {\em strong fairness}, ie, when the final ranking is fair for all values of . We also provide an exact algorithm for finding the closest fair ranking for the Ulam metric under strong fairness when there are only number of groups. Our algorithms are simple, fast, and might be extendable to other relevant metrics. We also give a novel meta-algorithm for the general rank aggregation problem under the fairness framework. Surprisingly, this meta-algorithm works for any generalized mean objective (including center and median problems) and any fairness criteria. As a byproduct, we obtain 3-approximation algorithms for both center and median problems, under both Kendall tau and Ulam metrics. Furthermore, using …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:jgBuDB5drN8C,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"We study the Improving Multi-Armed Bandit (IMAB) problem, where the reward obtained from an arm increases with the number of pulls it receives. This model provides an elegant abstraction for many real-world problems in domains such as education and employment, where decisions about the distribution of opportunities can affect the future capabilities of communities and the disparity between them. A decision-maker in such settings must consider the impact of her decisions on future rewards in addition to the standard objective of maximizing her cumulative reward at any time. In many of these applications, the time horizon is unknown to the decision-maker beforehand, which motivates the study of the IMAB problem in the technically more challenging horizon-unaware setting. We study the tension that arises between two seemingly conflicting objectives in the horizon-unaware setting: a) maximizing the cumulative reward at any time based on current rewards of the arms, and b) ensuring that arms with better long-term rewards get sufficient opportunities even if they initially have low rewards. We show that, surprisingly, the two objectives are aligned with each other in this setting. Our main contribution is an anytime algorithm for the IMAB problem that achieves the best possible cumulative reward while ensuring that the arms reach their true potential given sufficient time. Our algorithm mitigates the initial disparity due to lack of opportunity and continues pulling an arm till it stops improving. We prove the optimality of our algorithm by showing that a) any algorithm for the IMAB problem, no matter how utilitarian, must suffer policy regret and  …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:ubry08Y2EpUC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"We study the fair allocation of indivisible goods among agents with identical, additive valuations but individual budget constraints. Here, the indivisible goods--each with a specific size and value--need to be allocated such that the bundle assigned to each agent is of total size at most the agent's budget. Since envy-free allocations do not necessarily exist in the indivisible goods context, compelling relaxations--in particular, the notion of envy-freeness up to goods (EFk)--have received significant attention in recent years. In an EFk allocation, each agent prefers its own bundle over that of any other agent, up to the removal of goods, and the agents have similarly bounded envy against the charity (which corresponds to the set of all unallocated goods). Recently, Wu et al. (2021) showed that an allocation that satisfies the budget constraints and maximizes the Nash social welfare is -approximately EF1. However, the computation (or even existence) of exact EFk allocations remained an intriguing open problem. We make notable progress towards this by proposing a simple, greedy, polynomial-time algorithm that computes EF2 allocations under budget constraints. Our algorithmic result implies the universal existence of EF2 allocations in this fair division context. The analysis of the algorithm exploits intricate structural properties of envy-freeness. Interestingly, the same algorithm also provides EF1 guarantees for important special cases. Specifically, we settle the existence of EF1 allocations for instances in which: (i) the value of each good is proportional to its size, (ii) all goods have the same size, or (iii) all the goods have the same value. Our EF2 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:1lhNe0rCu4AC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"We study fair and efficient allocation of divisible goods, in an online manner, among n agents. The goods arrive online in a sequence of T time periods. The agents' values for a good are revealed only after its arrival, and the online algorithm needs to fractionally allocate the good, immediately and irrevocably, among the agents. Towards a unifying treatment of fairness and economic efficiency objectives, we develop an algorithmic framework for finding online allocations to maximize the generalized mean of the values received by the agents. In particular, working with the assumption that each agent's value for the grand bundle of goods is appropriately scaled, we address online maximization of p-mean welfare. Parameterized by an exponent term p in (-infty, 1], these means encapsulate a range of welfare functions, including social welfare (p= 1), egalitarian welfare (p to-infty), and Nash social welfare (p to 0). We present a simple algorithmic template that takes a threshold as input and, with judicious choices for this threshold, leads to both universal and tailored competitive guarantees. First, we show that one can compute online a single allocation that O (sqrt (n) log n)-approximates the optimal p-mean welfare for all p<= 1. The existence of such a universal allocation is interesting in and of itself. Moreover, this universal guarantee achieves essentially tight competitive ratios for specific values of p. Next, we obtain improved competitive ratios for different ranges of p by executing our algorithm with p-specific thresholds, eg, we provide O (log^ 3 n)-competitive ratio for all p in (-1/(log 2n), 1). We complement our positive results by establishing lower …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:tH6gc1N1XXoC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"We extend the notion of regret with a welfarist perspective. Focussing on the classic multi-armed bandit (MAB) framework, the current work quantifies the performance of bandit algorithms by applying a fundamental welfare function, namely the Nash social welfare (NSW) function. This corresponds to equating algorithm's performance to the geometric mean of its expected rewards and leads us to the study of Nash regret, defined as the difference between the -- a priori unknown -- optimal mean (among the arms) and the algorithm's performance. Since NSW is known to satisfy fairness axioms, our approach complements the utilitarian considerations of average (cumulative) regret, wherein the algorithm is evaluated via the arithmetic mean of its expected rewards. This work develops an algorithm that, given the horizon of play , achieves a Nash regret of , here denotes the number of arms in the MAB instance. Since, for any algorithm, the Nash regret is at least as much as its average regret (the AM-GM inequality), the known lower bound on average regret holds for Nash regret as well. Therefore, our Nash regret guarantee is essentially tight. In addition, we develop an anytime algorithm with a Nash regret guarantee of .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:otzGkya1bYkC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"We study rectangle stabbing problems in which we are given n axis-aligned rectangles in the plane that we want to stab, i.e., we want to select line segments such that for each given rectangle there is a line segment that intersects two opposite edges of it. In the horizontal rectangle stabbing problem (Stabbing), the goal is to find a set of horizontal line segments of minimum total length such that all rectangles are stabbed. In general rectangle stabbing problem, also known as horizontal-vertical stabbing problem (HV-Stabbing), the goal is to find a set of rectilinear (i.e., either vertical or horizontal) line segments of minimum total length such that all rectangles are stabbed. Both variants are NP-hard. Chan, van Dijk, Fleszar, Spoerhase, and Wolff initiated the study of these problems by providing O(1)-approximation algorithms. Recently, Eisenbrand, Gallato, Svensson, and Venzin have presented a QPTAS and a polynomial-time 8 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:vDZJ-YLwNdEC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"We study the online bin packing problem under two stochastic settings. In the bin packing problem, we are given n items with sizes in (0,1] and the goal is to pack them into the minimum number of unit-sized bins. First, we study bin packing under the i.i.d. model, where item sizes are sampled independently and identically from a distribution in (0,1]. Both the distribution and the total number of items are unknown. The items arrive one by one and their sizes are revealed upon their arrival and they must be packed immediately and irrevocably in bins of size 1. We provide a simple meta-algorithm that takes an offline -asymptotic approximation algorithm and provides a polynomial-time -competitive algorithm for online bin packing under the i.i.d. model, where >0 is a small constant. Using the AFPTAS for offline bin packing, we thus provide a linear time -competitive algorithm for online bin packing under i.i.d. model, thus settling the problem. We then study the random-order model, where an adversary specifies the items, but the order of arrival of items is drawn uniformly at random from the set of all permutations of the items. Kenyon's seminal result [SODA'96] showed that the Best-Fit algorithm has a competitive ratio of at most 3/2 in the random-order model, and conjectured the ratio to be around 1.15. However, it has been a long-standing open problem to break the barrier of 3/2 even for special cases. Recently, Albers et al. [Algorithmica'21] showed an improvement to 5/4 competitive ratio in the special case when all the item sizes are greater than 1/3. For this special case, we settle the analysis by showing that Best-Fit has a competitive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:uDGL6kOW6j0C,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"We study the d-dimensional hypercube knapsack problem where we are given a set of d-dimensional hypercubes with associated profits, and a knapsack which is a unit d-dimensional hypercube. The goal is to find an axis-aligned non-overlapping packing of a subset of hypercubes such that the profit of the packed hypercubes is maximized. For this problem, Harren (ICALP'06) gave an algorithm with an approximation ratio of (1+1/2^d+epsilon). For d=2, Jansen and Solis-Oba (IPCO'08) showed that the problem admits a polynomial-time approximation scheme (PTAS); Heydrich and Wiese (SODA'17) further improved the running time and gave an efficient polynomial-time approximation scheme (EPTAS). Both the results use structural properties of 2-D packing, which do not generalize to higher dimensions. For d>2, it remains open to obtain a PTAS, and in fact, there has been no improvement since Harren's result. We settle the problem by providing a PTAS. Our main technical contribution is a structural lemma which shows that any packing of hypercubes can be converted into another structured packing such that a high profitable subset of hypercubes is packed into a constant number of special hypercuboids, called V-Boxes and N-Boxes. As a side result, we give an almost optimal algorithm for a variant of the strip packing problem in higher dimensions. This might have applications for other multidimensional geometric packing problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:AHdEip9mkN0C,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"In the Strip Packing problem (SP), we are given a vertical half-strip and a set of axis-aligned rectangles of width at most . The goal is to find a non-overlapping packing of all rectangles into the strip such that the height of the packing is minimized. A well-studied and frequently used practical constraint is to allow only those packings that are guillotine separable, i.e., every rectangle in the packing can be obtained by recursively applying a sequence of edge-to-edge axis-parallel cuts (guillotine cuts) that do not intersect any item of the solution. In this paper, we study approximation algorithms for the Guillotine Strip Packing problem (GSP), i.e., the Strip Packing problem where we require additionally that the packing needs to be guillotine separable. This problem generalizes the classical Bin Packing problem and also makespan minimization on identical machines, and thus it is already strongly NP-hard. Moreover, due to a reduction from the Partition problem, it is NP-hard to obtain a polynomial-time -approximation algorithm for GSP for any (exactly as Strip Packing). We provide a matching polynomial time -approximation algorithm for GSP. Furthermore, we present a pseudo-polynomial time -approximation algorithm for GSP. This is surprising as it is NP-hard to obtain a -approximation algorithm for (general) Strip Packing in pseudo-polynomial time. Thus, our results essentially settle the approximability of GSP for both the polynomial and the pseudo-polynomial settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:F1b5ZUV5XREC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"We study ROUND-UFP and ROUND-SAP, two generalizations of the classical BIN PACKING problem that correspond to the unsplittable flow problem on a path (UFP) and the storage allocation problem (SAP), respectively. We are given a path with capacities on its edges and a set of tasks where for each task we are given a demand and a subpath. In ROUND-UFP, the goal is to find a packing of all tasks into a minimum number of copies (rounds) of the given path such that for each copy, the total demand of tasks on any edge does not exceed the capacity of the respective edge. In ROUND-SAP, the tasks are considered to be rectangles and the goal is to find a non-overlapping packing of these rectangles into a minimum number of rounds such that all rectangles lie completely below the capacity profile of the edges. We show that in contrast to BIN PACKING, both the problems do not admit an asymptotic polynomial-time approximation scheme (APTAS), even when all edge capacities are equal. However, for this setting, we obtain asymptotic -approximations for both problems. For the general case, we obtain an -approximation algorithm and an -approximation under -resource augmentation for both problems. For the intermediate setting of the no bottleneck assumption (i.e., the maximum task demand is at most the minimum edge capacity), we obtain absolute - and asymptotic -approximation algorithms for ROUND-UFP and ROUND-SAP, respectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:LgRImbQfgY4C,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2022,"We study the Maximum Independent Set of Rectangles (MISR) problem, where we are given a set of axis-parallel rectangles in the plane and the goal is to select a subset of non-overlapping rectangles of maximum cardinality. In a recent breakthrough, Mitchell [46] obtained the first constant-factor approximation algorithm for MISR. His algorithm achieves an approximation ratio of 10 and it is based on a dynamic program that intuitively recursively partitions the input plane into special polygons called corner-clipped rectangles (CCRs), without intersecting certain special horizontal line segments called fences.
In this paper, we present a 3-approximation algorithm for MISR which is also based on a recursive partitioning scheme. First, we use a partition into a class of axis-parallel polygons with constant complexity each that are more general than CCRs. This allows us to provide an arguably simpler analysis and at the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:fbc8zXXH2BUC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"We study the Stochastic Multi-armed Bandit problem under bounded arm-memory. In this setting, the arms arrive in a stream, and the number of arms that can be stored in the memory at any time, is bounded. The decision-maker can only pull arms that are present in the memory. We address the problem from the perspective of two standard objectives: 1) regret minimization, and 2) best-arm identification. For regret minimization, we settle an important open question by showing an almost tight guarantee. We show cumulative regret in expectation for single-pass algorithms for arm-memory size of , where is the number of arms. For best-arm identification, we provide an -PAC algorithm with arm memory size of and optimal sample complexity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:BJbdYPG6LGMC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"We study the two-dimensional geometric knapsack problem, in which we are given a set of n axis-aligned rectangular items, each one with an associated profit, and an axis-aligned square knapsack. The goal is to find a (non-overlapping) packing of a maximum profit subset of items inside the knapsack (without rotating items). The best-known polynomial-time approximation factor for this problem (even just in the cardinality case) is 2+ε [Jansen and Zhang, SODA 2004]. In this article we present a polynomial-time 17/9+ε < 1.89-approximation, which improves to 558/325+ε < 1.72 in the cardinality case.
Prior results pack items into a constant number of rectangular containers that are filled via greedy strategies. We deviate from this setting and show that there exists a large profit solution where items are packed into a constant number of containers plus one L-shaped region at the boundary of the knapsack containing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:artPoR2Yc-kC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"Best Fit is a well known online algorithm for the bin packing problem, where a collection of one-dimensional items has to be packed into a minimum number of unit-sized bins. In a seminal work, Kenyon [SODA 1996] introduced the (asymptotic) random order ratio as an alternative performance measure for online algorithms. Here, an adversary specifies the items, but the order of arrival is drawn uniformly at random. Kenyon’s result establishes lower and upper bounds of 1.08 and 1.5, respectively, for the random order ratio of Best Fit. Although this type of analysis model became increasingly popular in the field of online algorithms, no progress has been made for the Best Fit algorithm after the result of Kenyon. We study the random order ratio of Best Fit and tighten the long-standing gap by establishing an improved lower bound of 1.10. For the case where all items are larger than 1/3, we show that the random …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:bKqednn6t2AC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"We study the generalized multidimensional bin packing problem (GVBP) that generalizes both geometric packing and vector packing. Here, we are given rectangular items where the item has width , height , and nonnegative weights . Our goal is to get an axis-parallel non-overlapping packing of the items into square bins so that for all , the sum of the weight of items in each bin is at most 1. This is a natural problem arising in logistics, resource allocation, and scheduling. Despite being well studied in practice, surprisingly, approximation algorithms for this problem have rarely been explored. We first obtain two simple algorithms for GVBP having asymptotic approximation ratios and . We then extend the Round-and-Approx (R&A) framework [Bansal-Khan, SODA'14] to wider classes of algorithms, and show how it can be adapted to GVBP. Using more sophisticated techniques, we obtain better approximation algorithms for GVBP, and we get further improvement by combining them with the R&A framework. This gives us an asymptotic approximation ratio of for GVBP, which improves to for the special case of . We obtain further improvement when the items are allowed to be rotated. We also present algorithms for a generalization of GVBP where the items are high dimensional cuboids.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:5icHVeHT4IsC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"We study the Maximum Independent Set of Rectangles (MISR) problem, where we are given a set of axis-parallel rectangles in the plane and the goal is to select a subset of non-overlapping rectangles of maximum cardinality. In a recent breakthrough, Mitchell [2021] obtained the first constant-factor approximation algorithm for MISR. His algorithm achieves an approximation ratio of 10 and it is based on a dynamic program that intuitively recursively partitions the input plane into special polygons called corner-clipped rectangles (CCRs), without intersecting certain special horizontal line segments called fences. In this paper, we present a -approximation algorithm for MISR which is also based on a recursive partitioning scheme. First, we use a partition into a class of axis-parallel polygons with constant complexity each that are more general than CCRs. This allows us to provide an arguably simpler analysis and at the same time already improves the approximation ratio to 6. Then, using a more elaborate charging scheme and a recursive partitioning into general axis-parallel polygons with constant complexity, we improve our approximation ratio to . In particular, we construct a recursive partitioning based on more general fences which can be sequences of up to line segments each. This partitioning routine and our other new ideas may be useful for future work towards a PTAS for MISR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:ALROH1vI_8AC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"The knapsack problem is one of the classical problems in combinatorial optimization: Given a set of items, each specified by its size and profit, the goal is to find a maximum profit packing into a knapsack of bounded capacity. In the online setting, items are revealed one by one and the decision, if the current item is packed or discarded forever, must be done immediately and irrevocably upon arrival. We study the online variant in the random order model where the input sequence is a uniform random permutation of the item set. We develop a randomized (1/6.65)-competitive algorithm for this problem, outperforming the current best algorithm of competitive ratio 1/8.06 (Kesselheim et al. in SIAM J Comput 47(5):1939–1964, 2018). Our algorithm is based on two new insights: We introduce a novel algorithmic approach that employs two given algorithms, optimized for restricted item classes, sequentially on the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:LO7wyVUgiFcC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"We study Nonpreemptive Peak Demand Minimization (NPDM) problem, where we are given a set of jobs, specified by their processing times and energy requirements. The goal is to schedule all jobs within a fixed time period such that the peak load (the maximum total energy requirement at any time) is minimized. This problem has recently received significant attention due to its relevance in smart-grids. Theoretically, the problem is related to the classical strip packing problem (SP). In SP, a given set of axis-aligned rectangles must be packed into a fixed-width strip, such that the height of the strip is minimized. NPDM can be modeled as strip packing with slicing and stacking constraint: each rectangle may be cut vertically into multiple slices and the slices may be packed into the strip as individual pieces. The stacking constraint forbids solutions where two slices of the same rectangle are intersected by the same vertical line. Nonpreemption enforces the slices to be placed in contiguous horizontal locations (but may be placed at different vertical locations). We obtain a -approximation algorithm for the problem. We also provide an asymptotic efficient polynomial-time approximation scheme (AEPTAS) which generates a schedule for almost all jobs with energy consumption . The remaining jobs fit into a thin container of height . The previous best for NPDM was 2.7 approximation based on FFDH [Ranjan et al. 2015]. One of our key ideas is providing several new lower bounds on the optimal solution of a geometric packing, which could be useful in other related problems. These lower bounds help us to obtain approximative solutions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:u-coK7KVo8oC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"In the \textsc{2-Dimensional Knapsack} problem (2DK) we are given a square knapsack and a collection of rectangular items with integer sizes and profits. Our goal is to find the most profitable subset of items that can be packed non-overlappingly into the knapsack. The currently best known polynomial-time approximation factor for 2DK is and there is a -approximation algorithm if we are allowed to rotate items by 90 degrees~{[}G\'alvez et al., FOCS 2017{]}. In this paper, we give -approximation algorithms in polynomial time for both cases, assuming that all input data are {integers polynomially bounded in }. G\'alvez et al.'s algorithm for 2DK partitions the knapsack into a constant number of rectangular regions plus \emph{one} L-shaped region and packs items into those {in a structured way}. We generalize this approach by allowing up to a \emph{constant} number of {\emph{more general}} regions that can have the shape of an L, a U, a Z, a spiral, and more, and therefore obtain an improved approximation ratio. {In particular, we present an algorithm that computes the essentially optimal structured packing into these regions. }",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:8xutWZnSdmoC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"In two-dimensional geometric knapsack problem, we are given a set of n axis-aligned rectangular items and an axis-aligned square-shaped knapsack. Each item has integral width, integral height and an associated integral profit. The goal is to find a (non-overlapping axis-aligned) packing of a maximum profit subset of rectangles into the knapsack. A well-studied and frequently used constraint in practice is to allow only packings that are guillotine separable, i.e., every rectangle in the packing can be obtained by recursively applying a sequence of edge-to-edge axis-parallel cuts that do not intersect any item of the solution. In this paper we study approximation algorithms for the geometric knapsack problem under guillotine cut constraints. We present polynomial time (1 + {\epsilon})-approximation algorithms for the cases with and without allowing rotations by 90 degrees, assuming that all input numeric data are polynomially bounded in n. In comparison, the best-known approximation factor for this setting is 3 + {\epsilon} [Jansen-Zhang, SODA 2004], even in the cardinality case where all items have the same profit. Our main technical contribution is a structural lemma which shows that any guillotine packing can be converted into another structured guillotine packing with almost the same profit. In this packing, each item is completely contained in one of a constant number of boxes and L-shaped regions, inside which the items are placed by a simple greedy routine. In particular, we provide a clean sufficient condition when such a packing obeys the guillotine cut constraints which might be useful for other settings where these constraints are imposed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:nZcligLrVowC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"We study a generalization of the knapsack problem with geometric and vector constraints. The input is a set of rectangular items, each with an associated profit and nonnegative weights (-dimensional vector), and a square knapsack. The goal is to find a non-overlapping axis-parallel packing of a subset of items into the given knapsack such that the vector constraints are not violated, i.e., the sum of weights of all the packed items in any of the dimensions does not exceed one. We consider two variants of the problem: the items are not allowed to be rotated, items can be rotated by 90 degrees. We give a -approximation algorithm for this problem (both versions). In the process, we also study a variant of the maximum generalized assignment problem (Max-GAP), called Vector-Max-GAP, and design a PTAS for it.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:F9fV5C73w3QC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2021,"In the 2-Dimensional Knapsack problem (2DK) we are given a square knapsack and a collection of n rectangular items with integer sizes and profits. Our goal is to find the most profitable subset of items that can be packed non-overlappingly into the knapsack. The currently best known polynomial-time approximation factor for 2DK is 17/9 + Îµ < 1.89 and there is a (3/2 + Îµ)-approximation algorithm if we are allowed to rotate items by 90 degrees GÃ¡lvez et al., FOCS 2017. In this paper, we give (4/3 + Îµ)-approximation algorithms in polynomial time for both cases, assuming that all input data are integers polynomially bounded in n. GÃ¡lvez et al.'s algorithm for 2DK partitions the knapsack into a constant number of rectangular regions plus one L-shaped region and packs items into those in a structured way. We generalize this approach by allowing up to a constant number of more general regions that can have the shape of an L, a U, a Z, a spiral, and more, and therefore obtain an improved approximation ratio. In particular, we present an algorithm that computes the essentially optimal structured packing into these regions. Â© Waldo GÃ¡lvez, Fabrizio Grandoni, Arindam Khan, Diego RamÃrez-Romero, and Andreas Wiese; licensed under Creative Commons License CC-BY 4.0 37th International Symposium on Computational Geometry (SoCG 2021).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:gKiMpY-AVTkC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2020,"We present a approximation algorithm for the matching augmentation problem (MAP): given a multi-graph with edges of cost either zero or one such that the edges of cost zero form a matching, find a 2-edge connected spanning subgraph (2-ECSS) of minimum cost. We first present a reduction of any given MAP instance to a collection of well-structured MAP instances such that the approximation guarantee is preserved. Then we present a approximation algorithm for a well-structured MAP instance. The algorithm starts with a min-cost 2-edge cover and then applies ear-augmentation steps. We analyze the cost of the ear-augmentations using an approach similar to the one proposed by Vempala and Vetta for the (unweighted) min-size 2-ECSS problem (in: Jansen and Khuller (eds.) Approximation Algorithms for Combinatorial Optimization, Third International Workshop, APPROX 2000, Proceedings, LNCS 1913 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:bnK-pcrLprsC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2020,"We study the knapsack problem with group fairness constraints. The input of the problem consists of a knapsack of bounded capacity and a set of items, each item belongs to a particular category and has and associated weight and value. The goal of this problem is to select a subset of items such that all categories are fairly represented, the total weight of the selected items does not exceed the capacity of the knapsack,and the total value is maximized. We study the fairness parameters such as the bounds on the total value of items from each category, the total weight of items from each category, and the total number of items from each category. We give approximation algorithms for these problems. These fairness notions could also be extended to the min-knapsack problem. The fair knapsack problems encompass various important problems, such as participatory budgeting, fair budget allocation, advertising.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:DJbcl8HfkQkC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2020,"Guillotine separability of rectangles has recently gained prominence in combinatorial optimization, computational geometry, and combinatorics. Consider a given large stock unit (say glass or wood) and we need to cut out a set of required rectangles from it. Many cutting technologies allow only end-to-end cuts called guillotine cuts. Guillotine cuts occur in stages. Each stage consists of either only vertical cuts or only horizontal cuts. In k-stage packing, the number of cuts to obtain each rectangle from the initial packing is at most k (plus an additional trimming step to separate the rectangle itself from a waste area). Pach and Tardos [Pach and Tardos, 2000] studied the following question: Given a set of n axis-parallel rectangles (in the weighted case, each rectangle has an associated weight), cut out as many rectangles (resp. weight) as possible using a sequence of guillotine cuts. They provide a guillotine cutting sequence that recovers 1/(2 log n)-fraction of rectangles (resp. weights). Abed et al.[Fidaa Abed et al., 2015] claimed that a guillotine cutting sequence can recover a constant fraction for axis-parallel squares. They also conjectured that for any set of rectangles, there exists a sequence of axis-parallel guillotine cuts that recovers a constant fraction of rectangles. This conjecture, if true, would yield a combinatorial O (1)-approximation for Maximum Independent Set of Rectangles (MISR), a long-standing open problem. We show the conjecture is not true, if we only allow o (log log n) stages (resp. o (log n/log log n)-stages for the weighted case). On the positive side, we show a simple O (n log n)-time 2-stage cut sequence that recovers 1/(1+ log n …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:HtS1dXgVpQUC,https://www.csa.iisc.ac.in/~arindamkhan/
Arindam Khan,"['Approximation Algorithms', 'Online Algorithms', 'Computational Geometry', 'Online Learning.']",13,643,2020,"In the Strip Packing problem, we are given a vertical half-strip [0, W]×[0,+∞) and a collection of open rectangles of width at most W. Our goal is to find an axis-aligned (non-overlapping) packing of such rectangles into the strip such that the maximum height OPT spanned by the packing is as small as possible. Strip Packing generalizes classical well-studied problems such as Makespan Minimization on identical machines (when rectangle widths are identical) and Bin Packing (when rectangle heights are identical). It has applications in manufacturing, scheduling and energy consumption in smart grids among others. It is NP-hard to approximate this problem within a factor (3/2-ε) for any constant ε> 0 by a simple reduction from the Partition problem. The current best approximation factor for Strip Packing is (5/3+ ε) by Harren et al.[Computational Geometry'14], and it is achieved with a fairly complex algorithm and analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yRsbV0AAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=yRsbV0AAAAAJ:cWzG1nlazyYC,https://www.csa.iisc.ac.in/~arindamkhan/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2023,"Unmanned aerial vehicles (UAVs), specifically quadrotors, have revolutionized various industries with their maneuverability and versatility, but their safe operation in dynamic environments heavily relies on effective collision avoidance techniques. This paper introduces a novel technique for safely navigating a quadrotor along a desired route while avoiding kinematic obstacles. The proposed approach employs control barrier functions and utilizes collision cones to ensure that the quadrotor's velocity and the obstacle's velocity always point away from each other. In particular, we propose a new constraint formulation that ensures that the relative velocity between the quadrotor and the obstacle always avoids a cone of vectors that may lead to a collision. By showing that the proposed constraint is a valid control barrier function (CBFs) for quadrotors, we are able to leverage on its real-time implementation via Quadratic Programs (QPs), called the CBF-QPs. We validate the effectiveness of the proposed CBF-QPs by demonstrating collision avoidance with moving obstacles under multiple scenarios. This is shown in the pybullet simulator.Furthermore we compare the proposed approach with CBF-QPs shown in literature, especially the well-known higher order CBF-QPs (HO-CBF-QPs), where in we show that it is more conservative compared to the proposed approach. This comparison also shown in simulation in detail.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:yB1At4FlUx8C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2023,"Cooperative control involves developing control strategies for individual robots that guarantee synchronized behavior of the states of all the robots in a team in some prescribed sense. In this work, we present a novel controller that achieves formation control for a group of differential-drive robots. First, we propose a nonlinear feedback control law that guarantees stable tracking of a reference trajectory for a single robot without exceeding the velocity limits of the robot. Using Lyapunov analysis, we obtain the necessary conditions on the control parameters and establish ultimate boundedness on error terms. Next, we formulate the formation control problem as a trajectory tracking problem for the multi-robot system and solve it using the proposed controller. Additionally, we provide constraints on formation size for given reference trajectory which ensures smooth turning of multi-robot formation without exceeding …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:9Nmd_mFXekcC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2022,"Evolution Strategy (ES) is a powerful black-box optimization technique based on the idea of natural evolution. In each of its iterations, a key step entails ranking candidate solutions based on some fitness score. For an ES method in Reinforcement Learning (RL), this ranking step requires evaluating multiple policies. This is presently done via on-policy approaches: each policy's score is estimated by interacting several times with the environment using that policy. This leads to a lot of wasteful interactions since, once the ranking is done, only the data associated with the top-ranked policies is used for subsequent learning. To improve sample efficiency, we propose a novel off-policy alternative for ranking, based on a local approximation for the fitness function. We demonstrate our idea in the context of a state-of-the-art ES method called the Augmented Random Search (ARS). Simulations in MuJoCo tasks show that, compared to the original ARS, our off-policy variant has similar running times for reaching reward thresholds but needs only around 70% as much data. It also outperforms the recent Trust Region ES. We believe our ideas should be extendable to other ES methods as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:t7zJ5fGR-2UC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2022,"In this paper, we show how to realize robust safety-critical control laws for robotic manipulators with a large number of inequality constraints (>100). In particular, we use control barrier functions (CBFs) formulated via the kinetic energy terms to represent constraints like joint position and velocity limits, both in configuration and task space. By using the kinetic energy terms, we can realize model-free constraints in a quadratic program (QP), which can be solved in real-time, thereby demonstrating fast computation time despite the presence of large constraints. We will consider two types of CBFs, the reciprocal and the zeroing type, and integrate with Control Lyapunov Function (CLF) based constraints to yield a multi-objective QP. Further, we will provide feasibility and continuity guarantees, thereby yielding a continuous, robust and a safe control law for a broad class of robotic systems. Towards the end, we will …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:z_wVstp3MssC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2022,"Recent works in Reinforcement Learning (RL) combine model-free (Mf)-RL algorithms with model-based (Mb)-RL approaches to get the best from both: asymptotic performance of Mf-RL and high sample-efficiency of Mb-RL. Inspired by these works, we propose a hierarchical framework that integrates online learning for the Mb-trajectory optimization with off-policy methods for the Mf-RL. In particular, two loops are proposed, where the Dynamic Mirror Descent based Model Predictive Control (DMD-MPC) is used as the inner loop Mb-RL to obtain an optimal sequence of actions. These actions are in turn used to significantly accelerate the outer loop Mf-RL. We show that our formulation is generic for a broad class of MPC based policies and objectives, and includes some of the well-known Mb-Mf approaches. We finally introduce a new algorithm: Mirror-Descent Model Predictive RL (M-DeMoRL), which uses Cross …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:-_dYPAW6P2MC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2022,"In this work, we demonstrate robust walking in the bipedal robot Digit on uneven terrains by just learning a single linear policy. In particular, we propose a new control pipeline, wherein the high-level trajectory modulator shapes the end-foot ellipsoidal trajectories, and the low-level gait controller regulates the torso and ankle orientation. The foot-trajectory modulator uses a linear policy and the regulator uses a linear PD control law. As opposed to neural network based policies, the proposed linear policy has only 13 learnable parameters, thereby not only guaranteeing sample efficient learning but also enabling simplicity and interpretability of the policy. This is achieved with no loss of performance on challenging terrains like slopes, stairs and outdoor landscapes. We first demonstrate robust walking in the custom simulation environment, MuJoCo, and then directly transfer to hardware with no modification of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:evX43VCCuoAC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2021,"Model Predictive Control (MPC) is a popular approach used for motion planning in dynamical systems. Given a finite horizon cost, we seek an optimal control law subject to safety constraints. However, in the presence of obstacles, existing MPC formulations are often slow and may lead to infeasibility. We propose a real-time implementable MPC formulation using control barrier functions (CBF) and successive convexification. We represent the non-convex obstacle avoidance constraints using CBFs that ensure that a feasible solution always exists. We then reformulate the non-convex optimal control problem using successive convexification to enable the use of computationally-efficient conic solvers. Our approach enables controller synthesis at real-time, which is difficult with existing approaches that rely on nonlinear solvers. We demonstrate the method in simulation, where we navigate a UAV to a target while …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:fEOibwPWpKIC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2021,"The use of internet-connected devices, especially small multi-rotor Unmanned Aerial Vehicles (UAVs), in scientific data gathering and applications is quite widespread. But due to limited intervention capability, the UAVs alone fail to automate agricultural tasks completely. Thereby, we propose a centralized framework capable of handling a heterogeneous mixture of UAVs and UGVs to cater to the needs of automating agriculture efficiently. The framework’s core is a novel heuristic decision module that creates new tasks by visually analyzing the farm and solves a vehicle routing problem to allocate it to agents optimally. It is also equipped with supporting modules to monitor their operation and, in case of failures, help them recover autonomously based on the task and agent assessment. The framework is used in three significant agricultural applications, namely yield prediction and drought stress detection in a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:uJ-U7cs_P_0C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2021,"In this paper, with a view toward fast deployment of locomotion gaits in low-cost hardware, we use a linear policy for realizing end-foot trajectories in the quadruped robot, Stoch 2. In particular, the parameters of the end-foot trajectories are shaped via a linear feedback policy that takes the torso orientation and the terrain slope as inputs. The corresponding desired joint angles are obtained via an inverse kinematics solver and tracked via a PID control law. Augmented Random Search, a model-free and a gradient-free learning algorithm is used to train this linear policy. Simulation results show that the resulting walking is robust to terrain slope variations and external pushes. This methodology is not only computationally light-weight but also uses minimal sensing and actuation capabilities in the robot, thereby justifying the approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:NJ774b8OgUMC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2021,"In this paper, with a view toward deployment of light-weight control frameworks for bipedal walking robots, we realize end-foot trajectories that are shaped by a single linear feedback policy. We learn this policy via a model-free and a gradient free learning algorithm, Augmented Random Search (ARS), in the two robot platforms Rabbit and Digit. Our contributions are two-fold: a) By using torso and support plane orientation as inputs, we achieve robust walking on slopes of upto 20° in simulation. b) We demonstrate additional behaviors like walking backwards, stepping-in-place, and recovery from external pushes of upto 120 N. The end-result is a robust and a fast feedback control law for bipedal walking on terrains with varying slopes. Towards the end, we also provide preliminary results of hardware transfer to Digit.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:2KloaMYe4IUC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2021,"Inverse Kinematics of bipedal humanoid robots remains a challenging problem in the domain of robotics and computation, due to high order non-linearity and computation involved in Inverse Kinematics solutions. Also, there are many constraints involved with the various joint parameters which makes their analysis even more complex. Through this paper, we attempt to solve the Inverse Kinematics problem of a bipedal humanoid robot, Cassie, using Radial Basis Function (RBF) Networks. Our method can also be applied to other higher degrees of freedom serial manipulators. Our simulation analyses the results based on size of datasets, data distribution and network parameters. We have considered datasets of size 300k and 1 million, single and multiple hidden layers, equal and random data distribution, different number of neurons in layers and different training functions. We achieve our target of limiting the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:35r97b3x0nAC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2021,"This letter addresses the problem of formally guaranteeing the stability of interconnected systems with local controllers with a view toward stabilizing quadrupeds viewed as coupled bipeds. In particular, we present a novel framework that views general rigid-body systems as a collection of lower-dimensional systems that are coupled via reaction forces. Stabilizing the corresponding coupled control system can thus be addressed by stabilizing each subsystem coupled through the passive dynamics. The main results of the letter are stability conditions that guarantee convergence for each control subsystem by formulating coupled control Lyapunov functions (CCLFs) using the notion of input-to-state stability (ISS). This theoretical result is illustrated via a simple cart-pole example, where exponential stability is obtained. Next, building on previous results where an 18-DOF quadrupedal robot is decomposed into two …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:tzM49s52ZIMC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2021,"Over the decades, kinematic controllers have proven to be practically useful for applications like set-point and trajectory tracking in robotic systems. To this end, we formulate a novel safety-critical paradigm by extending the methodology of control barrier functions (CBFs) to kinematic equations governing robotic systems. We demonstrate a purely kinematic implementation of a velocity-based CBF, and subsequently introduce a formulation that guarantees safety at the level of dynamics. This is achieved through a new form of CBFs that incorporate kinetic energy with the classical forms, thereby minimizing model dependence and conservativeness. The approach is then extended to underactuated systems. This method and the purely kinematic implementation are demonstrated in simulation on two robotic platforms: a 6-DOF robotic manipulator, and a cart-pole system.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:W5xh706n7nkC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2020,"Imitation learning is a data-driven approach to acquiring skills that relies on expert demonstrations to learn a policy that maps observations to actions. When performing demonstrations, experts are not always consistent and might accomplish the same task in slightly different ways. In this paper, we demonstrate inherent stochasticity in demonstrations collected for tasks including line following with a remote-controlled car and manipulation tasks including reaching, pushing, and picking and placing an object. We model stochasticity in the data distribution using autoregressive action generation, generative adversarial nets, and variational prediction and compare the performance of these approaches. We find that accounting for stochasticity in the expert data leads to substantial improvement in the success rate of task completion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:tKAzc9rXhukC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2020,"Robots that must operate in novel environments and collaborate with humans must be capable of acquiring new knowledge from human experts during operation. We propose teaching a robot novel objects it has not encountered before by pointing a hand at the new object of interest. An end-to-end neural network is used to attend to the novel object of interest indicated by the pointing hand and then to localize the object in new scenes. In order to attend to the novel object indicated by the pointing hand, we propose a spatial attention modulation mechanism that learns to focus on the highlighted object while ignoring the other objects in the scene. We show that a robot arm can manipulate novel objects that are highlighted by pointing a hand at them. We also evaluate the performance of the proposed architecture on a synthetic dataset constructed using emojis and on a real-world dataset of common objects.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:kzcrU_BdoSEC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2020,"With the research into development of quadruped robots picking up pace, learning based techniques are being explored for developing locomotion controllers for such robots. A key problem is to generate leg trajectories for continuously varying target linear and angular velocities, in a stable manner. In this paper, we propose a two pronged approach to address this problem. First, multiple simpler policies are trained to generate trajectories for a discrete set of target velocities and turning radius. These policies are then augmented using a higher level neural network for handling the transition between the learned trajectories. Specifically, we develop a neural network based filter that takes in target velocity, radius and transforms them into new commands that enable smooth transitions to the new trajectory. This transformation is achieved by learning from expert demonstrations. An application of this is the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:uLbwQdceFCQC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2020,"Control barrier function (CBF) based Quadratic Programs (QPs) were introduced in early 2014 as a means to guarantee safety in affine control systems in conjunction with stability/tracking. However, due to the presence of modelbased terms, they fail to provide guarantees under model perturbations. Therefore, in this paper, we propose a new class of CBFs for robotic systems that augment kinetic energy with the traditional forms. We show that with torque limits permitting, and with the kinematic models accurately known, forward invariance of safe sets generated by kinematic constraints (position and velocity) can be guaranteed. The proposed methodology is motivated by the control Lyapunov function (CLF) based QPs that use the kinetic energy function. By the property of CBF-QPs, we show that the pointwise min-norm control laws obtained are feasible and Lipschitz continuous, and can be derived analytically via the KKT conditions. In order to include stability with safety, we also augment CLF based constraints in the CBF-QPs to realize a unified control law that allows tracking with safety irrespective of the inertial parameters of the robot. We will demonstrate the robustness of this class of CBF-QPs in two robotic platforms: a 1-DOF and a 2-DOF manipulator, by scaling the masses by up to 100, and then simulating the resulting dynamics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:_Ybze24A_UAC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2020,"In this letter, we study stability properties of Proportional-Derivative (PD) controlled underactuated robotic systems for trajectory tracking applications. Stability of PD control laws for fully actuated systems is an established result, and we extend it for the class of underactuated robotic systems. We will first show some well known examples where PD tracking control laws do not yield tracking; some of which can even lead to instability. We will then show that for a subclass of robotic systems, PD tracking control laws, indeed, yield desirable tracking guarantees. We will show that for a specified time interval, and for sufficiently large enough PD gains (input saturations permitting), local boundedness of the tracking error can be guaranteed. In addition, for a class of systems with the kinetic symmetry property, stronger conditions like convergence to desirable bounds can be guaranteed. This class is not restrictive and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:JQOojiI6XY0C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2020,"Industrial robot manipulators are not able to match the precision and speed with which humans are able to execute contact rich tasks even to this day. Therefore, as a means to overcome this gap, we demonstrate generative methods for imitating a peg-in-hole insertion task in a 6-DOF robot manipulator. In particular, generative adversarial imitation learning (GAIL) is used to successfully achieve this task with a peg-hole clearance on the Yaskawa GP8 industrial robot. Experimental results show that the policy successfully learns within 20 episodes from a handful of human expert demonstrations on the robot (i.e., < 10 tele-operated robot demonstrations). The insertion time improves from > 20 seconds (which also includes failed insertions) to < 15 seconds, thereby validating the effectiveness of this approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:UHK10RUVsp4C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2020,"We establish stability results for PD tracking control laws in bipedal walking robots. Stability of PD control laws for continuous robotic systems is an established result, and we extend this for hybrid robotic systems, an alternating sequence of continuous and discrete events. Bipedal robots have the leg-swing as the continuous event, and the foot-strike as the discrete event. In addition, bipeds largely have underactuations due to the interactions between feet and ground. For each continuous event, we establish that the convergence rate of the tracking error can be regulated via appropriate tuning of the PD gains; and for each discrete event, we establish that this convergence rate sufficiently overcomes the nonlinear impacts by assumptions on the hybrid zero dynamics. The main contributions are (1) Extension of the stability results of PD control laws for underactuated robotic systems, and (2) Exponential ultimate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&sortby=pubdate&citation_for_view=is0x16gAAAAJ:hkOj_22Ku90C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2020,"Existing architectures for imitation learning using image-to-action policy networks perform poorly when presented with an input image containing multiple instances of the object of interest, especially when the number of expert demonstrations available for training are limited. We show that end-to-end policy networks can be trained in a sample efficient manner by (a) appending the feature map output of the vision layers with an embedding that can indicate instance preference or take advantage of an implicit preference present in the expert demonstrations, and (b) employing an autoregressive action generator network for the control layers. The proposed architecture for localization has improved accuracy and sample efficiency and can generalize to the presence of more instances of objects than seen during training. When used for end-to-end imitation learning to perform reach, push, and pick-and-place tasks on a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:Fu2w8maKXqMC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2020,"This paper presents the meta-algorithmic approach used to realize multi-contact walking on the humanoid robot, DURUS. This systematic methodology begins by decomposing human walking into a sequence of distinct events (e.g. heel-strike, toe-strike, and toe push-off). These events are converted into an alternating sequence of domains and guards, resulting in a hybrid system model of the locomotion. Through the use of a direct collocation based optimization framework, a walking gait is generated for the hybrid system model emulating human-like multi-contact walking behaviors – additional constraints are iteratively added and shaped from experimental evaluation to reflect the machine’s practical limitations. The synthesized gait is analyzed directly on hardware wherein feedback regulators are introduced which stabilize the walking gait, e.g., modulating foot placement. The end result is an energyoptimized …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:eMMeJKvmdy0C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2019,"In this paper, with a view toward fast deployment of learned locomotion gaits in low-cost hardware, we generate a library of walking trajectories, namely, forward trot, backward trot, side-step, and turn in our custom-built quadruped robot, Stoch 2, using reinforcement learning. There are existing approaches that determine optimal policies for each time step, whereas we determine an optimal policy, in the form of end-foot trajectories, for each half walking step i.e., swing phase and stance phase. The way-points for the foot trajectories are obtained from a linear policy, i.e., a linear function of the states of the robot, and cubic splines are used to interpolate between these points. Augmented Random Search, a model-free and gradient-free learning algorithm is used to learn the policy in simulation. This learned policy is then deployed on hardware, yielding a trajectory in every half walking step. Different locomotion patterns are learned in simulation by enforcing a preconfigured phase shift between the trajectories of different legs. The transition from one gait to another is achieved by using a low-pass filter for the phase, and the sim-to-real transfer is improved by a linear transformation of the states obtained through regression.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:PR6Y55bgFSsC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2019,"In this paper, inspired by Proportional-Derivative (PD) control laws, we present a class of Control Lyapunov Function (CLF) based Quadratic Programs (QPs) for robotic systems. Proportional-Derivative (PD) control laws are independent of the robot model, however, they fail to incorporate physical constraints, such as torque saturation. On the other hand, most optimization based control design approaches ensure satisfaction of the physical constraints, but they are sensitive to errors in the robot model. The PD based Quadratic Programs (PD-QPs), presented in this paper, are a first step towards bridging this gap between the PD and the optimization based controllers to bring the best of both together. We derive two versions of PD-QPs: model-based and model-free. Furthermore, for tracking time-varying trajectories, we establish asymptotic stability for the model-based PD-QP, and ultimate boundedness for the model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:1yQoGdGgb4wC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2019,"In this paper, we explore a specific form of deep reinforcement learning (D-RL) technique for quadrupedal walking—trajectory based policy search via deep policy networks. Existing approaches determine optimal policies for each time step, whereas we propose to determine an optimal policy for each walking step. We justify our approach based on the fact that animals including humans use “low” dimensional trajectories at the joint level to realize walking. We will construct these trajectories by using Bézier polynomials, with the coefficients being determined by a parameterized policy. In order to maintain smoothness of the trajectories during step transitions, hybrid invariance conditions are also applied. The action is computed at the beginning of every step, and a linear PD control law is applied to track at the individual joints. After each step, reward is computed, which is then used to update the new policy …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:dQ2og3OwTAUC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2019,"In this work, we provide a simulation framework to perform systematic studies on the effects of spinal joint compliance and actuation on bounding performance of a 16-DOF quadruped spined robot Stoch 2. Fast quadrupedal locomotion with active spine is an extremely hard problem, and involves a complex coordination between the various degrees of freedom. Therefore, past attempts at addressing this problem have not seen much success. Deep-Reinforcement Learning seems to be a promising approach, after its recent success in a variety of robot platforms, and the goal of this paper is to use this approach to realize the aforementioned behaviors. With this learning framework, the robot reached a bounding speed of 2.1m /s with a maximum Froude number of 2. Simulation results also show that use of active spine, indeed, increased the stride length, improved the cost of transport, and also reduced the natural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:ZuybSZzF8UAC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2019,"Humans and animals are believed to use a very minimal set of trajectories to perform a wide variety of tasks including walking. Our main objective in this paper is two fold 1) Obtain an effective tool to realize these basic motion patterns for quadrupedal walking, called the kinematic motion primitives (kMPs), via trajectories learned from deep reinforcement learning (D-RL) and 2) Realize a set of behaviors, namely trot, walk, gallop and bound from these kinematic motion primitives in our custom four legged robot, called the “Stoch”. D-RL is a data driven approach, which has been shown to be very effective for realizing all kinds of robust locomotion behaviors, both in simulation and in experiment. On the other hand, kMPs are known to capture the underlying structure of walking and yield a set of derived behaviors. We first generate walking gaits from D-RL, which uses policy gradient based approaches. We then …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:VL0QpB8kHFEC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2019,"In this paper, we present a complete description of the hardware design and control architecture of our custom built quadruped robot, called the Stoch. Our goal is to realize a robust, modular, and a reliable quadrupedal platform, using which various locomotion behaviors are explored. This platform enables us to explore different research problems in legged locomotion, which use both traditional and learning based techniques. We discuss the merits and limitations of the platform in terms of exploitation of available behaviours, fast rapid prototyping, reproduction and repair. Towards the end, we will demonstrate trotting, bounding behaviors, and preliminary results in turning. In addition, we will also show various gait transitions i.e., trot-to-turn and trot-to-bound behaviors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:N5tVd3kTz84C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2018,"To realize robotic systems in real-world settings, e.g., in restaurants, it will be necessary to achieve dynamic manipulation of nontrivial objects. In this context, this letter discusses methodologies used to realize trajectories in a robotic arm platform, specifically, applied to flipping burgers as an example of nonprehensile object manipulation. Flipping of burgers involves a series of tasks-going to the burger location, scooping, picking up, and flipping. Since the goal is to obtain these trajectories in a reasonably fast manner, we employ direct collocation based multisegmented trajectory optimization. We will first describe the problem setup, and then describe the constraints, decision variables employed, and then, to conclude, we will demonstrate these behaviors in a 6-DOF robot experimentally.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:LjlpjdlvIbIC,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2018,"This letter presents a new notion of input-to-state safe control barrier functions (ISSf-CBFs), which ensure safety of nonlinear dynamical systems under input disturbances. Similar to how safety conditions are specified in terms of forward invariance of a set, input-to-state safety conditions are specified in terms of forward invariance of a slightly larger set. In this context, invariance of the larger set implies that the states stay either inside or very close to the smaller safe set; and this closeness is bounded by the magnitude of the disturbances. The main contribution of the letter is the methodology used for obtaining a valid ISSf-CBF, given a control barrier function. The associated universal control law will also be provided. Towards the end, we will study unified quadratic programs that combine control Lyapunov functions and ISSf-CBFs in order to obtain a single control law that ensures both safety and stability in systems …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:SdhP9T11ey4C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2018,"This paper analyzes the input to state stability properties of controllers which stabilize hybrid periodic orbits. Systems that are input to state stable tend to be robust to modeling and sensing uncertainties. The main contribution of this paper is in the construction of control Lyapunov functions that do not just stabilize, but also input to state stabilize a given hybrid system. Bipedal robotic walking, which can be naturally modeled as a hybrid system, is analyzed under this class of controllers. Specifically, we will select a class of controllers via rapidly exponentially stabilizing control Lyapunov functions that stabilize bipedal robotic walking; typically modeled as hybrid periodic orbits. We will show with simulation results that given the control Lyapunov functions and the associated set of stabilizing controllers, there exist input to state stabilizing control Lyapunov functions and the associated set of controllers that input to state …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:ye4kPcJQO24C,http://shishirny.com/
Shishir N. Y. Kolathaya,"['Robotics', 'Nonlinear control', 'Machine learning', 'Hybrid systems']",13,660,2018,"Bipedal robots are a prime example of systems which exhibit highly nonlinear dynamics, underactuation, and undergo complex dissipative impacts. This paper discusses methods used to overcome a wide variety of uncertainties, with the end result being stable bipedal walking. The principal contribution of this paper is to establish sufficiency conditions for yielding input to state stable (ISS) hybrid periodic orbits, i.e., stable walking gaits under model-based and phase-based uncertainties. In particular, it will be shown formally that exponential input to state stabilization (e-ISS) of the continuous dynamics, and hybrid invariance conditions are enough to realize stable walking in the 23-DOF bipedal robot DURUS. This main result will be supported through successful and sustained walking of the bipedal robot DURUS in a laboratory environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=is0x16gAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=is0x16gAAAAJ:9vf0nzSNQJEC,http://shishirny.com/
Shirish Shevade,['Machine Learning'],15,2319,2022,"During software development, developers need answers to queries about semantic aspects of code. Even though extractive question-answering using neural approaches has been studied widely in natural languages, the problem of answering semantic queries over code using neural networks has not yet been explored. This is mainly because there is no existing dataset with extractive question and answer pairs over code involving complex concepts and long chains of reasoning. We bridge this gap by building a new, curated dataset called CodeQueries, and proposing a neural question-answering methodology over code. We build upon state-of-the-art pre-trained models of code to predict answer and supporting-fact spans. Given a query and code, only some of the code may be relevant to answer the query. We first experiment under an ideal setting where only the relevant code is given to the model and show that our models do well. We then experiment under three pragmatic considerations: (1) scaling to large-size code, (2) learning from a limited number of examples and (3) robustness to minor syntax errors in code. Our results show that while a neural model can be resilient to minor syntax errors in code, increasing size of code, presence of code that is not relevant to the query, and reduced number of training examples limit the model performance. We are releasing our data and models to facilitate future work on the proposed problem of answering semantic queries over code.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:NhqRSupF_l8C,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2022,"Bash is a Unix command language used for interacting with the Operating System. Recent works on natural language to Bash translation have made significant advances, but none of the previous methods utilize the problem’s inherent structure. We identify this structure andpropose a Segmented Invocation Transformer (SIT) that utilizes the information from the constituency parse tree of the natural language text. Our method is motivated by the alignment between segments in the natural language text and Bash command components. Incorporating the structure in the modelling improves the performance of the model. Since such systems must be universally accessible, we benchmark the inference times on a CPU rather than a GPU. We observe a 1.8 x improvement in the inference time and a 5x reduction in model parameters. Attribution analysis using Integrated Gradients reveals that the proposed method can capture the problem structure.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:b0M2c_1WBrUC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2022,"Community detection is a well-studied problem in machine learning and recommendation systems literature. In this paper, we study a novel variant of this problem where we assign predefined fashion communities to users in an Ecommerce ecosystem for downstream tasks. We model our problem as a link prediction task in knowledge graphs with multiple types of edges and multiple types of nodes depicting the intricate Ecommerce ecosystems. We employ Relational Graph Convolutional Networks (R-GCN) on top of this knowledge graph to determine whether a user should be assigned to a given community or not. We conduct empirical experiments on two real-world datasets from a leading fashion retailer. Our experiments demonstrate that the proposed graph-based approach performs significantly better than the non-graph-based baseline, indicating that higher order methods like GCN can improve the task of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:EUQCXRtRnyEC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2022,"Stochastic multi-armed bandit (MAB) mechanisms are widely used in sponsored search auctions, crowdsourcing, online procurement, etc. Existing stochastic MAB mechanisms with a deterministic payment rule, proposed in the literature, necessarily suffer a regret of Ω(T2/3), where T is the number of time steps. This happens because the existing mechanisms consider the worst case scenario where the means of the agents’ stochastic rewards are separated by a very small amount that depends on T. We make, and, exploit the crucial observation that in most scenarios, the separation between the agents’ rewards is rarely a function of T. Moreover, in the case that the rewards of the arms are arbitrarily close, the regret contributed by such sub-optimal arms is minimal. Our idea is to allow the center to indicate the resolution, Δ, with which the agents must be distinguished. This immediately leads us to introduce the notion of Δ …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:a0OBvERweLwC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2021,"The personalized list continuation (PLC) task is to curate the next items to user-generated lists (ordered sequence of items) in a personalized way. The main challenge in this task is understanding the ternary relationships among the interacting entities (users, items, and lists) that the existing works do not consider. Further, they do not take into account the multi-hop relationships among entities of the same type. In addition, capturing the sequential information amongst the items already present in the list also plays a vital role in determining the next relevant items that get curated.In this work, we propose HyperTeNet - a self-attention hypergraph and Transformer-based neural network architecture for the personalized list continuation task to address the challenges mentioned above. We use graph convolutions to learn the multi-hop relationship among the entities of the same type and leverage a self-attention-based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:_xSYboBqXhAC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2021,"Natural language processing for program synthesis has been widely researched. In this work, we focus on generating Bash commands from natural language invocations with explanations. We propose a novel transformer based solution by utilizing Bash Abstract Syntax Trees and manual pages. Our method incorporates tree structure information in the transformer architecture and provides explanations for its predictions via alignment matrices between user invocation and manual page text. Our method performs on par with the state of the art performance on Natural Language Context to Command task and performs better than fine-tuned T5 and Seq2Seq models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:bFI3QPDXJZMC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2021,"The personalized list continuation (PLC) task is to curate the next items to user-generated lists (ordered sequence of items) in a personalized way. The main challenge in this task is understanding the ternary relationships among the interacting entities (users, items, and lists) that the existing works do not consider. Further, they do not take into account the multi-hop relationships among entities of the same type. In addition, capturing the sequential information amongst the items already present in the list also plays a vital role in determining the next relevant items that get curated. In this work, we propose HyperTeNet -- a self-attention hypergraph and Transformer-based neural network architecture for the personalized list continuation task to address the challenges mentioned above. We use graph convolutions to learn the multi-hop relationship among the entities of the same type and leverage a self-attention-based hypergraph neural network to learn the ternary relationships among the interacting entities via hyperlink prediction in a 3-uniform hypergraph. Further, the entity embeddings are shared with a Transformer-based architecture and are learned through an alternating optimization procedure. As a result, this network also learns the sequential information needed to curate the next items to be added to the list. Experimental results demonstrate that HyperTeNet significantly outperforms the other state-of-the-art models on real-world datasets. Our implementation and datasets are available at https://github.com/mvijaikumar/HyperTeNet.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:f2IySw72cVMC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2021,"Machine-Learning-as-a-Service providers expose machine learning (ML) models through application programming interfaces (APIs) to developers. Recent work has shown that attackers can exploit these APIs to extract good approximations of such ML models, by querying them with samples of their choosing. We propose VarDetect, a stateful monitor that tracks the distribution of queries made by users of such a service, to detect model extraction attacks. Harnessing the latent distributions learned by a modified variational autoencoder, VarDetect robustly separates three types of attacker samples from benign samples, and successfully raises an alarm for each. Further, with VarDetect deployed as an automated defense mechanism, the extracted substitute models are found to exhibit poor performance and transferability, as intended. Finally, we demonstrate that even adaptive attackers with prior knowledge of the deployment of VarDetect, are detected by it.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:D03iK_w7-QYC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2021,"Explainable Recommendations provide the reasons behind why an item is recommended to a user, which often leads to increased user satisfaction and persuasiveness. An intuitive way to explain recommendations is by generating a synthetic personalized natural language review for a user-item pair. Although there exist some approaches in the literature that explain recommendations by generating reviews, the quality of the reviews is questionable. Besides, these methods usually take considerable time to train the underlying language model responsible for generating the text. In this work, we propose ReXPlug, an end-to-end framework with a plug and play way of explaining recommendations. ReXPlug predicts accurate ratings as well as exploits Plug and Play Language Model to generate high-quality reviews. We train a simple sentiment classifier for controlling a pre-trained language model for the generation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:pyW8ca7W8N0C,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2021,"Bundle recommendation – recommending a group of products in place of individual products to customers is gaining attention day by day. It presents two interesting challenges – (1) how to personalize and recommend existing bundles to users, and (2) how to generate personalized novel bundles targeting specific users. Recently, few models have been proposed for modeling the bundle recommendation problem. However, they have the following shortcomings. First, they do not consider the higher-order relationships amongst the entities (users, items and bundles). Second, they do not model the relative influence of items present in the bundles, which is crucial in defining such bundles. In this work, we propose GRAM-SMOT – a graph attention-based framework to address the above challenges. Further, we define a loss function based on the metric-learning approach to learn the embeddings of entities …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:cFHS6HbyZ2cC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2021,"Cross-Domain Collaborative Filtering (CDCF) provides a way to alleviate data sparsity and cold-start problems present in recommendation systems by exploiting the knowledge from related domains. Existing CDCF models are either based on matrix factorization or deep neural networks. Independent use of either of the techniques in isolation may result in suboptimal performance for the prediction task. Also, most of the existing models face challenges particularly in handling diversity between domains and learning complex non-linear relationships that exist amongst entities (users/items) within and across domains. In this work, we propose an end-to-end neural network model – NeuCDCF, to address these challenges in a cross-domain setting. More importantly, NeuCDCF is based on a wide and deep framework and learns the representations jointly using both matrix factorization and deep neural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:pqnbT2bcN3wC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2020,"Research on the task of Reading Comprehension style Question Answering (RCQA) has gained momentum in recent years due to the emergence of human annotated datasets and associated leaderboards, for example CoQA, HotpotQA, SQuAD, TriviaQA, etc. While state-of-the-art has advanced considerably, there is still ample opportunity to advance it further on some important variants of the RCQA task. In this paper, we propose a novel deep neural architecture, called TAP (Translucent Answer Prediction), to identify answers and evidence (in the form of supporting facts) in an RCQA task requiring multi-hop reasoning. TAP comprises two loosely coupled networks–Local and Global Interaction eXtractor (LoGIX) and Answer Predictor (AP). LoGIX predicts supporting facts, whereas AP consumes these predicted supporting facts to predict the answer span. The novel design of LoGIX is inspired by two key design desiderata–local context and global interaction–that we identified by analyzing examples of multi-hop RCQA task. The loose coupling between LoGIX and the AP reveals the set of sentences used by the AP in predicting an answer. Therefore, answer predictions of TAP can be interpreted in a translucent manner. TAP offers state-of-the-art performance on the HotpotQA (Yang et al. 2018) dataset–an apt dataset for multi-hop RCQA task–as it occupies Rank-1 on its leaderboard (https://hotpotqa. github. io/) at the time of submission.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:4OULZ7Gr8RgC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2020,"Machine learning models are increasingly being deployed in practice. Machine Learning as a Service (MLaaS) providers expose such models to queries by third-party developers through application programming interfaces (APIs). Prior work has developed model extraction attacks, in which an attacker extracts an approximation of an MLaaS model by making black-box queries to it. We design ActiveThief–a model extraction framework for deep neural networks that makes use of active learning techniques and unannotated public datasets to perform model extraction. It does not expect strong domain knowledge or access to annotated data on the part of the attacker. We demonstrate that (1) it is possible to use ActiveThief to extract deep classifiers trained on a variety of datasets from image and text domains, while querying the model with as few as 10-30% of samples from public datasets,(2) the resulting model exhibits a higher transferability success rate of adversarial examples than prior work, and (3) the attack evades detection by the state-of-the-art model extraction detection method, PRADA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:3s1wT3WcHBgC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2020,"Exploiting heterogeneous information networks (HIN) to top-N recommendation has been shown to alleviate the data sparsity problem present in recommendation systems. This requires careful effort in extracting relevant knowledge from HIN. However, existing models in this setting have the following shortcomings. Mainly, they are not end-to-end, which puts the burden on the system to first learn similarity or commuting matrix offline using some manually selected meta-paths before we train for the top-N recommendation objective. Further, they do not attentively extract user-specific information from HIN, which is essential for personalization. To address these challenges, we propose an end-to-end neural network model – GAMMA (Graph and Multi-view Memory Attention mechanism). We aim to replace the offline meta-path based similarity or commuting matrix computation with a graph attention …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:u_35RYKgDlwC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2020,"Social recommendation systems typically combine extra information like a social network with the user-item interaction network in order to alleviate data sparsity issues. This also helps in making more accurate and personalized recommendations. However, most of the existing systems work under the assumption that all socially connected users have equal influence on each other in a social network, which is not true in practice. Further, estimating the quantum of influence that exists among entities in a user-item interaction network is essential when only implicit ratings are available. This has been ignored even in many recent state-of-the-art models such as SAMN (Social Attentional Memory Network) and DeepSoR (Deep neural network model on Social Relations). Many a time, capturing a complex relationship between the entities (users/items) is essential to boost the performance of a recommendation system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:HoB7MX3m0LUC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2019,"Cross-Domain Collaborative Filtering (CDCF) provides a way to alleviate data sparsity and cold-start problems present in recommendation systems by exploiting the knowledge from related domains. Existing CDCF models are either based on matrix factorization or deep neural networks. Either of the techniques in isolation may result in suboptimal performance for the prediction task. Also, most of the existing models face challenges particularly in handling diversity between domains and learning complex non-linear relationships that exist amongst entities (users/items) within and across domains. In this work, we propose an end-to-end neural network model -- NeuCDCF, to address these challenges in a cross-domain setting. More importantly, NeuCDCF follows a wide and deep framework and it learns the representations combinedly from both matrix factorization and deep neural networks. We perform experiments on four real-world datasets and demonstrate that our model performs better than state-of-the-art CDCF models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:1sJd4Hv_s6UC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2019,"Novice programmers often struggle with the formal syntax of programming languages. In the traditional classroom setting, they can make progress with the help of real time feedback from their instructors which is often impossible to get in the massive open online course (MOOC) setting. Syntactic error repair techniques have huge potential to assist them at scale. Towards this, we design a novel programming language correction framework amenable to reinforcement learning. The framework allows an agent to mimic human actions for text navigation and editing. We demonstrate that the agent can be trained through self-exploration directly from the raw input, that is, program text itself, without either supervision or any prior knowledge of the formal syntax of the programming language. We evaluate our technique on a publicly available dataset containing 6975 erroneous C programs with typographic errors, written by students during an introductory programming course. Our technique fixes 1699 (24. 4%) programs completely and 1310 (18. 8%) program partially, outperforming DeepFix, a state-of-the-art syntactic error repair technique, which uses a fully supervised neural machine translation approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:70eg2SAEIzsC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2019,"Providing feedback is an integral part of teaching. Most open online courses on programming make use of automated grading systems to support programming assignments and give real-time feedback. These systems usually rely on test results to quantify the programs' functional correctness. They return failing tests to the students as feedback. However, students may find it difficult to debug their programs if they receive no hints about where the bug is and how to fix it. In this work, we present the first deep learning based technique that can localize bugs in a faulty program w.r.t. a failing test, without even running the program. At the heart of our technique is a novel tree convolutional neural network which is trained to predict whether a program passes or fails a given test. To localize the bugs, we analyze the trained network using a state-of-the-art neural prediction attribution technique and see which lines of the programs make it predict the test outcomes. Our experiments show that the proposed technique is generally more accurate than two state-of-the-art program-spectrum based and one syntactic difference based bug-localization baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:g5m5HwL7SMYC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2019,"Machine learning models trained on confidential datasets are increasingly being deployed for profit. Machine Learning as a Service (MLaaS) has made such models easily accessible to end-users. Prior work has developed model extraction attacks, in which an adversary extracts an approximation of MLaaS models by making black-box queries to it. However, none of these works is able to satisfy all the three essential criteria for practical model extraction: (1) the ability to work on deep learning models, (2) the non-requirement of domain knowledge and (3) the ability to work with a limited query budget. We design a model extraction framework that makes use of active learning and large public datasets to satisfy them. We demonstrate that it is possible to use this framework to steal deep classifiers trained on a variety of datasets from image and text domains. By querying a model via black-box access for its top prediction, our framework improves performance on an average over a uniform noise baseline by 4.70x for image tasks and 2.11x for text tasks respectively, while using only 30% (30,000 samples) of the public dataset at its disposal.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:M05iB0D1s5AC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2019,"Cross-Domain Collaborative Filtering (CDCF) mitigates data sparsity and cold-start issues present in conventional recommendation systems by exploiting and transferring knowledge from related domains. Leveraging user-generated tags (e.g. ancient-literature, military-history) for bridging the related domains is becoming a popular way for enhancing personalized recommendations. However, existing tag based models bridge the domains based on common tags between domains and their co-occurrence frequencies. This results in capturing the syntax similarities between the tags and ignoring the semantic similarities between them. In this work, to address these, we propose TagEmbedSVD, a tag-based CDCF model to cross-domain setting. TagEmbedSVD makes use of the pre-trained word embeddings (word2vec) for tags to enhance personalized recommendations in the cross-domain setting. Empirical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:ZHo1McVdvXMC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2019,"Providing feedback is an integral part of teaching. Most open online courses on programming make use of automated grading systems to support programming assignments and give real-time feedback. These systems usually rely on test results to quantify the programs' functional correctness. They return failing tests to the students as feedback. However, students may find it difficult to debug their programs if they receive no hints about where the bug is and how to fix it. In this work, we present NeuralBugLocator, a deep learning based technique, that can localize the bugs in a faulty program with respect to a failing test, without even running the program. At the heart of our technique is a novel tree convolutional neural network which is trained to predict whether a program passes or fails a given test. To localize the bugs, we analyze the trained network using a state-of-the-art neural prediction attribution technique and see which lines of the programs make it predict the test outcomes. Our experiments show that NeuralBugLocator is generally more accurate than two state-of-the-art program-spectrum based and one syntactic difference based bug-localization baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:SeFeTyx0c_EC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2018,"Novice programmers often struggle with the formal syntax of programming languages. To assist them, we design a novel programming language correction framework amenable to reinforcement learning. The framework allows an agent to mimic human actions for text navigation and editing. We demonstrate that the agent can be trained through self-exploration directly from the raw input, that is, program text itself, without any knowledge of the formal syntax of the programming language. We leverage expert demonstrations for one tenth of the training data to accelerate training. The proposed technique is evaluated on 6975 erroneous C programs with typographic errors, written by students during an introductory programming course. Our technique fixes 14% more programs and 29% more compiler error messages relative to those fixed by a state-of-the-art tool, DeepFix, which uses a fully supervised neural machine translation approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:J_g5lzvAfSwC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2018,"Multi-label classification has attracted much interest due to its wide applicability. Modeling label interactions and investigating their impact on classifier quality are crucial aspects of multi-label classification. In this paper, we propose a multi-structure SVM (called MSSVM) which allows the user to hypothesize multiple label interaction structures and helps to identify their importance in improving generalization performance. We design an efficient optimization algorithm to solve the proposed MSSVM. Extensive empirical evaluation provides fresh and interesting insights into the following questions: (a) How do label interactions affect multiple performance metrics typically used in multi-label classification? (b) Do higher order label interactions significantly impact a given performance metric for a particular dataset? (c) Can we make useful suggestions on the label interaction structure? and (d) Is it always …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:lSLTfruPkqcC,http://drona.csa.iisc.ac.in/~shirish/
Shirish Shevade,['Machine Learning'],15,2319,2018,"In this work, we propose an automated method to identify semantic bugs in student programs, called ATAS, which builds upon the recent advances in both symbolic execution and active learning. Symbolic execution is a program analysis technique which can generate test cases through symbolic constraint solving. Our method makes use of a reference implementation of the task as its sole input. We compare our method with a symbolic execution-based baseline on 6 programming tasks retrieved from CodeForces comprising a total of 23 K student submissions. We show an average improvement of over 2.5x over the baseline in terms of runtime (thus making it more suitable for online evaluation), without a significant degradation in evaluation accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HOIpJSwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HOIpJSwAAAAJ:RYcK_YlVTxYC,http://drona.csa.iisc.ac.in/~shirish/
Chaya Ganesh,['Cryptography'],13,458,2023,"In the setting of subversion, an adversary tampers with the machines of the honest parties thus leaking the honest parties’ secrets through the protocol transcript. The work of Mironov and Stephens-Davidowitz (EUROCRYPT’15) introduced the idea of reverse firewalls (RF) to protect against tampering of honest parties’ machines. All known constructions in the RF framework rely on the malleability of the underlying operations in order for the RF to rerandomize/sanitize the transcript. RFs are thus limited to protocols that offer some structure, and hence based on public-key operations. In this work, we initiate the study of efficient Multiparty Computation (MPC) protocols in the presence of tampering. In this regard,
We construct the first Oblivious Transfer (OT) extension protocol in the RF setting. We obtain maliciously-secure OTs using public key operations and inexpensive symmetric key operations, where is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:KlAtU1dfN6UC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2023,"Zero-knowledge Succinct Non-interactive ARguments of Knowledge (zkSNARKs) are becoming an increasingly fundamental tool in many real-world applications where the proof compactness is of the utmost importance, including blockchains. A proof of security for SNARKs in the Universal Composability (UC) framework (Canetti, FOCS’01) would rule out devastating malleability attacks. To retain security of SNARKs in the UC model, one must show their simulation-extractability such that the knowledge extractor is both black-box and straight-line, which would imply that proofs generated by honest provers are non-malleable. However, existing simulation-extractability results on SNARKs either lack some of these properties, or alternatively have to sacrifice witness succinctness to prove UC security.
In this paper, we provide a compiler lifting any simulation-extractable NIZKAoK into a UC-secure one in the global …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:Zph67rFs4hoC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2023,"Bulletproofs (Bünz et al. IEEE S&P 2018) are a celebrated ZK proof system that allows for short and efficient proofs, and have been implemented and deployed in several real-world systems. In practice, they are most often implemented in their non-interactive version obtained using the Fiat-Shamir transform. A security proof for this setting is necessary for ruling out malleability attacks. These attacks can lead to very severe vulnerabilities, as they allow an adversary to forge proofs re-using or modifying parts of the proofs provided by the honest parties. An earlier version of this work (Ganesh et al. EUROCRYPT 2022) provided evidence for non-malleability of Fiat-Shamir Bulletproofs. This was done by proving simulation-extractability, which implies non-malleability, in the algebraic group model. In this work, we generalize the former result and prove simulation extractability in the programmable random oracle model, removing the need for the algebraic group model. Along the way, we establish a generic chain of reductions for Fiat-Shamir-transformed multi-round public-coin proofs to be simulation-extractable in the (programmable) random oracle model, which may be of independent interest.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:YOwf2qJgpHMC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"Sealed bid auctions are used to allocate a resource among a set of interested parties. Traditionally, auctions need the presence of a trusted auctioneer to whom the bidders provide their private bid values. Existence of such a trusted party is not an assumption easily realized in practice. Generic secure computation protocols can be used to remove a trusted party. However, generic techniques result in inefficient protocols, and typically do not provide fairness -- that is, a corrupt party can learn the output and abort the protocol thereby preventing other parties from learning the output.
At CRYPTO 2009, Miltersen, Nielsen and Triandopoulos~\citeC:MilNieTri09, introduced the problem of building auctions that are secure against rational bidders. Such parties are modeled as self-interested agents who care more about maximizing their utility than about learning information about bids of other agents. To realize this, they …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:kNdYIx-mwKoC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"In current blockchain systems, full nodes that perform all of the available functionalities need to store the entire blockchain. In addition to the blockchain, full nodes also store a blockchain-summary, called the state, which is used to efficiently verify transactions. With the size of popular blockchains and their states growing rapidly, full nodes require massive storage resources in order to keep up with the scaling. This leads to a tug-of-war between scaling and decentralization since fewer entities can afford expensive resources. We present hybrid nodes for proof-of-work (PoW) cryptocurrencies which can validate transactions, validate blocks, validate states, mine, select the main chain, bootstrap new hybrid nodes, and verify payment proofs. With the use of a protocol called trimming, hybrid nodes only retain polylogarithmic number of blocks in the chain length in order to represent the proof-of-work of the blockchain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:3fE2CSJIrl8C,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"We give an efficient construction of a computational non-interactive witness indistinguishable (NIWI) proof in the plain model, and investigate notions of extraction for NIZKs for algebraic languages. Our starting point is the recent work of Couteau and Hartmann (CRYPTO 2020) who developed a new framework (CH framework) for constructing non-interactive zero-knowledge proofs and arguments under falsifiable assumptions for a large class of languages called algebraic languages. In this paper, we construct an efficient NIWI proof in the plain model for algebraic languages based on the CH framework. In the plain model, our NIWI construction is more efficient for algebraic languages than state-of-the-art Groth-Ostrovsky-Sahai (GOS) NIWI (JACM 2012). Next, we explore knowledge soundness of NIZK systems in the CH framework. We define a notion of strong f-extractability, and show that the CH proof system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:MXK_kJrjxJIC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"We show that three popular universal zero-knowledge SNARKs (Plonk, Sonic, and Marlin) are updatable SRS simulation extractable NIZKs and signatures of knowledge (SoK) out-of-the-box avoiding any compilation overhead.
Towards this we generalize results for the Fiat–Shamir (FS) transformation, which turns interactive protocols into signature schemes, non-interactive proof systems, or SoK in the random oracle model (ROM). The security of the transformation relies on rewinding to extract the secret key or the witness, even in the presence of signing queries for signatures and simulation queries for proof systems and SoK, respectively. We build on this line of work and analyze multi-round FS for arguments with a structured reference string (SRS). The combination of ROM and SRS, while redundant in theory, is the model of choice for the most efficient practical systems to date. We also consider the case where …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:8k81kl-MbHgC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"Bulletproofs (Bünz et al. IEEE S&P 2018) are a celebrated ZK proof system that allows for short and efficient proofs, and have been implemented and deployed in several real-world systems.
In practice, they are most often implemented in their non-interactive version obtained using the Fiat-Shamir transform, despite the lack of a formal proof of security for this setting.
Prior to this work, there was no evidence that malleability attacks were not possible against Fiat-Shamir Bulletproofs. Malleability attacks can lead to very severe vulnerabilities, as they allow an adversary to forge proofs re-using or modifying parts of the proofs provided by the honest parties.
In this paper, we show for the first time that Bulletproofs (or any other similar multi-round proof system satisfying some form of weak unique response property) achieve simulation-extractability in the algebraic group model.
This implies that Fiat-Shamir Bulletproofs are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:hqOjcs7Dif8C,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"We advance the state-of-the art for zero-knowledge commit-and-prove SNARKs (CP-SNARKs). CP-SNARKs are an important class of SNARKs which, using commitments as “glue”, allow to efficiently combine proof systems—e.g., general-purpose SNARKs (an efficient way to prove statements about circuits) and -protocols (an efficient way to prove statements about group operations). Thus, CP-SNARKs allow to efficiently provide zero-knowledge proofs for composite statements such as for some hash-function H.
Our main contribution is providing the first construction of CP-SNARKs where the proof size is succinct in the number of commitments.
We achieve our result by providing a general technique to compile Algebraic Holographic Proofs (AHP) (an underlying abstraction used in many modern SNARKs) with special “decomposition” properties into an efficient CP-SNARK. We then show that some of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:roLk4NBRz8UC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"In proof-of-work based cryptocurrencies, miners invest computing power to maintain a distributed ledger. One known drawback of such a consensus protocol is its immense energy consumption. To prevent this waste of energy various consensus mechanism such as proof-of-space or proof-of-stake have been proposed. In proof-of-stake, block creators are selected based on the amounts of currency they stake instead of their expanded computing power.
In this work we study Virtual ASICs–a generalization of proof-of-stake. Virtual ASICs are essentially a virtualized version of proof-of-work. Miners can buy on-chain virtual mining machines which can be powered by virtual electricity. Similar to their physical counterparts, each powered virtual ASIC has a certain chance to win the right to create the next block. In the boundary case where virtual electricity is free, the protocol corresponds to proof-of-stake using an ASIC …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:WF5omc3nYNoC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"Traditional notions of secure multiparty computation (MPC) allow mutually distrusting parties to jointly compute a function over their private inputs, but typically do not specify how these inputs are chosen. Motivated by real-world applications where corrupt inputs could adversely impact privacy and operational legitimacy, we consider a notion of authenticated MPC where the inputs are authenticated, eg, signed using a digital signature by some trusted authority. We propose a generic and efficient compiler that transforms any linear secret sharing based MPC protocol into one with input authentication. Our compiler incurs significantly lower computational costs and competitive communication overheads when compared to the best existing solutions, while entirely avoiding the (potentially expensive) protocol-specific techniques and pre-processing requirements that are inherent to these solutions. For -party MPC protocols with abort security where each party has inputs, our compiler incurs communication overall and a computational overhead of group exponentiations per party (the corresponding overheads for the most efficient existing solution are and ). Finally, for a corruption threshold , our compiler preserves the stronger identifiable abort security of the underlying MPC protocol. No existing solution for authenticated MPC achieves this regardless of the corruption threshold. Along the way, we make several technical contributions that are of independent interest. This includes the notion of distributed proofs of knowledge and concrete realizations of the same for several relations of interest, such as proving …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:ULOm3_A8WrAC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"The celebrated result by Gentry and Wichs established a theoretical barrier for succinct non-interactive arguments (SNARGs), showing that for (expressive enough) hard-on-average languages we must assume non-falsifiable assumptions. We further investigate those barriers by showing new negative and positive results related to extractability and to the preprocessing model. 1. We first ask the question “are there further barriers to SNARGs that are knowledge-sound (SNARKs) and with a black-box extractor?”. We show it is impossible to have such SNARKs in the standard model. This separates SNARKs in the random oracle model (which can have black-box extraction) and those in the standard model. 2. We find positive results regarding the same question in the non-adaptive setting. Under the existence of SNARGs (without extractability) and from standard assumptions, it is possible to build SNARKs with black-box extractability for a non-trivial subset of NP. 3. On the other hand, we show that (under some mild assumptions) all NP languages cannot have SNARKs with black-box extractability even in the non-adaptive setting. 4. The Gentry-Wichs result does not account for the preprocessing model, under which fall several efficient constructions. We show that also in the preprocessing model it is impossible to construct SNARGs that rely on falsifiable assumptions in a black-box way. Along the way, we identify a class of non-trivial languages, which we dub “trapdoor languages”, that bypass some of these impossibility results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:5nxA0vEk-isC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2022,"We construct polynomial commitment schemes with constant sized evaluation proofs and logarithmic verification time in the transparent setting. To the best of our knowledge, this is the first result achieving this combination of properties. Our starting point is a transparent inner product commitment scheme with constant-sized proofs and linear verification. We build on this to construct a polynomial commitment scheme with constant size evaluation proofs and logarithmic (in the degree of the polynomial) verification time. Our constructions make use of groups of unknown order instantiated by class groups. We prove security of our construction in the Generic Group Model (GGM). Using our polynomial commitment scheme to compile an information-theoretic proof system yields Dew--a transparent and constant-sized zkSNARK (Zero-knowledge Succinct Non-interactive ARguments of Knowledge) with logarithmic verification. Finally, we show how to recover the result of DARK (Bünz et al., Eurocrypt 2020). DARK presented a succinct transparent polynomial commitment scheme with logarithmic proof size and verification. However, it was recently discovered to have a gap in its security proof (Block et al, CRYPTO 2021). We recover its extractability based on our polynomial commitment construction, thus obtaining a transparent polynomial commitment scheme with logarithmic proof size and verification under the same assumptions as DARK, but with a prover time that is quadratic.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:0EnyYjriUFMC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2021,"We study Multi-party computation (MPC) in the setting of subversion, where the adversary tampers with the machines of honest parties. Our goal is to construct actively secure MPC protocols where parties are corrupted adaptively by an adversary (as in the standard adaptive security setting), and in addition, honest parties’ machines are compromised.
The idea of reverse firewalls (RF) was introduced at EUROCRYPT’15 by Mironov and Stephens-Davidowitz as an approach to protecting protocols against corruption of honest parties’ devices. Intuitively, an RF for a party is an external entity that sits between and the outside world and whose scope is to sanitize ’s incoming and outgoing messages in the face of subversion of their computer. Mironov and Stephens-Davidowitz constructed a protocol for passively-secure two-party computation. At CRYPTO’20, Chakraborty, Dziembowski and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:UebtZRa9Y70C,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2021,"We present a framework that allows to certify the fairness degree of a model based on an interactive and privacy-preserving test. The framework verifies any trained model, regardless of its training process and architecture. Thus, it allows us to evaluate any deep learning model on multiple fairness definitions empirically. We tackle two scenarios, where either the test data is privately available only to the tester or is publicly known in advance, even to the model creator. We investigate the soundness of the proposed approach using theoretical analysis and present statistical guarantees for the interactive test. Finally, we provide a cryptographic technique to automate fairness testing and certified inference with only black-box access to the model at hand while hiding the participants' sensitive data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:Se3iqnhoufwC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2021,"The lack of privacy in the first generation of cryptocurrencies such as Bitcoin, Ethereum, etc. is a well known problem in cryptocurrency research. To overcome this problem, several new cryptocurrencies were designed to guarantee transaction privacy and anonymity for their users (examples include ZCash, Monero, etc.).
However, the anonymity provided by such systems appears to be fundamentally problematic in current business and legislation settings: banks and other financial institutions must follow rules such as “Know Your Customer” (KYC), “Anti Money Laundering” (AML), etc. It is also well known that the (alleged or real) anonymity guarantees provided by cryptocurrencies have attracted ill-intentioned individuals to this space, who look at cryptocurrencies as a way of facilitating illegal activities (tax-evasion, ransom-ware, trading of illegal substances, etc.).
The fact that current cryptocurrencies do not comply …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:_FxGoFyzp5QC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2021,"We study interactive proof systems (IPSes) in a strong adversarial setting where the machines of honest parties might be corrupted and under control of the adversary. Our aim is to answer the following, seemingly paradoxical, questions:•
Can Peggy convince Vic of the veracity of an NP statement, without leaking any information about the witness even in case Vic is malicious and Peggy does not trust her computer?
•
Can we avoid that Peggy fools Vic into accepting false statements, even if Peggy is malicious and Vic does not trust her computer?
At EUROCRYPT 2015, Mironov and Stephens-Davidowitz introduced cryptographic reverse firewalls (RFs) as an attractive approach to tackling such questions. Intuitively, a RF for Peggy/Vic is an external party that sits between Peggy/Vic and the outside world and whose scope is to sanitize Peggy's/Vic's incoming and outgoing messages in the face of subversion of her/his …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:eQOLeE2rZwMC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2021,"The problems of Byzantine Broadcast (BB) and Byzantine Agreement (BA) are of interest to both the distributed computing and cryptography communities. Extension protocols for these primitives have been introduced to handle long messages efficiently at the cost of small number of single-bit broadcasts, referred to as seed broadcasts. While the communication optimality has remained the most sought-after property of an extension protocol in the literature, we prioritize both communication and round optimality in this work. In a setting with n parties and a static adversary controlling at most t parties in Byzantine fashion, we present BB and BA extension protocols with $$t<n$$ t < n , $$t < n/2$$ t < n / 2 and $$t<n/3$$ t < …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:qjMakFHDy7sC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2021,"Succinct non-interactive arguments of knowledge (SNARKs) enable non-interactive efficient verification of NP computations and admit short proofs. However, all current SNARK constructions assume that the statements to be proven can be efficiently represented as either Boolean or arithmetic circuits over finite fields. For most constructions, the choice of the prime field is limited by the existence of groups of matching order for which secure bilinear maps exist. In this work we overcome such restrictions and enable verifying computations over rings. We construct the first designated-verifier SNARK for statements which are represented as circuits over a broader kind of commutative rings, namely those containing big enough exceptional sets. Exceptional sets consist of elements such that their pairwise differences are invertible. Our contribution is threefold: We first introduce Quadratic Ring Programs (QRPs) as a characterization of NP where the arithmetic is over a ring. Second, inspired by the framework in Gennaro, Gentry, Parno and Raykova (EUROCRYPT 2013), we design SNARKs over rings in a modular way. We generalize pre-existent assumptions employed in field-restricted SNARKs to encoding schemes over rings. As our encoding notion is generic in the choice of the ring, it is amenable to different settings. Finally, we propose two applications for our SNARKs. Our first application is verifiable computation over encrypted data, specifically for evaluations of Ring-LWE-based homomorphic encryption schemes. In the second one, we use Rinocchio to naturally prove statements about circuits over eg , which closely matches real-life …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:LkGwnXOMwfcC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2020,"Method, System, and Computer Program Product for Determining Solvency of a Digital Asset Exchange Download PDF",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:ufrVoPGSRksC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2019,"Standardized digital signature schemes (eg, Rivest-Shamir-Adleman (RSA), Digital Signature Algorithm (DSA), Elliptical Curve Digital Signature Algorithm (EC-DSA), etc.) may be employed to prove authenticity of a message containing credentials. Proving possession of valid credentials may be performed using a combination of garbled circuits with message authentication codes (MACs) and proof of knowledge protocols (eg, Sigma protocol, Schnorr protocol, etc.). Such techniques may allow proving entities to prove possession of valid credentials using standardized signature schemes without revealing those credentials directly to a verifying entity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:IjCSPb-OGe4C,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2019,"Proof-of-stake (PoS) protocols are emerging as one of the most promising alternative to the wasteful proof-of-work (PoW) protocols for consensus in Blockchains (or distributed ledgers). However, current PoS protocols inherently disclose both the identity and the wealth of the stakeholders, and thus seem incompatible with privacy-preserving cryptocurrencies (such as ZCash, Monero, etc.). In this paper we initiate the formal study for PoS protocols with privacy properties. Our results include:
1.
A (theoretical) feasibility result showing that it is possible to construct a general class of private PoS (PPoS) protocols; and to add privacy to a wide class of PoS protocols,
2.
A privacy-preserving version of a popular PoS protocol, Ouroboros Praos …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:W7OEmFMy1HYC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2019,"In this paper we provide a formal treatment of proof of replicated storage, a novel cryptographic primitive recently proposed in the context of a novel cryptocurrency, namely Filecoin.
In a nutshell, proofs of replicated storage is a solution to the following problem: A user stores a file m on n different servers to ensure that the file will be available even if some of the servers fail. Using proof of retrievability, the user could check that every server is indeed storing the file. However, what if the servers collude and, in order to save on resources, decide to only store one copy of the file? A proof of replicated storage guarantees that, unless the (potentially colluding) servers are indeed reserving the space necessary to store n copies of the file, the user will not accept the proofs. While some candidate proofs of replicated storage have already been proposed, their soundness relies on timing assumptions i.e., the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:Y0pCki6q_DkC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2018,"The two most common ways to design non-interactive zero-knowledge (NIZK) proofs are based on Sigma protocols and QAP-based SNARKs. The former is highly efficient for proving algebraic statements while the latter is superior for arithmetic representations.
   Motivated by applications such as privacy-preserving credentials and privacy-preserving audits in cryptocurrencies, we study the design of NIZKs for composite statements that compose algebraic and arithmetic statements in arbitrary ways. Specifically, we provide a framework for proving statements that consist of ANDs, ORs and function compositions of a mix of algebraic and arithmetic components. This allows us to explore the full spectrum of trade-offs between proof size, prover cost, and CRS size/generation cost. This leads to proofs for statements of the form: knowledge of x such that for some public y where the prover’s …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:Tyk-4Ss8FVUC,https://www.csa.iisc.ac.in/~chaya/
Chaya Ganesh,['Cryptography'],13,458,2018,"Zero-knowledge (ZK) protocols are undoubtedly among the central primitives in cryptography, lending their power to numerous applications such as secure computation, voting, auctions, and anonymous credentials to name a few. The study of efficient ZK protocols for non-algebraic statements has seen rapid progress in recent times, relying on secure computation techniques. The primary contribution of this work lies in constructing efficient UC-secure constant round ZK protocols from garbled circuits that are secure against adaptive corruptions, with communication linear in the size of the statement. We begin by showing that the practically efficient ZK protocol of Jawurek et al. (CCS 2013) is adaptively secure when the underlying oblivious transfer (OT) satisfies a mild adaptive security guarantee. We gain adaptive security with little to no overhead over the static case. A conditional verification technique is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=b_NnjeQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=b_NnjeQAAAAJ:zYLM7Y9cAGgC,https://www.csa.iisc.ac.in/~chaya/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2023,"We study the polynomial equivalence problem for orbits of read-once arithmetic formulas (ROFs). Readonce formulas have received considerable attention in both algebraic and Boolean complexity and have served as a testbed for developing effective tools and techniques for analyzing circuits. Two n-variate polynomials f, g∈ F [x] are equivalent, denoted as f∼ g, if there is an A∈ GL (n, F) such that f= g (Ax). The orbit of f is the set of all polynomials equivalent to f. We investigate the complexity of the following two natural problems on ROFs:
• Equivalence test for ROFs: Given black-box access to f, check if it is in the orbit of an ROF. If yes, output an ROF C and an A∈ GL (n, F) such that f= C (Ax).• Polynomial equivalence for orbits of ROFs: Given black-box access to f and g in the orbits of two",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:hFOr9nPyWt4C,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2022,"We prove super-polynomial lower bounds for low-depth arithmetic circuits using the shifted partials measure [Gupta-Kamath-Kayal-Saptharishi, CCC 2013], [Kayal, ECCC 2012] and the affine projections of partials measure [Garg-Kayal-Saha, FOCS 2020], [Kayal-Nair-Saha, STACS 2016]. The recent breakthrough work of Limaye, Srinivasan and Tavenas [FOCS 2021] proved these lower bounds by proving lower bounds for low-depth set-multilinear circuits. An interesting aspect of our proof is that it does not require conversion of a circuit to a set-multilinear circuit, nor does it involve a random restriction. We are able to upper bound the measures for homogeneous formulas directly, without going via set-multilinearity. Our lower bounds hold for the iterated matrix multiplication as well as the Nisan-Wigderson design polynomials. We also define a subclass of homogeneous formulas which we call unique parse tree (UPT) formulas, and prove superpolynomial lower bounds for these. This generalizes the superpolynomial lower bounds for regular formulas in [Kayal-Saha-Saptharishi, STOC 2014], [Fournier-Limaye-Malod-Srinivasan, STOC 2014].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:-f6ydRqryjwC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2022,"Consider a homogeneous degree d polynomial f= T₁+⋯+ T_s, T_i= g_i (𝓁_ {i, 1},…, 𝓁_ {i, m}) where g_i’s are homogeneous m-variate degree d polynomials and 𝓁_ {i, j}’s are linear polynomials in n variables. We design a (randomized) learning algorithm that given black-box access to f, computes black-boxes for the T_i’s. The running time of the algorithm is poly (n, m, d, s) and the algorithm works under some non-degeneracy conditions on the linear forms and the g_i’s, and some additional technical assumptions n≥(md) ², s≤ n^{d/4}. The non-degeneracy conditions on 𝓁_ {i, j}’s constitute non-membership in a variety, and hence are satisfied when the coefficients of 𝓁_ {i, j}’s are chosen uniformly and randomly from a large enough set. The conditions on g_i’s are satisfied for random polynomials and also for natural polynomials common in the study of arithmetic complexity like determinant, permanent, elementary symmetric polynomial, iterated matrix multiplication. A particularly appealing algorithmic corollary is the following: Given black-box access to an f= Det_r (L^(1))+…+ Det_r (L^(s)), where L^(k)=(𝓁_ {i, j}^(k)) _ {i, j} with 𝓁_ {i, j}^(k)’s being linear forms in n variables chosen randomly, there is an algorithm which in time poly (n, r) outputs matrices (M^(k)) _k of linear forms st there exists a permutation π:[s]→[s] with Det_r (M^(k))= Det_r (L^(π (k))).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:IWHjjKOFINEC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2021,"The orbit of an n-variate polynomial f (𝐱) over a field 𝔽 is the set {f (A𝐱+ 𝐛): A∈ GL (n, 𝔽) and 𝐛∈ 𝔽ⁿ}. In this paper, we initiate the study of explicit hitting sets for the orbits of polynomials computable by several natural and well-studied circuit classes and polynomial families. In particular, we give quasi-polynomial time hitting sets for the orbits of:",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:aqlVkmm33-oC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2020,"We develop algorithms for writing a polynomial as sums of powers of low degree polynomials in the non-degenerate case. This problem generalizes symmetric tensor decomposition which is widely studied, having many applications in machine learning. Our algorithm for this more general problem allows us to solve the moment problem for mixtures of zero-mean Gaussians in the nondegenerate case. Our algorithm is based on a scheme for obtaining a learning algorithm for an arithmetic circuit model from lower bound for the same model, provided certain non-degeneracy conditions hold. The scheme reduces the learning problem to the problem of decomposing two vector spaces under the action of a set of linear operators, where the spaces and the operators are derived from the input circuit and the complexity measure used in a typical lower bound proof. The non-degeneracy conditions are certain restrictions on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:mVmsd5A6BfQC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2020,"Equivalence testing for a polynomial family {g_m} over a field F is the following problem: Given black-box access to an n-variate polynomial f(x), where n is the number of variables in g_m, check if there exists an A in GL(n,F) such that f(x) = g_m(Ax). If yes, then output such an A. The complexity of equivalence testing has been studied for a number of important polynomial families, including the determinant (Det) and the two popular variants of the iterated matrix multiplication polynomial: IMM_{w,d} (the (1,1) entry of the product of d many w w symbolic matrices) and Tr-IMM_{w,d} (the trace of the product of d many w w symbolic matrices). The families Det, IMM and Tr-IMM are VBP-complete, and so, in this sense, they have the same complexity. But, do they have the same equivalence testing complexity? We show that the answer is 'yes' for Det and Tr-IMM (modulo the use of randomness). The result is obtained by connecting the two problems via another well-studied problem called the full matrix algebra isomorphism problem (FMAI). In particular, we prove the following: 1. Testing equivalence of polynomials to Tr-IMM_{w,d}, for d 3 and w 2, is randomized polynomial-time Turing reducible to testing equivalence of polynomials to Det_w, the determinant of the w w matrix of formal variables. (Here, d need not be a constant.) 2. FMAI is randomized polynomial-time Turing reducible to equivalence testing (in fact, to tensor isomorphism testing) for the family of matrix multiplication tensors {Tr-IMM_{w,3}}. These in conjunction with the randomized poly-time reduction from determinant equivalence testing to FMAI [Garg,Gupta,Kayal,Saha19], imply that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:4DMP91E08xMC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2020,"We show an Ω̃ (n^ 2.5) lower bound for general depth four arithmetic circuits computing an explicit n-variate degree-Θ (n) multilinear polynomial over any field of characteristic zero. To our knowledge, and as stated in the survey [Amir Shpilka and Amir Yehudayoff, 2010], no super-quadratic lower bound was known for depth four circuits over fields of characteristic≠ 2 before this work. The previous best lower bound is Ω̃ (n^ 1.5)[Abhijat Sharma, 2017], which is a slight quantitative improvement over the roughly Ω (n^ 1.33) bound obtained by invoking the super-linear lower bound for constant depth circuits in [Ran Raz, 2010; Victor Shoup and Roman Smolensky, 1997].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:qxL8FJ1GzNcC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2019,"A matrix X is called a linear matrix if its entries are affine forms, i.e., degree one polynomials in n variables. What is a minimal-sized representation of a given matrix F as a product of linear matrices? Finding such a minimal representation is closely related to finding an optimal way to compute a given polynomial via an algebraic branching program. Here we devise an efficient algorithm for an average-case version of this problem. Specifically, given and blackbox access to the w2 entries of a matrix product , where each is a linear matrix over a given finite field , we wish to recover a factorization , where every is also a linear matrix over (or a small extension of ). We show that when the input F is sampled from a distribution defined by choosing random linear matrices over independently and taking their product and and , then an equivalent factorization …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:M3ejUd6NZC8C,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2019,"A homogeneous depth three circuit C computes a polynomial f = T1 + T2 + ... + Ts, where each Ti is a product of d linear forms in n variables over some underlying field F. Given black-box access to f, can we efficiently reconstruct (i.e. proper learn) a homogeneous depth three circuit computing f? Learning various subclasses of circuits is natural and interesting from both theoretical and practical standpoints and in particular, properly learning homogeneous depth three circuits efficiently is stated as an open problem in a work by Klivans and Shpilka (COLT 2003) and is well-studied. Unfortunately, there is substantial amount of evidence to show that this is a hard problem in the worst case. We give a (randomized) poly(n,d,s)-time algorithm to reconstruct non-degenerate homogeneous depth three circuits for n = Ω(d2) (with some additional mild requirements on s and the characteristic of F). We call a circuit C as non …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:Wp0gIr-vW9MC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2019,"The determinant polynomial Det_n (x) of degree n is the determinant of anxn matrix of formal variables. A polynomial f is equivalent to Det_n (x) over a field F if there exists a A in GL (n^ 2, F) such that f= Det_n (A* x). Determinant equivalence test over F is the following algorithmic task: Given black-box access to af in F [x], check if f is equivalent to Det_n (x) over F, and if so then output a transformation matrix A in GL (n^ 2, F). In (Kayal, STOC 2012), a randomized polynomial time determinant equivalence test was given over F= C. But, to our knowledge, the complexity of the problem over finite fields and over Q was not well understood. In this work, we give a randomized poly (n, log| F|) time determinant equivalence test over finite fields F (under mild restrictions on the characteristic and size of F). Over Q, we give an efficient randomized reduction from factoring square-free integers to determinant equivalence test for quadratic forms (ie the n= 2 case), assuming GRH. This shows that designing a polynomial-time determinant equivalence test over Q is a challenging task. Nevertheless, we show that determinant equivalence test over Q is decidable: For bounded n, there is a randomized polynomial-time determinant equivalence test over Q with access to an oracle for integer factoring. Moreover, for any n, there is a randomized polynomial-time algorithm that takes input black-box access to af in Q [x] and if f is equivalent to Det_n over Q then it returns a A in GL (n^ 2, L) such that f= Det_n (A* x), where L is an extension field of Q and [L: Q]<= n. The above algorithms over finite fields and over Q are obtained by giving a polynomial-time randomized reduction …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:dhFuZR0502QC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2019,"In a Nisan-Wigderson design polynomial (in short, a design polynomial), every pair of monomials share a few common variables. A useful example of such a polynomial, introduced in [Neeraj Kayal et al., 2014], is the following: NW_ {d, k}({x})= sum_ {h in F_d [z], deg (h)<= k}{prod_ {i= 0}^{d-1}{x_ {i, h (i)}}}, where d is a prime, F_d is the finite field with d elements, and k<< d. The degree of the gcd of every pair of monomials in NW_ {d, k} is at most k. For concreteness, we fix k= ceil [sqrt {d}]. The family of polynomials NW:={NW_ {d, k}: d is a prime} and close variants of it have been used as hard explicit polynomial families in several recent arithmetic circuit lower bound proofs. But, unlike the permanent, very little is known about the various structural and algorithmic/complexity aspects of NW beyond the fact that NW in VNP. Is NW_ {d, k} characterized by its symmetries? Is it circuit-testable, ie, given a circuit C can we check efficiently if C computes NW_ {d, k}? What is the complexity of equivalence test for NW, ie, given black-box access to af in F [{x}], can we check efficiently if there exists an invertible linear transformation A such that f= NW_ {d, k}(A*{x})? Characterization of polynomials by their symmetries plays a central role in the geometric complexity theory program. Here, we answer the first two questions and partially answer the third. We show that NW_ {d, k} is characterized by its group of symmetries over C, but not over R. We also show that NW_ {d, k} is characterized by circuit identities which implies that NW_ {d, k} is circuit-testable in randomized polynomial time. As another application of this characterization, we obtain the"" flip theorem"" for NW …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:9ZlFYXVOiuMC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2018,"An algebraic branching program (ABP) A can be modelled as a product expression X1amp;middot; X2… Xd, where X1 and Xd are 1 × w and w × 1 matrices, respectively, and every other Xk is a w × w matrix; the entries of these matrices are linear forms in m variables over a field F (which we assume to be either Q or a field of characteristic poly(m)). The polynomial computed by A is the entry of the 1 × 1 matrix obtained from the product ∏k=1d Xk. We say A is a full rank ABP if the w2(d − 2) + 2w linear forms occurring in the matrices X1, X2, …, Xd are F-linearly independent. Our main result is a randomized reconstruction algorithm for full rank ABPs: Given blackbox access to an m-variate polynomial f of degree at most m, the algorithm outputs a full rank ABP computing f if such an ABP exists, or outputs “no full rank ABP exists” (with high probability). The running time of the algorithm is polynomial in m and β, where β is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:ULOm3_A8WrAC,https://drona.csa.iisc.ac.in/~chandan/
Chandan Saha,"['Computational complexity', 'Computational algebra and number theory']",13,399,2018,"How many operations are needed to compute a given polynomial f(x1; x2; : : : ; xn)? Answering questions of this form naturally leads us on a search for clever algorithmic techniques to reduce the number of operations required. Simultaneously, it also leads us towards the complementary task of finding techniques and paradigms for proving lower bounds on the minimum number of operations required. In this survey we describe one such paradigm for obtaining lower bounds.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xJrC-GMAAAAJ&sortby=pubdate&citation_for_view=xJrC-GMAAAAJ:4TOpqqG69KYC,https://drona.csa.iisc.ac.in/~chandan/
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2022,"Decision tree ensembles are among the most commonly used machine learning models. These models are used in a wide range of applications and are deployed at scale. Decision tree ensemble inference is usually performed with libraries such as XGBoost, LightGBM, and Sklearn. These libraries incorporate a fixed set of optimizations for the hardware targets they support. However, maintaining these optimizations is prohibitively expensive with the evolution of hardware. Further, they do not specialize the inference code to the model being used, leaving significant performance on the table. This paper presents TREEBEARD, an optimizing compiler that progressively lowers the inference computation to optimized CPU code through multiple intermediate abstractions. By applying model-specific optimizations at the higher levels, tree walk optimizations at the middle level, and machine-specific optimizations lower …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:P5F9QuxV20EC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2022,"The state-of-the-art in high-performance deep learning today is primarily driven by manually developed libraries optimized and highly tuned by expert programmers using low-level abstractions with significant effort. This effort is often repeated for similar hardware and future ones. In this work, we pursue and evaluate the more modular and reusable approach of using compiler IR infrastructure to generate libraries by encoding all the required optimizations as a sequence of transformations and customized passes on an IR. We believe that until the recent introduction of MLIR (Multi-level intermediate representation), it had been hard to represent and transform computation at various levels of abstraction within a single IR.
Using the MLIR infrastructure, we build a transformation and lowering pipeline to automatically generate near-peak performance code for matrix-matrix multiplication (matmul) as well as matmul fused …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:bFI3QPDXJZMC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2021,"Loop tiling for locality is an important transformation for general-purpose and domain-specific compilation as it allows programs to exploit the benefits of deep memory hierarchies. Most code generation tools with the infrastructure to perform automatic tiling of loop nests rely on auto-tuning to find good tile sizes. Tile size selection models proposed in the literature either fall back to modeling complex non-linear optimization problems or tackle a narrow class of inputs. Hence, a fast and generic tile size selection model is desirable for it to be adopted into compiler infrastructures like those of GCC, LLVM, or MLIR.
In this paper, we propose a new, fast and lightweight tile size selection model that considers temporal and spatial reuse along dimensions of a loop nest. For an n-dimensional loop nest, we determine the tile sizes by calculating the zeros of a polynomial in a single variable of degree at most n. Our tile size …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:a0OBvERweLwC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2021,"The emergence of machine learning, image and audio processing on edge devices has motivated research towards power efficient custom hardware accelerators. Though FPGAs are an ideal target for energy efficient custom accelerators, the difficulty of hardware design and the lack of vendor agnostic, standardized hardware compilation infrastructure has hindered their adoption. This paper introduces HIR, an MLIR-based intermediate representation (IR) to describe hardware accelerator designs. HIR combines high level language features, such as loops and multi-dimensional tensors, with programmer defined explicit scheduling, to provide a high-level IR suitable for DSL compiler pipelines without compromising control over the micro-architecture of the accelerator. HIR's explicit schedules allow it to express fine-grained, synchronization-free parallelism and optimizations such as retiming and pipelining. Built as a dialect in MLIR, it draws from best IR practices learnt from communities like those of LLVM. While offering rich optimization opportunities and a high level abstraction, HIR enables sharing of optimizations, utilities and passes with software compiler infrastructure. Our implementation shows that the code generation time of the HIR code generator is on average 1112x lower than that of Xilinx Vivado HLS on a range of kernels without a compromise on the quality of the generated hardware. We believe that these are significant steps forward in the design of IRs for hardware synthesis and in equipping domain-specific languages with a productive and performing compilation path to custom hardware acceleration.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:yD5IFk8b50cC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2021,"This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR addresses software fragmentation, compilation for heterogeneous hardware, significantly reducing the cost of building domain specific compilers, and connecting existing compilers together. MLIR facilitates the design and implementation of code generators, translators and optimizers at different levels of abstraction and across application domains, hardware targets and execution environments. The contribution of this work includes (1) discussion of MLIR as a research artifact, built for extension and evolution, while identifying the challenges and opportunities posed by this novel design, semantics, optimization specification, system, and engineering. (2) evaluation of MLIR as a generalized infrastructure that reduces the cost of building compilers-describing diverse use-cases to show research and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:pyW8ca7W8N0C,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2020,"Effective models for fusion of loop nests continue to remain a challenge in both general-purpose and domain-specific language (DSL) compilers. The difficulty often arises from the combinatorial explosion of grouping choices and their interaction with parallelism and locality. This article presents a new fusion algorithm for high-performance domain-specific compilers for image processing pipelines. The fusion algorithm is driven by dynamic programming and explores spaces of fusion possibilities not covered by previous approaches, and it is also driven by a cost function more concrete and precise in capturing optimization criteria than prior approaches. The fusion model is particularly tailored to the transformation and optimization sequence applied by PolyMage and Halide, two recent DSLs for image processing pipelines. Our model-driven technique when implemented in PolyMage provides significant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:dfsIfKJdRG4C,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2020,"Polyhedral auto-transformation frameworks are known to find efficient loop transformations that maximize locality and parallelism and minimize synchronization. While complex loop transformations are routinely modeled in these frameworks, they tend to rely on ad hoc heuristics for loop fusion. Although there exist multiple loop fusion models with cost functions to maximize locality and parallelism, these models involve separate optimization steps rather than seamlessly integrating with other loop transformations like loop permutation, scaling, and shifting. Incorporating parallelism-preserving loop fusion heuristics into existing affine transformation frameworks like Pluto, LLVM-Polly, PPCG, and PoCC requires solving a large number of Integer Linear Programming formulations, which increase auto-transformation times significantly.
In this work, we incorporate polynomial time loop fusion heuristics into the Pluto-lp-dfp …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:4OULZ7Gr8RgC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2020,"This article is primarily meant to present an early case study on using MLIR, a new compiler intermediate representation infrastructure, for high-performance code generation. Aspects of MLIR covered in particular include memrefs, the affine dialect, and polyhedral utilities and pass infrastructure surrounding those. This article is also aimed at showing the role compiler infrastructure could play in generating code that is competitive with highly tuned manually developed libraries, albeit in a more modular, reusable, and automatable way.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:fPk4N6BV_jEC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2020,"This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR aims to address software fragmentation, improve compilation for heterogeneous hardware, significantly reduce the cost of building domain specific compilers, and aid in connecting existing compilers together. MLIR facilitates the design and implementation of code generators, translators and optimizers at different levels of abstraction and also across application domains, hardware targets and execution environments. The contribution of this work includes (1) discussion of MLIR as a research artifact, built for extension and evolution, and identifying the challenges and opportunities posed by this novel design point in design, semantics, optimization specification, system, and engineering. (2) evaluation of MLIR as a generalized infrastructure that reduces the cost of building compilers-describing diverse use-cases to show research and educational opportunities for future programming languages, compilers, execution environments, and computer architecture. The paper also presents the rationale for MLIR, its original design principles, structures and semantics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:zA6iFVUQeVQC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2020,"Unlike CPUs and GPUs, it is possible to use custom fixed-point data types, specified as a tuple (α, β), on FPGAs. The parameters α and β denote the number of integral and fractional bitwidths respectively. The power and area savings while performing arithmetic operations on fixed-point data types are well known to be significant over using floating-point data types.
In this paper, we propose a hybrid approach involving interval analysis and SMT solvers, for estimating integral bitwidths at different compute stages, in an image processing pipeline, specified using a domain-specific language (DSL) such as PolyMage. The DSL specification facilitates the compiler analysis to infer the underlying computational structure with ease. We also propose a simple and practical profile-driven greedy heuristic search technique for fractional bitwidth analysis. Using the Horn-Schunck Optical Flow benchmark program, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:u_35RYKgDlwC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2019,"Though CNNs are highly parallel workloads, in the absence of efficient on-chip memory reuse techniques, an accelerator for them quickly becomes memory bound. In this paper, we propose a CNN accelerator design for inference that is able to exploit all forms of reuse available to minimize off-chip memory access while increasing utilization of available resources. The proposed design is composed of cores, each of which contains a one-dimensional array of processing elements. These cores can exploit different types of reuse available in CNN layers of varying shapes without requiring any reconfiguration; in particular, our design minimizes underutilization due to problem sizes that are not perfect multiples of the underlying hardware array dimensions. A major obstacle in the adoption of FPGAs as a platform for CNN inference is the difficulty to program these devices using hardware description languages. Our end goal is to also address this, and we develop preliminary software support via a codesign in order to leverage the accelerator through TensorFlow, a dominant high-level programming model. Our framework takes care of tiling and scheduling of neural network layers and generates necessary low-level commands to execute the CNN. Experimental evaluation on a real system with a PCI-express based Xilinx VC709 board demonstrates the effectiveness of our approach. As a result of an effective interconnection, the design maintains a high frequency when we scale the number of PEs. The sustained performance overall is a good fraction of the accelerator's theoretical peak performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:3s1wT3WcHBgC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2019,"Sparse matrix-vector multiplication (SpMV) operations are commonly used in various scientific and engineering applications. The performance of the SpMV operation often depends on exploiting regularity patterns in the matrix. Various representations and optimization techniques have been proposed to minimize the memory bandwidth bottleneck arising from the irregular memory access pattern involved. Among recent representation techniques, tensor decomposition is a popular one used for very large but sparse matrices. Post sparse-tensor decomposition, the new representation involves indirect accesses, making it more challenging to optimize for massive parallelism, such as on GPUs.
Computational neuroscience algorithms often involve sparse datasets while still performing long running computations on them. The Linear Fascicle Evaluation (LiFE) application is a popular neuroscience algorithm used for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:ZHo1McVdvXMC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2018,"State-of-the-art algorithms used in automatic polyhedral transformation for parallelization and locality optimization typically rely on Integer Linear Programming (ILP). This poses a scalability issue when scaling to tens or hundreds of statements, and may be disconcerting in production compiler settings. In this work, we consider relaxing integrality in the ILP formulation of the Pluto algorithm, a popular algorithm used to find good affine transformations. We show that the rational solutions obtained from the relaxed LP formulation can easily be scaled to valid integral ones to obtain desired solutions, although with some caveats. We first present formal results connecting the solution of the relaxed LP to the original Pluto ILP. We then show that there are difficulties in realizing the above theoretical results in practice, and propose an alternate approach to overcome those while still leveraging linear programming. Our new …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:35N4QoGY0k4C,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2018,"Polyhedral compilers can perform complex loop optimizations that improve parallelism and cache behaviour of loops in the input program. These transformations result in significant performance gains on modern processors which have large compute power and deep memory hierarchies. The paper, ""Polyhedral Auto-transformation with No Integer Linear Programming"", identifies issues that adversely affect scalability of polyhedral transformation frameworks; in particular the Pluto algorithm. The construction and solving of a complex Integer Linear Programming (ILP) problem increases the time taken by a polyhedral compiler significantly. The paper presents two orthogonal ideas, which together overcome the scalability issues in the affine scheduling problem. It first relaxes the ILP to a Linear Programming (LP) problem, thereby solving a cheaper algorithm. To overcome the sub-optimalities that arise due to this relaxation, the affine scheduling problem is decomposed into following three components: (1) Fusion and dimension matching, (2) Loop scaling and shifting, and (3) Loop skewing. This new auto-transformation framework, pluto-lp-dfp, significantly improves the time taken by the Pluto algorithm without sacrificing performance of the generated code. This report first provides proofs for the theoretical claims made in the paper surrounding relaxed LP formulation of the Pluto algorithm. The second part of the report describes an approach to find good loop fusion (or distribution) and loop permutations that enable tileability. This short report serves as the supplementary material for the paper.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:vV6vV6tmYwMC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2018,"The power and area savings while performing arithmetic operations on fixed-point data type are well known to be significant over using floating-point data type. PolyMage-HLS stores data at each stage of a pipeline using a fixed-point data type (α, β) where α and β denote the number of integral and fractional bits. The integral bitwidth (α) requirement at a pipeline stage can be inferred from its range. In this paper, we first propose an interval-arithmetic based range analysis algorithm to estimate the number of bits required to store the integral part of the data at each stage of an image processing pipeline. The analysis algorithm uses the homogeneity of pixel signals at each stage to cluster them and perform a combined range analysis. Secondly, we propose a software architecture for easily deploying any kind of interval/affine arithmetic based range analyses in the DSL compiler. Thirdly, we show that interval/affine arithmetic based techniques fail to take into account correlated computations across stages and hence could lead to poor range estimates. These errors in range estimates accumulate across stages, especially for iterative programs, such as Horn-Schunck Optical Flow, resulting in estimates nearly unusable in practice. Then, we propose a new range analysis technique using Satisfiability Modulo Theory (SMT) solvers, and show that the range estimates obtained through it are very close to the lower bounds obtained through profile-driven analysis. Finally, for estimating fractional bitwidth (β) requirement at each stage of the pipeline, we propose a simple and practical heuristic search algorithm, which makes very few profile passes, as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:EUQCXRtRnyEC,https://www.csa.iisc.ac.in/~udayb
Uday Reddy Bondhugula,"['Compilers', 'HPC', 'AI systems', 'Automatic parallelization', 'Polyhedral framework']",22,2444,2018,"Effective models for fusion of loop nests continue to remain a challenge in both general-purpose and domain-specific language (DSL) compilers. The difficulty often arises from the combinatorial explosion of grouping choices and their interaction with parallelism and locality. This paper presents a new fusion algorithm for high-performance domain-specific compilers for image processing pipelines. The fusion algorithm is driven by dynamic programming and explores spaces of fusion possibilities not covered by previous approaches, and is driven by a cost function more concrete and precise in capturing optimization criteria than prior approaches. The fusion model is particularly tailored to the transformation and optimization sequence applied by PolyMage and Halide, two recent DSLs for image processing pipelines. Our model-driven technique when implemented in PolyMage provides significant improvements (up …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=cwo0elIAAAAJ&sortby=pubdate&citation_for_view=cwo0elIAAAAJ:J_g5lzvAfSwC,https://www.csa.iisc.ac.in/~udayb
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2023,"We prove that perfectly-secure optimally-resilient secure Multi-Party Computation (MPC) for a circuit with C gates and depth D can be obtained in communication complexity and expected time. For and , this is the first perfectly-secure optimal-resilient MPC protocol with linear communication complexity per gate and constant expected time complexity per layer.
Compared to state-of-the-art MPC protocols in the player elimination framework [Beerliova and Hirt TCC’08, and Goyal, Liu, and Song CRYPTO’19], for and , our results significantly improve the run time from to expected while keeping communication complexity at .
Compared to state-of-the-art MPC protocols that obtain an expected time complexity [Abraham, Asharov, and Yanai TCC’21], for , our results significantly improve the communication complexity from to while keeping the expected run time at …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:-_dYPAW6P2MC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2023,"Secure multi-party computation (MPC) is a fundamental problem in secure distributed computing. An MPC protocol allows a set of n mutually distrusting parties with private inputs to securely compute any publicly known function of their inputs, by keeping their respective inputs as private as possible. While several works in the past have addressed the problem of designing communication-efficient MPC protocols in the synchronous communication setting, not much attention has been paid to the design of efficient MPC protocols in the asynchronous communication setting. In this work, we focus on the design of efficient asynchronous MPC (AMPC) protocol with statistical security, tolerating a computationally unbounded adversary, capable of corrupting up to t parties out of the n parties. The seminal work of Ben-Or, Kelmer and Rabin (PODC 1994) and later Abraham, Dolev and Stern (PODC 2020) showed that the optimal resilience for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:tkaPQYYpVKoC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2023,"In the classical notion of multiparty computation (MPC), an honest party learning private inputs of others, either as a part of protocol specification or due to a malicious party’s unspecified messages, is not considered a potential breach. Several works in the literature exploit this seemingly minor loophole to achieve the strongest security of guaranteed output delivery via a trusted third party, which nullifies the purpose of MPC. Alon et al. (CRYPTO 2020) presented the notion of Friends and Foes (\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\texttt{FaF}$$\end{document}) security, which accounts for such undesired leakage towards honest parties by modelling them as semi-honest (friends) who …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:LjlpjdlvIbIC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2023,"Secure shuffle is an important primitive that finds use in several applications such as secure electronic voting, oblivious RAMs, secure sorting, to name a few. For time-sensitive shuffle-based applications that demand a fast response time, it is essential to design a fast and efficient shuffle protocol. In this work, we design secure and fast shuffle protocols relying on the techniques of secure multiparty computation. We make several design choices that aid in achieving highly efficient protocols. Specifically, we consider malicious 3-party computation setting with an honest majority and design robust ring-based protocols. Our shuffle protocols provide a fast online (ie, input-dependent) phase compared to the state-of-the-art for the considered setting. To showcase the efficiency improvements brought in by our shuffle protocols, we consider two distinct applications of anonymous broadcast and secure graph computation via the GraphSC paradigm. In both cases, multiple shuffle invocations are required. Hence, going beyond standalone shuffle invocation, we identify two distinct scenarios of multiple invocations and provide customised protocols for the same. Further, we showcase that our customized protocols not only provide a fast response time, but also provide improved overall run time for multiple shuffle invocations. With respect to the applications, we not only improve in terms of efficiency, but also work towards providing improved security guarantees, thereby outperforming the respective state-of-the-art works. We benchmark our shuffle protocols and the considered applications to analyze the efficiency improvements with respect to various parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:35r97b3x0nAC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2023,"In STOC 1989, Rabin and Ben-Or (RB) established an important milestone in the fields of cryptography and distributed computing by showing that every functionality can be computed with statistical (information-theoretic) security in the presence of an active (aka Byzantine) rushing adversary that controls up to half of the parties. We study the round complexity of general secure multiparty computation and several related tasks in the RB model. Our main result shows that every functionality can be realized in only four rounds of interaction which is known to be optimal. This completely settles the round complexity of statistical actively-secure optimally-resilient MPC, resolving a long line of research. Along the way, we construct the first round-optimal statistically-secure verifiable secret sharing protocol (Chor, Goldwasser, Micali, and Awerbuch; STOC 1985), show that every single-input functionality (eg, multi-verifier zero-knowledge) can be realized in 3 rounds, and prove that the latter bound is optimal. The complexity of all our protocols is exponential in the number of parties, and the question of deriving polynomially-efficient protocols is left for future research. Our main technical contribution is a construction of a new type of statistically-secure signature scheme whose existence was open even for smaller resiliency thresholds. We also describe a new statistical compiler that lifts up passively-secure protocols to actively-secure protocols in a round-efficient way via the aid of protocols for single-input functionalities. This compiler can be viewed as a statistical variant of the GMW compiler (Goldreich, Micali, Wigderson; STOC, 1987) that originally employed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:2KloaMYe4IUC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2023,"The rising issues of harassment, exploitation, corruption, and other forms of abuse have led victims to seek comfort by acting in unison against common perpetrators (eg,# MeToo movement). One way to curb these issues is to install allegation escrow systems that allow victims to report such incidents. The escrows are responsible for identifying victims of a common perpetrator and taking the necessary action to bring justice to them. However, users hesitate to participate in these systems due to the fear of such sensitive reports being leaked to perpetrators, who may further misuse them. Thus, to increase trust in the system, cryptographic solutions are being designed to realize secure allegation escrow (SAE) systems. In the work of Arun et al.(NDSS'20), which presents the state-of-the-art solution, we identify attacks that can leak sensitive information and compromise victim privacy. We also report issues present in prior works that were left unidentified. To arrest all these breaches, we put forth an SAE system that prevents the identified attacks and retains the salient features from all prior works. The cryptographic technique of secure multi-party computation (MPC) serves as the primary underlying tool in designing our system. At the heart of our system lies a new duplicity check protocol and an improved matching protocol. We also provide additional features such as allegation modification and deletion, which were absent in the state of the art. To demonstrate feasibility, we benchmark the proposed system with state-of-the-art MPC protocols and report the cost of processing an allegation. Different settings that affect system performance are analyzed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:tzM49s52ZIMC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"A multiparty computation protocol is perfectly secure for some function f if it perfectly emulates an ideal computation of f. Thus, perfect security is the strongest and most desirable notion of security, as it guarantees security in the face of any adversary and eliminates the dependency on any security parameter. Ben-Or et al. [STOC ’88] and Chaum et al. [STOC ’88] showed that any function can be computed with perfect security if strictly less than one-third of the parties can be corrupted. For two-party sender-receiver functionalities (where only one party receives an output), Ishai et al. [TCC ’13] showed that any function can be computed with perfect security in the correlated randomness model. Unfortunately, they also showed that perfect security cannot be achieved in general for two-party functions that give outputs to both parties (even in the correlated randomness model).
We study the feasibility of obtaining perfect …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:kzcrU_BdoSEC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"Broadcast is an essential primitive for secure computation. We focus in this paper on optimal resilience (i.e., when the number of corrupted parties t is less than a third of the computing parties n), and with no setup or cryptographic assumptions.
While broadcast with worst case t rounds is impossible, it has been shown [Feldman and Micali STOC’88, Katz and Koo CRYPTO’06] how to construct protocols with expected constant number of rounds in the private channel model. However, those constructions have large communication complexity, specifically expected number of bits transmitted for broadcasting a message of length L. This leads to a significant communication blowup in secure computation protocols in this setting.
In this paper, we substantially improve the communication complexity of broadcast in constant expected time. Specifically, the expected communication complexity of our protocol is . For …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:ye4kPcJQO24C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"The task of achieving full security (with guaranteed output delivery) in secure multiparty computation (MPC) is a long-studied problem. Known impossibility results (Cleve, STOC 86) rule out general solutions in the dishonest majority setting. In this work, we consider solutions that use an external trusted party (TP) to bypass the impossibility results, and study the minimal requirements needed from this trusted party. In particular, we restrict ourselves to the extreme setting where the size of the TP is independent of the size of the functionality to be computed (called “small"" TP) and this TP is invoked only once during the protocol execution. We present several positive and negative results for fully-secure MPC in this setting.
For a natural class of protocols, specifically, those with a universal output decoder, we show that the size of the TP must necessarily be exponential in the number of parties. This result holds irrespective …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:WqliGbK-hY8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"We study the round complexity of secure multiparty computation (MPC) in the challenging model where full security, including guaranteed output delivery, should be achieved at the presence of an active rushing adversary who corrupts up to half of parties. It is known that 2 rounds are insufficient in this model (Gennaro et al. Crypto 2002), and that 3 round protocols can achieve computational security under public-key assumptions (Gordon et al. Crypto 2015; Ananth et al. Crypto 2018; and Badrinarayanan et al. Asiacrypt 2020). However, despite much effort, it is unknown whether public-key assumptions are inherently needed for such protocols, and whether one can achieve similar results with security against computationally-unbounded adversaries.
In this paper, we use Minicrypt-type assumptions to realize 3-round MPC with full and active security. Our protocols come in two flavors: for a small (logarithmic) number of parties n …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:8AbLer7MMksC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"Consider a set of N clients, each of which holds a private input string. An input string that is held by at least τ clients is defined as a τ-heavy hitter. In various application scenarios, data-aggregation servers are interested in learning τ-heavy hitters. To ensure that the servers do not learn anything about client input in the process, the problem of identifying heavy hitters privately is gaining popularity. Towards this, we design a novel system called Vogue, which provides improved efficiency as well as security guarantees over the state-of-the-art system of Poplar. Concretely, Vogue provides up to 27x efficiency improvement over Poplar when considering 400,000 clients who hold 256-bit input strings. Moreover, Vogue overcomes intermediate information leakages present in Poplar and guarantees full security in the presence of a malicious adversary. In the process of designing Vogue, we also design secure and efficient …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:7T2F9Uy0os0C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"The growing volumes of data collected and its analysis to provide better services create worries about digital privacy. The literature has relied on secure multiparty computation techniques to address privacy concerns and give practical solutions. However, recent research has mostly focused on the small-party honest-majority setting of up to four parties, noting efficiency concerns. In this work, we extend the strategies to support a larger number of participants in honest-majority setting with efficiency at the center stage.
Designed in the preprocessing paradigm, our semi-honest protocol improves the online complexity of the decade-old state-of-the-art protocol of Damgård and Nielson (CRYPTO'07). In addition to having an improved online communication cost, we can shut down almost half of the parties in the online phase, thereby saving up to 50% in the system's operational costs. Our maliciously secure protocol also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:NJ774b8OgUMC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"Secure multiparty computation (MPC) is increasingly being used to address privacy issues in various applications. The recent work of Alon et al. (CRYPTO'20) identified the shortcomings of traditional MPC and defined a Friends-and-Foes (FaF) security notion to address the same. We showcase the need for FaF security in real-world applications such as dark pools. This subsequently necessitates designing concretely efficient FaF-secure protocols. Towards this, keeping efficiency at the center stage, we design ring-based FaF-secure MPC protocols in the small-party honest-majority setting. Specifically, we provide (1,1)-FaF secure 5 party computation protocols (5PC) that consider one malicious and one semi-honest corruption and constitutes the optimal setting for attaining honest-majority. At the heart of it lies the multiplication protocol that requires a single round of communication with 8 ring elements (amortized …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:5awf1xo2G04C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"Multiparty randomized encodings (Applebaum, Brakerski, and Tsabary, SICOMP 2021) reduce the task of securely computing a complicated multiparty functionality f to the task of securely computing a simpler functionality g. The reduction is non-interactive and preserves information-theoretic security against a passive (semi-honest) adversary, also referred to as privacy. The special case of a degree-2 encoding g (2MPRE) has recently found several applications to secure multiparty computation (MPC) with either information-theoretic security or making black-box access to cryptographic primitives. Unfortunately, as all known constructions are based on information-theoretic MPC protocols in the plain model, they can only be private with an honest majority.
In this paper, we break the honest-majority barrier and present the first construction of general 2MPRE that remains secure in the presence of a dishonest majority. Our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:eMMeJKvmdy0C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"We introduce the problem of Verifiable Relation Sharing (VRS) where a client (prover) wishes to share a vector of secret data items among k servers (the verifiers) while proving in zero-knowledge that the shared data satisfies some properties. This combined task of sharing and proving generalizes notions like verifiable secret sharing and zero-knowledge proofs over secret-shared data. We study VRS from a theoretical perspective and focus on its round complexity.
As our main contribution, we show that every efficiently-computable relation can be realized by a VRS with an optimal round complexity of two rounds where the first round is input-independent (offline round). The protocol achieves full UC-security against an active adversary that is allowed to corrupt any t-subset of the parties that may include the client together with some of the verifiers. For a small (logarithmic) number of parties, we achieve an optimal resiliency …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:HE397vMXCloC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"In this chapter, we discuss how one can improve the efficiency of the BGW protocol in the pre-processing model, where parties are allowed to generate correlated randomness in advance, independent of the circuit-evaluation. We discuss two classes of protocols in the pre-processing model, one based on Beaver’s random multiplication-triples and another based on random double-shared values.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:W5xh706n7nkC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"So far our focus was on general n-party secure MPC, where the emphasis was on asymptotic efficiency. In this chapter, we discuss a special case of perfectly-secure MPC, namely MPC for small number of parties. Instead of asymptotic efficiency, our focus will be on concrete efficiency. The use case considered in this chapter is that of secure 3-party computation (secure 3PC), with one passive corruption. We discuss two different protocols in this setting, the first one due to [9] and the second one due to [47].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:_Ybze24A_UAC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"In this chapter, we revisit the perfectly-secure 3PC protocols discussed in Chap. 9 and show that one can further improve the communication complexity of these protocols, if instead of perfect security, one settles for cryptographic security. Specifically, the pre-processing phase of the protocols are significantly simplified. The setting considered in this chapter is that of 3 mutually-distrusting parties , tolerating a computationally-bounded adversary who can corrupt at most 1 out of the 3 parties; i.e.  and .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:uLbwQdceFCQC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"In the previous chapter, we have shown that one can implement the GMW protocol in the plain model, if we know how to securely compute the OT function . In this chapter, our focus will be to securely compute . As mentioned earlier, OT in itself is a very important cryptographic primitive and has been studied in depth. There are many instantiations available based on a spectrum of assumptions. Our goal is not to cover all of them. We refer the interested readers to [88] for a more detailed and rigorous coverage of OT.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:JQOojiI6XY0C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"In this chapter, we present the classic perfectly-secure MPC protocol due to Ben-Or, Goldwasser and Wigderson [25], popularly known as the BGW MPC protocol. Here our focus will be on secure computation of linear functions. We present the formal security definition of MPC and prove the security in the simulation paradigm. Using the secure linear function evaluation method, we then construct protocol for a special linear function involving the product of a public matrix and a secret vector. This special linear function will then be used for building the BGW protocol for any function in the next chapter. We conclude the chapter mentioning the issues that BGW protocol for linear functions may have while facing a malicious adversary. The BGW MPC protocol is a generic MPC protocol, which allows the parties to securely compute any finite function. The set of mutually-distrusting parties is denoted by . The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:UHK10RUVsp4C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"Till now, our focus was on perfectly-secure MPC tolerating threshold adversaries. In this chapter, we shift our attention to perfectly-secure MPC tolerating general (non-threshold) adversaries.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:dQ2og3OwTAUC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"In this chapter, we present the seminal secure two-party computation (secure 2PC) protocol due to Yao [138]. The striking feature of the protocol is that unlike all the protocols discussed till now where the number of interactions among the parties is proportional to the multiplicative depth of the underlying circuit, Yao’s protocol requires only a constant number of interactions among the parties, irrespective of the circuit size. Thus the protocol can be deployed in high-latency networks, where the round-trip delay between the parties is high.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:hkOj_22Ku90C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"In this chapter, we introduce the problem of secret-sharing. We present the generalized secret-sharing scheme of Ito et al. [98] and the threshold secret-sharing scheme of Shamir [135]. While secret-sharing schemes find extensive application in MPC, we showcase here another important application, namely perfectly-secure message transmission. We conclude with demonstrating what can go wrong in a secret-sharing scheme in the face of malicious adversaries. Consider the following application. There is a bank with three managers. There is a locker in the bank, which needs to be opened every day using the help of the managers. Each of the managers has got a password to operate the locker. However, no one trusts any single manager. So we want to design a system where the locker can be opened only if at least two of the managers enter their respective passwords, but the locker should remain inaccessible …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:PR6Y55bgFSsC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"All the MPC protocols discussed so far offer perfect-security against computationally-unbounded adversaries. For the next few chapters, we shift our attention to cryptographic-security (also known as computational or conditional security), where the security is provided only against computationally-bounded adversaries.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:1yQoGdGgb4wC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"In this chapter, we discuss the BGW protocol for securely evaluating any function. We first discuss the challenges associated with evaluating the multiplication gates, leading to the degree-reduction problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:ZuybSZzF8UAC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"In this chapter, we discuss the relevant topics from abstract algebra which are later used extensively. We start with the definition of groups. A set with some binary operation o over , is called a group if all the following properties (also known as group-axioms) are satisfied: Closure : for every , the element . Associativity : for every a, b, c, the condition holds. Existence of identity : there exists a unique identity element , such that for every , the condition holds. ExistenceGroup of inverse : for every , there exists a unique element, say , such that the condition holds. We note that in Definition 2.1, the operation oneed not satisfy the commutative property. If apart from the axioms , the operation o satisfies the commutative property, then along with the operation o is called as an Abelian group.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:N5tVd3kTz84C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"In this chapter, we discuss a simple MPC protocol, which allows a set of n mutually-distrusting parties to compute the sum of their private bits “securely”, without revealing anything beyond the sum. This is a simple case study for a specific function before we plunge into the more involved general case. We will also introduce a powerful proof mechanism based on the simulation-paradigm, which is used extensively throughout this book. We conclude with a few possible breaks for the MPC protocol in the face of stronger adversarial setting, including malicious adversaries. Consider a set of n mutually-distrusting parties , where each party has a private bit . The parties are interested to learn the sum and nothing beyond. Specifically, each should learn only S and whatever it can infer about the inputs of the other parties from its own input and the sum S. For instance, once S is learnt by  …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:VL0QpB8kHFEC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"This book focuses on multi-party computation (MPC) protocols in the passive corruption model (also known as the semi-honest or honest-but-curious model). The authors present seminal possibility and feasibility results in this model and includes formal security proofs. Even though the passive corruption model may seem very weak, achieving security against such a benign form of adversary turns out to be non-trivial and demands sophisticated and highly advanced techniques. MPC is a fundamental concept, both in cryptography as well as distributed computing. On a very high level, an MPC protocol allows a set of mutually-distrusting parties with their private inputs to jointly and securely perform any computation on their inputs. Examples of such computation include, but not limited to, privacy-preserving data mining; secure e-auction; private set-intersection; and privacy-preserving machine learning. MPC protocols emulate the role of an imaginary, centralized trusted third party (TTP) that collects the inputs of the parties, performs the desired computation, and publishes the result. Due to its powerful abstraction, the MPC problem has been widely studied over the last four decades.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:Fu2w8maKXqMC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"Verifiable Secret-Sharing (VSS) is a fundamental primitive in secure distributed computing. It is used as a building block in several distributed computing tasks, such as Byzantine agreement and secure multi-party computation. In this article, we consider VSS schemes with perfect security, tolerating computationally unbounded adversaries. We comprehensively survey the existing perfectly secure VSS schemes in three different communication settings, namely, synchronous, asynchronous, and hybrid setting and provide full details of the existing schemes in these settings. The aim of this survey is to provide a clear knowledge and foundation to researchers who are interested in knowing and extending the state-of-the-art perfectly secure VSS schemes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:5Ul4iDaHHb8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"The growing volumes of data being collected and its analysis to provide better services are creating worries about digital privacy. To address privacy concerns and give practical solutions, the literature has relied on secure multiparty computation. However, recent research has mostly focused on the small-party honest-majority setting of up to four parties, noting efficiency concerns. In this work, we extend the strategies to support a larger number of participants in an honest-majority setting with efficiency at the center stage. Cast in the preprocessing paradigm, our semi-honest protocol improves the online complexity of the decade-old state-of-the-art protocol of Damg\aa rd and Nielson (CRYPTO'07). In addition to having an improved online communication cost, we can shut down almost half of the parties in the online phase, thereby saving up to 50% in the system's operational costs. Our maliciously secure protocol also enjoys similar benefits and requires only half of the parties, except for one-time verification, towards the end. To showcase the practicality of the designed protocols, we benchmark popular applications such as deep neural networks, graph neural networks, genome sequence matching, and biometric matching using prototype implementations. Our improved protocols aid in bringing up to 60-80% savings in monetary cost over prior work.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:AXPGKjj_ei8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"As e-commerce companies begin to consider using delivery drones for customer fulfillment, there are growing concerns around citizen privacy. Drones are equipped with cameras, and the video feed from these cameras is often required as part of routine navigation, be it for semi autonomous or fully-autonomous drones. Footage of ground-based citizens may be captured in this video feed, thereby leading to privacy concerns. This paper presents Privadome, a system that implements the vision of a virtual privacy dome centered around the citizen. Privadome is designed to be integrated with city-scale regulatory authorities that oversee delivery drone operations and realizes this vision through two components, PD-MPC and PD-ROS. PD-MPC allows citizens equipped with a mobile device to identify drones that have captured their footage. It uses secure two-party computation to achieve this goal without compromising the privacy of the citizen's location. PD-ROS allows the citizen to communicate with such drones and obtain an audit trail showing how the drone uses their footage and determine if privacy-preserving steps are taken to sanitize the footage. An experimental evaluation of Privadome using our prototype implementations of PD-MPC and PD-ROS shows that the system scales to near-term city-scale delivery drone deployments (hundreds of drones). We show that with PD-MPC the mobile data usage on the citizen's mobile device is comparable to that of routine activities on the device, such as streaming videos. We also show that the workflow of PD-ROS consumes a modest amount of additional CPU resources and power on our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:Mojj43d5GZwC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"Identifying a cluster around a seed node in a graph, termed local clustering, finds use in several applications, including fraud detection, targeted advertising, community detection, etc. However, performing local clustering is challenging when the graph is distributed among multiple data owners, which is further aggravated by the privacy concerns that arise in disclosing their view of the graph. This necessitates designing solutions for privacy-preserving local clustering and is addressed for the first time in the literature. We propose using the technique of secure multiparty computation (MPC) to achieve the same. Our local clustering algorithm is based on the heat kernel PageRank (HKPR) metric, which produces the best-known cluster quality. En route to our final solution, we have two important steps:(i) designing data-oblivious equivalent of the state-of-the-art algorithms for computing local clustering and HKPR values, and (ii) compiling the data-oblivious algorithms into its secure realisation via an MPC framework that supports operations over fixed-point arithmetic representation such as multiplication and division. Keeping efficiency in mind for large graphs, we choose the best-known honest-majority 3-party framework of SWIFT (Koti et al., USENIX'21) and enhance it with some of the necessary yet missing primitives, before using it for our purpose. We benchmark the performance of our secure protocols, and the reported run time showcases the practicality of the same. Further, we perform extensive experiments to evaluate the accuracy loss of our protocols. Compared to their cleartext counterparts, we observe that the results are comparable and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:ZfRJV9d4-WMC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2022,"Consider the problem of securely identifying τ-heavy hitters, where given a set of client inputs, the goal is to identify those inputs which are held by at least τ clients in a privacy-preserving manner. Towards this, we design a novel system Vogue, whose key highlight in comparison to prior works, is that it ensures complete privacy and does not leak any information other than the heavy hitters. In doing so, Vogue aims to achieve as efficient a solution as possible. To showcase these efficiency improvements, we benchmark our solution and observe that it requires around 14 minutes to compute the heavy hitters for τ= 900 on 256-bit inputs when considering 400K clients. This is in contrast to the state of the art solution that requires over an hour for the same. In addition to the static input setting described above, Vogue also accounts for streaming inputs and provides a protocol that outperforms the state-of-the-art therein. The efficiency improvements witnessed while computing heavy hitters in both, the static and streaming input settings, are attributed to our new secure stable compaction protocol, whose round complexity is independent of the size of the input array to be compacted",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:tKAzc9rXhukC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2021,"Secure Multi-party Computation (MPC) allows to securely compute on private data. To make MPC practical, logic synthesis can be used to automatically translate a description of the function to be computed securely into optimized and error-free boolean circuits. The work of Demmler et al. (CCS'15) used industry-grade hardware synthesis tools (DC, Yosys) to generate depth-optimized circuits for MPC. To evaluate their optimized circuits, they used the ABY framework (Demmler et al., NDSS'15) for secure two-party computation. The recent ABY2.0 framework (Patra et al., USENIX Security'21) presented round-efficient constructions using multi-input AND gates and improved over ABY by at least 6× in online communication. In this work, we propose SynCirc, an efficient hardware synthesis framework designed for MPC applications. Our framework is based on Verilog and the open-source tool Yosys-ABC. It provides …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:D_sINldO8mEC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2021,"We settle the exact round complexity of three-party computation (3PC) in honest-majority setting, for a range of security notions such as selective abort, unanimous abort, fairness and guaranteed output delivery. It is a folklore that the implication holds from the guaranteed output delivery to fairness to unanimous abort to selective abort. We focus on computational security and consider two network settings—pairwise-private channels without and with a broadcast channel. In the minimal setting of pairwise-private channels, 3PC with selective abort is known to be feasible in just two rounds, while guaranteed output delivery is infeasible to achieve irrespective of the number of rounds. Settling the quest for exact round complexity of 3PC in this setting, we show that three rounds are necessary and sufficient for unanimous abort and fairness. Extending our study to the setting with an additional broadcast channel, we show …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:SP6oXDckpogC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2021,"Secure Multi-party Computation (MPC) allows a set of mutually distrusting parties to jointly evaluate a function on their private inputs while maintaining input privacy. In this work, we improve semi-honest secure two-party computation (2PC) over rings, with a focus on the efficiency of the online phase.
We propose an efficient mixed-protocol framework, outperforming the state-of-the-art 2PC framework of ABY. Moreover, we extend our techniques to multiinput multiplication gates without inflating the online communication, ie, it remains independent of the fan-in. Along the way, we construct efficient protocols for several primitives such as scalar product, matrix multiplication, comparison, maxpool, and equality testing. The online communication of our scalar product is two ring elements irrespective of the vector dimension, which is a feature achieved for the first time in the 2PC literature. The practicality of our new set of protocols is showcased with four applications: i) AES S-box, ii) Circuit-based Private Set Intersection, iii) Biometric Matching, and iv) Privacypreserving Machine Learning (PPML). Most notably, for PPML, we implement and benchmark training and inference of Logistic Regression and Neural Networks over LAN and WAN networks. For training, we improve online runtime (both for LAN and WAN) over SecureML (Mohassel et al., IEEE S&P’17) in the range 1.5×–6.1×, while for inference, the improvements are in the range of 2.5×–754.3×.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:sSrBHYA8nusC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2021,"Performing machine learning (ML) computation on private data while maintaining data privacy, aka Privacy-preserving Machine Learning (PPML), is an emergent field of research. Recently, PPML has seen a visible shift towards the adoption of the Secure Outsourced Computation (SOC) paradigm due to the heavy computation that it entails. In the SOC paradigm, computation is outsourced to a set of powerful and specially equipped servers that provide service on a pay-per-use basis. In this work, we propose SWIFT, a robust PPML framework for a range of ML algorithms in SOC setting, that guarantees output delivery to the users irrespective of any adversarial behaviour. Robustness, a highly desirable feature, evokes user participation without the fear of denial of service. At the heart of our framework lies a highly-efficient, maliciously-secure, three-party computation (3PC) over rings that provides guaranteed output delivery (GOD) in the honestmajority setting. To the best of our knowledge, SWIFT is the first robust and efficient PPML framework in the 3PC setting. SWIFT is as fast as (and is strictly better in some cases than) the best-known 3PC framework BLAZE (Patra et al. NDSS’20), which only achieves fairness. We extend our 3PC framework for four parties (4PC). In this regime, SWIFT is as fast as the best known fair 4PC framework Trident (Chaudhari et al. NDSS’20) and twice faster than the best-known robust 4PC framework FLASH (Byali et al. PETS’20). We demonstrate our framework’s practical relevance by benchmarking popular ML algorithms such as Logistic Regression and deep Neural Networks such as VGG16 and LeNet, both over …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:vRqMK49ujn8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2021,"Mixing arithmetic and boolean circuits to perform privacy-preserving machine learning has become increasingly popular. Towards this, we propose a framework for the case of four parties with at most one active corruption called Tetrad. Tetrad works over rings and supports two levels of security, fairness and robustness. The fair multiplication protocol costs 5 ring elements, improving over the state-of-the-art Trident (Chaudhari et al. NDSS'20). A key feature of Tetrad is that robustness comes for free over fair protocols. Other highlights across the two variants include (a) probabilistic truncation without overhead, (b) multi-input multiplication protocols, and (c) conversion protocols to switch between the computational domains, along with a tailor-made garbled circuit approach. Benchmarking of Tetrad for both training and inference is conducted over deep neural networks such as LeNet and VGG16. We found that Tetrad is up to 4 times faster in ML training and up to 5 times faster in ML inference. Tetrad is also lightweight in terms of deployment cost, costing up to 6 times less than Trident.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:LPZeul_q3PIC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2021,"The problems of Byzantine Broadcast (BB) and Byzantine Agreement (BA) are of interest to both the distributed computing and cryptography communities. Extension protocols for these primitives have been introduced to handle long messages efficiently at the cost of small number of single-bit broadcasts, referred to as seed broadcasts. While the communication optimality has remained the most sought-after property of an extension protocol in the literature, we prioritize both communication and round optimality in this work. In a setting with n parties and a static adversary controlling at most t parties in Byzantine fashion, we present BB and BA extension protocols with $$t<n$$ t < n , $$t < n/2$$ t < n / 2 and $$t<n/3$$ t < …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:cFHS6HbyZ2cC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2021,"Traditional zero-knowledge protocols have been studied and optimized for the setting where a single prover holds the complete witness and tries to convince a verifier about a predicate on the witness, without revealing any additional information to the verifier. In this work, we study the notion of distributed-prover zero knowledge (DPZK) for arbitrary predicates where the witness is shared among multiple mutually distrusting provers and they want to convince a verifier that their shares together satisfy the predicate. We make the following contributions to the notion of distributed proof generation:(i) we propose a new MPC-style security definition to capture the adversarial settings possible for different collusion models between the provers and the verifier,(ii) we discuss new efficiency parameters for distributed proof generation such as the number of rounds of interaction and the amount of communication among the provers, and (iii) we propose a compiler that realizes distributed proof generation from the zero-knowledge protocols in the Interactive Oracle Proofs (IOP) paradigm. Our compiler can be used to obtain DPZK from arbitrary IOP protocols, but the concrete efficiency overheads are substantial in general. To this end, we contribute (iv) a new zero-knowledge IOP which can be compiled into an efficient DPZK protocol. The -DPZK protocol , with provers and one verifier, admits proof size with a communication complexity of , where is the number of gates in the arithmetic circuit representing the predicate and is the number of wires that depends on inputs from two or more parties. Significantly …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:1qzjygNMrQYC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2021,"We give constructions of three-round secure multiparty computation (MPC) protocols for general functions that make black-box use of a two-round oblivious transfer (OT). For the case of semi-honest adversaries, we make use of a two-round, semi-honest secure OT in the plain model. This resolves the round-complexity of black-box (semi-honest) MPC protocols from minimal assumptions and answers an open question of Applebaum et al. (ITCS 2020). For the case of malicious adversaries, we make use of a two-round maliciously-secure OT in the common random/reference string model that satisfies a (mild) variant of adaptive security for the receiver.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:VOx2b1Wkg3QC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2020,"The two traditional streams of multiparty computation (MPC) protocols consist of– (a) protocols achieving guaranteed output delivery () or fairness () in the honest-majority setting and (b) protocols achieving unanimous or selective abort (, ) in the dishonest-majority setting. The favorable presence of honest majority amongst the participants is necessary to achieve the stronger notions of  or . While the constructions of each type are abound in the literature, one class of protocols does not seem to withstand the threat model of the other. For instance, the honest-majority protocols do not guarantee privacy of the inputs of the honest parties in the face of dishonest majority and likewise the dishonest-majority protocols cannot achieve and , tolerating even a single corruption, let alone dishonest minority. The promise of the unconventional yet much sought-after species of MPC, termed as ‘Best-of-Both-Worlds …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:4fKUyHm3Qg0C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2020,"In STOC 1988, Ben-Or, Goldwasser, and Wigderson (BGW) established an important milestone in the fields of cryptography and distributed computing by showing that every functionality can be computed with perfect (information-theoretic and error-free) security at the presence of an active (aka Byzantine) rushing adversary that controls up to n/3 of the parties. We study the round complexity of general secure multiparty computation in the BGW model. Our main result shows that every functionality can be realized in only four rounds of interaction, and that some functionalities cannot be computed in three rounds. This completely settles the round-complexity of perfect actively-secure optimally-resilient MPC, resolving a long line of research. Our lower-bound is based on a novel round-reduction technique that allows us to lift existing three-round lower-bounds for verifiable secret sharing to four-round lower-bounds for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:08ZZubdj9fEC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2020,"Machine learning tools have illustrated their potential in many significant sectors such as healthcare and finance, to aide in deriving useful inferences. The sensitive and confidential nature of the data, in such sectors, raise natural concerns for the privacy of data. This motivated the area of Privacy-preserving Machine Learning (PPML) where privacy of the data is guaranteed. Typically, ML techniques require large computing power, which leads clients with limited infrastructure to rely on the method of Secure Outsourced Computation (SOC). In SOC setting, the computation is outsourced to a set of specialized and powerful cloud servers and the service is availed on a pay-per-use basis. In this work, we explore PPML techniques in the SOC setting for widely used ML algorithms-- Linear Regression, Logistic Regression, and Neural Networks. We propose BLAZE, a blazing fast PPML framework in the three server setting tolerating one malicious corruption over a ring (\Z{\ell}). BLAZE achieves the stronger security guarantee of fairness (all honest servers get the output whenever the corrupt server obtains the same). Leveraging an input-independent preprocessing phase, BLAZE has a fast input-dependent online phase relying on efficient PPML primitives such as: (i) A dot product protocol for which the communication in the online phase is independent of the vector size, the first of its kind in the three server setting; (ii) A method for truncation that shuns evaluating expensive circuit for Ripple Carry Adders (RCA) and achieves a constant round complexity. This improves over the truncation method of ABY3 (Mohassel et al., CCS 2018) that uses RCA and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:l7t_Zn2s7bgC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2020,"The problem of Byzantine Agreement (BA) is of interest to both the distributed computing and cryptography communities. Following well-known results from distributed computing literature, the BA problem in the asynchronous network setting encounters inevitable non-termination issues. The impasse is overcome via randomization that allows construction of BA protocols in two flavors of termination guarantee—with overwhelming probability and with probability one. The latter type, termed as almost-surely terminating BA, is the main focus of this article. An eluding problem in the domain of almost-surely terminating BA is achieving a constant expected running time. Our primary contribution in this work makes significant progress in this direction.
In a setting with n parties and an adversary with unbounded computing power controlling at most t parties in a Byzantine fashion, we present two almost-surely terminating …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:tOudhMTPpwUC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2020,"We study information-theoretic secure multiparty protocols that achieve full security, including guaranteed output delivery, at the presence of an active adversary that corrupts a constant fraction of the parties. It is known that 2 rounds are insufficient for such protocols even when the adversary corrupts only two parties (Gennaro, Ishai, Kushilevitz, and Rabin; Crypto 2002), and that perfect protocols can be implemented in 3 rounds as long as the adversary corrupts less than a quarter of the parties (Applebaum, Brakerski, and Tsabary; Eurocrypt, 2019). Furthermore, it was recently shown that the quarter threshold is tight for any 3-round perfectly-secure protocol (Applebaum, Kachlon, and Patra; FOCS 2020). Nevertheless, one may still hope to achieve a better-than-quarter threshold at the expense of allowing some negligible correctness errors and/or statistical deviations in the security.
Our main results …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:geHnlv5EZngC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2020,"Privacy-preserving machine learning (PPML) via Secure Multi-party Computation (MPC) has gained momentum in the recent past. Assuming a minimal network of pair-wise private channels, we propose an efficient four-party PPML framework over rings $\Z {\ell} $, FLASH, the first of its kind in the regime of PPML framework, that achieves the strongest security notion of Guaranteed Output Delivery (all parties obtain the output irrespective of adversary's behaviour). The state of the art ML frameworks such as ABY3 by {\em Mohassel et. al}(ACM CCS'18) and SecureNN by {\em Wagh et. al}(PETS'19) operate in the setting of parties with one malicious corruption but achieve the {\em weaker} security guarantee of {\em abort}. We demonstrate PPML with real-time efficiency, using the following custom-made tools that overcome the limitations of the aforementioned state-of-the-art--(a){\em dot product}, which is independent of the vector size unlike the state-of-the-art ABY3, SecureNN and ASTRA by {\em Chaudhari et. al}(ACM CCSW'19), all of which have linear dependence on the vector size.(b){\em Truncation}, which is constant round and free of circuits like Ripple Carry Adder (RCA), unlike ABY3 which uses these circuits and has round complexity of the order of depth of these circuits. We then exhibit the application of our FLASH framework in the secure server-aided prediction of vital algorithms--Linear Regression, Logistic Regression, Deep Neural Networks, and Binarized Neural Networks. We substantiate our theoretical claims through improvement in benchmarks of the aforementioned algorithms when compared with the current best framework ABY3 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:K3LRdlH-MEoC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2019,"Two of the most sought-after properties of Multi-party Computation (MPC) protocols are fairness and guaranteed output delivery (GOD), the latter also referred to as robustness. Achieving both, however, brings in the necessary requirement of malicious-minority. In a generalised adversarial setting where the adversary is allowed to corrupt both actively and passively, the necessary bound for a n-party fair or robust protocol turns out to be , where denote the threshold for active and passive corruption with the latter subsuming the former. Subsuming the malicious-minority as a boundary special case, this setting, denoted as dynamic corruption, opens up a range of possible corruption scenarios for the adversary. While dynamic corruption includes the entire range of thresholds for starting from to , the boundary corruption restricts the adversary only to the boundary cases of  …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:WbkHhVStYXYC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2019,"Oblivious Transfer (OT) is one of the most fundamental cryptographic primitives with wide-spread application in general secure multi-party computation (MPC) as well as in a number of tailored and special-purpose problems of interest such as private set intersection (PSI), private information retrieval (PIR), contract signing to name a few. Often the instantiations of OT require prohibitive communication and computation complexity. OT extension protocols are introduced to compute a very large number of OTs referred to as extended OTs at the cost of a small number of OTs referred to as seed OTs. We present a fast OT extension protocol for small secrets in the active setting. Our protocol when used to produce 1-out-of-n OTs outperforms all the known actively secure OT extensions. Our protocol is built on the semi-honest secure extension protocol of Kolesnikov and Kumaresan of CRYPTO'13 (referred to as KK13 protocol henceforth) which is the best known OT extension for short secrets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:zA6iFVUQeVQC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:evX43VCCuoAC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2019,"The concrete efficiency of secure computation has been the focus of many recent works. In this work, we present concretely-efficient protocols for secure 3-party computation (3PC) over a ring of integers modulo 2ℓ tolerating one corruption, both with semi-honest and malicious security. Owing to the fact that computation over ring emulates computation over the real-world system architectures, secure computation over ring has gained momentum of late.
Cast in the offline-online paradigm, our constructions present the most efficient online phase in concrete terms. In the semi-honest setting, our protocol requires communication of 2 ring elements per multiplication gate during the online phase. In the malicious setting, our protocol requires communication of 4 elements per multiplication gate during the online phase, beating the state-of-the-art protocol by 5 elements. Realized with both the security notions of selective …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:XiSMed-E-HIC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2019,"Secure Multi-party Computation (MPC) with small population and honest majority has drawn focus specifically due to customization in techniques and resulting efficiency that the constructions can offer. In this work, we investigate a wide range of security notions in the five-party setting, tolerating two active corruptions. Being constant-round, our protocols are best suited for real-time, high latency networks such as the Internet. In a minimal setting of pairwise-private channels, we present efficient instantiations with unanimous abort (where either all honest parties obtain the output or none of them do) and fairness (where the adversary obtains its output only if all honest parties also receive it). With the presence of an additional broadcast channel (known to be necessary), we present a construction with guaranteed output delivery (where any adversarial behaviour cannot prevent the honest parties from receiving the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:Tiz5es2fbqcC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2018,"Secure Multi-Party Computation (MPC) with small number of parties is an interesting area of research, primarily due to its ability to model most real-life MPC applications and the simplicity and efficiency of the resulting protocols. In this work, we present efficient, constant-round 3-party (3PC) and 4-party (4PC) protocols in the honest-majority setting that achieve strong security notions of fairness (corrupted parties receive their output only if all honest parties receive output) and guaranteed output delivery (corrupted parties cannot prevent honest parties from receiving their output). Being constant-round, our constructions are suitable for Internet-like high-latency networks and are built from garbled circuits (GC). Assuming the minimal model of pairwise-private channels, we present two protocols that involve computation and communication of a single GC-- (a) a 4-round 3PC with fairness, (b) a 5-round 4PC with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:OU6Ihb5iCvQC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2018,"The problem of Byzantine Agreement (BA) is of interest to both distributed computing and cryptography community. Following well-known results from the distributed computing literature, BA problem in the asynchronous network setting encounters inevitable non-termination issues. The impasse is overcome via randomization that allows construction of BA protocols in two flavours of termination guarantee - with overwhelming probability and with probability one. The latter type termed as almost-surely terminating BAs are the focus of this paper. An eluding problem in the domain of almost-surely terminating BAs is achieving a constant expected running time. Our work makes progress in this direction.
In a setting with n parties and an adversary with unbounded computing power controlling at most t parties in Byzantine fashion, we present two asynchronous almost-surely terminating BA protocols:
With the optimal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:KxtntwgDAa4C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2018,"Perfectly-secure verifiable secret sharing (VSS) and multi-party computation (MPC) protocols in asynchronous network tolerate only at most one-fourth of corruption, while their counterparts in synchronous network sustain against at most one-third corruption. Moreover property-wise, synchronous protocols provide much stronger guarantees than the asynchronous counterparts. Taking note of the fact that asynchronous network is more realistic on one hand and on the other, synchrony of a network has positive impact on several aspects of distributed protocols including properties and fault-tolerance, we explore the power of hybrid networks that combines best of both the worlds by supporting a few synchronous rounds at the onset of a protocol execution, before turning to asynchronous mode. In hybrid networks, we investigate various feasibility questions pertaining to protocols giving guarantees attainable in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:nb7KW1ujOQ8C,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2018,"We settle the exact round complexity of three-party computation (3PC) in honest-majority setting, for a range of security notions such as selective abort, unanimous abort, fairness and guaranteed output delivery. Selective abort security, the weakest in the lot, allows the corrupt parties to selectively deprive some of the honest parties of the output. In the mildly stronger version of unanimous abort, either all or none of the honest parties receive the output. Fairness implies that the corrupted parties receive their output only if all honest parties receive output and lastly, the strongest notion of guaranteed output delivery implies that the corrupted parties cannot prevent honest parties from receiving their output. It is a folklore that the implication holds from the guaranteed output delivery to fairness to unanimous abort to selective abort. We focus on two network settings– pairwise-private channels without and with a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:_Re3VWB3Y0AC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2018,"Fault-tolerant distributed consensus is a fundamental problem in secure distributed computing. In this work, we consider the problem of distributed consensus in directed graphs tolerating crash failures. Tseng and Vaidya (PODC’15) presented necessary and sufficient condition for the existence of consensus protocols in directed graphs. We improve the round and communication complexity of their protocol. Moreover, we prove that our protocol requires the optimal number of communication rounds, required by any protocol belonging to a restricted class of crash-tolerant consensus protocols in directed graphs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:dshw04ExmUIC,https://www.csa.iisc.ac.in/~arpita/
Arpita Patra,"['Cryptography', 'Secure Computation', 'Distributed Computing']",19,1344,2018,"Zero-knowledge (ZK) protocols are undoubtedly among the central primitives in cryptography, lending their power to numerous applications such as secure computation, voting, auctions, and anonymous credentials to name a few. The study of efficient ZK protocols for non-algebraic statements has seen rapid progress in recent times, relying on secure computation techniques. The primary contribution of this work lies in constructing efficient UC-secure constant round ZK protocols from garbled circuits that are secure against adaptive corruptions, with communication linear in the size of the statement. We begin by showing that the practically efficient ZK protocol of Jawurek et al. (CCS 2013) is adaptively secure when the underlying oblivious transfer (OT) satisfies a mild adaptive security guarantee. We gain adaptive security with little to no overhead over the static case. A conditional verification technique is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=RG6kKh8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=RG6kKh8AAAAJ:NhqRSupF_l8C,https://www.csa.iisc.ac.in/~arpita/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2023,A processing apparatus is provided that includes NVRAM and one or more processors configured to process a first set and a second set of instructions according to a hierarchical processing scope and process a scoped persistence barrier residing in the program after the first instruction set and before the second instruction set. The barrier includes an instruction to cause first data to persist in the NVRAM before second data persists in the NVRAM. The first data results from execution of each of the first set of instructions processed according to the one hierarchical processing scope. The second data results from execution of each of the second set of instructions processed according to the one hierarchical processing scope. The processing apparatus also includes a controller configured to cause the first data to persist in the NVRAM before the second data persists in the NVRAM based on the scoped persistence …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:isC4tDSrTZIC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2023,"While the implications of persistent memory (PM) on CPU hardware and software are well-explored, the same is not true for GPUs (Graphics Processing Units). A recent work, GPM, demonstrated how GPU programs can benefit from the fine-grain persistence of PM. However, in the absence of a persistency model, one cannot reason about the correctness of PM-aware GPU programs. Persistency models define the order in which writes to PM are persisted. We explore persistency models for GPUs.
We explore persistency models for GPUs. We demonstrate that CPU persistency models fall short for GPUs. We qualitatively and quantitatively argue that GPU persistency models should support scopes and buffering of writes to PM to leverage parallelism while adapting to higher NVM latencies. We formally specify a GPU persistency model that supports both scopes and buffers. We detail how GPU architecture can …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:SeFeTyx0c_EC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2023,"Secure Two-party Computation (2PC) allows two parties to compute any function on their private inputs without revealing their inputs in the clear to each other. Since 2PC is known to have notoriously high overheads, one of the most popular computation models is that of 2PC with a trusted dealer, where a trusted dealer provides correlated randomness (independent of any input) to both parties during a preprocessing phase. Recent works construct efficient 2PC protocols in this model based on the cryptographic technique of function secret sharing (FSS). We build an end-to-end system Orca to accelerate the computation of FSS-based 2PC protocols with GPUs. Next, we observe that the main performance bottleneck in such accelerated protocols is in storage (due to the large amount of correlated randomness), and we design new FSS-based 2PC cryptographic protocols for several key functionalities in ML which reduce storage by up to . Compared to prior state-of-the-art on secure training accelerated with GPUs in the same computation model (Piranha, Usenix Security 2022), we show that Orca has higher accuracy, lesser communication, and is faster on CIFAR-10.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:ZHo1McVdvXMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2022,"Multi-Chip Module (MCM) designs have emerged as a key technique to scale up a GPU’s compute capabilities in the face of slowing transistor technology. However, the disaggregated nature of MCM GPUs with many chiplets connected via in-package interconnects leads to non-uniformity. We explore the implications of MCM’s non-uniformity on the GPU’s virtual memory. We quantitatively demonstrate that an MCM-aware virtual memory system should aim to 1 leverage aggregate TLB capacity across chiplets while limiting accesses to L2 TLB on remote chiplets, 2 reduce accesses to page table entries resident on a remote chiplet’s memory during page walks. We propose MCM-aware GPU virtual memory (MGvm) that leverages static analysis techniques, previously used for thread and data placement, to map virtual addresses to chiplets and to place the page tables. At runtime, MGvm balances its objective of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:HoB7MX3m0LUC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2022,"Systems, apparatuses, and methods for enforcing processor quality of service guarantees when servicing system service requests (SSRs) are disclosed. A system includes a first processor executing an operating system and a second processor executing an application which generates SSRs for the first processor to service. The first processor monitors the number of cycles spent servicing SSRs over a previous time interval, and if this number of cycles is above a threshold, the first processor starts delaying the servicing of subsequent SSRs. In one implementation, if the previous delay was non-zero, the first processor increases the delay used in the servicing of subsequent SSRs. If the number of cycles is less than or equal to the threshold, then the first processor services SSRs without delay. As the delay is increased, the second processor begins to stall and its SSR generation rate falls, reducing the load on the first …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:pqnbT2bcN3wC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2022,"Systems, apparatuses, and methods for enforcing processor quality of service guarantees when servicing system service requests (SSRs) are disclosed. A system includes a first processor executing an operating system and a second processor executing an application which generates SSRs for the first processor to service. The first processor monitors the number of cycles spent servicing SSRs over a previous time interval, and if this number of cycles is above a threshold, the first processor starts delaying the servicing of subsequent SSRs. In one implementation, if the previous delay was non-zero, the first processor increases the delay used in the servicing of subsequent SSRs. If the number of cycles is less than or equal to the threshold, then the first processor services SSRs without delay. As the delay is increased, the second processor begins to stall and its SSR generation rate falls, reducing the load on the first …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:M3NEmzRMIkIC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2022,"The GPU is a key computing platform for many application domains. While the new non-volatile memory technology has brought the promise of byte-addressable persistence (a.k.a., persistent memory, or PM) to CPU applications, the same, unfortunately, is beyond the reach of GPU programs.
We take three key steps toward enabling GPU programs to access PM directly. First, enable direct access to PM from within a GPU kernel without needing to modify the hardware. Next, we demonstrate three classes of GPU-accelerated applications that benefit from PM. In the process, we create a workload suite with nine such applications. We then create a GPU library, written in CUDA, to support logging, checkpointing, and primitives for native persistence for programmers to easily leverage PM.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:ldfaerwXgEUC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"Newer use cases of GPU (Graphics Processing Unit) computing, e.g., graph analytics, look less like traditional bulk-synchronous GPU programs. To cater to the needs of emerging applications with semantically richer and finer grain sharing patterns, GPU vendors have been introducing advanced programming features, e.g., scoped synchronization and independent thread scheduling. While these features can speed up many applications and enable newer use cases, they can also introduce subtle synchronization errors if used incorrectly.
We present iGUARD, a runtime software tool to detect races in GPU programs due to incorrect use of such advanced features. A key need for a race detector to be practical is to accurately detect races at reasonable overheads. We thus perform the race detection on the GPU itself without relying on the CPU. The GPU's parallelism helps speed up race detection by 15x over a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:2P1L_qKh6hAC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"Intel and AMD processors have long supported more than one large page sizes – 1GB and 2MB, to reduce address translation overheads for applications with large memory footprints. However, previous works on large pages have primarily focused on 2MB pages, partly due to a lack of evidence on the usefulness of 1GB pages to real-world applications. Consequently, micro-architectural resources devoted to 1GB pages have gone underutilized for a decade.
We quantitatively demonstrate where 1GB pages can be valuable, especially when employed in conjunction with 2MB pages. Unfortunately, the lack of application-transparent dynamic allocation of 1GB pages is to blame for the under-utilization of 1GB pages on today’s systems. Toward this, we design and implement Trident in Linux to fully harness micro-architectural resources devoted for all page sizes in the current x86 hardware by transparently allocating …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:vV6vV6tmYwMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"A data processing system includes a memory, a group of input/output (I/O) devices, an input/output memory management unit (IOMMU). The IOMMU is connected to the memory and adapted to allocate a hardware resource from among a group of hardware resources to receive an address translation request for a memory access from an I/O device. The IOMMU detects address translation requests from the plurality of I/O devices. The IOMMU reorders the address translation requests such that an order of dispatching an address translation request is based on a policy associated with the I/O device that is requesting the memory access. The IOMMU selectively allocates a hardware resource to the input/output device, based on the policy that is associated with the I/O device in response to the reordering.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:blknAaTinKkC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"Various messaging systems and methods are disclosed for meeting invitation management. In one aspect, a method of messaging is provided that includes generating a message to invite one or more invitees to a meeting. The message includes an assertion to suppress an auto-responder of the one or more invitees. The message is sent to the one or more invitees. The assertion suppresses the auto-responder of the one or more invitees.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:ZeXyd9-uunAC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"An operating system has many memory management goals including reducing memory access latency, and reducing memory footprint. These goals can conflict with each other when independent subsystems optimize them in silos. In this work, we report one such conflict that appears between memory de-duplication and NUMA (non-uniform memory access) management. Linux's memory de-duplication subsystem, namely KSM, is NUMA unaware. Consequently, while de-duplicating pages across NUMA nodes, it can place de-duplicated pages in a manner that can lead to significant performance variations, unfairness, and subvert process priority. Toward this, we introduce NUMA-aware KSM, a.k.a., nuKSM, that makes judicious decisions about the placement of de-duplicated pages to reduce the impact of NUMA, unfairness, and avoid priority subversion. Independent of the NUMA effects, we observed that KSM …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:70eg2SAEIzsC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"In FaaS workflows, a set of functions implement application logic by interacting and exchanging data among themselves. Contemporary FaaS platforms execute each function of a workflow in separate containers. When functions in a workflow interact, the resulting latency slows execution. Faastlane minimizes function interaction latency by striving to execute functions of a workflow as threads within a single process of a container instance, which eases data sharing via simple load/store instructions. For FaaS workflows that operate on sensitive data, Faastlane provides lightweight thread-level isolation domains using Intel Memory Protection Keys (MPK). While threads ease sharing, implementations of languages such as Python and Node. js (widely used in FaaS applications) disallow concurrent execution of threads. Faastlane dynamically identifies opportunities for parallelism in FaaS workflows and fork processes (instead of threads) or spawns new container instances to concurrently execute parallel functions of a workflow. We implemented Faastlane atop Apache OpenWhisk and show that it accelerates workflow instances by up to 15×, and reduces function interaction latency by up to 99.95% compared to OpenWhisk.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:lSLTfruPkqcC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"GPUs are now commonly available in most modern computing platforms. They are increasingly being adopted in cloud platforms and data centers due to their immense computing capability. In response to this growth in usage, manufacturers continuously try to improve GPU hardware by adding new features. However, this increase in usage and the addition of utility-improving features can create new, unexpected attack channels. In this paper, we show that two such features-unified virtual memory (UVM) and multi-process service (MPS)-primarily introduced to improve the programmability and efficiency of GPU kernels have an unexpected consequence-that of creating a novel covert-timing channel via the GPU's translation lookaside buffer (TLB) hierarchy. To enable this covert channel, we first perform experiments to understand the characteristics of TLBs present on a GPU. The use of UVM allows fine-grained …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:RYcK_YlVTxYC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"A method for preventing a side channel attack by executing an enclave on a remote computing device. The method comprises configuring the enclave based on configuration parameters defined by a computing device. A page created in first enclave cache memory in the remote computing device and adding virtual page address information and page security attributes corresponding to the page in a second enclave cache memory, and an encrypted log entry is created in a protected memory of the remote computing device. The enclave is initiated by comparing the log entry and a second hash key generated by the remote computing device. A new page of pre-defined size is dynamically added to the first enclave cache memory after initiation of the enclave. The enclave is executed based on a successful validation of a size of the page created in first enclave cache memory to be equal to the pre-defined page size.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:J_g5lzvAfSwC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"Increasing heterogeneity in the memory system mandates careful data placement to hide the non-uniform memory access (NUMA) effects on applications. However, NUMA optimizations have predominantly focused on application data in the past decades, largely ignoring the placement of kernel data structures due to their small memory footprint; this is evident in typical OS designs that pin kernel objects in memory. In this paper, we show that careful placement of kernel data structures is gaining importance in the context of page-tables: sub-optimal placement of page-tables causes severe slowdown (up to 3.1x) on virtualized NUMA servers.
In response, we present vMitosis -- a system for explicit management of two-level page-tables, i.e., the guest and extended page-tables, on virtualized NUMA servers. vMitosis enables faster address translation by migrating and replicating page-tables. It supports two prevalent …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:NaGl4SEjCO4C,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"The last level TLB (LLT) and the last level cache (LLC) play a critical role in the overall performance of memory-intensive applications. While management of LLC content has received significant attention, the same may not be true for LLT. In this work, we first explore the well-known concept of dead blocks in caches for TLBs. We find that dead pages are fairly common in the LLT. Different from dead blocks in LLCs, dead pages in LLTs are most often dead-on-arrival, i.e., they produce zero hits in the TLB. We design a storage-efficient dead page predictor that works with a fraction of storage compared to typical dead block predictors. This is important since an LLT itself requires only a few KBs of storage compared to MBs in LLC. We then leverage the dead page information to guide a simple dead block predictor in LLC. This is driven by the observation that dead blocks are often concentrated within dead pages. In …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:ns9cj8rnVeAC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2021,"GPU (Graphics Processing Unit) architecture has evolved to accelerate parts of a single application at a time. Consequently, several aspects of its architecture, particularly the virtual memory, have embraced a shared-mostly design. This implicitly assumes that a single application and, thus, one address space is resident in the GPU at a time. However, recent trends, e.g., deployment of GPUs in the cloud, necessitate efficient multi-tenancy. Multi-tenancy is needed for sharing the physical resources of a large server-class GPU across multiple concurrent tenants (applications) for resource consolidation while ensuring fairness among the tenants.We first quantify how different components of GPU's virtual memory can impede multi-tenancy. We show that shared page walkers are a key bottleneck under multi-tenancy. We, therefore, propose dynamic page walk stealing that enables soft partitioning of the shared pool of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:O3NaXMp0MMsC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2020,"Intel’s SGX architecture offers clients of public cloud computing platforms the ability to create hardware-protected enclaves whose contents are protected from privileged system software. However, SGX relies on system software for enclave memory management. In a sequence of recent papers, researchers have demonstrated that this reliance allows a malicious OS/hypervisor to snoop on the page addresses being accessed from within an enclave via various channels. This page address stream can then be used to infer secrets if the enclave’s page access pattern depends upon the secret and this constitutes an important class of side-channels.
We propose SGXL, a hardware-software co-designed system that significantly increases the difficulty of any page address-based side-channels through the use of large pages. A large page maps address ranges at a much larger granularity than the default page size (at …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:RGFaLdJalmkC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2020,"Large pages are commonly deployed to reduce address translation overheads for big-memory workloads. Modern x86-64 processors from Intel and AMD support two large page sizes -- 1GB and 2MB. However, previous works on large pages have primarily focused on 2MB pages, partly due to lack of substantial evidence on the profitability of 1GB pages to real-world applications. We argue that in fact, inadequate system software support is responsible for a decade of underutilized hardware support for 1GB pages. Through extensive experimentation on a real system, we demonstrate that 1GB pages can improve performance over 2MB pages, and when used in tandem with 2MB pages for an important set of applications; the support for the latter is crucial but missing in current systems. Our design and implementation of \trident{} in Linux fully exploit hardware supported large pages by dynamically and transparently allocating 1GB, 2MB, and 4KB pages as deemed suitable. \trident{} speeds up eight memory-intensive applications by {}, on average, over Linux's use of 2MB pages. We also propose \tridentpv{}, an extension to \trident{} that effectively virtualizes 1GB pages via copy-less promotion and compaction in the guest OS. Overall, this paper shows that even GB-sized pages have considerable practical significance with adequate software enablement, in turn motivating architects to continue investing/innovating in large pages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:YFjsv_pBGBYC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2020,"Large pages are commonly deployed to reduce address translation overheads for big-memory workloads. Modern x86-64 processors from Intel and AMD support two large page sizes--1GB and 2MB. However, previous works on large pages have primarily focused on 2MB pages, partly due to lack of substantial evidence on the profitability of 1GB pages to real-world applications. We argue that in fact, inadequate system software support is responsible for a decade of underutilized hardware support for 1GB pages. Through extensive experimentation on a real system, we demonstrate that 1GB pages can improve performance over 2MB pages, and when used in tandem with 2MB pages for an important set of applications; the support for the latter is crucial but missing in current systems. Our design and implementation of\trident {} in Linux fully exploit hardware supported large pages by dynamically and transparently …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:BqipwSGYUEgC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2020,"GPUs have emerged as a key computing platform for an ever-growing range of applications. Unlike traditional bulk-synchronous GPU programs, many emerging GPU-accelerated applications, such as graph processing, have irregular interaction among the concurrent threads. Consequently, they need complex synchronization. To enable both high performance and adequate synchronization, GPU vendors have introduced scoped synchronization operations that allow a programmer to synchronize within a subset of concurrent threads (a.k. a., scope) that she deems adequate. Scoped-synchronization avoids the performance overhead of synchronization across thousands of GPU threads while ensuring correctness when used appropriately. This flexibility, however, could be a new source of incorrect synchronization where a race can occur due to insufficient scope of the synchronization operation, and not due to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:hMod-77fHWUC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2020,"A method and processing apparatus for accelerating program processing is provided that includes a plurality of processors configured to process a plurality of tasks of a program and a controller. The controller is configured to determine, from the plurality of tasks being processed by the plurality of processors, a task being processed on a first processor to be a lagging task causing a delay in execution of one or more other tasks of the plurality of tasks. The controller is further configured to provide the determined lagging task to a second processor to be executed by the second processor to accelerate execution of the lagging task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:qxL8FJ1GzNcC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2020,"An operating system (OS) of a processing system having a plurality of processor cores determines a cost associated with different mechanisms for performing a translation lookaside buffer (TLB) shootdown in response to, for example, a virtual address being remapped to a new physical address, and selects a TLB shootdown mechanism to purge outdated or invalid address translations from the TLB based on the determined cost. In some embodiments, the OS selects an inter-processor interrupt (IPI) as the TLB shootdown mechanism if the cost associated with sending an IPI is less than a threshold cost. In some embodiments, the OS compares the cost of using an IPI as the TLB shootdown mechanism versus the cost of sending a hardware broadcast to all processor cores of the processing system as the shootdown mechanism and selects the shootdown mechanism having the lower cost.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:JV2RwH3_ST0C,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2020,"On public cloud computing platforms, cloud providers own and administer the system software (eg, the BIOS, the OS, and/or the hypervisor) that manages the computing infrastructure. A malicious actor can leverage this system software to compromise the integrity and confidentiality of data and code of the clients of public computing infrastructures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:NMxIlDl6LWMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2019,"The present disclosure is directed to techniques for migrating data between heterogeneous memories in a computing system. More specifically, the techniques involve migrating data between a memory having better access characteristics (eg, lower latency but greater capacity) and a memory having worse access characteristics (eg, higher latency but lower capacity). Migrations occur with a variable migration granularity. A migration granularity specifies a number of memory pages, having virtual addresses that are contiguous in virtual address space, that are migrated in a single migration operation. A history-based technique that adjusts migration granularity based on the history of memory utilization by an application is provided. A profiling-based technique that adjusts migration granularity based on a profiling operation is also provided.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:hC7cP41nSMkC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2019,"A data processing system includes a memory and an input output memory management unit that is connected to the memory. The input output memory management unit is adapted to receive batches of address translation requests. The input output memory management unit has instructions that identify, from among the batches of address translation requests, a later batch having a lower number of memory access requests than an earlier batch, and selectively schedules access to a page table walker for each address translation request of a batch.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:TFP_iSt0sucC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2019,A processing apparatus is provided that includes NVRAM and one or more processors configured to process a first set and a second set of instructions according to a hierarchical processing scope and process a scoped persistence barrier residing in the program after the first instruction set and before the second instruction set. The barrier includes an instruction to cause first data to persist in the NVRAM before second data persists in the NVRAM. The first data results from execution of each of the first set of instructions processed according to the one hierarchical processing scope. The second data results from execution of each of the second set of instructions processed according to the one hierarchical processing scope. The processing apparatus also includes a controller configured to cause the first data to persist in the NVRAM before the second data persists in the NVRAM based on the scoped persistence …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:maZDTaKrznsC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2019,A processing apparatus is provided that includes NVRAM and one or more processors configured to process a first set and a second set of instructions according to a hierarchical processing scope and process a scoped persistence barrier residing in the program after the first instruction set and before the second instruction set. The barrier includes an instruction to cause first data to persist in the NVRAM before second data persists in the NVRAM. The first data results from execution of each of the first set of instructions processed according to the one hierarchical processing scope. The second data results from execution of each of the second set of instructions processed according to the one hierarchical processing scope. The processing apparatus also includes a controller configured to cause the first data to persist in the NVRAM before the second data persists in the NVRAM based on the scoped persistence …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:mVmsd5A6BfQC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2019,"Cluster manager functional blocks perform operations for migrating pages in portions in corresponding migration clusters. During operation, each cluster manager keeps an access record that includes information indicating accesses of pages in the portions in the corresponding migration cluster. Based on the access record and one or more migration policies, each cluster manager migrates pages between the portions in the corresponding migration cluster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:bEWYMUwI8FkC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2019,"Cluster manager functional blocks perform operations for migrating pages in portions in corresponding migration clusters. During operation, each cluster manager keeps an access record that includes information indicating accesses of pages in the portions in the corresponding migration cluster. Based on the access record and one or more migration policies, each cluster manager migrates pages between the portions in the corresponding migration cluster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:dhFuZR0502QC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2019,"The described embodiments include a computing device with two or more translation lookaside buffers (TLB). During operation, the computing device updates an entry in the TLB based on a virtual address to physical address translation and metadata from a page table entry that were acquired during a page table walk. The computing device then computes, based on a lease length expression, a lease length for the entry in the TLB. Next, the computing device sets, for the entry in the TLB, a lease value to the lease length, wherein the lease value represents a time until a lease for the entry in the TLB expires, wherein the entry in the TLB is invalid when the associated lease has expired. The computing device then uses the lease value to control operations that are allowed to be performed using information from the entry in the TLB.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:k_IJM867U9cC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"Recent studies on commercial hardware demonstrated that irregular GPU workloads could bottleneck on virtual-to-physical address translations. GPU's single-instruction multiple-thread (SIMT) execution can generate many concurrent memory accesses, all of which require address translation before accesses can complete. Unfortunately, many of these address translation requests often miss in the TLB, generating many concurrent page table walks. In this work, we investigate how to reduce address translation overheads for such applications. We observe that many of these concurrent page walk requests, while irregular from the perspective of a single GPU wavefront, still fall on neighboring virtual page addresses. The address mappings for these neighboring pages are typically stored in the same 64-byte cache line. Since cache lines are the smallest granularity of memory access, the page table walker implicitly …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:-f6ydRqryjwC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"Heterogeneous systems combine general-purpose CPUs with domain-specific accelerators like GPUs. Recent heterogeneous system designs have enabled GPUs to request OS services, but the domain-specific nature of accelerators means that they must rely on the CPUs to handle these requests. Such system service requests can unintentionally harm the performance of unrelated CPU applications. Tests on a real heterogeneous processor demonstrate that GPU system service requests can degrade contemporaneous CPU application performance by up to 44% and can reduce energy efficiency by limiting CPU sleep time. The reliance on busy CPU cores to perform the system services can also slow down GPU work by up to 18%. This new form of interference is found only in accelerator-rich heterogeneous designs and may be exacerbated in future systems with more accelerators. We explore mitigation strategies from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:IWHjjKOFINEC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"The described embodiments include a computing device with two or more translation lookaside buffers (TLB) that performs operations for handling entries in the TLBs. During operation, the computing device maintains lease values for entries in the TLBs, the lease values representing times until leases for the entries expire, wherein a given entry in the TLB is invalid when the associated lease has expired. The computing device uses the lease value to control operations that are allowed to be performed using information from the entries in the TLBs. In addition, the computing device maintains, in a page table, longest lease values for page table entries indicating when corresponding longest leases for entries in TLBs expire. The longest lease values are used to determine when and if a TLB shootdown is to be performed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:HDshCWvjkbEC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:qUcmZB5y_30C,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"The described embodiments include a computing device with two or more translation lookaside buffers (TLB) that performs operations for handling entries in the TLBs. During operation, the computing device maintains lease values for entries in the TLBs, the lease values representing times until leases for the entries expire, wherein a given entry in the TLB is invalid when the associated lease has expired. The computing device uses the lease value to control operations that are allowed to be performed using information from the entries in the TLBs. In addition, the computing device maintains, in a page table, longest lease values for page table entries indicating when corresponding longest leases for entries in TLBs expire. The longest lease values are used to determine when and if a TLB shootdown is to be performed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:_kc_bZDykSQC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"The described embodiments include a computing device with two or more types of processors and a memory that is shared between the two or more types of processors. The computing device performs operations for handling cache coherency between the two or more types of processors. During operation, the computing device sets a cache coherency indicator in metadata in a page table entry in a page table, the page table entry information about a page of data that is stored in the memory. The computing device then uses the cache coherency indicator to determine operations to be performed when accessing data in the page of data in the memory. For example, the computing device can use the coherency indicator to determine whether a coherency operation is to be performed when a processor of a given type accesses data in the page of data in the memory.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:R3hNpaxXUhUC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:TQgYirikUcIC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:mB3voiENLucC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"The described embodiments include a computing device with two or more types of processors and a memory that is shared between the two or more types of processors. The computing device performs operations for handling cache coherency between the two or more types of processors. During operation, the computing device sets a cache coherency indicator in metadata in a page table entry in a page table, the page table entry information about a page of data that is stored in the memory. The computing device then uses the cache coherency indicator to determine operations to be performed when accessing data in the page of data in the memory. For example, the computing device can use the coherency indicator to determine whether a coherency operation is to be performed when a processor of a given type accesses data in the page of data in the memory.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:4DMP91E08xMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"Memory is becoming increasingly heterogeneous with the emergence of disparate memory technologies ranging from non-volatile memories like PCM, STT-RAM, and memristors to 3D-stacked memories like HBM. In such systems, data is of ten migrated across memory regions backed by different technologies for better overall performance. An effective migration mechanism is a prerequisite in such systems.
Prior works on OS-directed page migration have focused on what data to migrate and/or on when to migrate. In this work, we demonstrate the need to investigate another dimension -- how much to migrate. Specifically, we show that the amount of data migrated in a single migration operation (called ""migration granularity"") is vital to the overall performance. Through analysis on real hardware, we further show that different applications benefit from different migration granularities, owing to their distinct memory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:L8Ckcad2t8MC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"GPUs are becoming first-class compute citizens and increasingly support programmability-enhancing features such as shared virtual memory and hardware cache coherence. This enables them to run a wider variety of programs. However, a key aspect of general-purpose programming where GPUs still have room for improvement is the ability to invoke system calls. We explore how to directly invoke system calls from GPUs. We examine how system calls can be integrated with GPGPU programming models, where thousands of threads are organized in a hierarchy of execution groups. To answer questions on GPU system call usage and efficiency, we implement Genesys, a generic GPU system call interface for Linux. Numerous architectural and OS issues are considered and subtle changes to Linux are necessary, as the existing kernel assumes that only CPUs invoke system calls. We assess the performance of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:e5wmG9Sq2KIC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"GPUs are becoming first-class compute citizens and increasingly support programmability-enhancing features such as shared virtual memory and hardware cache coherence. This enables them to run a wider variety of programs. However, a key aspect of general-purpose programming where GPUs still have room for improvement is the ability to invoke system calls. We explore how to directly invoke system calls from GPUs. We examine how system calls can be integrated with GPGPU programming models, where thousands of threads are organized in a hierarchy of execution groups. To answer questions on GPU system call usage and efficiency, we implement Genesys, a generic GPU system call interface for Linux. Numerous architectural and OS issues are considered and subtle changes to Linux are necessary, as the existing kernel assumes that only CPUs invoke system calls. We assess the performance of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:hFOr9nPyWt4C,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"Recent studies on commercial hardware demonstrated that irregular GPU applications can bottleneck on virtual-to-physical address translations. In this work, we explore ways to reduce address translation overheads for such applications. We discover that the order of servicing GPU's address translation requests (specifically, page table walks) plays a key role in determining the amount of translation overhead experienced by an application. We find that different SIMD instructions executed by an application require vastly different amounts of work to service their address translation needs, primarily depending upon the number of distinct pages they access. We show that better forward progress is achieved by prioritizing translation requests from the instructions that require less work to service their address translation needs. Further, in the GPU's Single-Instruction-Multiple-Thread (SIMT) execution paradigm, all …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:QIV2ME_5wuYC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,A method and apparatus for performing inter-lane power management includes de-energizing one or more execution lanes upon a determination that the one or more execution lanes are to be predicated. Energy from the predicated execution lanes is redistributed to one or more active execution lanes.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:4JMBOYKVnBMC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,A method and apparatus for performing inter-lane power management includes de-energizing one or more execution lanes upon a determination that the one or more execution lanes are to be predicated. Energy from the predicated execution lanes is redistributed to one or more active execution lanes.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:Zph67rFs4hoC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"Techniques described herein improve processor performance in situations where a large number of system service requests are being received from other devices. More specifically, upon detecting that certain operating conditions that indicate a processor slowdown are present, the processor performs one or more system service adjustment techniques. These techniques include throttling (reducing the rate of handling) of such requests, coalescing (grouping multiple requests into a single group) the requests, disabling microarchitctural structures (such as caches or branch prediction units) or updates to those structures, and prefetching data for or pre-performing these requests. Each of these adjustment techniques helps to reduce the number of and/or workload associated with servicing requests for system services.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:7PzlFSSx8tAC,http://www.csa.iisc.ac.in/~arkapravab/
Arkaprava Basu,"['Computer Architecture', 'OS-hardware interactions', 'GPU runtimes']",15,3924,2018,"Two key trends in computing are evident --- emergence of GPU as a first-class compute element and emergence of byte-addressable nonvolatile memory technologies (NVRAM) as DRAM-supplement. GPUs and NVRAMs are likely to coexist in future systems. However, previous works have either focused on GPUs or on NVRAMs, in isolation. In this work, we investigate the enhancements necessary for a GPU to efficiently and correctly manipulate NVRAM-resident persistent data structures.
Specifically, we find that previously proposed CPU-centric persist barriers fall short for GPUs. We thus introduce the concept of scoped persist barriers that aligns with the hierarchical programming framework of GPUs. Scoped persist barriers enable GPU programmers to express which execution group (a.k.a., scope) a given persist barrier applies to. We demonstrate that: 1 use of narrower scope than algorithmically-required can …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=pL5B4ywAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=pL5B4ywAAAAJ:Wp0gIr-vW9MC,http://www.csa.iisc.ac.in/~arkapravab/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2023,"We study the problem of dividing indivisible chores among agents whose costs (for the chores) are supermodular set functions with binary marginals. Such functions capture complementarity among chores, i.e., they constitute an expressive class wherein the marginal disutility of each chore is either one or zero, and the marginals increase with respect to supersets. In this setting, we study the broad landscape of finding fair and efficient chore allocations. In particular, we establish the existence of EF1 and Pareto efficient chore allocations, MMS-fair and Pareto efficient allocations, and Lorenz dominating chore allocations. Furthermore, we develop polynomial-time algorithms--in the value oracle model--for computing the chore allocations for each of these fairness and efficiency criteria. Complementing these existential and algorithmic results, we show that in this chore division setting, the aforementioned fairness notions, namely EF1, MMS, and Lorenz domination are incomparable: an allocation that satisfies any one of these notions does not necessarily satisfy the others. Additionally, we study EFX chore division. In contrast to the above-mentioned positive results, we show that, for binary supermodular costs, Pareto efficient allocations that are even approximately EFX do not exist, for any arbitrarily small approximation constant. Focusing on EFX fairness alone, when the cost functions are identical we present an algorithm (Add-and-Fix) that computes an EFX allocation. For binary marginals, we show that Add-and-Fix runs in polynomial time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:CHSYGLWDkRkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2022,"We study coverage problems in which, for a set of agents and a given threshold T, the goal is to select T subsets (of the agents) that, while satisfying combinatorial constraints, achieve fair and efficient coverage among the agents. In this setting, the valuation of each agent is equated to the number of selected subsets that contain it, plus one. The current work utilizes the Nash social welfare function to quantify the extent of fairness and collective efficiency. We develop a polynomial-time \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\left( 18 + o(1) \right) $$\end{document}-approximation algorithm for maximizing Nash social welfare in coverage instances. Our algorithm applies to all instances …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:bFI3QPDXJZMC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2022,"Cake cutting is a classic model for studying fair division of a heterogeneous, divisible resource among agents with individual preferences. Addressing cake division under a typical requirement that each agent must receive a connected piece of the cake, we develop approximation algorithms for finding envy-free (fair) cake divisions. In particular, this work improves the state-of-the-art additive approximation bound for this fundamental problem. Our results hold for general cake division instances in which the agents' valuations satisfy basic assumptions and are normalized (to have value for the cake). Furthermore, the developed algorithms execute in polynomial time under the standard Robertson-Webb query model. Prior work has shown that one can efficiently compute a cake division (with connected pieces) in which the additive envy of any agent is at most . An efficient algorithm is also known for finding connected cake divisions that are (almost) -multiplicatively envy-free. Improving the additive approximation guarantee and maintaining the multiplicative one, we develop a polynomial-time algorithm that computes a connected cake division that is both -additively envy-free and -multiplicatively envy-free. Our algorithm is based on the ideas of interval growing and envy-cycle-elimination. In addition, we study cake division instances in which the number of distinct valuations across the agents is parametrically bounded. We show that such cake division instances admit a fully polynomial-time approximation scheme for connected envy-free cake division.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:abG-DnoFyZgC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2022,"We study the fair allocation of indivisible goods among agents with identical, additive valuations but individual budget constraints. Here, the indivisible goods--each with a specific size and value--need to be allocated such that the bundle assigned to each agent is of total size at most the agent's budget. Since envy-free allocations do not necessarily exist in the indivisible goods context, compelling relaxations--in particular, the notion of envy-freeness up to goods (EFk)--have received significant attention in recent years. In an EFk allocation, each agent prefers its own bundle over that of any other agent, up to the removal of goods, and the agents have similarly bounded envy against the charity (which corresponds to the set of all unallocated goods). Recently, Wu et al. (2021) showed that an allocation that satisfies the budget constraints and maximizes the Nash social welfare is -approximately EF1. However, the computation (or even existence) of exact EFk allocations remained an intriguing open problem. We make notable progress towards this by proposing a simple, greedy, polynomial-time algorithm that computes EF2 allocations under budget constraints. Our algorithmic result implies the universal existence of EF2 allocations in this fair division context. The analysis of the algorithm exploits intricate structural properties of envy-freeness. Interestingly, the same algorithm also provides EF1 guarantees for important special cases. Specifically, we settle the existence of EF1 allocations for instances in which: (i) the value of each good is proportional to its size, (ii) all goods have the same size, or (iii) all the goods have the same value. Our EF2 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:b0M2c_1WBrUC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2022,"We study the problem of fair rent division that entails splitting the rent and allocating the rooms of an apartment among agents in a fair manner (i.e., under the imposed rents, no agent has a strictly stronger preference for any other agent’s room). The utility functions specify the cardinal preferences of the agents for the rooms for every possible room rent. Although envy-free solutions are guaranteed to exist under reasonably general utility functions, efficient algorithms for finding them were known only for quasilinear utilities. This work addresses this notable gap and develops a fully polynomial-time approximation scheme for fair rent division with minimal assumptions on the utility functions. Envy-free solutions correspond to equilibria of a two-sided matching market with monetary transfers; hence, this work also provides efficient algorithms for finding approximate equilibria in such markets. We complement the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:RHpTSmoSYBkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2022,"We study the problem of allocating indivisible goods among strategic agents. We focus on settings wherein monetary transfers are not available and each agent's private valuation is a submodular function with binary marginals, ie, the agents' valuations are matroid-rank functions. In this setup, we establish a notable dichotomy between two of the most well-studied fairness notions in discrete fair division; specifically, between envy-freeness up to one good (EF1) and maximin shares (MMS). First, we show that a known Pareto-efficient mechanism is group strategy-proof for finding EF1 allocations, under matroid-rank valuations. The group strategy-proofness guarantee strengthens an existing result that establishes truthfulness (individually for each agent) in the same context. Our result also generalizes prior work from binary additive valuations to the matroid-rank case. Next, we establish that an analogous positive result cannot be achieved for MMS, even when considering truthfulness on an individual level. Specifically, we prove that, for matroid-rank valuations, there does not exist a truthful mechanism that is index oblivious, Pareto efficient, and maximin fair. For establishing our results, we develop a characterization of truthful mechanisms for matroid-rank functions. This characterization in fact holds for a broader class of valuations (specifically, holds for binary XOS functions) and might be of independent interest.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:g5m5HwL7SMYC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2022,"We study fair and efficient allocation of divisible goods, in an online manner, among n agents. The goods arrive online in a sequence of T time periods. The agents' values for a good are revealed only after its arrival, and the online algorithm needs to fractionally allocate the good, immediately and irrevocably, among the agents. Towards a unifying treatment of fairness and economic efficiency objectives, we develop an algorithmic framework for finding online allocations to maximize the generalized mean of the values received by the agents. In particular, working with the assumption that each agent's value for the grand bundle of goods is appropriately scaled, we address online maximization of p-mean welfare. Parameterized by an exponent term p in (-infty, 1], these means encapsulate a range of welfare functions, including social welfare (p= 1), egalitarian welfare (p to-infty), and Nash social welfare (p to 0). We present a simple algorithmic template that takes a threshold as input and, with judicious choices for this threshold, leads to both universal and tailored competitive guarantees. First, we show that one can compute online a single allocation that O (sqrt (n) log n)-approximates the optimal p-mean welfare for all p<= 1. The existence of such a universal allocation is interesting in and of itself. Moreover, this universal guarantee achieves essentially tight competitive ratios for specific values of p. Next, we obtain improved competitive ratios for different ranges of p by executing our algorithm with p-specific thresholds, eg, we provide O (log^ 3 n)-competitive ratio for all p in (-1/(log 2n), 1). We complement our positive results by establishing lower …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:M05iB0D1s5AC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2022,"We extend the notion of regret with a welfarist perspective. Focussing on the classic multi-armed bandit (MAB) framework, the current work quantifies the performance of bandit algorithms by applying a fundamental welfare function, namely the Nash social welfare (NSW) function. This corresponds to equating algorithm's performance to the geometric mean of its expected rewards and leads us to the study of Nash regret, defined as the difference between the -- a priori unknown -- optimal mean (among the arms) and the algorithm's performance. Since NSW is known to satisfy fairness axioms, our approach complements the utilitarian considerations of average (cumulative) regret, wherein the algorithm is evaluated via the arithmetic mean of its expected rewards. This work develops an algorithm that, given the horizon of play , achieves a Nash regret of , here denotes the number of arms in the MAB instance. Since, for any algorithm, the Nash regret is at least as much as its average regret (the AM-GM inequality), the known lower bound on average regret holds for Nash regret as well. Therefore, our Nash regret guarantee is essentially tight. In addition, we develop an anytime algorithm with a Nash regret guarantee of .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:pyW8ca7W8N0C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2022,"We study the problem of allocating indivisible goods among agents in a fair and economically efficient manner. In this context, the Nash social welfare—defined as the geometric mean of agents’ valuations for their assigned bundles—stands as a fundamental measure that quantifies the extent of fairness of an allocation. Focusing on instances in which the agents’ valuations have binary marginals, we develop essentially tight results for (approximately) maximizing Nash social welfare under two of the most general classes of complement-free valuations, i.e., under binary and binary subadditive valuations.
For binary valuations, we develop a polynomial-time algorithm that finds a constant-factor (specifically ) approximation for the optimal Nash social welfare, in the standard value-oracle model. The allocations computed by our algorithm also achieve constant-factor approximation for social welfare and the groupwise …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:ldfaerwXgEUC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2022,"We study the problem of allocating indivisible goods among agents in a fair manner. While envy-free allocations of indivisible goods are not guaranteed to exist, envy-freeness can be achieved by additionally providing some subsidy to the agents. These subsidies can be alternatively viewed as a divisible good (money) that is fractionally assigned among the agents to realize an envy-free outcome. In this setup, we bound the subsidy required to attain envy-freeness among agents with dichotomous valuations, i.e., among agents whose marginal value for any good is either zero or one. We prove that, under dichotomous valuations, there exists an allocation that achieves envy-freeness with a per-agent subsidy of either or . Furthermore, such an envy-free solution can be computed efficiently in the standard value-oracle model. Notably, our results hold for general dichotomous valuations and, in particular, do not require the (dichotomous) valuations to be additive, submodular, or even subadditive. Also, our subsidy bounds are tight and provide a linear (in the number of agents) factor improvement over the bounds known for general monotone valuations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:a0OBvERweLwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2021,"We study Markov Decision Processes (MDP) wherein states correspond to causal graphs that stochastically generate rewards. In this setup, the learner's goal is to identify atomic interventions that lead to high rewards by intervening on variables at each state. Generalizing the recent causal-bandit framework, the current work develops (simple) regret minimization guarantees for two-stage causal MDPs, with parallel causal graph at each state. We propose an algorithm that achieves an instance dependent regret bound. A key feature of our algorithm is that it utilizes convex optimization to address the exploration problem. We identify classes of instances wherein our regret guarantee is essentially tight, and experimentally validate our theoretical results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:yD5IFk8b50cC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2021,"We study the problem of allocating indivisible goods among agents with the objective of maximizing Nash social welfare (NSW). This welfare function is defined as the geometric mean of the agents' valuations and, hence, it strikes a balance between the extremes of social welfare (arithmetic mean) and egalitarian welfare (max-min value). Nash social welfare has been extensively studied in recent years for various valuation classes. In particular, a notable negative result is known when the agents' valuations are complement-free and are specified via value queries: for XOS valuations, one necessarily requires exponentially many value queries to find any sublinear (in ) approximation for NSW. Indeed, this lower bound implies that stronger query models are needed for finding better approximations. Towards this, we utilize demand oracles and XOS oracles; both of these query models are standard and have been used in prior work on social welfare maximization with XOS valuations. We develop the first sublinear approximation algorithm for maximizing Nash social welfare under XOS valuations, specified via demand and XOS oracles. Hence, this work breaks the -approximation barrier for NSW maximization under XOS valuations. We obtain this result by developing a novel connection between NSW and social welfare under a capped version of the agents' valuations. In addition to this insight, which might be of independent interest, this work relies on an intricate combination of multiple technical ideas, including the use of repeated matchings and the discrete moving knife method. In addition, we partially complement the algorithmic result by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:u_35RYKgDlwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2021,"This paper studies a multi-armed bandit (MAB) version of the range-searching problem. In its basic form, range searching considers as input a set of points (on the real line) and a collection of (real) intervals. Here, with each specified point, we have an associated weight, and the problem objective is to find a maximum-weight point within every given interval. The current work addresses range searching with stochastic weights: each point corresponds to an arm (that admits sample access) and the point's weight is the (unknown) mean of the underlying distribution. In this MAB setup, we develop sample-efficient algorithms that find, with high probability, near-optimal arms within the given intervals, i.e., we obtain PAC (probably approximately correct) guarantees. We also provide an algorithm for a generalization wherein the weight of each point is a multi-dimensional vector. The sample complexities of our algorithms depend, in particular, on the size of the optimal hitting set of the given intervals. Finally, we establish lower bounds proving that the obtained sample complexities are essentially tight. Our results highlight the significance of geometric constructs -- specifically, hitting sets -- in our MAB setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:2P1L_qKh6hAC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2021,"Agriculture has become a high-risk profession towards climate change and weather variability, which have direct impact on farmers’ socio-economic condition, and at the same time has to face challenge to provide food security for ever increasing population. So, there is a need to study the different aspects of climate smart agriculture and the present study is an attempt to assess the adoption consistency of farmers about CSA practices and factors likely to influence thereon. The adopters of overall selected practices were 79.85 per cent. The adoption consistency for overall selected CSA practices was of medium level for majority of respondents (58.25%). The LMR model showed that adoption consistency was expressed variation by selected explanatory variables with 23 per cent (R2= 0.23).‘Age’(X1),‘dependency ratio of family’(X3),‘proportion of low land’(X4),‘market accessibility’(X7) and ‘cropping intensity’(X9) were found to have positive and significant influence on adoption consistency. In order to increase adoption consistency, extension agencies, both in public and private sectors, should put forward strategic effort to make farmers aware of climate change and its impact on food production. Regular extension and technology backstopping is very important for increasing adoption consistency of farmers. The different stakeholders (both public and private) in input and output chains should work in convergence mode as a common entity so that farmers get necessary environment for adoption of technologies",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:3s1wT3WcHBgC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"We study fair and economically efficient allocation of indivisible goods among agents whose valuations are rank functions of matroids. Such valuations constitute a well-studied class of submodular functions (i.e., they exhibit a diminishing returns property) and model preferences in several resource-allocation settings. We prove that, for matroid-rank valuations, a social welfare-maximizing allocation that gives each agent her maximin share always exists. Furthermore, such an allocation can be computed in polynomial time. We establish similar existential and algorithmic results for the pairwise maximin share guarantee as well. To complement these results, we show that if the agents have binary XOS valuations or weighted-rank valuations, then maximin fair allocations are not guaranteed to exist. Both of these valuation classes are immediate generalizations of matroid-rank functions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:70eg2SAEIzsC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"In the allocation of resources to a set of agents, how do fairness guarantees impact social welfare? A quantitative measure of this impact is the price of fairness, which measures the worst-case loss of social welfare due to fairness constraints. While initially studied for divisible goods, recent work on the price of fairness also studies the setting of indivisible goods.
In this paper, we resolve the price of two well-studied fairness notions in the context of indivisible goods: envy-freeness up to one good () and approximate maximin share (). For both and we show, via different techniques, that the price of fairness is , where n is the number of agents. From previous work, it follows that these guarantees are tight. We, in fact, obtain the price-of-fairness results via efficient algorithms. For our bound holds for additive valuations, whereas for , it holds for the more general class of subadditive valuations …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:35N4QoGY0k4C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"In the maximum coverage problem, we are given subsets of a universe along with an integer and the objective is to find a subset of size that maximizes . It is a classic result that the greedy algorithm for this problem achieves an optimal approximation ratio of . In this work we consider a generalization of this problem wherein an element can contribute by an amount that depends on the number of times it is covered. Given a concave, nondecreasing function , we define , where . The standard maximum coverage problem corresponds to taking . For any such , we provide an efficient algorithm that achieves an approximation ratio equal to the Poisson concavity ratio of , defined by . Complementing this approximation guarantee, we establish a matching NP-hardness result when grows in a sublinear way. As special cases, we improve the result of [Barman et al., IPCO, 2020] about maximum multi-coverage, that was based on the unique games conjecture, and we recover the result of [Dudycz et al., IJCAI, 2020] on multi-winner approval-based voting for geometrically dominant rules. Our result goes beyond these special cases and we illustrate it with applications to distributed resource allocation problems, welfare maximization problems and approval-based voting for general rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:vV6vV6tmYwMC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"This work develops algorithmic results for the classic cake-cutting problem in which a divisible, heterogeneous resource (modeled as a cake) needs to be partitioned among agents with distinct preferences. We focus on a standard formulation of cake cutting wherein each agent must receive a contiguous piece of the cake. While multiple hardness results exist in this setup for finding fair/efficient cake divisions, we show that, if the value densities of the agents satisfy the monotone likelihood ratio property(MLRP), then strong algorithmic results hold for various notions of fairness and economic efficiency.
Addressing cake-cutting instances with MLRP, first we develop an algorithm that finds cake divisions (with connected pieces) that are envy-free, up to an arbitrary precision. The time complexity of our algorithm is polynomial in the number of agents and the bit complexity of an underlying Lipschitz constant. We obtain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:J_g5lzvAfSwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"We revisit the connection between bargaining and equilibrium in exchange economies, and study its algorithmic implications. We consider bargaining outcomes to be allocations that cannot be blocked (i.e., profitably re-traded) by coalitions of small size and show that these allocations must be approximate Walrasian equilibria. Our results imply that deciding whether an allocation is approximately Walrasian can be done in polynomial time, even in economies for which finding an equilibrium is known to be computationally hard.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:JV2RwH3_ST0C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"We develop polynomial-time algorithms for the fair and efficient allocation of indivisible goods among agents that have subadditive valuations over the goods. We first consider the Nash social welfare as our objective and design a polynomial-time algorithm that, in the value oracle model, finds an -approximation to the Nash optimal allocation. Subadditive valuations include XOS (fractionally subadditive) and submodular valuations as special cases. Our result, even for the special case of submodular valuations, improves upon the previously best known -approximation ratio of Garg et al. (2020). More generally, we study maximization of -mean welfare. The -mean welfare is parameterized by an exponent term and encompasses a range of welfare functions, such as social welfare (), Nash social welfare (), and egalitarian welfare (). We give an algorithm that, for subadditive valuations and any given , computes (in the value oracle model and in polynomial time) an allocation with -mean welfare at least times the optimal. Further, we show that our approximation guarantees are essentially tight for XOS and, hence, subadditive valuations. We adapt a result of Dobzinski et al. (2010) to show that, under XOS valuations, an approximation for the -mean welfare for any (including the Nash social welfare) requires exponentially many value queries; here, is any fixed constant.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:NaGl4SEjCO4C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"We study the problem of allocating indivisible goods among agents that have an identical subadditive valuation over the goods. The extent of fairness and efficiency of allocations is measured by the generalized means of the values that the allocations generate among the agents. Parameterized by an exponent term , generalized-mean welfares encompass multiple well-studied objectives, such as social welfare, Nash social welfare, and egalitarian welfare. We establish that, under identical subadditive valuations and in the demand oracle model, one can efficiently find a single allocation that approximates the optimal generalized-mean welfare---to within a factor of ---uniformly for all . Hence, by way of a constant-factor approximation algorithm, we obtain novel results for maximizing Nash social welfare and egalitarian welfare for identical subadditive valuations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:RGFaLdJalmkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"In the classic maximum coverage problem, we are given subsets of a universe [n] along with an integer k and the objective is to find a subset of size k that maximizes . It is well-known that the greedy algorithm for this problem achieves an approximation ratio of and there is a matching inapproximability result. We note that in the maximum coverage problem if an element is covered by several sets, it is still counted only once. By contrast, if we change the problem and count each element e as many times as it is covered, then we obtain a linear objective function, , which can be easily maximized under a cardinality constraint.
We study the maximum -multi-coverage problem which naturally interpolates between these two extremes. In this problem, an element can be counted up to times but no more; hence, we consider maximizing the function , subject to the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:M3NEmzRMIkIC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"We consider the problem of allocating indivisible goods fairly among n agents who have additive and submodular valuations for the goods. Our fairness guarantees are in terms of the maximin share, which is defined to be the maximum value that an agent can ensure for herself, if she were to partition the goods into n bundles, and then receive a minimum valued bundle. Since maximin fair allocations (i.e., allocations in which each agent gets at least her maximin share) do not always exist, prior work has focused on approximation results that aim to find allocations in which the value of the bundle allocated to each agent is (multiplicatively) as close to her maximin share as possible. In particular, Procaccia and Wang (2014) along with Amanatidis et al. (2015) have shown that under additive valuations, a 2/3-approximate maximin fair allocation always exists and can be found in polynomial time. We complement these …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:qUcmZB5y_30C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2020,"In the allocation of resources to a set of agents, how do fairness guarantees impact the social welfare? A quantitative measure of this impact is the price of fairness, which measures the worst-case loss of social welfare due to fairness constraints. While initially studied for divisible goods, recent work on the price of fairness also studies the setting of indivisible goods. In this paper, we resolve the price of two well-studied fairness notions for the allocation of indivisible goods: envy-freeness up to one good (EF1), and approximate maximin share (MMS). For both EF1 and 1/2-MMS guarantees, we show, via different techniques, that the price of fairness is O (",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:lSLTfruPkqcC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2019,"The classic cake-cutting problem provides a model for addressing fair and efficient allocation of a divisible, heterogeneous resource (metaphorically, the cake) among agents with distinct preferences. Focusing on a standard formulation of cake cutting, in which each agent must receive a contiguous piece of the cake, this work establishes algorithmic and hardness results for multiple fairness/efficiency measures.
First, we consider the well-studied notion of envy-freeness and develop an efficient algorithm that finds a cake division (with connected pieces) wherein the envy is multiplicatively within a factor of . The same algorithm in fact achieves an approximation ratio of for the problem of finding cake divisions with as large a Nash social welfare () as possible. is another standard measure of fairness and this work also establishes a connection between envy-freeness and : approximately envy-free cake divisions (with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:hMod-77fHWUC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2019,"In critical decision-making scenarios, optimizing accuracy can lead to a biased classifier, hence past work recommends enforcing group-based fairness metrics in addition to maximizing accuracy. However, doing so exposes the classifier to another kind of bias called infra-marginality. This refers to individual-level bias where some individuals/subgroups can be worse off than under simply optimizing for accuracy. For instance, a classifier implementing race-based parity may significantly disadvantage women of the advantaged race. To quantify this bias, we propose a general notion of -infra-marginality that can be used to evaluate the extent of this bias. We prove theoretically that, unlike other fairness metrics, infra-marginality does not have a trade-off with accuracy: high accuracy directly leads to low infra-marginality. This observation is confirmed through empirical analysis on multiple simulated and real-world datasets. Further, we find that maximizing group fairness often increases infra-marginality, suggesting the consideration of both group-level fairness and individual-level infra-marginality. However, measuring infra-marginality requires knowledge of the true distribution of individual-level outcomes correctly and explicitly. We propose a practical method to measure infra-marginality, and a simple algorithm to maximize group-wise accuracy and avoid infra-marginality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:NMxIlDl6LWMC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2019,"We consider the problem of allocating a set of indivisible goods among a group of homogeneous agents under matroid constraints and additive valuations, in a fair manner. We propose a novel algorithm that computes a fair allocation for instances with additive and identical valuations, even under matroid constraints. Our result provides a computational anchor to the existential result of the fairness notion, called EF1 (envy-free up to one good) by Biswas and Barman in this setting. We further provide examples to show that the fairness notions stronger than EF1 does not always exist in this setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:blknAaTinKkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2019,"We study classic fair-division problems in a partial information setting. This paper respectively addresses fair division of rent, cake, and indivisible goods among agents with cardinal preferences. We will show that, for all of these settings and under appropriate valuations, a fair (or an approximately fair) division among n agents can be efficiently computed using only the valuations of n− 1 agents. The nth (secretive) agent can make an arbitrary selection after the division has been proposed and, irrespective of her choice, the computed division will admit an overall fair allocation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:iH-uZ7U-co4C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2019,"We study Fisher markets that admit equilibria wherein each good is integrally assigned to some agent. While strong existence and computational guarantees are known for equilibria of Fisher markets with additive valuations (Eisenberg and Gale 1959; Orlin 2010), such equilibria, in general, assign goods fractionally to agents. Hence, Fisher markets are not directly applicable in the context of indivisible goods. In this work we show that one can always bypass this hurdle and, up to a bounded change in agents’ budgets, obtain markets that admit an integral equilibrium. We refer to such markets as pure markets and show that, for any given Fisher market (with additive valuations), one can efficiently compute a “near-by,” pure market with an accompanying integral equilibrium.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:j3f4tGmQtD8C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2019,"The classic cake-cutting problem provides a model for addressing fair and efficient allocation of a divisible, heterogeneous resource (metaphorically, the cake) among agents with distinct preferences. Focusing on a standard formulation of cake cutting, in which each agent must receive a contiguous piece of the cake, this work establishes algorithmic and hardness results for multiple fairness/efficiency measures. First, we consider the well-studied notion of envy-freeness and develop an efficient algorithm that finds a cake division (with connected pieces) wherein the envy is multiplicatively within a factor of . The same algorithm in fact achieves an approximation ratio of for the problem of finding cake divisions with as large a Nash social welfare (NSW) as possible. NSW is another standard measure of fairness and this work also establishes a connection between envy-freeness and NSW: approximately envy-free cake divisions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:RYcK_YlVTxYC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2019,"We study fair division of indivisible goods in a single-parameter environment. In particular, we develop truthful social welfare maximizing mechanisms for fairly allocating indivisible goods. Our fairness guarantees are in terms of solution concepts which are tailored to address allocation of indivisible goods and, hence, provide an appropriate framework for fair division of goods. This work specifically considers fairness in terms of envy freeness up to one good (EF1), maximin share guarantee (MMS), and Nash social welfare (NSW). Our first result shows that (in a single-parameter environment) the problem of maximizing welfare, subject to the constraint that the allocation of the indivisible goods is EF1, admits a polynomial-time, 1/2-approximate, truthful auction. We further prove that this problem is NP-Hard and, hence, an approximation is warranted. This hardness result also complements prior works which show that an arbitrary EF1 allocation can be computed efficiently. We also establish a bi-criteria approximation guarantee for the problem of maximizing social welfare under MMS constraints. In particular, we develop a truthful auction which efficiently finds an allocation wherein each agent gets a bundle of value at least times her maximin share and the welfare of the computed allocation is at least the optimal, here is a fixed constant. We complement this result by showing that maximizing welfare is computationally hard even if one aims to only satisfy the MMS constraint approximately.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:TFP_iSt0sucC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2018,"We study classic fair-division problems in a partial information setting. This paper respectively addresses fair division of rent, cake, and indivisible goods among agents with cardinal preferences. We will show that, for all of these settings and under appropriate valuations, a fair (or an approximately fair) division among n agents can be efficiently computed using only the valuations of n-1 agents. The nth (secretive) agent can make an arbitrary selection after the division has been proposed and, irrespective of her choice, the computed division will admit an overall fair allocation. For the rent-division setting we prove that the (well-behaved) utilities of n-1 agents suffice to find a rent division among n rooms such that, for every possible room selection of the secretive agent, there exists an allocation (of the remaining n-1 rooms among the n-1 agents) which ensures overall envy freeness (fairness). We complement this …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:O3NaXMp0MMsC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2018,"We consider the problem of fairly allocating indivisible goods, among agents, under cardinality constraints and additive valuations. In this setting, we are given a partition of the entire set of goods—ie, the goods are categorized—and a limit is specified on the number of goods that can be allocated from each category to any agent. The objective here is to find a fair allocation in which the subset of goods assigned to any agent satisfies the given cardinality constraints. This problem naturally captures a number of resource-allocation applications, and is a generalization of the well-studied (unconstrained) fair division problem.
The two central notions of fairness, in the context of fair division of indivisible goods, are envy freeness up to one good (EF1) and (approximate) maximin share guarantee (MMS). We show that the existence and algorithmic guarantees established for these solution concepts in the unconstrained setting can essentially be achieved under cardinality constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:_Qo2XoVZTnwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2018,"Sparsity is a basic property of real vectors that is exploited in a wide variety of machine learning applications. In this work, we describe property testing algorithms for sparsity that observe a low-dimensional projec-tion of the input. We consider two settings. In the first setting, we test sparsity with respect to an unknown basis: given input vectors whose concatenation as columns forms , does for matrices and such that each column of is -sparse, or is “far” from having such a decomposition? In the second setting, we test sparsity with respect to a known basis: for a fixed design ma-trix , given input vector , is for some -sparse vector or is “far” from having such a decomposition? We analyze our algorithms using tools from high-dimensional geometry and probability.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:R3hNpaxXUhUC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2018,"We study the problem of allocating a set of indivisible goods among a set of agents in a fair and efficient manner. An allocation is said to be fair if it is envy-free up to one good (EF1), which means that each agent prefers its own bundle over the bundle of any other agent up to the removal of one good. In addition, an allocation is deemed efficient if it satisfies Pareto efficiency. While each of these well-studied properties is easy to achieve separately, achieving them together is far from obvious. Recently, Caragiannis et al. (2016) established the surprising result that when agents have additive valuations for the goods, there always exists an allocation that simultaneously satisfies these two seemingly incompatible properties. Specifically, they showed that an allocation that maximizes the Nash social welfare objective is both EF1 and Pareto efficient. However, the problem of maximizing Nash social welfare is NP-hard. As …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:-f6ydRqryjwC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2018,"We consider prediction with expert advice when the loss vectors are assumed to lie in a set described by the sum of atomic norm balls. We derive a regret bound for a general version of the online mirror descent (OMD) algorithm that uses a combination of regularizers, each adapted to the constituent atomic norms. The general result recovers standard OMD regret bounds, and yields regret bounds for new structured settings where the loss vectors are (i) noisy versions of vectors from a low-dimensional subspace,(ii) sparse vectors corrupted with noise, and (iii) sparse perturbations of low-rank vectors. For the problem of online learning with structured losses, we also show lower bounds on regret in terms of rank and sparsity of the loss vectors, which implies lower bounds for the above additive loss settings as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:hC7cP41nSMkC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2018,"We consider the problem of fairly allocating indivisible goods, among agents, under cardinality constraints and additive valuations. In this setting, we are given a partition of the entire set of goods---i.e., the goods are categorized---and a limit is specified on the number of goods that can be allocated from each category to any agent. The objective here is to find a fair allocation in which the subset of goods assigned to any agent satisfies the given cardinality constraints. This problem naturally captures a number of resource-allocation applications, and is a generalization of the well-studied (unconstrained) fair division problem. The two central notions of fairness, in the context of fair division of indivisible goods, are envy freeness up to one good (EF1) and the (approximate) maximin share guarantee (MMS). We show that the existence and algorithmic guarantees established for these solution concepts in the unconstrained setting can essentially be achieved under cardinality constraints. Specifically, we develop efficient algorithms which compute EF1 and approximately MMS allocations in the constrained setting. Furthermore, focusing on the case wherein all the agents have the same additive valuation, we establish that EF1 allocations exist and can be computed efficiently even under laminar matroid constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:TQgYirikUcIC,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2018,"We study the problem of allocating indivisible goods among n agents in a fair manner. For this problem, maximin share (MMS) is a well-studied solution concept which provides a fairness threshold. Specifically, maximin share is defined as the minimum utility that an agent can guarantee for herself when asked to partition the set of goods into n bundles such that the remaining (n-1) agents pick their bundles adversarially. An allocation is deemed to be fair if every agent gets a bundle whose valuation is at least her maximin share. Even though maximin shares provide a natural benchmark for fairness, it has its own drawbacks and, in particular, it is not sufficient to rule out unsatisfactory allocations. Motivated by these considerations, in this work we define a stronger notion of fairness, called groupwise maximin share guarantee (GMMS). In GMMS, we require that the maximin share guarantee is achieved not just with respect to the grand bundle, but also among all the subgroups of agents. Hence, this solution concept strengthens MMS and provides an ex-post fairness guarantee. We show that in specific settings, GMMS allocations always exist. We also establish the existence of approximate GMMS allocations under additive valuations, and develop a polynomial-time algorithm to find such allocations. Moreover, we establish a scale of fairness wherein we show that GMMS implies approximate envy freeness. Finally, we empirically demonstrate the existence of GMMS allocations in a large set of randomly generated instances. For the same set of instances, we additionally show that our algorithm achieves an approximation factor better than the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:hFOr9nPyWt4C,https://www.csa.iisc.ac.in/~barman/
Siddharth Barman,['Algorithmic Game Theory and Approximation Algorithms'],18,1306,2018,"We study the problem of fairly allocating a set of indivisible goods among agents with additive valuations. The extent of fairness of an allocation is measured by its Nash social welfare, which is the geometric mean of the valuations of the agents for their bundles. While the problem of maximizing Nash social welfare is known to be APX-hard in general, we study the effectiveness of simple, greedy algorithms in solving this problem in two interesting special cases. First, we show that a simple, greedy algorithm provides a 1.061-approximation guarantee when agents have identical valuations, even though the problem of maximizing Nash social welfare remains NP-hard for this setting. Second, we show that when agents have binary valuations over the goods, an exact solution (i.e., a Nash optimal allocation) can be found in polynomial time via a greedy algorithm. Our results in the binary setting extend to provide novel, exact algorithms for optimizing Nash social welfare under concave valuations. Notably, for the above mentioned scenarios, our techniques provide a simple alternative to several of the existing, more sophisticated techniques for this problem such as constructing equilibria of Fisher markets or using real stable polynomials.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=HcGQSKIAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=HcGQSKIAAAAJ:HDshCWvjkbEC,https://www.csa.iisc.ac.in/~barman/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2023,"Salient Span Masking (SSM) has shown itself to be an effective strategy to improve closed-book question answering performance. SSM extends general masked language model pretraining by creating additional unsupervised training sentences that mask a single entity or date span, thus oversampling factual information. Despite the success of this paradigm, the span types and sampling strategies are relatively arbitrary and not widely studied for other tasks. Thus, we investigate SSM from the perspective of temporal tasks, where learning a good representation of various temporal expressions is important. To that end, we introduce Temporal Span Masking (TSM) intermediate training. First, we find that SSM alone improves the downstream performance on three temporal tasks by an avg. +5.8 points. Further, we are able to achieve additional improvements (avg. +0.29 points) by adding the TSM task. These comprise the new best reported results on the targeted tasks. Our analysis suggests that the effectiveness of SSM stems from the sentences chosen in the training data rather than the mask choice: sentences with entities frequently also contain temporal expressions. Nonetheless, the additional targeted spans of TSM can still improve performance, especially in a zero-shot context.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:DGzKIA18-3YC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2023,"The process of design and discovery of new materials can be significantly expedited and simplified if we can learn effectively from available data. Deep learning (DL) approaches have recently received a lot of interest for their ability to speed up the design of novel materials by predicting material properties with precision close to experiments and ab-initio calculations. The application of deep learning to predict materials properties measured by experiments are valuable yet challenging due to the limited amount of experimental data. Most of the existing approaches to predict properties from computational data have also been directed towards specific material properties. In this work, we extend this approach, by proposing Landscape Crystal Graph Convolution Network(LCGCN), an accurate and transferable deep learning framework based on graph convolutional networks. LCGCN directly learns the potential energy surface (PES) from atomic configurations. This approach can enable transferable models that can predict different material properties. We apply this framework to bulk crystals (i.e. Al2O3), and test it by calculating potential energy surfaces at different temperatures and across different phases of crystal.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:cF7EPgIk0B4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Recent research has revealed undesirable biases in NLP data and models. However, these efforts largely focus on social disparities in the West, and are not directly portable to other geo-cultural contexts. In this position paper, we outline a holistic research agenda to re-contextualize NLP fairness research for the Indian context, accounting for Indian societal context, bridging technological gaps in capability and resources, and adapting to Indian cultural values. We also summarize findings from an empirical study on various social biases along different axes of disparities relevant to India, demonstrating their prevalence in corpora and models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:rpSJNIKeXWsC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"New smartphone users have difficulty engaging with it and often use only a limited set of features like calling and messaging. These users are hesitant to explore using the smartphone and rely on experienced users to teach them how to use the phone. However, experienced users are not always around to guide them. To help new users learn how to use the phone on their own, we propose a natural language based instruction following agent that operates over the UI and shows the user how to perform various tasks. Common how-to questions, such as ""How to block calls from unknown numbers?"", are documented on support sites with a sequence of steps in natural language describing what the user should do. We parse these steps using Large Language Models (LLMs) and generate macros that can be executed on-device when the user asks a query. To evaluate this agent, we introduce UGIF-DataSet, a multi-lingual, multi-modal UI grounded dataset for step-by-step task completion on the smartphone. It contains 523 natural language instructions with paired sequences of multilingual UI screens and actions that show how to execute the task in eight languages. We compare the performance of different large language models including PaLM, GPT3, etc. and find that the end-to-end task completion success rate is 48% for English UI but the performance drops to 32% for non-English languages. We analyse the common failure modes of existing models on this task and point out areas for improvement.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:nOiSByfp82kC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"New smartphone users have difficulty engaging with it and often use only a limited set of features like calling and messaging. These users are hesitant to explore using the smartphone and rely on experienced users to teach them how to use the phone. However, experienced users are not always around to guide them. To help new users learn how to use the phone on their own, we propose a natural language based instruction following agent that operates over the UI and shows the user how to perform various tasks. Common how-to questions, such as"" How to block calls from unknown numbers?"", are documented on support sites with a sequence of steps in natural language describing what the user should do. We parse these steps using Large Language Models (LLMs) and generate macros that can be executed on-device when the user asks a query. To evaluate this agent, we introduce UGIF-DataSet, a multi …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:u_mOZUIutIEC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Despite cross-lingual generalization demonstrated by pre-trained multilingual models, the translate-train paradigm of transferring English datasets across multiple languages remains to be the key ingredient for training task-specific multilingual models. However, for many low-resource languages, the availability of a reliable translation service entails significant amounts of costly human-annotated translation pairs. Further, the translation services for low-resource languages may continue to be brittle due to domain mismatch between the task-specific input text and the general-purpose text used while training the translation models. We consider the task of multilingual semantic parsing and demonstrate the effectiveness and flexibility offered by large language models (LLMs) for translating English datasets into several languages via few-shot prompting. We provide (i) Extensive comparisons with prior translate-train methods across 50 languages demonstrating that LLMs can serve as highly effective data translators, outperforming prior translation based methods on 40 out of 50 languages; (ii) A comprehensive study of the key design choices that enable effective data translation via prompted LLMs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:Cvh0bltMcLgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Recent years have witnessed much interest in temporal reasoning over knowledge graphs (KG) for complex question answering (QA), but there remains a substantial gap in human capabilities. We explore how to generalize relational graph convolutional networks (RGCN) for temporal KGQA. Specifically, we propose a novel, intuitive and interpretable scheme to modulate the messages passed through a KG edge during convolution, based on the relevance of its associated time period to the question. We also introduce a gating device to predict if the answer to a complex temporal question is likely to be a KG entity or time and use this prediction to guide our scoring mechanism. We evaluate the resulting system, which we call TwiRGCN, on TimeQuestions, a recently released, challenging dataset for multi-hop complex temporal QA. We show that TwiRGCN significantly outperforms state-of-the-art systems on this dataset across diverse question types. Notably, TwiRGCN improves accuracy by 9--10 percentage points for the most difficult ordinal and implicit question types.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:tgTmbKTkO1IC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Recent research has revealed undesirable biases in NLP data & models. However, these efforts focus of social disparities in West, and are not directly portable to other geo-cultural contexts. In this paper, we focus on NLP fairness in the context of India. We start with a brief account of prominent axes of social disparities in India. We build resources for fairness evaluation in the Indian context and use them to demonstrate prediction biases along some of the axes. We then delve deeper into social stereotypes for Region & Religion, demonstrating its prevalence in corpora & models. Finally, we outline a holistic research agenda to re-contextualize NLP fairness research for the Indian context, accounting for Indian societal context, bridging technological gaps in capability, resources, and adapting to Indian cultural values. While we focus on 'India' here, this framework can be generalized for recontextualization in other geo-cultural contexts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:cdwqcPQS8ssC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"NLU systems deployed in the real world are expected to be regularly updated by retraining or finetuning the underlying neural network on new training examples accumulated over time. In our work, we focus on the multilingual setting where we would want to further finetune a multilingual model on new training data for the same NLU task on which the aforementioned model has already been trained for. We show that under certain conditions, naively updating the multilingual model can lead to losses in performance over a subset of languages although the aggregated performance metric shows an improvement. We establish this phenomenon over four tasks belonging to three task families (token-level, sentence-level and seq2seq) and find that the baseline is far from ideal for the setting at hand. We then build upon recent advances in parameter-efficient finetuning to develop novel finetuning pipelines that allow us to jointly minimize catastrophic forgetting while encouraging positive cross-lingual transfer, hence improving the spread of gains over different languages while reducing the losses incurred in this setup.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:1xBWf43XMUgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"We design and implement a personalized and automated physical activity coaching engine, PACE, which uses the Fogg’s behavioral model (FBM) to engage users in mini-conversation based coaching sessions. It is a chat-based nudge assistant that can boost (encourage) and sense (ask) the motivation, ability and propensity of users to walk and help them in achieving their step count targets, similar to a human coach. We demonstrate the feasibility, effectiveness and acceptability of PACE by directly comparing to human coaches in a Wizard-of-Oz deployment study with 33 participants over 21 days. We tracked coach-participant conversations, step counts and qualitative survey feedback. Our findings indicate that the PACE framework strongly emulated human coaching with no significant differences in the overall number of active days, step count and engagement patterns. The qualitative user feedback suggests …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:ybfzIt2tCtgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"In order for NLP technology to be widely applicable and useful, it needs to be inclusive of users across the world's languages, equitable, i.e., not unduly biased towards any particular language, and accessible to users, particularly in low-resource settings where compute constraints are common. In this paper, we propose an evaluation paradigm that assesses NLP technologies across all three dimensions, hence quantifying the diversity of users they can serve. While inclusion and accessibility have received attention in recent literature, equity is currently unexplored. We propose to address this gap using the Gini coefficient, a well-established metric used for estimating societal wealth inequality. Using our paradigm, we highlight the distressed state of diversity of current technologies for Indian (IN) languages, motivated by their linguistic diversity and large, varied speaker population. To improve upon these metrics, we demonstrate the importance of region-specific choices in model building and dataset creation and also propose a novel approach to optimal resource allocation during fine-tuning. Finally, we discuss steps that must be taken to mitigate these biases and call upon the community to incorporate our evaluation paradigm when building linguistically diverse technologies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:ufKn5pxu7C0C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Diffusion magnetic resonance imaging and tractography enable the estimation of anatomical connectivity in the human brain, in vivo. Yet, without ground-truth validation, different tractography algorithms can yield widely varying connectivity estimates. Although streamline pruning techniques mitigate this challenge, slow compute times preclude their use in big-data applications. We present ‘Regularized, Accelerated, Linear Fascicle Evaluation’ (ReAl-LiFE), a GPU-based implementation of a state-of-the-art streamline pruning algorithm (LiFE), which achieves >100× speedups over previous CPU-based implementations. Leveraging these speedups, we overcome key limitations with LiFE’s algorithm to generate sparser and more accurate connectomes. We showcase ReAl-LiFE’s ability to estimate connections with superlative test–retest reliability, while outperforming competing approaches. Moreover, we predicted …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:v_xunPV0uK0C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Style transfer is the task of rewriting a sentence into a target style while approximately preserving content. While most prior literature assumes access to a large style-labelled corpus, recent work (Riley et al. 2021) has attempted “few-shot” style transfer using only 3-10 sentences at inference for style extraction. In this work we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available. We notice that existing few-shot methods perform this task poorly, often copying inputs verbatim. We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases. When compared to prior work, our model achieves 2-3x better performance in formality transfer and code-mixing addition across seven languages. Moreover, our method is better at controlling the style transfer magnitude using an input scalar knob. We report promising qualitative results for several attribute transfer tasks (sentiment transfer, simplification, gender neutralization, text anonymization) all without retraining the model. Finally, we find model evaluation to be difficult due to the lack of datasets and metrics for many languages. To facilitate future research we crowdsource formality annotations for 4000 sentence pairs in four Indic languages, and use this data to design our automatic evaluations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:oAywNP-vUhwC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Pre-trained multilingual language models such as mBERT and XLM-R have demonstrated great potential for zero-shot cross-lingual transfer to low web-resource languages (LRL). However, due to limited model capacity, the large difference in the sizes of available monolingual corpora between high web-resource languages (HRL) and LRLs does not provide enough scope of co-embedding the LRL with the HRL, thereby affecting downstream task performance of LRLs. In this paper, we argue that relatedness among languages in a language family along the dimension of lexical overlap may be leveraged to overcome some of the corpora limitations of LRLs. We propose Overlap BPE (OBPE), a simple yet effective modification to the BPE vocabulary generation algorithm which enhances overlap across related languages. Through extensive experiments on multiple NLP tasks and datasets, we observe that OBPE generates a vocabulary that increases the representation of LRLs via tokens shared with HRLs. This results in improved zero-shot transfer from related HRLs to LRLs without reducing HRL representation and accuracy. Unlike previous studies that dismissed the importance of token-overlap, we show that in the low-resource related language setting, token overlap matters. Synthetically reducing the overlap to zero can cause as much as a four-fold drop in zero-shot transfer accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:It0W0vAlS5QC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Knowledge Graphs (KGs) are multi-relational graphs where nodes represent entities, and typed edges represent relationships among entities. These graphs store real-world facts such as (Lionel Messi, plays-for-team, Barcelona) as edges, called triples. KGs such as NELL, YAGO, Freebase, and WikiData have been very popular and support many applications such as Web Search, Query Recommendation, and Question Answering. Although popular, these KGs suffer from incompleteness. Learning Knowledge Graph Embeddings (KGE) is a common approach for predicting missing edges (i.e., link prediction) and representing entities and relations in downstream tasks. While numerous KGE methods have been proposed in the past decade, our understanding and analysis of such embeddings have been limited. Further, such methods only work well with ontological KGs. In this thesis, we address these gaps …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:yZoBfgUKqwcC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Few-shot style transfer is the task of rewriting an input sentence using the stylistic properties extracted from a few (3-10) exemplar sentences, while approximately preserving the input content. This is especially useful in low resource settings where no large style-transfer datasets are available. We push the state-of-the-art for few-shot style transfer with a new method that models the stylistic difference between paraphrases. When compared to prior work our method achieves better performance in, output diversity and style transfer magnitude control for five Indian Languages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:xa5BkEQK8BgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2022,"Fitness coaching is effective in helping individuals to develop and maintain healthy lifestyle habits. However, there is a significant shortage of fitness coaches, particularly in low resource communities. Automated coaching assistants may help to improve the accessibility of personalized fitness coaching. Although a variety of automated nudge systems have been developed, few make use of formal behavior science principles and they are limited in their level of personalization. In this work, we introduce a computational framework leveraging the Fogg’s behavioral science model which serves as a personalised and automated coaching engine (PACE). PACE is a rule-based system that infers user state and suggests appropriate text nudges. We compared the effectiveness of PACE to human coaches in a Wizard-of-Oz deployment study with 33 participants over 21 days. Participants were randomized to either a human …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:wkm4DBaukwsC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"While recent work on multilingual language models has demonstrated their capacity for cross-lingual zero-shot transfer on downstream tasks, there is a lack of consensus in the community as to what shared properties between languages enable such transfer. Analyses involving pairs of natural languages are often inconclusive and contradictory since languages simultaneously differ in many linguistic aspects. In this paper, we perform a large-scale empirical study to isolate the effects of various linguistic properties by measuring zero-shot transfer between four diverse natural languages and their counterparts constructed by modifying aspects such as the script, word order, and syntax. Among other things, our experiments show that the absence of sub-word overlap significantly affects zero-shot transfer when languages differ in their word order, and there is a strong correlation between transfer performance and word embedding alignment between languages (e.g., R=0.94 on the task of NLI). Our results call for focus in multilingual models on explicitly improving word embedding alignment between languages rather than relying on its implicit emergence.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:IHkkN1K1AlAC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"Style transfer is the task of rewriting an input sentence into a target style while approximately preserving its content. While most prior literature assumes access to large style-labelled corpora, recent work (Riley et al. 2021) has attempted ""few-shot"" style transfer using only 3-10 sentences at inference for extracting the target style. In this work we consider one such low resource setting where no datasets are available: style transfer for Indian languages. We find that existing few-shot methods perform this task poorly, with a strong tendency to copy inputs verbatim. We push the state-of-the-art for few-shot style transfer with a new method modeling the stylistic difference between paraphrases. When compared to prior work using automatic and human evaluations, our model achieves 2-3x better performance and output diversity in formality transfer and code-mixing addition across five Indian languages. Moreover, our method is better able to control the amount of style transfer using an input scalar knob. We report promising qualitative results for several attribute transfer directions, including sentiment transfer, text simplification, gender neutralization and text anonymization, all without retraining the model. Finally we found model evaluation to be difficult due to the lack of evaluation datasets and metrics for Indian languages. To facilitate further research in formality transfer for Indic languages, we crowdsource annotations for 4000 sentence pairs in four languages, and use this dataset to design our automatic evaluation suite.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:j8pvxH-kN2QC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"Knowledge-intensive NLP tasks can benefit from linking natural language text with facts from a Knowledge Graph (KG). Although facts themselves are language-agnostic, the fact labels (i.e., language-specific representation of the fact) in the KG are often present only in a few languages. This makes it challenging to link KG facts to sentences in languages other than the limited set of languages. To address this problem, we introduce the task of Multilingual Fact Linking (MFL) where the goal is to link fact expressed in a sentence to corresponding fact in the KG, even when the fact label in the KG is not available in the language of the sentence. To facilitate research in this area, we present a new evaluation dataset, IndicLink. This dataset contains 11,293 linked WikiData facts and 6,429 sentences spanning English and six Indian languages. We propose a Retrieval+Generation model, ReFCoG, that can scale to millions of KG facts by combining Dual Encoder based retrieval with a Seq2Seq based generation model which is constrained to output only valid KG facts. ReFCoG outperforms standard Retrieval+Re-ranking models by 10.7 pts in Precision@1. In spite of this gain, the model achieves an overall score of 52.1, showing ample scope for improvement in the task.ReFCoG code and IndicLink data are available at https://github.com/SaiKeshav/mfl",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:CCeGMaHljPEC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"Pre-trained multilingual language models (LMs) have achieved state-of-the-art results in cross-lingual transfer, but they often lead to an inequitable representation of languages due to limited capacity, skewed pre-training data, and sub-optimal vocabularies. This has prompted the creation of an ever-growing pretrained model universe, where each model is trained on large amounts of language or domain specific data with a carefully curated, linguistically informed vocabulary. However, doing so brings us back full circle and prevents one from leveraging the benefits of multilinguality. To address the gaps at both ends of the spectrum, we propose MERGEDISTILL, a framework to merge pre-trained LMs in a way that can best leverage their assets with minimal dependencies, using task-agnostic knowledge distillation. We demonstrate the applicability of our framework in a practical setting by leveraging pre-existing teacher LMs and training student LMs that perform competitively with or even outperform teacher LMs trained on several orders of magnitude more data and with a fixed model capacity. We also highlight the importance of teacher selection and its impact on student model performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:HqhvjgTjE9cC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"Open Knowledge Graphs (OpenKG) refer to a set of (head noun phrase, relation phrase, tail noun phrase) triples such as (tesla, return to, new york) extracted from a corpus using OpenIE tools. While OpenKGs are easy to bootstrap for a domain, they are very sparse and far from being directly usable in an end task. Therefore, the task of predicting new facts, i.e., link prediction, becomes an important step while using these graphs in downstream tasks such as text comprehension, question answering, and web search query recommendation. Learning embeddings for OpenKGs is one approach for link prediction that has received some attention lately. However, on careful examination, we found that current OpenKG link prediction algorithms often predict noun phrases (NPs) with incompatible types for given noun and relation phrases. We address this problem in this work and propose OKGIT that improves OpenKG link prediction using novel type compatibility score and type regularization. With extensive experiments on multiple datasets, we show that the proposed method achieves state-of-the-art performance while producing type compatible NPs in the link prediction task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:MGPUR4WVBMEC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"Recent research in multilingual language models (LM) has demonstrated their ability to effectively handle multiple languages in a single model. This holds promise for low web-resource languages (LRL) as multilingual models can enable transfer of supervision from high resource languages to LRLs. However, incorporating a new language in an LM still remains a challenge, particularly for languages with limited corpora and in unseen scripts. In this paper we argue that relatedness among languages in a language family may be exploited to overcome some of the corpora limitations of LRLs, and propose RelateLM. We focus on Indian languages, and exploit relatedness along two dimensions: (1) script (since many Indic scripts originated from the Brahmic script), and (2) sentence structure. RelateLM uses transliteration to convert the unseen script of limited LRL text into the script of a Related Prominent Language (RPL) (Hindi in our case). While exploiting similar sentence structures, RelateLM utilizes readily available bilingual dictionaries to pseudo translate RPL text into LRL corpora. Experiments on multiple real-world benchmark datasets provide validation to our hypothesis that using a related language as pivot, along with transliteration and pseudo translation based data augmentation, can be an effective way to adapt LMs for LRLs, rather than direct training or pivoting through English.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:WMtz-WDmgKQC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"Pre-trained multilingual language models (LMs) have achieved state-of-the-art results in cross-lingual transfer, but they often lead to an inequitable representation of languages due to limited capacity, skewed pre-training data, and sub-optimal vocabularies. This has prompted the creation of an ever-growing pre-trained model universe, where each model is trained on large amounts of language or domain specific data with a carefully curated, linguistically informed vocabulary. However, doing so brings us back full circle and prevents one from leveraging the benefits of multilinguality. To address the gaps at both ends of the spectrum, we propose MergeDistill, a framework to merge pre-trained LMs in a way that can best leverage their assets with minimal dependencies, using task-agnostic knowledge distillation. We demonstrate the applicability of our framework in a practical setting by leveraging pre-existing teacher LMs and training student LMs that perform competitively with or even outperform teacher LMs trained on several orders of magnitude more data and with a fixed model capacity. We also highlight the importance of teacher selection and its impact on student model performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:mVC4hKzE2FoC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"The ability to learn from limited data, or few-shot learning, is a desirable and often critical requirement for NLP systems. While many existing methods do poorly at learning from a handful of examples, large pretrained language models have recently been shown to be efficient few-shot learners. One approach to few-shot learning, which does not require finetuning of model parameters, is to augment the language model's input with priming text which is typically constructed using task specific descriptions and examples. In this work, we further explore priming-based few-shot learning, with focus on using examples as prompts. We show that presenting examples in the right order is key for generalization. We introduce PERO (Prompting with Examples in the Right Order), where we formulate few-shot learning as search over the set of permutations of the training examples. We show that PERO can learn to generalize efficiently using as few as 10 examples, in contrast to existing approaches. While the newline token is a natural choice for separating the examples in the prompt, we show that learning a new separator token can potentially provide further gains in performance. We demonstrate the effectiveness of the proposed method on the tasks of sentiment classification, natural language inference and fact retrieval. Finally, we analyze the learned prompts to reveal novel insights, including the idea that two training examples in the right order alone can provide competitive performance for sentiment classification and natural language inference.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:GJVTs2krol4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by providing temporal scopes (start and end times) on each edge in the KG. While Question Answering over KG (KGQA) has received some attention from the research community, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored area. Lack of broad coverage datasets has been another factor limiting progress in this area. We address this challenge by presenting CRONQUESTIONS, the largest known Temporal KGQA dataset, clearly stratified into buckets of structural complexity. CRONQUESTIONS expands the only known previous dataset by a factor of 340x. We find that various state-of-the-art KGQA methods fall far short of the desired performance on this new dataset. In response, we also propose CRONKGQA, a transformer-based solution that exploits recent advances in Temporal KG embeddings, and achieves performance superior to all baselines, with an increase of 120% in accuracy over the next best performing method. Through extensive experiments, we give detailed insights into the workings of CRONKGQA, as well as situations where significant further improvements appear possible. In addition to the dataset, we have released our code as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:Nnq8S6OXqDYC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"Robots that can manipulate objects in unstructured environments and collaborate with humans can benefit immensely by understanding natural language. We propose a pipelined architecture of two stages to perform spatial reasoning on the text input. All the objects in the scene are first localized, and then the instruction for the robot in natural language and the localized co-ordinates are mapped to the start and end co-ordinates corresponding to the locations where the robot must pick up and place the object respectively. We show that representing the localized objects by quantizing their positions to a binary grid is preferable to representing them as a list of 2D co-ordinates. We also show that attention improves generalization and can overcome biases in the dataset. The proposed method is used to pick-and-place playing cards using a robot arm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:LWqeokA2EBkC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"Graph-based semi-supervised learning (SSL) assigns labels to initially unlabelled vertices in a graph. Graph neural networks (GNNs), esp. graph convolutional networks (GCNs), are at the core of the current-state-of-the art models for graph-based SSL problems. GCNs have recently been extended to undirected hypergraphs in which relationships go beyond pairwise associations. There is a need to extend GCNs to directed hypergraphs which represent more expressively many real-world data sets such as co-authorship networks and recommendation networks. Furthermore, labels of interest in these applications are most naturally represented by probability distributions. Motivated by these needs, in this paper, we propose a novel GNN-based method for directed hypergraphs, called Directed Hypergraph Network (DHN) for semi-supervised learning of probability distributions (Soft SSL). A key contribution of this …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:_mQi-xiA4oYC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2021,"India is a multilingual society with 1369 rationalized languages and dialects being spoken across the country (INDIA, 2011). Of these, the 22 scheduled languages have a staggering total of 1.17 billion speakers and 121 languages have more than 10,000 speakers (INDIA, 2011). India also has the second largest (and an ever growing) digital footprint (Statista, 2020). Despite this, today's state-of-the-art multilingual systems perform suboptimally on Indian (IN) languages. This can be explained by the fact that multilingual language models (LMs) are often trained on 100+ languages together, leading to a small representation of IN languages in their vocabulary and training data. Multilingual LMs are substantially less effective in resource-lean scenarios (Wu and Dredze, 2020; Lauscher et al., 2020), as limited data doesn't help capture the various nuances of a language. One also commonly observes IN language text transliterated to Latin or code-mixed with English, especially in informal settings (for example, on social media platforms) (Rijhwani et al., 2017). This phenomenon is not adequately handled by current state-of-the-art multilingual LMs. To address the aforementioned gaps, we propose MuRIL, a multilingual LM specifically built for IN languages. MuRIL is trained on significantly large amounts of IN text corpora only. We explicitly augment monolingual text corpora with both translated and transliterated document pairs, that serve as supervised cross-lingual signals in training. MuRIL significantly outperforms multilingual BERT (mBERT) on all tasks in the challenging cross-lingual XTREME benchmark (Hu et al., 2020). We also present results …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:GiYFt9mpioMC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"Knowledge Graph (KG) Embedding methods have been widely studied in the past few years and many methods have been proposed. These methods represent entities and relations in the KG as vectors in a vector space, trained to distinguish correct edges from the incorrect ones. For this distinction, simple functions of vectors’ dimensions, called interactions, are used. These interactions are used to calculate the candidate tail entity vector which is matched against all entities in the KG. However, for most of the existing methods, these interactions are fixed and manually specified. In this work, we propose an automated framework for discovering the interactions while training the KG Embeddings. The proposed method learns relevant interactions along with other parameters during training, allowing it to adapt to different datasets. Many of the existing methods can be seen as special cases of the proposed framework. We demonstrate the effectiveness of the proposed method on link prediction task by extensive experiments on multiple benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:u0Mu_IsstPMC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"Robots that can manipulate objects in unstructured environments and collaborate with humans can benefit immensely by understanding natural language. We propose a pipelined architecture of two stages to perform spatial reasoning on the text input. All the objects in the scene are first localized, and then the instruction for the robot in natural language and the localized co-ordinates are mapped to the start and end co-ordinates corresponding to the locations where the robot must pick up and place the object respectively. We show that representing the localized objects by quantizing their positions to a binary grid is preferable to representing them as a list of 2D co-ordinates. We also show that attention improves generalization and can overcome biases in the dataset. The proposed method is used to pick-and-place playing cards using a robot arm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:hKjooKYXoHIC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"Link prediction insimple graphs is a fundamental problem in which new links between vertices are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among vertices that go beyond pairwise associations. For example, in a chemical reaction, relationship among the reactants and products is inherently higher-order. Additionally, there is a need to represent the direction from reactants to products. Hypergraphs provide a natural way to represent such complex higher-order relationships. Graph Convolutional Network (GCN) has recently emerged as a powerful deep learning-based approach for link prediction over simple graphs. However, their suitability for link prediction in hypergraphs is underexplored -- we fill this gap in this paper and propose Neural Hyperlink Predictor (NHP). NHP adapts GCNs for link prediction in hypergraphs …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:adHtZc2wMuEC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"Knowledge Graphs (KG) are multi-relational graphs consisting of entities as nodes and relations among them as typed edges. Goal of the Question Answering over KG (KGQA) task is to answer natural language queries posed over the KG. Multi-hop KGQA requires reasoning over multiple edges of the KG to arrive at the right answer. KGs are often incomplete with many missing links, posing additional challenges for KGQA, especially for multi-hop KGQA. Recent research on multi-hop KGQA has attempted to handle KG sparsity using relevant external text, which isn’t always readily available. In a separate line of research, KG embedding methods have been proposed to reduce KG sparsity by performing missing link prediction. Such KG embedding methods, even though highly relevant, have not been explored for multi-hop KGQA so far. We fill this gap in this paper and propose EmbedKGQA. EmbedKGQA is particularly effective in performing multi-hop KGQA over sparse KGs. EmbedKGQA also relaxes the requirement of answer selection from a pre-specified neighborhood, a sub-optimal constraint enforced by previous multi-hop KGQA methods. Through extensive experiments on multiple benchmark datasets, we demonstrate EmbedKGQA’s effectiveness over other state-of-the-art baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:N6_Y7JlWxwsC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"The human brain is very effective at integrating new words one by one into the composed representation of a sentence as it is read left-to-right. This raises the important question of what happens to the neural representations of words present earlier in the sentence? For example, do the strength of word representations encountered earlier on in the sentence remain constant or do they evolve as additional words are processed? Representation of words by neural activity in the brain has been the subject of several previous studies. We perform the experiment with a naturalistic task in which the subjects read simple active and passive sentences. Naturalistic studies have tended to explore words in isolation or in a very limited context (e.g., adjective-noun phrases). Representation of previously encountered words during incremental sentence reading, and how such representation evolve as more parts of a sentence are read, is a fundamental but unexplored problem – we take a first step in this direction. In particular, we examine the spatio-temporal characteristics of neural activity encoding nouns and verbs encountered in a sentence as it is read word-by-word. We use Magnetoencephalography (MEG) to passively observe neural activity, providing 1 ms temporal resolution.
Our experiments reveal that nouns and verbs read early in the sentence have a varying influence on neural activity while reading subsequent words, decreasing and increasing at particular word positions in active and passively voiced sentences, with particularly important contributions to activity in frontal and temporal cortical regions. We find the noun and verb information to be …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:QKtdBID3u5MC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"The recent growth in the popularity and success of deep learning models on NLP classification tasks has accompanied the need for generating some form of natural language explanation of the predicted labels. Such generated natural language (NL) explanations are expected to be faithful, i.e., they should correlate well with the model's internal decision making. In this work, we focus on the task of natural language inference (NLI) and address the following question: can we build NLI systems which produce labels with high accuracy, while also generating faithful explanations of its decisions? We propose Natural-language Inference over Label-specific Explanations (NILE), a novel NLI method which utilizes auto-generated label-specific NL explanations to produce labels along with its faithful explanation. We demonstrate NILE's effectiveness over previously reported methods through automated and human evaluation of the produced labels and explanations. Our evaluation of NILE also supports the claim that accurate systems capable of providing testable explanations of their decisions can be designed. We discuss the faithfulness of NILE's explanations in terms of sensitivity of the decisions to the corresponding explanations. We argue that explicit evaluation of faithfulness, in addition to label and explanation accuracy, is an important step in evaluating model's explanations. Further, we demonstrate that task-specific probes are necessary to establish such sensitivity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:oldoQiaHq2UC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"Given a sentence (e.g., “I like mangoes”) and a constraint (e.g., sentiment flip), the goal of controlled text generation is to produce a sentence that adapts the input sentence to meet the requirements of the constraint (e.g., “I hate mangoes”). Going beyond such simple constraints, recent work has started exploring the incorporation of complex syntactic-guidance as constraints in the task of controlled paraphrase generation. In these methods, syntactic-guidance is sourced from a separate exemplar sentence. However, these prior works have only utilized limited syntactic information available in the parse tree of the exemplar sentence. We address this limitation in the paper and propose Syntax Guided Controlled Paraphraser (SGCP), an end-to-end framework for syntactic paraphrase generation. We find …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:5LPo_wSKItgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"Blind estimation of local (per-residue) and global (for the whole structure) accuracies in protein structure models is an essential step in many protein modeling applications. With the recent developments in deep-learning, single-model quality assessment methods have been also advanced, primarily through the use of 2D and 3D convolutional deep neural networks. Here we explore an alternative approach and train a graph convolutional network with nodes representing protein atoms and edges connecting spatially adjacent atom pairs on the dataset Rosetta-300k which contains a set of 300k conformations from 2,897 proteins. We show that our proposed architecture, ProteinGCN, is capable of predicting both local and global accuracies in protein models at state-of-the-art levels. Further, the number of free parameters in ProteinGCN is almost 1-2 orders of magnitude smaller compared to the 3D convolutional networks proposed earlier. We provide the source code of our work to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:i91s68tWr-MC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"Simple weighted averaging of word vectors often yields effective representations for sentences which outperform sophisticated seq2seq neural models in many tasks. While it is desirable to use the same method to represent documents as well, unfortunately, the effectiveness is lost when representing long documents involving multiple sentences. One of the key reasons is that a longer document is likely to contain words from many different topics; hence, creating a single vector while ignoring all the topical structure is unlikely to yield an effective document representation. This problem is less acute in single sentences and other short text fragments where the presence of a single topic is most likely. To alleviate this problem, we present P-SIF, a partitioned word averaging model to represent long documents. P-SIF retains the simplicity of simple weighted word averaging while taking a document's topical structure into account. In particular, P-SIF learns topic-specific vectors from a document and finally concatenates them all to represent the overall document. We provide theoretical justifications on the correctness of P-SIF. Through a comprehensive set of experiments, we demonstrate P-SIF's effectiveness compared to simple weighted averaging and many other baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:NU-BerS4NX4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"Graph Neural Networks (GNN) have been shown to work effectively for modeling graph structured data to solve tasks such as node classification, link prediction and graph classification. There has been some recent progress in defining the notion of pooling in graphs whereby the model tries to generate a graph level representation by downsampling and summarizing the information present in the nodes. Existing pooling methods either fail to effectively capture the graph substructure or do not easily scale to large graphs. In this work, we propose ASAP (Adaptive Structure Aware Pooling), a sparse and differentiable pooling method that addresses the limitations of previous graph pooling architectures. ASAP utilizes a novel self-attention network along with a modified GNN formulation to capture the importance of each node in a given graph. It also learns a sparse soft cluster assignment for nodes at each layer to effectively pool the subgraphs to form the pooled graph. Through extensive experiments on multiple datasets and theoretical analysis, we motivate our choice of the components used in ASAP. Our experimental results show that combining existing GNN architectures with ASAP leads to state-of-the-art results on multiple graph classification benchmarks. ASAP has an average improvement of 4%, compared to current sparse hierarchical state-of-the-art method. We make the source code of ASAP available to encourage reproducible research 1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:C-Rn0OCouf8C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"Most existing knowledge graphs suffer from incompleteness, which can be alleviated by inferring missing links based on known facts. One popular way to accomplish this is to generate low-dimensional embeddings of entities and relations, and use these to make inferences. ConvE, a recently proposed approach, applies convolutional filters on 2D reshapings of entity and relation embeddings in order to capture rich interactions between their components. However, the number of interactions that ConvE can capture is limited. In this paper, we analyze how increasing the number of these interactions affects link prediction performance, and utilize our observations to propose InteractE. InteractE is based on three key ideas–feature permutation, a novel feature reshaping, and circular convolution. Through extensive experiments, we find that InteractE outperforms state-of-the-art convolutional link prediction baselines on FB15k-237. Further, InteractE achieves an MRR score that is 9%, 7.5%, and 23% better than ConvE on the FB15k-237, WN18RR and YAGO3-10 datasets respectively. The results validate our central hypothesis–that increasing feature interaction is beneficial to link prediction performance. We make the source code of InteractE available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:8RAEygVn5_EC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2020,"This tutorial aims to introduce recent advances in graph-based deep learning techniques such as Graph Convolutional Networks (GCNs) for Natural Language Processing (NLP). It provides a brief introduction to deep learning methods on non-Euclidean domains such as graphs and justifies their relevance in NLP. It then covers recent advances in applying graph-based deep learning methods for various NLP tasks, such as semantic role labeling, machine translation, relationship extraction, and many more.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:M0j1y4EgrScC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Efficient representation of text documents is an important building block in many NLP tasks. Research on long text categorization has shown that simple weighted averaging of word vectors for sentence representation often outperforms more sophisticated neural models. Recently proposed Sparse Composite Document Vector (SCDV) (Mekala et. al, 2017) extends this approach from sentences to documents using soft clustering over word vectors. However, SCDV disregards the multi-sense nature of words, and it also suffers from the curse of higher dimensionality. In this work, we address these shortcomings and propose SCDV-MS. SCDV-MS utilizes multi-sense word embeddings and learns a lower dimensional manifold. Through extensive experiments on multiple real-world datasets, we show that SCDV-MS embeddings outperform previous state-of-the-art embeddings on multi-class and multi-label text categorization tasks. Furthermore, SCDV-MS embeddings are more efficient than SCDV in terms of time and space complexity on textual classification tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:VnuxuLaQPLMC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report the performance of several existing methods using our protocol. The reproducible code has been made publicly available",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:kO05sadLmrgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Graph Convolutional Networks (GCNs) have recently been shown to be quite successful in modeling graph-structured data. However, the primary focus has been on handling simple undirected graphs. Multi-relational graphs are a more general and prevalent form of graphs where each edge has a label and direction associated with it. Most of the existing approaches to handle such graphs suffer from over-parameterization and are restricted to learning representations of nodes only. In this paper, we propose CompGCN, a novel Graph Convolutional framework which jointly embeds both nodes and relations in a relational graph. CompGCN leverages a variety of entity-relation composition operations from Knowledge Graph Embedding techniques and scales with the number of relations. It also generalizes several of the existing multi-relational GCN methods. We evaluate our proposed method on multiple tasks such as node classification, link prediction, and graph classification, and achieve demonstrably superior results. We make the source code of CompGCN available to foster reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:WIXB4To3Tx4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Open Information Extraction (OpenIE) methods are effective at extracting (noun phrase, relation phrase, noun phrase) triples from text, eg,(Barack Obama, took birth in, Honolulu). Organization of such triples in the form of a graph with noun phrases (NPs) as nodes and relation phrases (RPs) as edges results in the construction of Open Knowledge Graphs (OpenKGs). In order to use such OpenKGs in downstream tasks, it is often desirable to learn embeddings of the NPs and RPs present in the graph. Even though several Knowledge Graph (KG) embedding methods have been recently proposed, all of those methods have targeted Ontological KGs, as opposed to OpenKGs. Straightforward application of existing Ontological KG embedding methods to OpenKGs is challenging, as unlike Ontological KGs, OpenKGs are not canonicalized, ie, a real-world entity may be represented using multiple nodes in the OpenKG, with each node corresponding to a different NP referring to the entity. For example, nodes with labels Barack Obama, Obama, and President Obama may refer to the same real-world entity Barack Obama. Even though canonicalization of OpenKGs has received some attention lately, output of such methods has not been used to improve OpenKG embed-dings. We fill this gap in the paper and propose Canonicalization-infused Representations (CaRe) for OpenKGs. Through extensive experiments, we observe that CaRe enables existing models to adapt to the challenges in OpenKGs and achieve substantial improvements for the link prediction task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:1EqfMoDn7-AC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Visual Question Answering (VQA) has emerged as an important problem spanning Computer Vision, Natural Language Processing and Artificial Intelligence (AI). In conventional VQA, one may ask questions about an image which can be answered purely based on its content. For example, given an image with people in it, a typical VQA question may inquire about the number of people in the image. More recently, there is growing interest in answering questions which require commonsense knowledge involving common nouns (eg, cats, dogs, microphones) present in the image. In spite of this progress, the important problem of answering questions requiring world knowledge about named entities (eg, Barack Obama, White House, United Nations) in the image has not been addressed in prior research. We address this gap in this paper, and introduce KVQA–the first dataset for the task of (world) knowledge-aware VQA. KVQA consists of 183K question-answer pairs involving more than 18K named entities and 24K images. Questions in this dataset require multi-entity, multi-relation, and multi-hop reasoning over large Knowledge Graphs (KG) to arrive at an answer. To the best of our knowledge, KVQA is the largest dataset for exploring VQA over KG. Further, we also provide baseline performances using state-of-the-art methods on KVQA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:wGzT3bKASkAC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Diffusion imaging and tractography enable mapping structural connections in the human brain, in-vivo. Linear Fascicle Evaluation (LiFE) is a state-of-the-art approach for pruning spurious connections in the estimated structural connectome, by optimizing its fit to the measured diffusion data. Yet, LiFE imposes heavy demands on computing time, precluding its use in analyses of large connectome databases. Here, we introduce a GPU-based implementation of LiFE that achieves 50-100x speedups over conventional CPU-based implementations for connectome sizes of up to several million fibers. Briefly, the algorithm accelerates generalized matrix multiplications on a compressed tensor through efficient GPU kernels, while ensuring favorable memory access patterns. Leveraging these speedups, we advance LiFE’s algorithm by imposing a regularization constraint on estimated fiber weights during connectome pruning. Our regularized, accelerated, LiFE algorithm (“ReAl-LiFE”) estimates sparser connectomes that also provide more accurate fits to the underlying diffusion signal. We demonstrate the utility of our approach by classifying pathological signatures of structural connectivity in patients with Alzheimer’s Disease (AD). We estimated million fiber whole-brain connectomes, followed by pruning with ReAl-LiFE, for 90 individuals (45 AD patients and 45 healthy controls). Linear classifiers, based on support vector machines, achieved over 80% accuracy in classifying AD patients from healthy controls based on their ReAl-LiFE pruned structural connectomes alone. Moreover, classification based on the ReAl-LiFE pruned connectome outperformed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:9LpHyFPp1DQC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Word Sense Disambiguation (WSD) is a long-standing but open problem in Natural Language Processing (NLP). WSD corpora are typically small in size, owing to an expensive annotation process. Current supervised WSD methods treat senses as discrete labels and also resort to predicting the Most-Frequent-Sense (MFS) for words unseen during training. This leads to poor performance on rare and unseen senses. To overcome this challenge, we propose Extended WSD Incorporating Sense Embeddings (EWISE), a supervised model to perform WSD by predicting over a continuous sense embedding space as opposed to a discrete label space. This allows EWISE to generalize over both seen and unseen senses, thus achieving generalized zero-shot learning. To obtain target sense embeddings, EWISE utilizes sense definitions. EWISE learns a novel sentence encoder for sense definitions by using WordNet relations and also ConvE, a recently proposed knowledge graph embedding method. We also compare EWISE against other sentence encoders pretrained on large corpora to generate definition embeddings. EWISE achieves new state-of-the-art WSD performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:ojlX30-wUrgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"What is the relationship between sentence representations learned by deep recurrent models against those encoded by the brain? Is there any correspondence between hidden layers of these recurrent models and brain regions when processing sentences? Can these deep models be used to synthesize brain data which can then be utilized in other extrinsic tasks? We investigate these questions using sentences with simple syntax and semantics (e.g., The bone was eaten by the dog.). We consider multiple neural network architectures, including recently proposed ELMo and BERT. We use magnetoencephalography (MEG) brain recording data collected from human subjects when they were reading these simple sentences. Overall, we find that BERT's activations correlate the best with MEG brain data. We also find that the deep network representation can be used to generate brain data from new sentences to augment existing brain data. To the best of our knowledge, this is the first work showing that the MEG brain recording when reading a word in a sentence can be used to distinguish earlier words in the sentence. Our exploration is also the first to use deep neural network representations to generate synthetic brain data and to show that it helps in improving subsequent stimuli decoding task accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:sJK75vZXtG0C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Inducing diversity in the task of paraphrasing is an important problem in NLP with applications in data augmentation and conversational agents. Previous paraphrasing approaches have mainly focused on the issue of generating semantically similar paraphrases while paying little attention towards diversity. In fact, most of the methods rely solely on top-k beam search sequences to obtain a set of paraphrases. The resulting set, however, contains many structurally similar sentences. In this work, we focus on the task of obtaining highly diverse paraphrases while not compromising on paraphrasing quality. We provide a novel formulation of the problem in terms of monotone submodular function maximization, specifically targeted towards the task of paraphrasing. Additionally, we demonstrate the effectiveness of our method for data augmentation on multiple tasks such as intent classification and paraphrase recognition. In order to drive further research, we have made the source code available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:S2WlVNSe3u4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Predicting properties of nodes in a graph is an important problem with applications in a variety of domains. Graph-based Semi Supervised Learning (SSL) methods aim to address this problem by labeling a small subset of the nodes as seeds, and then utilizing the graph structure to predict label scores for the rest of the nodes in the graph. Recently, Graph Convolutional Networks (GCNs) have achieved impressive performance on the graph-based SSL task. In addition to label scores, it is also desirable to have confidence scores associated with them. Unfortunately, confidence estimation in the context of GCN has not been previously explored. We fill this important gap in this paper and propose ConfGCN, which estimates labels scores along with their confidences jointly in GCN-based setting. ConfGCN uses these estimated confidences to determine the influence of one node on another during neighborhood aggregation, thereby acquiring anisotropic capabilities. Through extensive analysis and experiments on standard benchmarks, we find that ConfGCN is able to outperform state-of-the-art baselines. We have made ConfGCN’s source code available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:3vbIHxFL9FgC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Semi-supervised learning on graph structured data has received significant attention with the recent introduction of Graph Convolution Networks (GCN). While traditional methods have focused on optimizing a loss augmented with Laplacian regularization framework, GCNs perform an implicit Laplacian type regularization to capture local graph structure. In this work, we propose Lovasz Convolutional Network (LCNs) which are capable of incorporating global graph properties. LCNs achieve this by utilizing Lovasz’s orthonormal embeddings of the nodes. We analyse local and global properties of graphs and demonstrate settings where LCNs tend to work better than GCNs. We validate the proposed method on standard random graph models such as stochastic block models (SBM) and certain community structure based graphs where LCNs outperform GCNs and learn more intuitive embeddings. We also perform extensive binary and multi-class classification experiments on real world datasets to demonstrate LCN’s effectiveness. In addition to simple graphs, we also demonstrate the use of LCNs on hyper-graphs by identifying settings where they are expected to work better than GCNs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:j5aT6aphRxQC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Document date is essential for many important tasks, such as document retrieval, summarization, event detection, etc. While existing approaches for these tasks assume accurate knowledge of the document date, this is not always available, especially for arbitrary documents from the Web. Document Dating is a challenging problem which requires inference over the temporal structure of the document. Prior document dating systems have largely relied on handcrafted features while ignoring such document internal structures. In this paper, we propose NeuralDater, a Graph Convolutional Network (GCN) based document dating approach which jointly exploits syntactic and temporal graph structures of document in a principled way. To the best of our knowledge, this is the first application of deep learning for the problem of document dating. Through extensive experiments on real-world datasets, we find that NeuralDater significantly outperforms state-of-the-art baseline by 19% absolute (45% relative) accuracy points.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:Nw_I7GeUguwC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Knowledge of the creation date of documents facilitates several tasks such as summarization, event extraction, temporally focused information extraction etc. Unfortunately, for most of the documents on the Web, the time-stamp metadata is either missing or can't be trusted. Thus, predicting creation time from document content itself is an important task. In this paper, we propose Attentive Deep Document Dater (AD3), an attention-based neural document dating system which utilizes both context and temporal information in documents in a flexible and principled manner. We perform extensive experimentation on multiple real-world datasets to demonstrate the effectiveness of AD3 over neural and non-neural baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:17ZO-CJnx_8C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"Knowledge of the creation date of documents facilitates several tasks such as summarization, event extraction, temporally focused information extraction etc. Unfortunately, for most of the documents on the Web, the time-stamp metadata is either missing or can't be trusted. Thus, predicting creation time from document content itself is an important task. In this paper, we propose Attentive Deep Document Dater (AD3), an attention-based neural document dating system which utilizes both context and temporal information in documents in a flexible and principled manner. We perform extensive experimentation on multiple real-world datasets to demonstrate the effectiveness of AD3 over neural and non-neural baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:4QKQTXcH0q8C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"In many real-world network datasets such as co-authorship, co-citation, email communication, etc., relationships are complex and go beyond pairwise. Hypergraphs provide a flexible and natural modeling tool to model such complex relationships. The obvious existence of such complex relationships in many real-world networks naturaly motivates the problem of learning with hypergraphs. A popular learning paradigm is hypergraph-based semi-supervised learning (SSL) where the goal is to assign labels to initially unlabeled vertices in a hypergraph. Motivated by the fact that a graph convolutional network (GCN) has been effective for graph-based SSL, we propose HyperGCN, a novel GCN for SSL on attributed hypergraphs. Additionally, we show how HyperGCN can be used as a learning-based approach for combinatorial optimisation on NP-hard hypergraph problems. We demonstrate HyperGCN's effectiveness through detailed experimentation on real-world hypergraphs. We have made HyperGCN's source code available to foster reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:gmHTDCtJMcoC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2019,"In many real-world network datasets such as co-authorship, co-citation, email communication, etc., relationships are complex and go beyond pairwise. Hypergraphs provide a flexible and natural modeling tool to model such complex relationships. The obvious existence of such complex relationships in many real-world networks naturally motivates the problem of learning with hypergraphs. A popular learning paradigm is hypergraph-based semi-supervised learning (SSL) where the goal is to assign labels to initially unlabelled vertices in a hypergraph. Motivated by the fact that a graph convolutional network (GCN) has been effective for graph-based SSL, we propose HyperGCN, a novel GCN for SSL on attributed hypergraphs. Additionally, we show how HyperGCN can be used as a learning-based approach for combinatorial optimisation on NP-hard hypergraph problems. We demonstrate Hyper-GCN’s effectiveness through detailed experimentation on real-world hypergraphs. We have made HyperGCN’s source code available to foster reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:zzCxg_vo7cAC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Distantly-supervised Relation Extraction (RE) methods train an extractor by automatically aligning relation instances in a Knowledge Base (KB) with unstructured text. In addition to relation instances, KBs often contain other relevant side information, such as aliases of relations (e.g., founded and co-founded are aliases for the relation founderOfCompany). RE models usually ignore such readily available side information. In this paper, we propose RESIDE, a distantly-supervised neural relation extraction method which utilizes additional side information from KBs for improved relation extraction. It uses entity type and relation alias information for imposing soft constraints while predicting relations. RESIDE employs Graph Convolution Networks (GCN) to encode syntactic information from text and improves performance even when limited side information is available. Through extensive experiments on benchmark datasets, we demonstrate RESIDE's effectiveness. We have made RESIDE's source code available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:G36d5HCDkJYC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Developing accurate, transferable and computationally inexpensive machine learning models can rapidly accelerate the discovery and development of new materials. Some of the major challenges involved in developing such models are, (i) limited availability of materials data as compared to other fields, (ii) lack of universal descriptor of materials to predict its various properties. The limited availability of materials data can be addressed through transfer learning, while the generic representation was recently addressed by Xie and Grossman [1], where they developed a crystal graph convolutional neural network (CGCNN) that provides a unified representation of crystals. In this work, we develop a new model (MT-CGCNN) by integrating CGCNN with transfer learning based on multi-task (MT) learning. We demonstrate the effectiveness of MT-CGCNN by simultaneous prediction of various material properties such as Formation Energy, Band Gap and Fermi Energy for a wide range of inorganic crystals (46774 materials). MT-CGCNN is able to reduce the test error when employed on correlated properties by upto 8%. The model prediction has lower test error compared to CGCNN, even when the training data is reduced by 10%. We also demonstrate our model's better performance through prediction of end user scenario related to metal/non-metal classification. These results encourage further development of machine learning approaches which leverage multi-task learning to address the aforementioned challenges in the discovery of new materials. We make MT-CGCNN's source code available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:T8_be82Iz5gC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Knowledge Graph (KG) embedding has emerged as an active area of research resulting in the development of several KG embedding methods. Relational facts in KG often show temporal dynamics, eg, the fact (Cristiano Ronaldo, playsFor, Manchester United) is valid only from 2003 to 2009. Most of the existing KG embedding methods ignore this temporal dimension while learning embeddings of the KG elements. In this paper, we propose HyTE, a temporally aware KG embedding method which explicitly incorporates time in the entity-relation space by associating each timestamp with a corresponding hyperplane. HyTE not only performs KG inference using temporal guidance, but also predicts temporal scopes for relational facts with missing time annotations. Through extensive experimentation on temporal datasets extracted from real-world KGs, we demonstrate the effectiveness of our model over both traditional as well as temporal KG embedding methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:wuD5JclIwkYC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Low rank tensor completion is a well studied problem and has applications in various fields. However, in many real world applications the data is dynamic, i.e., new data arrives at different time intervals. As a result, the tensors used to represent the data grow in size. Besides the tensors, in many real world scenarios, side information is also available in the form of matrices which also grow in size with time. The problem of predicting missing values in the dynamically growing tensor is called dynamic tensor completion. Most of the previous work in dynamic tensor completion make an assumption that the tensor grows only in one mode. To the best of our Knowledge, there is no previous work which incorporates side information with dynamic tensor completion. We bridge this gap in this paper by proposing a dynamic tensor completion framework called Side Information infused Incremental Tensor Analysis (SIITA …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:rqnDXT1GswoC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Generalized canonical correlation analysis (GCCA) integrates information from data samples that are acquired at multiple feature spaces (or `views') to produce low-dimensional representations-which is an extension of classical two-view CCA. Since the 1960s, (G)CCA has attracted much attention in statistics, machine learning, and data mining because of its importance in data analytics. Despite these efforts, the existing GCCA algorithms have serious complexity issues. The memory and computational complexities of the existing algorithms usually grow as a quadratic and cubic function of the problem dimension (the number of samples / features), respectively-e.g., handling views with ≈1,000 features using such algorithms already occupies ≈10 6 memory and the periteration complexity is ≈10 9 flops-which makes it hard to push these methods much further. To circumvent such difficulties, we first propose a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:Gpwnp1kGG20C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Word embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings. SynGCN utilizes the dependency context of a word without increasing the vocabulary size. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both models available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:eFf2swCANGcC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Knowledge Graph (KG) embedding has emerged as a very active area of research over the last few years, resulting in the development of several embedding methods. These KG embedding methods represent KG entities and relations as vectors in a high-dimensional space. Despite this popularity and effectiveness of KG embeddings in various tasks (eg, link prediction), geometric understanding of such embeddings (ie, arrangement of entity and relation vectors in vector space) is unexplored–we fill this gap in the paper. We initiate a study to analyze the geometry of KG embeddings and correlate it with task performance and other hyperparameters. To the best of our knowledge, this is the first study of its kind. Through extensive experiments on real-world datasets, we discover several insights. For example, we find that there are sharp differences between the geometry of embeddings learnt by different classes of KG embeddings methods. We hope that this initial study will inspire other follow-up research on this important but unexplored problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:Oo1CbQkBAzEC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Entity Linking (EL) systems aim to automatically map mentions of an entity in text to the corresponding entity in a Knowledge Graph (KG). Degree of connectivity of an entity in the KG directly affects an EL system’s ability to correctly link mentions in text to the entity in KG. This causes many EL systems to perform well for entities well connected to other entities in KG, bringing into focus the role of KG density in EL. In this paper, we propose Entity Linking using Densified Knowledge Graphs (ELDEN). ELDEN is an EL system which first densifies the KG with co-occurrence statistics from a large text corpus, and then uses the densified KG to train entity embeddings. Entity similarity measured using these trained entity embeddings result in improved EL. ELDEN outperforms state-of-the-art EL system on benchmark datasets. Due to such densification, ELDEN performs well for sparsely connected entities in the KG too. ELDEN’s approach is simple, yet effective. We have made ELDEN’s code and data publicly available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:hefNtdE4IMkC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Learning effective document-level representation is essential in many important NLP tasks such as document classification, summarization, etc. Recent research has shown that simple weighted averaging of word vectors is an effective way to represent sentences, often outperforming complicated seq2seq neural models in many tasks. While it is desirable to use the same method to represent documents as well, unfortunately, the effectiveness is lost when representing long documents involving multiple sentences. One reason for this degradation is due to the fact that a longer document is likely to contain words from many different themes (or topics), and hence creating a single vector while ignoring all the thematic structure is unlikely to yield an effective representation of the document. This problem is less acute in single sentences and other short text fragments where presence of a single theme/topic is most likely. To overcome this problem, in this paper we present PSIF, a partitioned word averaging model to represent long documents. P-SIF retains the simplicity of simple weighted word averaging while taking a document's thematic structure into account. In particular, P-SIF learns topic-specific vectors from a document and finally concatenates them all to represent the overall document. Through our experiments over multiple real-world datasets and tasks, we demonstrate PSIF's effectiveness compared to simple weighted averaging and many other state-of-the-art baselines. We also show that PSIF is particularly effective in representing long multi-sentence documents. We will release PSIF's embedding source code and data-sets for reproducing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:BW2nPTmhBn4C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Relation extraction is the problem of classifying the relationship between two entities in a given sentence. Distant Supervision (DS) is a popular technique for developing relation extractors starting with limited supervision. We note that most of the sentences in the distant supervision relation extraction setting are very long and may benefit from word attention for better sentence representation. Our contributions in this paper are threefold. Firstly, we propose two novel word attention models for distantly- supervised relation extraction: (1) a Bi-directional Gated Recurrent Unit (Bi-GRU) based word attention model (BGWA), (2) an entity-centric attention model (EA), and (3) a combination model which combines multiple complementary models using weighted voting method for improved relation extraction. Secondly, we introduce GDS, a new distant supervision dataset for relation extraction. GDS removes test data noise present in all previous distant- supervision benchmark datasets, making credible automatic evaluation possible. Thirdly, through extensive experiments on multiple real-world datasets, we demonstrate the effectiveness of the proposed methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:qCpRzq7zkD8C,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Open Information Extraction (OpenIE) methods extract (noun phrase, relation phrase, noun phrase) triples from text, resulting in the construction of large Open Knowledge Bases (Open KBs). The noun phrases (NPs) and relation phrases in such Open KBs are not canonicalized, leading to the storage of redundant and ambiguous facts. Recent research has posed canonicalization of Open KBs as clustering over manually-defined feature spaces. Manual feature engineering is expensive and often sub-optimal. In order to overcome this challenge, we propose Canonicalization using Embeddings and Side Information (CESI) -- a novel approach which performs canonicalization over learned embeddings of Open KBs. CESI extends recent advances in KB embedding by incorporating relevant NP and relation phrase side information in a principled manner. Through extensive experiments on multiple real-world datasets …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:CMvovTBb2okC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Whereas people learn many different types of knowledge from diverse experiences over many years, and become better learners over time, most current machine learning systems are much more narrow, learning just a single function or data model based on statistical analysis of a single data set. We suggest that people learn better than computers precisely because of this difference, and we suggest a key direction for machine learning research is to develop software architectures that enable intelligent agents to also learn many types of knowledge, continuously over many years, and to become better learners over time. In this paper we define more precisely this never-ending learning paradigm for machine learning, and we present one case study: the Never-Ending Language Learner (NELL), which achieves a number of the desired properties of a never-ending learner. NELL has been learning to read the Web …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:a2necdfpwlEC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Link prediction in simple graphs is a fundamental problem in which new links between nodes are predicted based on the observed structure of the graph. However, in many real-world applications, there is a need to model relationships among nodes which go beyond pairwise associations. For example, in a chemical reaction, relationship among the reactants and products is inherently higher-order. Additionally, there is need to represent the direction from reactants to products. Hypergraphs provide a natural way to represent such complex higher-order relationships. Even though Graph Convolutional Networks (GCN) have recently emerged as a powerful deep learning-based approach for link prediction over simple graphs, their suitability for link prediction in hypergraphs is unexplored -- we fill this gap in this paper and propose Neural Hyperlink Predictor (NHP). NHP adapts GCNs for link prediction in hypergraphs. We propose two variants of NHP --NHP-U and NHP-D -- for link prediction over undirected and directed hypergraphs, respectively. To the best of our knowledge, NHP-D is the first method for link prediction over directed hypergraphs. Through extensive experiments on multiple real-world datasets, we show NHP's effectiveness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:rFyVMFCKTwsC,https://parthatalukdar.github.io/
Partha Talukdar,"['Natural Language Processing', 'Machine Learning', 'Multilingual learning', 'Knowledge Graphs']",36,6121,2018,"Recently, word embeddings have been widely adopted across several NLP applications. However, most word embedding methods solely rely on linear context and do not provide a framework for incorporating word relationships like hyper- nym, nmod in a principled manner. In this paper, we propose WordGCN, a Graph Convolution based word representation learning approach which provides a framework for exploit- ing multiple types of word relationships. WordGCN operates at sentence as well as corpus level and allows to incorporate dependency parse based context in an efficient manner without increasing the vocabulary size. To the best of our knowledge, this is the first approach which effectively incorporates word relationships via Graph Convolutional Networks for learning word representations. Through extensive experiments on various intrinsic and extrinsic tasks, we demonstrate WordGCN’s effectiveness over existing word embedding approaches. We make WordGCN’s source code available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CIZwXAcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CIZwXAcAAAAJ:qPeb-qHga9sC,https://parthatalukdar.github.io/
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2022,"The primary goal of artificial intelligence is to mimic humans. Therefore, to advance toward this goal, the AI community attempts to imitate qualities/skills possessed by humans and imbibes them into machines with the help of datasets/tasks. Earlier, many tasks which require knowledge about the objects present in an image are satisfactorily solved by vision models. Recently, with the aim to incorporate knowledge about non-object image regions (hideouts, turns, and other obscured regions), a task for identification of potential hideouts termed Covert Geo-Location (CGL) detection was proposed by Saha et al. It involves identification of image regions which have the potential to either cause an imminent threat or appear as target zones to be accessed for further investigation to identify any occluded objects. Only certain occluding items belonging to certain semantic classes can give rise to CGLs. This fact was overlooked by Saha et al. and no attempts were made to utilize semantic class information, which is crucial for CGL detection. In this paper, we propose a multitask-learning-based approach to achieve 2 goals - i) extraction of features having semantic class information; ii) robust training of the common encoder, exploiting large standard annotated datasets as training set for the auxiliary task (semantic segmentation). To explicitly incorporate class information in the features extracted by the encoder, we have further employed attention mechanism in a novel manner. We have also proposed a better evaluation metric for CGL detection that gives more weightage to recognition rather than precise localization. Experimental evaluations performed on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:v_xunPV0uK0C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2022,"Most of the visual scene understanding tasks in the field of computer vision involve the identification of the objects present in the scene. Image regions like hideouts, turns, and other obscured regions of the scene also contain crucial information, for specific surveillance tasks. In this work, we propose an intelligent visual aid for the identification of such locations in an image, which has either the potential to create an imminent threat from an adversary or appear as the target zones needing further investigation to identify concealed objects. Covert places (CGL) for hiding behind an occluding object are concealed 3D locations, not usually detectable from the viewpoint (camera). Hence, this involves delineating specific image regions around the outer boundary of the projections of the occluding objects, as places to be accessed around the potential hideouts. CGL detection finds applications in military counter …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:htyGaKyDgHMC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2022,"Open-ended surveillance task for a robot in an unspecified environment using only an RGB camera, has not been addressed at length in literature. This is unlike the popular scenario of path planning where both the target and environments are often known. We focus on the task of a robot which needs to estimate a realistic depiction of the surrounding 3D environment, including the location of obstacles and free space to navigate in the scene within the view field. In this paper, we propose an unsupervised algorithm to iteratively compute an optimal direction for maximal unhindered movement in the scene. This task is challenging when presented with only a single RGB view of the scene, without the use of any online depth sensor. Our process combines cues from two deep-learning processes - semantic segmentation and depth map estimation, to automatically decide plausible robot movement paths while avoiding …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:It0W0vAlS5QC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2022,"Video generation is a challenging task that requires modeling plausible spatial and temporal dynamics in a video. Inspired by how humans perceive a video by grouping a scene into moving and stationary components, we propose a method that decomposes the task of video generation into the synthesis of foreground, background and motion. Foreground and background together describe the appearance, whereas motion specifies how the foreground moves in a video over time. We propose V3GAN, a novel three-branch generative adversarial network where two branches model foreground and background information, while the third branch models the temporal information without any supervision. The foreground branch is augmented with our novel feature-level masking layer that aids in learning an accurate mask for foreground and background separation. To encourage motion consistency, we further propose a shuffling loss for the video discriminator. Extensive quantitative and qualitative analysis on synthetic as well as real-world benchmark datasets demonstrates that V3GAN outperforms the state-of-the-art methods by a significant margin.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:WMtz-WDmgKQC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2022,"Generative models aiming to generate content from noise have achieved high-fidelity synthesis for image data. However, obtaining comparable performance in the field of unconditional video generation still remains challenging. In this work, we propose a recurrent GAN architecture to model the high-dimensional video data distribution. Recurrent networks by design are able to generate complex, long sequences in an autoregressive fashion. However, the standard LSTM unit for videos (ConvLSTM) is not ideally suited for the task of unconditional video generation. Therefore, we propose a simple yet effective LSTM variant called as TransConv LSTM (TC-LSTM) by modulating the conventional ConvLSTM to have a transpose convolutional structure in input-to-state transitions. This enables the network to model both spatial and temporal relationships across layers simultaneously inside the TC-LSTM unit. TC-LSTM unit acts as a building block of our generator. Extensive quantitative and qualitative analysis shows that RV-GAN outperforms state-of-the-art methods by a significant margin on Moving MNIST, MUG, Weizmann and UCF101 datasets. Additionally, owing to the recurrent structure, our method is able to generate high-quality videos, up to 2 times longer (32 frames) than training videos at inference time. Further analysis confirms that the proposed architecture is generic and can be easily adapted to other tasks like class-conditional video synthesis and text-to-video synthesis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:IHkkN1K1AlAC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2021,"Video generation task is a challenging problem which involves the modelling of complex real-world dynamics. Most of the existing methods have designed deep networks to tackle high-dimensional video data distributions. However, the utilization of wide networks is still under explored. Inspired by the success of wide networks in the image recognition literature, we present G3AN++, a three-stream generative adversarial network for video. The three streams are spatial, temporal and spatio-temporal processing branches. In pursuit of improving the quality of video generation, we make our network wider by splitting the spatial stream into two parallel identical branches learning complementary feature representations. We further introduce a novel adaptive masking layer to impose the complementary constraint. The masking layer encourages the parallel branches to learn distinct and richer visual features. Extensive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:MGPUR4WVBMEC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2021,"Humans possess an innate capability of recognizing objects and their corresponding parts and confine their attention to that location in a visual scene where the object is spatially present. Recently, efforts to train machines to mimic this ability of humans in the form of weakly supervised object localization, using training labels only at the image-level, have garnered a lot of attention. Nonetheless, one of the well-known problems that most of the existing methods suffer from is localizing only the most discriminative part of an object. Such methods provide very little or no focus on other pertinent parts of the object. In this paper, we propose a novel way of scrupulously localizing objects using training with labels as for the entire image by mining information from complementary regions in an image. Primarily, we adapt to regional dropout at complementary spatial locations to create two intermediate images. With the help of a novel Channel-wise Assisted Attention Module (CAAM) coupled with a Spatial Self-Attention Module (SSAM), we parallely train our model to leverage the information from complementary image regions for excellent localization. Finally, we fuse the attention maps generated by the two classifiers using our Attention-based Fusion Loss. Several experimental studies manifest the superior performance of our proposed approach. Our method demonstrates a significant increase in localization performance over the existing state-of-the-art methods on CUB-200-2011 and ILSVRC 2016 datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:_mQi-xiA4oYC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2020,"Predicting future frames of a video sequence has been a problem of high interest in the field of Computer Vision as it caters to a multitude of applications. The ability to predict, anticipate and reason about future events is the essence of intelligence and one of the main goals of decision-making systems such as human-machine interaction, robot navigation and autonomous driving. However, the challenge lies in the ambiguous nature of the problem as there may be multiple future sequences possible for the same input video shot. A naively designed model averages multiple possible futures into a single blurry prediction. Recently, two distinct approaches have attempted to address this problem as: (a) use of latent variable models that represent underlying stochasticity and (b) adversarially trained models that aim to produce sharper images. A latent variable model often struggles to produce realistic results, while an adversarially trained model underutilizes latent variables and thus fails to produce diverse predictions. These methods have revealed complementary strengths and weaknesses. Combining the two approaches produces predictions that appear more realistic and better cover the range of plausible futures. This forms the basis and objective of study in this project work. In this paper, we proposed a novel multi-scale architecture combining both approaches. We validate our proposed model through a series of experiments and empirical evaluations on Moving MNIST, UCF101, and Penn Action datasets. Our method outperforms the results obtained using the baseline methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:N6_Y7JlWxwsC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2020,"Face Recognition using convolutional neural networks have achieved considerable success in constrained environments in the recent past. However, the performance of these methods deteriorates in case of mismatch of training and test distributions, under classroom/surveillance scenarios. These test (probe) samples suffer from degradations such as noise, poor illumination, pose variations, occlusion, low-resolution (LR), blur as well as aliasing, when compared to the crisp, rich training (gallery) set, comprising mostly of high-resolution (HR) mugshot images captured in laboratory settings. To cope with this scenario, we propose a novel dual deep-shallow channeled generative adversarial network (D2SC-GAN) which performs supervised domain adaptation (DA) by mapping LR degraded probe samples to their corresponding HR gallery-like counterparts to perform closed-set face recognition. D2SC-GAN uses a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:kO05sadLmrgC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2020,"Certain facial parts are salient (unique) in appearance, which substantially contribute to the holistic recognition of a subject. Occlusion of these salient parts deteriorates the performance of face recognition algorithms. In this paper, we propose a generative model to reconstruct the missing parts of the face which are under occlusion. The proposed generative model (SD-GAN) reconstructs a face preserving the illumination variation and identity of the face. A novel adversarial training algorithm has been designed for a bimodal mutually exclusive Generative Adversarial Network (GAN) model, for faster convergence. A novel adversarial ""structural"" loss function is also proposed, comprising of two components: a holistic and a local loss, characterized by SSIM and patch-wise MSE. Ablation studies on real and synthetically occluded face datasets reveal that our proposed technique outperforms the competing methods by a considerable margin, even for boosting the performance of Face Recognition.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:T8_be82Iz5gC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2020,"For every event occurring in the real world, most often a sound is associated with the corresponding visual scene. Humans possess an inherent ability to automatically map the audio content with visual scenes leading to an effortless and enhanced understanding of the underlying event. This triggers an interesting question: Can this natural correspondence between video and audio, which has been diminutively explored so far, be learned by a machine and modeled jointly to localize the sound source in a visual scene? In this paper, we propose a novel algorithm that addresses the problem of localizing sound source in unconstrained videos, which uses efficient fusion and attention mechanisms. Two novel blocks namely, Audio Visual Fusion Block (AVFB) and Segment-Wise Attention Block (SWAB) have been developed for this purpose. Quantitative and qualitative evaluations show that it is feasible to use the same algorithm with minor modifications to serve the purpose of sound localization using three different types of learning: supervised, weakly supervised and unsupervised. A novel Audio Visual Triplet Gram Matrix Loss (AVTGML) has been proposed as a loss function to learn the localization in an unsupervised way. Our empirical evaluations demonstrate a significant increase in performance over the existing state-of-the-art methods, serving as a testimony to the superiority of our proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:9LpHyFPp1DQC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2019,"Scene Parsing is an important cog for modern autonomous driving systems. Most of the works in semantic segmentation pertains to day-time scenes with favourable weather and illumination conditions. In this paper, we propose a novel deep architecture, NiSeNet, that performs semantic segmentation of night scenes using a domain mapping approach of synthetic to real data. It is a dual-channel network, where we designed a Real channel using DeepLabV3+ coupled with an MSE loss to preserve the spatial information. In addition, we used an Adaptive channel reducing the domain gap between synthetic and real night images, which also complements the failures of Real channel output. Apart from the dual channel, we introduced a novel fusion scheme to fuse the outputs of two channels. In addition to that, we compiled a new dataset Urban Night Driving Dataset (UNDD); it consists of 7125 unlabelled day and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:orDZ08hpP44C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2019,"This paper proposes a novel network architecture for video frame prediction based on Graph Convolutional Neural Networks (GCNN). Most recent methods often fail in situations where multiple close-by objects at different scales move in random directions with variable speeds. We overcome this by modeling the scene as a space-time graph with intermediate features from the pixels (or a local region) as vertices and the relationships among them as edges. Our main contribution lies within posing the frame generation problem with our proposed space-time graph, which enables the network to learn the spatial as well as temporal inter-pixel relationships independent of each other, thus making the system invariant to velocity differences among the moving objects present in the scene. Moreover, we also propose a novel directional attention mechanism for the graph based model to efficiently learn a significance score …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:_tF6a-HnqWAC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2019,"Image Stitching is a hard task to solve in the presence of large parallax in the images. Specifically, for a sequence of frames from unconstrained videos which are considerably shaky, recent works fail to align such a sequence of images accurately. The proposed method “GreenWarps” aims to accurately align frames/images with large parallax. The method consists of two novel stages, namely, Prewarping and Diffeomorphic Mesh warping. The first stage warps unaligned image to the reference image using Green Coordinates. The second stage of the model refines the alignment by using a demon-based diffeomorphic warping method for mesh deformation termed “DiffeoMeshes”. The warping is performed using Green Coordinates in both the stages without the assumption of any motion model. The combination of the two stages provide accurate alignment of the images. Experiments were performed on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:NZNkWSpQBv0C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2019,"This paper studies the problem of Video Object Segmentation which aims at segmenting objects of interest throughout entire videos, when provided with initial ground truth annotation. Although, variety of works in this field have been done utilizing Convolutional Neural Networks (CNNs), adversarial training techniques have not been used in spite of their effectiveness as a holistic approach. Our proposed architecture consists of a Generative Adversarial framework for the purpose of foreground object segmentation in videos coupled with Intersection-over-union and temporal information based loss functions for training the network. The main contribution of the paper lies in formulation of the two novel loss functions:(i) Inter-frame Temporal Symmetric Difference Loss (ITSDL) and (ii) Intra-frame Temporal Loss (IFTL), which not only enhance the segmentation quality of the predicted mask but also maintain the temporal consistency between the subsequent generated frames. Our end-to-end trainable network exhibits impressive performance gain compared to the state-of-the-art model when evaluated on three popular real-world Video Object Segmentation datasets viz. DAVIS 2016, SegTrack-v2 and YouTube-Objects dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:hfzGNhXhx5MC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2019,"Attention mechanisms alongside encoder-decoder architectures have become integral components for solving the image captioning problem. The attention mechanism recombines an encoding of the image depending on the state of the decoder, to generate the caption sequence. The decoder is predominantly recurrent in nature. In contrast, we propose a novel network possessing attention-like properties that are pervasive through its layers, by utilizing a convolutional neural network (CNN) to refine and combine representations at multiple levels of the architecture for captioning images. We also enable the model to use explicit higher-level semantic information obtained by performing panoptic segmentation on the image. The attention capability of the model is visually demonstrated, and an experimental evaluation is shown on the MS-COCO dataset. We exhibit that the approach is more robust, efficient, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:d4tt_xEv1X8C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2019,"This paper proposes a dual-channel based Graph Convolutional Network (GCN) for the Video Object Segmentation (VOS) task. The main contribution lies in formulating two pixel graphs based on the raw RGB and optical flow features. Both spatial and temporal features are learned independently, making the network robust to various challenging scenarios in real-world videos. Additionally, a motion orientation-based aggregator scheme efficiently captures long-range dependencies among objects. This not only deals with the complex issue of modelling velocity differences among multiple objects moving in various directions, but also adapts to change of appearance of objects due to pose and scale deformations. Also, an occlusion-aware attention mechanism has been employed to facilitate accurate segmentation under scenarios where multiple objects have temporal discontinuity in their appearance due to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:8uzoZH4hB9AC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2019,"Context is an important aspect for accurate saliency detection. However, the question of how to formally model image context within saliency detection frameworks is still an open problem. Recent saliency detection models designed using complex Deep Neural Networks to extract robust features, however often fail to select the right contextual features. These methods generally utilize physical attributes of objects for generating final saliency maps, but ignores scene contextual information. In this paper, we overcome such limitation using (i) a proposed novel end-to-end framework with a Contextual Unit (CTU) module that models the scene contextual information to give efficient saliency maps with the help of Convolutional GRU (Conv-GRU). This is the first work reported so far that utilizes Conv-GRU to generate image saliency maps. In addition, (ii) we propose a novel way of using the Conv-GRU that helps to refine …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:7VEv-pLvLSsC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2019,"Panorama creation from unconstrained hand-held videos is a challenging task due to the presence of large parallax, moving objects and motion blur. Alignment of the frames taken from a hand-held video is often very difficult to perform. The method proposed here aims to generate a panorama view of the video shot given as input. The proposed framework for panorama creation consists of four stages: The first stage performs a sparse frame selection based on alignment and blur score. A global order for aligning the selected frames is generated by computing a Minimum Spanning Tree with the most connected frame as the root of the MST. The third stage performs frame alignment using a novel warping model termed as DiffeoMeshes, a demon-based diffeomorphic registration process for mesh deformation, whereas the fourth stage renders the panorama. For evaluating the alignment performance …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:DXE8ND7PrJAC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2019,"This paper presents feature reconstruction based approach using Generative Adversarial Networks (GAN) to solve the problem of predicting future frames from natural video scenes. Recent GAN based methods often generate blurry outcomes and fail miserably in case of long-range prediction. Our proposed method incorporates an intermediate feature generating GAN to minimize the disparity between the ground truth and predicted outputs. For this, we propose two novel objective functions: (a) Locally Guided Gram Loss (LGGL) and (b) Multi-Scale Correlation Loss (MSCL) to further enhance the quality of the predicted frames. LGGL aides the feature generating GAN to maximize the similarity between the intermediate features of the ground-truth and the network output by constructing Gram matrices from locally extracted patches over several levels of the generator. MSCL incorporates a correlation based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:m92CDrhVnKEC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Face Recognition (FR) under adversarial conditions has been a big challenge for researchers in the Computer Vision and Machine Learning communities in the recent past. Most of state-of-the-art face recognition systems have been designed to overcome degradations in a face due to variations in pose, illumination, contrast, resolution, along with blur. However, interestingly none have addressed the fascinating issue of makeup as a spoof attack, which drastically changes the appearance of a face, making it difficult for even humans to detect and identify the impostor. In this paper, we propose a novel multi-component deep convolutional neural network (CNN) based architecture which performs the complex task of makeup removal from a disguised face, to reveal the original mugshot image of the impostor (i.e. without makeup). The proposed network also performs the hard tasks of FR on a disguised face in addition …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:i91s68tWr-MC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Describing the contents of an image automatically has been a fundamental problem in the field of artificial intelligence and computer vision. Existing approaches are either top-down, which start from a simple representation of an image and convert it into a textual description; or bottom-up, which come up with attributes describing numerous aspects of an image to form the caption or a combination of both. Recurrent neural networks (RNN) enhanced by Long Short-Term Memory networks (LSTM) have become a dominant component of several frameworks designed for solving the image captioning task. Despite their ability to reduce the vanishing gradient problem, and capture dependencies, they are inherently sequential across time. In this work, we propose two novel approaches, a top-down and a bottom-up approach independently, which dispenses the recurrence entirely by incorporating the use of a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:pRWBApOjXDcC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Face Recognition (FR) using Convolutional Neural Network (CNN) based models have achieved considerable success in constrained environments. They however fail to perform well in unconstrained scenarios, especially when the images are captured using surveillance cameras. These probe samples suffer from degradations such as noise, poor illumination, low resolution, blur as well as aliasing, when compared to the rich training (gallery) set, comprising mostly of mugshot images captured in laboratory settings. These images in the training (gallery) set are crisp and have high contrast, compared to the probe samples. To cope with this scenario, we propose a novel dual-pathway generative adversarial network (DP-GAN) which maps low resolution images captured using surveillance camera into their corresponding high resolution images, which are gallery-like, using a novel combination of multi-scale …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:AFXcoJnoRH0C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Video object segmentation aims to segment objects in a video sequence, given some user annotation which indicates the object of interest. Although Convolutional Neural Networks (CNNs) have been used in the recent past for the purpose of foreground segmentation in videos, adversarial training methods have not been used effectively to solve this problem, in spite of its extensive use for solving many other problems in Computer Vision. Earlier, flow features and motion trajectories have been extensively used to capture the temporal consistency between subsequent frames to segment moving objects in videos. However, we show that our proposed framework of processing the video frames independently using a deep generative adversarial network (GAN), is able to maintain the temporal coherency across frames without the use of any explicit trajectory based information, to provide superior results. Our main …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:4QKQTXcH0q8C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Most Face Recognition (FR) systems provide acceptable performances under controlled environments, but fail to perform well when subjected to severe degradations. The major bottle-neck occurs due to severe degradation in the image quality captured by surveillance cameras, compared to the high-quality mug-shot images used for training. In this work, we propose a deep network based on a generative adversarial network (GAN), termed LR-GAN, which helps to reconstruct realistic mugshot images from low-resolution probe samples. These synthesized but realistic (in quality) face images facilitate superior matching performance for FR. The main contribution of the paper is in the adversarial training procedure of LR-GAN to optimize a “multi-scale reconstruction loss”, based on Multi-Scale Structural Similarity Index (MS-SSIM), patch-wise mean-squared error (PMSE), modified Jensen–Shannon Divergence (JSD …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:-nhnvRiOwuoC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Facial make‐up changes the appearance of a person and significantly degrades the performance of automated face verification (FV) systems. Here, the authors propose the design of an end‐to‐end siamese convolutional neural network (SCNN) that simultaneously replicates the facial make‐up of a subject using its target image (under facial make‐up) on a query face image and verifies the identity of the query face sample either with or without make‐up. The SCNN model is designed using loss functions to deal with the variations due to make‐up. The proposed architecture can reciprocate the make‐up at appropriate locations of the face without any human interventions. Rigorous experimentations on four benchmark facial make‐up datasets reveal the efficiency of their proposed model. Ablation studies show improvement of 4% for genuine acceptance rate at 0.1% false acceptance rate and reduction of equal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:1yWc8FF-_SYC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Learning based on convolutional neural networks (CNNs) or deep learning has been a major research area with applications in face recognition (FR). Under degraded conditions, performance of FR algorithms severely degrade. The work presented in this paper has three contributions. First, it proposes a transfer-CNN architecture of deep learning tailor-made for domain adaptation (DA), to overcome the difference in feature distributions between the gallery and probe samples. The proposed architecture consists of three units: base convolution (BCM), transfer (TM) and linear (LM) modules. Secondly, a novel 3-stage algorithm for Mutually Exclusive Training (3-MET) based on stochastic gradient descent, has been proposed. The initial stage of 3-MET involves updating the parameters of the BCM and LM units using samples from gallery. The second stage involves updating the parameters of TM, to bridge the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:CdxZDUztZiMC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Learning based on convolutional neural networks (CNNs) or deep learning has been a major research area with applications in face recognition (FR). However, performances of algorithms designed for FR are unsatisfactory when surveillance conditions severely degrade the test probes. The work presented in this paper has three contributions. First, it proposes a novel adaptive-CNN architecture of deep learning refurbished for domain adaptation (DA), to overcome the difference in feature distributions between the gallery and probe samples. The proposed architecture consists of three components: feature (FM), adaptive (AM) and classification (CM) modules. Secondly, a novel 2-stage algorithm for Mutually Exclusive Training (2-MET) based on stochastic gradient descent, has been proposed. The final stage of training in 2-MET freezes the layers of the FM and CM, while updating (tuning) only the parameters of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:DkZNVXde3BIC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Human recognition in a multi‐biometric system is performed by combining biometric clues from different sources (multiple sensors, units, algorithms, samples and modalities) at different levels (sensor, feature, score, rank and decision level). Low computational complexity and adequate data for fusion make the score‐level fusion a preferable option over other levels of fusion. However, incompatibility issue prevails at this level as scores obtained from different uni‐biometric systems are disparate in nature. This disparity can be resolved by using score normalisation before fusion. This study first analysed the effect of generalised extreme value distribution‐based score normalisation technique on different fusion techniques and then proposes an efficient score fusion technique based on Dezert–Smarandache theory (DSmT). A unique blend of belief assignment and decision‐making methods in the DSmT framework is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:jU7OWUQzBzMC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Moving Object Segmentation is a challenging task for jittery/wobbly videos. For jittery videos, the non-smooth camera motion makes discrimination between foreground objects and background layers hard to solve. While most recent works for moving video object segmentation fail in this scenario, our method generates an accurate segmentation of a single moving object. The proposed method performs a sparse segmentation, where frame-wise labels are assigned only to trajectory coordinates, followed by the pixel-wise labeling of frames. The sparse segmentation involving stabilization and clustering of trajectories in a 3-stage iterative process. At the 1st stage, the trajectories are clustered using pairwise Procrustes distance as a cue for creating an affinity matrix. The 2nd stage performs a block-wise Procrustes analysis of the trajectories and estimates Frechet means (in Kendall's shape space) of the clusters. The Frechet means represent the average trajectories of the motion clusters. An optimization function has been formulated to stabilize the Frechet means, yielding stabilized trajectories at the 3rd stage. The accuracy of the motion clusters are iteratively refined, producing distinct groups of stabilized trajectories. Next, the labels obtained from the sparse segmentation are propagated for pixel-wise labeling of the frames, using a GraphCut based energy formulation. Use of Procrustes analysis and energy minimization in Kendall's shape space for moving object segmentation in jittery videos, is the novelty of this work. Second contribution comes from experiments performed on a dataset formed of 20 real-world natural jittery videos, with manually …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:DBa1UEJaJKAC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"There is a need in modern neuroscience for accurate and automated image processing techniques for analyzing the large volume of neuroanatomical imaging data. Even at light microscopic levels, imaging mouse brains produces individual data volumes in the TerraByte range. A fundamental task involves the detection and quantification of objects of a given type, eg neuronal nuclei or somata, in brain scan dataset. Traditionally this quantification has been performed by human visual inspection with high accuracy, that is not scalable. When modern automated CNN and SVM-based methods are used to solve this classification problem, they achieve accuracy levels that range between 85–92%. However, higher rates of precision and recall that are close to that of human performance are necessary. In this paper, we describe an unsupervised, iterative algorithm, which provides a high performance for a specific problem of detecting Green Fluorescent Protein labeled nuclei in 2D scans of mouse brains. The algorithm judiciously combines classical computer vision techniques and is focused on the complex problem of decomposing strong overlapped objects of interest. Our proposed technique uses feature detection methods on ridge lines over distance transformation of the image and an arc based iterative spatial-filling method to solve the problem. We demonstrate our results on mouse brain dataset of Gigabyte resolution and compare it with manual annotation of the brains. Our results show that an aptly designed CV algorithm with classical feature extractors when tailored to this problem of interest achieves near-ideal human-like performance …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:wvYxNZNCP7wC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Smart Content Based Image Retrieval (CBIR) helps to simultaneously localize and recognize all object(s) present in a scene, for image retrieval task. The major drawbacks in such kind of system are: (a) overhead for addition of new class is high - addition of new class requires manual annotation of large number of samples and retraining of an entire object model; and (b) use of handcrafted features for recognition and localization task, which limits its performance. In this era of data proliferation where it is easy to discover new object categories and hard to label all of them i.e. less amount of labeled samples for training which raises the above mentioned drawbacks. In this work, we propose an approach which cuts down the overhead of labelling the data and re-training on an entire module to learn new classes. The major components in proposed framework are: (a) selection of an appropriate pre-trained …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:SWgZeABleR0C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"This paper proposes a feature reconstruction based approach using pixel-graph and Generative Adversarial Networks (GAN) for solving the problem of synthesizing future frames from video scenes. Recent methods of frame synthesis often generate blurry outcomes in case of long-range prediction and scenes involving multiple objects moving at different velocities due to their holistic approach. Our proposed method introduces a novel pixel-graph based context aggregation layer (PixGraph) which efficiently captures long range dependencies. PixGraph incorporates a weighting scheme through which the internal features of each pixel (or a group of neighboring pixels) can be modeled independently of the others, thus handling the issue of separate objects moving in different directions and with very dissimilar speed. We also introduce a novel objective function, the Locally Guided Gram Loss (LGGL), which aides the GAN based model to maximize the similarity between the intermediate features of the ground-truth and the network output by constructing Gram matrices from locally extracted patches over several levels of the generator. Our proposed model is end-to-end trainable and exhibits superior performance compared to the state-of-the-art on four realworld benchmark video datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:69ZgNCALVd0C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Pose-Invariant Face Recognition (PIFR) has been a serious challenge in the general field of face recognition (FR). The performance of face recognition algorithms deteriorate due to various degradations such as pose, illuminaton, occlusions, blur, noise, aliasing, etc. In this paper, we deal with the problem of 3D pose variation of a face. for that we design and propose PosIX Generative Adversarial Network (PosIX-GAN) that has been trained to generate a set of nice (high quality) face images with 9 different pose variations, when provided with a face image in any arbitrary pose as input. The discriminator of the GAN has also been trained to perform the task of face recognition along with the job of discriminating between real and generated (fake) images. Results when evaluated using two benchmark datasets, reveal the superior performance of PosIX-GAN over state-of-the-art shallow as well as deep learning methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:mWEH9CqjF64C,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Image Stitching is a hard task to solve in the presence of large parallax in the images. Specifically, for a sequence of frames from unconstrained videos which are considerably shaky, recent works fail to align such a sequence of images accurately. The proposed method"" GreenWarps"" aims to accurately align frames/images with large parallax. The method consists of two novel stages, namely, Prewarping and Diffeomorphic Mesh warping. The first stage warps unaligned image to the reference image using Green Coordinates. The second stage of the model refines the alignment by using a demon-based diffeomorphic warping method for mesh deformation termed"" DiffeoMeshes"". The warping is performed using Green Coordinates in both the stages without the assumption of any motion model. The combination of the two stages provide accurate alignment of the images. Experiments were performed on two standard image stitching datasets and one dataset consisting of images created from unconstrained videos. The results show superior performance of our method compared to the state-of-the-art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:QUX0mv85b1cC,http://www.cse.iitm.ac.in/~sdas
Sukhendu Das,"['Computer Vision', 'Pattern Recognition', 'Computer Graphics']",13,878,2018,"Image Stitching is a hard task to solve in the presence of large parallax in video frames. In many cases, video frames shot using hand-held cameras have low resolution, blur and large parallax errors. Most recent works fail to align such a sequence of images accurately. The proposed method aims to accurately align image frames, by employing a novel demon-based, edge-preserving diffeomorphic registration for image stitching, termed as “DiffeoWarps”. The first stage aligns the images globally using a mesh-based perspective (homography) transformation. At the second stage, an alternating method of minimization of correspondence energy and TV-regularization improves the alignment. The “diffeowarped” images are then blended to obtain good quality stitched results. We experimented on two standard datasets as well as on a dataset comprising of 10 sets of images/frames collected from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nqDmEHUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nqDmEHUAAAAJ:1DsIQWDZLl8C,http://www.cse.iitm.ac.in/~sdas
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2023,"Methods and systems for localization within an environment include determining a topology estimate of nodes located in a dynamic indoor environment, based on distances measured between the nodes. Rigid k-core sub-graphs of the topology estimate are generated to determine relative localizations of the nodes. Relative localizations are transformed into absolute localizations to generate a map of positions of the nodes within the environment. A feature of the map is deployed to a device in the environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:PELIpwtuRlgC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2022,"Aspects of the present disclosure describe systems, methods, and structures infrastructure-free RF tracking in dynamic indoor environments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:Y5dfb0dijaUC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2022,"With the emergence of next generation networks, Network Traffic Classification (NTC) has seen greater importance in network management and security. Recently, Channel State Information (CSI) based WiFi sensing techniques have shown their potential for NTC applications [1], [2] as a privacy-preserving yet effective tool. As CSI could be prone to interference, this paper examines the performance of CSI-based NTC models under interference-induced adversarial attacks. Specifically, the impact of spectral allocation of the interference, underlying interfering network traffic type, and physical location of the interference are studied and quantified. We conducted experiments using off-the-shelf devices to test the NTC performance, with and without the adversarial interference attack of ping, buffered video streaming, and live video streaming network traffics. Subsequently, we found that spectral allocation of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:dTyEYWd-f8wC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2021,"Systems and methods for localizing and tracking mobile objects are provided. A method includes determining an initial location of a node in a multi-hop network based on multi-lateration from an unmanned aerial vehicle. The method also includes applying an adaptive aperture to address a non-uniform velocity of the node based on the turn and a velocity vector. A determination whether localization for the node can be implemented using first hop nodes in the multi-hop network is made. In response to a determination that localization cannot be implemented using the first hop nodes, inertial sensor measurements associated with the node are accessed and the inertial sensor measurements are integrated with the adaptive aperture to improve localization accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:Mojj43d5GZwC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2021,"Promising solutions exist today that can accurately track mobile entities indoor using visual inertial odometry in favorable visual conditions, or by leveraging fine-grained ranging (RF, ultrasonic, IR, etc.) to reference anchors. However, they are unable to directly cater to ""dynamic"" indoor environments (e.g. first responder scenarios, multi-player AR/VR gaming in everyday spaces, etc.) that are devoid of such favorable conditions. Indeed, we show that the need for ""infrastructure-free"", and robustness to ""node mobility"" and ""visual conditions"" in such environments, motivates a robust RF-based approach along with the need to address a novel and challenging variant of its infrastructure-free (i.e. peer-to-peer) localization problem that is latency-bounded - accurate tracking of mobile entities imposes a latency budget that not only affects the solution computation but also the collection of peer-to-peer ranges themselves. In this work, we present the design and deployment of DynoLoc that addresses this latency-bounded infrastructure-free RF localization problem. To this end, DynoLoc unravels the fundamental tradeoff between latency and localization accuracy and incorporates design elements that judiciously leverage the available ranging resources to adaptively estimate the joint topology of nodes, coupled with robust algorithm that maximizes the localization accuracy even in the face of practical environmental artifacts (wireless connectivity and multipath, node mobility, etc.). This allows DynoLoc to track (every second) a network of few tens of mobile entities even at speeds of 1-2 m/s with median accuracies under 1-2 m (compared to 5m+ with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:JoZmwDi-zQgC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2021,"An example method of operating a network may include determining whether a flow is to be added to the network based on: a flow type of the flow, a link condition of the flow, and for each possible combination of flow type and link condition out of multiple flow types and multiple link conditions, the number of flows currently carried on the network that correspond to the respective combination.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:tkaPQYYpVKoC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2021,Systems and methods for localizing and tracking mobile objects are provided. The method includes determining an initial location of a node based on multi-lateration from an unmanned aerial vehicle and determining a velocity vector associated with the node based on multi-lateration. The method also includes detecting when the node turns. An adaptive aperture is applied to address a non-uniform velocity of the node based on the turn and the velocity vector.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:eMMeJKvmdy0C,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2021,"A computer-implemented method, system, and computer program product are provided for positioning an unmanned autonomous vehicle (UAV) in a long term evolution radio access network. The method includes acquiring, by a processor-device, a position of the UAV with a global position system. The method also includes determining, by the processor-device, physical distances from the UAV to each of a plurality of user equipment (UE) responsive to a time-of-flight from the UAV to each of the plurality of UE. The method additionally includes generating, by the processor-device, radio environment maps for each of the plurality of UE with signal-to-noise ratios (SNR) from each of the plurality of UEs to the UAV. The method further includes selecting, by the processor-device, a determined position for the UAV as a position with a minimum SNR in the REMs. The method also includes commanding the UAV to move to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:olpn-zPbct0C,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2019,"A system for implementing a wireless communication network is provided. The system includes a plurality of unmanned aerial vehicles (UAVs) forming a wireless multi-hop mesh network constituting a backhaul. A given one of the UAVs includes a radio access network (RAN) agent configured to determine at least one UAV configuration for optimized coverage of one or more user equipment (UE) devices in a terrestrial zone, a haul agent configured to coordinate an optimization of the backhaul based at least in part on the at least one UAV configuration determined by the RAN agent, and a core agent configured to implement a distributed core architecture among the plurality of UAVs. The system further includes a controller configured to control the plurality of UAVs based on information received from at least one of the agents.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:bnK-pcrLprsC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2019,"We use a crowdsourcing approach for RF spectrum patrolling, where heterogeneous, low-cost spectrum sensors are deployed widely and are tasked with detecting unauthorized transmissions while consuming only a limited amount of resources. We pose this as a signal detection problem where the individual sensor's detection performance may vary widely based on their respective hardware or software configurations, but are hard to model using traditional approaches. Still an optimal subset of sensors and their configurations must be chosen to maximize the overall detection performance subject to given resource (cost) limitations. We present the challenges of this problem in crowdsourced settings and propose a set of methods to address them. These methods use data-driven approaches to model individual sensors and exploit mechanisms for sensor selection and fusion while accounting for their correlated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:WA5NYHcadZ8C,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:_B80troHkn4C,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2019,"Shared spectrum systems is an emerging paradigm to improve spectrum utilization and thus address the unabated increase in mobile data consumption. The paradigm allows the “unused” spectrum bands of licensed Primary Users (PUs) to be shared with Secondary Users (SUs), without causing any harmful interference to the PUs. Allocation of spectrum to the SUs is done based on spectrum availability at the SUs' locations; such allocation of spectrum is greatly facilitated by spectrum occupancy maps. In this work, we address the problem of creating spectrum occupancy maps from spectrum occupancy data over a large number of instants, in the challenging scenario of dynamically (temporally) changing spectrum occupancy due to intermittent transmission of primary users. The problem is particularly challenging when the available occupancy data is very sparse spatially, i.e., only very few locations report sensing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:t6usbXjVLHcC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2019,"First responders, a critical lifeline of any society, often find themselves in precarious situations. The ability to track them real-time in unknown indoor environments, would significantly contributes to the success of their mission as well as their safety. In this work, we present the design, implementation and evaluation of TrackIO—a system capable of accurately localizing and tracking mobile responders realtime in large indoor environments. TrackIO leverages the mobile virtual infrastructure offered by unmanned aerial vehicles (UAVs), coupled with the balanced penetration-accuracy tradeoff offered by ultra-wideband (UWB), to accomplish this objective directly from outside, without relying on access to any indoor infrastructure. Towards a practical system, TrackIO incorporates four novel mechanisms in its design that address key challenges to enable tracking responders (i) who are mobile with potentially non-uniform velocities (eg during turns),(ii) deep indoors with challenged reachability,(iii) in real-time even for a large network, and (iv) with high accuracy even when impacted by UAV’s position error. TrackIO’s real-world performance reveals that it can track static nodes with a median accuracy of about 1–1.5 m and mobile (even running) nodes with a median accuracy of 2–2.5 m in large buildings in real-time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:5ugPr518TE4C,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2018,"We use a crowdsourcing approach for RF spectrum patrolling, where heterogeneous, low-cost spectrum sensors are deployed widely and are tasked with detecting unauthorized transmissions in a collaborative fashion while consuming only a limited amount of resources. We pose this as a collaborative signal detection problem where the individual sensor's detection performance may vary widely based on their respective hardware or software configurations, but are hard to model using traditional approaches. Still an optimal subset of sensors and their configurations must be chosen to maximize the overall detection performance subject to given resource (cost) limitations. We present the challenges of this problem in crowdsourced settings and present a set of methods to address them. The proposed methods use data-driven approaches to model individual sensors and develops mechanisms for sensor selection …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:J-pR_7NvFogC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2018,"Un-manned aerial vehicle (UAVs) have the potential to change the landscape of wide-area wireless connectivity by bringing them to areas where connectivity was sparing or non-existent (e.g. rural areas) or has been compromised due to disasters. While Google's Project Loon and Facebook's Project Aquila are examples of high-altitude, long-endurance UAV-based connectivity efforts in this direction, the telecom operators (e.g. AT&T and Verizon) have been exploring low-altitude UAV-based LTE solutions for on-demand deployments. Understandably, these projects are in their early stages and face formidable challenges in their realization and deployment. The goal of this document is to expose the reader to both the challenges as well as the potential offered by these unconventional connectivity solutions. We aim to explore the end-to-end design of such UAV-based connectivity networks particularly in the context of low-altitude UAV networks providing LTE connectivity. Specifically, we aim to highlight the challenges that span across multiple layers (access, core network, and backhaul) in an inter-twined manner as well as the richness and complexity of the design space itself. To help interested readers navigate this complex design space towards a solution, we also articulate the overview of one such end-to-end design, namely SkyLiTE-- a self-organizing network of low-altitude UAVs that provide optimized LTE connectivity in a desired region.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:mvPsJ3kp5DgC,https://www.cse.iitm.ac.in/~ayon/
Ayon Chakraborty,"['Mobile Sensing', 'IoT', 'Wireless Networks']",13,393,2018,"We envision a flexible, dynamic airborne LTE infrastructure built upon Unmanned Autonomous Vehicles (UAVs) that will provide on-demand, on-time, network access, anywhere. In this paper, we design, implement and evaluate SkyRAN, a self-organizing UAV-based LTE RAN (Radio Access Network) that is a key component of this UAV LTE infrastructure network. SkyRAN determines the UAV's operating position in 3D airspace so as to optimize connectivity to all the UEs on the ground. It realizes this by overcoming various challenges in constructing and maintaining radio environment maps to UEs that guide the UAV's position in real-time. SkyRAN is designed to be scalable in that it can be quickly deployed to provide efficient connectivity even over a larger area. It is adaptive in that it reacts to changes in the terrain and UE mobility, to maximize LTE coverage performance while minimizing operating overhead. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xKrkM1EAAAAJ&sortby=pubdate&citation_for_view=xKrkM1EAAAAJ:V3AGJWp-ZtQC,https://www.cse.iitm.ac.in/~ayon/
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2023,"Fault attacks are a potent class of physical attacks that exploit a fault njected during device operation to steal secret keys from a cryptographic device. The success of a fault attack depends intricately on (a) the cryptographic properties of the cipher,(b) the program structure, and (c) the underlying hardware architecture. While there are several tools that automate the process of fault attack evaluation, none of them consider all three influencing aspects.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:LgRImbQfgY4C,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2022,"The emergence of distributed manufacturing ecosystems for electronic hardware involving untrusted parties has led to diverse trust issues. In particular, Intellectual Property (IP) piracy, reverse engineering, and overproduction pose significant threats to integrated circuits (IC) manufacturers. Watermarking has been one of the solutions employed by the semiconductor industry to overcome many of the trust issues. However, existing watermarking techniques often suffer from one or more of the following deficiencies: (1) low structural coverage, (2) applicability to specific design abstraction level (e.g., gate or layout), (3) high design overhead, and (4) vulnerabilities to removal or tampering attacks. We address these deficiencies by introducing a new watermarking scheme, called SIGNED : S ignature I nsertion through challen G e respo N se in E lectronic D esign. SIGNED  relies on a challenge-response protocol …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:Bg7qf7VwUHIC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2022,"Malware programs are diverse, with varying objectives, functionalities, and threat levels ranging from mere pop-ups to financial losses. Consequently, their run-time footprints across the system differ, impacting the optimal data source (Network, Operating system (OS), Hardware) and features that are instrumental to malware detection. Further, the variations in threat levels of malware classes affect the user requirements for detection. Thus, the optimal tuple of <data-source, features, user-requirements> is different for each malware class, impacting the state-of-the-art detection solutions that are agnostic to these subtle differences. This paper presents SUNDEW, a framework to detect malware classes using their optimal tuple of <data-source, features, user-requirements>. SUNDEW uses an ensemble of specialized predictors, each trained with a particular data source (network, OS, and hardware) and tuned for features and requirements of a specific class. While the specialized ensemble with a holistic view across the system improves detection, aggregating the independent conflicting inferences from the different predictors is challenging. SUNDEW resolves such conflicts with a hierarchical aggregation considering the threat-level, noise in the data sources, and prior domain knowledge. We evaluate SUNDEW on a real-world dataset of over 10,000 malware samples from 8 classes. It achieves an F1-Score of one for most classes, with an average of 0.93 and a limited performance overhead of 1.5%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:BJbdYPG6LGMC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2022,"Artificial Intelligence techniques on malware run-time behavior have emerged as a promising tool in the arms race against sophisticated and stealthy cyber-attacks. While data of malware run-time features are critical for research and benchmark comparisons, unfortunately, there is a dearth of real-world datasets due to multiple challenges to their collection. The evasive nature of malware, its dependence on connected real-world conditions to execute, and its potential repercussions pose significant challenges for executing malware in laboratory settings. Consequently, prior open datasets rely on isolated virtual sandboxes to run malware, resulting in data that is not representative of malware behavior in the wild.
This paper presents RaDaR, an open real-world dataset for run-time behavioral analysis of Windows malware. RaDaR is collected by executing malware on a real-world testbed with Internet connectivity and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:vDZJ-YLwNdEC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2022,"An in-depth analysis of the impact of malware across multiple layers of cyber-connected systems is crucial for confronting evolving cyber-attacks. Gleaning such insights requires executing malware samples in analysis frameworks and observing their run-time characteristics. However, the evasive nature of malware, its dependence on real-world conditions, Internet connectivity, and short-lived remote servers to reveal its behavior, and the catastrophic consequences of its execution, pose significant challenges in collecting its real-world run-time behavior in analysis environments.
In this context, we propose JUGAAD, a malware behavior-as-a-service to meet the demands for the safe execution of malware. Such a service enables the users to submit malware hashes or programs and retrieve their precise and comprehensive real-world run-time characteristics. Unlike prior services that analyze malware and present …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:gKiMpY-AVTkC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2022,"In this paper, we propose a novel class of speculative attacks, called Timed Speculative Attacks (TSA), that does not depend on the state changes in the cache memory. Instead, it makes use of the timing differences that occur due to store-to-load forwarding. We propose two attack strategies - Fill-and-Forward utilizing correctly speculated loads, and Fill-and-Misdirect using mis-speculated load instructions. While Fill-and-Forward exploits the shared store buffers in a multi-threaded CPU core, the Fill-and-Misdirect approach exploits the influence of rolled back mis-speculated loads on subsequent instructions. As case studies, we demonstrate a covert channel using Fill-and-Forward and key recovery attacks on OpenSSL AES and Romulus-N Authenticated Encryption with Associated Data scheme using Fill-and-Misdirect approach. Finally, we show that TSA is able to subvert popular cache-based countermeasures for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:tH6gc1N1XXoC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2022,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:5icHVeHT4IsC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2022,"Decentralized exchange markets leveraging blockchain have been proposed recently to provide open and equal access to traders, improve transparency and avoid single-point-of-compromise of centralized exchanges. However, they compromise on the privacy of traders with respect to their asset ownership, account balance, order details and their identity. In this paper, we present Rialto, a fully decentralized privacy-preserving exchange marketplace with support for matching trade orders, on-chain settlement and market price discovery. Rialto provides order rate and account balance confidentiality and unlinkability between traders and their trade orders, while retaining the desirable properties of a traditional marketplace like front-running resilience and market fairness. We define formal security notions of the marketplace. We perform a detailed evaluation of our solution, demonstrate that it scales well and is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:ZzlSgRqYykMC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2022,"Power side-channel attacks are potent security threats that exploit the power consumption patterns of an electronic device to glean sensitive information ranging from secret keys and passwords to web-browsing activity. While pre-Silicon tools promise early detection of side-channel leakage at the design stage, they require several hours of simulation time. In this paper, we present an analytical framework called FORTIFY that estimates the power side-channel vulnerability of digital circuit designs at signal-level granularity, given the RTL or gate-level netlist of the design, at least 100 times faster than contemporary works. We demonstrate the correctness of FORTIFY by comparing it with a recent simulation-based side-channel leakage analysis framework. We also test its scalability by evaluating FORTIFY on an open-source System-on-Chip.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:gVv57TyPmFsC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2022,"Cryptography hardware are highly vulnerable to a class of side-channel attacks known as Differential Fault Analysis (DFA). These attacks exploit fault induced errors to compromise secret keys from ciphers within a few seconds. A bias in the error probabilities strengthens the attack considerably. It abets in bypassing countermeasures and is also the basis of powerful attack variants like the Differential Fault Intensity Analysis (DFIA) and Statistical Ineffective Fault Analysis (SIFA). In this paper, we make two significant contributions. First, we identify the correlation between fault induced errors and gatelevel parameters like the threshold voltage, gate size, and . We show how these parameters can influence the bias in the error probabilities. Then, we propose an algorithm, called Avatar, that carefully tunes gate-level parameters to strengthen the redundancy countermeasures against DFA, DFIA, and SIFA attacks …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:nVrZBo8bIpAC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2021,"Micro-architectural attacks use information leaked through shared resources to break hardware-enforced isolation. These attacks have been used to steal private information ranging from cryptographic keys to privileged Operating System (OS) data in devices ranging from mobile phones to cloud servers. Most existing software countermeasures either have unacceptable overheads or considerable false positives. Further, they are designed for specific attacks and cannot readily adapt to new variants. In this paper, we propose a framework called LEASH, which works from the OS scheduler to stymie micro-architectural attacks with minimal overheads, negligible impact of false positives, and is capable of handling a wide range of attacks. LEASH works by starving maliciously behaving threads at runtime, providing insufficient time and resources to carry out an attack. The CPU allocation for a falsely flagged thread found to be benign is boosted to minimize overheads. To demonstrate the framework, we modify Linux's Completely Fair Scheduler with LEASH and evaluate it with seven micro-architectural attacks ranging from Meltdown and Rowhammer to a TLB covert channel. The runtime overheads are evaluated with a range of real-world applications and found to be less than 1% on average.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:OP4eGU-M3BUC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2021,"Formally bounding side-channel leakage is important to bridge the gap between theory and practice in cryptography. However, bounding side-channel leakages is difficult because leakage in a cryptosystem could be from several sources. Moreover, the amount of leakage from a source may vary depending on the implementation of the cipher and the form of attack. To formally analyze the security of a cryptosystem, it is therefore essential to consider each source of leakage independently. This paper considers data prefetching, which is used in most modern day cache memories to reduce miss penalty. We build a framework that would help computer architects theoretically gauge the impact of a data prefetcher in time-driven cache attacks early in the design phase. The framework computes leakage due to the prefetcher using a metric that is based on the Kullback–Leibler transformation. We use the framework to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:_FM0Bhl9EiAC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2021,"Owing to the failure of Dennard’s scaling, the past decade has seen a steep growth of prominent new paradigms leveraging opportunities in computer architecture. Two technologies of interest are Posit and RISC-V. Posit was introduced in mid-2017 as a viable alternative to IEEE-754, and RISC-V provides a commercial-grade open source Instruction Set Architecture (ISA). In this article, we bring these two technologies together and propose a Configurable Posit Enabled RISC-V Core called PERI.
The article provides insights on how the Single-Precision Floating Point (“F”) extension of RISC-V can be leveraged to support posit arithmetic. We also present the implementation details of a parameterized and feature-complete posit Floating Point Unit (FPU). The configurability and the parameterization features of this unit generate optimal hardware, which caters to the accuracy and energy/area tradeoffs imposed by the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:a3BOlSfXSfwC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2020,"The power consumption of a microprocessor is a huge channel for information leakage. While the most popular exploitation of this channel is to recover cryptographic keys from embedded devices, other applications such as mobile app fingerprinting, reverse engineering of firmware, and password recovery are growing threats. Countermeasures proposed so far are tuned to specific applications, such as crypto-implementations. They are not scalable to the large number and variety of applications that typically run on a general purpose microprocessor.In this paper, we investigate the design of a microprocessor, called PARAM with increased resistance to power based sidechannel attacks. To design PARAM, we start with identifying the most leaking modules in an open-source RISC V processor. We evaluate the leakage in these modules and then add suitable countermeasures. The countermeasures depend on the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:LhH-TYMQEocC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2020,"Bloom filter (BF), when used by an online application, experiences monotonically increasing false-positive errors. The decay of stale elements can control false-positives. Existing mechanisms for decay require unreasonable storage and computation. Inexpensive methods reset the BF periodically, resulting in inconsistent guarantees and performance issues in the underlying computing system. In this article, we propose Fading Bloom filter (FadingBF), which can provide inexpensive yet safe decay of elements. FadingBF neither requires additional storage nor computation to achieve this but instead exploits the underlying storage medium’s intrinsic properties, i.e., DRAM capacitor characteristics. We realize FadingBF by implementing the BF on a DRAM memory module with its periodic refresh disabled . Consequently, the capacitors holding the data elements that are not accessed frequently will predictably lose …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:yqoGN6RLRZoC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2020,"The emergence of distributed manufacturing ecosystems for electronic hardware involving untrusted parties has given rise to diverse trust issues. In particular, IP piracy, overproduction, and hardware Trojan attacks pose significant threats to digital design manufacturers. Watermarking has been one of the solutions employed by the semiconductor industry to overcome many of the trust issues. However, current watermarking techniques have low coverage, incur hardware overheads, and are vulnerable to removal or tampering attacks. Additionally, these watermarks cannot detect Trojan implantation attacks where an adversary alters a design for malicious purposes. We address these issues in our framework called SIGNED: Secure Lightweight Watermarking Scheme for Digital Designs. SIGNED relies on a challenge-response protocol based interrogation scheme for generating the watermark. SIGNED identifies sensitive regions in the target netlist and samples them to form a compact signature that is representative of the functional and structural characteristics of a design. We show that this signature can be used to simultaneously verify, in a robust manner, the provenance of a design, as well as any malicious alterations to it at any stage during design process. We evaluate SIGNED on the ISCAS85 and ITC benchmark circuits and obtain a detection accuracy of 87.61\% even for modifications as low as 5-gates. We further demonstrate that SIGNED can benefit from integration with a logic locking solution, where it can achieve increased protection against removal/tempering attacks and incurs lower overhead through judicious reuse of the locking …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:r_AWSJRzSzQC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2020,"Fault attacks are potent physical attacks on crypto-devices. A single fault injected during encryption can reveal the cipher's secret key. In a hardware realization of an encryption algorithm, only a tiny fraction of the gates is exploitable by such an attack. Finding these vulnerable gates has been a manual and tedious task requiring considerable expertise. In this paper, we propose SOLOMON, the first automatic fault attack vulnerability detection framework for hardware designs. Given a cipher implementation, either at RTL or gate-level, SOLOMON uses formal methods to map vulnerable regions in the cipher algorithm to specific locations in the hardware thus enabling targeted countermeasures to be deployed with much lesser overheads. We demonstrate the efficacy of the SOLOMON framework using three ciphers: AES, CLEFIA, and Simon.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:mNrWkgRL2YcC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2020,"Fault injection attacks are one of the most powerful forms of cryptanalytic attacks on ciphers. A single, precisely injected fault during the execution of a cipher like the AES, can completely reveal the key within a few milliseconds. Software implementations of ciphers, therefore, need to be thoroughly evaluated for such attacks. In recent years, automated tools have been developed to perform these evaluations. These tools either work on the cipher algorithm or on their implementations. Tools that work at the algorithm level can provide a comprehensive assessment of fault attack vulnerability for different fault attacks and with different fault models. Their application is, however, restricted because every realization of the cipher has unique vulnerabilities. On the other hand, tools that work on cipher implementations have a much wider application but are often restricted by the range of fault attacks and the number of fault models they can evaluate.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:bKqednn6t2AC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2020,"Spectrum Sharing Data Falsification (SSDF) attacks can cause heavy performance degradation to Cognitive Radio (CR) based Internet of Battlefield Things (IoBT) networks. The challenge in such networks is to handle this security problem real time, in addition to spectrum sharing. This requires a robust CR architecture and protocol that can provide integrity of the spectrum sensing data being shared between Secondary Users (SUs) for collaborative spectrum decisions in protocols like PROLEMus. We propose one such protocol called Proactive Blockchain based Spectrum Sharing (ProBLeSS) protocol which leverages a blockchain to provide security against SSDF attacks in CR-IoBT networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:yFnVuubrUp4C,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2020,"Cache timing attacks are a serious threat to the security of computing systems. It permits sensitive information, such as cryptographic keys, to leak across virtual machines and even to remote servers. Encrypted Address Cache, proposed by CEASER - a best paper candidate at MICRO 2018 - is a promising countermeasure that stymies the timing channel by employing cryptography to randomize the cache address space. The author claims strong security guarantees by providing randomization both spatially (randomizing every address) and temporally (changing the encryption key periodically). In this letter, we point out a serious flaw in their encryption approach that undermines the proposed security guarantees. Specifically, we show that the proposed Low-Latency Block Cipher, used for encryption in CEASER, is composed of only linear functions which neutralizes the spatial and temporal randomization. Thus, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:DJbcl8HfkQkC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2020,"Cryptocurrencies are rapidly finding wide application in areas such as Real Time Gross Settlements and Payments Systems. Ripple is a cryptocurrency that has gained prominence with banks and payment providers. It solves the Byzantine General’s Problem with it’s Ripple Protocol Consensus Algorithm (RPCA), where each server maintains a list of servers, called Unique Node List (UNL) that represents the network for the server, and will not collectively defraud it. The server believes that the network has come to a consensus when members of the UNL come to a consensus on a transaction.
In this paper we improve Ripple to achieve better speed, security, last mile connectivity and ease of use. We implement guidelines and automated systems for building and maintaining UNLs for resilience, robustness, improved security, and efficient information propagation. We enhance the system so as to ensure that each server receives information from across the whole network rather than just from the UNL members. We also introduce the paradigm of UNL overlap as a function of information propagation and the trust a server assigns to its own UNL. Our design not only reduces vulnerabilities such as eclipse attacks, but also makes it easier to identify malicious behaviour and entities attempting to fraudulently Double Spend or stall the system. We provide experimental evidence of the benefits of our approach over the current Ripple scheme. We observe≥ 4.97 x and 98.22 x in speedup and success rate for information propagation respectively, and≥ 3.16 x and 51.70 x in speedup and success rate in consensus.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:yMeIxYmEMEAC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"Illegal use of memory pointers is a serious security vulnerability. A large number of malwares exploit the spatial and temporal nature of these vulnerabilities to subvert execution or glean sensitive data from an application. Recent countermeasures attach metadata to memory pointers, which define the pointer’s capabilities. The metadata is used by the hardware to validate pointer-based memory accesses. However, recent works have considerable overheads. Further, the pointer validation is decoupled from the actual memory access. We show that this could open up vulnerabilities in multithreaded applications and introduce new vulnerabilities due to speculation in out-of-order processors.
In this article, we demonstrate that the overheads can be reduced considerably by efficient metadata management. We show that the hardware can be designed in a manner that would remain safe in multithreaded applications …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:HIFyuExEbWQC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"Power side-channel attacks pose a serious threat to the security of embedded devices. Most available countermeasures have significant overheads resulting in the application not meeting its requirements of low-power, high-performance and small area. We propose an algorithm called Karna 11 Karna, much like Achilles from Greek mythology, was born with a shield that protected him from attacks. Similarly, Our proposed scheme, Karna protects the design from power side-channel attacks in the manufacturing phase or in other words the chip is manufactured(born) with a shield. that can be incorporated in the Electronic Design Automation (EDA) flow, in order to significantly improve the side-channel security of the device, without impacting the other device characteristics. Karna does not add additional logic but rather achieves this by first identifying vulnerable gates in the design and then reconfiguring these gates …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:cWzG1nlazyYC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"In recent years several hardware enforced pointer protection schemes have been proposed. The most notable amongst them is the Intel MPX, which can identify spatial violations at run time. Recently, it is shown that Intel MPX is vulnerable to a potent attack called Meltdown, which exploits the processor’s transient behavior during speculative execution.In this paper, we show that there is a fundamental design flaw in Intel MPX and all other hardware enforced pointer protection schemes that we surveyed, making all of them vulnerable to Meltdown. We then suggest a design strategy called MSMPX, that provides hardware enforced pointer protection, while at the same time being immune to Meltdown. We compare the hardware overheads on an OpenRISC processor and the performance overheads with respect to Intel MPX.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:ODE9OILHJdcC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"An important aspect of malware design is to be able to evade detection. This is increasingly difficult to achieve with powerful runtime detection techniques based on behavioural and heuristic analysis. In this paper, we propose D-TIME, a new distributed threadless independent malware execution framework to evade runtime detection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:dBIO0h50nwkC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"A malware goes through multiple stages in its life-cycle at the target machine before mounting its expected attack. The entire life-cycle can span anywhere from a few weeks to several months. The network communications during the initial phase could be the earliest indicators of a malware infection. While prior works have leveraged network traffic, none have focused on the temporal analysis of how early can the malware be detected. The main challenges here are the difficulty in differentiating benign-looking malware communications in the early stages of the malware life-cycle. In our quest to build an early warning system, we analyze malware communications to identify such early indicators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:9c2xU6iGI7YC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"In this era of IoT devices, security is very often traded off for smaller device footprint and low power consumption. Considering the exponentially growing security threats of IoT and cyber-physical systems, it is important that these devices have built-in features that enhance security. In this paper, we present Shakti-MS, a lightweight RISC-V processor with built-in support for both temporal and spatial memory protection. At run time, Shakti-MS can detect and stymie memory misuse in C and C++ programs, with minimum runtime overheads. The solution uses a novel implementation of fat-pointers to efficiently detect misuse of pointers at runtime. Our proposal is to use stack-based cookies for crafting fat-pointers instead of having object-based identifiers. We store the fat-pointer on the stack, which eliminates the use of shadow memory space, or any table to store the pointer metadata. This reduces the storage overheads …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:IUKN3-7HHlwC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"A powerful cache timing attack cannot only determine the secret key of a cryptographic cipher accurately but also do so quickly. Cache timing attacks that utilize the shared L1 cache memory are known to have these two characteristics. On the other hand, attacks using the shared last-level cache (LLC) memory are not always successful in obtaining the secret key, and they take considerably longer than an L1 cache attack. This paper leverages the fact that all LLC attacks run on multi-core CPUs, facilitating the attack programs to be parallelized. We show how parallelization can be used to reduce the runtime and improve the attack’s success making it at par with L1 cache attacks. We then propose a new methodology for LLC cache attacks, by which an attacker can maximize the attack success for a given time frame. The only additional requirement is learning about the target system’s runtime behavior, which …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:_5tno0g5mFcC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"The IT infrastructure of large organizations consists of devices and software services purchased from multiple vendors. The problem of measuring the quality of service (QoS) of each of these vendor devices (and services) is challenging since the vendors may tamper with the measurements for monetary benefits or saving debugging efforts. Existing solutions for QoS measurement in trusted environments cannot be extended for this problem since the vendors can easily circumvent them. Solutions borrowed from other areas such as client-server QoS measurement do not help either since they incur unreasonable storage and network overheads, or require extensive modifications to the packet headers. In this paper, we propose the Measuring Tape scheme, comprised of (1) a novel data structure called evidence Bloom filter (e-BF) that can be deployed at the vendor devices (and services), and (2) unique querying …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:IRz6iEL74y4C,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"Hardware performance counters (HPCs) are present in most modern processors and provide an interface to user-level processes to monitor their performance in terms of the number of micro-architectural events, executed during the process execution. In this paper, we analyze the leakage from these HPC events and present a new micro-architectural side-channel attack that observes the number of instruction counts during the execution of an encryption algorithm as side-channel information to recover the secret key. This paper explores the fact that the instruction counts can act as a side channel and then describes the instruction profiling attack (IPA) methodology with the help of two block ciphers, namely AES and CLEFIA, on Intel and AMD processors. We follow the principles of profiled instruction attacks and show that the proposed attack is more potent than the well-known cache timing attacks in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:DUooU5lO8OsC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"Composite fields are used for implementing the advanced encryption standard (AES) SBox when compact and side-channel resistant constructions are required. The prior art has investigated efficient implementations of such SBoxes for application specific integrated circuit (ASIC) platforms. On field programmable gate arrays (FPGAs); however, due to the considerably different structure compared with ASICs, these implementations perform poorly. In this letter, we revisit composite field AES SBox implementations for FPGAs. We show how design choices and optimizations can be made to better suit the granular look-up tables that are present in modern FPGAs. We investigate 2880 SBox constructions and show that about half of them are better than the state-of-the-art composite field implementation. Our best SBox implementation is 18% smaller compared with the state-of-the-art implementation on an FPGA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:mlAyqtXpCwEC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"Most cipher implementations are vulnerable to a class of cryptanalytic attacks known as fault injection attacks. To reveal the secret key, these attacks make use of faults induced at specific locations during the execution of the cipher. Countermeasures for fault injection attacks require these vulnerable locations in the implementation to be first identified and then protected. However, both these steps are difficult and error-prone and, hence, it requires considerable expertise to design efficient countermeasures. Incorrect or insufficient application of the countermeasures would cause the implementation to remain vulnerable, while inefficient application of the countermeasures could lead to significant performance penalties to achieve the desired fault-attack resistance. In this paper, we present a novel framework called SAFARI for automatically synthesizing fault-attack resistant implementations of block ciphers. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:WJVC3Jt7v1AC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2019,"Online detection of cyber-attacks on IoT devices is extremely difficult due to the limited battery and computational power available in these devices. An alternate approach is to shrink the attack surface in order to reduce the threat of attack. This would require that the device undergo more stringent security tests before deployment. Formal verification is a promising tool that can be used to not only detect potential vulnerabilities but also provide guarantees of security. This chapter reviews several security issues that plague IoT devices such as functional correctness of implementations, programming bugs, side-channel analysis, and hardware Trojans. In each of these cases, we discuss state-of-the-art mechanisms that use formal verification tools to detect the vulnerability much before the device is deployed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:6ZxmRoH8BuwC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2018,"The Conference on Security, Privacy, and Applied Cryptography Engineering 2018 (SPACE 2018), was held during December 15–19, 2018, at the Indian Institute of Technology Kanpur, India. This annual event is devoted to various aspects of security, privacy, applied cryptography, and cryptographic engineering. This is a challenging field, requiring expertise from diverse domains, ranging from mathematics to solid-state circuit design.
This year we received 34 submissions from 11 different countries. The submissions were evaluated based on their significance, novelty, technical quality, and relevance to the SPACE conference. The submissions were reviewed in a double-blind mode by at least three members of the 36-member Program Committee. The Program Committee was aided by 22 additional reviewers. The Program Committee meetings were held electronically, with intensive discussions. After an extensive review process, 12 papers were accepted for presentation at the conference, for an acceptance rate of 35.29%. The program also included six invited talks and five tutorials on several aspects of applied cryptology, delivered by world-renowned researchers: Nasour Bagheri, Shivam Bhasin, Jo Van Bulck, Shay Gueron, Avi Mendelson, Mridul Nandi, Abhik Roychoudhury, Sandeep Shukla, Vanessa Teague, and Eran Toch. We sincerely thank the invited speakers for accepting our invitations in spite of their busy schedules. Like its previous editions, SPACE 2018 was organized in co-operation with the International Association for Cryptologic Research (IACR). We are thankful to the Indian Institute of Technology Kanpur for being the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:OTTXONDVkokC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2018,"The weakest link in cryptosystems is quite often due to the implementation rather than the mathematical underpinnings. A vast majority of attacks in the recent past have targeted programming flaws and bugs to break security systems. Due to the complexity, empirically verifying such systems is practically impossible, while manual verification as well as testing do not provide adequate guarantees.
In this article, we leverage model checking techniques to prove the functional correctness of an elliptic curve cryptography (ECC) library with respect to its formal specification. We demonstrate how the huge state space of the C library can be aptly verified using a hierarchical assume-guarantee verification strategy. To test the scalability of this approach, we verify the correctness of five MST-specified elliptic curve implementations. We also verify the newer curve25519 elliptic curve, which is finding multiple applications, due …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:umqufdRvDiIC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2018,"Blockchains are known to provide verifiable tamper-resistant trails of accepted transactions. This guarantee comes at the considerable cost of storage and computational power, thereby restricting its application. Current research has focused on alternatives such as proof of reputation, proof of stake, and proof of elapsed-time to reduce the computational burden on the blockchain participants. Orthogonal to this effort, we focus on a specific set of applications that cannot commit much storage space and computational resources, but require only reasonable guarantees on the validity of transactions. To this end, we introduce blockchain design alternatives, collectively called ApproxBC, that can provide proof of transactions with provable confidence bounds. Consequently, ApproxBC can considerably reduce the computation and storage resources required, making them suitable for resource-constrained Internet of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:XvxMoLDsR5gC,http://cse.iitm.ac.in/~chester
Chester Rebeiro,"['hardware security', 'side-channel analysis', 'operating systems', 'Computer Architecture', 'VLSI']",15,711,2018,"Illegal memory accesses are a serious security vulnerability that have been exploited on numerous occasions. In this letter, we present Gandalf, a compiler assisted hardware extension for the OpenRISC processor that thwarts all forms of memory-based attacks. We associate lightweight capabilities to all program variables, which are checked at run time by the hardware. Gandalf is transparent to the user and does not require significant OS modifications. Moreover, it achieves locality and incurs minimal overheads in the hardware. We demonstrate these features with a customized Linux kernel executing SPEC2006 benchmarks. To the best of our knowledge, this is the first work to demonstrate a complete solution for hardware-based memory protection schemes for embedded platforms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ctxSQrwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ctxSQrwAAAAJ:NXb4pA-qfm4C,http://cse.iitm.ac.in/~chester
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2021,"Mainstream compilers perform a multitude of analyses and optimizations on the given input program. Each analysis pass may generate a program-abstraction. Each optimization pass is typically composed of multiple alternating phases of inspection of program-abstractions and transformations of the program. Upon transformation of a program, the program-abstractions generated by various analysis passes may become inconsistent with the program's modified state. Consequently, the downstream transformations may be considered unsafe until the relevant program-abstractions are stabilized, i.e., the program-abstractions are made consistent with the modified program. In general, the existing compiler frameworks do not perform automated stabilization of the program-abstractions and instead leave it to the optimization writer to deal with the complex task of identifying the relevant program-abstractions to stabilize, the points where the stabilization is to be performed, and the exact procedure of stabilization. Similarly, adding new analyses becomes a challenge as one has to understand which all existing optimizations may impact the newly added program-abstractions. In this paper, we address these challenges by providing the design and implementation of a novel generalized compiler-design framework called Homeostasis. Homeostasis can be used to guarantee the trigger of automated stabilization of relevant program-abstractions under every possible transformation of the program. Interestingly, Homeostasis provides such guarantees not only for the existing optimization passes but also for any future optimizations that may be added to the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:BqipwSGYUEgC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2020,"Graph algorithms are widely used in various applications. Their programmability and performance have garnered a lot of interest among the researchers. Being able to run these graph analytics programs on distributed systems is an important requirement. Green-Marl is a popular Domain Specific Language (DSL) for coding graph algorithms and is known for its simplicity. However, the existing Green-Marl compiler for distributed systems (Green-Marl to Pregel) can only compile limited types of Green-Marl programs (in Pregel canonical form). This severely restricts the types of parallel Green-Marl programs that can be executed on distributed systems. We present DisGCo, the first compiler to translate any general Green-Marl program to equivalent MPI program that can run on distributed systems.
Translating Green-Marl programs to MPI (SPMD/MPMD style of computation, distributed memory) presents many other …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:YFjsv_pBGBYC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2020,"Task-parallel languages such as X10 implement dynamic lightweight task-parallel execution model, where programmers are encouraged to express the ideal parallelism in the program. Prior work has used loop chunking to extract useful parallelism from ideal. Traditional loop chunking techniques assume that iterations in the loop are of similar workload, or the behavior of the first few iterations can be used to predict the load in later iterations. However, in loops with non-uniform work distribution, such assumptions do not hold. This problem becomes more complicated in the presence of atomic blocks (critical sections).
In this paper, we propose a new optimization called deep-chunking that uses a mixed compile-time and runtime technique to chunk the iterations of the parallel-for-loops, based on the runtime workload of each iteration. We propose a parallel algorithm that is executed by individual threads to efficiently …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:hMod-77fHWUC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2020,"There are relatively few studies of distributed GPU graph analytics systems in the literature and they are limited in scope since they deal with small data-sets, consider only a few applications, and do not consider the interplay between partitioning policies and optimizations for computation and communication.In this paper, we present the first detailed analysis of graph analytics applications for massive real-world datasets on a distributed multi-GPU platform and the first analysis of strong scaling of smaller real-world datasets. We use D-IrGL, the state-of-the-art distributed GPU graph analytical framework, in our study. Our evaluation shows that (1) the Cartesian vertex-cut partitioning policy is critical to scale computation out on GPUs even at a small scale, (2) static load imbalance is a key factor in performance since memory is limited on GPUs, (3) device-host communication is a significant portion of execution time and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:blknAaTinKkC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2020,"Existing precise context-sensitive heap analyses do not scale well for large OO programs. Further, identifying the right context abstraction becomes quite intriguing as two of the most popular categories of context abstractions (call-site- and object-sensitive) lead to theoretically incomparable precision. In this paper, we address this problem by first doing a detailed comparative study (in terms of precision and efficiency) of the existing approaches, both with and without heap cloning. In addition, we propose novel context abstractions that lead to a new sweet-spot in the arena.
We first enhance the precision of level-summarized relevant value (LSRV) contexts (a highly scalable abstraction with precision matching that of call-site-sensitivity) using heap cloning. Then, motivated by the resultant scalability, we propose the idea of mixing various context abstractions, and add the advantages of k-object-sensitive analyses to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:JV2RwH3_ST0C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2020,"May-Happen-in-Parallel (MHP) analysis forms the basis for many problems of program analysis and program understanding. MHP analysis can also be used by IDEs (integrated-development-environments) to help programmers to refactor parallel-programs, identify racy programs, understand which parts of the program run in parallel, and so on. Since the code keeps changing in the IDE, re-computing the MHP information after every change can be an expensive affair. In this manuscript, we propose a novel scheme to perform incremental MHP analysis (on the fly) of programs written in task parallel languages like X10 to keep the MHP information up to date, in an IDE environment.
The key insight of our proposed approach to maintain the MHP information up to date is that we need not rebuild (from scratch) every data structure related to MHP information, after each modification (addition or deletion of statements) in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:M3NEmzRMIkIC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"Load-balancing among the threads of a GPU for graph analytics workloads is difficult because of the irregular nature of graph applications and the high variability in vertex degrees, particularly in power-law graphs. We describe a novel load balancing scheme to address this problem. Our scheme is implemented in the IrGL compiler to allow users to generate efficient load balanced code for a GPU from high-level sequential programs. We evaluated several graph analytics applications on up to 16 distributed GPUs using IrGL to compile the code and the Gluon substrate for inter-GPU communication. Our experiments show that this scheme can achieve an average speed-up of 2.2x on inputs that suffer from severe load imbalance problems when previous state-of-the-art load-balancing schemes are used.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:TFP_iSt0sucC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"Many program-analysis based tools require precise points-to/alias information only for some program variables. To meet this requirement efficiently, there have been many works on demand-driven analyses that perform only the work necessary to compute the points-to or alias information on the requested variables (queries). However, these demand-driven analyses can be very expensive when applied on large systems where the number of queries can be significant. Such a blow-up in analysis time is unacceptable in cases where scalability with real-time constraints is crucial; for example, when program analysis tools are plugged into an IDE (Integrated Development Environment). In this paper, we propose schemes to improve the scalability of demand-driven analyses without compromising on precision. Our work is based on novel ideas for eliminating irrelevant and redundant data-flow paths for the given …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:bEWYMUwI8FkC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"X10 is a partitioned global address space programming language that supports the notion of places; a place consists of some data and some lightweight tasks called activities. Each activity runs at a place and may invoke a place-change operation (using the at-construct) to synchronously perform some computation at another place. These place-change operations can be very expensive, as they need to copy all the required data from the current place to the remote place. However, identifying the necessary number of place-change operations and the required data during each place-change operation are non-trivial tasks, especially in the context of irregular applications (like graph applications) that contain complex code with large amounts of cross-referencing objects—not all of those objects may be actually required, at the remote place. In this article, we present AT-Com, a scheme to optimize X10 code with place …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:iH-uZ7U-co4C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"Distributed graph analytics systems for CPUs, like D-Galois and Gemini, and for GPUs, like D-IrGL and Lux, use a bulk-synchronous parallel (BSP) programming and execution model. BSP permits bulk-communication and uses large messages which are supported efficiently by current message transport layers, but bulk-synchronization can exacerbate the performance impact of load imbalance because a round cannot be completed until every host has completed that round. Asynchronous distributed graph analytics systems circumvent this problem by permitting hosts to make progress at their own pace, but existing systems either use global locks and send small messages or send large messages but do not support general partitioning policies such as vertex-cuts. Consequently, they perform substantially worse than bulk-synchronous systems. Moreover, none of their programming or execution models can be …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:r0BpntZqJG4C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"Many modern task‐parallel languages allow the programmer to synchronize tasks using high‐level constructs like barriers, clocks, and phasers. While these high‐level synchronization primitives help the programmer express the program logic in a convenient manner, they also have their associated overheads. In this paper, we identify the sources of some of these overheads for task‐parallel languages like X10 that support lock‐step synchronization, and propose a mechanism to reduce these overheads.
We first propose three desirable properties that an efficient runtime (for task‐parallel languages like X10, HJ, Chapel, and so on) should satisfy, to minimize the overheads during lock‐step synchronization. We use these properties to derive a scheme to called uClocks to improve the efficiency of X10 clocks; uClocks consists of an extension to X10 clocks and two related runtime optimizations. We prove that uClocks …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:RHpTSmoSYBkC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"Languages like Java and C# follow a two-step process of compilation: static compilation and just-in-time (JIT) compilation. As the time spent in JIT compilation gets added to the execution-time of the application, JIT compilers typically sacrifice the precision of program analyses for efficiency. The alternative of performing the analysis for the whole program statically ignores the analysis of libraries (available only at runtime), and thereby generates imprecise results. To address these issues, in this article, we propose a two-step (static+JIT) analysis framework called precise-yet-efficient (PYE) that helps generate precise analysis-results at runtime at a very low cost.
PYE achieves the twin objectives of precision and performance during JIT compilation by using a two-pronged approach: (i) It performs expensive analyses during static compilation, while accounting for the unavailability of the runtime libraries by generating …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:4JMBOYKVnBMC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"OpenMP uses the efficient ‘team of workers’ model, where workers are given chunks of tasks (iterations of a parallel-for-loop, or sections in a parallel-sections block) to execute, and worker (not tasks) can be synchronized using barriers. Thus, OpenMP restricts the invocation of barriers in these tasks; as otherwise, the behavior of the program would be dependent on the number of runtime workers. To address such a restriction which can adversely impact programmability and readability, Aloor and Nandivada proposed UW-OpenMP by taking inspiration from the more intuitive interaction of tasks and barriers in newer task parallel languages like X10, HJ, Chapel and so on. UW-OpenMP gives the programmer an impression that each parallel task is executed by a unique worker, and importantly these parallel tasks can be synchronized using a barrier construct. Though UW-OpenMP is a useful extension of OpenMP …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:R3hNpaxXUhUC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"The precision of heap analyses determines the precision of several associated optimizations, and has been a prominent area in compiler research. It has been shown that context-sensitive heap analyses are more precise than the insensitive ones, but their scalability continues to be a cause of concern. Though the value-contexts approach improves the scalability of classical call-string based context-sensitive analyses, it still does not scale well for several popular whole-program heap analyses. In this paper, we propose a three-stage analysis approach that lets us scale complex whole-program value-contexts based heap analyses for large programs, without losing their precision.
Our approach is based on a novel idea of level-summarized relevant value-contexts (LSRV-contexts), which take into account an important observation that we do not need to compare the complete value-contexts at each call-site. Our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:HDshCWvjkbEC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"IMOP follows the object-oriented visitor design pattern, and has been written in Java. The parser and certain fundamental visitors of the Abstract Syntax Tree (ASTs), Control Flow Graphs (CFGs), etc., have been written using JavaCC/JTB. This report looks into the design and key features of IMOP, along with an appropriate level of implementation detail, wherever required. 1",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:maZDTaKrznsC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"Graph coloring is a widely studied problem that is used in a variety of applications, such as task scheduling, register allocation, eigenvalue computations, social network analysis, and so on. Many of the modern day applications deal with large graphs (with millions of vertices and edges) and researchers have exploited the parallelism provided by multi-core systems to efficiently color such large graphs. GPUs provide a promising parallel infrastructure to run large applications. In this paper, we present new schemes to efficiently color large graphs on GPUs.
We extend the algorithm of Rokos et al. [21] to efficiently color graphs using GPUs. Their approach has to continually resolve conflicts for color assignment. We present a data driven variation of their algorithm and use an improved scheme for conflict resolution. We also propose two optimizations for our algorithm to reduce both the execution time and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:j3f4tGmQtD8C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2019,"Modern languages like Java and C# follow a two-step process for compilation and execution: the input program is statically compiled to an intermediate language (for example, Bytecode for Java and CIL for C#), which is then executed on a possibly remote virtual machine (for example, JVM and .NET). Many virtual machines (Alpern et al. 2005; Paleczny et al. 2001) use inbuilt just-in-time (JIT) compiler (s) to generate optimized assembly code that can be directly executed on the hardware.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:e5wmG9Sq2KIC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2018,"X10 is a partitioned global address space (PGAS) programming language that supports the notion of places; a place consists of some data and some lightweight tasks called activities. Each activity runs at a place and may invoke a place-change operation (using the at-construct) to synchronously perform some computation at another place. These place-change operations need to copy all the required data from the current place to the remote place. However, identifying the required data during each place-change operation is a non-trivial task, especially in the context of irregular applications (like graph applications) that contain large amounts of cross-referencing objects - not all of those objects may be actually required, at the remote place. In this paper, we present a new optimization AT-Opt that minimizes the amount of data serialized and communicated during place-change operations.
AT-Opt uses a novel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:hFOr9nPyWt4C,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2018,"Refactoring is a program transformation that restructures existing code without altering its behaviour and is a key practice in popular software design movements, such as Agile. Identification of potential refactoring opportunities is an important step in the refactoring process. In large systems, manual identification of useful refactoring opportunities requires a lot of effort and time. Hence, there is a need for automatic identification of refactoring opportunities. However, this problem has not been addressed well for many non-trivial refactorings. Two such non-trivial, yet popular refactorings are “Replace Type Code with Subclass” (SC) and “Replace Type Code with State” (ST) refactorings. In this paper, we present new approaches to identify SC and ST refactoring opportunities.
Our proposed approach is based around the notion of control-fields. A control-field is a field of a class that exposes the different underlying …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:-f6ydRqryjwC,http://www.cse.iitm.ac.in/~krishna
V Krishna Nandivada,"['Compilers', 'Program Analysis', 'Programming Languages', 'High Performance Computing']",9,266,2018,"This paper presents a Tensor Transposition Library for GPUs (TTLG). A distinguishing feature of TTLG is that it also includes a performance prediction model, which can be used by higher level optimizers that use tensor transposition. For example, tensor contractions are often implemented by using the TTGT (Transpose-Transpose-GEMM-Transpose) approach - transpose input tensors to a suitable layout and then use high-performance matrix multiplication followed by transposition of the result. The performance model is also used internally by TTLG for choosing among alternative kernels and/or slicing/blocking parameters for the transposition. TTLG is compared with current state-of-the-art alternatives for GPUs. Comparable or better transposition times for the ""repeated-use"" scenario and considerably better ""single-use"" performance are observed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kbgu7ccAAAAJ&sortby=pubdate&citation_for_view=kbgu7ccAAAAJ:hC7cP41nSMkC,http://www.cse.iitm.ac.in/~krishna
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2022,"Replicated data types (RDTs) are data structures that permit concurrent modification of multiple, potentially geo-distributed, replicas without coordination between them. RDTs are designed in such a way that conflicting operations are eventually deterministically reconciled ensuring convergence. Constructing correct RDTs remains a difficult endeavour due to the complexity of reasoning about independently evolving states of the replicas. With the focus on the correctness of RDTs (and rightly so), existing approaches to RDTs are less efficient compared to their sequential counterparts in terms of the time and space complexity of local operations. This is unfortunate since RDTs are often used in a local-first setting where the local operations far outweigh remote communication.
This paper presents PEEPUL, a pragmatic approach to building and verifying efficient RDTs. To make reasoning about correctness easier, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:HbR8gkJAVGIC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:SpbeaW3--B0C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2021,"Effect handlers have been gathering momentum as a mechanism for modular programming with user-defined effects. Effect handlers allow for non-local control flow mechanisms such as generators, async/await, lightweight threads and coroutines to be composably expressed. We present a design and evaluate a full-fledged efficient implementation of effect handlers for OCaml, an industrial-strength multi-paradigm programming language. Our implementation strives to maintain the backwards compatibility and performance profile of existing OCaml code. Retrofitting effect handlers onto OCaml is challenging since OCaml does not currently have any non-local control flow mechanisms other than exceptions. Our implementation of effect handlers for OCaml: (i) imposes a mean 1% overhead on a comprehensive macro benchmark suite that does not use effect handlers; (ii) remains compatible with program analysis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:kz9GbA2Ns4gC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2021,"Bug-free concurrent programs are hard to write due to non-determinism arising out of concurrency and program inputs. Since concurrency bugs typically manifest under specific inputs and thread schedules, conventional testing methodologies for concurrent programs like stress testing and random testing, which explore random schedules, have a strong chance of missing buggy schedules.
In this paper, we introduce a novel technique that combines property-based testing with mutation-based, grey box fuzzer, applied to event-driven OCaml programs. We have implemented this technique in ConFuzz, a directed concurrency bug-finding tool for event-driven OCaml programs. Using ConFuzz, programmers specify high-level program properties as assertions in the concurrent program. ConFuzz uses the popular greybox fuzzer AFL to generate inputs as well as concurrent schedules to maximise the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:k8Z6L05lTy4C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2020,"Programming loosely connected distributed applications is a challenging endeavour. Loosely connected distributed applications such as geo-distributed stores and intermittently reachable IoT devices cannot afford to coordinate among all of the replicas in order to ensure data consistency due to prohibitive latency costs and the impossibility of coordination if availability is to be ensured. Thus, the state of the replicas evolves independently, making it difficult to develop correct applications. Existing solutions to this problem limit the data types that can be used in these applications, which neither offer the ability to compose them to construct more complex data types nor offer transactions.
In this paper, we describe Banyan, a distributed programming model for developing loosely connected distributed applications. Data types in Banyan are equipped with a three-way merge function à la Git to handle …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:e_rmSamDkqQC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2020,"OCaml is an industrial-strength, multi-paradigm programming language, widely used in industry and academia. OCaml is also one of the few modern managed system programming languages to lack support for shared memory parallel programming. This paper describes the design, a full-fledged implementation and evaluation of a mostly-concurrent garbage collector (GC) for the multicore extension of the OCaml programming language. Given that we propose to add parallelism to a widely used programming language with millions of lines of existing code, we face the challenge of maintaining backwards compatibility--not just in terms of the language features but also the performance of single-threaded code running with the new GC. To this end, the paper presents a series of novel techniques and demonstrates that the new GC strikes a balance between performance and feature backwards compatibility for sequential programs and scales admirably on modern multicore processors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:-FonjvnnhkoC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2019,"Programming geo-replicated distributed systems is challenging given the complexity of reasoning about different evolving states on different replicas. Existing approaches to this problem impose significant burden on application developers to consider the effect of how operations performed on one replica are witnessed and applied on others. To alleviate these challenges, we present a fundamentally different approach to programming in the presence of replicated state. Our insight is based on the use of invertible relational specifications of an inductively-defined data type as a mechanism to capture salient aspects of the data type relevant to how its different instances can be safely merged in a replicated environment. Importantly, because these specifications only address a data type's (static) structural properties, their formulation does not require exposing low-level system-level details concerning asynchrony …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:ILKRHgRFtOwC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2019,"Programmers regularly use distributed version control systems (DVCS) such as Git to facilitate collaborative software development. The primary purpose of a DVCS is to maintain integrity of source code in the presence of concurrent, possibly conflicting edits from collaborators. In addition to safely merging concurrent non-conflicting edits, a DVCS extensively tracks source code provenance to help programmers contextualize and resolve conflicts. Provenance also facilitates debugging by letting programmers see diffs between versions and quickly find those edits that introduced the offending conflict (eg, via git blame).
In this paper, we posit that analogous workflows to collaborative software development also arise in distributed software execution; we argue that the characteristics that make a DVCS an ideal fit for the former also make it an ideal fit for the latter. Building on this observation, we propose a distributed programming model, called carmot that views distributed shared state as an entity evolving in time, manifested as a sequence of persistent versions, and relies on an explicitly defined merge semantics to reconcile concurrent conflicting versions. We show examples demonstrating how carmot simplifies distributed programming, while also enabling novel workflows integral to modern applications such as blockchains. We also describe a prototype implementation of carmot that we use to evaluate its practicality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:L7CI7m0gUJcC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2018,"The language Eff is an OCaml-like language serving as a prototype implementation of the theory of algebraic effects, intended for experimentation with algebraic effects on a large scale. We present the embedding of Eff into OCaml, using the library of delimited continuations or the multicore OCaml branch. We demonstrate the correctness of the embedding denotationally, relying on the tagless-final-style interpreter-based denotational semantics, including the novel, direct denotational semantics of multi-prompt delimited control. The embedding is systematic, lightweight, performant and supports even higher-order, 'dynamic' effects with their polymorphism. OCaml thus may be regarded as another implementation of Eff, broadening the scope and appeal of that language.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:yB1At4FlUx8C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2018,"High-level data types are often associated with semantic invariants that must be preserved by any correct implementation. While having implementations enforce strong guarantees such as linearizability or serializability can often be used to prevent invariant violations in concurrent settings, such mechanisms are impractical in geo-distributed replicated environments, the platform of choice for many scalable Web services. To achieve high-availability essential to this domain, these environments admit various forms of weak consistency that do not guarantee all replicas have a consistent view of an application's state. Consequently, they often admit difficult-to-understand anomalous behaviors that violate a data type's invariants, but which are extremely challenging, even for experts, to understand and debug.
In this paper, we propose a novel programming framework for replicated data types (RDTs) equipped with an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:vbGhcppDl1QC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2018,"We propose a new semantics for shared-memory parallel programs that gives strong guarantees even in the presence of data races. Our local data race freedom property guarantees that all data-race-free portions of programs exhibit sequential semantics. We provide a straightforward operational semantics and an equivalent axiomatic model, and evaluate an implementation for the OCaml programming language. Our evaluation demonstrates that it is possible to balance a comprehensible memory model with a reasonable (no overhead on x86, ~0.6% on ARM) sequential performance trade-off in a mainstream programming language.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:4MWp96NkSFoC,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2018,"Digital infrastructure in modern urban environments is currently very Internet-centric, and involves transmitting data to physically remote environments. The cost for this is data insecurity, high response latency and unpredictable reliability of services. In this paper, we lay out a software architecture that inverts the current model by building an operating system designed to securely connect physical spaces with extremely low latency, high bandwidth local-area computation capabilities and service discovery. We describe our early prototype design OSMOSE, which is based on unikernels and a distributed store.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:URolC5Kub84C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2018,"Languages like C\#, C++, or JavaScript support complex control flow statements like exception handling, iterators (yield), and even asynchrony (async/await) through special extensions. For exceptions, the runtime needs to be extended with exception handling stack frames. For iterators and asynchrony, the situation is more involved, as the compiler needs to turn regular code into stack restoring state machines. Furthermore, these features need to interact as expected, eg finally blocks must not be forgotten in the state machines for iterators. And all of this work needs to be done again for the next control flow abstraction that comes along. Or we can use algebraic effect handlers! This single mechanism generalizes all the control flow abstractions listed above and more, composes freely, has simple operational semantics, and can be efficiently compiled, since there is just one mechanism that needs to be supported well. Handlers allow programmers to keep the code in direct-style, which is easy to reason about, and empower library writers to implement various high-level abstractions without special extensions. The idea of algebraic effects handlers has already been experimented with in the form of small research languages and libraries in several mainstream languages, including OCaml, Haskell, Clojure, and Scala. The next step, and the aim of this seminar, is to seriously consider adoption by mainstream languages including both functional languages such as OCaml or Haskell, as well as languages like JavaScript and the JVM and .NET ecosystems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:TIZ-Mc8IlK0C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:AvfA0Oy_GE0C,https://kcsrk.info/
KC Sivaramakrishnan,"['Functional Programming', 'Concurrency', 'Garbage Collection', 'Distributed Databases']",12,554,2018,"Algebraic effects and their handlers have been steadily gaining attention as a programming language feature for composably expressing user-defined computational effects. While several prototype implementations of languages incorporating algebraic effects exist, Multicore OCaml incorporates effect handlers as the primary means of expressing concurrency in the language. In this paper, we make the observation that effect handlers can elegantly express particularly difficult programs that combine system programming and concurrency without compromising performance. Our experimental results on a highly concurrent and scalable web server demonstrate that effect handlers perform on par with highly optimised monadic concurrency libraries, while retaining the simplicity of direct-style code.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Kc2cHqYAAAAJ&sortby=pubdate&citation_for_view=Kc2cHqYAAAAJ:EkHepimYqZsC,https://kcsrk.info/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",5,125,2022,"Distributed protocols are generally parametric and can be executed on a system with any number of nodes, and hence proving their correctness becomes an infinite state verification problem. The most popular approach for verifying distributed protocols is to find an inductive invariant which is strong enough to prove the required safety property. However, finding inductive invariants is known to be notoriously hard, and is especially harder in the context of distributed protocols which are quite complex due to their asynchronous nature. In this work, we investigate an orthogonal cut-off based approach to verifying distributed protocols which sidesteps the problem of finding an inductive invariant, and instead reduces checking correctness to a finite state verification problem. The main idea is to find a finite, fixed protocol instance called the cutoff instance, such that if the cutoff instance is safe, then any protocol instance would also be safe. Previous cutoff based approaches have only been applied to a restricted class of protocols and specifications. We formalize the cutoff approach in the context of a general protocol modeling language (RML), and identify sufficient conditions which can be efficiently encoded in SMT to check whether a given protocol instance is a cutoff instance. Further, we propose a simple static analysis-based algorithm to automatically synthesize a cut-off instance. We have applied our approach successfully on a number of complex distributed protocols, providing the first known cut-off results for many of them.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&sortby=pubdate&citation_for_view=KiT5oNUAAAAJ:roLk4NBRz8UC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",5,125,2022,"Replicated data types (RDTs) are data structures that permit concurrent modification of multiple, potentially geo-distributed, replicas without coordination between them. RDTs are designed in such a way that conflicting operations are eventually deterministically reconciled ensuring convergence. Constructing correct RDTs remains a difficult endeavour due to the complexity of reasoning about independently evolving states of the replicas. With the focus on the correctness of RDTs (and rightly so), existing approaches to RDTs are less efficient compared to their sequential counterparts in terms of the time and space complexity of local operations. This is unfortunate since RDTs are often used in a local-first setting where the local operations far outweigh remote communication.
This paper presents PEEPUL, a pragmatic approach to building and verifying efficient RDTs. To make reasoning about correctness easier, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&sortby=pubdate&citation_for_view=KiT5oNUAAAAJ:ufrVoPGSRksC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",5,125,2021,"Serializability is a well-understood concurrency control mechanism that eases reasoning about highly-concurrent database programs. Unfortunately, enforcing serializability has a high performance cost, especially on geographically distributed database clusters. Consequently, many databases allow programmers to choose when a transaction must be executed under serializability, with the expectation that transactions would only be so marked when necessary to avoid serious concurrency bugs. However, this is a significant burden to impose on developers, requiring them to (a) reason about subtle concurrent interactions among potentially interfering transactions, (b) determine when such interactions would violate desired invariants, and (c) then identify the minimum number of transactions whose executions should be serialized to prevent these violations. To mitigate this burden, this paper presents a sound fully …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&sortby=pubdate&citation_for_view=KiT5oNUAAAAJ:WF5omc3nYNoC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",5,125,2021,We propose a framework to automate and mechanize simulation-based proofs of cutoffs for parameterized verification of distributed protocols. We propose a strategy to derive the simulation relation given the cutoff instance and encode the correctness of the simulation relation as a formula in first-order logic. We have successfully applied our approach on a number of distributed protocols.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&sortby=pubdate&citation_for_view=KiT5oNUAAAAJ:_FxGoFyzp5QC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",5,125,2020,"Geo-replicated systems provide a number of desirable properties such as globally low latency, high availability, scalability, and built-in fault tolerance. Unfortunately, programming correct applications on top of such systems has proven to be very challenging, in large part because of the weak consistency guarantees they offer. These complexities are exacerbated when we try to adapt existing highly-performant concurrent libraries developed for shared-memory environments to this setting. The use of these libraries, developed with performance and scalability in mind, is highly desirable. But, identifying a suitable notion of correctness to check their validity under a weakly consistent execution model has not been well-studied, in large part because it is problematic to naïvely transplant criteria such as linearizability that has a useful interpretation in a shared-memory context to a distributed one where the cost of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&sortby=pubdate&citation_for_view=KiT5oNUAAAAJ:eQOLeE2rZwMC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",5,125,2019,"Relational database applications are notoriously difficult to test and debug. Concurrent execution of database transactions may violate complex structural invariants that constraint how changes to the contents of one (shared) table affect the contents of another. Simplifying the underlying concurrency model is one way to ameliorate the difficulty of understanding how concurrent accesses and updates can affect database state with respect to these sophisticated properties. Enforcing serializable execution of all transactions achieves this simplification, but it comes at a significant price in performance, especially at scale, where database state is often replicated to improve latency and availability.
To address these challenges, this paper presents a novel testing framework for detecting serializability violations in (SQL) database-backed Java applications executing on weakly-consistent storage systems. We manifest our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&sortby=pubdate&citation_for_view=KiT5oNUAAAAJ:YsMSGLbcyi4C,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",5,125,2019,"Maintaining multiple replicas of data is crucial to achieving scalability, availability and low latency in distributed applications. Conflict-free Replicated Data Types (CRDTs) are important building blocks in this domain because they are designed to operate correctly under the myriad behaviors possible in a weakly-consistent distributed setting. Because of the possibility of concurrent updates to the same object at different replicas, and the absence of any ordering guarantees on these updates, convergence is an important correctness criterion for CRDTs. This property asserts that two replicas which receive the same set of updates (in any order) must nonetheless converge to the same state. One way to prove that operations on a CRDT converge is to show that they commute since commutative actions by definition behave the same regardless of the order in which they execute. In this paper, we present a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&sortby=pubdate&citation_for_view=KiT5oNUAAAAJ:W7OEmFMy1HYC,http://kartiknagar.github.io/
Kartik Nagar,"['Program Analysis', 'Verification', 'Concurrency', 'Hardware-Software Interaction']",5,125,2018,"While a number of weak consistency mechanisms have been developed in recent years to improve performance and ensure availability in distributed, replicated systems, ensuring correctness of transactional applications running on top of such systems remains a difficult and important problem. Serializability is a well-understood correctness criterion for transactional programs; understanding whether applications are serializable when executed in a weakly-consistent environment, however remains a challenging exercise. In this work, we combine the dependency graph-based characterization of serializability and the framework of abstract executions to develop a fully automated approach for statically finding bounded serializability violations under \emph{any} weak consistency model. We reduce the problem of serializability to satisfiability of a formula in First-Order Logic, which allows us to harness the power of existing SMT solvers. We provide rules to automatically construct the FOL encoding from programs written in SQL (allowing loops and conditionals) and the consistency specification written as a formula in FOL. In addition to detecting bounded serializability violations, we also provide two orthogonal schemes to reason about unbounded executions by providing sufficient conditions (in the form of FOL formulae) whose satisfiability would imply the absence of anomalies in any arbitrary execution. We have applied the proposed technique on TPC-C, a real world database program with complex application logic, and were able to discover anomalies under Parallel Snapshot Isolation, and verify serializability for unbounded executions under …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=KiT5oNUAAAAJ&sortby=pubdate&citation_for_view=KiT5oNUAAAAJ:Tyk-4Ss8FVUC,http://kartiknagar.github.io/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2023,"Acoustic imaging sonar systems are widely used for long-range underwater surveillance in various civilian and military applications. They provide 2-D images of underwater objects, even in turbid water conditions where optical underwater imaging systems fail. Achieving high accuracy in automatic deep learning based underwater image classification remains an open problem due to insufficient data availability, poor image resolution, low signal-to-noise ratio surroundings, etc. In this study, we conduct a comparative analysis of different advanced deep learning approaches, i.e., transfer learning and few-shot learning, to address the problem of automatic object classification in sonar images, using a few samples of data. Specifically, two metric learning-based approaches, i.e., siamese network and triplet network as well as library-based approaches, are studied under the few-shot learning paradigm. Extensive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:q3CdL3IzO_QC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2022,"Generalizing beyond the experiences has a significant role in developing robust and practical machine learning systems. It has been shown that current Visual Question Answering (VQA) models are over-dependent on the language-priors (spurious correlations between question-types and their most frequent answers) from the train set and pose poor performance on Out-of-Distribution (OOD) test sets. This conduct negatively affects the robustness of VQA models and restricts them from being utilized in real-world situations. This paper shows that the sequence model architecture used in the question-encoder has a significant role in the OOD performance of VQA models. To demonstrate this, we performed a detailed analysis of various existing RNN-based and Transformer-based question-encoders, and along, we proposed a novel Graph attention network (GAT)-based question-encoder. Our study found that a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:HbR8gkJAVGIC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2022,"Video-based computer vision tasks can benefit from estimation of the salient regions and interactions between those regions. Traditionally, this has been done by identifying the object regions in the images by utilizing pre-trained models to perform object detection, object segmentation and/or object pose estimation. Although using pre-trained models is a viable approach, it has several limitations in the need for an exhaustive annotation of object categories, a possible domain gap between datasets and a bias that is typically present in pre-trained models. In this work, we propose to utilize the common rationale that a sequence of video frames capture a set of common objects and interactions between them, thus a notion of co-segmentation between the video frame features may equip the model with the ability to automatically focus on task-specific salient regions and improve the underlying task’s performance in an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:oNZyr7d5Mn4C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2022,"The human face is one of the predominant means of person recognition. Human faces are affected by many factors i.e. time, attributes, weather, and other subject-specific variations. Although face aging has been studied in the past, the impact of the aforesaid factors, especially, the effect of attributes on the aging process were unexplored. In this paper, we propose a novel holistic “Face Age progression With Attribute Manipulation” (FAWAM) model that generates face images at different ages while simultaneously varying attributes and other subject specific characteristics. We address the task in a bottom-up manner, considering both age and attributes submodules. For face aging, we use an attribute-conscious face aging model with a pyramidal generative adversarial network that can model age-specific facial changes while maintaining intrinsic subject specific characteristics. For facial attribute manipulation, the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:LI9QrySNdTsC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2022,"Acoustic imaging systems dominate in underwater imaging due to their unique ability to illuminate objects on the seabed, even in dark or turbid water conditions. These systems mounted on an autonomous underwater vehicle (AUV) are being used for a variety of civilian and military applications. Mine detection and classification is a predominant application. The raw images captured using these systems are usually noisy and poor in their resolution. Consequently, methods to enhance sonar images are necessary to aid further processing and classification of these acquired scenes. Inspired by the developments in the field of deep learning in different areas of computer vision, this study explores efficient deep neural networks for acoustic image super resolution. The study is performed on a custom-made sonar image dataset to handle the deficiency of public datasets in the domain. We employ a Generative …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:i2xiXl-TujoC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2022,"The present disclosure relates to semiconductor structures and, more particularly, to devices with slotted active regions and methods of manufacture. The method includes: forming a mandrel on top of a diffusion region comprising a diffusion material; forming a first material over the mandrel and the diffusion region; removing the mandrel to form multiple spacers each having a thickness; depositing a second material over the spacers and the diffusion material; and forming slots in the diffusion region by removing a portion of the second material over the diffusion region and the underlying diffusion material.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:Dip1O2bNi0gC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2022,"Video frame interpolation aims to synthesize one or multiple frames between two consecutive frames in a video. It has a wide range of applications including slow-motion video generation, video compression and developing video codecs. Some older works tackled this problem by assuming per-pixel linear motion between video frames. However, objects often follow a non-linear motion pattern in the real domain and some recent methods attempt to model per-pixel motion by non-linear models (eg, quadratic). A quadratic model can also be inaccurate, especially in the case of motion discontinuities over time (ie sudden jerks) and occlusions, where some of the flow information may be invalid or inaccurate. In our paper, we propose to approximate the per-pixel motion using a space-time convolution network that is able to adaptively select the motion model to be used. Specifically, we are able to softly switch between a linear and a quadratic model. Towards this end, we use an end-to-end 3D CNN encoder-decoder architecture over bidirectional optical flows and occlusion maps to estimate the non-linear motion model of each pixel. Further, a motion refinement module is employed to refine the non-linear motion and the interpolated frames are estimated by a simple warping of the neighboring frames with the estimated per-pixel motion. We show that our method outperforms state-of-the-art algorithms on four datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:e_rmSamDkqQC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2022,"The goal of video captioning is to generate captions for a video by understanding visual and temporal cues. A general video captioning model consists of an Encoder-Decoder framework where Encoder generally captures the visual and temporal information while the decoder generates captions. Recent works have incorporated object-level information into the Encoder by a pretrained off-the-shelf object detector, significantly improving performance. However, using an object detector comes with the following downsides: 1) object detectors may not exhaustively capture all the object categories. 2) In a realistic setting, the performance may be influenced by the domain gap between the object detector and the visual-captioning dataset. To remedy this, we argue that using an external object detector could be eliminated if the model is equipped with the capability of automatically finding salient regions. To achieve this, we propose a novel architecture that learns to attend to salient regions such as objects, persons automatically using a co-segmentation inspired attention module. Then, we utilize a novel salient region interaction module to promote information propagation between salient regions of adjacent frames. Further, we incorporate this salient region-level information into the model using knowledge distillation. We evaluate our model on two benchmark datasets MSR-VTT and MSVD, and show that our model achieves competitive performance without using any object detector.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:WZBGuue-350C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2021,"Generalizing beyond the experiences has a significant role in developing practical AI systems. It has been shown that current Visual Question Answering (VQA) models are over-dependent on the language-priors (spurious correlations between question-types and their most frequent answers) from the train set and pose poor performance on Out-of-Distribution (OOD) test sets. This conduct limits their generalizability and restricts them from being utilized in real-world situations. This paper shows that the sequence model architecture used in the question-encoder has a significant role in the generalizability of VQA models. To demonstrate this, we performed a detailed analysis of various existing RNN-based and Transformer-based question-encoders, and along, we proposed a novel Graph attention network (GAT)-based question-encoder. Our study found that a better choice of sequence model in the question-encoder improves the generalizability of VQA models even without using any additional relatively complex bias-mitigation approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:k8Z6L05lTy4C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2021,"Attention models are widely used in Vision-language (V-L) tasks to perform the visual-textual correlation. Humans perform such a correlation with a strong linguistic understanding of the visual world. However, even the best performing attention model in V-L tasks lacks such a high-level linguistic understanding, thus creating a semantic gap between the modalities. In this paper, we propose an attention mechanism - Linguistically-aware Attention (LAT) - that leverages object attributes obtained from generic object detectors along with pre-trained language models to reduce this semantic gap. LAT represents visual and textual modalities in a common linguistically-rich space, thus providing linguistic awareness to the attention process. We apply and demonstrate the effectiveness of LAT in three V-L tasks: Counting-VQA, VQA, and Image captioning. In Counting-VQA, we propose a novel counting-specific VQA model to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:ILKRHgRFtOwC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2021,"This paper explores an efficient solution for Space-time Super-Resolution, aiming to generate High-resolution Slow-motion videos from Low Resolution and Low Frame rate videos. A simplistic solution is the sequential running of Video Super Resolution and Video Frame interpolation models. However, this type of solutions are memory inefficient, have high inference time, and could not make the proper use of space-time relation property. To this extent, we first interpolate in LR space using quadratic modeling. Input LR frames are super-resolved using a state-of-the-art Video Super-Resolution method. Flowmaps and blending mask which are used to synthesize LR interpolated frame is reused in HR space using bilinear upsampling. This leads to a coarse estimate of HR intermediate frame which often contains artifacts along motion boundaries. We use a refinement network to improve the quality of HR intermediate frame via residual learning. Our model is lightweight and performs better than current state-of-the-art models in REDS STSR Validation set.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:MLfJN-KU85MC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2021,"Practical autonomous driving systems face two crucial challenges: memory constraints and domain gap issues. In this paper, we present a novel approach to learn domain adaptive knowledge in models with limited memory, thus bestowing the model with the ability to deal with these issues in a comprehensive manner. We term this as"" Domain Adaptive Knowledge Distillation"" and address the same in the context of unsupervised domain-adaptive semantic segmentation by proposing a multi-level distillation strategy to effectively distil knowledge at different levels. Further, we introduce a novel cross entropy loss that leverages pseudo labels from the teacher. These pseudo teacher labels play a multifaceted role towards:(i) knowledge distillation from the teacher network to the student network & (ii) serving as a proxy for the ground truth for target domain images, where the problem is completely unsupervised. We introduce four paradigms for distilling domain adaptive knowledge and carry out extensive experiments and ablation studies on real-to-real as well as synthetic-to-real scenarios. Our experiments demonstrate the profound success of our proposed method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:b1wdh0AR-JQC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2020,"Divide and conquer is an established algorithm design paradigm that has proven itself to solve a variety of problems efficiently. However, it is yet to be fully explored in solving problems with a neural network, particularly the problem of image super-resolution. In this work, we propose an approach to divide the problem of image super-resolution into multiple subproblems and then solve/conquer them with the help of a neural network. Unlike a typical deep neural network, we design an alternate network architecture that is much wider (along with being deeper) than existing networks and is specially designed to implement the divide-and-conquer design paradigm with a neural network. Additionally, a technique to calibrate the intensities of feature map pixels is being introduced. Extensive experimentation on five datasets reveals that our approach towards the problem and the proposed architecture generate better …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:TIZ-Mc8IlK0C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2020,"Representation learning from 3D point clouds is challenging due to their inherent nature of permutation invariance and irregular distribution in space. Existing deep learning methods follow a hierarchical feature extraction paradigm in which high-level abstract features are derived from low-level features. However, they fail to exploit different granularity of information due to the limited interaction between these features. To this end, we propose Multi-Abstraction Refinement Network (MARNet) that ensures an effective exchange of information between multi-level features to gain local and global contextual cues while effectively preserving them till the final layer. We empirically show the effectiveness of MARNet in terms of state-of-the-art results on two challenging tasks: Shape classification and Coarse-to-fine grained semantic segmentation. MARNet significantly improves the classification performance by 2% over the baseline and outperforms the state-of-the-art methods on semantic segmentation task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:gsN89kCJA0AC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2020,"A sub-problem of paramount importance in super-resolution is the generation of an upsampled image (or frame) that is ‘sharp’. In deblurring, the core problem itself is of removing the blur, and it is equivalent to the problem of generating a ‘sharper’ version of the given image. This sharpness in the generated image comes by accurately predicting the high-frequency details (commonly referred to as fine-details) such as object edges. Thus high-frequency prediction is a vital sub-problem in super-resolution and a core problem in deblurring. To generate a sharp upsampled or deblurred image, this paper proposes a multi-stage neural network architecture ‘HFR-Net’ that works on the principle of ‘explicit refinement and fusion of high-frequency details’. To implement this principle, HFR-Net is trained with a novel 2-phase progressive–retrogressive training method. In addition to the training method, this paper also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:p__nRnzSRKYC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2020,"Recent studies have shown that current VQA models are heavily biased on the language priors in the train set to answer the question, irrespective of the image. E.g., overwhelmingly answer “what sport is” as “tennis” or “what color banana” as “yellow.” This behavior restricts them from real-world application scenarios. In this work, we propose a novel model-agnostic question encoder, Visually-Grounded Question Encoder (VGQE), for VQA that reduces this effect. VGQE utilizes both visual and language modalities equally while encoding the question. Hence the question representation itself gets sufficient visual-grounding, and thus reduces the dependency of the model on the language priors. We demonstrate the effect of VGQE on three recent VQA models and achieve state-of-the-art results on the bias-sensitive split of the VQAv2 dataset; VQA-CPv2. Further, unlike the existing bias-reduction techniques, on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:EYYDruWGBe4C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2020,"A video super-resolution technique is expected to generate asharp'upsampled video. The sharpness in the generated video comes from the precise prediction of the high-frequency details (eg object edges). Thus high-frequency prediction becomes a vital sub-problem of the super-resolution task. To generate a sharp-upsampled video, this paper proposes an upsampling network architectureHFR-Net'that works on the principle ofexplicit refinement and fusion of high-frequency details'. To implement this principle and to train HFR-Net, a novel technique named 2-phase progressive-retrogressive training is being proposed. Additionally, a method called dual motion warping is also being introduced to preprocess the videos that have varying motion intensities (slow and fast). Results on multiple video datasets demonstrate the improved performance of our approach over the current state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:4MWp96NkSFoC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2020,"Divide and Conquer is a well-established approach in the literature that has efficiently solved a variety of problems. However, it is yet to be explored in full in solving image super-resolution. To predict a sharp up-sampled image, this work proposes a divide and conquer approach based wide and deep network (WDN) that divides the 4x up-sampling problem into 32 disjoint subproblems that can be solved simultaneously and independently of each other. Half of these subproblems deal with predicting the overall features of the high-resolution image, while the remaining are exclusively for predicting the finer details. Additionally, a technique that is found to be more effective in calibrating the pixel intensities has been proposed. Results obtained on multiple datasets demonstrate the improved performance of the proposed wide and deep network over state-of-the-art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:ML0RJ9NH7IQC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2020,"Conventional approaches to Sketch-Based Image Retrieval (SBIR) assume that the data of all the classes are available during training. The assumption may not always be practical since the data of a few classes may be unavailable, or the classes may not appear at the time of training. Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) relaxes this constraint and allows the algorithm to handle previously unseen classes during the test. This paper proposes a generative approach based on the Stacked Adversarial Network (SAN) and the advantage of Siamese Network (SN) for ZS-SBIR. While SAN generates a high-quality sample, SN learns a better distance metric compared to that of the nearest neighbor search. The capability of the generative model to synthesize image features based on the sketch reduces the SBIR problem to that of an image-to-image retrieval problem. We evaluate the efficacy of our proposed approach on TU-Berlin, and Sketchy database in both standard ZSL and generalized ZSL setting. The proposed method yields a significant improvement in standard ZSL as well as in a more challenging generalized ZSL setting (GZSL) for SBIR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:Z5m8FVwuT1cC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2019,"Deblurring is the task of restoring a blurred image to a sharp one, retrieving the information lost due to the blur. In blind deblurring we have no information regarding the blur kernel. As deblurring can be considered as an image to image translation task, deep learning based solutions, including the ones which use GAN (Generative Adversarial Network), have been proven effective for deblurring. Most of them have an encoder-decoder structure. Our objective is to try different GAN structures and improve its performance through various modifications to the existing structure for supervised deblurring. In supervised deblurring we have pairs of blurred and their corresponding sharp images, while in the unsupervised case we have a set of blurred and sharp images but their is no correspondence between them. Modifications to the structures is done to improve the global perception of the model. As blur is non-uniform in nature, for deblurring we require global information of the entire image, whereas convolution used in CNN is able to provide only local perception. Deep models can be used to improve global perception but due to large number of parameters it becomes difficult for it to converge and inference time increases, to solve this we propose the use of attention module (non-local block) which was previously used in language translation and other image to image translation tasks in deblurring. Use of residual connection also improves the performance of deblurring as features from the lower layers are added to the upper layers of the model. It has been found that classical losses like L1, L2, and perceptual loss also help in training of GANs when …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:t7zJ5fGR-2UC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2019,"Deep Convolutional Neural Networks have shown drastic improvements in the performance of various Computer Vision tasks. However, shape classification is a problem that has not seen state-of-the-art results using CNNs. The problem is due to lack of large amounts of data to learn to handle multiple variations such as noise, pose variations, part articulations and affine deformations present in the shapes. In this paper, we introduce a new technique for augmenting 2D shape data that uses part articulations. This utilizes a novel articulation cut detection method to determine putative shape parts. Standard off-the-shelf CNN models trained with our novel data augmentation technique on standard 2D shape datasets yielded significant improvements over the state-of-the-art in most experiments and our data augmentation approach has the potential to be extended to other problems such as Image Classification and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:BrmTIyaxlBUC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2019,"In the information retrieval task, sketch-based image retrieval (SBIR) has drawn significant attention owing to the ease with which sketches can be drawn. The existing deep learning methods for the SBIR are very unrealistic in the real scenario, and its performance reduces drastically for unseen class test examples. Recently, Zero-Shot Sketch-Based Image Retrieval (ZS-SBIR) has drawn a lot of attention due to its ability to retrieve the novel/unseen class images at test time. These methods try to project sketch features into the image domain by learning a distribution conditioned on the sketch. We propose a new framework for ZS-SBIR that models joint distribution between the sketch and image domain using a generative adversarial network. The joint distribution modeling ability of our generative model helps to reduce the domain gap between the sketches and images. Our framework helps to synthesize the novel class image features using sketch features. The generative ability of our model for the unseen/novel classes, conditioned on sketch feature, allows it to perform well on the seen as well as unseen class sketches. We conduct extensive experiments on two widely used SBIR benchmark datasets-Sketchy and Tu-Berlin and obtain significant improvement over the existing state-of-the-art. We will release the code publicly for reproducibility of results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:uc_IGeMz5qoC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2019,"Recognizing a person's face images with intentional/unintentional disguising effects such as make-up, plastic surgery, artificial wearables (hats, eye-glasses) is a challenging task. We propose a Feature EnsemBle Network (FEBNet) for recognizing Disguised Faces in the Wild (DFW). FEBNet encompasses multiple base networks (SE-ResNet50, Inception-ResNet-V1) pretrained on large-scale face recognition datasets (MS-Celeb-1M, VGGFace2) and fine-tuned on DFW training dataset. During the fine-tuning phase, we propose to use two novel objective functions, namely, 1) Category loss, 2) Impersonator Triplet loss along with two prevalent objective functions: Identity loss, Inter-person Triplet loss. To further improve the performance, we apply a state-of-the-art re-ranking strategy as a post-processing step. Extensive ablation studies and evaluation results show that FEBNet significantly outperforms the baseline models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:yB1At4FlUx8C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2019,"Person re-identification (Re-ID) is an important real-world surveillance problem that entails associating a person's identity over a network of cameras. Video-based Re-ID approaches have gained significant attention recently since a video, and not just an image, is often available. In this work, we propose a novel Co-segmentation inspired video Re-ID deep architecture and formulate a Co-segmentation based Attention Module (COSAM) that activates a common set of salient features across multiple frames of a video via mutual consensus in an unsupervised manner. As opposed to most of the prior work, our approach is able to attend to person accessories along with the person. Our plug-and-play and interpretable COSAM module applied on two deep architectures (ResNet50, SE-ResNet50) outperform the state-of-the-art methods on three benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:nrtMV_XWKgEC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2018,"Sketch-based image retrieval (SBIR) is the task of retrieving images from a natural image database that correspond to a given hand-drawn sketch. Ideally, an SBIR model should learn to associate components in the sketch (say, feet, tail, etc.) with the corresponding components in the image having similar shape characteristics. However, current evaluation methods simply focus only on coarse-grained evaluation where the focus is on retrieving images which belong to the same class as the sketch but not necessarily having the same shape characteristics as in the sketch. As a result, existing methods simply learn to associate sketches with classes seen during training and hence fail to generalize to unseen classes. In this paper, we propose a new benchmark for zero-shot SBIR where the model is evaluated in novel classes that are not seen during training. We show through extensive experiments that existing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:xtoqd-5pKcoC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2018,"Matching deformable objects using their shapes are an important problem in computer vision since shape is perhaps the most distinguishable characteristic of an object. The problem is difficult due to many factors such as intra-class variations, local deformations, articulations, viewpoint changes and missed and extraneous contour portions due to errors in shape extraction. While small local deformations have been handled in the literature by allowing some leeway in the matching of individual contour points via methods such as Chamfer distance and Hausdorff distance, handling more severe deformations and articulations has been done by applying local geometric corrections such as similarity or affine. However, determining which portions of the shape should be used for the geometric corrections is very hard, although some methods have been tried. In this paper, we address this problem by an efficient …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:u_35RYKgDlwC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2018,"The task of matching image patches is a fundamental problem in computer vision. When sufficiently textured patches are normalized up to similarity transformation, a simple Normalized Cross Correlation (NCC) of corresponding patches will give a high value. In practice, using it on patches per se may not perform well due to the noisy variations of pixel intensities. A more prudent approach will be to apply it to the abstract features extracted by a deep convolutional network. We study the applicability of an NCC based convolutional network for the task of Patch Matching. Further, there may be cases where the network may fail due to insufficient textures. In those cases, a simple pixel difference based method will be beneficial. To this end, we propose to improve the two basic architectures, Siamese networks and Central-Surround stream networks, using robust matching layers for learning the similarities of patches …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:eJXPG6dFmWUC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2018,"We present a generative framework for zero-shot action recognition where some of the possible action classes do not occur in the training data. Our approach is based on modeling each action class using a probability distribution whose parameters are functions of the attribute vector representing that action class. In particular, we assume that the distribution parameters for any action class in the visual space can be expressed as a linear combination of a set of basis vectors where the combination weights are given by the attributes of the action class. These basis vectors can be learned solely using labeled data from the known (i.e., previously seen) action classes, and can then be used to predict the parameters of the probability distributions of unseen action classes. We consider two settings: (1) Inductive setting, where we use only the labeled examples of the seen action classes to predict the unseen action class …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:5Ul4iDaHHb8C,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:S16KYo8Pm5AC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2018,"Sketch-based image retrieval (SBIR) is the task of retrieving images from a natural image database that correspond to a given hand-drawn sketch. Ideally, an SBIR model should learn to associate components in the sketch (say, feet, tail, etc.) with the corresponding components in the image. However, current evaluation methods simply focus only on coarse-grained evaluation where the focus is on retrieving images which belong to the same class as the sketch but not necessarily having the same components as in the sketch. As a result, existing methods simply learn to associate sketches with classes seen during training and hence fail to generalize to unseen classes. In this paper, we propose a new bench mark for zero-shot SBIR where the model is evaluated on novel classes that are not seen during training. We show through extensive experiments that existing models for SBIR which are trained in a discriminative setting learn only class specific mappings and fail to generalize to the proposed zero-shot setting. To circumvent this, we propose a generative approach for the SBIR task by proposing deep conditional generative models which take the sketch as an input and fill the missing information stochastically. Experiments on this new benchmark created from the"" Sketchy"" dataset, which is a large-scale database of sketch-photo pairs demonstrate that the performance of these generative models is significantly better than several state-of-the-art approaches in the proposed zero-shot framework of the coarse-grained SBIR task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:z_wVstp3MssC,http://sites.google.com/view/anurag-mittal/
Anurag Mittal,"['Computer Vision', 'Image Processing']",18,1722,2018,"Zero shot learning in Image Classification refers to the setting where images from some novel classes are absent in the training data but other information such as natural language descriptions or attribute vectors of the classes are available. This setting is important in the real world since one may not be able to obtain images of all the possible classes at training. While previous approaches have tried to model the relationship between the class attribute space and the image space via some kind of a transfer function in order to model the image space correspondingly to an unseen class, we take a different approach and try to generate the samples from the given attributes, using a conditional variational autoencoder, and use the generated samples for classification of the unseen classes. By extensive testing on four benchmark datasets, we show that our model outperforms the state of the art, particularly in the more realistic generalized setting, where the training classes can also appear at the test time along with the novel classes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=mB9AZSAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=mB9AZSAAAAAJ:u9iWguZQMMsC,http://sites.google.com/view/anurag-mittal/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2023,"We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm, when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal O (1/t) rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation, and show that this variant fares favourably in problems with ill-conditioned features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:QyXJ3EUuO1IC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2023,"We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm, when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyze a variant of TD that incorporates regularization. From our finite time analysis, we conclude that the regularized version of TD is useful for problems with ill-conditioned features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:U_HPUtbDl20C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2022,"We present in this paper a family of generalized simultaneous perturbation stochastic approximation (G-SPSA) estimators that estimate the gradient of the objective using noisy function measurements, but where the number of function measurements and the form of the gradient estimator is guided by the desired estimator bias. In particular, estimators with more function measurements are seen to result in lower bias. We provide an analysis of convergence of generalized SPSA, and point to possible future directions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:PyEswDtIyv0C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2022,"The objective in a traditional reinforcement learning (RL) problem is to find a policy that optimizes the expected value of a performance metric such as the infinite-horizon cumulative discounted or long-run average cost/reward. In practice, optimizing the expected value alone may not be satisfactory, in that it may be desirable to incorporate the notion of risk into the optimization problem formulation, either in the objective or as a constraint. Various risk measures have been proposed in the literature, eg, exponential utility, variance, percentile performance, chance constraints, value at risk (quantile), conditional value-at-risk, prospect theory and its later enhancement, cumulative prospect theory.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:HGTzPopzzJcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2022,"In several applications such as clinical trials and financial portfolio optimization, the expected value (or the average reward) does not satisfactorily capture the merits of a drug or a portfolio. In such applications, risk plays a crucial role, and a risk-aware performance measure is preferable, so as to capture losses in the case of adverse events. This survey aims to consolidate and summarise the existing research on risk measures, specifically in the context of multi-armed bandits. We review various risk measures of interest, and comment on their properties. Next, we review existing concentration inequalities for various risk measures. Then, we proceed to defining risk-aware bandit problems, We consider algorithms for the regret minimization setting, where the exploration-exploitation trade-off manifests, as well as the best-arm identification setting, which is a pure exploration problem -- both in the context of risk-sensitive measures. We conclude by commenting on persisting challenges and fertile areas for future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:jE2MZjpN3IcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2022,"We introduce biased gradient oracles to capture a setting where the function measurements have an estimation error that can be controlled through a batch size parameter. Our proposed oracles are appealing in several practical contexts, for instance, risk measure estimation from a batch of independent and identically distributed (i.i.d.) samples, or simulation optimization, where the function measurements are ‘biased’ due to computational constraints. In either case, increasing the batch size reduces the estimation error. We highlight the applicability of our biased gradient oracles in a risk-sensitive reinforcement learning setting. In the stochastic non-convex optimization context, we analyze a variant of the randomized stochastic gradient (RSG) algorithm with a biased gradient oracle. We quantify the convergence rate of this algorithm by deriving non-asymptotic bounds on its performance. Next, in the stochastic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:Dem6FJhTUoYC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2022,"This paper presents a unified approach based on Wasserstein distance to derive concentration bounds for empirical estimates for two broad classes of risk measures defined in the paper. The classes of risk measures introduced include as special cases well known risk measures from the finance literature such as conditional value at risk (CVaR), optimized certainty equivalent risk, spectral risk measures, utility-based shortfall risk, cumulative prospect theory (CPT) value, rank dependent expected utility and distorted risk measures. Two estimation schemes are considered, one for each class of risk measures. One estimation scheme involves applying the risk measure to the empirical distribution function formed from a collection of i.i.d. samples of the random variable (r.v.), while the second scheme involves applying the same procedure to a truncated sample. The bounds provided apply to three popular classes of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:-jrNzM816MMC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2021,"Utility-Based Shortfall Risk (UBSR) is a risk metric that is increasingly popular in financial applications, owing to certain desirable properties that it enjoys. We consider the problem of estimating UBSR in a recursive setting, where samples from the underlying loss distribution are available one-at-a-time. We cast the UBSR estimation problem as a root finding problem, and propose stochastic approximation-based estimations schemes. We derive non-asymptotic bounds on the estimation error in the number of samples. We also consider the problem of UBSR optimization within a parameterized class of random variables. We propose a stochastic gradient descent based algorithm for UBSR optimization, and derive non-asymptotic bounds on its convergence.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:NDuN12AVoxsC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2021,"We propose two policy gradient algorithms for solving the problem of control in an off-policy reinforcement learning (RL) context. Both algorithms incorporate a smoothed functional (SF) based gradient estimation scheme. The first algorithm is a straightforward combination of importance sampling-based off-policy evaluation with SF-based gradient estimation. The second algorithm, inspired by the stochastic variance-reduced gradient (SVRG) algorithm, incorporates variance reduction in the update iteration. For both algorithms, we derive non-asymptotic bounds that establish convergence to an approximate stationary point. From these results, we infer that the first algorithm converges at a rate that is comparable to the well-known REINFORCE algorithm in an off-policy RL context, while the second algorithm exhibits an improved rate of convergence.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:AXkvAH5U_nMC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2021,"We consider the problem of estimating a spectral risk measure (SRM) from iid samples, and propose a novel method that is based on numerical integration. We show that our SRM estimate concentrates exponentially, when the underlying distribution has bounded support. Further, we also consider the case when the underlying distribution satisfies an exponential moment bound, which includes sub-Gaussian and subexponential distributions. For these distributions, we derive a concentration bound for our estimation scheme. We validate the theoretical findings on a synthetic setup, and in a vehicular traffic routing application.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:q-HalDI95KYC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2021,"We propose a stochastic approximation (SA) based method with randomization of samples for policy evaluation using the least squares temporal difference (LSTD) algorithm. Our proposed scheme is equivalent to running regular temporal difference learning with linear function approximation, albeit with samples picked uniformly from a given dataset. Our method results in an O(d) improvement in complexity in comparison to LSTD, where d is the dimension of the data. We provide non-asymptotic bounds for our proposed method, both in high probability and in expectation, under the assumption that the matrix underlying the LSTD solution is positive definite. The latter assumption can be easily satisfied for the pathwise LSTD variant proposed by Lazaric (J Mach Learn Res 13:3041–3074, 2012). Moreover, we also establish that using our method in place of LSTD does not impact the rate of convergence of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:SjuI4pbJlxcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2020,"Conditional Value-at-Risk (CVaR) is a widely used risk metric in applications such as finance. We derive concentration bounds for CVaR estimates, considering separately the cases of sub-Gaussian, light-tailed and heavy-tailed distributions. For the sub-Gaussian and light-tailed cases, we use a classical CVaR estimator based on the empirical distribution constructed from the samples. For heavy-tailed random variables, we assume a mild ‘bounded moment’condition, and derive a concentration bound for a truncation-based estimator. Our concentration bounds exhibit exponential decay in the sample size, and are tighter than those available in the literature for the above distribution classes. To demonstrate the applicability of our concentration results, we consider the CVaR optimization problem in a multi-armed bandit setting. Specifically, we address the best CVaR-arm identification problem under a fixed budget. Using our CVaR concentration results, we derive an upperbound on the probability of incorrect arm identification.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:Ade32sEp0pkC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2020,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:1Ye0OR6EYb4C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2019,"Traditional multi-armed bandit problems are geared towards finding the arm with the highest expected value – an objective that is risk-neutral. In several practical applications, e.g., finance, a risk-sensitive objective is to control the worst-case losses and Conditional Value-at-Risk (CVaR) is a popular risk measure for modeling the aforementioned objective. We consider the CVaR optimization problem in a best-arm identification framework under a fixed budget. First, we derive a novel two-sided concentration bound for a well-known CVaR estimator using empirical distribution function, assuming that the underlying distribution is unbounded, but light-tailed. This bound may be of independent interest. Second, we adapt the well-known successive rejects algorithm to incorporate a CVaRbased criterion and derive an upper-bound on the probability of incorrect identification of our proposed algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:rHJHxKgnXwkC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2019,"We introduce deterministic perturbation (DP) schemes for the recently proposed random directions stochastic approximation, and propose new first-order and second-order algorithms. In the latter case, these are the first second-order algorithms to incorporate DPs. We show that the gradient and/or Hessian estimates in the resulting algorithms with DPs are asymptotically unbiased, so that the algorithms are provably convergent. Furthermore, we derive convergence rates to establish the superiority of the first-order and second-order algorithms, for the special case of a convex and quadratic optimization problem, respectively. Numerical experiments are used to validate the theoretical results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:-mN3Mh-tlDkC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2019,"The classic objective in a reinforcement learning (RL) problem is to find a policy that minimizes, in expectation, a long-run cost objective such as the infinite horizon discounted or average cost. In many practical applications, optimizing the expected value alone is not sufficient and it may be necessary to include a risk measure in the optimization process either as the objective or a constraint. Various risk measures have been proposed in the literature, e.g., mean-variance tradeoff, exponential utility, the percentile performance, value at risk, conditional value at risk, prospect theory and its later enhancement, cumulative prospect theory. In this two-part article, we are primarily concerned with the combination of risk criteria and reinforcement learning in a constrained optimization framework, i.e., a setting where the goal to find a policy that minimizes the usual objective of infinite horizon discounted/average cost, while …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:prdVHNxh-e8C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2019,"Known finite-sample concentration bounds for the Wasserstein distance between the empirical and true distribution of a random variable are used to derive a two-sided concentration bound for the error between the true conditional value-at-risk (CVaR) of a (possibly unbounded) random variable and a standard estimate of its CVaR computed from an iid sample. The bound applies under fairly general assumptions on the random variable, and improves upon previous bounds which were either one sided, or applied only to bounded random variables. Specializations of the bound to sub-Gaussian and sub-exponential random variables are also derived. A similar procedure is followed to derive concentration bounds for the error between the true and estimated Cumulative Prospect Theory (CPT) value of a random variable, in cases where the random variable is bounded or sub-Gaussian. These bounds are shown to match a known bound in the bounded case, and improve upon the known bound in the sub-Gaussian case. The usefulness of the bounds is illustrated through an algorithm, and corresponding regret bound for a stochastic bandit problem, where the underlying risk measure to be optimized is CVaR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:DBa1UEJaJKAC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2019,"Traditional multi-armed bandit problems are geared towards finding the arm with the highest expected value--an objective that is risk-neutral. In several practical applications, eg, finance, a risk-sensitive objective is to control the worst-case losses and Conditional Value-at-Risk (CVaR) is a popular risk measure for modelling the aforementioned objective. We consider the CVaR optimization problem in a best-arm identification framework under a fixed budget. First, we derive a novel two-sided concentration bound for a well-known CVaR estimator using empirical distribution function, assuming that the underlying distribution is unbounded, but either sub-Gaussian or light-tailed. This bound may be of independent interest. Second, we adapt the well-known successive rejects algorithm to incorporate a CVaR-based criterion and derive an upper-bound on the probability of incorrect identification of our proposed algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:WC9gN4BGCRcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2019,"While the objective in traditional multi-armed bandit problems is to find the arm with the highest mean, in many settings, finding an arm that best captures information about other arms is of interest. This objective, however, requires learning the underlying correlation structure and not just the means. Sensors placement for industrial surveillance and cellular network monitoring are a few applications, where the underlying correlation structure plays an important role. Motivated by such applications, we formulate the correlated bandit problem, where the objective is to find the arm with the lowest mean-squared error (MSE) in estimating all the arms. To this end, we derive first an MSE estimator based on sample variances/covariances and show that our estimator exponentially concentrates around the true MSE. Under a best-arm identification framework, we propose a successive rejects type algorithm and provide bounds on the probability of error in identifying the best arm. Using minimax theory, we also derive fundamental performance limits for the correlated bandit problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:LPtt_HFRSbwC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2019,"Known finite-sample concentration bounds for the Wasserstein distance between the empirical and true distribution of a random variable are used to derive a two-sided concentration bound for the error between the true conditional value-at-risk (CVaR) of a (possibly unbounded) random variable and a standard estimate of its CVaR computed from an iid sample. The bound applies under fairly general assumptions on the random variable, and improves upon previous bounds which were either one sided, or applied only to bounded random variables. Specializations of the bound to sub-Gaussian and sub-exponential random variables are also derived. A similar procedure is followed to derive concentration bounds for the error between the true and estimated Cumulative Prospect Theory (CPT) value of a random variable, in cases where the random variable is bounded or sub-Gaussian. These bounds are shown to match a known bound in the bounded case, and improve upon the known bound in the sub-Gaussian case. The usefulness of the bounds is illustrated through an algorithm, and corresponding regret bound for a stochastic bandit problem, where the underlying risk measure to be optimized is CVaR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:yxmsSjX2EkcC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2019,"Conditional Value-at-Risk (CVaR) is a popular risk measure for modelling losses in the case of a rare but extreme event. We consider the problem of estimating CVaR from i.i.d. samples of an unbounded random variable, which is either sub-Gaussian or sub-exponential. We derive a novel one-sided concentration bound for a natural sample-based CVaR estimator in this setting. Our bound relies on a concentration result for a quantile-based estimator for Value-at-Risk (VaR), which may be of independent interest.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:jU7OWUQzBzMC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2018,"The classic objective in a reinforcement learning (RL) problem is to find a policy that minimizes, in expectation, a long-run objective such as the infinite-horizon cumulative discounted or long-run average cost. In many practical applications, optimizing the expected value alone is not sufficient, and it may be necessary to include a risk measure in the optimization process, either in the objective or as a constraint. Various risk measures have been proposed in the literature, eg, variance, exponential utility, percentile performance, chance constraints, value at risk (quantile), conditional value-at-risk, coherent risk measure, prospect theory and its later enhancement, cumulative prospect theory. In this article, we focus on the combination of risk criteria and reinforcement learning in a constrained optimization framework, ie, a setting where the goal to find a policy that optimizes the usual objective of infinite-horizon discounted …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:jFemdcug13IC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2018,"Cumulative prospect theory (CPT) is a popular approach for modeling human preferences. It is based on probabilistic distortions and generalizes the expected utility theory. We bring the CPT to a stochastic optimization framework and propose algorithms for both estimation and optimization of CPT-value objectives. We propose an empirical distribution function-based scheme to estimate the CPT value, and then, use this scheme in the inner loop of a CPT-value optimization procedure. We propose both gradient based as well as gradient-free CPT-value optimization algorithms that are based on two well-known simulation optimization ideas: simultaneous perturbation stochastic approximation and model-based parameter search, respectively. We provide theoretical convergence guarantees for all the proposed algorithms and also illustrate the potential of CPT-based criteria in a traffic signal control application.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:7wO8s98CvbsC,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2018,"Let µk denote the expected value of the stochastic rewards from arm k, for k= 1,..., K. The optimal arm is one that has the highest expected value, ie, µ∗= maxk= 1,..., K µk. The goal of the bandit algorithm is to maximize Sn=∑ n t= 1 Xt. Notice that Sn is a random variable (rv) and hence, has a distribution. So, a natural objective is to design an algorithm that maximizes E (Sn).
The framework outlined above captures “exploration-exploitation dilemma”. To elaborate, in any round the bandit algorithm can choose to either explore by pulling an arm to estimate its mean reward, or exploit by pulling an arm that has the highest estimated mean reward. Notice that the rewards are stochastic, ie, each arm has a reward distribution with a mean and certain spread. Since the bandit algorithm does not know the arms’ reward distributions, it has to estimate the mean rewards though sampling and the sampling has to be adaptive, ie, in any round, based on the samples obtained so far, the bandit algorithm has to adaptively decide which arm to pull next. A bandit algorithm that explores too often would end with a lower expected value for the total reward Sn. On the other hand, an algorithm that does not sample the individual arms enough number of times to be confident about their mean rewards would end up pulling a sub-optimal excessively in the exploit stage and this would again lead to a low Sn in expectation. Thus, the",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:WC23djZS0W4C,http://cse.iitm.ac.in/~prashla/
Prashanth L.A.,"['Reinforcement learning', 'simulation optimization', 'multi-armed bandits']",17,1271,2018,"The classic objective in a reinforcement learning (RL) problem is to find a policy that minimizes, in expectation, a long-run objective such as the infinite-horizon discounted or long-run average cost. In many practical applications, optimizing the expected value alone is not sufficient, and it may be necessary to include a risk measure in the optimization process, either as the objective or as a constraint. Various risk measures have been proposed in the literature, eg, mean-variance tradeoff, exponential utility, the percentile performance, value at risk, conditional value at risk, prospect theory and its later enhancement, cumulative prospect theory. In this article, we focus on the combination of risk criteria and reinforcement learning in a constrained optimization framework, ie, a setting where the goal to find a policy that optimizes the usual objective of infinite-horizon discounted/average cost, while ensuring that an explicit risk constraint is satisfied. We introduce the risk-constrained RL framework, cover popular risk measures based on variance, conditional value-at-risk and cumulative prospect theory, and present a template for a risk-sensitive RL algorithm. We survey some of our recent work on this topic, covering problems encompassing discounted cost, average cost, and stochastic shortest path settings, together with the aforementioned risk measures in a constrained framework. This non-exhaustive survey is aimed at giving a flavor of the challenges involved in solving a risk-sensitive RL problem, and outlining some potential future research directions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q1YXWpoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q1YXWpoAAAAJ:MAUkC_7iAq8C,http://cse.iitm.ac.in/~prashla/
Shweta Agrawal,['Cryptography'],21,2131,2023,"We introduce the notion of public key encryption with secure key leasing (PKE-SKL). Our notion supports the leasing of decryption keys so that a leased key achieves the decryption functionality but comes with the guarantee that if the quantum decryption key returned by a user passes a validity test, then the user has lost the ability to decrypt. Our notion is similar in spirit to the notion of secure software leasing (SSL) introduced by Ananth and La Placa (Eurocrypt 2021) but captures significantly more general adversarial strategies. (In more detail, our adversary is not restricted to use an honest evaluation algorithm to run pirated software.) Our results can be summarized as follows:
Definitions: We introduce the definition of PKE with secure key leasing and formalize a security notion that we call indistinguishability against key leasing attacks (IND-KLA security). We also define a one-wayness notion for PKE-SKL that we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:b0M2c_1WBrUC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2023,"A broadcast, trace and revoke system generalizes broadcast encryption as well as traitor tracing. In such a scheme, an encryptor can specify a list of revoked users so that (i) users in L can no longer decrypt ciphertexts, (ii) ciphertext size is independent of L, (iii) a pirate decryption box supports tracing of compromised users. The “holy grail” of this line of work is a construction which resists unbounded collusions, achieves all parameters (including public and secret key) sizes independent of |L| and |N|, and is based on polynomial hardness assumptions. In this work we make the following contributions:
Public Trace Setting: We provide a construction which (i) achieves optimal parameters, (ii) supports embedding identities (from an exponential space) in user secret keys, (iii) relies on polynomial hardness assumptions, namely compact functional encryption () and a key-policy attribute based encryption () with special efficiency properties, and (iv …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:abG-DnoFyZgC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2023,"The four-volume proceedings LNCS 13791, 13792, 13793, and 13794 constitute the proceedings of the 28th International Conference on the Theory and Application of Cryptology and Information Security, ASIACRYPT 2022, held in Taipei, Taiwan, during December 5-9, 2022. The total of 98 full papers presented in these proceedings was carefully reviewed and selected from 364 submissions. The papers were organized in topical sections as follows: Part I: Award papers; functional and witness encryption; symmetric key cryptanalysis; multiparty computation; real world protocols; and blockchains and cryptocurrencies. Part II: Isogeny based cryptography; homomorphic encryption; NIZK and SNARKs; non interactive zero knowledge; and symmetric cryptography. Part III: Practical cryptography; advanced encryption; zero knowledge; quantum algorithms; lattice cryptoanalysis. Part IV: Signatures; commitments; theory; cryptoanalysis; and quantum cryptography.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:EUQCXRtRnyEC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2022,"Multi-input functional encryption, MIFE, is a powerful generalization of functional encryption that allows computation on encrypted data coming from multiple different data sources. In a recent work, Agrawal, Goyal, and Tomida (CRYPTO 2021) constructed MIFE for the class of quadratic functions. This was the first MIFE construction from bilinear maps that went beyond inner product computation. We advance the state-of-the-art in MIFE, and propose new constructions with stronger security and broader functionality.
Stronger Security: In the typical formulation of MIFE security, an attacker is allowed to either corrupt all or none of the users who can encrypt the data. In this work, we study MIFE security in a stronger and more natural model where we allow an attacker to corrupt any subset of the users, instead of only permitting all-or-nothing corruption. We formalize the model by providing each user a unique encryption …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:bFI3QPDXJZMC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2022,"The recent work of Agrawal et al. [Crypto ’21] and Goyal et al. [Eurocrypt ’22] concurrently introduced the notion of dynamic bounded collusion security for functional encryption (FE) and showed a construction satisfying the notion from identity based encryption (IBE). Agrawal et al. [Crypto ’21] further extended it to FE for Turing machines in non-adaptive simulation setting from the sub-exponential learining with errors assumption (). Concurrently, the work of Goyal et al. [Asiacrypt ’21] constructed attribute based encryption (ABE) for Turing machines achieving adaptive indistinguishability based security against bounded (static) collusions from IBE, in the random oracle model. In this work, we significantly improve the state of art for dynamic bounded collusion FE and ABE for Turing machines by achieving adaptive simulation style security from a broad class of assumptions, in the standard model. In more detail, we obtain the following results:
We construct an adaptively secure () FE for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:yD5IFk8b50cC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2022,"Blind signatures are a fundamental cryptographic primitive with numerous practical applications. While there exist many practical blind signatures from number-theoretic assumptions, the situation is far less satisfactory from post-quantum assumptions. In this work, we provide the first overall practical, lattice-based blind signature, supporting an unbounded number of signature queries and additionally enjoying optimal round complexity. We provide a detailed estimate of parameters achieved -- we obtain a signature of size slightly above 45KB, for a core-SVP hardness of 109 bits. The run-times of the signer, user and verifier are also very small.
Our scheme relies on the Gentry, Peikert and Vaikuntanathan signature [STOC'08] and non-interactive zero-knowledge proofs for linear relations with small unknowns, which are significantly more efficient than their general purpose counterparts. Its security stems from a new …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:ZHo1McVdvXMC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2022,"Motivated by several new and natural applications, we initiate the study of multi-input predicate encryption () and further develop multi-input attribute based encryption (). Our contributions are:
Formalizing Security: We provide definitions for and in the symmetric key setting and formalize security in the standard indistinguishability (IND) paradigm, against unbounded collusions.
Two-input  for  from  and Pairings: We provide the first constructions for two-input key-policy for from and pairings. Our construction leverages a surprising connection between techniques recently developed by Agrawal and Yamada (Eurocrypt, 2020) in the context of succinct single-input ciphertext-policy, to the seemingly unrelated problem of two-input key-policy. Similarly to Agrawal-Yamada, our construction is proven secure in the bilinear generic group model. By leveraging inner product functional encryption and using (a variant of) the KOALA knowledge assumption, we obtain a construction in the standard model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:f2IySw72cVMC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2022,"In TCC 2013, Boyen suggested the first lattice based construction of attribute based encryption () for the circuit class . Unfortunately, soon after, a flaw was found in the security proof of the scheme. However, it remained unclear whether the scheme is actually insecure, and if so, whether it can be repaired. Meanwhile, the construction has been heavily cited and continues to be extensively studied due to its technical novelty. In particular, this is the first lattice based which uses linear secret sharing schemes (LSSS) as a crucial tool to enforce access control. In this work, we show that the scheme is in fact insecure,if the scheme is instantiated by the linear secret sharing scheme specified in the paper. To do so, we provide a polynomial-time attack that completely breaks the security of the scheme. We suggest a route to fix the security of the scheme, via the notion of admissible LSSS and instantiate these for the class …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:rO6llkc54NcC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2022,"A trace and revoke () scheme is an user traitor tracing scheme which additionally enables the encryptor to specify a list of revoked users so that these users can no longer decrypt ciphertexts. The``holy grail''of this line of work is a construction which resists unbounded collusions, achieves ciphertext, public and secret key sizes independent (ignoring logarithmic dependencies) of and , and is based on polynomial hardness assumptions. In this work we make the following contributions: 1. Public Trace Setting: We provide a construction which (i) achieves optimal parameters,(ii) supports embedding identities (from an exponential space) in user secret keys,(iii) relies on polynomial hardness assumptions, namely compact functional encryption () and a key-policy attribute based encryption () with special efficiency properties constructed by Boneh et al.(Eurocrypt 2014) from Learning With Errors (), and (iv) enjoys adaptive security with respect to the revocation list. The previous best known construction by Nishimaki, Wichs and Zhandry (Eurocrypt 2016) which achieved optimal parameters and embedded identities, relied on indistinguishability obfuscation, which is considered an inherently subexponential assumption and achieved only selective security with respect to the revocation list. 2. Secret Trace Setting: We provide the first construction with optimal ciphertext, public and secret key sizes and embedded identities from any assumption outside Obfustopia. In detail, our construction relies on Lockable Obfuscation which can be constructed using (Goyal, Koppula, Waters and Wichs, Zirdelis, Focs 2017) and two schemes:(i) the key-policy scheme with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:_xSYboBqXhAC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2022,"Blind signatures are a fascinating primitive which allow a user to obtain signatures from a signer, while hiding the message. Tremendously useful, these have been studied extensively for decades. Yet, to the best of our knowledge, all concretely practical blind signatures rely on non-standard assumptions and/or achieve sub-optimal round complexity. In this work, we provide an efficient, round-optimal (two-round) blind signature scheme from the hardness of the discrete log (DL) problem {\it and} the learning with errors problem in the (non black-box) random oracle model. Our construction enjoys {\it post-quantum} blindness and does not rely on idealizations such as the algebraic group model or generic group model. We provide a concrete instantiation of our construction. Specifically, our blind signature size and verification time is the same as base Schnorr signature scheme which is used for a building block …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:pyW8ca7W8N0C,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2022,"Threshold signature schemes enable distribution of the signature issuing capability to multiple users, to mitigate the threat of signing key compromise. Though a classic primitive, these signatures have witnessed a surge of interest in recent times due to relevance to modern applications like blockchains and cryptocurrencies. In this work, we study round-optimal threshold signatures in the post-quantum regime and improve the only known lattice-based construction by Boneh et al [CRYPTO’18] as follows:• Efficiency. We reduce the amount of noise flooding used in the construction from down to , where is the bound on the number of generated signatures and is the security parameter. By using lattice hardness assumptions over polynomial rings, this allows to decrease the signature bit-lengths from to~ , bringing them significantly closer to practice. Our improvement relies on a careful analysis using Rényi divergence rather than statistical distance in the security proof.• Instantiation. The construction of Boneh et al requires a standard signature scheme to be evaluated homomorphically. To instantiate this, we provide a homomorphism-friendly variant of Lyubashevsky’s signature [EUROCRYPT’12] which achieves low circuit depth by being “rejection-free” and uses an optimal, moderate noise flooding of , matching the above.• Towards Adaptive Security. The construction of Boneh et al satisfies only selective security, where all the corrupted parties must be announced before any signing query is made. We improve this in two ways: in the Random Oracle Model, we obtain partial adaptivity where signing queries can be made …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:D03iK_w7-QYC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2021,"We initiate the study of multi-party functional encryption ( which unifies and abstracts out various notions of functional encryption which support distributed ciphertexts or secret keys, such as multi-input FE, multi-client FE, decentralized multi-client FE, multi-authority FE, dynamic decentralized FE, adhoc multi-input FE and such others. Using our framework, we identify several gaps in the literature and provide some constructions to fill these:
1. Multi-Authority with Inner Product Computation. The recent work of Abdalla et al. (ASIACRYPT’20) constructed a novel “composition” of Attribute Based Encryption () and Inner Product Functional Encryption (), namely functional encryption schemes that combine the access control functionality of attribute based encryption with the possibility of performing linear operations on the encrypted data. In this work, we extend the access control component to support the much more challenging multi-authority …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:2P1L_qKh6hAC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2021,"Laconic Function Evaluation (LFE) is a novel primitive introduced by Quach, Wee and Wichs (FOCS’18) that allows two parties to perform function evaluation laconically in the following manner: first, Alice sends a compressed “digest” of some function–say C–to Bob. Second, Bob constructs a ciphertext for his input M given the digest. Third, Alice, after receiving the ciphertext from Bob and having access to her circuit, can recover C (M) and (ideally) nothing more about Bob’s message. The protocol is said to be laconic if the sizes of the digest and ciphertext are much smaller than the circuit size| C|. Quach, Wee and Wichs provided a construction of laconic function evaluation for general circuits under the learning with errors (LWE) assumption (with subexponential approximation factors), where all parameters grow polynomially with the depth but not the size of the circuit. Under LWE, their construction achieves the restricted notion of selective security where Bob’s input M must be chosen non-adaptively before even the CRS is known.
In this work, we provide the first construction of LFE for NC1, which satisfies adaptive security from the ring learning with errors assumption (with polynomial approximation factors). The construction is based on the functional encryption scheme by Agrawal and Rosen (TCC 2017). Using the compiler from Quach, Wee and Wichs which bootstraps LFE to succinct, single key FE generically, we obtain a significant simplification of the succinct single key FE of Agrawal and Rosen.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:SeFeTyx0c_EC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2021,"Blind signatures have numerous applications in privacy-preserving technologies. While there exist many practical blind signatures from number-theoretic assumptions, the situation is far less satisfactory from post-quantum assumptions. In this work, we make advances towards making lattice-based blind signatures practical. We introduce two round-optimal constructions in the random oracle model, and provide guidance towards their concrete realization as well as efficiency estimates.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:dfsIfKJdRG4C,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2021,"We define and construct Deniable Fully Homomorphic Encryption based on the Learning With Errors (LWE) polynomial hardness assumption. Deniable FHE enables storing encrypted data in the cloud to be processed securely without decryption, maintaining deniability of the encrypted data, as well the prevention of vote-buying in electronic voting schemes where encrypted votes can be tallied without decryption.
Our constructions achieve compactness independently of the level of deniability- both the size of the public key and the size of the ciphertexts are bounded by a fixed polynomial, independent of the detection probability achieved by the scheme. This is in contrast to all previous constructions of deniable encryption schemes (even without requiring homomorphisms) which are based on polynomial hardness assumptions, originating with the seminal work of Canetti, Dwork, Naor and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:4OULZ7Gr8RgC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2021,"Can a sender encode a pair of messages jointly, and send their encoding over (say) a binary erasure channel, so that the receiver can decode exactly one of the two messages and the sender does not know which one?
Garg et al. (Crypto 2015) showed that this is information-theoretically impossible. We show how to circumvent this impossibility by assuming that the receiver is computationally bounded, settling for an inverse-polynomial security error (which is provably necessary), and relying on ideal obfuscation. Our solution creates a “computational anti-correlation” between the events of receiving and receiving by exploiting the anti-concentration of the binomial distribution.
The ideal obfuscation primitive in our construction can either be directly realized using (stateless) tamper-proof hardware, yielding an unconditional result, or heuristically instantiated in the plain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:fPk4N6BV_jEC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2021,"The classic work of Gorbunov, Vaikuntanathan and Wee (CRYPTO 2012) and follow-ups provided constructions of bounded collusion Functional Encryption (FE) for circuits from mild assumptions. In this work, we improve the state of affairs for bounded collusion FE in several ways:
1.
New Security Notion. We introduce the notion of dynamic bounded collusion FE, where the declaration of collusion bound is delayed to the time of encryption. This enables the encryptor to dynamically choose the collusion bound for different ciphertexts depending on their individual level of sensitivity. Hence, the ciphertext size grows linearly with its own collusion bound and the public key size is independent of collusion bound. In contrast, all prior constructions have public key and ciphertext size that grow at least linearly with a fixed bound Q …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:u_35RYKgDlwC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2021,"We construct the first multi-input functional encryption (MIFE) scheme for quadratic functions from pairings. Our construction supports polynomial number of users, where user i, for , encrypts input to obtain ciphertext , the key generator provides a key for vector and decryption, given and , recovers and nothing else. We achieve indistinguishability-based (selective) security against unbounded collusions under the standard bilateral matrix Diffie-Hellman assumption. All previous MIFE schemes either support only inner products (linear functions) or rely on strong cryptographic assumptions such as indistinguishability obfuscation or multi-linear maps.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:3s1wT3WcHBgC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"Candidates of Indistinguishability Obfuscation () can be categorized as “direct” or “bootstrapping based”. Direct constructions rely on high degree multilinear maps [28, 29] and provide heuristic guarantees, while bootstrapping based constructions [2, 7, 33, 36, 38, 39] rely, in the best case, on bilinear maps as well as new variants of the Learning With Errors () assumption and pseudorandom generators. Recent times have seen exciting progress in the construction of indistinguishability obfuscation () from bilinear maps (along with other assumptions) [2, 7, 33, 38].
As a notable exception, a recent work by Agrawal [2] provided a construction for without using any maps. This work identified a new primitive, called Noisy Linear Functional Encryption () that provably suffices for and gave a direct construction of from new assumptions on lattices. While a preliminary cryptanalysis for the new assumptions was …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:vV6vV6tmYwMC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"Inner product functional encryption () [1] is a popular primitive which enables inner product computations on encrypted data. In , the ciphertext is associated with a vector $$\varvec{x}$$, the secret key is associated with a vector $$\varvec{y}$$ and decryption reveals the inner product $$\langle \varvec{x},\varvec{y}\rangle $$. Previously, it was known how to achieve adaptive indistinguishability () based security for from the , and assumptions [8]. However, in the stronger simulation () based security game, it was only known how to support a restricted adversary that makes all its key requests either before or after seeing the challenge ciphertext, but not both. In more detail, Wee [46] showed that the -based scheme of Agrawal et al. (Crypto 2016) achieves semi-adaptive simulation-based security, where the adversary must make all its key requests after seeing the challenge ciphertext. On the other hand, O’Neill showed that all -secure  …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:RYcK_YlVTxYC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"Text and image analysis are playing very important role in healthcare and medical domain. The whole clinical process is getting affected positively by text and image processing. Many datasets, algorithms, models and tools are available for extracting useful information and for applying natural language processing, machine learning and deep learning algorithms. But there exist many challenges in healthcare data for successful implementation of text and image based machine learning models, which include: (i) storage and retrieval of high resolution images, (ii) scarcity of data (iii) dataset generation and validation, (iv) appropriate algorithms and models for extracting hidden information from images and texts, (v) use of modern concepts like deep neural networks, recurrent neural network, (vi) data wrangling and (vii) processing capacity of processors. This chapter will: (i) establish a background for the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:pqnbT2bcN3wC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"We define and construct Deniable Fully Homomorphic Encryption based on the Learning With Errors (LWE) polynomial hardness assumption. Deniable FHE enables storing encrypted data in the cloud to be processed securely without decryption, maintaining deniability of the encrypted data, as well the prevention of vote-buying in electronic voting schemes where encrypted votes can be tallied without decryption. Our constructions achieve compactness independently of the level of deniability-both the size of the public key and the size of the ciphertexts are bounded by a fixed polynomial, independent of the detection probability achieved by the scheme. This is in contrast to all previous constructions of deniable encryption schemes (even without requiring homomorphisms) which are based on polynomial hardness assumptions, originating with the seminal work of Canetti, Dwork, Naor and Ostrovsky (CRYPTO 1997) in which the ciphertext size grows with the inverse of the detection probability. Canetti et al. argued that this dependence``seems inherent'', but our constructions illustrate this is not the case. We note that the Sahai-Waters (STOC 2014) construction of deniable encryption from indistinguishability-obfuscation achieves compactness and can be easily modified to achieve deniable FHE as well, but it requires multiple, stronger sub-exponential hardness assumptions, which are furthermore not post-quantum secure. In contrast, our constructions rely only on the LWE polynomial hardness assumption, as currently required for FHE even without deniability. The running time of our encryption algorithm depends on the inverse of the detection …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:g5m5HwL7SMYC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"Garg et al. (Crypto 2015) initiated the study of cryptographic protocols over noisy channels in the non-interactive setting, namely when only one party speaks. A major question left open by this work is the completeness of finite channels, whose input and output alphabets do not grow with the desired level of security. In this work, we address this question by obtaining the following results:
1.
Completeness of Bit-ROT with Inverse Polynomial Error. We show that bit-ROT (i.e., Randomized Oblivious Transfer channel, where each of the two messages is a single bit) can be used to realize general randomized functionalities with inverse polynomial error. Towards this, we provide a construction of string-ROT from bit-ROT with inverse polynomial error.
2.
No Finite Channel is Complete with Negligible …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:M05iB0D1s5AC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"The celebrated work of Gorbunov, Vaikuntanathan and Wee [GVW13] provided the first key policy attribute based encryption scheme (ABE) for circuits from the Learning With Errors (LWE) assumption. However, the arguably more natural ciphertext policy variant has remained elusive, and is a central primitive not yet known from LWE.
In this work, we construct the first symmetric key ciphertext policy attribute based encryption scheme (CP-ABE) for all polynomial sized circuits from the learning with errors (LWE) assumption. In more detail, the ciphertext for a message m is labelled with an access control policy f, secret keys are labelled with public attributes from the domain of f and decryption succeeds to yield the hidden message m if and only if . The size of our public and secret key do not depend on the size of the circuits supported by the scheme – this enables our construction to support circuits …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:ldfaerwXgEUC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"Broadcast Encryption with optimal parameters was a long-standing problem, whose first solution was provided in an elegant work by Boneh, Waters and Zhandry [BWZ14]. However, this work relied on multilinear maps of logarithmic degree, which is not considered a standard assumption. Recently, Agrawal and Yamada [AY20] improved this state of affairs by providing the first construction of optimal broadcast encryption from Bilinear Maps and Learning With Errors (LWE). However, their proof of security was in the generic bilinear group model. In this work, we improve upon their result by providing a new construction and proof in the standard model. In more detail, we rely on the Learning With Errors (LWE) assumption and the Knowledge of OrthogonALity Assumption (KOALA) [BW19] on bilinear groups.
Our construction combines three building blocks: a (computational) nearly linear secret sharing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:70eg2SAEIzsC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"Boneh, Waters and Zhandry (CRYPTO 2014) used multilinear maps to provide a solution to the long-standing problem of public-key broadcast encryption (BE) where all parameters in the system are small. In this work, we improve their result by providing a solution that uses only bilinear maps and Learning With Errors (LWE). Our scheme is fully collusion-resistant against any number of colluders, and can be generalized to an identity-based broadcast system with short parameters. Thus, we reclaim the problem of optimal broadcast encryption from the land of “Obfustopia”.
Our main technical contribution is a ciphertext policy attribute based encryption (CP-ABE) scheme which achieves special efficiency properties – its ciphertext size, secret key size, and public key size are all independent of the size of the circuits supported by the scheme. We show that this special CP-ABE scheme implies BE with optimal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:lSLTfruPkqcC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"We introduce the notion of a Functionally Encrypted Datastore which collects data anonymously from multiple data-owners, stores it encrypted on an untrusted server, and allows untrusted clients to make select-and-compute queries on the collected data. Little coordination and no communication is required among the data-owners or the clients. Our notion is general enough to capture many real world scenarios that require controlled computation on encrypted data, such as is required for contact tracing in the wake of a pandemic. Our leakage and performance profile is similar to that of conventional searchable encryption systems, while the functionality we offer is significantly richer.
In more detail, the client specifies a query as a pair (Q, f) where Q is a filtering predicate which selects some subset of the dataset and f is a function on some computable values associated with the selected data. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:NaGl4SEjCO4C,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"We present a brief introduction to post-quantum cryptography. This note introduces the concept of post-quantum cryptography, discusses its importance and provides a short overview of the mathematical techniques that are currently used to develop this field.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:YFjsv_pBGBYC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2020,"Consider sources that supply sensitive data to an aggregator. Standard encryption only hides the data from eavesdroppers, but using specialized encryption one can hope to hide the data (to the extent possible) from the aggregator itself. For flexibility and security, we envision schemes that allow sources to supply encrypted data, such that at any point a dynamically-chosen subset of sources can allow an agreed-upon joint function of their data to be computed by the aggregator. A primitive called multi-input functional encryption (MIFE), due to Goldwasser et al.(EUROCRYPT 2014), comes close, but has two main limitations:",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:maZDTaKrznsC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2019,"Waters [Crypto, 2012] provided the first attribute based encryption scheme ABE for Deterministic Finite Automata (DFA) from a parametrized or “q-type” assumption over bilinear maps. Obtaining a construction from static assumptions has been elusive, despite much progress in the area of ABE.
In this work, we construct the first attribute based encryption scheme for DFA from static assumptions on pairings, namely, the assumption. Our scheme supports unbounded length inputs, unbounded length machines and unbounded key requests. In more detail, secret keys in our construction are associated with a DFA M of unbounded length, ciphertexts are associated with a tuple where is a public attribute of unbounded length and is a secret message bit, and decryption recovers if and only if .
Our techniques are at least as interesting as our final result. We present a simple compiler that combines constructions of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:GnPB-g6toBAC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2019,"Constructing Attribute Based Encryption (ABE) [56] for uniform models of computation from standard assumptions, is an important problem, about which very little is known. The only known ABE schemes in this setting that (i) avoid reliance on multilinear maps or indistinguishability obfuscation, (ii) support unbounded length inputs and (iii) permit unbounded key requests to the adversary in the security game, are by Waters from Crypto, 2012 [57] and its variants. Waters provided the first ABE for Deterministic Finite Automata (DFA) satisfying the above properties, from a parametrized or “q-type” assumption over bilinear maps. Generalizing this construction to Nondeterministic Finite Automata (NFA) was left as an explicit open problem in the same work, and has seen no progress to date. Constructions from other assumptions such as more standard pairing based assumptions, or lattice based assumptions has also proved …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:ns9cj8rnVeAC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2019,"We introduce the notion of a Functionally Encrypted Datastore which collects data from multiple data-owners, stores them encrypted on an untrusted server, and allows untrusted clients to make selectand-compute queries on the collected data. Little coordination and no communication is required among the data-owners or the clients. Our security and performance profile is similar to that of conventional searchable encryption systems, while the functionality we offer is significantly richer. The client specifies a query as a pair (Q, f) where Q is a filtering predicate which selects some subset of the dataset and f is a function on some computable values associated with the selected data. We provide efficient protocols for various functionalities of practical relevance. We demonstrate the utility, efficiency and scalability of our protocols via extensive experimentation. In particular, we use our protocols to model computations relevant to the Genome Wide Association Studies such as Minor Allele Frequency (MAF), Chi-square analysis and Hamming Distance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:BqipwSGYUEgC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2019,"Constructing indistinguishability obfuscation (iO iO) 17 is a central open question in cryptography. We provide new methods to make progress towards this goal. Our contributions may be summarized as follows: 1. Bootstrapping. In a recent work, Lin and Tessaro 71 (LT) show that iO iO may be constructed using (i) Functional Encryption (FE FE) for polynomials of degree L,(ii) Pseudorandom Generators (PRG PRG) with blockwise locality L and polynomial expansion, and (iii) Learning With Errors (LWE LWE). Since there exist constructions of FE FE for quadratic polynomials from standard assumptions on bilinear maps 16, 68, the ideal scenario would be to set L= 2 L= 2, yielding iO iO from widely believed assumptions Unfortunately, it was shown soon after 18, 73 that PRG PRG with block locality 2 and the expansion factor required by the LT construction, concretely\varOmega (n ⋅ 2^ b (3+ ϵ)) Ω (n· 2 b (3+ ϵ …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:k_IJM867U9cC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2018,"We construct Indistinguishability Obfuscation () and Functional Encryption () schemes in the Turing machine model from the minimal assumption of compact for circuits (). Our constructions overcome the barrier of sub-exponential loss incurred by all prior work. Our contributions are:
1.
We construct in the Turing machine model from the same assumptions as required in the circuit model, namely, sub-exponentially secure for circuits. The previous best constructions [6, 41] require sub-exponentially secure for circuits, which in turn requires sub-exponentially secure for circuits [5, 15].
2.
We provide a new construction of single input for Turing machines with unbounded length inputs and optimal parameters from polynomially secure, compact for circuits. The previously best known …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:mB3voiENLucC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2018,"The Learning with Errors (LWE) problem has been extensively studied in cryptography due to its strong hardness guarantees, efficiency and expressiveness in constructing advanced cryptographic primitives. In this work, we show that using polar codes in conjunction with LWE-based encryption yields several advantages. To begin, we demonstrate the obvious improvements in the efficiency or rate of information transmission in the LWE-based scheme by leveraging polar coding (with no change in the cryptographic security guarantee). Next, we integrate wiretap polar coding with LWE-based encryption to ensure provable semantic security over a wiretap channel in addition to cryptographic security based on the hardness of LWE. To the best of our knowledge this is the first wiretap code to have cryptographic security guarantees as well. Finally, we study the security of the private key used in LWE-based encryption …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:hFOr9nPyWt4C,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2018,"Constructing indistinguishability obfuscation (iO)[BGI+ 01] is a central open question in cryptography. We provide new methods to make progress towards this goal. Our contributions may be summarized as follows: 1.{\textbf Bootstrapping}. In a recent work, Lin and Tessaro [LT17](LT) show that iO may be constructed using i) Functional Encryption (FE) for polynomials of degree , ii) Pseudorandom Generators (PRG) with blockwise locality and polynomial expansion, and iii) Learning With Errors (LWE). Since there exist constructions of FE for quadratic polynomials from standard assumptions on bilinear maps [Lin17, BCFG17], the ideal scenario would be to set , yielding iO from widely believed assumptions. Unfortunately, it was shown soon after [LV17, BBKK17] that PRG with block locality and the expansion factor required by the LT construction, concretely , where is the input length and is the block length, do not exist. In the worst case, these lower bounds rule out 2-block local PRG with stretch . While [LV17, BBKK17] provided strong negative evidence for constructing iO based on bilinear maps, they could not rule out the possibility completely; a tantalizing gap has remained. Given the current state of lower bounds, the existence of 2 block local PRG with expansion factor remains open, although this stretch does not suffice for the LT bootstrapping, and is hence unclear to be relevant for iO. In this work, we improve the state of affairs as follows.(a) Weakening requirements on PRGs: In this work, we show that the narrow window of expansion factors left open by lower bounds do suffice for iO. We show a new method to construct FE for from i) FE for degree L polynomials, ii) PRGs of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:-f6ydRqryjwC,http://www.cse.iitm.ac.in/~shwetaag/
Shweta Agrawal,['Cryptography'],21,2131,2018,"In Public-Key Encryption, traditionally no security is expected if honest parties use keys provided by an adversary. In this work, we re-examine this premise. While using untrusted keys may seem nonsensical at first glance, we argue the use of providing certain security guarantees even in such situations. We propose Chosen Object Attack (COA) security as a broad generalization of various notions of security that have been considered in the literature, including CCA security, key anonymity and robustness, along with concerns arising from untrusted keys. The main premise of this definition is that any of the objects in a cryptographic scheme could be adversarialy generated, and that should not compromise the security of honest parties in a way an idealized scheme would not have. Our contributions are threefold.• Firstly, we develop a comprehensive security definition for PKE in the real/ideal paradigm. Our definition subsumes CCA2 security, Anonymity and Robustness as special cases, and also addresses security concerns in complex application scenarios where the keys may be malicious (without having to explicitly model the underlying attack scenarios). To avoid impossibility results associated with simulation-based security, we use the notion of indistinguishability-preserving security (IND-PRE) from the “Cryptographic Agents” framework (Agrawal et al., EUROCRYPT 2015). Towards this, we extend this framework to accommodate adversarially created objects. Our definition can alternately be interpreted as the union of all possible game-based security definitions. We remark that the agents framework as extended in this work is applicable to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=uLkJ5_4AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=uLkJ5_4AAAAJ:IWHjjKOFINEC,http://www.cse.iitm.ac.in/~shwetaag/
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2023,"With the evolution of multicellularity, communication among cells in different tissues and organs became pivotal to life. Molecular basis of such communication has long been studied, but genome-wide screens for genes and other biomolecules mediating tissue-tissue signaling are lacking. To systematically identify inter-tissue mediators, we present a novel computational approach MultiCens (Multilayer/Multi-tissue network Centrality measures). Unlike single-layer network methods, MultiCens can distinguish within- vs. across-layer connectivity to quantify the “influence” of any gene in a tissue on a query set of genes of interest in another tissue. MultiCens enjoys theoretical guarantees on convergence and decomposability, and performs well on synthetic benchmarks. On human multi-tissue datasets, MultiCens predicts known and novel genes linked to hormones. MultiCens further reveals shifts in gene network architecture among four brain regions in Alzheimer’s disease. MultiCens-prioritized hypotheses from these two diverse applications, and potential future ones like “Multi-tissue-expanded Gene Ontology” analysis, can enable whole-body yet molecular-level systems investigations in humans.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:AXkvAH5U_nMC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2023,"Despite their potential in real-world applications, multi-agent reinforcement learning (MARL) algorithms often suffer from high sample complexity. To address this issue, we present a novel model-based MARL algorithm, BiLL (Bi-Level Latent Variable Model-based Learning), that learns a bi-level latent variable model from high-dimensional inputs. At the top level, the model learns latent representations of the global state, which encode global information relevant to behavior learning. At the bottom level, it learns latent representations for each agent, given the global latent representations from the top level. The model generates latent trajectories to use for policy learning. We evaluate our algorithm on complex multi-agent tasks in the challenging SMAC and Flatland environments. Our algorithm outperforms state-of-the-art model-free and model-based baselines in sample efficiency, including on two extremely challenging Super Hard SMAC maps.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:w0F2JDEymm0C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"We propose a hybrid planner-(deep) reinforcement learning (RL) architecture, RePReL, that leverages a relational planner to efficiently provide useful state abstractions. State abstractions have a tremendous advantage for better generalization and transfer in RL. Our framework takes an important step toward constructing these abstractions. Specifically, the framework enables multi-level abstractions by leveraging a high-level planner to communicate with a low-level (deep) reinforcement learner. Our empirical results demonstrate the generalization and transfer capabilities of the framework in both discrete and continuous domains with rich structures (objects and relations between these objects). A key aspect of RePReL is that it can be seen as a plug-and-play framework where different planners can be used in combination with different (deep) RL agents.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:1DsIQWDZLl8C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"We apply reinforcement learning (RL) to robotics. One of the drawbacks of traditional RL algorithms has been their poor sample efficiency. One approach to improve it is model-based RL. We learn a model of the environment, essentially its dynamics and reward function, use it to generate imaginary trajectories and backpropagate through them to update the policy, exploiting the differentiability of the model. Intuitively, learning more accurate models should lead to better performance. Recently, there has been growing interest in developing better deep neural network based dynamics models for physical systems, through better inductive biases. We focus on robotic systems undergoing rigid body motion. We compare two versions of our model-based RL algorithm, one which uses a standard deep neural network based dynamics model and the other which uses a much more accurate, physics-informed neural network based dynamics model. We show that, in environments that are not sensitive to initial conditions, model accuracy matters only to some extent, as numerical errors accumulate slowly. In these environments, both versions achieve similar average-return, while the physics-informed version achieves better sample efficiency. We show that, in environments that are sensitive to initial conditions, model accuracy matters a lot, as numerical errors accumulate fast. In these environments, the physics-informed version achieves significantly better average-return and sample efficiency. We show that, in challenging environments, where we need a lot of samples to learn, physics-informed model-based RL can achieve better asymptotic performance …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:kWvqk_afx_IC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"In this work, we present a novel approach for link prediction on heterogeneous networks – networks that accommodate multiple types of nodes as well as multiple types of relations among them. Specifically, we propose a multi-view network representation learning framework to incorporate structural intuitions from the underlying graph and enrich the relational representations for link prediction. The method relies on the metapath view, the community view, and the subgraph view between a source and target node pair whose linkage is to be predicted. Furthermore, our proposed model leverages a relation-aware attention mechanism to aggregate the candidate contexts in a principled way. Empirically, we demonstrate that the proposed architecture outperforms state-of-the-art transductive and inductive methods in link prediction by a significant margin. A detailed ablation study and attention weight visualizations …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:FiDNX6EVdGUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"When an agent encounters a continual stream of new tasks in the lifelong learning setting, it leverages the knowledge it gained from the earlier tasks to help learn the new tasks better. In such a scenario, identifying an efficient knowledge representation becomes a challenging problem. Most research works propose to either store a subset of examples from the past tasks in a replay buffer, dedicate a separate set of parameters to each task or penalize excessive updates over parameters by introducing a regularization term. While existing methods employ the general task-agnostic stochastic gradient descent update rule, we propose a task-aware optimizer that adapts the learning rate based on the relatedness among tasks. We utilize the directions taken by the parameters during the updates by additively accumulating the gradients specific to each task. These task-based accumulated gradients act as a knowledge base that is maintained and updated throughout the stream. We empirically show that our proposed adaptive learning rate not only accounts for catastrophic forgetting but also exhibits knowledge transfer. We also show that our method performs better than several state-of-the-art methods in lifelong learning on complex datasets. Moreover, our method can also be combined with the existing methods and achieve substantial improvement in performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:ubry08Y2EpUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Node classification is an important task to solve in graph-based learning. Even though a lot of work has been done in this field, imbalance is neglected. Real-world data is not perfect, and is imbalanced in representations most of the times. Apart from text and images, data can be represented using graphs, and thus addressing the imbalance in graphs has become of paramount importance. In the context of node classification, one class has less examples than others. Changing data composition is a popular way to address the imbalance in node classification. This is done by resampling the data to balance the dataset. However, that can sometimes lead to loss of information or add noise to the dataset. Therefore, in this work, we implicitly solve the problem by changing the model loss. Specifically, we study how attention networks can help tackle imbalance. Moreover, we observe that using a regularizer to assign larger weights to minority nodes helps to mitigate this imbalance. We achieve State of the Art results than the existing methods on several standard citation benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:ce2CqMG-AY4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"ARTIFICIAL INTELLIGENCE (AI) and data science (DS) centers are becoming ubiquitous in academic institutions around the globe. These centers serve to focus research efforts and bring together large teams to address important problems. AI centers in more mature research ecosystems tend to be multi-institutional, such as the Alan Turing Institute in the UK with 13 academic partners12 and Mila in Montreal with four academic partners and numerous industry partners. 8 Often such centers are also focused on a specific theme, such as the 18 AI institutes funded by NSF. 10 In contrast, the centers in India tend to be contained in only one institute—this facilitates the institute to identify AI/DS as a growth area and an area of interest to the Institute. The centers tend to be active in content creation, teaching, and consulting apart from their research activities. In this article, we look at the activities of centers located at seven …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:uVUOdF_882EC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"We study the weak supervision learning problem of Learning from Label Proportions (LLP) where the goal is to learn an instance-level classifier using proportions of various class labels in a bag -- a collection of input instances that often can be highly correlated. While representation learning for weakly-supervised tasks is found to be effective, they often require domain knowledge. To the best of our knowledge, representation learning for tabular data (unstructured data containing both continuous and categorical features) are not studied. In this paper, we propose to learn diverse representations of instances within the same bags to effectively utilize the weak bag-level supervision. We propose a domain agnostic LLP method, called ""Self Contrastive Representation Learning for LLP"" (SelfCLR-LLP) that incorporates a novel self--contrastive function as an auxiliary loss to learn representations on tabular data for LLP …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:mKu_rENv82IC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Classification of data with imbalanced characteristics is an essential research problem as the data from most real-world applications follow non-uniform class proportions. Solutions to handle class imbalance depend on how important one data point is versus the other. Directed data sampling and data-level cost-sensitive methods use the data point importance information to sample from the dataset such that the essential data points are retained and possibly oversampled. In this paper, we propose a novel topic modeling-based weighting framework to assign importance to the data points in an imbalanced dataset based on the topic posterior probabilities estimated using the latent Dirichlet allocation and probabilistic latent semantic analysis models. We also propose TOMBoost, a topic modeled boosting scheme based on the weighting framework, particularly tuned for learning with class imbalance. In an empirical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:RoXSNcbkSzsC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"We formulate a new inference task in the domain of multivariate time series forecasting (MTSF), called Variable Subset Forecast (VSF), where only a small subset of the variables is available during inference. Variables are absent during inference because of long-term data loss (eg. sensor failures) or high -> low-resource domain shift between train / test. To the best of our knowledge, robustness of MTSF models in presence of such failures, has not been studied in the literature. Through extensive evaluation, we first show that the performance of state of the art methods degrade significantly in the VSF setting. We propose a non-parametric, wrapper technique that can be applied on top any existing forecast models. Through systematic experiments across 4 datasets and 5 forecast models, we show that our technique is able to recover close to 95% performance of the models even when only 15% of the original …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:6_hjMsCP8ZoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Fusion of high-level symbolic reasoning with lower level signal-based reasoning has attracted significant attention. We propose an architecture that integrates the high-level symbolic domain knowledge using a hierarchical planner with a lower level reinforcement learner that uses hybrid data (structured and unstructured). We introduce a novel neuro-symbolic system, Hybrid Deep RePReL that achieves the best of both worlds-the generalization ability of the planner with the effective learning ability of deep RL. Our results in two domains demonstrate the superiority of our approach in terms of sample efficiency as well as generalization to increased set of objects.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:sszUF3NjhM4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"The options framework in Hierarchical Reinforcement Learning breaks down overall goals into a combination of options or simpler tasks and associated policies, allowing for abstraction in the action space. Ideally, these options can be reused across different higher-level goals; indeed, such reuse is necessary to realize the vision of a continual learning agent that can effectively leverage its prior experience. Previous approaches have only proposed limited forms of transfer of prelearned options to new task settings. We propose a novel option indexing approach to hierarchical learning (OI-HRL), where we learn an affinity function between options and the items present in the environment. This allows us to effectively reuse a large library of pretrained options, in zero-shot generalization at test time, by restricting goal-directed learning to only those options relevant to the task at hand. We develop a meta-training loop that learns the representations of options and environments over a series of HRL problems, by incorporating feedback about the relevance of retrieved options to the higher-level goal. We evaluate OI-HRL in two simulated settings - the CraftWorld and AI2THOR environments - and show that we achieve performance competitive with oracular baselines, and substantial gains over a baseline that has the entire option pool available for learning the hierarchical policy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:jE2MZjpN3IcC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"In the framework of learning from label proportions (LLP) the goal is to learn a good instance-level label predictor from the observed label proportions of bags of instances. Most of the LLP algorithms either explicitly or implicitly assume the nature of bag distributions with respect to the actual labels and instances, or cleverly adapt supervised learning techniques to suit LLP. In practical applications however, the scale and nature of data could render such assumptions invalid and the many of the algorithms impractical. In this paper we address the hard problem of solving LLP with provable error bounds while being bag distribution agnostic and model agnostic. We first propose the concept of generalized bags, an extension of bags and then devise an algorithm to combine bag distributions, if possible, into good generalized bag distributions. We show that (whp) any classifier optimizing the squared Euclidean label-proportion loss on such a generalized bag distribution is guaranteed to minimize the instance-level loss as well. The predictive quality of our method is experimentally evaluated and it equals or betters the previous methods on pseudo-synthetic and real-world datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:q-HalDI95KYC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Green Security Games have become a popular way to model scenarios involving the protection of natural resources, such as wildlife. Sensors (e.g. drones equipped with cameras) have also begun to play a role in these scenarios by providing real-time information. Incorporating both human and sensor defender resources strategically is the subject of recent work on Security Games with Signaling (SGS). However, current methods to solve SGS do not scale well in terms of time or memory. We therefore propose a novel approach to SGS, which, for the first time in this domain, employs an Evolutionary Computation paradigm: EASGS. EASGS effectively searches the huge SGS solution space via suitable solution encoding in a chromosome and a specially-designed set of operators. The operators include three types of mutations, each focusing on a particular aspect of the SGS solution, optimized crossover and a local coverage improvement scheme (a memetic aspect of EASGS). We also introduce a new set of benchmark games, based on dense or locally-dense graphs that reflect real-world SGS settings. In the majority of 342 test game instances, EASGS outperforms state-of-the-art methods, including a reinforcement learning method, in terms of time scalability, nearly constant memory utilization, and quality of the returned defender's strategies (expected payoffs).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:DBa1UEJaJKAC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"In recent years, it has been seen that deep neural networks are lacking robustness and are likely to break in case of adversarial perturbations in input data. Strong adversarial attacks are proposed by various authors for computer vision and Natural Language Processing (NLP). As a counter-effort, several defense mechanisms are also proposed to save these networks from failing. In contrast with image data, generating adversarial attacks and defending these models is not easy in NLP because of the discrete nature of the text data. However, numerous methods for adversarial defense are proposed of late, for different NLP tasks such as text classification, named entity recognition, natural language inferencing, etc. These methods are not just used for defending neural networks from adversarial attacks, but also used as a regularization mechanism during training, saving the model from overfitting. The proposed survey is an attempt to review different methods proposed for adversarial defenses in NLP in the recent past by proposing a novel taxonomy. This survey also highlights the fragility of the advanced deep neural networks in NLP and the challenges in defending them.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:SjuI4pbJlxcC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"In the past few years, it has become increasingly evident that deep neural networks are not resilient enough to withstand adversarial perturbations in input data, leaving them vulnerable to attack. Various authors have proposed strong adversarial attacks for computer vision and Natural Language Processing (NLP) tasks. As a response, many defense mechanisms have also been proposed to prevent these networks from failing. The significance of defending neural networks against adversarial attacks lies in ensuring that the model’s predictions remain unchanged even if the input data is perturbed. Several methods for adversarial defense in NLP have been proposed, catering to different NLP tasks such as text classification, named entity recognition, and natural language inference. Some of these methods not only defend neural networks against adversarial attacks but also act as a regularization mechanism during …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:F2UWTTQJPOcC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"The memory consolidation process enables the accumulation of recent and remote memories in the long-term memory store. In general, the deep network models of memory suffer from forgetting old information while learning new information, called catastrophic forgetting/interference. The human brain overcomes this problem quite effectively, a problem that continues to challenge current deep neural network models.
We propose a regularization-based model to solve the problem of catastrophic forgetting. According to the proposed training mechanism, the network parameters are constrained to vary in a direction orthogonal to the average of the error gradients corresponding to the previous tasks. We also ensure that the constraint used in parameter updating satisfies the locality principle.
The proposed model’s performance is compared with Elastic Weight Consolidation on standard datasets such as permuted MNIST and split MNIST on classification tasks using fully connected networks, and Convolution-based networks. The model performance is also compared to an autoencoder on split MNIST dataset, and to complex core50 dataset on two types of classification tasks with EWC.
The proposed model gives a new view on plasticity at the neuronal level. In the proposed model, the parameter updating is controlled by the neuronal level plasticity rather than synapse level plasticity as in other standard models. The biological plausibility of the proposed model is discussed by linking the extra parameters to synaptic tagging, which represents the state of the synapse involved in Long Term Potentiation (LTP).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:Ade32sEp0pkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Hand pose estimation in 3D from depth images is a highly complex task. Current state-of-the-art 3D hand pose estimators focus only on the accuracy of the model as measured by how closely it matches the ground truth hand pose but overlook the resulting hand pose's anatomical correctness. In this paper, we present the Single Shot Corrective CNN (SSC-CNN) to tackle the problem of enforcing anatomical correctness at the architecture level. In contrast to previous works which use post-facto pose filters, SSC-CNN predicts the hand pose that conforms to the human hand's biomechanical bounds and rules in a single forward pass. The model was trained and tested on the HANDS2017 and MSRA datasets. Experiments show that our proposed model shows comparable accuracy to the state-of-the-art models as measured by the ground truth pose. However, the previous methods have high anatomical errors, whereas our model is free from such errors. Experiments show that our proposed model shows zero anatomical errors along with comparable accuracy to the state-of-the-art models as measured by the ground truth pose. The previous methods have high anatomical errors, whereas our model is free from such errors. Surprisingly even the ground truth provided in the existing datasets suffers from anatomical errors, and therefore Anatomical Error Free (AEF) versions of the datasets, namely AEF-HANDS2017 and AEF-MSRA, were created.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:1yWc8FF-_SYC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Determining optimum inventory replenishment decisions are critical for retail businesses with uncertain demand. The problem becomes particularly challenging when multiple products with different lead times and cross-product constraints are considered. This paper addresses the aforementioned challenges in multi-product, multi-period inventory management using deep reinforcement learning (deep RL). The proposed approach improves upon existing methods for inventory control on three fronts: (1) concurrent inventory management of a large number (hundreds) of products under realistic constraints, (2) minimal retraining requirements on the RL agent under system changes through the definition of an individual product meta-model, (3) efficient handling of multi-period constraints that stem from different lead times of different products. We approach the inventory problem as a special class of dynamical system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:jgBuDB5drN8C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Emergency Medical Services (EMS) are a crucial part of the healthcare system. For evaluating the quality of EMS and better planning of EMS allocation to emergency requests, it is important to know the incident location for each emergency request. Currently in India, the callers requesting EMS verbally describe the incident location to which ambulances are dispatched. Therefore, incident locations are stored as descriptions and not as geo-coordinates. However, most EMS vehicles are equipped with GPS. There is a need for automated approaches to identify the incident locations from geospatial data of ambulances. This paper presents a system that uses a clustering approach followed by a distance heuristic implementation for effective identification of the incident locations from ambulance trajectories. Overall, for various levels of precision set for manual validation, the approach proves to be effective with an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:Br1UauaknNIC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Imitation learning (IL) is a popular approach in the continuous control setting as among other reasons it circumvents the problems of reward mis-specification and exploration in reinforcement learning (RL). In IL from demonstrations, an important challenge is to obtain agent policies that are smooth with respect to the inputs. Learning through imitation a policy that is smooth as a function of a large state-action (s-a) space (typical of high dimensional continuous control environments) can be challenging. We take a first step towards tackling this issue by using smoothness inducing regularizers on both the policy and the cost models of adversarial imitation learning. Our regularizers work by ensuring that the cost function changes in a controlled manner as a function of s-a space; and the agent policy is well behaved with respect to the state space. We call our new smooth IL algorithm Smooth Policy and Cost Imitation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:XUvXOeBm_78C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Robust Policy Search is the problem of learning policies that do not degrade in performance when subject to unseen environment model parameters. It is particularly relevant for transferring policies learned in a simulation environment to the real world. Several existing approaches involve sampling large batches of trajectories which reflect the differences in various possible environments, and then selecting some subset of these to learn robust policies, such as the ones that result in the worst performance. We propose an active learning based framework, EffAcTS, to selectively choose model parameters for this purpose so as to collect only as much data as necessary to select such a subset. We apply this framework using Linear Bandits, and experimentally validate the gains in sample efficiency and the performance of our approach on standard continuous control tasks. We also present a Multi-Task Learning …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:bz8QjSJIRt4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"The drastic growth in the number of vehicles in the last few decades has necessitated significantly better traffic management and planning. To manage the traffic efficiently, traffic volume is an essential parameter. Most methods solve the vehicle counting problem under the assumption of state-of-the-art computation power. With the recent growth in cost-effective Internet of Things (IoT) devices and edge computing, several machine learning models are being tailored for such devices. Solving the traffic count problem on these devices will enable us to create a real-time dashboard of network-wide live traffic analytics. This paper proposes a Detect-Track-Count (DTC) framework to count vehicles efficiently on edge devices. The proposed solution aims at improving the performance of tiny vehicle detection models using an ensemble knowledge distillation technique. Experimental results on multiple datasets show that the custom knowledge distillation setup helps generalize a tiny object detector better.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:jFemdcug13IC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2022,"Many real-world applications deal with data that have an underlying graph structure associated with it. To perform downstream analysis on such data, it is crucial to capture relational information of nodes over their expanded neighborhood efficiently. Herein, we focus on the problem of Collective Classification (CC) for assigning labels to unlabeled nodes. Most deep learning models for CC heavily rely on differentiable variants of Weisfeiler-Lehman (WL) kernels. However, due to current computing architectures' limitations, WL kernels and their differentiable variants are limited in their ability to capture useful relational information only over a small expanded neighborhood of a node. To address this concern, we propose the framework, I-HOP, that couples differentiable kernels with an iterative inference mechanism to scale to larger neighborhoods. I-HOP scales differentiable graph kernels to capture and summarize …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:LPtt_HFRSbwC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Hidden Markov models (HMMs) belong to the class of double embedded stochastic models which were originally leveraged for speech recognition and synthesis. HMMs subsequently became a generic sequence model across multiple domains like NLP, bio-informatics and thermodynamics to name a few. Literature has several heuristic metrics to compare two HMMs by factoring in their structure and emission probability distributions in HMM nodes. However, typical structure-based metrics overlook the similarity between HMMs having different structures yet similar behavior and typical behavior-based metrics rely on the representativeness of the reference sequence used for assessing the similarity in behavior. Further, little exploration has taken place in leveraging the recent advancements in deep graph neural networks for learning effective representations for HMMs. In this paper, we propose two novel deep neural network based approaches to learn embeddings for HMMs and evaluate the validity of the embeddings based on subsequent clustering and classification tasks. Our proposed approaches use a Graph variational Autoencoder and diffpooling based Graph neural network (GNN) to learn embeddings for HMMs. The graph autoencoder infers latent low-dimensional flat embeddings for HMMs in a task-agnostic manner; whereas the diffpooling based graph neural network learns class-label aware embeddings by inferring and aggregating a hierarchical set of clusters and sub-clusters of graph nodes. Empirical results reveal that the HMM embeddings learnt through the Graph variational autoencoders and diffpooling based GNN …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:yxmsSjX2EkcC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"In budget-constrained settings aimed at mitigating unfairness, like law enforcement, it is essential to prioritize the sources of unfairness before taking measures to mitigate them in the real world. Unlike previous works, which only serve as a caution against possible discrimination and de-bias data after data generation, this work provides a toolkit to mitigate unfairness during data generation, given by the Unfair Edge Prioritization algorithm, in addition to de-biasing data after generation, given by the Discrimination Removal algorithm. We assume that a non-parametric Markovian causal model representative of the data generation procedure is given. The edges emanating from the sensitive nodes in the causal graph, such as race, are assumed to be the sources of unfairness. We first quantify Edge Flow in any edge X–> Y, which is the belief of observing a specific value of Y due to the influence of a specific value of X along X–> Y. We then quantify Edge Unfairness by formulating a non-parametric model in terms of edge flows. We then prove that cumulative unfairness towards sensitive groups in a decision, like race in a bail decision, is non-existent when edge unfairness is absent. We prove this result for the non-trivial non-parametric model setting when the cumulative unfairness cannot be expressed in terms of edge unfairness. We then measure the Potential to mitigate the Cumulative Unfairness when edge unfairness is decreased. Based on these measurements, we propose the Unfair Edge Prioritization algorithm that can then be used by policymakers. We also propose the Discrimination Removal Procedure that de-biases a data distribution by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:prdVHNxh-e8C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Synthesizing high-quality, realistic images from text-descriptions is a challenging task, and current methods synthesize images from text in a multi-stage manner, typically by first generating a rough initial image and then refining image details at subsequent stages. However, existing methods that follow this paradigm suffer from three important limitations. Firstly, they synthesize initial images without attempting to separate image attributes at a word-level. As a result, object attributes of initial images (that provide a basis for subsequent refinement) are inherently entangled and ambiguous in nature. Secondly, by using common text-representations for all regions, current methods prevent us from interpreting text in fundamentally different ways at different parts of an image. Different image regions are therefore only allowed to assimilate the same type of information from text at each refinement stage. Finally, current methods generate refinement features only once at each refinement stage and attempt to address all image aspects in a single shot. This single-shot refinement limits the precision with which each refinement stage can learn to improve the prior image. Our proposed method introduces three novel components to address these shortcomings: (1) An initial generation stage that explicitly generates separate sets of image features for each word n-gram. (2) A spatial dynamic memory module for refinement of images. (3) An iterative multi-headed mechanism to make it easier to improve upon multiple image aspects. Experimental results demonstrate that our Multi-Headed Spatial Dynamic Memory image refinement with our Multi-Tailed Word-level …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:CB2v5VPnA5kC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"State abstraction enables sample-efficient learning and better task transfer in complex reinforcement learning environments. Recently, we proposed RePReL (Kokel et al. 2021), a hierarchical framework that leverages a relational planner to provide useful state abstractions for learning. We present a brief overview of this framework and the use of a dynamic probabilistic logic model to design these state abstractions. Our experiments show that RePReL not only achieves better performance and efficient learning on the task at hand but also demonstrates better generalization to unseen tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:owLR8QvbtFgC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Essential gene prediction models built so far are heavily reliant on sequence-based features, and the scope of network-based features has been narrow. Previous work from our group demonstrated the importance of using network-based features for predicting essential genes with high accuracy. Here, we apply our approach for the prediction of essential genes to organisms from the STRING database and host the results in a standalone website. Our database, NetGenes, contains essential gene predictions for 2,700+ bacteria predicted using features derived from STRING protein–protein functional association networks. Housing a total of over 2.1 million genes, NetGenes offers various features like essentiality scores, annotations, and feature vectors for each gene. NetGenes database is available from https://rbc-dsai-iitm.github.io/NetGenes/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:4X0JR2_MtJMC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"This article is one of two Distill publications about graph neural networks. Take a look at A Gentle Introduction to Graph Neural Networks for a companion view on many things graph and neural network related.
Many systems and interactions-social networks, molecules, organizations, citations, physical models, transactions-can be represented quite naturally as graphs. How can we reason about and make predictions within these systems?",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:WC23djZS0W4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Purpose The multi-armed bandit problem in reinforcement learning (RL) has often been used for classification problems [1]. As such, we wished to compare contextual multi-armed bandit to a multi-step Markov Decision Process (MDP)-based RL approach to classifying brain MRI’s. Methods",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:L1USKYWJimsC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Multiplex networks are complex graph structures in which a set of entities are connected to each other via multiple types of relations, each relation representing a distinct layer. Such graphs are used to investigate many complex biological, social, and technological systems. In this work, we present a novel semi-supervised approach for structure-aware representation learning on multiplex networks. Our approach relies on maximizing the mutual information between local node-wise patch representations and label correlated structure-aware global graph representations to model the nodes and cluster structures jointly. Specifically, it leverages a novel cluster-aware, node-contextualized global graph summary generation strategy for effective joint-modeling of node and cluster representations across the layers of a multiplex network. Empirically, we demonstrate that the proposed architecture outperforms state-of-the-art …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:7wO8s98CvbsC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,Depth-based 3D hand trackers are expected to estimate highly accurate poses of the human hand given the image. One of the critical problems in tracking the hand pose is the generation of realistic predictions. This paper proposes a novel “anatomical filter” that accepts a hand pose from a hand tracker and generates the closest possible pose within the real human hand’s anatomical bounds. The filter works by calculating the 26-DoF vector representing the joint angles and correcting those angles based on the real human hand’s biomechanical limitations. The proposed filter can be plugged into any hand tracker to enhance its performance. The filter has been tested on two state-of-the-art 3D hand trackers. The empirical observations show that our proposed filter improves the hand pose’s anatomical correctness and allows a smooth trade-off with pose error. The filter achieves the lowest prediction error when used with state-of-the-art trackers at 10% correction.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:cK4Rrx0J3m0C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Link prediction in graphs is studied by modeling the dyadic interactions among two nodes. The relationships can be more complex than simple dyadic interactions and could require the user to model super-dyadic associations among nodes. Such interactions can be modeled using a hypergraph, which is a generalization of a graph where a hyperedge can connect more than two nodes. In this work, we consider the problem of hyperedge prediction in a k-uniform hypergraph. We utilize the tensor-based representation of hypergraphs and propose a novel interpretation of the tensor eigenvectors. This is further used to propose a hyperedge prediction algorithm. The proposed algorithm utilizes the Fiedler eigenvector computed using tensor eigenvalue decomposition of hypergraph Laplacian. The Fiedler eigenvector is used to evaluate the construction cost of new hyperedges, which is further utilized to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:wMgC3FpKEyYC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"The teacher-student framework aims to improve the sample efficiency of RL algorithms by deploying an advising mechanism in which a teacher helps a student by guiding its exploration. Prior work in this field has considered an advising mechanism where the teacher advises the student about the optimal action to take in a given state. However, real-world teachers can leverage domain expertise to provide more informative signals. Using this insight, we propose to extend the current advising framework wherein the teacher would provide not only the optimal action but also a qualitative assessment of the state. We introduce a novel architecture, namely Advice Replay Memory (ARM), to effectively reuse the advice provided by the teacher. We demonstrate the robustness of our approach by showcasing our experiments on multiple Atari 2600 games using a fixed set of hyper-parameters. Additionally, we show that a student taking help even from a sub-optimal teacher can achieve significant performance boosts and eventually outperform the teacher. Our approach outperforms the baselines even when provided with comparatively suboptimal teachers and an advising budget, which is smaller by orders of magnitude. The contributions of our paper are 4-fold (a) effectively leveraging a teacher's knowledge by richer advising (b) introduction of ARM to effectively reuse the advice throughout learning (c) ability to achieve significant performance boost even with a coarse state categorization (d) enabling the student to outperform the teacher.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:CaZNVDsoPx4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Contextual bandits algorithms have become essential in real-world user interaction problems in recent years. However, these algorithms represent context as attribute value representation, which makes them infeasible for real world domains like social networks, which are inherently relational. We propose Relational Boosted Bandits (RB2), a contextual bandits algorithm for relational domains based on (relational) boosted trees. RB2 enables us to learn interpretable and explainable models due to the more descriptive nature of the relational representation. We empirically demonstrate the effectiveness and interpretability of RB2 on tasks such as link prediction, relational classification, and recommendation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:sJsF-0ZLhtgC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"State abstraction is necessary for better task transfer in complex reinforcement learning environments. Inspired by the benefit of state abstraction in MAXQ and building upon hybrid planner-RL architectures, we propose RePReL, a hierarchical framework that leverages a relational planner to provide useful state abstractions. Our experiments demonstrate that the abstractions enable faster learning and efficient transfer across tasks. More importantly, our framework enables the application of standard RL approaches for learning in structured domains. The benefit of using the state abstractions is critical in relational settings, where the number and/or types of objects are not fixed apriori. Our experiments clearly show that RePReL framework not only achieves better performance and efficient learning on the task at hand but also demonstrates better generalization to unseen tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:48xauSegjOkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Simple Summary
Cancer is caused by the accumulation of somatic mutations, some of which are responsible for the disease’s progression (drivers) while others are functionally neutral (passengers). Although several methods have been developed to distinguish between the two classes of mutations, very few have concentrated on using the neighborhood nucleotide sequences as potential discrimination features. In this study, we show that driver mutations’ neighborhood is significantly different from that of passengers. We further develop a novel machine learning tool, NBDriver, which is highly efficient at identifying pathogenic variants from multiple independent test datasets. Efficient and accurate identification of novel pathogenic variants from sequenced cancer genomes would help facilitate more effective therapies tailored to patients’ mutational profiles.
Abstract
Identifying cancer-causing mutations from sequenced cancer genomes hold much promise for targeted therapy and precision medicine. “Driver” mutations are primarily responsible for cancer progression, while “passengers” are functionally neutral. Although several computational approaches have been developed for distinguishing between driver and passenger mutations, very few have concentrated on using the raw nucleotide sequences surrounding a particular mutation as potential features for building predictive models. Using experimentally validated cancer mutation data in this study, we explored various string-based feature representation techniques to incorporate information on the neighborhood bases immediately 5′ and 3′ from each …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:buQ7SEKw-1sC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:MhiOAD_qIWkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Autonomous driving has emerged as one of the most active areas of research as it has the promise of making transportation safer and more efficient than ever before. Most real-world autonomous driving pipelines perform perception, motion planning and action in a loop. In this work we present MADRaS, an open-source multi-agent driving simulator for use in the design and evaluation of motion planning algorithms for autonomous driving. Given a start and a goal state, the task of motion planning is to solve for a sequence of position, orientation and speed values in order to navigate between the states while adhering to safety constraints. These constraints often involve the behaviors of other agents in the environment. MADRaS provides a platform for constructing a wide variety of highway and track driving scenarios where multiple driving agents can be trained for motion planning tasks using reinforcement learning and other machine learning algorithms. MADRaS is built on TORCS, an open-source car-racing simulator. TORCS offers a variety of cars with different dynamic properties and driving tracks with different geometries and surface. MADRaS inherits these functionalities from TORCS and introduces support for multi-agent training, inter-vehicular communication, noisy observations, stochastic actions, and custom traffic cars whose behaviors can be programmed to simulate challenging traffic conditions encountered in the real world. MADRaS can be used to create driving tasks whose complexities can be tuned along eight axes in well-defined steps. This makes it particularly suited for curriculum and continual learning. MADRaS is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:F1b5ZUV5XREC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"India has a maternal mortality ratio of 113 and child mortality ratio of 2830 per 100,000 live births. Lack of access to preventive care information is a major contributing factor for these deaths, especially in low resource households. We partner with ARMMAN, a non-profit based in India employing a call-based information program to disseminate health-related information to pregnant women and women with recent child deliveries. We analyze call records of over 300,000 women registered in the program created by ARMMAN and try to identify women who might not engage with these call programs that are proven to result in positive health outcomes. We built machine learning based models to predict the long term engagement pattern from call logs and beneficiaries' demographic information, and discuss the applicability of this method in the real world through a pilot validation. Through a pilot service quality improvement study, we show that using our model's predictions to make interventions boosts engagement metrics by 61.37%. We then formulate the intervention planning problem as restless multi-armed bandits (RMABs), and present preliminary results using this approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:lgwcVrK6X84C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"We present a deep network-based model of the associative memory functions of the hippocampus. The proposed network architecture has two key modules: 1) an autoencoder module which represents the forward and backward projections of the cortico-hippocampal projections and 2) a module that computes familiarity of the stimulus and implements hill-climbing over the familiarity which represents the dynamics of the loops within the hippocampus. The proposed network is used in two simulation studies. In the first part of the study, the network is used to simulate image pattern completion by autoassociation under normal conditions. In the second part of the study, the proposed network is extended to a heteroassociative memory and is used to simulate picture naming task in normal and Alzheimer’s disease (AD) conditions. The network is trained on pictures and names of digits from 0 – 9. The encoder layer of the network is partly damaged to simulate AD conditions. As in case of AD patients, under moderate damage condition, the network recalls superordinate words (“odd” instead of “nine”). Under severe damage conditions, the network shows a null response (“I don’t know”). Neurobiological plausibility of the model is extensively discussed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:QD3KBmkZPeQC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,This paper presents a sampling-based method for optimal motion planning in non-holonomic systems in the absence of known cost functions. It uses the principle of learning through experience to deduce the cost-to-go of regions within the workspace. This cost information is used to bias an incremental graph-based search algorithm that produces solution trajectories. Iterative improvement of cost information and search biasing produces solutions that are proven to be asymptotically optimal. The proposed framework builds on incremental Rapidly-exploring Random Trees (RRT) for random sampling-based search and Reinforcement Learning (RL) to learn workspace costs. A series of experiments were performed to evaluate and demonstrate the performance of the proposed method.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:4xDN1ZYqzskC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"In real time electricity markets, the objective of generation companies while bidding is to maximize their profit. The strategies for learning optimal bidding have been formulated through game theoretical approaches and stochastic optimization problems. Similar studies in reactive power markets have not been reported so far because the network voltage operating conditions have an increased impact on reactive power markets than on active power markets. Contrary to active power markets, the bids of rivals are not directly related to fuel costs in reactive power markets. Hence, the assumption of a suitable probability distribution function is unrealistic, making the strategies adopted in active power markets unsuitable for learning optimal bids in reactive power market mechanisms. Therefore, a bidding strategy is to be learnt from market observations and experience in imperfect oligopolistic competition-based markets. In this paper, a pioneer work on learning optimal bidding strategies from observation and experience in a three-stage reactive power market is reported.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:uDGL6kOW6j0C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Identifying how hard it is to achieve a good classification performance on a given dataset can be useful in data analysis, model selection, and meta-learning. We hypothesize that the dataset clustering indices which capture the characteristics of a dataset are related to the respective classification complexity. In this work, we propose a method for determining the empirical classification complexity of a dataset based on its clustering indices. We model this mapping problem as a supervised classification task where the estimated clustering indices of a given dataset form the features and with an indicator variable representing its classification complexity as the label. For the experiments, we use a set of clustering and classification algorithms spanning different modeling assumptions. To test whether the given dataset is complex, we estimate its clustering indices and feed it to the trained complexity classifier to output the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:PVgj2kMGcgYC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"A classification tree is grown by repeated partitioning of the dataset based on a predefined split criterion. The node split in the growth process depends only on the class ratio of the data chunk that gets split in every internal node of the tree. In a classification tree learning task, when the class ratio of the unlabeled part of the dataset is available, it becomes feasible to use the unlabeled data alongside the labeled data to train the tree in a semi-supervised style. Our motivation is to facilitate the usage of the abundantly available unlabeled data for building classification trees, as it is laborious and expensive to acquire labels. In this paper, we propose a semi-supervised approach to growing classification trees, where we adapted the Maximum Mean Discrepancy (MMD) method for estimating the class ratio at every node split. In our experimentation using several binary and multiclass classification datasets, we observed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:NyGDZy8z5eUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Data from Global Positioning Systems (GPS) and fare-meters in For-Hire vehicles (FHVs) have been used for various applications – both in research as well as organizational decision-making. The utility of such exercises largely depend on the accuracy of the data. This study looks at an environment where the data is partially mislabeled. Specifically, we take a common real-world setting where vehicle operators choose to render transportation services to customers without the use of a fare-meter, often by negotiating a fixed rate with the customer. This practice, which to different degrees, has been observed and documented across urban areas in the world, leads to various undesirable effects. In this study, we seek to identify cases of such behavior in the dataset. Typically, a supervised learning classifier could be built to predict the occupancy status from GPS traces, which can then be used, to look for anomalies …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:0CzhzZyukY4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"As machine learning is applied more to real-world problems like robotics, control of autonomous vehicles, drones, and recommendation systems, it becomes essential to consider the notion of agency where multiple agents with local observations start impacting each other and interact to achieve their goals. Multi-agent reinforcement learning (MARL) is concerned with developing learning algorithms that can discover effective policies in multi-agent environments. In this work, we develop algorithms for addressing two critical challenges in MARL - non-stationarity and robustness. We show that naive independent reinforcement learning does not preserve the strategic game-theoretic interaction between the agents, and we present a way to realize the classical infinite order recursion reasoning in a reinforcement learning setting. We refer to this framework as Interactive Policy Optimization (IPO) and derive four MARL algorithms using centralized-training-decentralized-execution that generalize the widely used single-agent policy gradient methods to multi-agent settings. Finally, we provide a method to estimate opponent's parameters in adversarial settings using maximum likelihood and integrate IPO with an adversarial learning framework to train agents robust to destabilizing disturbances from the environment/adversaries and for better sim2real transfer from simulated multi-agent environments to the real world.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:hsZV8lGYWTMC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2021,"Option discovery and skill acquisition frameworks are integral to the functioning of a hierarchically organized Reinforcement learning agent. However, such techniques often yield a large number of options or skills, which can be represented succinctly by filtering out any redundant information. Such a reduction can decrease the required computation while also improving the performance on a target task. To compress an array of option policies, we attempt to find a policy basis that accurately captures the set of all options. In this work, we propose Option Encoder, an auto-encoder based framework with intelligently constrained weights, that helps discover a collection of basis policies. The policy basis can be used as a proxy for the original set of skills in a suitable hierarchically organized framework. We demonstrate the efficacy of our method on a collection of grid-worlds evaluating the obtained policy basis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:DJbcl8HfkQkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Green Security Games (GSGs) have been successfully used in the protection of valuable resources such as fisheries, forests and wildlife. While real-world deployment involves both resource allocation and subsequent coordinated patrolling with communication and real-time, uncertain information, previous game models do not fully address both of these stages simultaneously. Furthermore, adopting existing solution strategies is difficult since they do not scale well for larger, more complex variants of the game models. We therefore first propose a novel GSG model that combines defender allocation, patrolling, real-time drone notification to human patrollers, and drones sending warning signals to attackers. The model further incorporates uncertainty for real-time decision-making within a team of drones and human patrollers. Second, we present CombSGPO, a novel and scalable algorithm based on reinforcement learning, to compute a defender strategy for this game model. CombSGPO performs policy search over a multi-dimensional, discrete action space to compute an allocation strategy that is best suited to a best-response patrolling strategy for the defender, learnt by training a multi-agent Deep Q-Network. We show via experiments that CombSGPO converges to better strategies and is more scalable than comparable approaches. Third, we provide a detailed analysis of the coordination and signaling behavior learnt by CombSGPO, showing group formation between defender resources and patrolling formations based on signaling and notifications between resources. Importantly, we find that strategic signaling emerges in the final learnt …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:6yz0xqPARnAC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Learning on graphs is a subject of great interest due to the abundance of relational data from real-world systems. Many of these systems involve higher-order interactions (super-dyadic) rather than mere pairwise (dyadic) relationships; examples of these are co-authorship, co-citation, and metabolic reaction networks. Such super-dyadic relations are more adequately modeled using hypergraphs rather than graphs. Learning on hypergraphs has thus been garnering increased attention with potential applications in network analysis, VLSI design, and computer vision, among others. Especially, hypergraph clustering is gaining attention because of its enormous applications such as component placement in VLSI, group discovery in bibliographic systems, image segmentation in CV, etc. For the problem of clustering on graphs, modularity maximization has been known to work well in the pairwise setting. Our primary contribution in this article is to provide a generalization of the modularity maximization framework for clustering on hypergraphs. In doing so, we introduce a null model for graphs generated by hypergraph reduction and prove its equivalence to the configuration model for undirected graphs. The proposed graph reduction technique preserves the node degree sequence from the original hypergraph. The modularity function can be defined on a thus reduced graph, which can be maximized using any standard modularity maximization method, such as the Louvain method. We additionally propose an iterative technique that provides refinement over the obtained clusters. We demonstrate both the efficacy and efficiency of our methods on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:Bg7qf7VwUHIC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Hypergraphs have gained increasing attention in the machine learning community lately due to their superiority over graphs in capturing super-dyadic interactions among entities. In this work, we propose a novel approach for the partitioning of k-uniform hypergraphs. Most of the existing methods work by reducing the hypergraph to a graph followed by applying standard graph partitioning algorithms. The reduction step restricts the algorithms to capturing only some weighted pairwise interactions and hence loses essential information about the original hypergraph. We overcome this issue by utilizing the tensor-based representation of hypergraphs, which enables us to capture actual super-dyadic interactions. We prove that the hypergraph to graph reduction is a special case of tensor contraction. We extend the notion of minimum ratio-cut and normalized-cut from graphs to hypergraphs and show the relaxed optimization problem is equivalent to tensor eigenvalue decomposition. This novel formulation also enables us to capture different ways of cutting a hyperedge, unlike the existing reduction approaches. We propose a hypergraph partitioning algorithm inspired from spectral graph theory that can accommodate this notion of hyperedge cuts. We also derive a tighter upper bound on the minimum positive eigenvalue of even-order hypergraph Laplacian tensor in terms of its conductance, which is utilized in the partitioning algorithm to approximate the normalized cut. The efficacy of the proposed method is demonstrated numerically on simple hypergraphs. We also show improvement for the min-cut solution on 2-uniform hypergraphs (graphs) over …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:2tRrZ1ZAMYUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"One challenging and essential task in biochemistry is the generation of novel molecules with desired properties. Novel molecule generation remains a challenge since the molecule space is difficult to navigate through, and the generated molecules should obey the rules of chemical valency. Through this work, we propose a novel method, which we call unitMCTS, to perform molecule generation by making a unit change to the molecule at every step using Monte Carlo Tree Search. We show that this method outperforms the recently published techniques on benchmark molecular optimization tasks such as QED and penalized logP. We also demonstrate the usefulness of this method in improving molecule properties while being similar to the starting molecule. Given that there is no learning involved, our method finds desired molecules within a shorter amount of time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:AHdEip9mkN0C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Understanding on-road vehicle behaviour from a temporal sequence of sensor data is gaining in popularity. In this paper, we propose a pipeline for understanding vehicle behaviour from a monocular image sequence or video. A monocular sequence along with scene semantics, optical flow and object labels are used to get spatial information about the object (vehicle) of interest and other objects (semantically contiguous set of locations) in the scene. This spatial information is encoded by a Multi-Relational Graph Convolutional Network (MR-GCN), and a temporal sequence of such encodings is fed to a recurrent network to label vehicle behaviours. The proposed framework can classify a variety of vehicle behaviours to high fidelity on datasets that are diverse and include European, Chinese and Indian on-road scenes. The framework also provides for seamless transfer of models across datasets without entailing re …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:OP4eGU-M3BUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"We present a novel Multi-Relational Graph Convolutional Network (MRGCN) based framework to model on-road vehicle behaviors from a sequence of temporally ordered frames as grabbed by a moving monocular camera. The input to MRGCN is a multi-relational graph where the graph's nodes represent the active and passive agents/objects in the scene, and the bidirectional edges that connect every pair of nodes are encodings of their Spatio-temporal relations.We show that this proposed explicit encoding and usage of an intermediate spatio-temporal interaction graph to be well suited for our tasks over learning end-end directly on a set of temporally ordered spatial relations. We also propose an attention mechanism for MRGCNs that conditioned on the scene dynamically scores the importance of information from different interaction types.The proposed framework achieves significant performance gain over …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:gVv57TyPmFsC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Law enforcement must prioritize sources of unfairness before mitigating their underlying unfairness, considering that they have limited resources. Unlike previous works that only make cautionary claims of discrimination and de-biases data after its generation, this paper attempts to prioritize unfair sources before mitigating their unfairness in the real-world. We assume that a causal bayesian network, representative of the data generation procedure, along with the sensitive nodes, that result in unfairness, are given. We quantify Edge Flow, which is the belief flowing along an edge by attenuating the indirect path influences, and use it to quantify Edge Unfairness. We prove that cumulative unfairness is non-existent in any decision, like judicial bail, towards any sensitive groups, like race, when the edge unfairness is absent, given an error-free linear model of conditional probability. We then measure the potential to mitigate the cumulative unfairness when edge unfairness is decreased. Based on these measures, we propose an unfair edge prioritization algorithm that prioritizes the unfair edges and a discrimination removal procedure that de-biases the generated data distribution. The experimental section validates the specifications used for quantifying the above measures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:kVjdVfd2voEC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Many real-world systems involve higher-order interactions and thus demand complex models such as hypergraphs. For instance, a research article could have multiple collaborating authors, and therefore the co-authorship network is best represented as a hypergraph. In this work, we focus on the problem of hyperedge prediction. This problem has immense applications in multiple domains, such as predicting new collaborations in social networks, discovering new chemical reactions in metabolic networks, etc. Despite having significant importance, the problem of hyperedge prediction hasn’t received adequate attention, mainly because of its inherent complexity. In a graph with n nodes the number of potential edges is , whereas in a hypergraph, the number of potential hyperedges is . To avoid searching through the huge space of hyperedges, current methods restrain the original problem in the following two ways …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:artPoR2Yc-kC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"India accounts for 11% of maternal deaths globally where a woman dies in childbirth every fifteen minutes. Lack of access to preventive care information is a significant problem contributing to high maternal morbidity and mortality numbers, especially in low-income households. We work with ARMMAN, a non-profit based in India, to further the use of call-based information programs by early-on identifying women who might not engage on these programs that are proven to affect health parameters positively.We analyzed anonymized call-records of over 300,000 women registered in an awareness program created by ARMMAN that uses cellphone calls to regularly disseminate health related information. We built robust deep learning based models to predict short term and long term dropout risk from call logs and beneficiaries' demographic information. Our model performs 13% better than competitive baselines for short-term forecasting and 7% better for long term forecasting. We also discuss the applicability of this method in the real world through a pilot validation that uses our method to perform targeted interventions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:U4n9YNQMCAIC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Deep Neural Networks (DNNs) have advanced the state-of-the-art in a variety of machine learning tasks and are deployed in increasing numbers of products and services. However, the computational requirements of training and evaluating large-scale DNNs are growing at a much faster pace than the capabilities of the underlying hardware platforms that they are executed upon. To address this challenge, one promising approach is to exploit the error resilient nature of DNNs by skipping or approximating computations that have negligible impact on classification accuracy. Almost all prior efforts in this direction propose static DNN approximations by either pruning network connections, implementing computations at lower precision, or compressing weights.
In this work, we propose Dynamic Variable Effort Deep Neural Networks (DyVEDeep) to reduce the computational requirements of DNNs during inference …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:vDijr-p_gm4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"This paper describes the application of reinforcement learning (RL) to multi-product inventory management in supply chains. The problem description and solution are both adapted from a real-world business solution. The novelty of this problem with respect to supply chain literature is (i) we consider concurrent inventory management of a large number (50 to 1000) of products with shared capacity, (ii) we consider a multi-node supply chain consisting of a warehouse which supplies three stores, (iii) the warehouse, stores, and transportation from warehouse to stores have finite capacities, (iv) warehouse and store replenishment happen at different time scales and with realistic time lags, and (v) demand for products at the stores is stochastic. We describe a novel formulation in a multi-agent (hierarchical) reinforcement learning framework that can be used for parallelised decision-making, and use the advantage actor critic (A2C) algorithm with quantised action spaces to solve the problem. Experiments show that the proposed approach is able to handle a multi-objective reward comprised of maximising product sales and minimising wastage of perishable products.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:gKiMpY-AVTkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"We consider the task of generating dialogue responses from background knowledge comprising of domain specific resources. Specifically, given a conversation around a movie, the task is to generate the next response based on background knowledge about the movie such as the plot, review, Reddit comments etc. This requires capturing structural, sequential and semantic information from the conversation context and the background resources. This is a new task and has not received much attention from the community. We propose a new architecture that uses the ability of BERT to capture deep contextualized representations in conjunction with explicit structure and sequence information. More specifically, we use (i) Graph Convolutional Networks (GCNs) to capture structural information, (ii) LSTMs to capture sequential information and (iii) BERT for the deep contextualized representations that capture semantic information. We analyze the proposed architecture extensively. To this end, we propose a plug-and-play Semantics-Sequences-Structures (SSS) framework which allows us to effectively combine such linguistic information. Through a series of experiments we make some interesting observations. First, we observe that the popular adaptation of the GCN model for NLP tasks where structural information (GCNs) was added on top of sequential information (LSTMs) performs poorly on our task. This leads us to explore interesting ways of combining semantic and structural information to improve the performance. Second, we observe that while BERT already outperforms other deep contextualized representations such as ELMo, it still …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:5icHVeHT4IsC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Recent studies on interpretability of attention distributions have led to notions of faithful and plausible explanations for a model's predictions. Attention distributions can be considered a faithful explanation if a higher attention weight implies a greater impact on the model's prediction. They can be considered a plausible explanation if they provide a human-understandable justification for the model's predictions. In this work, we first explain why current attention mechanisms in LSTM based encoders can neither provide a faithful nor a plausible explanation of the model's predictions. We observe that in LSTM based encoders the hidden representations at different time-steps are very similar to each other (high conicity) and attention weights in these situations do not carry much meaning because even a random permutation of the attention weights does not affect the model's predictions. Based on experiments on a wide variety of tasks and datasets, we observe attention distributions often attribute the model's predictions to unimportant words such as punctuation and fail to offer a plausible explanation for the predictions. To make attention mechanisms more faithful and plausible, we propose a modified LSTM cell with a diversity-driven training objective that ensures that the hidden representations learned at different time steps are diverse. We show that the resulting attention distributions offer more transparency as they (i) provide a more precise importance ranking of the hidden states (ii) are better indicative of words important for the model's predictions (iii) correlate better with gradient-based attribution methods. Human evaluations indicate that the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:5MTHONV0fEkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Ensuring robustness of Deep Neural Networks (DNNs) is crucial to their adoption in safety-critical applications such as self-driving cars, drones, and healthcare. Notably, DNNs are vulnerable to adversarial attacks in which small input perturbations can produce catastrophic misclassifications. In this work, we propose EMPIR, ensembles of quantized DNN models with different numerical precisions, as a new approach to increase robustness against adversarial attacks. EMPIR is based on the observation that quantized neural networks often demonstrate much higher robustness to adversarial attacks than full precision networks, but at the cost of a substantial loss in accuracy on the original (unperturbed) inputs. EMPIR overcomes this limitation to achieve the 'best of both worlds', i.e., the higher unperturbed accuracies of the full precision models combined with the higher robustness of the low precision models, by composing them in an ensemble. Further, as low precision DNN models have significantly lower computational and storage requirements than full precision models, EMPIR models only incur modest compute and memory overheads compared to a single full-precision model (<25% in our evaluations). We evaluate EMPIR across a suite of DNNs for 3 different image recognition tasks (MNIST, CIFAR-10 and ImageNet) and under 4 different adversarial attacks. Our results indicate that EMPIR boosts the average adversarial accuracies by 42.6%, 15.2% and 10.5% for the DNN models trained on the MNIST, CIFAR-10 and ImageNet datasets respectively, when compared to single full-precision models, without sacrificing accuracy on the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:u-coK7KVo8oC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Reinforcement learning algorithms are sensitive to hyper-parameters and require tuning and tweaking for specific environments for improving performance. Ensembles of reinforcement learning models on the other hand are known to be much more robust and stable. However, training multiple models independently on an environment suffers from high sample complexity. We present here a methodology to create multiple models from a single training instance that can be used in an ensemble through directed perturbation of the model parameters at regular intervals. This allows training a single model that converges to several local minima during the optimization process as a result of the perturbation. By saving the model parameters at each such instance, we obtain multiple policies during training that are ensembled during evaluation. We evaluate our approach on challenging discrete and continuous control tasks and also discuss various ensembling strategies. Our framework is substantially sample efficient, computationally inexpensive and is seen to outperform state of the art (SOTA) approaches",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:Aul-kAQHnToC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Automatically predicting the defect type of a software defect from its description can significantly speed up and improve the software defect management process. A major challenge for the supervised learning based current approaches for this task is the need for labeled training data. Creating such data is an expensive and effort-intensive task requiring domain-specific expertise. In this paper, we propose to circumvent this problem by carrying out concept-based classification (CBC) of software defect reports with help of the Explicit Semantic Analysis (ESA) framework. We first create the concept-based representations of a software defect report and the defect types in the software defect classification scheme by projecting their textual descriptions into a concept-space spanned by the Wikipedia articles. Then, we compute the “semantic” similarity between these concept-based representations and assign the software …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:nZcligLrVowC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Models often need to be constrained to a certain size for them to be considered interpretable. For example, a decision tree of depth 5 is much easier to understand than one of depth 50. Limiting model size, however, often reduces accuracy. We suggest a practical technique that minimizes this trade-off between interpretability and classification accuracy. This enables an arbitrary learning algorithm to produce highly accurate small-sized models. Our technique identifies the training data distribution to learn from that leads to the highest accuracy for a model of a given size. We represent the training distribution as a combination of sampling schemes. Each scheme is defined by a parameterized probability mass function applied to the segmentation produced by a decision tree. An Infinite Mixture Model with Beta components is used to represent a combination of such schemes. The mixture model parameters are learned using Bayesian Optimization. Under simplistic assumptions, we would need to optimize for O(d) variables for a distribution over a d-dimensional input space, which is cumbersome for most real-world data. However, we show that our technique significantly reduces this number to a fixed set of eight variables at the cost of relatively cheap preprocessing. The proposed technique is flexible: it is model-agnostic, i.e., it may be applied to the learning algorithm for any model family, and it admits a general notion of model size. We demonstrate its effectiveness using multiple real-world datasets to construct decision trees, linear probability models and gradient boosted models with different sizes. We observe significant improvements in the F1 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:Ehil0879vHcC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Ensemble learning is a very prevalent method employed in machine learning. The relative success of ensemble methods is attributed to their ability to tackle a wide range of instances and complex problems that require different low-level approaches. However, ensemble methods are relatively less popular in reinforcement learning owing to the high sample complexity and computational expense involved in obtaining a diverse ensemble. We present a novel training and model selection framework for model-free reinforcement algorithms that use ensembles of policies obtained from a single training run. These policies are diverse in nature and are learned through directed perturbation of the model parameters at regular intervals. We show that learning and selecting an adequately diverse set of policies is required for a good ensemble while extreme diversity can prove detrimental to overall performance. Selection of an adequately diverse set of policies is done through our novel policy selection framework. We evaluate our approach on challenging discrete and continuous control tasks and also discuss various ensembling strategies. Our framework is substantially sample efficient, computationally inexpensive and is seen to outperform state-of-the-art (SOTA) scores in Atari 2600 and Mujoco.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:yFnVuubrUp4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:LgRImbQfgY4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"The performance of a trained object detection neural network depends a lot on the image quality. Generally, images are pre-processed before feeding them into the neural network and domain knowledge about the image dataset is used to choose the pre-processing techniques. In this paper, we introduce an algorithm called ObjectRL to choose the amount of a particular pre-processing to be applied to improve the object detection performances of pre-trained networks. The main motivation for ObjectRL is that an image which looks good to a human eye may not necessarily be the optimal one for a pre-trained object detector to detect objects.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:BJbdYPG6LGMC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"This paper evaluates the applicability of reinforcement learning (RL) to multi-product inventory management in supply chains. The novelty of this problem with respect to supply chain literature is (i) we consider concurrent inventory management of a large number (hundreds) of products under realistic constraints such as shared capacity, and (ii) the number of products (size of the problem) can change frequently, implying that the RL agent needs to work in this regime without retraining. We approach the problem as a special class of dynamical system control, and explain why the generic problem cannot be satisfactorily solved using classical optimisation techniques. Subsequently, we formulate the problem in a reinforcement learning framework that can be used for parallelised decision-making, and use the advantage actor critic (A2C) and deep Q-network (DQN) algorithms with quantised action spaces to solve the problem. Experiments on scales between 100 and 220 products show that these approaches perform better than other baseline algorithms. They are also able to transfer learning without retraining, when the number of products change.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:fbc8zXXH2BUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"We propose a Semi-Supervised Learning (SSL) methodology that explicitly encodes different necessary priors to learn efficient representations for nodes in a network. The key to our framework is a semi-supervised cluster invariance constraint that explicitly groups nodes of similar labels together. We show that explicitly encoding this constraint allows one to learn meaningful node representations from both qualitative (visual) and quantitative standpoints. Specifically, our methodology realizes improved node classification and visually-enhanced clusterability of nodes on a wide range of datasets over competitive baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:ZzlSgRqYykMC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Social network interventions are used across a wide variety of domains to disseminate information or inspire changes in behavior; application areas range from substance abuse [24], to microfinance adoption [1], to HIV prevention [27, 28]. Such processes are computationally modelled via the influence maximization problem, where the goal is to select a subset of nodes from the network to spread a message, such that the number of people it eventually reaches is maximized. Several algorithmic approaches have been proposed for influence maximization [4, 10, 12, 16]. However, real-world applications of influence maximization are often limited by the high cost of collecting network data. In many domains, for instance, those arising in public health, a successful intervention requires information about the face-to-face interactions with the members of a population. This information is typically gathered via in-person surveys; conducting such surveys requires substantial effort on the part of the organization deploying an intervention. We are motivated in particular by the problem of using influence maximization for HIV prevention among homeless youth, where algorithms have been successfully piloted in real-world settings [27, 28]. In the HIV prevention domain, gathering the social network of the youth who frequent a given homeless centre requires a week or more of effort by social workers, which is not feasible for a typical community agency. The method proposed in [27] addresses this by introducing the CHANGE algorithm which uses a simple yet effective sampling method: surveying random nodes and one of their neighbours to discover parts of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:_OXeSy2IsFwC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"We propose a Semi-Supervised Learning (SSL) framework, USS-NMF, that allows for explicitly encoding different necessary priors to learn efficient node representations in a graph. USS-NMF specializes in encoding the important yet largely ignored necessary prior for SSL, the cluster assumption. The cluster assumption of SSL requires the existence of well-separated dense regions in a low-dimensional manifold with high label smoothness within each region. USSNMF encodes this assumption in the form of a proposed semi-supervised cluster invariance constraint, which is a group-level smoothness constraint on nodes. We show that explicitly enforcing this constraint enables learning meaningful node representations from both qualitative (visual) and quantitative standpoints. Specifically, USSNMF achieves superior performance on semi-supervised node classification and clustering tasks across thirteen datasets from over eight baselines. Also, the learned node embeddings from USS-NMF yield high-quality (wellseparated homophilous) clusters in t-SNE visualizations.
1 Background on Graph Embedding Graph Embedding techniques have become popular for learning representations for different components of the graph like nodes, edges, sub-graphs, and the entire graph. Graph embedding models encode different intrinsic and extrinsic properties of the network as continuous low dimensional vectors. Network representation learning has been realized by a variety of paradigms such as factorization models, graph kernels, skip-gram based models, deep learning models, generative models and hybrid paradigms, etc [2].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:P7Ujq4OLJYoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Many real-world systems consist of entities that exhibit complex group interactions rather than simple pairwise relationships; such multi-way relations are more suitably modeled using hypergraphs. In this work, we generalize the framework of modularity maximization, commonly used for community detection on graphs, for the hypergraph clustering problem. We introduce a hypergraph null model that can be shown to correspond exactly to the configuration model for undirected graphs. We then derive an adjacency matrix reduction that preserves the hypergraph node degree sequence, for use with this null model. The resultant modularity function can be maximized using the Louvain method, a popular fast algorithm known to work well in practice for graphs. We additionally propose an iterative refinement over this clustering that exploits higher-order information within the hypergraph, seeking to encourage balanced …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:fFSKOagxvKUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"Transit networks are essentially temporal with their topology evolving over time. While there are several studies on the topological properties of bus transit networks, none of them have captured the temporal network characteristics. We present a temporal analysis of a bus transit network using snapshot representation. We propose a supply-based weight measure, called the service utilization factor (SUF), and define it as the passenger demand per trip between two bus stops. We evaluate the complex network properties in three weighted cases for a bus network in India, using the number of overlapping routes, passenger demand between routes and SUF as weights. The study network is well-connected with 1.48 number of transfers on average to travel between any two stops over the day. The temporal analysis indicated an inadequate number of services in peak periods and route redundancy across the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:3htObqc8RwsC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2020,"The use of association rule mining techniques in diverse contexts and domains has resulted in the creation of numerous interestingness measures. This, in turn, has motivated researchers to come up with various classification schemes for these measures. One popular approach to classify the objective measures is to assess the set of mathematical properties they satisfy in order to help practitioners select the right measure for a given problem. In this research, we discuss the insufficiency of the existing properties in the literature to capture certain behaviors of interestingness measures. This motivates us to adopt an approach where a measure is described by how it varies if there is a unit change in the frequency count , at different preexisting states of the counts. This rate of change analysis is formally defined as the first partial derivative of the measure with respect to the various frequency …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:kz9GbA2Ns4gC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"This paper describes a purely data-driven solution to a class of sequential decision-making problems with a large number of concurrent online decisions, with applications to computing systems and operations research. We assume that while the micro-level behaviour of the system can be broadly captured by analytical expressions or simulation, the macro-level or emergent behaviour is complicated by non-linearity, constraints, and stochasticity. If we represent the set of concurrent decisions to be computed as a vector, each element of the vector is assumed to be a continuous variable, and the number of such elements is arbitrarily large and variable from one problem instance to another. We first formulate the decision-making problem as a canonical reinforcement learning (RL) problem, which can be solved using purely data-driven techniques. We modify a standard approach known as advantage actor critic (A2C) to ensure its suitability to the problem at hand, and compare its performance to that of baseline approaches on the specific instance of a multi-product inventory management task. The key modifications include a parallelised formulation of the decision-making task, and a training procedure that explicitly recognises the quantitative relationship between different decisions. We also present experimental results probing the learned policies, and their robustness to variations in the data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:ODE9OILHJdcC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"In this work, we focus on the task of Automatic Question Generation (AQG) where given a passage and an answer the task is to generate the corresponding question. It is desired that the generated question should be (i) grammatically correct (ii) answerable from the passage and (iii) specific to the given answer. An analysis of existing AQG models shows that they produce questions which do not adhere to one or more of {the above-mentioned qualities}. In particular, the generated questions look like an incomplete draft of the desired question with a clear scope for refinement. {To alleviate this shortcoming}, we propose a method which tries to mimic the human process of generating questions by first creating an initial draft and then refining it. More specifically, we propose Refine Network (RefNet) which contains two decoders. The second decoder uses a dual attention network which pays attention to both (i) the original passage and (ii) the question (initial draft) generated by the first decoder. In effect, it refines the question generated by the first decoder, thereby making it more correct and complete. We evaluate RefNet on three datasets, \textit{viz.}, SQuAD, HOTPOT-QA, and DROP, and show that it outperforms existing state-of-the-art methods by 7-16\% on all of these datasets. Lastly, we show that we can improve the quality of the second decoder on specific metrics, such as, fluency and answerability by explicitly rewarding revisions that improve on the corresponding metric during training. The code has been made publicly available \footnote{https://github.com/PrekshaNema25/RefNet-QG}",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:HtS1dXgVpQUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"SimRank is a widely studied link-based similarity measure that is known for its simple, yet powerful philosophy that two nodes are similar if they are referenced by similar nodes. While this philosophy has been the basis of several improvements, there is another useful, albeit less frequently discussed interpretation for SimRank known as the Random Surfer-Pair Model. In this work, we show that other well known measures related to SimRank can also be reinterpreted using Random Surfer-Pair Models, and establish a mathematically sound, general and unifying framework for several link-based similarity measures. This also serves to provide new insights into their functioning and allows for using these measures in a Monte Carlo framework, which provides several computational benefits. As an illustration of its utility in designing measures, we develop a new measure based on two existing measures under this …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:4vMrXwiscB8C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"The present disclosure relates to a method performed by a network node (54) in a communication network (50) comprising a plurality of communication devices (51), for finding temporally connected connection patterns of the communication devices in the network. The method comprises identifying signalling between the communication devices during a predefined time duration to form a main communication graph in which the plurality of communication devices are nodes. The method also comprises partitioning the main communication graph for a time period comprised in said time duration to capture temporally connected signalling between some of the communication devices as illustrated in the main communication graph in a partitioned communication graph. The method also comprises forming at least one subgraph from the partitioned communication graph, comprising m nodes corresponding to m …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:WZBGuue-350C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"Generating a curriculum for guided learning involves subjecting the agent to easier goals first, and then gradually increasing their difficulty. This work takes a similar direction and proposes a dual curriculum scheme for solving robotic manipulation tasks with sparse rewards, called MaMiC. It includes a macro curriculum scheme which divides the task into multiple subtasks followed by a micro curriculum scheme which enables the agent to learn between such discovered subtasks. We show how combining macro and micro curriculum strategies help in overcoming major exploratory constraints considered in robot manipulation tasks without having to engineer any complex rewards and also illustrate the meaning and usage of the individual curricula. The performance of such a scheme is analysed on the Fetch environments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:OTTXONDVkokC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"A serious challenge when finding influential actors in real-world social networks is the lack of knowledge about the structure of the underlying network. Current state-of-the-art methods rely on hand-crafted sampling algorithms; these methods sample nodes and their neighbours in a carefully constructed order and choose opinion leaders from this discovered network to maximize influence spread in the (unknown) complete network. In this work, we propose a reinforcement learning framework for network discovery that automatically learns useful node and graph representations that encode important structural properties of the network. At training time, the method identifies portions of the network such that the nodes selected from this sampled subgraph can effectively influence nodes in the complete network. The realization of such transferable network structure based adaptable policies is attributed to the meticulous design of the framework that encodes relevant node and graph signatures driven by an appropriate reward scheme. We experiment with real-world social networks from four different domains and show that the policies learned by our RL agent provide a 10-36% improvement over the current state-of-the-art method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:yMeIxYmEMEAC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"SimRank is a widely studied link-based similarity measure that is known for its simple, yet powerful philosophy that two nodes are similar if they are referenced by similar nodes. While this philosophy has been the basis of several improvements, there is another useful, albeit less frequently discussed interpretation for SimRank known as the Random Surfer-Pair Model. In this work, we show that other well known measures related to SimRank can also be reinterpreted using Random Surfer-Pair Models, and establish a mathematically sound, general and unifying framework for several link-based similarity measures. This also serves to provide new insights into their functioning and allows for using these measures in a Monte Carlo framework, which provides several computational benefits. Next, we describe how the framework can be used as a versatile tool for developing measures according to given design …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:r_AWSJRzSzQC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"In this work we present a novel approach for transfer-guided exploration in reinforcement learning that is inspired by the human tendency to leverage experiences from similar encounters in the past while navigating a new task. Given an optimal policy in a related task-environment, we show that its bisimulation distance from the current task-environment gives a lower bound on the optimal advantage of state-action pairs in the current task-environment. Transfer-guided Exploration (ExTra) samples actions from a Softmax distribution over these lower bounds. In this way, actions with potentially higher optimum advantage are sampled more frequently. In our experiments on gridworld environments, we demonstrate that given access to an optimal policy in a related task-environment, ExTra can outperform popular domain-specific exploration strategies viz. epsilon greedy, Model-Based Interval Estimation - Exploration Bonus (MBIE-EB), Pursuit and Boltzmann in rate of convergence. We further show that ExTra is robust to choices of source task and shows a graceful degradation of performance as the dissimilarity of the source task increases. We also demonstrate that ExTra, when used alongside traditional exploration algorithms, improves their rate of convergence. Thus it is capable of complementing the efficacy of traditional exploration algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:HIFyuExEbWQC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"As Machine Learning (ML) becomes pervasive in various real world systems, the need for models to be understandable has increased. We focus on interpretability, noting that models often need to be constrained in size for them to be considered interpretable, e.g., a decision tree of depth 5 is easier to interpret than one of depth 50. But smaller models also tend to have high bias. This suggests a trade-off between interpretability and accuracy. We propose a model agnostic technique to minimize this trade-off. Our strategy is to first learn a powerful, possibly black-box, probabilistic model - referred to as the oracle - on the training data. Uncertainty in the oracle's predictions are used to learn a sampling distribution for the training data. The interpretable model is trained on a sample obtained using this distribution. We demonstrate that such a model often is significantly more accurate than one trained on the original data. Determining the sampling strategy is formulated as an optimization problem. Our solution to this problem possesses the following key favorable properties: (1) the number of optimization variables is independent of the dimensionality of the data: a fixed number of seven variables are used (2) our technique is model agnostic - in that both the interpretable model and the oracle may belong to arbitrary model families. Results using multiple real world datasets, using Linear Probability Models and Decision Trees as interpretable models, with Gradient Boosted Model and Random Forest as oracles, are presented. We observe significant relative improvements in the F1-score in most cases, occasionally seeing improvements greater than …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:9c2xU6iGI7YC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"The study of networks has been evolving because of its applications in diverse fields. Many complex systems involve multiple types of interactions and such systems are better modeled as multilayer networks. The question “which are the most (or least) important nodes in a given network?”, has gained substantial attention in the network science community. The importance of a node is known as centrality and there are multiple ways to define it. Extending the centrality measure to multilayer networks is challenging since the relative contribution of intra-layer edges vs. that of inter-layer edges to multilayer centrality is not straightforward. With the growing applications of multilayer networks, several attempts have been made to define centrality in multilayer networks in recent years. There are different ways of tuning the inter-layer couplings which may lead to different classes of centrality measures. In this article …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:6ZxmRoH8BuwC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"The options framework in reinforcement learning models the notion of a skill or a temporally extended sequence of actions. The discovery of a reusable set of skills has typically entailed building options, that navigate to bottleneck states. This work adopts a complementary approach, where we attempt to discover options that navigate to landmark states. These states are prototypical representatives of well-connected regions and can hence access the associated region with relative ease. In this work, we propose Successor Options, which leverages Successor Representations to build a model of the state space. The intra-option policies are learnt using a novel pseudo-reward and the model scales to high-dimensional spaces easily. Additionally, we also propose an Incremental Successor Options model that iterates between constructing Successor Representations and building options, which is useful when robust Successor Representations cannot be built solely from primitive actions. We demonstrate the efficacy of our approach on a collection of grid-worlds, and on the high-dimensional robotic control environment of Fetch.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:mlAyqtXpCwEC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"One of the major drawbacks of RL is the low sample efficiency of the learning algorithms. In many cases domain expertise can help to mitigate this effect. Teacher-Student framework is one such paradigm, where a more experienced agent (teacher) upon being queried helps to accelerate the student’s learning by providing advice on the action to take in a given state. Real world teachers not only provide the action to take in a given state but also provide a more informative signal using the synthesis of knowledge they may have gained with experience. With this motivation, we propose a richer advising framework where the teacher augments the student’s knowledge by also providing the expected long term reward of following that action. The student can then use this value to steadily guide its Q-Network in the correct direction which can lead to a quicker convergence. To help student relive the advices received throughout its learning, we introduce an additional memory called the Advice Replay Memory (ARM). Results show that a student following our approach (a) is able to exploit the environment better, and (b) has a steeper learning curve.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:IUKN3-7HHlwC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"Graphs are increasingly becoming ubiquitous as models for structured data. A generative model that closely mimics the structural properties of a given set of graphs has utility in a variety of domains. Much of the existing work require that a large number of parameters, in fact exponential in size of the graphs, be estimated from the data. We take a slightly different approach to this problem, leveraging the extensive prior work in the formal graph grammar literature. In this paper, we propose a graph generation model based on Probabilistic Edge Replacement Grammars (PERGs). We propose a variant of PERG called Restricted PERG (RPERG), which is analogous to PCFGs in string grammar literature. With this restriction, we are able to derive a learning algorithm for estimating the parameters of the grammar from graph data. We empirically demonstrate on real life datasets that RPERGs outperform existing methods …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:XvxMoLDsR5gC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"Graphs are a natural abstraction for many problems where nodes represent entities and edges represent a relationship across entities. An important area of research that has emerged over the last decade is the use of graphs as a vehicle for non-linear dimensionality reduction in a manner akin to previous efforts based on manifold learning with uses for downstream database processing, machine learning and visualization. In this systematic yet comprehensive experimental survey, we benchmark several popular network representation learning methods operating on two key tasks: link prediction and node classification. We examine the performance of 12 unsupervised embedding methods on 15 datasets. To the best of our knowledge, the scale of our study -- both in terms of the number of methods and number of datasets -- is the largest to date. Our results reveal several key insights about work-to-date in this space. First, we find that certain baseline methods (task-specific heuristics, as well as classic manifold methods) that have often been dismissed or are not considered by previous efforts can compete on certain types of datasets if they are tuned appropriately. Second, we find that recent methods based on matrix factorization offer a small but relatively consistent advantage over alternative methods (e.g., random-walk based methods) from a qualitative standpoint. Specifically, we find that MNMF, a community preserving embedding method, is the most competitive method for the link prediction task. While NetMF is the most competitive baseline for node classification. Third, no single method completely outperforms other embedding methods on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:WJVC3Jt7v1AC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"Biological networks catalog the complex web of interactions happening between different molecules, typically proteins, within a cell. These networks are known to be highly modular, with groups of proteins associated with specific biological functions. Human diseases often arise from the dysfunction of one or more such proteins of the biological functional group. The ability, to identify and automatically extract these modules has implications for understanding the etiology of different diseases as well as the functional roles of different protein modules in disease. The recent DREAM challenge posed the problem of identifying disease modules from six heterogeneous networks of proteins/genes. There exist many community detection algorithms, but all of them are not adaptable to the biological context, as these networks are densely connected and the size of biologically relevant modules is quite small. The contribution of this study is 3-fold: first, we present a comprehensive assessment of many classic community detection algorithms for biological networks to identify non-overlapping communities, and propose heuristics to identify small and structurally well-defined communities—core modules. We evaluated our performance over 180 GWAS datasets. In comparison to traditional approaches, with our proposed approach we could identify 50% more number of disease-relevant modules. Thus, we show that it is important to identify more compact modules for better performance. Next, we sought to understand the peculiar characteristics of disease-enriched modules and what causes standard community detection algorithms to detect so few of them. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:a9-T7VOCCH8C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"Recently, there has been a lot of work on pruning filters from deep convolutional neural networks (CNNs) with the intention of reducing computations. The key idea is to rank the filters based on a certain criterion (say, -norm, average percentage of zeros, etc.) and retain only the top-ranked filters. Once the low-scoring filters are pruned away, the remainder of the network is fine-tuned and is shown to give performance comparable to the original unpruned network. In this work, we report experiments which suggest that the comparable performance of the pruned network is not due to the specific criterion chosen, but due to the inherent plasticity of deep neural networks which allows them to recover from the loss of pruned filters once the rest of the filters are fine-tuned. Specifically, we show counterintuitive results wherein by randomly pruning 25–50% filters from deep CNNs we are able to obtain the same …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:GtLg2Ama23sC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"In the domain of algorithmic music composition, machine learning-driven systems eliminate the need for carefully hand-crafting rules for composition. In particular, the capability of recurrent neural networks to learn complex temporal patterns lends itself well to the musical domain. Promising results have been observed across a number of recent attempts at music composition using deep RNNs. These approaches generally aim at first training neural networks to reproduce subsequences drawn from existing songs. Subsequently, they are used to compose music either at the audio sample-level or at the note-level. We designed a representation that divides polyphonic music into a small number of monophonic streams. This representation greatly reduces the complexity of the problem and eliminates an exponential number of probably poor compositions. On top of our LSTM neural network that learnt musical sequences in this representation, we built an RL agent that learnt to find combinations of songs whose joint dominance produced pleasant compositions. We present Amadeus, an algorithmic music composition system that composes music that consists of intricate melodies, basic chords, and even occasional contrapuntal sequences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:FAceZFleit8C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"Object detection in videos is an important task in computer vision for various applications such as object tracking, video summarization and video search. Although great progress has been made in improving the accuracy of object detection in recent years due to the rise of deep neural networks, the state-of-the-art algorithms are highly computationally intensive. In order to address this challenge, we make two important observations in the context of videos: (i) Objects often occupy only a small fraction of the area in each video frame, and (ii) There is a high likelihood of strong temporal correlation between consecutive frames. Based on these observations, we propose Pack and Detect (PaD), an approach to reduce the computational requirements of object detection in videos. In PaD, only selected video frames called anchor frames are processed at full size. In the frames that lie between anchor frames (inter-anchor …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:PVjk1bu6vJQC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"Robust Policy Search is the problem of learning policies that do not degrade in performance when subject to unseen environment model parameters. It is particularly relevant for transferring policies learned in a simulation environment to the real world. Several existing approaches involve sampling large batches of trajectories which reflect the differences in various possible environments, and then selecting some subset of these to learn robust policies, such as the ones that result in the worst performance. We propose an active learning based framework, EffAcTS, to selectively choose model parameters for this purpose so as to collect only as much data as necessary to select such a subset. We apply this framework using Linear Bandits, and experimentally validate the gains in sample efficiency and the performance of our approach on standard continuous control tasks. We also present a Multi-Task Learning …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:yqoGN6RLRZoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:mNrWkgRL2YcC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:IRz6iEL74y4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"Reinforcement Learning (RL) enables modelling of complex behavioral patterns for sequential decision making tasks with well-defined goals. Many successful RL algorithms rely on Temporal Difference (TD) Learning and consequently, accurate estimation of the value function becomes important. In this respect, λ-returns (LR) have proven effective in the past as they enable aggregation over multiple multi-step returns and help in faster propagation of delayed rewards. Though the exponentially decaying weighing scheme of λ-returns does garner validity from such theoretical and empirical results in the literature, it’s important to observe that it is a static weighing scheme with limited flexibility. We propose a new paradigm of dynamically weighted returns called Confidencebased Returns wherein the multiple many-step look-aheads are explicitly valued based on the confidence in the estimates. We propose a simple and efficient way to model confidence and use it to derive Confidence-based Returns. We incorporate Confidence-based Returns (CR) into the Asynchronous Advantage Actor Critic (A3C) algorithm to obtain a new variant of A3C called CRA3C and demonstrate the efficacy of CRA3C by showcasing results on multiple high-dimensional visual input tasks in the Atari 2600 domain.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:anf4URPfarAC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"Hierarchical Reinforcement Learning is a popular method to exploit temporal abstractions in order to tackle the curse of dimensionality. The options framework is one such hierarchical framework that models the notion of skills or options. However, learning a collection of task-agnostic transferable skills is a challenging task. Option discovery typically entails using heuristics, the majority of which revolve around discovering bottleneck states. In this work, we adopt a method complementary to the idea of discovering bottlenecks. Instead, we attempt to discover ``landmark"" sub-goals which are prototypical states of well connected regions. These sub-goals are points from which densely connected set of states are easily accessible. We propose a new model called Successor options that leverages Successor Representations to achieve the same. We also design a novel pseudo-reward for learning the intra-option policies. Additionally, we describe an Incremental Successor options model that iteratively builds options and explores in environments where exploration through primitive actions is inadequate to form the Successor Representations. Finally, we demonstrate the efficacy of our approach on a collection of grid worlds and on complex high dimensional environments like Deepmind-Lab.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:4fGpz3EwCPoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2019,"The problem of identifying free space in an environment from a given single image is a subject matter of interest in the field of computer vision and robotics. The aim of this paper is to construct a scaled 2D floor map from a single two-point perspective (2PP) image for visualizing the relative dimensions and poses of the objects, by taking minimal information. This is done by proposing a new simple method which utilizes the perspective property of the given image, viz., vanishing points. This paper introduces necessary geometrical constructions by introducing the notion of the side view of an image, using which few simple geometrical relations will be derived, that will help in constructing a 2D floor map. To the best of our knowledge, this is the first work of its kind, which introduces architectural concepts for map construction and for measurements from it, thus proving novelty of the introduced method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:5qfkUJPXOUwC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Clustering on hypergraphs has been garnering increased attention with potential applications in network analysis, VLSI design and computer vision, among others. In this work, we generalize the framework of modularity maximization for clustering on hypergraphs. To this end, we introduce a hypergraph null model, analogous to the configuration model on undirected graphs, and a node-degree preserving reduction to work with this model. This is used to define a modularity function that can be maximized using the popular and fast Louvain algorithm. We additionally propose a refinement over this clustering, by reweighting cut hyperedges in an iterative fashion. The efficacy and efficiency of our methods are demonstrated on several real-world datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:_FM0Bhl9EiAC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Monocular SLAM refers to using a single camera to estimate robot ego motion while building a map of the environment. While Monocular SLAM is a well studied problem, automating Monocular SLAM by integrating it with trajectory planning frameworks is particularly challenging. This paper presents a novel formulation based on Reinforcement Learning (RL) that generates fail safe trajectories wherein the SLAM generated outputs do not deviate largely from their true values. Quintessentially, the RL framework successfully learns the otherwise complex relation between perceptual inputs and motor actions and uses this knowledge to generate trajectories that do not cause failure of SLAM. We show systematically in simulations how the quality of the SLAM dramatically improves when trajectories are computed using RL. Our method scales effectively across Monocular SLAM frameworks in both simulation and in real …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:W5xh706n7nkC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Treating deep neural networks as black boxes and using them as-is from a toolbox could potentially lead to sub-optimal performance. Increasingly machine learning researchers have to be more aware of the computational workloads entailed by their models and how to optimize for them. In this talk, I will describe three different pieces of our recent work with deep convolutional networks and their variants in improving inference performance across a variety of tasks like object detection, identification, tracking, etc. These studies demonstrate the need for peeling back the cover and paying attention to the computation even when using standard models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:4hFrxpcac9AC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Machine learning approaches to predict essential genes have gained a lot of traction in recent years. These approaches predominantly make use of sequence and network-based features to predict essential genes. However, the scope of network-based features used by the existing approaches is very narrow. Further, many of these studies focus on predicting essential genes within the same organism, which cannot be readily used to predict essential genes across organisms. Therefore, there is clearly a need for a method that is able to predict essential genes across organisms, by leveraging network-based features. In this study, we extract several sets of network-based features from protein–protein association networks available from the STRING database. Our network features include some common measures of centrality, and also some novel recursive measures recently proposed in social network literature. We extract hundreds of network-based features from networks of 27 diverse organisms to predict the essentiality of 87000+ genes. Our results show that network-based features are statistically significantly better at classifying essential genes across diverse bacterial species, compared to the current state-of-the-art methods, which use mostly sequence and a few ‘conventional’ network-based features. Our diverse set of network properties gave an AUROC of 0.847 and a precision of 0.320 across 27 organisms. When we augmented the complete set of network features with sequence-derived features, we achieved an improved AUROC of 0.857 and a precision of 0.335. We also constructed a reduced set of 100 sequence and network …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:kh2fBNsKQNwC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Learning options that allow agents to exhibit temporally higher order behavior has proven to be useful in increasing exploration, reducing sample complexity and for various transfer scenarios. Deep Discovery of Options (DDO) is a generative algorithm that learns a hierarchical policy along with options directly from expert trajectories. We perform a qualitative and quantitative analysis of options inferred from DDO in different domains. To this end, we suggest different value metrics like option termination condition, hinge value function error and KL-Divergence based distance metric to compare different methods. Analyzing the termination condition of the options and number of time steps the options were run revealed that the options were terminating prematurely. We suggest modifications which can be incorporated easily and alleviates the problem of shorter options and a collapse of options to the same mode.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:Ri6SYOTghG4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Sparse reward problems are one of the biggest challenges in Reinforcement Learning. Goal-directed tasks are one such sparse reward problems where a reward signal is received only when the goal is reached. One promising way to train an agent to perform goal-directed tasks is to use Hindsight Learning approaches. In these approaches, even when an agent fails to reach the desired goal, the agent learns to reach the goal it achieved instead. Doing this over multiple trajectories while generalizing the policy learned from the achieved goals, the agent learns a goal conditioned policy to reach any goal. One such approach is Hindsight Experience replay which uses an off-policy Reinforcement Learning algorithm to learn a goal conditioned policy. In this approach, a replay of the past transitions happens in a uniformly random fashion. Another approach is to use a Hindsight version of the policy gradients to directly learn a policy. In this work, we discuss different ways to replay past transitions to improve learning in hindsight experience replay focusing on prioritized variants in particular. Also, we implement the Hindsight Policy gradient methods to robotic tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:bKqednn6t2AC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"The problem of identifying free space in an environment from a given single image is a subject matter of interestin the field of computer vision and robotics. The aim of this paper is to construct a scaled 2D floor map from a single two-point perspective (2PP) image for visualizing the relative dimensions and poses of the objects, by taking minimal information. This is done by proposing a new simple method which utilizes the perspective property of the given image, viz., vanishing points. This paper introduces necessary geometrical constructions by introducing the notion of the side view of an image, using which few simple geometrical relations will be derived, that will help in constructing a 2D floor map. To the best of our knowledge, this is the first work of its kind, which introduces architectural concepts for map construction and for measurements from it, thus proving novelty of the introduced method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:86PQX7AUzd4C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"There is a growing interest in understanding, as opposed to predicting, the repayment behavior of customers of financial institutions that provide loans. This study proposes a modified Hidden Markov Model (HMM) based clustering, which clusters repayment sequences across selected subsets of the HMM parameters. We demonstrate that different implementations of this modified adaptation helps us gain an in-depth understanding of various drivers that are hard to directly observe but nevertheless govern repayment. These include drivers such as the ability to repay (financial health of the customer) or the intention to repay independent of the ability (willful defaulting and unintentional delinquency). Algorithmically, we achieve this partially constrained HMM clustering (PC-HMM) by placing constraints on the expectation-maximization (EM) algorithm where a subset of parameters are used to cluster the repayments via …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:hCrLmN-GePgC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Most methods that attempt to tackle the problem of Autonomous Driving and overtaking usually try to either directly minimize an objective function or iteratively in a Reinforcement Learning like framework to generate motor actions given a set of inputs. We follow a similar trend but train the agent in a way similar to a curriculum learning approach where the agent is first given an easier problem to solve, followed by a harder problem. We use Deep Deterministic Policy Gradients to learn overtaking maneuvers for a car, in presence of multiple other cars, in a simulated highway scenario. The novelty of our approach lies in the training strategy used where we teach the agent to drive in a manner similar to the way humans learn to drive and the fact that our reward function uses only the raw sensor data at the current time step. This method, which resembles a curriculum learning approach is able to learn smooth maneuvers …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:rmuvC79q63oC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Most methods that attempt to tackle the problem of Autonomous Driving and overtaking usually try to either directly minimize an objective function or iteratively in a Reinforcement Learning like framework to generate motor actions given a set of inputs. We follow a similar trend but train the agent in a way similar to a curriculum learning approach where the agent is first given an easier problem to solve, followed by a harder problem. We use Deep Deterministic Policy Gradients to learn overtaking maneuvers for a car, in presence of multiple other cars, in a simulated highway scenario. The novelty of our approach lies in the training strategy used where we teach the agent to drive in a manner similar to the way humans learn to drive and the fact that our reward function uses only the raw sensor data at the current time step. This method, which resembles a curriculum learning approach is able to learn smooth maneuvers …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:_axFR9aDTf0C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Given a graph where every node has certain attributes associated with it and some nodes have labels associated with them, Collective Classification (CC) is the task of assigning labels to every unlabeled node using information from the node as well as its neighbors. It is often the case that a node is not only influenced by its immediate neighbors but also by higher order neighbors, multiple hops away. Recent state-of-the-art models for CC learn end-to-end differentiable variations of Weisfeiler-Lehman (WL) kernels to aggregate multi-hop neighborhood information. In this work, we propose a Higher Order Propagation Framework, HOPF, which provides an iterative inference mechanism for these powerful differentiable kernels. Such a combination of classical iterative inference mechanism with recent differentiable kernels allows the framework to learn graph convolutional filters that simultaneously exploit the attribute and label information available in the neighborhood. Further, these iterative differentiable kernels can scale to larger hops beyond the memory limitations of existing differentiable kernels. We also show that existing WL kernel-based models suffer from the problem of Node Information Morphing where the information of the node is morphed or overwhelmed by the information of its neighbors when considering multiple hops. To address this, we propose a specific instantiation of HOPF, called the NIP models, which preserves the node information at every propagation step. The iterative formulation of NIP models further helps in incorporating distant hop information concisely as summaries of the inferred labels. We do an extensive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:Ug5p-4gJ2f0C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Semi-supervised node classification in attributed graphs, i.e., graphs with node features, involves learning to classify unlabeled nodes given a partially labeled graph. Label predictions are made by jointly modeling the node and its' neighborhood features. State-of-the-art models for node classification on such attributed graphs use differentiable recursive functions that enable aggregation and filtering of neighborhood information from multiple hops. In this work, we analyze the representation capacity of these models to regulate information from multiple hops independently. From our analysis, we conclude that these models despite being powerful, have limited representation capacity to capture multi-hop neighborhood information effectively. Further, we also propose a mathematically motivated, yet simple extension to existing graph convolutional networks (GCNs) which has improved representation capacity. We extensively evaluate the proposed model, F-GCN on eight popular datasets from different domains. F-GCN outperforms the state-of-the-art models for semi-supervised learning on six datasets while being extremely competitive on the other two.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:XoXfffV-tXoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Text-based games are suitable test-beds for designing agents that can learn by interaction with the environment in the form of natural language text. Very recently, deep reinforcement learning based agents have been successfully applied for playing text-based games. In this paper, we explore the possibility of designing a single agent to play several text-based games and of expanding the agent's vocabulary using the vocabulary of agents trained for multiple games. To this extent, we explore the application of recently proposed policy distillation method for video games to the text-based game setting. We also use text-based games as a test-bed to analyze and hence understand policy distillation approach in detail.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:ruyezt5ZtCIC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"We propose a novel variant of the UCB algorithm (referred to as Efficient-UCB-Variance (EUCBV)) for minimizing cumulative regret in the stochastic multi-armed bandit (MAB) setting. EUCBV incorporates the arm elimination strategy proposed in UCB-Improved, while taking into account the variance estimates to compute the arms' confidence bounds, similar to UCBV. Through a theoretical analysis we establish that EUCBV incurs a gap-dependent regret bound which is an improvement over that of existing state-of-the-art UCB algorithms (such as UCB1, UCB-Improved, UCBV, MOSS). Further, EUCBV incurs a gap-independent regret bound which is an improvement over that of UCB1, UCBV and UCB-Improved, while being comparable with that of MOSS and OCUCB. Through an extensive numerical study we show that EUCBV significantly outperforms the popular UCB variants (like MOSS, OCUCB, etc.) as well as Thompson sampling and Bayes-UCB algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:LI9QrySNdTsC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Recently there has been a lot of work on pruning filters from deep convolutional neural networks (CNNs) with the intention of reducing computations. The key idea is to rank the filters based on a certain criterion (say, l1-norm, average percentage of zeros, etc) and retain only the top ranked filters. Once the low scoring filters are pruned away the remainder of the network is fine tuned and is shown to give performance comparable to the original unpruned network. In this work, we report experiments which suggest that the comparable performance of the pruned network is not due to the specific criterion chosen but due to the inherent plasticity of deep neural networks which allows them to recover from the loss of pruned filters once the rest of the filters are fine-tuned. Specifically, we show counter-intuitive results wherein by randomly pruning 25-50% filters from deep CNNs we are able to obtain the same performance as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:-FonjvnnhkoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Most reinforcement learning algorithms are inefficient for learning multiple tasks in complex robotic systems, where different tasks share a set of actions. In such environments a compound policy may be learnt with shared neural network parameters, which performs multiple tasks concurrently. However such compound policy may get biased towards a task or the gradients from different tasks negate each other, making the learning unstable and sometimes less data efficient. In this paper, we propose a new approach for simultaneous training of multiple tasks sharing a set of common actions in continuous action spaces, which we call as DiGrad (Differential Policy Gradient). The proposed framework is based on differential policy gradients and can accommodate multi-task learning in a single actor-critic network. We also propose a simple heuristic in the differential policy gradient update to further improve the learning. The proposed architecture was tested on 8 link planar manipulator and 27 degrees of freedom(DoF) Humanoid for learning multi-goal reachability tasks for 3 and 2 end effectors respectively. We show that our approach supports efficient multi-task learning in complex robotic systems, outperforming related methods in continuous action spaces.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:i2xiXl-TujoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Identification of modules in molecular networks is at the core of many current analysis methods in biomedical research. However, how well different approaches identify disease-relevant modules in different types of gene and protein networks remains poorly understood. We launched the “Disease Module Identification DREAM Challenge”, an open competition to comprehensively assess module identification methods across diverse protein-protein interaction, signaling, gene co-expression, homology, and cancer-gene networks. Predicted network modules were tested for association with complex traits and diseases using a unique collection of 180 genome-wide association studies (GWAS). Our critical assessment of 75 contributed module identification methods reveals novel top-performing algorithms, which recover complementary trait-associated modules. We find that most of these modules correspond to core disease-relevant pathways, which often comprise therapeutic targets and correctly prioritize candidate disease genes. This community challenge establishes benchmarks, tools and guidelines for molecular network analysis to study human disease biology (https://synapse.org/modulechallenge).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:pAkWuXOU-OoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:S16KYo8Pm5AC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Classification of data with imbalance characteristics has become an important research problem, as data from most of the real-world applications follow non-uniform class distributions. A simple solution to handle class imbalance is by sampling from the dataset appropriately to compensate for the imbalance in class proportions. When the data distribution is unknown during sampling, making assumptions on the distribution requires domain knowledge and insights on the dataset. We propose a novel unsupervised topic modeling based weighting framework to estimate the latent data distribution of a dataset. We also propose TODUS, a topics oriented directed undersampling algorithm that follows the estimated data distribution to draw samples from the dataset. TODUS minimizes the loss of important information that typically gets dropped during random undersampling. We have shown empirically that the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:e_rmSamDkqQC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"The Interconnection and Damping Assignment Passivity Based Control (IDA-PBC) is a well-known method for control of complex physical systems in the port-Hamiltonian framework. Improvising on top of IDA-PBC which just focuses on stability, the memristive port-Hamiltonian control addresses performance concerns in the control task by providing a state-modulated damping term to IDA-PBC via a memristor element. The control way of implementing the memristive IDA-PBC first requires solving a set of Partial Differential Equations (PDEs) and then choosing a suitable memristance function for the system, out of which the former is a challenging math problem and the latter is a design problem. This paper employs reinforcement learning to learn the memristive IDA-PBC law and in the process, avoids the challenging task of solving PDEs, automates the design of the memristance function and also respects some …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:PoWvk5oyLR8C,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Video image processing of traffic camera feeds is useful for counting and classifying vehicles, estimating queue length, traffic speed and also for tracking individual vehicles. Unlike homogeneous traffic, heterogeneous traffic includes multiple vehicle types that do not follow lane discipline. Vehicle detection is especially challenging when vehicles are occluded which is common in heterogeneous traffic. Recently Deep Learning has shown remarkable promise in solving many computer vision tasks such as object recognition, detection, and tracking. However, training deep learning architectures require huge labeled datasets which are time-consuming and expensive to acquire. We circumvent this problem by data augmentation. By properly augmenting an existing large general (non-traffic) dataset with a small low-resolution heterogeneous traffic dataset (that we collected), we obtain state-of-the-art vehicle detection …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:foquWX3nUaYC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Financial institutions that provide loans are interested in understanding, as opposed to just predicting, the repayment behavior of its customers. This study applies a modified Hidden Markov Model (HMM) based clustering which clusters repayment sequences across selected subsets of the HMM parameters. We demonstrate that different implementations of this adaptation help us gain an in-depth understanding of various drivers that are hard to observe directly, but nevertheless govern repayment. These include drivers such as the ability to repay, or the intention to repay independent of the ability. Our results are compared to an alternate sequence clustering approach. The study concludes with the observation that the ability to cluster on selective parameters, in conjunction with the structural construct of HMMs, enables the discovery of substantially more meaningful business insights.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:M7yex6snE4oC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Impulsivity involves irresistibility in execution of actions and is prominent in medication condition of Parkinson’s disease (PD) patients. In this chapter, we model a probabilistic reversal learning task in PD patients with and without impulse control disorder (ICD) to understand the basis of their neural circuitry responsible for displaying ICD in PD condition. The proposed model is of the basal ganglia (BG) action selection dynamics, and it predicts the dysfunction of both dopaminergic (DA) and serotonergic (5HT) neuromodulator systems to account for the experimental results. Furthermore, the BG is modeled after utility function framework with DA controlling reward prediction and 5HT controlling the loss and risk prediction, respectively. The striatal model has three pools of medium spiny neurons (MSNs) including those with D1 receptor (R) alone, D2R alone, and co-expressing D1R–D2R neurons. Some …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:HhcuHIWmDEUC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:LdasjJ6CEcoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"Smart Content Based Image Retrieval (CBIR) helps to simultaneously localize and recognize all object(s) present in a scene, for image retrieval task. The major drawbacks in such kind of system are: (a) overhead for addition of new class is high - addition of new class requires manual annotation of large number of samples and retraining of an entire object model; and (b) use of handcrafted features for recognition and localization task, which limits its performance. In this era of data proliferation where it is easy to discover new object categories and hard to label all of them i.e. less amount of labeled samples for training which raises the above mentioned drawbacks. In this work, we propose an approach which cuts down the overhead of labelling the data and re-training on an entire module to learn new classes. The major components in proposed framework are: (a) selection of an appropriate pre-trained …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:q3CdL3IzO_QC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"In addition to dopaminergic input, serotonergic (5-HT) fibers also widely arborize through the basal ganglia circuits and strongly control their dynamics. Although empirical studies show that 5-HT plays many functional roles in risk-based decision making, reward, and punishment learning, prior computational models mostly focus on its role in behavioral inhibition or timescale of prediction. This chapter presents an extended reinforcement learning (RL)-based model of DA and 5-HT function in the BG, which reconciles some of the diverse roles of 5-HT. The model uses the concept of utility function—a weighted sum of the traditional value function expressing the expected sum of the rewards, and a risk function expressing the variance observed in reward outcomes. Serotonin is represented by a weight parameter, used in this combination of value and risk functions, while the neuromodulator dopamine (DA) is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:xtoqd-5pKcoC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"We present a model of bird song learning and production in which the motor control pathway is modeled by a trainable network of oscillators and the Anterior Forebrain Pathway (AFP) is modeled as a stochastic system. Song learning in many species of birds is divided into two phases. In the first phase, the sensory phase, the male bird listens to the tutor song of another male bird in the colony and memorizes some aspect of the tutor song. In the second phase, the motor learning phase, the bird establishes the songs learnt earlier by rehearsal aided by auditory self-feedback. We hypothesize that: (1) the songbird learns only evaluations of songs during the sensory phase; (2) the AFP plays a role analogous to the Explorer, a key component in reinforcement learning (RL); (3) the motor pathway learns the song by combining the evaluations (value information) stored from the sensory phase, and the exploratory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:Dip1O2bNi0gC,http://www.cse.iitm.ac.in/~ravi
Balaraman Ravindran,"['Reinforcement Learning', 'Data Mining', 'Social Network Analysis', 'Text Analytics']",30,3528,2018,"A designed experiment is typically followed by a statistical analysis of the results, using which the preferred settings of the inputs are selected for operation. In this paper, we motivate real-world scenarios, where it could be advantageous to succeed the experiment with continued exploration upon deployment in the online context. We propose the use of Linear Bandits to conduct sequential experiments in the online setting. The linear bandit algorithms, which utilize results from the designed experiment as an initial seed, are then used to select a treatment combination in each step or trial. Specifically, the study analyzes two linear bandit algorithms and compares them to three different baselines. The two linear bandit algorithms are OFUL, which is shown in literature to have one of the best theoretical performances, and LGUCBand, a novel contribution of this research, which uses the statistical concept of upper …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=nGUcGrYAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=nGUcGrYAAAAJ:k8Z6L05lTy4C,http://www.cse.iitm.ac.in/~ravi
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"We present Samanantar, the largest publicly available parallel corpora collection for Indic languages. The collection contains a total of 49.7 million sentence pairs between English and 11 Indic languages (from two language families). Specifically, we compile 12.4 million sentence pairs from existing, publicly available parallel corpora, and additionally mine 37.4 million sentence pairs from the Web, resulting in a 4× increase. We mine the parallel sentences from the Web by combining many corpora, tools, and methods: (a) Web-crawled monolingual corpora, (b) document OCR for extracting sentences from scanned documents, (c) multilingual representation models for aligning sentences, and (d) approximate nearest neighbor search for searching in a large collection of sentences. Human evaluation of samples from the newly mined corpora validate the high quality of the parallel sentences across 11 languages …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:5Ul4iDaHHb8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"The rapid growth of machine translation (MT) systems has necessitated comprehensive studies to meta-evaluate evaluation metrics being used, which enables a better selection of metrics that best reflect MT quality. Unfortunately, most of the research focuses on high-resource languages, mainly English, the observations for which may not always apply to other languages. Indian languages, having over a billion speakers, are linguistically different from English, and to date, there has not been a systematic study of evaluating MT systems from English into Indian languages. In this paper, we fill this gap by creating an MQM dataset consisting of 7000 fine-grained annotations, spanning 5 Indian languages and 7 MT systems, and use it to establish correlations between annotator scores and scores obtained using existing automatic metrics. Our results show that pre-trained metrics, such as COMET, have the highest correlations with annotator scores. Additionally, we find that the metrics do not adequately capture fluency-based errors in Indian languages, and there is a need to develop metrics focused on Indian languages. We hope that our dataset and analysis will help promote further research in this area.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:ZuybSZzF8UAC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"We present, Naamapadam, the largest publicly available Named Entity Recognition (NER) dataset for the 11 major Indian languages from two language families. In each language, it contains more than 400k sentences annotated with a total of at least 100k entities from three standard entity categories (Person, Location and Organization) for 9 out of the 11 languages. The training dataset has been automatically created from the Samanantar parallel corpus by projecting automatically tagged entities from an English sentence to the corresponding Indian language sentence. We also create manually annotated testsets for 8 languages containing approximately 1000 sentences per language. We demonstrate the utility of the obtained dataset on existing testsets and the Naamapadam-test data for 8 Indic languages. We also release IndicNER, a multilingual mBERT model fine-tuned on the Naamapadam training set. IndicNER achieves the best F1 on the Naamapadam-test set compared to an mBERT model fine-tuned on existing datasets. IndicNER achieves an F1 score of more than 80 for 7 out of 11 Indic languages. The dataset and models are available under open-source licenses at https://ai4bharat.iitm.ac.in/naamapadam.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:N5tVd3kTz84C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"In this work, we introduce IndicXTREME, a benchmark consisting of nine diverse tasks covering 18 languages from the Indic sub-continent belonging to four different families. Across languages and tasks, IndicXTREME contains a total of 103 evaluation sets, of which 51 are new contributions to the literature. To maintain high quality, we only use human annotators to curate or translate\footnote{for IndicXParaphrase, where an automatic translation system is used, a second human verification and correction step is done.} our datasets. To the best of our knowledge, this is the first effort toward creating a standard benchmark for Indic languages that aims to test the zero-shot capabilities of pretrained language models. We also release IndicCorp v2, an updated and much larger version of IndicCorp that contains 20.9 billion tokens in 24 languages. We pretrain IndicBERT v2 on IndicCorp v2 and evaluate it on IndicXTREME to show that it outperforms existing multilingual language models such as XLM-R and MuRIL.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:VL0QpB8kHFEC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"There are over 300 sign languages in the world, many of which have very limited or no labelled sign-to-text datasets. To address low-resource data scenarios, self-supervised pretraining and multilingual finetuning have been shown to be effective in natural language and speech processing. In this work, we apply these ideas to sign language recognition. We make three contributions.-First, we release SignCorpus, a large pretraining dataset on sign languages comprising about 4.6 K hours of signing data across 10 sign languages. SignCorpus is curated from sign language videos on the internet, filtered for data quality, and converted into sequences of pose keypoints thereby removing all personal identifiable information (PII).-Second, we release Sign2Vec, a graph-based model with 5.2 M parameters that is pretrained on SignCorpus. We envisage Sign2Vec as a multilingual large-scale pretrained model which can be fine-tuned for various sign recognition tasks across languages.-Third, we create MultiSign-ISLR--a multilingual and label-aligned dataset of sequences of pose keypoints from 11 labelled datasets across 7 sign languages, and MultiSign-FS--a new finger-spelling training and test set across 7 languages. On these datasets, we fine-tune Sign2Vec to create multilingual isolated sign recognition models. With experiments on multiple benchmarks, we show that pretraining and multilingual transfer are effective giving significant gains over state-of-the-art results. All datasets, models, and code has been made open-source via the OpenHands toolkit.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:PR6Y55bgFSsC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"Natural Language Generation (NLG) for non-English languages is hampered by the scarcity of datasets in these languages. We present the IndicNLG Benchmark, a collection of datasets for benchmarking NLG for 11 Indic languages. We focus on five diverse tasks, namely, biography generation using Wikipedia infoboxes, news headline generation, sentence summarization, paraphrase generation and, question generation. We describe the created datasets and use them to benchmark the performance of several monolingual and multilingual baselines that leverage pre-trained sequence-to-sequence models. Our results exhibit the strong performance of multilingual language-specific pre-trained models, and the utility of models trained on our dataset for other related NLG tasks. Our dataset creation methods can be easily applied to modest-resource languages as they involve simple steps such as scraping news articles and Wikipedia infoboxes, light cleaning, and pivoting through machine translation data. To the best of our knowledge, the IndicNLG Benchmark is the first NLG benchmark for Indic languages and the most diverse multilingual NLG dataset, with approximately 8M examples across 5 tasks and 11 languages. The datasets and models will be publicly available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:1yQoGdGgb4wC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"Deep learning based text-to-speech (TTS) systems have been evolving rapidly with advances in model architectures, training methodologies, and generalization across speakers and languages. However, these advances have not been thoroughly investigated for Indian language speech synthesis. Such investigation is computationally expensive given the number and diversity of Indian languages, relatively lower resource availability, and the diverse set of advances in neural TTS that remain untested. In this paper, we evaluate the choice of acoustic models, vocoders, supplementary loss functions, training schedules, and speaker and language diversity for Dravidian and Indo-Aryan languages. Based on this, we identify monolingual models with FastPitch and HiFi-GAN V1, trained jointly on male and female speakers to perform the best. With this setup, we train and evaluate TTS models for 13 languages and find our models to significantly improve upon existing models in all languages as measured by mean opinion scores. We open-source all models on the Bhashini platform.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:LjlpjdlvIbIC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"Deep learning based text-to-speech (TTS) systems have been evolving rapidly with advances in model architectures, training methodologies, and generalization across speakers and languages. However, these advances have not been thoroughly investigated for Indian language speech synthesis. Such investigation is computationally expensive given the number and diversity of Indian languages, relatively lower resource availability, and the diverse set of advances in neural TTS that remain untested. In this paper, we evaluate the choice of acoustic models, vocoders, supplementary loss functions, training schedules, and speaker and language diversity for Dravidian and Indo-Aryan languages. Based on this, we identify monolingual models with FastPitch and HiFi-GAN V1, trained jointly on male and female speakers to perform the best. With this setup, we train and evaluate TTS models for 13 languages and find …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:ye4kPcJQO24C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"End-to-end (E2E) models have become the default choice for state-of-the-art speech recognition systems. Such models are trained on large amounts of labelled data, which are often not available for low-resource languages. Techniques such as self-supervised learning and transfer learning hold promise, but have not yet been effective in training accurate models. On the other hand, collecting labelled datasets on a diverse set of domains and speakers is very expensive. In this work, we demonstrate an inexpensive and effective alternative to these approaches by ``mining'' text and audio pairs for Indian languages from public sources, specifically from the public archives of All India Radio. As a key component, we adapt the Needleman-Wunsch algorithm to align sentences with corresponding audio segments given a long audio and a PDF of its transcript, while being robust to errors due to OCR, extraneous text, and non-transcribed speech. We thus create Shrutilipi, a dataset which contains over 6,400 hours of labelled audio across 12 Indian languages totalling to 4.95M sentences. On average, Shrutilipi results in a 2.3x increase over publicly available labelled data. We establish the quality of Shrutilipi with 21 human evaluators across the 12 languages. We also establish the diversity of Shrutilipi in terms of represented regions, speakers, and mentioned named entities. Significantly, we show that adding Shrutilipi to the training set of Wav2Vec models leads to an average decrease in WER of 5.8\% for 7 languages on the IndicSUPERB benchmark. For Hindi, which has the most benchmarks (7), the average WER falls from 18.8% to 13.5%. This …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:WqliGbK-hY8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"A cornerstone in AI research has been the creation and adoption of standardized training and test datasets to earmark the progress of state-of-the-art models. A particularly successful example is the GLUE dataset for training and evaluating Natural Language Understanding (NLU) models for English. The large body of research around self-supervised BERT-based language models revolved around performance improvements on NLU tasks in GLUE. To evaluate language models in other languages, several language-specific GLUE datasets were created. The area of speech language understanding (SLU) has followed a similar trajectory. The success of large self-supervised models such as wav2vec2 enable creation of speech models with relatively easy to access unlabelled data. These models can then be evaluated on SLU tasks, such as the SUPERB benchmark. In this work, we extend this to Indic languages by releasing the IndicSUPERB benchmark. Specifically, we make the following three contributions. (i) We collect Kathbath containing 1,684 hours of labelled speech data across 12 Indian languages from 1,218 contributors located in 203 districts in India. (ii) Using Kathbath, we create benchmarks across 6 speech tasks: Automatic Speech Recognition, Speaker Verification, Speaker Identification (mono/multi), Language Identification, Query By Example, and Keyword Spotting for 12 languages. (iii) On the released benchmarks, we train and evaluate different self-supervised models alongside a commonly used baseline FBANK. We show that language-specific fine-tuned models are more accurate than baseline on most of the tasks …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:eq2jaN3J8jMC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"End-to-end (E2E) models have become the default choice for state-of-the-art speech recognition systems. Such models are trained on large amounts of labelled data, which are often not available for low-resource languages. Techniques such as self-supervised learning and transfer learning hold promise, but have not yet been effective in training accurate models. On the other hand, collecting labelled datasets on a diverse set of domains and speakers is very expensive. In this work, we demonstrate an inexpensive and effective alternative to these approaches by``mining''text and audio pairs for Indian languages from public sources, specifically from the public archives of All India Radio. As a key component, we adapt the Needleman-Wunsch algorithm to align sentences with corresponding audio segments given a long audio and a PDF of its transcript, while being robust to errors due to OCR, extraneous text, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:5awf1xo2G04C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"Recent methods in speech and language technology pretrain very large models which are fine-tuned for specific tasks. However, the benefits of such large models are often limited to a few resource rich languages of the world. In this work, we make multiple contributions towards building ASR systems for low resource languages from the Indian subcontinent. First, we curate 17,000 hours of raw speech data for 40 Indian languages from a wide variety of domains including education, news, technology, and finance. Second, using this raw speech data we pretrain several variants of wav2vec style models for 40 Indian languages. Third, we analyze the pretrained models to find key features: codebook vectors of similar sounding phonemes are shared across languages, representations across layers are discriminative of the language family, and attention heads often pay attention within small local windows. Fourth, we fine-tune this model for downstream ASR for 9 languages and obtain state-of-the-art results on 3 public datasets, including on very low-resource languages such as Sinhala and Nepali. Our work establishes that multilingual pretraining is an effective strategy for building ASR systems for the linguistically diverse speakers of the Indian subcontinent.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:kRWSkSYxWN8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"We introduce Aksharantar, the largest publicly available transliteration dataset for 21 Indic languages containing 26 million transliteration pairs. We build this dataset by mining transliteration pairs from large monolingual and parallel corpora, as well as collecting transliterations from human annotators to ensure diversity of words and representation of low-resource languages. We introduce a new, large, diverse testset for Indic language transliteration containing 103k words pairs spanning 19 languages that enables fine-grained analysis of transliteration models. We train the IndicXlit model on the Aksharantar training set. IndicXlit is a single transformer-based multilingual transliteration model for roman to Indic script conversion supporting 21 Indic languages. It achieves state-of-the art results on the Dakshina testset, and establishes strong baselines on the Aksharantar testset released along with this work. All the datasets and models are publicly available at https://indicnlp.ai4bharat.org/aksharantar. We hope the availability of these large-scale, open resources will spur innovation for Indic language transliteration and downstream applications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:t6usbXjVLHcC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"Gesture typing is a method of typing words on a touch-based keyboard by creating a continuous trace passing through the relevant keys. This work is aimed at developing a keyboard that supports gesture typing in Indic languages. We begin by noting that when dealing with Indic languages, one needs to cater to two different sets of users: (i) users who prefer to type in the native Indic script (Devanagari, Bengali, etc.) and (ii) users who prefer to type in the English script but want the output transliterated into the native script. In both cases, we need a model that takes a trace as input and maps it to the intended word. To enable the development of these models, we create and release two datasets. First, we create a dataset containing keyboard traces for 193,658 words from 7 Indic languages. Second, we curate 104,412 English-Indic transliteration pairs from Wikidata across these languages. Using these datasets we build a model that performs path decoding, transliteration, and transliteration correction. Unlike prior approaches, our proposed model does not make co-character independence assumptions during decoding. The overall accuracy of our model across the 7 languages varies from 70-95%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:B3FOqHPlNUQC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"Self-attention heads are characteristic of Transformer models and have been well studied for interpretability and pruning. In this work, we demonstrate an altogether different utility of attention heads, namely for adversarial detection. Specifically, we propose a method to construct input-specific attention subnetworks (IAS) from which we extract three features to discriminate between authentic and adversarial inputs. The resultant detector significantly improves (by over 7.5%) the state-of-the-art adversarial detection accuracy for the BERT encoder on 10 NLU datasets with 11 different adversarial attack types. We also demonstrate that our method (a) is more accurate for larger models which are likely to have more spurious correlations and thus vulnerable to adversarial attack, and (b) performs well even with modest training sets of adversarial examples.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:XiVPGOgt02cC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"In recent years, it has been seen that deep neural networks are lacking robustness and are likely to break in case of adversarial perturbations in input data. Strong adversarial attacks are proposed by various authors for computer vision and Natural Language Processing (NLP). As a counter-effort, several defense mechanisms are also proposed to save these networks from failing. In contrast with image data, generating adversarial attacks and defending these models is not easy in NLP because of the discrete nature of the text data. However, numerous methods for adversarial defense are proposed of late, for different NLP tasks such as text classification, named entity recognition, natural language inferencing, etc. These methods are not just used for defending neural networks from adversarial attacks, but also used as a regularization mechanism during training, saving the model from overfitting. The proposed survey is an attempt to review different methods proposed for adversarial defenses in NLP in the recent past by proposing a novel taxonomy. This survey also highlights the fragility of the advanced deep neural networks in NLP and the challenges in defending them.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:bnK-pcrLprsC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"Recent studies have shown the advantages of evaluating NLG systems using pairwise comparisons as opposed to direct assessment. Given systems, a naive approach for identifying the top-ranked system would be to uniformly obtain pairwise comparisons from all pairs of systems. However, this can be very expensive as the number of human annotations required would grow quadratically with . In this work, we introduce Active Evaluation, a framework to efficiently identify the top-ranked system by actively choosing system pairs for comparison using dueling bandit algorithms. We perform extensive experiments with 13 dueling bandits algorithms on 13 NLG evaluation datasets spanning 5 tasks and show that the number of human annotations can be reduced by 80%. To further reduce the number of human annotations, we propose model-based dueling bandit algorithms which combine automatic evaluation metrics with human evaluations. Specifically, we eliminate sub-optimal systems even before the human annotation process and perform human evaluations only on test examples where the automatic metric is highly uncertain. This reduces the number of human annotations required further by 89%. In effect, we show that identifying the top-ranked system requires only a few hundred human annotations, which grow linearly with . Lastly, we provide practical recommendations and best practices to identify the top-ranked system efficiently. Our code has been made publicly available at https://github.com/akashkm99/duelnlg",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:5ugPr518TE4C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"In this paper, we present the IndicNLG suite, a collection of datasets for benchmarking Natural Language Generation (NLG) for 11 Indic languages. We focus on five diverse tasks, namely, biography generation using Wikipedia infoboxes (WikiBio), news headline generation, sentence summarization, question generation and paraphrase generation. We describe the process of creating the datasets and present statistics of the dataset, following which we train and report a variety of strong monolingual and multilingual baselines that leverage pre-trained sequence-to-sequence models and analyze the results to understand the challenges involved in Indic language NLG. To the best of our knowledge, this is the first NLG dataset for Indic languages and also the largest multilingual NLG dataset. Our methods can also be easily applied to modest-resource languages with reasonable monolingual and parallel corpora, as well as corpora containing structured data like Wikipedia. We hope this dataset spurs research in NLG on diverse languages and tasks, particularly for Indic languages. The datasets and models are publicly available at https://indicnlp.ai4bharat.org/indicnlg-suite.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:wbdj-CoPYUoC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"In the past few years, it has become increasingly evident that deep neural networks are not resilient enough to withstand adversarial perturbations in input data, leaving them vulnerable to attack. Various authors have proposed strong adversarial attacks for computer vision and Natural Language Processing (NLP) tasks. As a response, many defense mechanisms have also been proposed to prevent these networks from failing. The significance of defending neural networks against adversarial attacks lies in ensuring that the model’s predictions remain unchanged even if the input data is perturbed. Several methods for adversarial defense in NLP have been proposed, catering to different NLP tasks such as text classification, named entity recognition, and natural language inference. Some of these methods not only defend neural networks against adversarial attacks but also act as a regularization mechanism during …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:HE397vMXCloC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"In the last few years, a large number of automatic evaluation metrics have been proposed for evaluating Natural Language Generation (NLG) systems. The rapid development and adoption of such automatic evaluation metrics in a relatively short time has created the need for a survey of these metrics. In this survey, we (i) highlight the challenges in automatically evaluating NLG systems, (ii) propose a coherent taxonomy for organising existing evaluation metrics, (iii) briefly describe different existing metrics, and finally (iv) discuss studies criticising the use of automatic evaluation metrics. We then conclude the article highlighting promising future directions of research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:738O_yMBCRsC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2022,"Many real-world applications deal with data that have an underlying graph structure associated with it. To perform downstream analysis on such data, it is crucial to capture relational information of nodes over their expanded neighborhood efficiently. Herein, we focus on the problem of Collective Classification (CC) for assigning labels to unlabeled nodes. Most deep learning models for CC heavily rely on differentiable variants of Weisfeiler-Lehman (WL) kernels. However, due to current computing architectures' limitations, WL kernels and their differentiable variants are limited in their ability to capture useful relational information only over a small expanded neighborhood of a node. To address this concern, we propose the framework, I-HOP, that couples differentiable kernels with an iterative inference mechanism to scale to larger neighborhoods. I-HOP scales differentiable graph kernels to capture and summarize …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:J-pR_7NvFogC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"AI technologies for Natural Languages have made tremendous progress recently. However, commensurate progress has not been made on Sign Languages, in particular, in recognizing signs as individual words or as complete sentences. We introduce OpenHands, a library where we take four key ideas from the NLP community for low-resource languages and apply them to sign languages for word-level recognition. First, we propose using pose extracted through pretrained models as the standard modality of data to reduce training time and enable efficient inference, and we release standardized pose datasets for 6 different sign languages - American, Argentinian, Chinese, Greek, Indian, and Turkish. Second, we train and release checkpoints of 4 pose-based isolated sign language recognition models across all 6 languages, providing baselines and ready checkpoints for deployment. Third, to address the lack of labelled data, we propose self-supervised pretraining on unlabelled data. We curate and release the largest pose-based pretraining dataset on Indian Sign Language (Indian-SL). Fourth, we compare different pretraining strategies and for the first time establish that pretraining is effective for sign language recognition by demonstrating (a) improved fine-tuning performance especially in low-resource settings, and (b) high crosslingual transfer from Indian-SL to few other sign languages. We open-source all models and datasets in OpenHands with a hope that it makes research in sign languages more accessible, available here at https://github.com/AI4Bharat/OpenHands .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:q3oQSFYPqjQC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"As neural-network-based QA models become deeper and more complex, there is a demand for robust frameworks which can access a model's rationale for its prediction. Current techniques that provide insights on a model's working are either dependent on adversarial datasets or are proposing models with explicit explanation generation components. These techniques are time-consuming and challenging to extend to existing models and new datasets. In this work, we use `Integrated Gradients' to extract rationale for existing state-of-the-art models in the task of Reading Comprehension based Question Answering (RCQA). On detailed analysis and comparison with collected human rationales, we find that though ~40-80% words of extracted rationale coincide with the human rationale (precision), only 6-19% of human rationale is present in the extracted rationale (recall).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:mvPsJ3kp5DgC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"Large multilingual models, such as mBERT, have shown promise in crosslingual transfer. In this work, we employ pruning to quantify the robustness and interpret layer-wise importance of mBERT. On four GLUE tasks, the relative drops in accuracy due to pruning have almost identical results on mBERT and BERT suggesting that the reduced attention capacity of the multilingual models does not affect robustness to pruning. For the crosslingual task XNLI, we report higher drops in accuracy with pruning indicating lower robustness in crosslingual transfer. Also, the importance of the encoder layers sensitively depends on the language family and the pre-training corpus size. The top layers, which are relatively more influenced by fine-tuning, encode important information for languages similar to English (SVO) while the bottom layers, which are relatively less influenced by fine-tuning, are particularly important for agglutinative and low-resource languages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:BrmTIyaxlBUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"Natural Language Generation (NLG) evaluation is a multifaceted task requiring assessment of multiple desirable criteria, e.g., fluency, coherency, coverage, relevance, adequacy, overall quality, etc. Across existing datasets for 6 NLG tasks, we observe that the human evaluation scores on these multiple criteria are often not correlated. For example, there is a very low correlation between human scores on fluency and data coverage for the task of structured data to text generation. This suggests that the current recipe of proposing new automatic evaluation metrics for NLG by showing that they correlate well with scores assigned by humans for a single criteria (overall quality) alone is inadequate. Indeed, our extensive study involving 25 automatic evaluation metrics across 6 different tasks and 18 different evaluation criteria shows that there is no single metric which correlates well with human scores on all desirable criteria, for most NLG tasks. Given this situation, we propose CheckLists for better design and evaluation of automatic metrics. We design templates which target a specific criteria (e.g., coverage) and perturb the output such that the quality gets affected only along this specific criteria (e.g., the coverage drops). We show that existing evaluation metrics are not robust against even such simple perturbations and disagree with scores assigned by humans to the perturbed output. The proposed templates thus allow for a fine-grained assessment of automatic evaluation metrics exposing their limitations and will facilitate better design, analysis and evaluation of such metrics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:eflP2zaiRacC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"In this paper, we study pre-trained sequence-to-sequence models for a group of related languages, with a focus on Indic languages. We present IndicBART, a multilingual, sequence-to-sequence pre-trained model focusing on 11 Indic languages and English. IndicBART utilizes the orthographic similarity between Indic scripts to improve transfer learning between similar Indic languages. We evaluate IndicBART on two NLG tasks: Neural Machine Translation (NMT) and extreme summarization. Our experiments on NMT and extreme summarization show that a model specific to related languages like IndicBART is competitive with large pre-trained models like mBART50 despite being significantly smaller. It also performs well on very low-resource translation scenarios where languages are not included in pre-training or fine-tuning. Script sharing, multilingual training, and better utilization of limited model capacity contribute to the good performance of the compact IndicBART model.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:eJXPG6dFmWUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"Recent advancements in the realization of highly efficient shot noise-limited direct detectors now enable atomically-resolved in situ TEM image time-series to be acquired with temporal resolutions in the millisecond (ms) regime [1]. Many catalysts exhibit turnover frequencies on the order of 10-1–102 sec-1, so the opportunity to visualize atomic behavior with high time resolution holds much promise for understanding the chemical transformation processes occurring on catalyst surfaces. Unfortunately, acquiring in situ TEM time-series with~ ms temporal resolution necessarily produces datasets severely degraded by shot noise [2]. For typical atomicresolution in situ TEM imaging conditions, at high frame rates the average dose in each frame can be< 1 eper pixel. Following Poisson statistics, counted images with an average dose< 1 e-per pixel necessarily have a signal-to-noise ratio less than unity, and consequently …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:D_sINldO8mEC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"Multilingual Language Models (\MLLMs) such as mBERT, XLM, XLM-R, \textit{etc.} have emerged as a viable option for bringing the power of pretraining to a large number of languages. Given their success in zero-shot transfer learning, there has emerged a large body of work in (i) building bigger \MLLMs~covering a large number of languages (ii) creating exhaustive benchmarks covering a wider variety of tasks and languages for evaluating \MLLMs~ (iii) analysing the performance of \MLLMs~on monolingual, zero-shot cross-lingual and bilingual tasks (iv) understanding the universal language patterns (if any) learnt by \MLLMs~ and (v) augmenting the (often) limited capacity of \MLLMs~ to improve their performance on seen or even unseen languages. In this survey, we review the existing literature covering the above broad areas of research pertaining to \MLLMs. Based on our survey, we recommend some promising directions of future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:fQNAKQ3IYiAC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"The advent of Deep Learning and the availability of large scale datasets has accelerated research on Natural Language Generation with a focus on newer tasks and better models. With such rapid progress, it is vital to assess the extent of scientific progress made and identify the areas/components that need improvement. To accomplish this in an automatic and reliable manner, the NLP community has actively pursued the development of automatic evaluation metrics. Especially in the last few years, there has been an increasing focus on evaluation metrics, with several criticisms of existing metrics and proposals for several new metrics. This tutorial presents the evolution of automatic evaluation metrics to their current state along with the emerging trends in this field by specifically addressing the following questions:(i) What makes NLG evaluation challenging?(ii) Why do we need automatic evaluation metrics?(iii) What are the existing automatic evaluation metrics and how can they be organised in a coherent taxonomy?(iv) What are the criticisms and shortcomings of existing metrics?(v) What are the possible future directions of research?",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:LPZeul_q3PIC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"Multi-headed attention heads are a mainstay in transformer-based models. Different methods have been proposed to classify the role of each attention head based on the relations between tokens which have high pair-wise attention. These roles include syntactic (tokens with some syntactic relation), local (nearby tokens), block (tokens in the same sentence) and delimiter (the special [CLS],[SEP] tokens). There are two main challenges with existing methods for classification:(a) there are no standard scores across studies or across functional roles, and (b) these scores are often average quantities measured across sentences without capturing statistical significance. In this work, we formalize a simple yet effective score that generalizes to all the roles of attention heads and employs hypothesis testing on this score for robust inference. This provides us the right lens to systematically analyze attention heads and confidently comment on many commonly posed questions on analyzing the BERT model. In particular, we comment on the co-location of multiple functional roles in the same attention head, the distribution of attention heads across layers, and effect of fine-tuning for specific NLP tasks on these functional roles. The code is made publicly available at https://github. com/iitmnlp/heads-hypothesis",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:8AbLer7MMksC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"Are existing object detection methods adequate for detecting text and visual elements in scientific plots which are arguably different than the objects found in natural images? To answer this question, we train and compare the accuracy of Fast/Faster R-CNN, SSD, YOLO and RetinaNet on the PlotQA dataset with over 220,000 scientific plots. At the standard IOU setting of 0.5, most networks perform well with mAP scores greater than 80% in detecting the relatively simple objects in plots. However, the performance drops drastically when evaluated at a stricter IOU of 0.9 with the best model giving a mAP of 35.70%. Note that such a stricter evaluation is essential when dealing with scientific plots where even minor localisation errors can lead to large errors in downstream numerical inferences. Given this poor performance, we propose minor modifications to existing models by combining ideas from different object detection networks. While this significantly improves the performance, there are still two main issues:(i) performance on text objects which are essential for reasoning is very poor, and (ii) inference time is unacceptably large considering the simplicity of plots. To solve this open problem, we make a series of contributions:(a) an efficient region proposal method based on Laplacian edge detectors,(b) a feature representation of region proposals that includes neighbouring information,(c) a linking component to join multiple region proposals for detecting longer textual objects, and (d) a custom loss function that combines a smooth L1-loss with an IOU-based loss. Combining these ideas, our final model is very accurate at extreme IOU values …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:Tiz5es2fbqcC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2021,"Deep convolutional neural networks (CNNs) for video denoising are typically trained with supervision, assuming the availability of clean videos. However, in many applications, such as microscopy, noiseless videos are not available. To address this, we propose an Unsupervised Deep Video Denoiser (UDVD), a CNN architecture designed to be trained exclusively with noisy data. The performance of UDVD is comparable to the supervised state-of-the-art, even when trained only on a single short noisy video. We demonstrate the promise of our approach in real-world imaging applications by denoising raw video, fluorescence-microscopy and electron-microscopy data. In contrast to many current approaches to video denoising, UDVD does not require explicit motion compensation. This is advantageous because motion compensation is computationally expensive, and can be unreliable when the input data are noisy. A gradient-based analysis reveals that UDVD automatically tracks the motion of objects in the input noisy videos. Thus, the network learns to perform implicit motion compensation, even though it is only trained for denoising.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:4fKUyHm3Qg0C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"Deep convolutional neural networks (CNNs) for video denoising are typically trained with supervision, assuming the availability of clean videos. However, in many applications, such as microscopy, noiseless videos are not available. To address this, we propose an Unsupervised Deep Video Denoiser (UDVD), a CNN architecture designed to be trained exclusively with noisy data. The performance of UDVD is comparable to the supervised state-of-the-art, even when trained only on a single short noisy video. We demonstrate the promise of our approach in real-world imaging applications by denoising raw video, fluorescence-microscopy and electron-microscopy data. In contrast to many current approaches to video denoising, UDVD does not require explicit motion compensation. This is advantageous because motion compensation is computationally expensive, and can be unreliable when the input data are noisy …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:sSrBHYA8nusC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"Given the success of Transformer-based models, two directions of study have emerged: interpreting role of individual attention heads and down-sizing the models for efficiency. Our work straddles these two streams: We analyse the importance of basing pruning strategies on the interpreted role of the attention heads. We evaluate this on Transformer and BERT models on multiple NLP tasks. Firstly, we find that a large fraction of the attention heads can be randomly pruned with limited effect on accuracy. Secondly, for Transformers, we find no advantage in pruning attention heads identified to be important based on existing studies that relate importance to the location of a head. On the BERT model too we find no preference for top or bottom layers, though the latter are reported to have higher importance. However, strategies that avoid pruning middle layers and consecutive layers perform better. Finally, during fine-tuning the compensation for pruned attention heads is roughly equally distributed across the un-pruned heads. Our results thus suggest that interpretation of attention heads does not strongly inform pruning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:tS2w5q8j5-wC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"In this paper, we introduce NLP resources for 11 major Indian languages from two major language families. These resources include:(a) large-scale sentence-level monolingual corpora,(b) pre-trained word embeddings,(c) pre-trained language models, and (d) multiple NLU evaluation datasets (IndicGLUE benchmark). The monolingual corpora contains a total of 8.8 billion tokens across all 11 languages and Indian English, primarily sourced from news crawls. The word embeddings are based on FastText, hence suitable for handling morphological complexity of Indian languages. The pre-trained language models are based on the compact ALBERT model. Lastly, we compile the (IndicGLUE benchmark for Indian language NLU. To this end, we create datasets for the following tasks: Article Genre Classification, Headline Prediction, Wikipedia Section-Title Prediction, Cloze-style Multiple choice QA, Winograd NLI and COPA. We also include publicly available datasets for some Indic languages for tasks like Named Entity Recognition, Cross-lingual Sentence Retrieval, Paraphrase detection, etc. Our embeddings are competitive or better than existing pre-trained embeddings on multiple tasks. We hope that the availability of the dataset will accelerate Indic NLP research which has the potential to impact more than a billion people. It can also help the community in evaluating advances in NLP over a more diverse pool of languages. The data and models are available at https://indicnlp. ai4bharat. org.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:K3LRdlH-MEoC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"BERT and its variants have achieved state-of-the-art performance in various NLP tasks. Since then, various works have been proposed to analyze the linguistic information being captured in BERT. However, the current works do not provide an insight into how BERT is able to achieve near human-level performance on the task of Reading Comprehension based Question Answering. In this work, we attempt to interpret BERT for RCQA. Since BERT layers do not have predefined roles, we define a layer's role or functionality using Integrated Gradients. Based on the defined roles, we perform a preliminary analysis across all layers. We observed that the initial layers focus on query-passage interaction, whereas later layers focus more on contextual understanding and enhancing the answer prediction. Specifically for quantifier questions (how much/how many), we notice that BERT focuses on confusing words (i.e., on other numerical quantities in the passage) in the later layers, but still manages to predict the answer correctly. The fine-tuning and analysis scripts will be publicly available at https://github.com/iitmnlp/BERT-Analysis-RCQA .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:vRqMK49ujn8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"Indian Sign Language (ISL) is a complete language with its own grammar, syntax, vocabulary and several unique linguistic attributes. It is used by over 5 million deaf people in India. Currently, there is no publicly available dataset on ISL to evaluate Sign Language Recognition (SLR) approaches. In this work, we present the Indian Lexicon Sign Language Dataset - INCLUDE - an ISL dataset that contains 0.27 million frames across 4,287 videos over 263 word signs from 15 different word categories. INCLUDE is recorded with the help of experienced signers to provide close resemblance to natural conditions. A subset of 50 word signs is chosen across word categories to define INCLUDE-50 for rapid evaluation of SLR meth- ods with hyperparameter tuning. As the first large scale study of SLR on ISL, we evaluate several deep neural networks combining different methods for augmentation, feature extraction …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:08ZZubdj9fEC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"Recent advances in Generative Adversarial Networks (GANs) have resulted in its widespread applications to multiple domains. A recent model, IRGAN, applies this framework to Information Retrieval (IR) and has gained significant attention over the last few years. In this focused work, we critically analyze multiple components of IRGAN, while providing experimental and theoretical evidence of some of its shortcomings. Specifically, we identify issues with the constant baseline term in the policy gradients optimization and show that the generator harms IRGAN's performance. Motivated by our findings, we propose two models influenced by self-contrastive estimation and co-training which outperform IRGAN on two out of the three tasks considered.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:tOudhMTPpwUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"The self-attention module is a key component of Transformer-based models, wherein each token pays attention to every other token. Recent studies have shown that these heads exhibit syntactic, semantic, or local behaviour. Some studies have also identified promise in restricting this attention to be local, i.e., a token attending to other tokens only in a small neighbourhood around it. However, no conclusive evidence exists that such local attention alone is sufficient to achieve high accuracy on multiple NLP tasks. In this work, we systematically analyse the role of locality information in learnt models and contrast it with the role of syntactic information. More specifically, we first do a sensitivity analysis and show that, at every layer, the representation of a token is much more sensitive to tokens in a small neighborhood around it than to tokens which are syntactically related to it. We then define an attention bias metric to determine whether a head pays more attention to local tokens or to syntactically related tokens. We show that a larger fraction of heads have a locality bias as compared to a syntactic bias. Having established the importance of local attention heads, we train and evaluate models where varying fractions of the attention heads are constrained to be local. Such models would be more efficient as they would have fewer computations in the attention layer. We evaluate these models on 4 GLUE datasets (QQP, SST-2, MRPC, QNLI) and 2 MT datasets (En-De, En-Ru) and clearly demonstrate that such constrained models have comparable performance to the unconstrained models. Through this systematic evaluation we establish that attention in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:WbkHhVStYXYC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"We consider the task of generating dialogue responses from background knowledge comprising of domain specific resources. Specifically, given a conversation around a movie, the task is to generate the next response based on background knowledge about the movie such as the plot, review, Reddit comments etc. This requires capturing structural, sequential and semantic information from the conversation context and the background resources. This is a new task and has not received much attention from the community. We propose a new architecture that uses the ability of BERT to capture deep contextualized representations in conjunction with explicit structure and sequence information. More specifically, we use (i) Graph Convolutional Networks (GCNs) to capture structural information, (ii) LSTMs to capture sequential information and (iii) BERT for the deep contextualized representations that capture semantic information. We analyze the proposed architecture extensively. To this end, we propose a plug-and-play Semantics-Sequences-Structures (SSS) framework which allows us to effectively combine such linguistic information. Through a series of experiments we make some interesting observations. First, we observe that the popular adaptation of the GCN model for NLP tasks where structural information (GCNs) was added on top of sequential information (LSTMs) performs poorly on our task. This leads us to explore interesting ways of combining semantic and structural information to improve the performance. Second, we observe that while BERT already outperforms other deep contextualized representations such as ELMo, it still …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:XiSMed-E-HIC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"We present the IndicNLP corpus, a large-scale, general-domain corpus containing 2.7 billion words for 10 Indian languages from two language families. We share pre-trained word embeddings trained on these corpora. We create news article category classification datasets for 9 languages to evaluate the embeddings. We show that the IndicNLP embeddings significantly outperform publicly available pre-trained embedding on multiple evaluation tasks. We hope that the availability of the corpus will accelerate Indic NLP research. The resources are available at https://github.com/ai4bharat-indicnlp/indicnlp_corpus.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:u9iWguZQMMsC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"Recent studies on interpretability of attention distributions have led to notions of faithful and plausible explanations for a model's predictions. Attention distributions can be considered a faithful explanation if a higher attention weight implies a greater impact on the model's prediction. They can be considered a plausible explanation if they provide a human-understandable justification for the model's predictions. In this work, we first explain why current attention mechanisms in LSTM based encoders can neither provide a faithful nor a plausible explanation of the model's predictions. We observe that in LSTM based encoders the hidden representations at different time-steps are very similar to each other (high conicity) and attention weights in these situations do not carry much meaning because even a random permutation of the attention weights does not affect the model's predictions. Based on experiments on a wide variety of tasks and datasets, we observe attention distributions often attribute the model's predictions to unimportant words such as punctuation and fail to offer a plausible explanation for the predictions. To make attention mechanisms more faithful and plausible, we propose a modified LSTM cell with a diversity-driven training objective that ensures that the hidden representations learned at different time steps are diverse. We show that the resulting attention distributions offer more transparency as they (i) provide a more precise importance ranking of the hidden states (ii) are better indicative of words important for the model's predictions (iii) correlate better with gradient-based attribution methods. Human evaluations indicate that the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:p2g8aNsByqUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"A method comprising using at least one hardware processor for: receiving a topic under consideration (TUC) and a set of claims referring to the TUC; identifying semantic similarity relations between claims of the set of claims; clustering the claims into a plurality of claim clusters based on the identified semantic similarity relations, wherein said claim clusters represent semantically different claims of the set of claims; and generating a list of non-redundant claims comprising said semantically different claims.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:hFOr9nPyWt4C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"There is an increasing focus on model-based dialog evaluation metrics such as ADEM, RUBER, and the more recent BERT-based metrics. These models aim to assign a high score to all relevant responses and a low score to all irrelevant responses. Ideally, such models should be trained using multiple relevant and irrelevant responses for any given context. However, no such data is publicly available, and hence existing models are usually trained using a single relevant response and multiple randomly selected responses from other contexts (random negatives). To allow for better training and robust evaluation of model-based metrics, we introduce the DailyDialog++ dataset, consisting of (i) five relevant responses for each context and (ii) five adversarially crafted irrelevant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:l7t_Zn2s7bgC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2020,"Existing synthetic datasets (FigureQA, DVQA) for reasoning over plots do not contain variability in data labels, real-valued data, or complex reasoning questions. Consequently, proposed models for these datasets do not fully address the challenge of reasoning over plots. In particular, they assume that the answer comes either from a small fixed size vocabulary or from a bounding box within the image. However, in practice, this is an unrealistic assumption because many questions require reasoning and thus have real-valued answers which appear neither in a small fixed size vocabulary nor in the image. In this work, we aim to bridge this gap between existing datasets and real-world plots. Specifically, we propose PlotQA with 28.9 million question-answer pairs over 224,377 plots on data from real-world sources and questions based on crowd-sourced question templates. Further, 80.76% of the out-of-vocabulary (OOV) questions in PlotQA have answers that are not in a fixed vocabulary. Analysis of existing models on PlotQA reveals that they cannot deal with OOV questions: their overall accuracy on our dataset is in single digits. This is not surprising given that these models were not designed for such questions. As a step towards a more holistic model which can address fixed vocabulary as well as OOV questions, we propose a hybrid approach: Specific questions are answered by choosing the answer from a fixed vocabulary or by extracting it from a predicted bounding box in the plot, while other questions are answered with a table question-answering engine which is fed with a structured table generated by detecting visual elements from the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:OU6Ihb5iCvQC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"With the prolification of multimodal interaction in various domains, recently there has been much interest in text based image retrieval in the computer vision community. However most of the state of the art techniques model this problem in a purely neural way, which makes it difficult to incorporate pragmatic strategies in searching a large scale catalog especially when the search requirements are insufficient and the model needs to resort to an interactive retrieval process through multiple iterations of question-answering. Motivated by this, we propose a neural-symbolic approach for a one-shot retrieval of images from a large scale catalog, given the caption description. To facilitate this, we represent the catalog and caption as scene-graphs and model the retrieval task as a learnable graph matching problem, trained end-to-end with a REINFORCE algorithm. Further, we briefly describe an extension of this pipeline to an iterative retrieval framework, based on interactive questioning and answering.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:KxtntwgDAa4C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"In this work, we focus on the task of Automatic Question Generation (AQG) where given a passage and an answer the task is to generate the corresponding question. It is desired that the generated question should be (i) grammatically correct (ii) answerable from the passage and (iii) specific to the given answer. An analysis of existing AQG models shows that they produce questions which do not adhere to one or more of {the above-mentioned qualities}. In particular, the generated questions look like an incomplete draft of the desired question with a clear scope for refinement. {To alleviate this shortcoming}, we propose a method which tries to mimic the human process of generating questions by first creating an initial draft and then refining it. More specifically, we propose Refine Network (RefNet) which contains two decoders. The second decoder uses a dual attention network which pays attention to both (i) the original passage and (ii) the question (initial draft) generated by the first decoder. In effect, it refines the question generated by the first decoder, thereby making it more correct and complete. We evaluate RefNet on three datasets, \textit{viz.}, SQuAD, HOTPOT-QA, and DROP, and show that it outperforms existing state-of-the-art methods by 7-16\% on all of these datasets. Lastly, we show that we can improve the quality of the second decoder on specific metrics, such as, fluency and answerability by explicitly rewarding revisions that improve on the corresponding metric during training. The code has been made publicly available \footnote{https://github.com/PrekshaNema25/RefNet-QG}",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:P5F9QuxV20EC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"Domain-specific goal-oriented dialogue systems typically require modeling three types of inputs, namely, (i) the knowledge-base associated with the domain, (ii) the history of the conversation, which is a sequence of utterances, and (iii) the current utterance for which the response needs to be generated. While modeling these inputs, current state-of-the-art models such as Mem2Seq typically ignore the rich structure inherent in the knowledge graph and the sentences in the conversation context. Inspired by the recent success of structure-aware Graph Convolutional Networks (GCNs) for various NLP tasks such as machine translation, semantic role labeling, and document dating, we propose a memory-augmented GCN for goal-oriented dialogues. Our model exploits (i) the entity relation graph in a knowledge-base and (ii) the dependency graph associated with an utterance to compute richer representations for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:D03iK_w7-QYC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem. ADEM (Lowe et al. 2017) formulated the automatic evaluation of dialogue systems as a learning problem and showed that such a model was able to predict responses which correlate significantly with human judgements, both at utterance and system level. Their system was shown to have beaten word-overlap metrics such as BLEU with large margins. We start with the question of whether an adversary can game the ADEM model. We design a battery of targeted attacks at the neural network based ADEM evaluation system and show that automatic evaluation of dialogue systems still has a long way to go. ADEM can get confused with a variation as simple as reversing the word order in the text! We report experiments on several such adversarial scenarios that draw out counterintuitive scores on the dialogue responses. We take a systematic look at the scoring function proposed by ADEM and connect it to linear system theory to predict the shortcomings evident in the system. We also devise an attack that can fool such a system to rate a response generation system as favorable. Finally, we allude to future research directions of using the adversarial attacks to design a truly automated dialogue evaluation system.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:EUQCXRtRnyEC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"Deep Learning has managed to push boundaries in a wide variety of tasks. One area of interest is to tackle problems in reasoning and understanding, with an aim to emulate human intelligence. In this work, we describe a deep learning model that addresses the reasoning task of question-answering on categorical plots. We introduce a novel architecture FigureNet, that learns to identify various plot elements, quantify the represented values and determine a relative ordering of these statistical values. We test our model on the FigureQA dataset which provides images and accompanying questions for scientific plots like bar graphs and pie charts, augmented with rich annotations. Our approach outperforms the state-of-the-art Relation Networks baseline by approximately 7% on this dataset, with a training time that is over an order of magnitude lesser.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:CHSYGLWDkRkC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"Recent advances in Question Answering have lead to the development of very complex models which compute rich representations for query and documents by capturing all pairwise interactions between query and document words. This makes these models expensive in space and time, and in practice one has to restrict the length of the documents that can be fed to these models. Such models have also been recently employed for the task of predicting dialog responses from available background documents (eg, Holl-E dataset). However, here the documents are longer, thereby rendering these complex models infeasible except in select restricted settings. In order to overcome this, we use standard simple models which do not capture all pairwise interactions, but learn to emulate certain characteristics of a complex teacher network. Specifically, we first investigate the conicity of representations learned by a complex model and observe that it is significantly lower than that of simpler models. Based on this insight, we modify the simple architecture to mimic this characteristic. We go further by using knowledge distillation approaches, where the simple model acts as a student and learns to match the output from the complex teacher network. We experiment with the Holl-E dialog data set and show that by mimicking characteristics and matching outputs from a teacher, even a simple network can give improved performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:NhqRSupF_l8C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"When humans learn to perform a difficult task (say, reading comprehension (RC) over longer passages), it is typically the case that their performance improves significantly on an easier version of this task (say, RC over shorter passages). Ideally, we would want an intelligent agent to also exhibit such a behavior. However, on experimenting with state of the art RC models using the standard RACE dataset, we observe that this is not true. Specifically, we see counter-intuitive results wherein even when we show frustratingly easy examples to the model at test time, there is hardly any improvement in its performance. We refer to this as non-adversarial evaluation as opposed to adversarial evaluation. Such non-adversarial examples allow us to assess the utility of specialized neural components. For example, we show that even for easy examples where the answer is clearly embedded in the passage, the neural components designed for paying attention to relevant portions of the passage fail to serve their intended purpose. We believe that the non-adversarial dataset created as a part of this work would complement the research on adversarial evaluation and give a more realistic assessment of the ability of RC models. All the datasets and codes developed as a part of this work will be made publicly available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:abG-DnoFyZgC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"The task of Reading Comprehension with Multiple Choice Questions, requires a human (or machine) to read a given passage, question pair and select one of the n given options. The current state of the art model for this task first computes a question-aware representation for the passage and then selects the option which has the maximum similarity with this representation. However, when humans perform this task they do not just focus on option selection but use a combination of elimination and selection. Specifically, a human would first try to eliminate the most irrelevant option and then read the passage again in the light of this new information (and perhaps ignore portions corresponding to the eliminated option). This process could be repeated multiple times till the reader is finally ready to select the correct option. We propose ElimiNet, a neural network-based model which tries to mimic this process. Specifically, it has gates which decide whether an option can be eliminated given the passage, question pair and if so it tries to make the passage representation orthogonal to this eliminated option (akin to ignoring portions of the passage corresponding to the eliminated option). The model makes multiple rounds of partial elimination to refine the passage representation and finally uses a selection module to pick the best option. We evaluate our model on the recently released large scale RACE dataset and show that it outperforms the current state of the art model on 7 out of the question types in this dataset. Further, we show that taking an ensemble of our elimination-selection based method with a selection based method gives us an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:rO6llkc54NcC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"Recently, there has been a lot of work on pruning filters from deep convolutional neural networks (CNNs) with the intention of reducing computations. The key idea is to rank the filters based on a certain criterion (say, -norm, average percentage of zeros, etc.) and retain only the top-ranked filters. Once the low-scoring filters are pruned away, the remainder of the network is fine-tuned and is shown to give performance comparable to the original unpruned network. In this work, we report experiments which suggest that the comparable performance of the pruned network is not due to the specific criterion chosen, but due to the inherent plasticity of deep neural networks which allows them to recover from the loss of pruned filters once the rest of the filters are fine-tuned. Specifically, we show counterintuitive results wherein by randomly pruning 25–50% filters from deep CNNs we are able to obtain the same …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:pyW8ca7W8N0C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:1sJd4Hv_s6UC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"Recently, there has been a lot of interest in building compact models for video classification which have a small memory footprint (< 1 GB). While these models are compact, they typically operate by repeated application of a small weight matrix to all the frames in a video. For example, recurrent neural network based methods compute a hidden state for every frame of the video using a recurrent weight matrix. Similarly, cluster-and-aggregate based methods such as NetVLAD have a learnable clustering matrix which is used to assign soft-clusters to every frame in the video. Since these models look at every frame in the video, the number of floating point operations (FLOPs) is still large even though the memory footprint is small. In this work, we focus on building compute-efficient video classification models which process fewer frames and hence have less number of FLOPs. Similar to memory efficient models, we use the idea of distillation albeit in a different setting. Specifically, in our case, a compute-heavy teacher which looks at all the frames in the video is used to train a compute-efficient student which looks at only a small fraction of frames in the video. This is in contrast to a typical memory efficient Teacher-Student setting, wherein both the teacher and the student look at all the frames in the video but the student has fewer parameters. Our work thus complements the research on memory efficient video classification. We do an extensive evaluation with three types of models for video classification, viz.,(i) recurrent models (ii) cluster-and-aggregate models and (iii) memory-efficient cluster-and-aggregate models and show that in each of these cases …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:b0M2c_1WBrUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2019,"Recent advances in Generative Adversarial Networks facilitated by improvements to the framework and successful application to various problems has resulted in extensions to multiple domains. IRGAN attempts to leverage the framework for Information-Retrieval (IR), a task that can be described as modeling the correct conditional probability distribution p(d|q) over the documents (d), given the query (q). The work that proposes IRGAN claims that optimizing their minimax loss function will result in a generator which can learn the distribution, but their setup and baseline term steer the model away from an exact adversarial formulation, and this work attempts to point out certain inaccuracies in their formulation. Analyzing their loss curves gives insight into possible mistakes in the loss functions and better performance can be obtained by using the co-training like setup we propose, where two models are trained in a co-operative rather than an adversarial fashion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:f2IySw72cVMC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Existing supervised solutions for Named Entity Recognition (NER) typically rely on a large annotated corpus. Collecting large amounts of NER annotated corpus is time-consuming and requires considerable human effort. However, collecting small amounts of annotated corpus for any language is feasible, but the performance degrades due to data sparsity. We address the data sparsity by borrowing features from the data of a closely related language. We use hierarchical neural networks to train a supervised NER system. The feature borrowing from a closely related language happens via the shared layers of the network. The neural network is trained on the combined dataset of the low-resource language and a closely related language, also termed Multilingual Learning. Unlike existing systems, we share all layers of the network between the two languages. We apply multilingual learning for NER in Indian …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:a0OBvERweLwC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Existing dialog datasets contain a sequence of utterances and responses without any explicit background knowledge associated with them. This has resulted in the development of models which treat conversation as a sequence-to-sequence generation task i.e, given a sequence of utterances generate the response sequence). This is not only an overly simplistic view of conversation but it is also emphatically different from the way humans converse by heavily relying on their background knowledge about the topic (as opposed to simply relying on the previous sequence of utterances). For example, it is common for humans to (involuntarily) produce utterances which are copied or suitably modified from background articles they have read about the topic. To facilitate the development of such natural conversation models which mimic the human process of conversing, we create a new dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie. We establish baseline results on this dataset (90K utterances from 9K conversations) using three different models: (i) pure generation based models which ignore the background knowledge (ii) generation based models which learn to copy information from the background knowledge when required and (iii) span prediction based models which predict the appropriate response span in the background knowledge.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:u_35RYKgDlwC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"There has always been criticism for using -gram based similarity metrics, such as BLEU, NIST, etc, for evaluating the performance of NLG systems. However, these metrics continue to remain popular and are recently being used for evaluating the performance of systems which automatically generate questions from documents, knowledge graphs, images, etc. Given the rising interest in such automatic question generation (AQG) systems, it is important to objectively examine whether these metrics are suitable for this task. In particular, it is important to verify whether such metrics used for evaluating AQG systems focus on answerability of the generated question by preferring questions which contain all relevant information such as question type (Wh-types), entities, relations, etc. In this work, we show that current automatic evaluation metrics based on -gram similarity do not always correlate well with human judgments about answerability of a question. To alleviate this problem and as a first step towards better evaluation metrics for AQG, we introduce a scoring function to capture answerability and show that when this scoring function is integrated with existing metrics, they correlate significantly better with human judgments. The scripts and data developed as a part of this work are made publicly available at https://github.com/PrekshaNema25/Answerability-Metric",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:zA6iFVUQeVQC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"There is an increasing demand for goal-oriented conversation systems which can assist users in various day-to-day activities such as booking tickets, restaurant reservations, shopping, etc. Most of the existing datasets for building such conversation systems focus on monolingual conversations and there is hardly any work on multilingual and/or code-mixed conversations. Such datasets and systems thus do not cater to the multilingual regions of the world, such as India, where it is very common for people to speak more than one language and seamlessly switch between them resulting in code-mixed conversations. For example, a Hindi speaking user looking to book a restaurant would typically ask, ""Kya tum is restaurant mein ek table book karne mein meri help karoge?"" (""Can you help me in booking a table at this restaurant?""). To facilitate the development of such code-mixed conversation models, we build a goal-oriented dialog dataset containing code-mixed conversations. Specifically, we take the text from the DSTC2 restaurant reservation dataset and create code-mixed versions of it in Hindi-English, Bengali-English, Gujarati-English and Tamil-English. We also establish initial baselines on this dataset using existing state of the art models. This dataset along with our baseline implementations is made publicly available for research purposes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:3s1wT3WcHBgC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Given a graph where every node has certain attributes associated with it and some nodes have labels associated with them, Collective Classification (CC) is the task of assigning labels to every unlabeled node using information from the node as well as its neighbors. It is often the case that a node is not only influenced by its immediate neighbors but also by higher order neighbors, multiple hops away. Recent state-of-the-art models for CC learn end-to-end differentiable variations of Weisfeiler-Lehman (WL) kernels to aggregate multi-hop neighborhood information. In this work, we propose a Higher Order Propagation Framework, HOPF, which provides an iterative inference mechanism for these powerful differentiable kernels. Such a combination of classical iterative inference mechanism with recent differentiable kernels allows the framework to learn graph convolutional filters that simultaneously exploit the attribute and label information available in the neighborhood. Further, these iterative differentiable kernels can scale to larger hops beyond the memory limitations of existing differentiable kernels. We also show that existing WL kernel-based models suffer from the problem of Node Information Morphing where the information of the node is morphed or overwhelmed by the information of its neighbors when considering multiple hops. To address this, we propose a specific instantiation of HOPF, called the NIP models, which preserves the node information at every propagation step. The iterative formulation of NIP models further helps in incorporating distant hop information concisely as summaries of the inferred labels. We do an extensive …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:HoB7MX3m0LUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Semi-supervised node classification in attributed graphs, i.e., graphs with node features, involves learning to classify unlabeled nodes given a partially labeled graph. Label predictions are made by jointly modeling the node and its' neighborhood features. State-of-the-art models for node classification on such attributed graphs use differentiable recursive functions that enable aggregation and filtering of neighborhood information from multiple hops. In this work, we analyze the representation capacity of these models to regulate information from multiple hops independently. From our analysis, we conclude that these models despite being powerful, have limited representation capacity to capture multi-hop neighborhood information effectively. Further, we also propose a mathematically motivated, yet simple extension to existing graph convolutional networks (GCNs) which has improved representation capacity. We extensively evaluate the proposed model, F-GCN on eight popular datasets from different domains. F-GCN outperforms the state-of-the-art models for semi-supervised learning on six datasets while being extremely competitive on the other two.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:pqnbT2bcN3wC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"While multimodal conversation agents are gaining importance in several domains such as retail, travel etc., deep learning research in this area has been limited primarily due to the lack of availability of large-scale, open chatlogs. To overcome this bottleneck, in this paper we introduce the task of multimodal, domain-aware conversations, and propose the MMD benchmark dataset. This dataset was gathered by working in close coordination with large number of domain experts in the retail domain. These experts suggested various conversations flows and dialog states which are typically seen in multimodal conversations in the fashion domain. Keeping these flows and states in mind, we created a dataset consisting of over 150K conversation sessions between shoppers and sales agents, with the help of in-house annotators using a semi-automated manually intense iterative process. With this dataset, we propose 5 new sub-tasks for multimodal conversations along with their evaluation methodology. We also propose two multimodal neural models in the encode-attend-decode paradigm and demonstrate their performance on two of the sub-tasks, namely text response generation and best image response selection. These experiments serve to establish baseline performance and open new research directions for each of these sub-tasks. Further, for each of the sub-tasks, we present a'per-state evaluation'of 9 most significant dialog states, which would enable more focused research into understanding the challenges and complexities involved in each of these states.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:35N4QoGY0k4C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"While conversing with chatbots, humans typically tend to ask many questions, a significant portion of which can be answered by referring to large-scale knowledge graphs (KG). While Question Answering (QA) and dialog systems have been studied independently, there is a need to study them closely to evaluate such real-world scenarios faced by bots involving both these tasks. Towards this end, we introduce the task of Complex Sequential QA which combines the two tasks of (i) answering factual questions through complex inferencing over a realistic-sized KG of millions of entities, and (ii) learning to converse through a series of coherently linked QA pairs. Through a labor intensive semi-automatic process, involving in-house and crowdsourced workers, we created a dataset containing around 200K dialogs with a total of 1.6 M turns. Further, unlike existing large scale QA datasets which contain simple questions that can be answered from a single tuple, the questions in our dialogs require a larger subgraph of the KG. Specifically, our dataset has questions which require logical, quantitative, and comparative reasoning as well as their combinations. This calls for models which can:(i) parse complex natural language questions,(ii) use conversation context to resolve coreferences and ellipsis in utterances,(iii) ask for clarifications for ambiguous queries, and finally (iv) retrieve relevant subgraphs of the KG to answer such questions. However, our experiments with a combination of state of the art dialog and QA models show that they clearly do not achieve the above objectives and are inadequate for dealing with such complex real world settings. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:J_g5lzvAfSwC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"We propose DuoRC, a novel dataset for Reading Comprehension (RC) that motivates several new challenges for neural approaches in language understanding beyond those offered by existing RC datasets. DuoRC contains 186,089 unique question-answer pairs created from a collection of 7680 pairs of movie plots where each pair in the collection reflects two versions of the same movie - one from Wikipedia and the other from IMDb - written by two different authors. We asked crowdsourced workers to create questions from one version of the plot and a different set of workers to extract or synthesize answers from the other version. This unique characteristic of DuoRC where questions and answers are created from different versions of a document narrating the same underlying story, ensures by design, that there is very little lexical overlap between the questions created from one version and the segments containing the answer in the other version. Further, since the two versions have different levels of plot detail, narration style, vocabulary, etc., answering questions from the second version requires deeper language understanding and incorporating external background knowledge. Additionally, the narrative style of passages arising from movie plots (as opposed to typical descriptive passages in existing datasets) exhibits the need to perform complex reasoning over events across multiple sentences. Indeed, we observe that state-of-the-art neural RC models which have achieved near human performance on the SQuAD dataset, even when coupled with traditional NLP techniques to address the challenges presented in DuoRC exhibit very poor …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:vV6vV6tmYwMC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"In this work, we focus on the task of generating natural language descriptions from a structured table of facts containing fields (such as nationality, occupation, etc) and values (such as Indian, actor, director, etc). One simple choice is to treat the table as a sequence of fields and values and then use a standard seq2seq model for this task. However, such a model is too generic and does not exploit task-specific characteristics. For example, while generating descriptions from a table, a human would attend to information at two levels: (i) the fields (macro level) and (ii) the values within the field (micro level). Further, a human would continue attending to a field for a few timesteps till all the information from that field has been rendered and then never return back to this field (because there is nothing left to say about it). To capture this behavior we use (i) a fused bifocal attention mechanism which exploits and combines this micro and macro level information and (ii) a gated orthogonalization mechanism which tries to ensure that a field is remembered for a few time steps and then forgotten. We experiment with a recently released dataset which contains fact tables about people and their corresponding one line biographical descriptions in English. In addition, we also introduce two similar datasets for French and German. Our experiments show that the proposed model gives 21% relative improvement over a recently proposed state of the art method and 10% relative improvement over basic seq2seq models. The code and the datasets developed as a part of this work are publicly available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:ldfaerwXgEUC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Structured data summarization involves generation of natural language summaries from structured input data. In this work, we consider summarizing structured data occurring in the form of tables as they are prevalent across a wide variety of domains. We formulate the standard table summarization problem, which deals with tables conforming to a single predefined schema. To this end, we propose a mixed hierarchical attention based encoder-decoder model which is able to leverage the structure in addition to the content of the tables. Our experiments on the publicly available WEATHERGOV dataset show around 18 BLEU (~ 30%) improvement over the current state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:2P1L_qKh6hAC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"In many visual domains (like fashion, furniture, etc.) the search for products on online platforms requires matching textual queries to image content. For example, the user provides a search query in natural language (e.g.,pink floral top) and the results obtained are of a different modality (e.g., the set of images of pink floral tops). Recent work on multimodal representation learning enables such cross-modal matching by learning a common representation space for text and image. While such representations ensure that the n-dimensional representation of pink floral top is very close to representation of corresponding images, they do not ensure that the first k 1 (<; n) dimensions correspond to color, the next k 2 (<; n) correspond to style and so on. In other words, they learn entangled representations where each dimension does not correspond to a specific attribute. We propose two simple variants which can learn …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:M05iB0D1s5AC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Recently there has been a lot of work on pruning filters from deep convolutional neural networks (CNNs) with the intention of reducing computations. The key idea is to rank the filters based on a certain criterion (say, l1-norm, average percentage of zeros, etc) and retain only the top ranked filters. Once the low scoring filters are pruned away the remainder of the network is fine tuned and is shown to give performance comparable to the original unpruned network. In this work, we report experiments which suggest that the comparable performance of the pruned network is not due to the specific criterion chosen but due to the inherent plasticity of deep neural networks which allows them to recover from the loss of pruned filters once the rest of the filters are fine-tuned. Specifically, we show counter-intuitive results wherein by randomly pruning 25-50% filters from deep CNNs we are able to obtain the same performance as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:NaGl4SEjCO4C,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Converting an n-dimensional vector to a probability distribution over n objects is a commonly used component in many machine learning tasks like multiclass classification, multilabel classification, attention mechanisms etc. For this, several probability mapping functions have been proposed and employed in literature such as softmax, sum-normalization, spherical softmax, and sparsemax, but there is very little understanding in terms how they relate with each other. Further, none of the above formulations offer an explicit control over the degree of sparsity. To address this, we develop a unified framework that encompasses all these formulations as special cases. This framework ensures simple closed-form solutions and existence of sub-gradients suitable for learning via backpropagation. Within this framework, we propose two novel sparse formulations, sparsegen-lin and sparsehourglass, that seek to provide a control over the degree of desired sparsity. We further develop novel convex loss functions that help induce the behavior of aforementioned formulations in the multilabel classification setting, showing improved performance. We also demonstrate empirically that the proposed formulations, when used to compute attention weights, achieve better or comparable performance on standard seq2seq tasks like neural machine translation and abstractive summarization.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:fPk4N6BV_jEC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Deep Learning has managed to push boundaries in a wide variety of tasks. One area of interest is to tackle problems in reasoning and understanding, in an aim to emulate human intelligence. In this work, we describe a deep learning model that addresses the reasoning task of question-answering on bar graphs and pie charts. We introduce a novel architecture that learns to identify various plot elements, quantify the represented values and determine a relative ordering of these statistical values. We test our model on the recently released FigureQA dataset, which provides images and accompanying questions, for bar graphs and pie charts, augmented with rich annotations. Our approach outperforms the state-of-the-art Relation Networks baseline and traditional CNN-LSTM models when evaluated on this dataset. Our model also has a considerably faster training time of approximately 2 days on 1 GPU compared to the Relation Networks baseline which requires around two weeks to train on 4 GPUs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:ZHo1McVdvXMC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Over the past few years, various tasks involving videos such as classification, description, summarization and question answering have received a lot of attention. Current models for these tasks compute an encoding of the video by treating it as a sequence of images and going over every image in the sequence. However, for longer videos this is very time consuming. In this paper, we focus on the task of video classification and aim to reduce the computational time by using the idea of distillation. Specifically, we first train a teacher network which looks at all the frames in a video and computes a representation for the video. We then train a student network whose objective is to process only a small fraction of the frames in the video and still produce a representation which is very close to the representation computed by the teacher network. This smaller student network involving fewer computations can then be employed at inference time for video classification. We experiment with the YouTube-8M dataset and show that the proposed student network can reduce the inference time by upto 30% with a very small drop in the performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:g5m5HwL7SMYC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"We address the task of joint training of transliteration models for multiple language pairs (multilingual transliteration). This is an instance of multitask learning, where individual tasks (language pairs) benefit from sharing knowledge with related tasks. We focus on transliteration involving related tasks i.e., languages sharing writing systems and phonetic properties (orthographically similar languages). We propose a modified neural encoder-decoder model that maximizes parameter sharing across language pairs in order to effectively leverage orthographic similarity. We show that multilingual transliteration significantly outperforms bilingual transliteration in different scenarios (average increase of 58% across a variety of languages we experimented with). We also show that multilingual transliteration models can generalize well to languages/language pairs not encountered during training and hence perform well …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:70eg2SAEIzsC,https://www.cse.iitm.ac.in/~miteshk
Mitesh Khapra,"['Natural Language Processing', 'Machine Learning']",29,3080,2018,"Graph convolutional networks and its variants are the state-of-the-art methods for learning node embeddings in a graph-structured data. However, these existing approaches fail to capture the neighborhood information efficiently beyond a certain depth from the node. In this work, we propose a novel hierarchical feature aggregation approach which explictly aggregates the feature information from different depths of a node's neighborhood using an LSTM model. Proposed model gives promising results on four real-world datasets as compared to state-of-the-art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=DV8z8DYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=DV8z8DYAAAAJ:RYcK_YlVTxYC,https://www.cse.iitm.ac.in/~miteshk
Surender Baswana,['Design and analysis of algorithms'],13,788,2022,"Let be an undirected graph on n vertices with non-negative capacities on its edges. The mincut sensitivity problem for the insertion of an edge is defined as follows. Build a compact data structure for G and a given set of vertices that, on receiving any edge of positive capacity as query input, can efficiently report the set of all pairs from whose mincut value increases upon insertion of the edge (x, y) to G. The only result that exists for this problem is for a single pair of vertices (Picard and Queyranne, in: Rayward-Smith (ed) Combinatorial optimization II. Mathematical programming Studies, vol 13, no 1. Springer, Berlin, pp 8–16, 1980. https://doi.org/10.1007/BFb0120902, and dates back to 1980. We present the following results for the single source and the all-pairs versions of this problem.
Single source  Given any designated source vertex s, there exists a data structure of size (Data structure sizes are in words …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:M05iB0D1s5AC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2022,"Let G be an undirected graph. We address the problem of fault tolerant depth first search (DFS) tree defined as follows. Build a compact data structure that, given any set of failed vertices or edges, can efficiently report a DFS tree of . We present an algorithm which is drastically simpler and yet more efficient than the current state-of-the-art algorithms for this problem. Additionally, for achieving efficiency, the current-state-of-the-algorithms have to crucially rely on sophisticated data structures. The simplicity of our algorithm also enables us to replace these sophisticated data structures with much simpler and lighter data structures that occupy optimal space and take optimal preprocessing time. Our algorithm for the fault tolerant DFS tree also leads to a better time complexity for maintaining a DFS tree in a fully dynamic environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:3s1wT3WcHBgC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2022,"Let G be a directed multi-graph on n vertices and m edges with a designated source vertex s and a designated sink vertex t. We study the (s, t)-cuts of capacity minimum+ 1 and as an important application of them, we give a solution to the dual edge sensitivity for (s, t)-mincuts-reporting the (s, t)-mincut upon failure or addition of any pair of edges.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:rO6llkc54NcC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2022,"Let G = (V, E) be an undirected unweighted graph on n vertices and m edges. We address the problem of sensitivity oracle for all-pairs mincuts in G defined as follows.
Build a compact data structure that, on receiving any pair of vertices s,t ∊ V and failure (or insertion) of any edge as query, can efficiently report the mincut between s and t after the failure (or the insertion).
To the best of our knowledge, there exists no data structure for this problem which takes o(mn) space and a non-trivial query time. We present the following results.
Our first data structure occupies space and guarantees query time to report the value of resulting (s, t)-mincut upon failure (or insertion) of any edge. Moreover, the set of vertices defining a resulting (s, t)-mincut after the update can be reported in time which is worst-case optimal.
Our second data structure optimizes space at the expense of increased query time. It takes space–which is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:ZHo1McVdvXMC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2020,"Let G=(V, E) be an undirected unweighted graph on n vertices and m edges. We address the problem of fault-tolerant data structure for all-pairs mincuts in G defined as follows. Build a compact data structure that, on receiving a pair of vertices s, t∈ V and any edge (x, y) as query, can efficiently report the value of the mincut between s and t upon failure of the edge (x, y).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:g5m5HwL7SMYC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2020,"Let G=(V,E) be an n-vertices m-edges directed graph with edge weights in the range [1,W] for some parameter W, and sϵ V be a designated source. In this article, we address several variants of the problem of maintaining the (1+ε)-approximate shortest path from s to each vϵ V{s} in the presence of a failure of an edge or a vertex.
From the graph theory perspective, we show that G has a subgraph H with Õ(ε -1} nlog W) edges such that for any x,vϵ V, the graph H \ x contains a path whose length is a (1+ε)-approximation of the length of the shortest path from s to v in G \ x. We show that the size of the subgraph H is optimal (up to logarithmic factors) by proving a lower bound of Ω (ε -1 n log W) edges. Demetrescu, Thorup, Chowdhury, and Ramachandran (SICOMP 2008) showed that the size of a fault tolerant exact shortest path subgraph in weighted directed/undirected graphs is Ω (m). Parter and Peleg (ESA 2013 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:RYcK_YlVTxYC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2019,"The centrally funded technical institutes (CFTIs) for undergraduate studies in India consist of the prestigious Indian Institutes of Technology (IITs) as well as several non-IITs (the National Institutes of Technology, the Indian Institutes of Information Technology, and others). The IITs use the candidate rankings obtained from performance on the JEE Advanced exam for their admissions, whereas the non-IITs use a different set of rankings (obtained from the JEE Main exam) for their admissions. Until 2014, the IITs and the non-IITs used two separate processes to allocate seats to candidates. Every year, several individual candidates would get two seats, one from each of these processes. As a result, at least one of those two seats would go vacant. This would especially be a problem for the IITs as their allocation process would complete before that of the non-IITs. In 2015, we designed and implemented a new joint …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:vV6vV6tmYwMC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2019,"Until 2014, admissions to the Indian Institutes of Technology (IITs) were conducted under one umbrella, whereas the admissions to the non-IIT Centrally Funded Government Institutes (CFTIs) were conducted under a different umbrella, the Central Seat Allocation Board. In 2015, a new Multi-Round Multi-Run Deferred Acceptance joint seat allocation process was implemented, improving the efficiency and productivity of concerned stakeholders. The process brings all CFTIs under one umbrella for admissions: 100 institutes and approximately 39000 seats in 2018. In this scheme, each candidate submits a single choice list over all available programs, and receives no more than a single seat from the system, based on the choices and the ranks in the relevant merit lists. Significantly, overbooking of seats is forbidden. In this report, we provide details of our safe, fair and optimal algorithm. Novel features include the ability to handle multiple merit lists, seat guarantee across multiple rounds, implementing reservation, and de-reservation rules, handling escalation of ranks due to a revision of marks by state boards during the allocation process, and dealing with last minute de-recognition of other backward caste categories. A notable rule required the allocation of supernumerary seats to females, provided the program did not have a sufficient desired percentage, while, at the same time, not reducing the number of seats available to non-females. Looking forward, we posit first that it is inevitable that different colleges will prefer different mechanisms of judging merit, and assigning relative rank. We believe the ability of our algorithm to gracefully handle …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:2P1L_qKh6hAC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2019,"In this paper we study the problem of maintaining the strongly connected components of a graph in the presence of failures. In particular, we show that given a directed graph with and , and an integer value , there is an algorithm that computes in time for any set F of size at most k the strongly connected components of the graph . The running time of our algorithm is almost optimal since the time for outputting the SCCs of is at least . The algorithm uses a data structure that is computed in a preprocessing phase in polynomial time and is of size . Our result is obtained using a new observation on the relation between strongly connected components (SCCs) and reachability. More specifically, one of the main building blocks in our result is a restricted variant of the problem in which we only compute strongly connected components that intersect a certain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:ns9cj8rnVeAC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2019,"Depth first search (DFS) tree is a fundamental data structure for solving various problems in graphs. It is well known that it takes time to build a DFS tree for a given undirected graph on vertices and edges. We address the problem of maintaining a DFS tree when the graph is undergoing updates (insertion and deletion of vertices or edges). We present the following results for this problem: (1) Fault tolerant DFS tree: There exists a data structure of size (where hides the polylogarithmic factors) which can be preprocessed in time such that given any set of failed vertices or edges, a DFS tree of the graph can be reported in time. (2) Fully dynamic DFS tree: There exists a fully dynamic algorithm for maintaining a DFS tree that takes time for preprocessing and worst case time per update for any arbitrary online sequence of updates. (3) Incremental DFS tree: There exists an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:GnPB-g6toBAC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2018,"Let G = (V, E) be an undirected weighted graph on n = |V| vertices and m = |E| edges. Length of a path between two vertices is the sum of the weights of all the edges of the path. The shortest path between a pair of vertices is the path of least length among all possible paths between the two vertices in the graph. The length of the shortest path between two vertices is also called the distance between the two vertices. An α-approximate shortest path between two vertices is a path of length at-most α times the length of the shortest path.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:HoB7MX3m0LUC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2018,"We present an algorithm for maintaining a maximal matching in a graph under addition and deletion of edges. Our algorithm is randomized and it takes expected amortized time for each edge update, where is the number of vertices in the graph. Moreover, for any sequence of edge updates, the total time taken by the algorithm is with high probability. (Original article at https://doi.org/10.1137/130914140.)",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:lSLTfruPkqcC,http://www.cse.iitk.ac.in/~sbaswana
Surender Baswana,['Design and analysis of algorithms'],13,788,2018,"The depth first search (DFS) tree is a fundamental data structure used for solving various graph problems. For a given graph G = (V, E) on n vertices and m edges, a DFS tree can be built in O(m + n) time. In the last 20 years, a few algorithms have been designed for maintaining a DFS tree efficiently under insertion of edges. For undirected graphs, there are two prominent algorithms, namely, ADFS1 and ADFS2 [ICALP14] that achieve total update time of and O(n2) respectively. For directed acyclic graphs, the only non-trivial algorithm, namely, FDFS [IPL97] requires total O(mn) update time. However, even after 20 years of this result, there does not exist any non-trivial incremental algorithm for maintaining a DFS tree in directed graphs with o(m2) worst case bound.
In this paper, we carry out extensive experimental and theoretical evaluation of the existing incremental DFS algorithms in random graphs and real world …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=U42j5MkAAAAJ&sortby=pubdate&citation_for_view=U42j5MkAAAAJ:NaGl4SEjCO4C,http://www.cse.iitk.ac.in/~sbaswana
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2019,"Testing whether a set f of polynomials has an algebraic dependence is a basic problem with several applications. The polynomials are given as algebraic circuits. The complexity of algebraic independence testing is wide open over finite fields (Dvir, Gabizon, Wigderson, FOCS’07). Previously, the best complexity bound known was NP# P (Mittmann, Saxena, Scheiblechner, Trans. AMS 2014). In this article we put the problem in AM∩ coAM. In particular, dependence testing is unlikely to be NP-hard. Our proof uses methods of algebraic geometry. We estimate the size of the image and the sizes of the preimages of the polynomial map f over the finite field. A gap between the corresponding sizes for independent and for dependent sets of polynomials is utilized in the AM protocols.
A conference version of this paper appeared in the Proceedings of the 33rd Computational Complexity Conference (CCC’18)[24] and as a poster in STOC 2018: TheoryFest.∗ Supported by DST and Research I Foundation of CSE, IITK.† Supported by DST/SJF/MSA-01/2013-14.‡ Supported by DFG grant TH 472/5-1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:dTyEYWd-f8wC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2019,"Isomorphism problems about structures frequently appear in computer science. Some example structures are NP-hard problems, graphs, fields, algebras, and polynomials. Indian theorists have been studying these closely, and have proved some of the best results known. Communication complexity studies the interaction required to solve a problem when the input is distributed across multiple parties. Indian researchers, notably at Tata Institute of Fundamental Research, Mumbai (TIFR), have made leading contributions to this area.
Logic and automata theory. The close interplay between automata theory and logic was first identified by Buchi. Pnueli introduced temporal logic as a language for specifying properties of reactive systems. Emerson, Clarke, and Sifakis invented model checking: determining algorithmically whether a formal model satisfies a temporal logic specification.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:PR6Y55bgFSsC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2019,"Polynomial factoring has famous practical algorithms over fields-- finite, rational and p-adic. However, modulo prime powers, factoring gets harder because there is non-unique factorization and a combinatorial blowup ensues. For example, x^2+p \bmod p^2 is irreducible, but x^2+px \bmod p^2 has exponentially many factors! We present the first randomized poly(\deg f, łog p) time algorithm to factor a given univariate integral f(x) modulo p^k, for a prime p and k łeq 4. Thus, we solve the open question of factoring modulo p^3 posed in (Sircana, ISSAC'17). Our method reduces the general problem of factoring f(x) mod p^k to that of \em root finding in a related polynomial E(y) \bmodłangle p^k, \varphi(x)^\ell \rangle for some irreducible \varphi \bmod p. We can efficiently solve the latter for kłe4, by incrementally transforming E(y). Moreover, we discover an efficient refinement of Hensel lifting to lift factors of f(x) \bmod p to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:Mojj43d5GZwC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2019,"Finding an irreducible factor, of a polynomial modulo a prime , is not known to be in deterministic polynomial time. Though there is such a classical algorithm that {\em counts} the number of irreducible factors of . We can ask the same question modulo prime-powers . The irreducible factors of blow up exponentially in number; making it hard to describe them. Can we count those irreducible factors that remain irreducible mod ? These are called {\em basic-irreducible}. A simple example is in ; it has many basic-irreducible factors. Also note that, is irreducible but not basic-irreducible! We give an algorithm to count the number of basic-irreducible factors of in deterministic poly(deg)-time. This solves the open questions posed in (Cheng et al, ANTS'18 \& Kopp et al, Math.Comp.'19). In particular, we are counting roots ; which gives the first deterministic poly-time algorithm to compute Igusa zeta function of . Also, our algorithm efficiently partitions the set of all basic-irreducible factors (possibly exponential) into merely deg-many disjoint sets, using a compact tree data structure and {\em split} ideals.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:_B80troHkn4C,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2019,"Proof. This is trivially true when n= 2: r= 3 satisfies all conditions. So assume that n> 2. Then⌈ log5 n⌉> 10 and Lemma 3.1 applies. Observe that the largest value of k for any number of the form mk≤ B=⌈ log5 n⌉, m≥ 2, is⌊ log B⌋. Now consider the smallest number s that does not divide the product n⌊ log B⌋·
⌊ log2 n⌋",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:AXPGKjj_ei8C,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2018,"The motivation for this work (Pandey et al. 2016) comes from two problems: testing algebraic independence of arithmetic circuits over a field of small characteristic and generalizing the structural property of algebraic dependence used by Kumar, Saraf, CCC’16 to arbitrary fields. It is known that in the case of zero, or large characteristic, using a classical criterion based on the Jacobian, we get a randomized poly-time algorithm to test algebraic independence. Over small characteristic, the Jacobian criterion fails and there is no subexponential time algorithm known. This problem could well be conjectured to be in RP, but the current best algorithm puts it in NP (Mittmann, Saxena, Scheiblechner, Trans.AMS’14). Currently, even the case of two bivariate circuits over is open. We come up with a natural generalization of Jacobian criterion that works over all characteristics. The new criterion is efficient if the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:NhqRSupF_l8C,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2018,"We show that for the blackbox polynomial identity testing (PIT) problem it suffices to study circuits that depend only on the first extremely few variables. One only need to consider size-s degree-s circuits that depend on the first log∘ c s variables (where c is a constant and we are composing c logarithms). Thus, hitting-set generator (hsg) manifests a bootstrapping behavior— a partial hsg against very few variables can be efficiently grown to a complete hsg. A boolean analog, or a pseudorandom generator property of this type, is unheard-of. Our idea is to use the partial hsg and its annihilator polynomial to efficiently bootstrap the hsg exponentially wrt variables. This is repeated c times in an efficient way.
Pushing the envelope further we show that: (1) a quadratic-time blackbox PIT for 6913-variate degree-s size-s polynomials, will lead to a “near”-complete derandomization of PIT, and (2) a blackbox PIT for n-variate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:5Ul4iDaHHb8C,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2018,"Newton iteration (NI) is an almost 350 years old recursive formula that approximates a simple root of a polynomial quite rapidly. We generalize it to a matrix recurrence (allRootsNI) that approximates all the roots simultaneously. In this form, the process yields a better circuit complexity in the case when the number of roots r is small but the multiplicities are exponentially large. Our method sets up a linear system in r unknowns and iteratively builds the roots as formal power series. For an algebraic circuit f(x1,…,xn) of size s we prove that each factor has size at most a polynomial in: s and the degree of the squarefree part of f. Consequently, if f1 is a 2Ω(n)-hard polynomial then any nonzero multiple ∏i fiei is equally hard for arbitrary positive ei’s, assuming that ∑ideg(fi) is at most 2O(n).
It is an old open question whether the class of poly(n)-sized formulas (resp. algebraic branching programs) is closed under factoring …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:8AbLer7MMksC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2018,"We consider the problem of recovering (that is, interpolating) and identity testing of a “hidden” monic polynomial f, given an oracle access to for , where is finite field of q elements (extension fields access is not permitted). The naive interpolation algorithm needs queries and thus requires . We design algorithms that are asymptotically better in certain cases; requiring only queries to the oracle. In the randomized (and quantum) setting, we give a substantially better interpolation algorithm, that requires only queries. Such results have been known before only for the special case of a linear f, called the hidden shifted power problem. We use techniques from algebra, such as effective versions of Hilbert’s Nullstellensatz, and analytic number theory, such as results on the distribution of rational functions in subgroups and character sum estimates.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:isC4tDSrTZIC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2018,"Testing whether a set of polynomials has an algebraic dependence is a basic problem with several applications. The polynomials are given as algebraic circuits. Algebraic independence testing question is wide open over finite fields (Dvir, Gabizon, Wigderson, FOCS'07). The best complexity known is NP (Mittmann, Saxena, Scheiblechner, Trans.AMS'14). In this work we put the problem in AM coAM. In particular, dependence testing is unlikely to be NP-hard and joins the league of problems of ""intermediate"" complexity, eg. graph isomorphism & integer factoring. Our proof method is algebro-geometric-- estimating the size of the image/preimage of the polynomial map over the finite field. A gap in this size is utilized in the AM protocols. Next, we study the open question of testing whether every annihilator of has zero constant term (Kayal, CCC'09). We give a geometric characterization using Zariski closure of the image of ; introducing a new problem called approximate polynomials satisfiability (APS). We show that APS is NP-hard and, using projective algebraic-geometry ideas, we put APS in PSPACE (prior best was EXPSPACE via Grobner basis computation). As an unexpected application of this to approximative complexity theory we get-- Over any field, hitting-set for can be designed in PSPACE. This solves an open problem posed in (Mulmuley, FOCS'12, J.AMS 2017); greatly mitigating the GCT Chasm (exponentially in terms of space complexity).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:BrmTIyaxlBUC,http://www.cse.iitk.ac.in/users/nitin
Nitin Saxena,"['Complexity theory', 'Algebra', 'Number theory', 'Algebraic geometry', 'Algebraic combinatorics']",18,1263,2018,"Derandomization of blackbox identity testing reduces to extremely special circuit models. After a line of work, it is known that focusing on circuits with constant-depth and constantly many variables is enough (Agrawal, Ghosh, Saxena, STOC'18) to get to general hitting-sets and circuit lower bounds. This inspires us to study circuits with few variables, eg. logarithmic in the size s. We give the first poly (s)-time blackbox identity test for n= O (log s) variate size-s circuits that have poly (s)-dimensional partial derivative space; eg. depth-3 diagonal circuits (or Sigma wedge Sigma^ n). The former model is well-studied (Nisan, Wigderson, FOCS'95) but no poly (s2^ n)-time identity test was known before us. We introduce the concept of cone-closed basis isolation and prove its usefulness in studying log-variate circuits. It subsumes the previous notions of rank-concentration studied extensively in the context of ROABP models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=1Yl1h_YAAAAJ&sortby=pubdate&citation_for_view=1Yl1h_YAAAAJ:kRWSkSYxWN8C,http://www.cse.iitk.ac.in/users/nitin
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",13,441,2019,"Optimal location queries identify the best locations to set up new facilities for providing service to its users. For several businesses such as fuel stations, cellphone base-stations, etc., placement queries require taking into account the mobility patterns (or trajectories) of the users. In this work, we formulate the TOPS (Trajectory-Aware Optimal Placement of Services) query that locates the best k sites on a road network for the prevailing user trajectories. The problem is NP-hard. The greedy approach, which is the state-of-the-art technique for this problem, is not scalable and practical for real urban-scale scenarios, primarily due to its high memory footprint beyond the capabilities of commodity machines. To overcome these challenges, we develop an indexing framework called NETCLUS that derives its power through an unique combination of FM sketches with network clustering. Empirical studies show that NETCLUS …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&sortby=pubdate&citation_for_view=Sk-JV9QAAAAJ:isC4tDSrTZIC,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",13,441,2019,"The phenomenal growth of graph data from a wide variety of real-world applications has rendered graph querying to be a problem of paramount importance. Traditional techniques use structural as well as node similarities to find matches of a given query graph in a (large) target graph. However, almost all existing techniques have tacitly ignored the presence of relationships in graphs, which are usually encoded through interactions between node and edge labels. In this paper, we propose RAQ-Relationship-Aware Graph Querying-to mitigate this gap. Given a query graph, RAQ identifies the k best matching subgraphs of the target graph that encode similar relationships as in the query graph. To assess the utility of RAQ as a graph querying paradigm for knowledge discovery and exploration tasks, we perform a user survey on the Internet Movie Database (IMDb), where an overwhelming 86% of the 170 surveyed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&sortby=pubdate&citation_for_view=Sk-JV9QAAAAJ:Wp0gIr-vW9MC,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",13,441,2018,"Searching is one of the fundamental tasks in Computer Science. An intuitive way to search is to do it linearly, that is, start at the beginning of the dataset and continue till the searched-for item is found or nothing is found. However, as the volume of data increases, the response time of linear search is no longer acceptable. Indexes are designed to search through massive datasets quickly. There are a number of different ways of building complex and advanced indexes. Appropriate selection and modification of indexing structures according to dynamic business requirements is crucial for data-intensive applications. In this work, we present a few basic reusable indexing structures. These structures can be used to create advanced and complex indexing structures with lesser effort and time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&sortby=pubdate&citation_for_view=Sk-JV9QAAAAJ:TFP_iSt0sucC,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",13,441,2018,"A combinatorial algorithm to find a largest rectangle (LR) inside the inner isothetic cover which tightly inscribes a given digital object without holes is presented here which runs in O (k. n/g+(n/g) log⁡(n/g)) time, where n, g, and k being the number of pixels on the contour of the digital object, grid size, and the number of convex regions, respectively. Certain combinatorial rules are formulated to obtain an LR. An LR divides the object in several parts. The object can be rectangularized by recursive generation of a set of LRs and it generates LR-Graph which is useful for shape analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&sortby=pubdate&citation_for_view=Sk-JV9QAAAAJ:bEWYMUwI8FkC,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",13,441,2018,"Crowdsourcing, where the power of the human thinking is harnessed to answer queries that are otherwise difficult for computers to answer, has been successfully used in many applications. A particularly interesting application of crowdsourcing is crowd mining, where given a dataset, patterns are learned by asking questions to the crowd. Crowd mining is extremely useful in situations where either the information is complex or it is not available in a systematic manner. In this paper, we target one such scenario, that of common health practices and cures. A web-based framework, called MineAr, is built to ask simple questions to the crowd. The questions ask whether a common product helps in a disease (such as ginger for cold). The crowd worker can choose an answer from different grades varying from ""always"" to ""never"", or can skip if she is not sure. Association rules are then mined from these answers using …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&sortby=pubdate&citation_for_view=Sk-JV9QAAAAJ:iH-uZ7U-co4C,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",13,441,2018,"Money laundering refers to activities pertaining to hiding the true income, evading taxes, or converting illegally earned money for normal use. These activities are often performed through shell companies that masquerade as real companies but where actual the purpose is to launder money. Shell companies are used in all the three phases of money laundering, namely, placement, layering, and integration, often simultaneously. In this paper, we aim to identify shell companies. We propose to use only bank transactions since that is easily available. In particular, we look at all incoming and outgoing transactions from a particular bank account along with its various attributes, and use anomaly detection techniques to identify the accounts that pertain to shell companies. Our aim is to create an initial list of potential shell company candidates which can be investigated by financial experts later. Due to lack of real data, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&sortby=pubdate&citation_for_view=Sk-JV9QAAAAJ:r0BpntZqJG4C,http://www.cse.iitk.ac.in/users/arnabb/
Arnab Bhattacharya,"['Databases', 'Data Mining', 'Natural Language Processing', 'Information Retrieval', 'Artificial Intelligence']",13,441,2018,"Nearest neighbor searching of large databases in high-dimensional spaces is inherently difficult due to the curse of dimensionality. A flavor of approximation is, therefore, necessary to practically solve the problem of nearest neighbor search. In this paper, we propose a novel yet simple indexing scheme, HD-Index, to solve the problem of approximate k-nearest neighbor queries in massive high-dimensional databases. HD-Index consists of a set of novel hierarchical structures called RDB-trees built on Hilbert keys of database objects. The leaves of the RDB-trees store distances of database objects to reference objects, thereby allowing efficient pruning using distance filters. In addition to triangular inequality, we also use Ptolemaic inequality to produce better lower bounds. Experiments on massive (up to billion scale) high-dimensional (up to 1000+) datasets show that HD-Index is effective, efficient, and scalable.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Sk-JV9QAAAAJ&sortby=pubdate&citation_for_view=Sk-JV9QAAAAJ:mVmsd5A6BfQC,http://www.cse.iitk.ac.in/users/arnabb/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2023,"Extreme Classification (XC) seeks to tag data points with the most relevant subset of labels from an extremely large label set. Performing deep XC with dense, learnt representations for data points and labels has attracted much attention due to its superiority over earlier XC methods that used sparse, hand-crafted features. Negative mining techniques have emerged as a critical component of all deep XC methods, allowing them to scale to millions of labels. However, despite recent advances, training deep XC models with large encoder architectures such as transformers remains challenging. This paper notices that memory overheads of popular negative mining techniques often force mini-batch sizes to remain small and slow training down. In response, this paper introduces NGAME, a light-weight mini-batch creation technique that offers provably accurate in-batch negative samples. This allows training with larger …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:M3NEmzRMIkIC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2023,"Automated pedagogical error repair (APER) is the task of suggesting fixes to buggy programs written by beginner or novice programmers. APER tools have been shown to greatly improve the learning experience for students for whom error messages offered by compilers or runtime environments are either unhelpful and often misleading. Consequently, several APER tools have been proposed in literature using a variety of powerful machine learning techniques including sequence-to-sequence modelling (TRACER), reinforcement learning (RLAssist), graph attention (DrRepair) and decision trees (MACER). Despite offering high repair rates, these tools are often bulky, requiring several days of training and extensive GPU resources. This paper describes CAPER, a novel APER tool for the C programming language that offers 4-5% higher repair accuracy than existing APER tools on multiple benchmark error repair …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:J_g5lzvAfSwC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2023,"We report the design, development and deployment of PRIORITY, an intelligent portal aimed at reducing the workload of instructors, tutors and teaching assistants in large programming courses of creating lab, assignment and exam problems every week. PRIORITY offers a scalable, user friendly and indexed repository of problems that can be queried to retrieve problems related to a particular programming concept, say for loops. PRIORITY accomplishes this by casting problem retrieval as a multi-label learning problem and using solving it using novel feature selection and AI-techniques. We also report the results of an A/B test and user survey, both conducted while PRIORITY was being used to offer a CS1 course taught at IIT Kanpur with over 500 students. PRIORITY has been in deployment at IIT Kanpur for almost 2 years now and our experience thus far suggests that it not only presents a valuable tool for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:NaGl4SEjCO4C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2023,"Modern deep neural networks achieve excellent predictive performance due to their massive scale, flexible architecture design and availability of large training datasets. However, several applications additionally demand reliable estimates of model and predictive uncertainty that help in making robust predictions with limited training data, enabling out-of-distribution generalization, etc. Neural networks do not offer such uncertainly estimates out-of-the-box. Although Bayesian approaches to deep learning do provide a natural way to quantify model and predictive uncertainty by inferring the posterior distribution of the model weights and averaging the model’s predictions over the entire posterior distribution, standard Bayesian inference methods such as MCMC and variational inference are difficult to design and scale to massive networks. An appealing and popular alternative is to learn an ensemble of model weights …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:RGFaLdJalmkC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2022,"This paper presents SVAM (Sequential Variance-Altered MLE), a unified framework for learning generalized linear models under adversarial label corruption in training data. SVAM extends to tasks such as least squares regression, logistic regression, and gamma regression, whereas many existing works on learning with label corruptions focus only on least squares regression. SVAM is based on a novel variance reduction technique that may be of independent interest and works by iteratively solving weighted MLEs over variance-altered versions of the GLM objective. SVAM offers provable model recovery guarantees superior to the state-of-the-art for robust regression even when a constant fraction of training labels are adversarially corrupted. SVAM also empirically outperforms several existing problem-specific techniques for robust regression and classification. Code for SVAM is available at https://github.com/purushottamkar/svam/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:ns9cj8rnVeAC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2022,"The identification and control of human factors in climate change is a rapidly growing concern and robust, real-time air-quality monitoring and forecasting plays a critical role in allowing effective policy formulation and implementation. This paper presents DELFI, a novel deep learning-based mixture model to make effective long-term predictions of Particulate Matter (PM) 2.5 concentrations. A key novelty in DELFI is its multi-scale approach to the forecasting problem. The observation that point predictions are more suitable in the short-term and probabilistic predictions in the long-term allows accurate predictions to be made as much as 24 hours in advance. DELFI incorporates meteorological data as well as pollutant-based features to ensure a robust model that is divided into two parts: (i) a stack of three Long Short-Term Memory (LSTM) networks that perform differential modelling of the same window of past data, and (ii) a fully-connected layer enabling attention to each of the components. Experimental evaluation based on deployment of 13 stations in the Delhi National Capital Region (Delhi-NCR) in India establishes that DELFI offers far superior predictions especially in the long-term as compared to even non-parametric baselines. The Delhi-NCR recorded the 3rd highest PM levels amongst 39 mega-cities across the world during 2011-2015 and DELFI's performance establishes it as a potential tool for effective long-term forecasting of PM levels to enable public health management and environment protection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:O3NaXMp0MMsC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2022,"NOVEMBER 2022| VOL. 65| NO. 11| COMMUNICATIONS OF THE ACM 63 hot topics india region automate mechanical and time-consuming tasks performed by instructors and TAs? Apart from reducing manual effort, this could also improve instruction quality in resource-strapped situations. Our research group at IIT Kanpur has used Prutor data to develop AI tools targeting core pedagogical aspects of a course, such as question creation, doubt clearing, and grading (see Figure 2). Prutor data has also enabled researchers at IISc Bengaluru, National University of Singapore, Queensland University of Technology, and Innopolis University to develop solutions for error repair and improved feedback generation resulting in work appearing in several top-tier publications. 2–5, 8, 9, 11, 15, 17, 18",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:GnPB-g6toBAC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2022,"This paper presents AGGLIO (Accelerated Graduated Generalized LInear-model Optimization), a stage-wise, graduated optimization technique that offers global convergence guarantees for non-convex optimization problems whose objectives offer only local convexity and may fail to be even quasi-convex at a global scale. In particular, this includes learning problems that utilize popular activation functions such as sigmoid, softplus and SiLU that yield non-convex training objectives. AGGLIO can be readily implemented using point as well as mini-batch SGD updates and offers provable convergence to the global optimum in general conditions. In experiments, AGGLIO outperformed several recently proposed optimization techniques for non-convex and locally convex objectives in terms of convergence rate as well as convergent accuracy. AGGLIO relies on a graduation technique for generalized linear models, as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:k_IJM867U9cC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2022,"This paper develops the MUFIN technique for extreme classification (XC) tasks with millions of labels where datapoints and labels are endowed with visual and textual descriptors. Applications of MUFIN to product-to-product recommendation and bid query prediction over several millions of products are presented. Contemporary multi-modal methods frequently rely on purely embedding-based methods. On the other hand, XC methods utilize classifier architectures to offer superior accuracies than embedding-only methods but mostly focus on text-based categorization tasks. MUFIN bridges this gap by reformulating multi-modal categorization as an XC problem with several millions of labels. This presents the twin challenges of developing multi-modal architectures that can offer embeddings sufficiently expressive to allow accurate categorization over millions of labels; and training and inference routines that scale logarithmically in the number of labels. MUFIN develops an architecture based on cross-modal attention and trains it in a modular fashion using pre-training and positive and negative mining. A novel product-to-product recommendation dataset MM-AmazonTitles-300K containing over 300K products was curated from publicly available amazon. com listings with each product endowed with a title and multiple images. On the MM-AmazonTitles-300K and Polyvore datasets, and a dataset with over 4 million labels curated from click logs of the Bing search engine, MUFIN offered at least 3% higher accuracy than leading text-based, image-based and multi-modal techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:maZDTaKrznsC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2021,"This paper establishes the algorithmic principle of alternating projections onto incoherent low-rank subspaces (APIS) as a unifying principle for designing robust regression algorithms that offer consistent model recovery even when a significant fraction of training points are corrupted by an adaptive adversary. APIS offers the first algorithm for robust non-parametric (kernel) regression with an explicit breakdown point that works for general PSD kernels under minimal assumptions. APIS also offers, as straightforward corollaries, robust algorithms for a much wider variety of well-studied settings, including robust linear regression, robust sparse recovery, and robust Fourier transforms. Algorithms offered by APIS enjoy formal guarantees that are frequently sharper than (especially in non-parametric settings) or competitive to existing results in these settings. They are also straightforward to implement and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:TFP_iSt0sucC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2021,Training multi-layer Graph Convolution Networks (GCN) using standard SGD techniques scales poorly as each descent step ends up updating node embeddings for a large portion of the graph. Recent attempts to remedy this sub-sample the graph that reduces compute but introduce additional variance and may offer suboptimal performance. This paper develops the IGLU method that caches intermediate computations at various GCN layers thus enabling lazy updates that significantly reduce the compute cost of descent. IGLU introduces bounded bias into the gradients but nevertheless converges to a first-order saddle point under standard assumptions such as objective smoothness. Benchmark experiments show that IGLU offers up to 1.2% better accuracy despite requiring up to 88% less compute.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:isC4tDSrTZIC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2021,"Deep extreme multi-label learning (XML) requires training deep architectures that can tag a data point with its most relevant subset of labels from an extremely large label set. XML applications such as ad and product recommendation involve labels rarely seen during training but which nevertheless hold the key to recommendations that delight users. Effective utilization of label metadata and high quality predictions for rare labels at the scale of millions of labels are thus key challenges in contemporary XML research. To address these, this paper develops the SiameseXML framework based on a novel probabilistic model that naturally motivates a modular approach melding Siamese architectures with high-capacity extreme classifiers, and a training pipeline that effortlessly scales to tasks with 100 million labels. SiameseXML offers predictions 2–13% more accurate than leading XML methods on public benchmark datasets, as well as in live A/B tests on the Bing search engine, it offers significant gains in click-through-rates, coverage, revenue and other online metrics over state-of-the-art techniques currently in production. Code for SiameseXML is available at https://github. com/Extreme-classification/siamesexml",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:iH-uZ7U-co4C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2021,"Deep extreme classification (XC) seeks to train deep architectures that can tag a data point with its most relevant subset of labels from an extremely large label set. The core utility of XC comes from predicting labels that are rarely seen during training. Such rare labels hold the key to personalized recommendations that can delight and surprise a user. However, the large number of rare labels and small amount of training data per rare label offer significant statistical and computational challenges. State-of-the-art deep XC methods attempt to remedy this by incorporating textual descriptions of labels but do not adequately address the problem. This paper presents ECLARE, a scalable deep learning architecture that incorporates not only label text, but also label correlations, to offer accurate real-time predictions within a few milliseconds. Core contributions of ECLARE include a frugal architecture and scalable …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:r0BpntZqJG4C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2021,"Extreme multi-label classification (XML) involves tagging a data point with its most relevant subset of labels from an extremely large label set, with several applications such as product-to-product recommendation with millions of products. Although leading XML algorithms scale to millions of labels, they largely ignore label metadata such as textual descriptions of the labels. On the other hand, classical techniques that can utilize label metadata via representation learning using deep networks struggle in extreme settings. This paper develops the DECAF algorithm that addresses these challenges by learning models enriched by label metadata that jointly learn model parameters and feature representations using deep networks and offer accurate classification at the scale of millions of labels. DECAF makes specific contributions to model architecture design, initialization, and training, enabling it to offer up to 2-6 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:mB3voiENLucC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2021,"Low-cost sensors offer an attractive solution to the challenge of establishing affordable and dense spatio-temporal air quality monitoring networks with greater mobility and lower maintenance costs. These low-cost sensors offer reasonably consistent measurements but require in-field calibration to improve agreement with regulatory instruments. In this paper, we report the results of a deployment and calibration study on a network of six air quality monitoring devices built using the Alphasense O3 (OX-B431) and NO2 (NO2-B43F) electrochemical gas sensors. The sensors were deployed in two phases over a period of 3 months at sites situated within two megacities with diverse geographical, meteorological and air quality parameters. A unique feature of our deployment is a swap-out experiment wherein three of these sensors were relocated to different sites in the two phases. This gives us a unique opportunity to study the effect of seasonal, as well as geographical, variations on calibration performance. We report an extensive study of more than a dozen parametric and non-parametric calibration algorithms. We propose a novel local non-parametric calibration algorithm based on metric learning that offers, across deployment sites and phases, an R2 coefficient of up to 0.923 with respect to reference values for O3 calibration and up to 0.819 for NO2 calibration. This represents a 4–20 percentage point increase in terms of R2 values offered by classical non-parametric methods. We also offer a critical analysis of the effect of various data preparation and model design choices on calibration performance. The key recommendations emerging out of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:UeHWp8X0CEIC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2020,"Automated compilation error repair, the problem of suggesting fixes to buggy programs that fail to compile, has pedagogical applications for novice programmers who find compiler error messages cryptic and unhelpful. Existing works frequently involve black-box application of generative models, e.g. sequence-to-sequence prediction (TRACER) or reinforcement learning (RLAssist). Although convenient, this approach is inefficient at targeting specific error types as well as increases training costs. We present MACER, a novel technique for accelerated error repair based on a modular segregation of the repair process into repair identification and repair application. MACER uses powerful yet inexpensive learning techniques such as multi-label classifiers and rankers to first identify the type of repair required and then apply the suggested repair. Experiments indicate that this fine-grained approach offers not only superior error …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:hqOjcs7Dif8C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2020,"We provide the first global model recovery results for the IRLS (iteratively reweighted least squares) heuristic for robust regression problems. IRLS is known to offer excellent performance, despite bad initializations and data corruption, for several parameter estimation problems. Existing analyses of IRLS frequently require careful initialization, thus offering only local convergence guarantees. We remedy this by proposing augmentations to the basic IRLS routine that not only offer guaranteed global recovery, but in practice also outperform state-of-the-art algorithms for robust regression. Our routines are more immune to hyperparameter misspecification in basic regression tasks, as well as applied tasks such as linear-armed bandit problems. Our theoretical analyses rely on a novel extension of the notions of strong convexity and smoothness to weighted strong convexity and smoothness, and establishing that sub-Gaussian designs offer bounded weighted condition numbers. These notions may be useful in analyzing other algorithms as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:u5HHmVD_uO8C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2020,"Mass public quarantining, colloquially known as a lock-down, is a non-pharmaceutical intervention to check spread of disease. This paper presents ESOP (Epidemiologically and Socio-economically Optimal Policies), a novel application of active machine learning techniques using Bayesian optimization, that interacts with an epidemiological model to arrive at lock-down schedules that optimally balance public health benefits and socio-economic downsides of reduced economic activity during lock-down periods. The utility of ESOP is demonstrated using case studies with VIPER (Virus-Individual-Policy-EnviRonment), a stochastic agent-based simulator that this paper also proposes. However, ESOP is flexible enough to interact with arbitrary epidemiological simulators in a black-box manner, and produce schedules that involve multiple phases of lock-downs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:ULOm3_A8WrAC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2019,"Extreme classification seeks to assign each data point, the most relevant labels from a universe of a million or more labels. This task is faced with the dual challenge of high precision and scalability, with millisecond level prediction times being a benchmark. We propose DEFRAG, an adaptive feature agglomeration technique to accelerate extreme classification algorithms. Despite past works on feature clustering and selection, DEFRAG distinguishes itself in being able to scale to millions of features, and is especially beneficial when feature sets are sparse, which is typical of recommendation and multi-label datasets. The method comes with provable performance guarantees and performs efficient task-driven agglomeration to reduce feature dimensionalities by an order of magnitude or more. Experiments show that DEFRAG can not only reduce training and prediction times of several leading extreme classification algorithms by as much as 40%, but also be used for feature reconstruction to address the problem of missing features, as well as offer superior coverage on rare labels.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:Se3iqnhoufwC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2019,"We present algorithms for solving multi-armed and linear-contextual bandit tasks in the face of adversarial corruptions in the arm responses. Traditional algorithms for solving these problems assume that nothing but mild, e.g., i.i.d. sub-Gaussian, noise disrupts an otherwise clean estimate of the utility of the arm. This assumption and the resulting approaches can fail catastrophically if there is an observant adversary that corrupts even a small fraction of the responses generated when arms are pulled. To rectify this, we propose algorithms that use recent advances in robust statistical estimation to perform arm selection in polynomial time. Our algorithms are easy to implement and vastly outperform several existing UCB and EXP-style algorithms for stochastic and adversarial multi-armed and linear-contextual bandit problems in wide variety of experimental settings. Our algorithms enjoy minimax-optimal regret …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:UebtZRa9Y70C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2018,"We present a class of algorithms capable of directly training deep neural networks with respect to popular families of task-specific performance measures for binary classification such as the F-measure, QMean and the Kullback–Leibler divergence that are structured and non-decomposable. Our goal is to address tasks such as label-imbalanced learning and quantification. Our techniques present a departure from standard deep learning techniques that typically use squared or cross-entropy loss functions (that are decomposable) to train neural networks. We demonstrate that directly training with task-specific loss functions yields faster and more stable convergence across problems and datasets. Our proposed algorithms and implementations offer several advantages including (i) the use of fewer training samples to achieve a desired level of convergence, (ii) a substantial reduction in training time, (iii) a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:KlAtU1dfN6UC,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2018,"Compile-time errors pose a major learning hurdle for students of introductory programming courses. Compiler error messages, while accurate, are targeted at seasoned programmers, and seem cryptic to beginners. In this work, we address this problem of pedagogically-inspired program repair and report TRACER (Targeted RepAir of Compilation ERrors), a system for performing repairs on compilation errors, aimed at introductory programmers.
TRACER invokes a novel combination of tools from programming language theory and deep learning and offers repairs that not only enable successful compilation, but repairs that are very close to those actually performed by students on similar errors. The ability to offer such targeted corrections, rather than just code that compiles, makes TRACER more relevant in offering real-time feedback to students in lab or tutorial sessions, as compared to existing works that merely …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:IjCSPb-OGe4C,https://www.cse.iitk.ac.in/users/purushot/
Purushottam Kar,"['Optimization', 'Learning Theory', 'Machine Learning']",19,2496,2018,"Hierarchical classification is supervised multi-class classification problem over the set of class labels organized according to a hierarchy. In this report, we study the work by Ramaswamy et. al. on hierarchical classification over symmetric tree distance loss. We extend the consistency of hierarchical classification algorithm over asymmetric tree distance loss. We design a algorithm to find Bayes optimal classification for a k-ary tree as a hierarchy. We show that under reasonable assumptions over asymmetric loss function, the Bayes optimal classification over this asymmetric loss can be found in . We exploit this insight and attempt to extend the Ova-Cascade algorithm \citet{ramaswamy2015convex} for hierarchical classification over the asymmetric loss.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=MNXz0AoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=MNXz0AoAAAAJ:u-x6o8ySG0sC,https://www.cse.iitk.ac.in/users/purushot/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2023,"Vision transformers have been applied successfully for image recognition tasks. There have been either multi-headed self-attention based (ViT \cite{dosovitskiy2020image}, DeIT, \cite{touvron2021training}) similar to the original work in textual models or more recently based on spectral layers (Fnet\cite{lee2021fnet}, GFNet\cite{rao2021global}, AFNO\cite{guibas2021efficient}). We hypothesize that both spectral and multi-headed attention plays a major role. We investigate this hypothesis through this work and observe that indeed combining spectral and multi-headed attention layers provides a better transformer architecture. We thus propose the novel Spectformer architecture for transformers that combines spectral and multi-headed attention layers. We believe that the resulting representation allows the transformer to capture the feature representation appropriately and it yields improved performance over other transformer representations. For instance, it improves the top-1 accuracy by 2\% on ImageNet compared to both GFNet-H and LiT. SpectFormer-S reaches 84.25\% top-1 accuracy on ImageNet-1K (state of the art for small version). Further, Spectformer-L achieves 85.7\% that is the state of the art for the comparable base version of the transformers. We further ensure that we obtain reasonable results in other scenarios such as transfer learning on standard datasets such as CIFAR-10, CIFAR-100, Oxford-IIIT-flower, and Standford Car datasets. We then investigate its use in downstream tasks such of object detection and instance segmentation on the MS-COCO dataset and observe that Spectformer shows consistent performance that is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:1tZ8xJnm2c8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2023,"Hierarchical reinforcement learning is a promising approach that uses temporal abstraction to solve complex long horizon problems. However, simultaneously learning a hierarchy of policies is unstable as it is challenging to train higher-level policy when the lower-level primitive is non-stationary. In this paper, we propose a novel hierarchical algorithm by generating a curriculum of achievable subgoals for evolving lower-level primitives using reinforcement learning and imitation learning. The lower level primitive periodically performs data relabeling on a handful of expert demonstrations using our primitive informed parsing approach. We provide expressions to bound the sub-optimality of our method and develop a practical algorithm for hierarchical reinforcement learning. Since our approach uses a handful of expert demonstrations, it is suitable for most robotic control tasks. Experimental evaluation on complex maze navigation and robotic manipulation environments show that inducing hierarchical curriculum learning significantly improves sample efficiency, and results in efficient goal conditioned policies for solving temporally extended tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:kJDgFkosVoMC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2023,"We present READ Avatars, a 3D-based approach for generating 2D avatars that are driven by audio input with direct and granular control over the emotion. Previous methods are unable to achieve realistic animation due to the many-to-many nature of audio to expression mappings. We alleviate this issue by introducing an adversarial loss in the audio-to-expression generation process. This removes the smoothing effect of regression-based models and helps to improve the realism and expressiveness of the generated avatars. We note furthermore, that audio should be directly utilized when generating mouth interiors and that other 3D-based methods do not attempt this. We address this with audio-conditioned neural textures, which are resolution-independent. To evaluate the performance of our method, we perform quantitative and qualitative experiments, including a user study. We also propose a new metric for comparing how well an actor's emotion is reconstructed in the generated avatar. Our results show that our approach outperforms state of the art audio-driven avatar generation methods across several metrics. A demo video can be found at \url{https://youtu.be/QSyMl3vV0pA}",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:wE-fMHVdjMkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2023,"Despite rapid advancements in lifelong learning (LLL) research, a large body of research mainly focuses on improving the performance in the existing \textit{static} continual learning (CL) setups. These methods lack the ability to succeed in a rapidly changing \textit{dynamic} environment, where an AI agent needs to quickly learn new instances in a `single pass' from the non-i.i.d (also possibly temporally contiguous/coherent) data streams without suffering from catastrophic forgetting. For practical applicability, we propose a novel lifelong learning approach, which is streaming, i.e., a single input sample arrives in each time step, single pass, class-incremental, and subject to be evaluated at any moment. To address this challenging setup and various evaluation protocols, we propose a Bayesian framework, that enables fast parameter update, given a single training example, and enables any-time inference. We additionally propose an implicit regularizer in the form of snap-shot self-distillation, which effectively minimizes the forgetting further. We further propose an effective method that efficiently selects a subset of samples for online memory rehearsal and employs a new replay buffer management scheme that significantly boosts the overall performance. Our empirical evaluations and ablations demonstrate that the proposed method outperforms the prior works by large margins.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:zdjWy_NXXwUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2023,"Talking-face video generation works have achieved state-of-the-art results in synthesizing videos with lip synchronization. However, most of the previous works deal with low-resolution talking-face videos (up to 256x256 pixels), thus, generating extremely high-resolution videos still remains a challenge. We take a giant leap in this work and propose a novel method to synthesize talking-face videos at resolutions as high as 4K! Our task presents several key challenges:(i) Scaling the existing methods to such high resolutions is resource-constrained, both in terms of compute and the availability of very high-resolution datasets,(ii) The synthesized videos need to be spatially and temporally coherent. The sheer number of pixels that the model needs to generate while maintaining the temporal consistency at the video level makes this task non-trivial and has never been attempted before in literature. To address these issues, we propose to train the lip-sync generator in a compact Vector Quantized (VQ) space for the first time. Our core idea to encode the faces in a compact 16x16 representation allows us to model high-resolution videos. In our framework, we learn the lip movements in the quantized space on the newly collected 4K Talking Faces (4KTF) dataset. Our approach is speaker agnostic and can handle various languages and voices. We benchmark our technique against several competitive works and show that we can achieve a remarkable 64-times more pixels than the current state-of-the-art! Our supplementary demo video depicts additional qualitative results, comparisons, and several real-world applications, like professional movie editing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:X9ykpCP0fEIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2023,"This work proposes a novel method to generate realistic talking head videos using audio and visual streams. We animate a source image by transferring head motion from a driving video using a dense motion field generated using learnable keypoints. We improve the quality of lip sync using audio as an additional input, helping the network to attend to the mouth region. We use additional priors using face segmentation and face mesh to improve the structure of the reconstructed faces. Finally, we improve the visual quality of the generations by incorporating a carefully designed identity-aware generator module. The identity-aware generator takes the source image and the warped motion features as input to generate a high-quality output with fine-grained details. Our method produces state-of-the-art results and generalizes well to unseen faces, languages, and voices. We comprehensively evaluate our approach using multiple metrics and outperforming the current techniques both qualitative and quantitatively. Our work opens up several applications, including enabling low bandwidth video calls. We release a demo video and additional information at http://cvit. iiit. ac. in/research/projects/cvit-projects/avfr",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:qwy9JoKyICEC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2023,"Many people with some form of hearing loss consider lipreading as their primary mode of day-to-day communication. However, finding resources to learn or improve one's lipreading skills can be challenging. This is further exacerbated in the COVID19 pandemic due to restrictions on direct interactions with peers and speech therapists. Today, online MOOCs platforms like Coursera and Udemy have become the most effective form of training for many types of skill development. However, online lipreading resources are scarce as creating such resources is an extensive process needing months of manual effort to record hired actors. Because of the manual pipeline, such platforms are also limited in vocabulary, supported languages, accents, and speakers and have a high usage cost. In this work, we investigate the possibility of replacing real human talking videos with synthetically generated videos. Synthetic data can easily incorporate larger vocabularies, variations in accent, and even local languages and many speakers. We propose an end-to-end automated pipeline to develop such a platform using state-of-the-art talking head video generator networks, text-to-speech models, and computer vision techniques. We then perform an extensive human evaluation using carefully thought out lipreading exercises to validate the quality of our designed platform against the existing lipreading platforms. Our studies concretely point toward the potential of our approach in developing a large-scale lipreading MOOC platform that can impact millions of people with hearing loss.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:8Xgff_V0N9gC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2023,"Doubles play an indispensable role in the movie industry. They take the place of the actors in dangerous stunt scenes or scenes where the same actor plays multiple characters. The double's face is later replaced with the actor's face and expressions manually using expensive CGI technology, costing millions of dollars and taking months to complete. An automated, inexpensive, and fast way can be to use face-swapping techniques that aim to swap an identity from a source face video (or an image) to a target face video. However, such methods cannot preserve the source expressions of the actor important for the scene's context. To tackle this challenge, we introduce video-to-video (V2V) face-swapping, a novel task of face-swapping that can preserve (1) the identity and expressions of the source (actor) face video and (2) the background and pose of the target (double) video. We propose FaceOff, a V2V face-swapping system that operates by learning a robust blending operation to merge two face videos following the constraints above. It reduces the videos to a quantized latent space and then blends them in the reduced space. FaceOff is trained in a self-supervised manner and robustly tackles the non-trivial challenges of V2V face-swapping. As shown in the experimental section, FaceOff significantly outperforms alternate approaches qualitatively and quantitatively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:Xz60mAmATU4C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"In this paper, we aim to obtain improved attention for a visual question answering (VQA) task. It is challenging to provide supervision for attention. An observation we make is that visual explanations as obtained through class activation mappings (specifically Grad-CAM) that are meant to explain the performance of various networks could form a means of supervision. However, as the distributions of attention maps and that of Grad-CAMs differ, it would not be suitable to directly use these as a form of supervision. Rather, we propose the use of a discriminator that aims to distinguish samples of visual explanation and attention maps. The use of adversarial training of the attention regions as a two-player game between attention and explanation serves to bring the distributions of attention maps and visual explanations closer. Significantly, we observe that providing such a means of supervision also results in attention …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:DyXnQzXoVgIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"In the task incremental learning problem, deep learning models suffer from catastrophic forgetting of previously seen classes/tasks as they are trained on new classes/tasks. This problem becomes even harder when some of the test classes do not belong to the training class set, i.e., the task incremental generalized zero-shot learning problem. We propose a novel approach to address the task incremental learning problem for both the non zero-shot and zero-shot settings. Our proposed approach, called Rectification-based Knowledge Retention (RKR), applies weight rectifications and affine transformations for adapting the model to any task. During testing, our approach can use the task label information (task-aware) to quickly adapt the network to that task. We also extend our approach to make it task-agnostic so that it can work even when the task label information is not available during testing. Specifically, given a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:27LrP4qxOz0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Generating videos is a complex task that is accomplished by generating a set of temporally coherent images frame-by-frame. This limits the expressivity of videos to only image-based operations on the individual video frames needing network designs to obtain temporally coherent trajectories in the underlying image space. We propose INR-V, a video representation network that learns a continuous space for video-based generative tasks. INR-V parameterizes videos using implicit neural representations (INRs), a multi-layered perceptron that predicts an RGB value for each input pixel location of the video. The INR is predicted using a meta-network which is a hypernetwork trained on neural representations of multiple video instances. Later, the meta-network can be sampled to generate diverse novel videos enabling many downstream video-based generative tasks. Interestingly, we find that conditional regularization and progressive weight initialization play a crucial role in obtaining INR-V. The representation space learned by INR-V is more expressive than an image space showcasing many interesting properties not possible with the existing works. For instance, INR-V can smoothly interpolate intermediate videos between known video instances (such as intermediate identities, expressions, and poses in face videos). It can also in-paint missing portions in videos to recover temporally coherent full videos. In this work, we evaluate the space learned by INR-V on diverse generative tasks such as video interpolation, novel video generation, video inversion, and video inpainting against the existing baselines. INR-V significantly outperforms the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:-DxkuPiZhfEC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"In this work, we address the problem of generating speech from silent lip videos for any speaker in the wild. In stark contrast to previous works, our method (i) is not restricted to a fixed number of speakers, (ii) does not explicitly impose constraints on the domain or the vocabulary and (iii) deals with videos that are recorded in the wild as opposed to within laboratory settings. The task presents a host of challenges, with the key one being that many features of the desired target speech, like voice, pitch and linguistic content, cannot be entirely inferred from the silent face video. In order to handle these stochastic variations, we propose a new VAE-GAN architecture that learns to associate the lip and speech sequences amidst the variations. With the help of multiple powerful discriminators that guide the training process, our generator learns to synthesize speech sequences in any voice for the lip movements of any person …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:2v_ZtQDX9iAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"In this paper, we explore an interesting question of what can be obtained from an 8x8 pixel video sequence. Surprisingly, it turns out to be quite a lot. We show that when we process this 8x8 video with the right set of audio and image priors, we can obtain a full-length, 256x256 video. We achieve this 32x scaling of an extremely low-resolution input using our novel audio-visual upsampling network. The audio prior helps to recover the elemental facial details and precise lip shapes and a single high-resolution target identity image prior provides us with rich appearance details. Our approach is an end-to-end multi-stage framework. The first stage produces a coarse intermediate output video that can be then used to animate single target identity image and generate realistic, accurate and high-quality outputs. Our approach is simple and performs exceedingly well (an 8x improvement in FID score) compared to previous …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:qe6vwMD2xtsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"We leverage the modern advancements in talking head generation to propose an end-to-end system for talking head video compression. Our algorithm transmits pivot frames intermittently while the rest of the talking head video is generated by animating them. We use a state-of-the-art face reenactment network to detect key points in the non-pivot frames and transmit them to the receiver. A dense flow is then calculated to warp a pivot frame to reconstruct the non-pivot ones. Transmitting key points instead of full frames leads to significant compression. We propose a novel algorithm to adaptively select the best-suited pivot frames at regular intervals to provide a smooth experience. We also propose a frame-interpolater at the receiver's end to improve the compression levels further. Finally, a face enhancement network improves reconstruction quality, significantly improving several aspects like the sharpness of the generations. We evaluate our method both qualitatively and quantitatively on benchmark datasets and compare it with multiple compression techniques. We release a demo video and additional information at https://cvit.iiit.ac.in/research/projects/cvit-projects/talking-video-compression.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:hSRAE-fF4OAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Keyword Spotting (KWS) detects a set of pre-defined spo ken keywords. Building a KWS system for an arbitrary set re quires massive training datasets. We propose to use the text transcripts from an Automatic Speech Recognition (ASR) sys tem alongside triplets for KWS training. The intermediate rep resentation from the ASR system trained on a speech corpus is used as acoustic word embeddings for keywords. Triplet loss is added to the Connectionist Temporal Classification (CTC) loss in the ASR while training. This method achieves an Average Precision (AP) of 0.843 over 344 words unseen by the model trained on the TIMIT dataset. In contrast, the Multi-View re current method that learns jointly on the text and acoustic em beddings achieves only 0.218 for out-of-vocabulary words. This method is also applied to low-resource languages such as Tamil by converting Tamil characters to English using transliteration. This is a very challenging novel task for which we provide a dataset of transcripts for the keywords. Despite our model not generalizing well, we achieve a benchmark AP of 0.321 on over 38 words unseen by the model on the MSWC Tamil keyword set. The model also produces an accuracy of 96.2% for classifi cation tasks on the Google Speech Commands dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:g5Ck-dwhA_QC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Understanding the lip movement and inferring the speech from it is notoriously difficult for the common person. The task of accurate lip-reading gets help from various cues of the speaker and its contextual or environmental setting. Every speaker has a different accent and speaking style, which can be inferred from their visual and speech features. This work aims to understand the correlation/mapping between speech and the sequence of lip movement of individual speakers in an unconstrained and large vocabulary. We model the frame sequence as a distribution of features from the transformer in an autoencoder setting and learn the embeddings jointly that exploits temporal properties of both audio and video. We learn temporal synchronization using deep metric learning, which guides the decoder to generate speech in sync with input lip movements. The predictive posterior thus gives us the generated speech in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:silx2ntsSuwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Shopping experience on any e-commerce website is largely driven by the content customers interact with. The large volume of diverse content on e-commerce platforms, and the advances in machine learning, pose unique opportunities for gathering insights through content understanding and applying these insights to generate content better shopper experience. The purpose of the first edition of this workshop was to bring together researchers from industry and academia on questions surrounding e-commerce content understanding and generation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:CYCckWUYoCcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"A processor-implemented method for generating a lip-sync for a face to a target speech of a live session to a speech in one or more languages in-sync with improved visual quality using a machine learning model and a pre-trained lip-sync model is provided. The method includes (i) determining a visual representation of the face and an audio representation, the visual representation includes crops of the face;(ii) modifying the crops of the face to obtain masked crops;(iii) obtaining a reference frame from the visual representation at a second timestamp;(iv) combining the masked crops at the first timestamp with the reference to obtain lower half crops;(v) training the machine learning model by providing historical lower half crops and historical audio representations as training data;(vi) generating lip-synced frames for the face to the target speech, and (vii) generating an in-sync lip-synced frames by the pre-trained lip …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:SIv7DqKytYAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Bias mitigation in machine learning models is imperative, yet challenging. While several approaches have been proposed, one view towards mitigating bias is through adversarial learning. A discriminator is used to identify the bias attributes such as gender, age or race in question. This discriminator is used adversarially to ensure that it cannot distinguish the bias attributes. The main drawback in such a model is that it directly introduces a trade-off with accuracy as the features that the discriminator deems to be sensitive for discrimination of bias could be correlated with classification. In this work we solve the problem. We show that a biased discriminator can actually be used to improve this bias-accuracy tradeoff. Specifically, this is achieved by using a feature masking approach using the discriminator's gradients. We ensure that the features favoured for the bias discrimination are de-emphasized and the unbiased features are enhanced during classification. We show that this simple approach works well to reduce bias as well as improve accuracy significantly. We evaluate the proposed model on standard benchmarks. We improve the accuracy of the adversarial methods while maintaining or even improving the unbiasness and also outperform several other recent methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:k_7cPK9k7w8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Many real-life problem settings have classes of data with very few examples for training. Deep learning networks do not perform well for such few-shot classes. In order to perform well in this setting, the networks should learn to extract highly discriminative and generic features. In this paper, we propose to use a composite rotation based self-supervised auxiliary task to improve the representation learning of the network so that it can extract such discriminative features. Our proposed composite rotation based auxiliary task rotates the image at two levels, i.e., it rotates patches inside the image (inner rotation) and also rotates the whole image (outer rotation), and assigns one out of 16 rotation classes to the transformed image. We jointly train the network on the main image classification task and the composite rotation based auxiliary task. This helps the network to learn to extract more generic and discriminative features …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:LXmCCkuhhTsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Lipreading is a difficult task, even for humans. And synthesizing the original speech waveform from lipreading makes it even a more challenging problem. Towards this end, we present a deep learning framework that can be trained end-to-end to learn the mapping between the auditory and visual signals. In particular, in this paper, our interest is to design a model that can efficiently predict the speech signal in a given silent talking-face video. The proposed framework generates a speech signal by mapping the video frames in a sequence of feature vectors. However, unlike some recent methods that adopt a sequence-to-sequence approach for translation from the frame stream to the audio stream, we posit it as an analogy learning problem between the two modalities. In which each frame is mapped to the corresponding speech segment via a deep audio-visual analogy framework. We predict plausible audio stream …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:Xl6nMSl579sC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Convolutional layers convolve the input feature maps to generate valuable output features, and they help deep learning methods significantly in solving complex problems. In order to tackle problems efficiently, deep learning solutions should ensure that the parameters of the model do not increase significantly with the complexity of the problem. Pointwise convolutions are primarily used for parameter reduction in many deep learning architectures. They are convolutional filters of kernel size 1× 1. The pointwise convolution, however, ignores the spatial information around the points it is processing. This design is by choice, in order to reduce the overall parameters and computations. However, we hypothesize that this shortcoming of pointwise convolution has a significant impact on network performance. We propose a novel alternative design for pointwise convolution, which uses spatial information from the input …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:SnGPuo6Feq8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Visual Question Answering can be a functionally relevant task if purposed as such. In this paper, we aim to investigate and evaluate its efficacy in terms of localization-based question answering. We do this specifically in the context of autonomous driving where this functionality is important. To achieve our aim, we provide a new dataset, Auto-QA. Our new dataset is built over the Argoverse dataset and provides a truly multi-modal setting with seven views per frame and point-cloud LIDAR data being available for answering a localization-based question. We contribute localized attention adaptations of most popular VQA baselines and evaluate them on this task. We also provide joint point-cloud and image-based baselines that perform well on this task. An additional evaluation that we perform is to analyse whether the attention module is accurate or not for the image-based VQA baselines. To summarize, through this work we thoroughly analyze the localization abilities through visual question answering for autonomous driving and provide a new benchmark task for the same. Our best joint baseline model achieves a useful 74.8% accuracy on this task. We release our dataset and source code for our baseline modules in the following webpage:\url https://temporaryprojectpage. github. io/AUTO-QA/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:UuEBAcK4md4C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"In this paper, we investigate the task of Video-based Question Answering. We provide a diagnostic dataset that can be used to evaluate the extent of the reasoning abilities of various methods for solving this task. Previous datasets proposed for this task do not have this ability. Our dataset is large scale (around 1.3 million questions jointly for train and test) and evaluates both the spatial and temporal properties and the relationship between various objects for these properties. We evaluate the state-of-the-art language model (BERT) as a baseline to understand the extent of correlation based on language features alone. Other existing networks are then used to combine video features along with language features for solving this task. Unfortunately, we observe that the currently prevalent systems do not perform significantly better than the language baseline. We hypothesize that this is due to our efforts in ensuring that no obvious biases exist in this dataset and the dataset is balanced. To make progress, the learning techniques need to obtain an ability to reason, going beyond basic correlation of biases. This is an interesting and significant challenge provided through our work.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:65Yg0jNCQDAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2022,"Deep learning models generally learn the biases present in the training data. Researchers have proposed several approaches to mitigate such biases and make the model fair. Bias mitigation techniques assume that a sufficiently large number of training examples are present. However, we observe that if the training data is limited, then the effectiveness of bias mitigation methods is severely degraded. In this paper, we propose a novel approach to address this problem. Specifically, we adapt self-supervision and self-distillation to reduce the impact of biases on the model in this setting. Self-supervision and self-distillation are not used for bias mitigation. However, through this work, we demonstrate for the first time that these techniques are very effective in bias mitigation. We empirically show that our approach can significantly reduce the biases learned by the model. Further, we experimentally demonstrate that our approach is complementary to other bias mitigation strategies. Our approach significantly improves their performance and further reduces the model biases in the limited data regime. Specifically, on the L-CIFAR-10S skewed dataset, our approach significantly reduces the bias score of the baseline model by 78.22% and outperforms it in terms of accuracy by a significant absolute margin of 8.89%. It also significantly reduces the bias score for the state-of-the-art domain independent bias mitigation method by 59.26% and improves its performance by a significant absolute margin of 7.08%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:pS0ncopqnHgC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Communication with the deaf community relies profoundly on the interpretation of sign languages performed by the signers. In light of the recent breakthroughs in sign language translations, we propose a pipeline that we term ""Translating Sign Language Videos to Talking Faces"". In this context, we improve the existing sign language translation systems by using POS tags to improve language modeling. We further extend the challenge to develop a system that can interpret a video from a signer to an avatar speaking in spoken languages. We focus on the translation systems that attempt to translate sign languages to text without glosses, an expensive annotation form. We critically analyze two state-of-the-art architectures, and based on their limitations, we improvise the systems. We propose a two-stage approach to translate sign language into intermediate text followed by a language model to get the final …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:PkcyUWeTMh0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"This paper proposes a video editor based on OpenShot with several state-of-the-art facial video editing algorithms as added functionalities. Our editor provides an easy-to-use interface to apply modern lip-syncing algorithms interactively. Apart from lip-syncing, the editor also uses audio and facial re-enactment to generate expressive talking faces. The manual control improves the overall experience of video editing without missing out on the benefits of modern synthetic video generation algorithms. This control enables us to lip-sync complex dubbed movie scenes, interviews, television shows, and other visual content. Furthermore, our editor provides features that automatically translate lectures from spoken content, lip-sync of the professor, and background content like slides. While doing so, we also tackle the critical aspect of synchronizing background content with the translated speech. We qualitatively evaluate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:HJSXoJQnj-YC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Lipreading or visually recognizing speech from the mouth movements of a speaker is a challenging and mentally taxing task. Unfortunately, multiple medical conditions force people to depend on this skill in their day-to-day lives for essential communication. Patients suffering from Amyotrophic Lateral Sclerosis (ALS) often lose muscle control, consequently their ability to generate speech and communicate via lip movements. Existing large datasets do not focus on medical patients or curate personalized vocabulary relevant to an individual. Collecting a large-scale dataset of a patient, needed to train mod-ern data-hungry deep learning models is, however, extremely challenging. In this work, we propose a personalized network to lipread an ALS patient using only one-shot examples. We depend on synthetically generated lip movements to augment the one-shot scenario. A Variational Encoder based domain adaptation technique is used to bridge the real-synthetic domain gap. Our approach significantly improves and achieves high top-5accuracy with 83.2% accuracy compared to 62.6% achieved by comparable methods for the patient. Apart from evaluating our approach on the ALS patient, we also extend it to people with hearing impairment relying extensively on lip movements to communicate.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:rbm3iO8VlycC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Generating natural questions from an image is a semantic task that requires using vision and language modalities to learn multimodal representations. Images can have multiple visual and language cues such as places, captions, and tags. In this paper, we propose a principled deep Bayesian learning framework that combines these cues to produce natural questions. We observe that with the addition of more cues and by minimizing uncertainty in the among cues, the Bayesian network becomes more confident. We propose a Minimizing Uncertainty of Mixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues experts for generating probabilistic questions. This is a Bayesian framework and the results show a remarkable similarity to natural questions as validated by a human study. Ablation studies of our model indicate that a subset of cues is inferior at this task and hence the principled fusion …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:69ZgNCALVd0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"A wide variety of methods have been developed to enable lifelong learning in conventional deep neural networks. However, to succeed, these methods require a `batch' of samples to be available and visited multiple times during training. While this works well in a static setting, these methods continue to suffer in a more realistic situation where data arrives in \emph{online streaming manner}. We empirically demonstrate that the performance of current approaches degrades if the input is obtained as a stream of data with the following restrictions: each instance comes one at a time and can be seen only once, and the input data violates the i.i.d assumption, i.e., there can be a class-based correlation. We propose a novel approach (CIOSL) for the class-incremental learning in an \emph{online streaming setting} to address these challenges. The proposed approach leverages implicit and explicit dual weight regularization and experience replay. The implicit regularization is leveraged via the knowledge distillation, while the explicit regularization incorporates a novel approach for parameter regularization by learning the joint distribution of the buffer replay and the current sample. Also, we propose an efficient online memory replay and replacement buffer strategy that significantly boosts the model's performance. Extensive experiments and ablation on challenging datasets show the efficacy of the proposed method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:wvYxNZNCP7wC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Adaptation of a classifier to new domains is one of the challenging problems in machine learning. This has been addressed using many deep and non-deep learning based methods. Among the methodologies used, that of adversarial learning is widely applied to solve many deep learning problems along with domain adaptation. These methods are based on a discriminator that ensures source and target distributions are close. However, here we suggest that rather than using a point estimate obtaining by a single discriminator, it would be useful if a distribution based on ensembles of discriminators could be used to bridge this gap. This could be achieved using multiple classifiers or using traditional ensemble methods. In contrast, we suggest that a Monte Carlo dropout based ensemble discriminator could suffice to obtain the distribution based discriminator. Specifically, we propose a curriculum based dropout …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:EPG8bYD4jVwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Normalizing flows provide an elegant method for obtaining tractable density estimates from distributions by using invertible transformations. The main challenge is to improve the expressivity of the models while keeping the invertibility constraints intact. We propose to do so via the incorporation of localized self-attention. However, conventional self-attention mechanisms don't satisfy the requirements to obtain invertible flows and can't be naively incorporated into normalizing flows. To address this, we introduce a novel approach called Attentive Contractive Flow (ACF) which utilizes a special category of flow-based generative models - contractive flows. We demonstrate that ACF can be introduced into a variety of state of the art flow models in a plug-and-play manner. This is demonstrated to not only improve the representation power of these models (improving on the bits per dim metric), but also to results in significantly faster convergence in training them. Qualitative results, including interpolations between test images, demonstrate that samples are more realistic and capture local correlations in the data well. We evaluate the results further by performing perturbation analysis using AWGN demonstrating that ACF models (especially the dot-product variant) show better and more consistent resilience to additive noise.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:DrR-2ekChdkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"We aim to solve the highly challenging task of generating continuous sign language videos solely from speech segments for the first time. Recent efforts in this space have focused on generating such videos from human-annotated text transcripts without considering other modalities. However, replacing speech with sign language proves to be a practical solution while communicating with people suffering from hearing loss. Therefore, we eliminate the need of using text as input and design techniques that work for more natural, continuous, freely uttered speech covering an extensive vocabulary. Since the current datasets are inadequate for generating sign language directly from speech, we collect and release the first Indian sign language dataset comprising speech-level annotations, text transcripts, and the corresponding sign-language videos. Next, we propose a multi-tasking transformer network trained to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:TlpoogIpr_IC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Objectives
To study whether a trained convolutional neural network (CNN) can be of assistance to radiologists in differentiating Coronavirus disease (COVID)–positive from COVID-negative patients using chest X-ray (CXR) through an ambispective clinical study. To identify subgroups of patients where artificial intelligence (AI) can be of particular value and analyse what imaging features may have contributed to the performance of AI by means of visualisation techniques.
Methods
CXR of 487 patients were classified into [4] categories—normal, classical COVID, indeterminate, and non-COVID by consensus opinion of 2 radiologists. CXR which were classified as “normal” and “indeterminate” were then subjected to analysis by AI, and final categorisation provided as guided by prediction of the network. Precision and recall of the radiologist alone and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:ziOE8S1-AIUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"This work studies the long-standing problems of model capacity and negative interference in multilingual neural machine translation MNMT. We use network pruning techniques and observe that pruning 50-70% of the parameters from a trained MNMT model results only in a 0.29-1.98 drop in the BLEU score. Suggesting that there exist large redundancies even in MNMT models. These observations motivate us to use the redundant parameters and counter the interference problem efficiently. We propose a novel adaptation strategy, where we iteratively prune and retrain the redundant parameters of an MNMT to improve bilingual representations while retaining the multilinguality. Negative interference severely affects high resource languages, and our method alleviates it without any additional adapter modules. Hence, we call it parameter-free adaptation strategy, paving way for the efficient adaptation of MNMT. We demonstrate the effectiveness of our method on a 9 language MNMT trained on TED talks, and report an average improvement of +1.36 BLEU on high resource pairs. Code will be released here.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:mWEH9CqjF64C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Generative adversarial networks (GANs) are very popular to generate realistic images, but they often suffer from the training instability issues and the phenomenon of mode loss. In order to attain greater diversity in GAN synthesized data, it is critical to solving the problem of mode loss. Our work explores probabilistic approaches to GAN modelling that could allow us to tackle these issues. We present Prb-GANs, a new variation that uses dropout to create a distribution over the network parameters with the posterior learnt using variational inference. We describe theoretically and validate experimentally using simple and complex datasets the benefits of such an approach. We look into further improvements using the concept of uncertainty measures. Through a set of further modifications to the loss functions for each network of the GAN, we are able to get results that show the improvement of GAN performance. Our methods are extremely simple and require very little modification to existing GAN architecture.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:QUX0mv85b1cC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Understanding unsupervised domain adaptation has been an important task that has been well explored. However, the wide variety of methods have not analyzed the role of a classifier's performance in detail. In this paper, we thoroughly examine the role of a classifier in terms of matching source and target distributions. We specifically investigate the classifier ability by matching a) the distribution of features, b) probabilistic uncertainty for samples and c) certainty activation mappings. Our analysis suggests that using these three distributions does result in a consistently improved performance on all the datasets. Our work thus extends present knowledge on the role of the various distributions obtained from the classifier towards solving unsupervised domain adaptation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:rTD5ala9j4wC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"In this paper, we consider the problem of domain adaptation for multi-class classification, where we are provided a labeled set of examples in a source dataset and target dataset with no supervision. We tackle the mode collapse problem in adapting the classifier across domains. In this setting, we propose an adversarial learning-based approach using an informative discriminator. Our observation relies on the analysis that shows if the discriminator has access to all the information available, including the class structure present in the source dataset, then it can guide the transformation of features of the target set of classes to a more structured adapted space. Further, by training the informative discriminator using the more robust source samples, we are able to obtain better domain invariant features. Using this formulation, we achieve state-of-the-art results for the standard evaluation on benchmark datasets. We also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:kzcSZmkxUKAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"We aim to solve the highly challenging task of generating continuous sign language videos solely from speech segments for the first time. Recent efforts in this space have focused on generating such videos from human-annotated text transcripts without considering other modalities. However, replacing speech with sign language proves to be a practical solution while communicating with people suffering from hearing loss. Therefore, we eliminate the need of using text as input and design techniques that work for more natural, continuous, freely uttered speech covering an extensive vocabulary. Since the current datasets are inadequate for generating sign language directly from speech, we collect and release the first Indian sign language dataset comprising speech-level annotations, text transcripts, and the corresponding sign-language videos. Next, we propose a multi-tasking transformer network trained to generate signer's poses from speech segments. With speech-to-text as an auxiliary task and an additional cross-modal discriminator, our model learns to generate continuous sign pose sequences in an end-to-end manner. Extensive experiments and comparisons with other baselines demonstrate the effectiveness of our approach. We also conduct additional ablation studies to analyze the effect of different modules of our network. A demo video containing several results is attached to the supplementary material.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:eO3_k5sD8BwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"We propose a novel approach for class incremental online learning in a limited data setting. This problem setting is challenging because of the following constraints: (1) Classes are given incrementally, which necessitates a class incremental learning approach; (2) Data for each class is given in an online fashion, i.e., each training example is seen only once during training; (3) Each class has very few training examples; and (4) We do not use or assume access to any replay/memory to store data from previous classes. Therefore, in this setting, we have to handle twofold problems of catastrophic forgetting and overfitting. In our approach, we learn robust representations that are generalizable across tasks without suffering from the problems of catastrophic forgetting and overfitting to accommodate future classes with limited samples. Our proposed method leverages the meta-learning framework with knowledge consolidation. The meta-learning framework helps the model for rapid learning when samples appear in an online fashion. Simultaneously, knowledge consolidation helps to learn a robust representation against forgetting under online updates to facilitate future learning. Our approach significantly outperforms other methods on several benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:BrOSOlqYqPUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"There have been a number of techniques that have demonstrated the generation of multimedia data for one modality at a time using GANs, such as the ability to generate images, videos, and audio. However, so far, the task of multi-modal generation of data, specifically for audio and videos both, has not been sufficiently well-explored. Towards this, we propose a method that demonstrates that we are able to generate naturalistic samples of video and audio data by the joint correlated generation of audio and video modalities. The proposed method uses multiple discriminators to ensure that the audio, video, and the joint output are also indistinguishable from real-world samples. We present a dataset for this task and show that we are able to generate realistic samples. This method is validated using various standard metrics such as Inception Score, Frechet Inception Distance (FID) and through human evaluation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:kF1pexMAQbMC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Understanding the relationship between the auditory and visual signals is crucial for many different applications ranging from computer-generated imagery (CGI) and video editing automation to assisting people with hearing or visual impairments. However, this is challenging since the distribution of both audio and visual modality is inherently multi-modal. Therefore, most of the existing methods ignore the multimodal aspect and assume that there only exists a deterministic one-to-one mapping between the two modalities. It can lead to low-quality predictions as the model collapses to optimizing the average behavior rather than learning the full data distributions. In this paper, we present a stochastic model for generating speech in a silent video. The proposed model combines recurrent neural networks and variational deep generative models to learn the auditory signal’s conditional distribution given the visual signal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:O0nohqN1r9EC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"We propose a novel approach for class incremental online learning in a limited data setting. This problem setting is challenging because of the following constraints:(1) Classes are given incrementally, which necessitates a class incremental learning approach;(2) Data for each class is given in an online fashion, ie, each training example is seen only once during training;(3) Each class has very few training examples; and (4) We do not use or assume access to any replay/memory to store data from previous classes. Therefore, in this setting, we have to handle twofold problems of catastrophic forgetting and overfitting. In our approach, we learn robust representations that are generalizable across tasks without suffering from the problems of catastrophic forgetting and overfitting to accommodate future classes with limited samples. Our proposed method leverages the meta-learning framework with knowledge …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:An6A6Jpfc1oC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Many performance improvement techniques calibrate the outputs of convolutional layers to improve the performance of convolutional neural networks, e.g., Squeeze-and-Excitation Networks (SENets). These techniques train the network to extract calibration weights from the input itself. However, these methods increase the complexity of the model in order to perform calibration. We propose an approach to calibrate the outputs of convolutional layers efficiently. Specifically, we propose an architectural block called Accuracy Booster, which calibrates the convolutional layer outputs channel-wise while introducing minimal extra parameters and computation. We experimentally show that our approach achieves higher performance than existing calibration methods over several datasets and architectures while introducing lesser parameters than them. We also generalize our proposed block to calibrate the channel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:oi2SiIJ9l4AC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Music Genres serve as an important meta-data in the field of music information retrieval and have been widely used for music classification and analysis tasks. Visualizing these music genres can thus be helpful for music exploration, archival and recommendation. Probabilistic topic models have been very successful in modelling text documents. In this work, we visualize music genres using a probabilistic topic model. Unlike text documents, audio is continuous and needs to be sliced into smaller segments. We use simple MFCC features of these segments as musical words. We apply the topic model on the corpus and subsequently use the genre annotations of the data to interpret and visualize the latent space.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:7Hz3ACDFbsoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"In this paper, we propose a probabilistic framework for solving the task of ‘Visual Dialog’. Solving this task requires reasoning and understanding of visual modality, language modality, and common sense knowledge to answer. Various architectures have been proposed to solve this task by variants of multi-modal deep learning techniques that combine visual and language representations. However, we believe that it is crucial to understand and analyze the sources of uncertainty for solving this task. Our approach allows for estimating uncertainty and also aids a diverse generation of answers. The proposed approach is obtained through a probabilistic representation module that provides us with representations for image, question and conversation history, a module that ensures that diverse latent representations for candidate answers are obtained given the probabilistic representations and an uncertainty …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:IaI1MmNe2tcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Understanding and explaining deep learning models is an imperative task. Towards this, we propose a method that obtains gradient-based certainty estimates that also provide visual attention maps. Particularly, we solve for visual question answering task. We incorporate modern probabilistic deep learning methods that we further improve by using the gradients for these estimates. These have two-fold benefits: a) improvement in obtaining the certainty estimates that correlate better with misclassified samples and b) improved attention maps that provide state-of-the-art results in terms of correlation with human attention regions. The improved attention maps result in consistent improvement for various methods for visual question answering. Therefore, the proposed technique can be thought of as a tool for obtaining improved certainty estimates and explanations for deep learning models. We provide detailed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:-nhnvRiOwuoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"In this paper, we propose a method for obtaining sentence-level embeddings. While the problem of obtaining word-level embeddings is very well studied, we propose a novel method for obtaining sentence-level embeddings. This is obtained by a simple method in the context of solving the paraphrase generation task. If we use a sequential encoder-decoder model for generating paraphrase, we would like the generated paraphrase to be semantically close to the original sentence. One way to ensure this is by adding constraints for true paraphrase embeddings to be close and unrelated paraphrase candidate sentence embeddings to be far. This is ensured by using a sequential pair-wise discriminator that shares weights with the encoder. This discriminator is trained with a suitable loss function. Our loss function penalizes paraphrase sentence embedding distances from being too large. This loss is used in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:XUvXOeBm_78C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Indian language machine translation performance is hampered due to the lack of large scale multi-lingual sentence aligned corpora and robust benchmarks. Through this paper, we provide and analyse an automated framework to obtain such a corpus for Indian language neural machine translation (NMT) systems. Our pipeline consists of a baseline NMT system, a retrieval module, and an alignment module that is used to work with publicly available websites such as press releases by the government. The main contribution towards this effort is to obtain an incremental method that uses the above pipeline to iteratively improve the size of the corpus as well as improve each of the components of our system. Through our work, we also evaluate the design choices such as the choice of pivoting language and the effect of iterative incremental increase in corpus size. Our work in addition to providing an automated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:jE2MZjpN3IcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Abstract Knowledge distillation based deep model compression has been actively pursued in order to obtain improved performance on specified student architectures by distilling knowledge from deeper networks. Among various methods, attention based knowledge distillation has shown great promise on large datasets. However, this approach is limited by hand-designed attention functions such as absolute sum. We address this shortcoming by proposing trainable attention methods that can be used to obtain improved performance while distilling knowledge from teacher to student. We also show that, using dense connections efficiently between attention modules, we can further improve the student’s performance. Our approach, when applied to ResNet50 (teacher)-MobileNetv1 (student) pair on ImageNet dataset, has a reduction of 9.6% in Top-1 error rate over the previous state-of-the-art method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:jSAVyFp_754C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"In this paper, we present an audio-visual model to perform speech super-resolution at large scale-factors (8× and 16×). Previous works attempted to solve this problem using only the audio modality as input and thus were limited to low scale-factors of 2× and 4×. In contrast, we propose to incorporate both visual and auditory signals to superresolve speech of sampling rates as low as 1kHz. In such challenging situations, the visual features assist in learning the content and improves the quality of the generated speech. Further, we demonstrate the applicability of our approach to arbitrary speech signals where the visual stream is not accessible. Our “pseudo-visual network” precisely synthesizes the visual stream solely from the low-resolution speech input. Extensive experiments and the demo video illustrate our method’s remarkable results and benefits over state-of-the-art audio-only speech super-resolution approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:IsPWOBWtZBwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Deep learning models suffer from catastrophic forgetting when trained in an incremental learning setting. In this work, we propose a novel approach to address the task incremental learning problem, which involves training a model on new tasks that arrive in an incremental manner. The task incremental learning problem becomes even more challenging when the test set contains classes that are not part of the train set, ie, a task incremental generalized zero-shot learning problem. Our approach can be used in both the zero-shot and non zero-shot task incremental learning settings. Our proposed method uses weight rectifications and affine transformations in order to adapt the model to different tasks that arrive sequentially. Specifically, we adapt the network weights to work for new tasks by"" rectifying"" the weights learned from the previous task. We learn these weight rectifications using very few parameters. We additionally learn affine transformations on the outputs generated by the network in order to better adapt them for the new task. We perform experiments on several datasets in both zero-shot and non zero-shot task incremental learning settings and empirically show that our approach achieves state-of-the-art results. Specifically, our approach outperforms the state-of-the-art non zero-shot task incremental learning method by over 5% on the CIFAR-100 dataset. Our approach also significantly outperforms the state-of-the-art task incremental generalized zero-shot learning method by absolute margins of 6.91% and 6.33% for the AWA1 and CUB datasets, respectively. We validate our approach using various ablation studies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:WAzi4Gm8nLoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"One of the major limitations of deep learning models is that they face catastrophic forgetting in an incremental learning scenario. There have been several approaches proposed to tackle the problem of incremental learning. Most of these methods are based on knowledge distillation and do not adequately utilize the information provided by older task models, such as uncertainty estimation in predictions. The predictive uncertainty provides the distributional information can be applied to mitigate catastrophic forgetting in a deep learning framework. In the proposed work, we consider a Bayesian formulation to obtain the data and model uncertainties. We also incorporate self-attention framework to address the incremental learning problem. We define distillation losses in terms of aleatoric uncertainty and self-attention. In the proposed work, we investigate different ablation analyses on these losses. Furthermore, we are able to obtain better results in terms of accuracy on standard benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:F2UWTTQJPOcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"A great number of situational comedies (sitcoms) are being regularly made and the task of adding laughter tracks to these is a critical task. Providing an ability to be able to predict whether something will be humorous to the audience is also crucial. In this project, we aim to automate this task. Towards doing so, we annotate an existing sitcom (Big Bang Theory') and use the laughter cues present to obtain a manual annotation for this show. We provide detailed analysis for the dataset design and further evaluate various state of the art baselines for solving this task. We observe that existing LSTM and BERT based networks on the text alone do not perform as well as joint text and video or only video-based networks. Moreover, it is challenging to ascertain that the words attended to while predicting laughter are indeed humorous. Our dataset and analysis provided through this paper is a valuable resource towards solving this interesting semantic and practical task. As an additional contribution, we have developed a novel model for solving this task that is a multi-modal self-attention based model that outperforms currently prevalent models for solving this task. The project page for the submission is\url https://multimodal-humor-dataset. github. io/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:3bvyWxjaHKcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Unsupervised Domain adaptation methods solve the adaptation problem for an unlabeled target set, assuming that the source dataset is available with all labels. However, the availability of actual source samples is not always possible in practical cases. It could be due to memory constraints, privacy concerns, and challenges in sharing data. This practical scenario creates a bottleneck in the domain adaptation problem. This paper addresses this challenging scenario by proposing a domain adaptation technique that does not need any source data. Instead of the source data, we are only provided with a classifier that is trained on the source data. Our proposed approach is based on a generative framework, where the trained classifier is used for generating samples from the source classes. We learn the joint distribution of data by using the energy-based modeling of the trained classifier. At the same time, a new classifier is also adapted for the target domain. We perform various ablation analysis under different experimental setups and demonstrate that the proposed approach achieves better results than the baseline models in this extremely novel scenario.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:w0F2JDEymm0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"In recent years, the attention mechanism has become a fairly popular concept and has proven to be successful in many machine learning applications. However, deep learning models do not employ supervision for these attention mechanisms which can improve the model's performance significantly. Therefore, in this paper, we tackle this limitation and propose a novel method to improve the attention mechanism by inducing"" self-supervision"". We devise a technique to generate desirable attention maps for any model that utilizes an attention module. This is achieved by examining the model's output for different regions sampled from the input and obtaining the attention probability distributions that enhance the proficiency of the model. The attention distributions thus obtained are used for supervision. We rely on the fact, that attenuation of the unimportant parts, allows a model to attend to more salient regions, thus strengthening the prediction accuracy. The quantitative and qualitative results published in this paper show that this method successfully improves the attention mechanism as well as the model's accuracy. In addition to the task of Visual Question Answering (VQA), we also show results on the task of Image classification and Text classification to prove that our method can be generalized to any vision and language model that uses an attention module",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:FiDNX6EVdGUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"In this work, we re-think the task of speech enhancement in unconstrained real-world environments. Current state-of-the-art methods use only the audio stream and are limited in their performance in a wide range of real-world noises. Recent works using lip movements as additional cues improve the quality of generated speech over"" audio-only"" methods. But, these methods cannot be used for several applications where the visual stream is unreliable or completely absent. We propose a new paradigm for speech enhancement by exploiting recent breakthroughs in speech-driven lip synthesis. Using one such model as a teacher network, we train a robust student network to produce accurate lip movements that mask away the noise, thus acting as a"" visual noise filter"". The intelligibility of the speech enhanced by our pseudo-lip approach is comparable (< 3% difference) to the case of using real lips. This implies that we can exploit the advantages of using lip movements even in the absence of a real video stream. We rigorously evaluate our model using quantitative metrics as well as human evaluations. Additional ablation studies and a demo video on our website containing qualitative comparisons and results clearly illustrate the effectiveness of our approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:HhcuHIWmDEUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Learning from a few examples is an important practical aspect of training classifiers. Various works have examined this aspect quite well. However, all existing approaches assume that the few examples provided are always correctly labeled. This is a strong assumption, especially if one considers the current techniques for labeling using crowd-based labeling services. We address this issue by proposing a novel robust few-shot learning approach. Our method relies on generating robust prototypes from a set of few examples. Specifically, our method refines the class prototypes by producing hybrid features from the support examples of each class. The refined prototypes help to classify the query images better. Our method can replace the evaluation phase of any few-shot learning method that uses a nearest neighbor prototype-based evaluation procedure to make them robust. We evaluate our method on standard mini-ImageNet and tiered-ImageNet datasets. We perform experiments with various label corruption rates in the support examples of the few-shot classes. We obtain significant improvement over widely used few-shot learning methods that suffer significant performance degeneration in the presence of label noise. We finally provide extensive ablation experiments to validate our method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:pAkWuXOU-OoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"Hatching is a common method used by artists to accentuate the third dimension of a sketch, and to illuminate the scene. Our system SHAD3S attempts to compete with a human at hatching generic three-dimensional (3D) shapes, and also tries to assist her in a form exploration exercise. The novelty of our approach lies in the fact that we make no assumptions about the input other than that it represents a 3D shape, and yet, given a contextual information of illumination and texture, we synthesise an accurate hatch pattern over the sketch, without access to 3d or pseudo 3D. In the process, we contribute towards a) a cheap yet effective method to synthesise a sufficiently large high fidelity dataset, pertinent to task; b) creating a pipeline with conditional generative adversarial network (CGAN); and c) creating an interactive utility with GIMP, that is a tool for artists to engage with automated hatching or a form-exploration exercise. User evaluation of the tool suggests that the model performance does generalise satisfactorily over diverse input, both in terms of style as well as shape. A simple comparison of inception scores suggest that the generated distribution is as diverse as the ground truth. k",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:uVUOdF_882EC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"In this paper, we propose an approach to improve few-shot classification performance using a composite rotation based auxiliary task. Few-shot classification methods aim to produce neural networks that perform well for classes with a large number of training samples and classes with less number of training samples. They employ techniques to enable the network to produce highly discriminative features that are also very generic. Generally, the better the quality and generic-nature of the features produced by the network, the better is the performance of the network on few-shot learning. Our approach aims to train networks to produce such features by using a self-supervised auxiliary task. Our proposed composite rotation based auxiliary task performs rotation at two levels, ie, rotation of patches inside the image (inner rotation) and rotation of the whole image (outer rotation) and assigns one out of 16 rotation classes to the modified image. We then simultaneously train for the composite rotation prediction task along with the original classification task, which forces the network to learn high-quality generic features that help improve the few-shot classification performance. We experimentally show that our approach performs better than existing few-shot learning methods on multiple benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:1Ye0OR6EYb4C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2021,"In this paper, we propose a novel approach for generalized zero-shot learning in a multi-modal setting, where we have novel classes of audio/video during testing that are not seen during training. We use the semantic relatedness of text embeddings as a means for zero-shot learning by aligning audio and video embeddings with the corresponding class label text feature space. Our approach uses a cross-modal decoder and a composite triplet loss. The cross-modal decoder enforces a constraint that the class label text features can be reconstructed from the audio and video embeddings of data points. This helps the audio and video embeddings to move closer to the class label text embedding. The composite triplet loss makes use of the audio, video, and text embeddings. It helps bring the embeddings from the same class closer and push away the embeddings from different classes in a multi-modal setting. This helps the network to perform better on the multi-modal zero-shot learning task. Importantly, our multi-modal zero-shot learning approach works even if a modality is missing at test time. We test our approach on the generalized zero-shot classification and retrieval tasks and show that our approach outperforms other models in the presence of a single modality as well as in the presence of multiple modalities. We validate our approach by comparing it with previous approaches and using various ablations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:q-HalDI95KYC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"In this paper, we address the task of improving pair-wise machine translation for specific low resource Indian languages. Multilingual NMT models have demonstrated a reasonable amount of effectiveness on resource-poor languages. In this work, we show that the performance of these models can be significantly improved upon by using back-translation through a filtered back-translation process and subsequent fine-tuning on the limited pair-wise language corpora. The analysis in this paper suggests that this method can significantly improve a multilingual model's performance over its baseline, yielding state-of-the-art results for various Indian languages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:VN7nJs4JPk0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Data Augmentation methods for Neural Machine Translation (NMT) such as back-translation (BT) and self-training (ST) are quite popular. In a multilingual NMT system, simply copying monolingual source sentences to the target (Copying) is an effective data augmentation method. Back-translation aug-ments parallel data by translating monolingual sentences in the target side to source language. In this work we propose to use a partial back-translation method in a multilingual setting. Instead of translating the entire monolingual target sentence back into the source language, we replace selected high confidence phrases only and keep the rest of the words in the target language itself.(We call this method PhraseOut). Our experiments on low resource multilingual translation models show that PhraseOut gives reasonable improvements over the existing data augmentation methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:raTqNPD5sRQC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"A few-shot learning model generally consists of a feature extraction network and a classification module. In this paper, we propose an approach to improve few-shot image classification performance by increasing the representational capacity of the feature extraction network and improving the quality of the features extracted by it. The ability of the feature extraction network to extract highly discriminative features from images is essential to few-shot learning. Such features are generally class agnostic and contain information about the general content of the image. Our approach improves the training of the feature extraction network in order to enable them to produce such features. We train the network using filter-grafting along with an auxiliary self-supervision task and a knowledge distillation procedure. Particularly, filter-grafting rejuvenates unimportant (invalid) filters in the feature extraction network to make them …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:Dem6FJhTUoYC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"The ability to envisage the visual of a talking face based just on hearing a voice is a unique human capability. There have been a number of works that have solved for this ability recently. We differ from these approaches by enabling a variety of talking face generations based on single audio input. Indeed, just having the ability to generate a single talking face would make a system almost robotic in nature. In contrast, our unsupervised stochastic audio-to-video generation model allows for diverse generations from a single audio input. Particularly, we present an unsupervised stochastic audio-to-video generation model that can capture multiple modes of the video distribution. We ensure that all the diverse generations are plausible. We do so through a principled multi-modal variational autoencoder framework. We demonstrate its efficacy on the challenging LRW and GRID datasets and demonstrate performance better than the baseline, while having the ability to generate multiple diverse lip synchronized videos.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:ce2CqMG-AY4C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Hatching is a common method used by artists to accentuate the third dimension of a sketch, and to illuminate the scene. Our system SHAD3S attempts to compete with a human at hatching generic three-dimensional (3D) shapes, and also tries to assist her in a form exploration exercise. The novelty of our approach lies in the fact that we make no assumptions about the input other than that it represents a 3D shape, and yet, given a contextual information of illumination and texture, we synthesise an accurate hatch pattern over the sketch, without access to 3D or pseudo 3D. In the process, we contribute towards a) a cheap yet effective method to synthesise a sufficiently large high fidelity dataset, pertinent to task; b) creating a pipeline with conditional generative adversarial network (CGAN); and c) creating an interactive utility with GIMP, that is a tool for artists to engage with automated hatching or a form-exploration …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:DkZNVXde3BIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Convolutional Neural Networks (CNNs) have been successfully applied for relative camera pose estimation from labeled image-pair data, without requiring any handengineered features, camera intrinsic parameters or depth information. The trained CNN can be utilized for performing pose based visual servo control (PBVS). One of the ways to improve the quality of visual servo output is to improve the accuracy of the CNN for estimating the relative pose estimation. With a given state-of-the-art CNN for relative pose regression, how can we achieve an improved performance for visual servo control? In this paper, we explore switching of CNNs to improve the precision of visual servo control. The idea of switching a CNN is due to the fact that the dataset for training a relative camera pose regressor for visual servo control must contain variations in relative pose ranging from a very small scale to eventually a larger scale …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:KaMxkj08jr0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"We present the problem of Visually Precise Query (VPQ) generation which enables a more intuitive match between a user's information need and an e-commerce site's product description. Given an image of a fashion item, what is the most optimum search query that will retrieve the exact same or closely related product(s) with high probability. In this paper we introduce the task of VPQ generation which takes a product image and its title as its input and provides aword level extractive summary of the title, containing a list of salient attributes, which can now be used as a query to search for similar products. We collect a large dataset of fashion images and their titles and merge it with an existing research dataset which was created for a different task. Given the image and title pair, VPQ problem is posed as identifying a non-contiguous collection of spans within the title. We provide a dataset of around 400K image, title …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:kWvqk_afx_IC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"In this work, we investigate the problem of lip-syncing a talking face video of an arbitrary identity to match a target speech segment. Current works excel at producing accurate lip movements on a static image or videos of specific people seen during the training phase. However, they fail to accurately morph the lip movements of arbitrary identities in dynamic, unconstrained talking face videos, resulting in significant parts of the video being out-of-sync with the new audio. We identify key reasons pertaining to this and hence resolve them by learning from a powerful lip-sync discriminator. Next, we propose new, rigorous evaluation benchmarks and metrics to accurately measure lip synchronization in unconstrained videos. Extensive quantitative evaluations on our challenging benchmarks show that the lip-sync accuracy of the videos generated by our Wav2Lip model is almost as good as real synced videos. We provide …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:MAUkC_7iAq8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"While usage of convolutional neural networks (CNN) is widely prevalent, methods proposed so far always have considered homogeneous kernels for this task. In this paper, we propose a new type of convolution operation using heterogeneous kernels. The proposed Heterogeneous Kernel-Based Convolution (HetConv) reduces the computation (FLOPs) and the number of parameters as compared to standard convolution operation while it maintains representational efficiency. To show the effectiveness of our proposed convolution, we present extensive experimental results on the standard CNN architectures such as VGG, ResNet, Faster-RCNN, MobileNet, and SSD. We observe that after replacing the standard convolutional filters in these architectures with our proposed HetConv filters, we achieve 1.5  to 8  FLOPs based improvement in speed while it maintains (sometimes improves) the accuracy. We also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:PYBJJbyH-FwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"We present a determinantal point process (DPP) inspired alternative to non-maximum suppression (NMS) which has become an integral step in all state-of-the-art object detection frameworks. DPPs have been shown to encourage diversity in subset selection problems. We pose NMS as a subset selection problem and posit that directly incorporating DPP like framework can improve the overall performance of the object detection system. We propose an optimization problem which takes the same inputs as NMS, but introduces a novel sub-modularity based diverse subset selection functional. Our results strongly indicate that the modifications proposed in this paper can provide consistent improvements to state-of-the-art object detection pipelines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:HGTzPopzzJcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Convolution operation in deep convolutional neural networks is the most computationally expensive as compared to other operations. Most of the model computation (FLOPS) in the deep architecture belong to convolution operation. In this paper, we are proposing a novel skip convolution operation that employs significantly fewer computation as compared to the traditional one without sacrificing model accuracy. Skip convolution operation produces structured sparsity in the output feature maps without requiring sparsity in the model parameters for computation reduction. The existing convolution operation performs the redundant computation for object feature representation while the proposed convolution skips redundant computation. Our empirical evaluation for various deep models (VGG, ResNet, MobileNet, and Faster R-CNN) over various benchmarked datasets (CIFAR-10, CIFAR-100, ImageNet, and MS …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:RoXSNcbkSzsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"This work presents a novel training technique for deep neural networks that makes use of additional data from a distribution that is different from that of the original input data. This technique aims to reduce overfitting and improve the generalization performance of the network. Our proposed technique, namely Passive Batch Injection Training Technique (PBITT), even reduces the level of overfitting in networks that already use the standard techniques for reducing overfitting such as L 2 regularization and batch normalization, resulting in significant accuracy improvements. Passive Batch Injection Training Technique (PBITT) introduces a few passive mini-batches into the training process that contain data from a distribution that is different from the input data distribution. This technique does not increase the number of parameters in the final model and also does not increase the inference (test) time but still improves the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:6_hjMsCP8ZoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"We present sentence aligned parallel corpora across 10 Indian Languages - Hindi, Telugu, Tamil, Malayalam, Gujarati, Urdu, Bengali, Oriya, Marathi, Punjabi, and English - many of which are categorized as low resource. The corpora are compiled from online sources which have content shared across languages. The corpora presented significantly extends present resources that are either not large enough or are restricted to a specific domain (such as health). We also provide a separate test corpus compiled from an independent online source that can be independently used for validating the performance in 10 Indian languages. Alongside, we report on the methods of constructing such corpora using tools enabled by recent advances in machine translation and cross-lingual retrieval using deep neural network based methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:rHJHxKgnXwkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Convolutional neural networks (CNNs) have been the source of recent breakthroughs in many vision tasks. Feature pooling layers are being widely used in CNNs to reduce the spatial dimensions of the feature maps of the hidden layers. This gives CNNs the property of spatial invariance and also results in speed-up and reduces over-fitting. However, this also causes significant information loss. All existing feature pooling layers follow a one-step procedure for spatial pooling, which affects the overall performance due to significant information loss. Not much work has been done to do efficient feature pooling operation in CNNs. To reduce the loss of information at this critical operation of the CNNs, we propose a new EDS layer (Expansion Downsampling learnable-Scaling) to replace the existing pooling mechanism. We propose a two-step procedure to minimize the information loss by increasing the number of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:6bLC7aUMtPcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"While convolutional neural networks (CNNs) have achieved remarkable performance on various supervised and unsupervised learning tasks, they typically consist of a massive number of parameters. This results in significant memory requirements as well as a computational burden. Consequently, there is a growing need for filter-level pruning approaches for compressing CNN based models that not only reduce the total number of parameters but reduce the overall computation as well. We present a new min-max framework for the filter-level pruning of CNNs. Our framework jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance. Our framework consists of two modules: (1) An adaptive filter pruning (AFP) module, which minimizes the number of filters in the model; and (2) A pruning rate controller (PRC) module, which maximizes the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:DBa1UEJaJKAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Convolutional layers are a major driving force behind the successes of deep learning. Pointwise convolution (PWC) is a 1 × 1 convolutional filter that is primarily used for parameter reduction. However, the PWC ignores the spatial information around the points it is processing. This design is by choice, in order to reduce the overall parameters and computations. However, we hypothesize that this shortcoming of PWC has a significant impact on the network performance. We propose an alternative design for pointwise convolution, which uses spatial information from the input efficiently. Our design significantly improves the performance of the networks without substantially increasing the number of parameters and computations. We experimentally show that our design results in significant improvement in the performance of the network for classification as well as detection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:WHdLCjDvYFkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"The exponential increase in COVID-19 patients is overwhelming healthcare systems across the world. With limited testing kits, it is impossible for every patient with respiratory illness to be tested using conventional techniques (RT-PCR). The tests also have long turn-around time, and limited sensitivity. Detecting possible COVID-19 infections on Chest X-Ray may help quarantine high risk patients while test results are awaited. X-Ray machines are already available in most healthcare systems, and with most modern X-Ray systems already digitized, there is no transportation time involved for the samples either. In this work we propose the use of chest X-Ray to prioritize the selection of patients for further RT-PCR testing. This may be useful in an inpatient setting where the present systems are struggling to decide whether to keep the patient in the ward along with other patients or isolate them in COVID-19 areas. It would also help in identifying patients with high likelihood of COVID with a false negative RT-PCR who would need repeat testing. Further, we propose the use of modern AI techniques to detect the COVID-19 patients using X-Ray images in an automated manner, particularly in settings where radiologists are not available, and help make the proposed testing technology scalable. We present CovidAID: COVID-19 AI Detector, a novel deep neural network based model to triage patients for appropriate testing. On the publicly available covid-chestxray-dataset [2], our model gives 90.5% accuracy with 100% sensitivity (recall) for the COVID-19 infection. We significantly improve upon the results of Covid-Net [10] on the same dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:WC9gN4BGCRcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"In this paper, we aim to obtain improved attention for a visual question answering (VQA) task. It is challenging to provide supervision for attention. An observation we make is that visual explanations as obtained through class activation mappings (specifically Grad-CAM) that are meant to explain the performance of various networks could form a means of supervision. However, as the distributions of attention maps and that of Grad-CAMs differ, it would not be suitable to directly use these as a form of supervision. Rather, we propose the use of a discriminator that aims to distinguish samples of visual explanation and attention maps. The use of adversarial training of the attention regions as a two-player game between attention and explanation serves to bring the distributions of attention maps and visual explanations closer. Significantly, we observe that providing such a means of supervision also results in attention maps that are more closely related to human attention resulting in a substantial improvement over baseline stacked attention network (SAN) models. It also results in a good improvement in rank correlation metric on the VQA task. This method can also be combined with recent MCB based methods and results in consistent improvement. We also provide comparisons with other means for learning distributions such as based on Correlation Alignment (Coral), Maximum Mean Discrepancy (MMD) and Mean Square Error (MSE) losses and observe that the adversarial loss outperforms the other forms of learning the attention maps. Visualization of the results also confirms our hypothesis that attention maps improve using this form of supervision.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:owLR8QvbtFgC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Line art is arguably one of the fundamental and versatile modes of expression. We propose a pipeline for a robot to look at a grayscale line art and redraw it. The key novel elements of our pipeline are: a) we propose a novel task of mimicking line drawings, b) to solve the pipeline we modify the Quick-draw dataset and obtain supervised training for converting a line drawing into a series of strokes c) we propose a multi-stage segmentation and graph interpretation pipeline for solving the problem. The resultant method has also been deployed on a CNC plotter as well as a robotic arm. We have trained several variations of the proposed methods and evaluate these on a dataset obtained from Quick-draw. Through the best methods we observe an accuracy of around 98% for this task, which is a significant improvement over the baseline architecture we adapted from. This therefore allows for deployment of the method …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:MhiOAD_qIWkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Music Artist Classification is a challenging task in Music Information Retrieval. There exist methods that are based on either signal processing features or deep learning algorithms. While signal processing based approaches do perform well, the challenging task implies that signal processing alone does not suffice to provide good features for the task. Other approaches that rely on deep learning based techniques learn representations from large amount of labelled data. A limitation to this approach is the requirement for large amount of annotated corpus for obtaining a good set of parameters. In this work, we pose auxiliary signal processing based tasks for a deep learning network that includes predicting the harmonic-percussive and vocal-non vocal components of audio files. We show that training on a combination of these tasks provides us with a well trained CNN with a good set of parameters; which can then …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:Ade32sEp0pkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Privacy and utility of data are two aspects of a system that are often diagonally opposite to each other. Privacy concerns drive design decisions that can reduce the ability to make deductions or correlations from a given dataset (eg reducing the probability that an individual could be recognised from a given set of health records). Utility, on the other hand, tries to maximise the chances of finding essential relationships in the real world, that can then be used for making smarter systems (eg the ability to predict that an individual is at higher risk of being affected by a terminal disease). A term that is often used to explain this paradox is called the Privacy-Utility trade-off. Software practitioners have often ignored the privacy aspects due to lack of legal obligations, and have generally concentrated on achieving functionality. But with a renewed interest in Artificial Intelligence, privacy concerns are going to become more critical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:AXkvAH5U_nMC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Understanding and explaining deep learning models is an imperative task. Towards this, we propose a method that obtains gradient-based certainty estimates that also provide visual attention maps. Particularly, we solve for visual question answering task. We incorporate modern probabilistic deep learning methods that we further improve by using the gradients for these estimates. These have two-fold benefits: a) improvement in obtaining the certainty estimates that correlate better with misclassified samples and b) improved attention maps that provide state-of-the-art results in terms of correlation with human attention regions. The improved attention maps result in consistent improvement for various methods for visual question answering. Therefore, the proposed technique can be thought of as a recipe for obtaining improved certainty estimates and explanations for deep learning models. We provide detailed empirical analysis for the visual question answering task on all standard benchmarks and comparison with state of the art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:3NQIlFlcGxIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Multiple categories of objects are present in most images. Treating this as a multi-class classification is not justified. We treat this as a multi-label classification problem. In this paper, we further aim to minimize the supervision required for providing supervision in multi-label classification. Specifically, we investigate an effective class of approaches that associate a weak localization with each category either in terms of the bounding box or segmentation mask. Doing so improves the accuracy of multi-label categorization. The approach we adopt is one of active learning, ie, incrementally selecting a set of samples that need supervision based on the current model, obtaining supervision for these samples, retraining the model with the additional set of supervised samples and proceeding again to select the next set of samples. A crucial concern is the choice of the set of samples. In doing so, we provide a novel insight, and no specific measure succeeds in obtaining a consistently improved selection criterion. We, therefore, provide a selection criterion that consistently improves the overall baseline criterion by choosing the top k set of samples for a varied set of criteria. Using this criterion, we are able to show that we can retain more than 98% of the fully supervised performance with just 20% of samples (and more than 96% using 10%) of the dataset on PASCAL VOC 2007 and 2012. Also, our proposed approach consistently outperforms all other baseline metrics for all benchmark datasets and model combinations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:mUJArPsKIAAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Line art is arguably one of the fundamental and versatile modes of expression. We propose a pipeline for a robot to look at a grayscale line art and redraw it. The key novel elements of our pipeline are: a) we propose a novel task of mimicking line drawings, b) to solve the pipeline we modify the Quick-draw dataset and obtain supervised training for converting a line drawing into a series of strokes c) we propose a multi-stage segmentation and graph interpretation pipeline for solving the problem. The resultant method has also been deployed on a CNC plotter as well as a robotic arm. We have trained several variations of the proposed methods and evaluate these on a dataset obtained from Quick-draw. Through the best methods we observe an accuracy of around 98% for this task, which is a significant improvement over the baseline architecture we adapted from. This therefore allows for deployment of the method on robots for replicating line art in a reliable manner. We also show that while the rule-based vectorization methods do suffice for simple drawings, it fails for more complicated sketches, unlike our method which generalizes well to more complicated distributions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:w1MjKQ0l0TYC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Multi-task learning (MTL) using convolutional neural networks (CNN) deals with training the network for multiple correlated tasks in concert. For accuracy-critical applications, there are endeavors to boost the model performance by resorting to a deeper network, which also increases the model complexity. However, such burdensome models are difficult to be deployed on mobile or edge devices. To ensure a trade-off between performance and complexity of CNNs in the context of MTL, we introduce the novel paradigm of self-distillation within the network. Different from traditional knowledge distillation (KD), which trains the Student in accordance with a cumbersome Teacher, our self-distilled multi-task CNN model: SD-MTCNN aims at distilling knowledge from deeper CNN layers into the shallow layers. Precisely, we follow a hard-sharing based MTL setup where all the tasks share a generic feature-encoder on top of which separate task-specific decoders are enacted. Under this premise, SD-MTCNN distills the more abstract features from the decoders to the encoded feature space, which guarantees improved multi-task performance from different parts of the network. We validate SDMTCNN on three benchmark datasets: CityScapes, NYUv2, and Mini-Taskonomy, and results confirm the improved generalization capability of self-distilled multi-task CNNs in comparison to the literature and baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:OBSaB-F7qqsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Training Neural Ordinary Differential Equations (ODEs) is often computationally expensive. Indeed, computing the forward pass of such models involves solving an ODE which can become arbitrarily complex during training. Recent works have shown that regularizing the dynamics of the ODE can partially alleviate this. In this paper we propose a new regularization technique: randomly sampling the end time of the ODE during training. The proposed regularization is simple to implement, has negligible overhead and is effective across a wide variety of tasks. Further, the technique is orthogonal to several other methods proposed to regularize the dynamics of ODEs and as such can be used in conjunction with them. We show through experiments on normalizing flows, time series models and image recognition that the proposed regularization can significantly decrease training time and even improve performance over baseline models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:jFemdcug13IC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Humans involuntarily tend to infer parts of the conversation from lip movements when the speech is absent or corrupted by external noise. In this work, we explore the task of lip to speech synthesis, ie, learning to generate natural speech given only the lip movements of a speaker. Acknowledging the importance of contextual and speaker-specific cues for accurate lip-reading, we take a different path from existing works. We focus on learning accurate lip sequences to speech mappings for individual speakers in unconstrained, large vocabulary settings. To this end, we collect and release a large-scale benchmark dataset, the first of its kind, specifically to train and evaluate the single-speaker lip to speech task in natural settings. We propose a novel approach with key design choices to achieve accurate, natural lip to speech synthesis in such unconstrained scenarios for the first time. Extensive evaluation using quantitative, qualitative metrics and human evaluation shows that our method is four times more intelligible than previous works in this space.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:SjuI4pbJlxcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Generative models have recently shown the ability to realistically generate data and model the distribution accurately. However, joint modeling of an image with the attribute that it is labeled with requires learning a cross modal correspondence between images and the attribute data. Though the information present in the images and attributes possess completely different statistical properties altogether, there exists an inherent correspondence that is challenging to capture. Various models have aimed at capturing this correspondence either through joint modeling of a variational autoencoder or through separate encoder networks that are then concatenated. We present an alternative by proposing a bridged variational autoencoder that allows for learning cross-modal correspondence by incorporating cross-modal hallucination losses in the latent space. In comparison to the existing methods, we have found that by incorporating this information into the network we not only obtain better generation results, but also obtain very distinctive latent embeddings thereby increasing the accuracy of cross-modal generated results. We validate the proposed method through comparison with state of the art methods and benchmarking on standard datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:LPtt_HFRSbwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Generating natural questions from an image is a semantic task that requires using vision and language modalities to learn multimodal representations. Images can have multiple visual and language cues such as places, captions, and tags. In this paper, we propose a principled deep Bayesian learning framework that combines these cues to produce natural questions. We observe that with the addition of more cues and by minimizing uncertainty in the among cues, the Bayesian network becomes more confident. We propose a Minimizing Uncertainty of Mixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues experts for generating probabilistic questions. This is a Bayesian framework and the results show a remarkable similarity to natural questions as validated by a human study. We observe that with the addition of more cues and by minimizing uncertainty among the cues, the Bayesian framework becomes more confident. Ablation studies of our model indicate that a subset of cues is inferior at this task and hence the principled fusion of cues is preferred. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE, and CIDEr). Here we provide project link for Deep Bayesian VQG https://delta-lab-iitk. github. io/BVQG/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:hsZV8lGYWTMC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"In this paper, we propose a method to obtain robust explanations for visual question answering (VQA) that correlate well with the answers. Our model explains the answers obtained through a VQA model by providing visual and textual explanations. The main challenges that we address are i) Answers and textual explanations obtained by current methods are not well correlated and ii) Current methods for visual explanation do not focus on the right location for explaining the answer. We address both these challenges by using a collaborative correlated module which ensures that even if we do not train for noise based attacks, the enhanced correlation ensures that the right explanation and answer can be generated. We further show that this also aids in improving the generated visual and textual explanations. The use of the correlated module can be thought of as a robust method to verify if the answer and explanations are coherent. We evaluate this model using VQA-X dataset. We observe that the proposed method yields better textual and visual justification that supports the decision. We showcase the robustness of the model against a noise-based perturbation attack using corresponding visual and textual explanations. A detailed empirical analysis is shown.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:Br1UauaknNIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"We present a filter pruning approach for deep model compression, using a multitask network. Our approach is based on learning aa pruner network to prune a pre-trained target network. The pruner is essentially a multitask deep neural network with binary outputs that help identify the filters from each layer of the original network that do not have any significant contribution to the model and can therefore be pruned. The pruner network has the same architecture as the original network except that it has a multitask/multi-output last layer containing binary-valued outputs (one per filter), which indicate which filters have to be pruned. The pruner's goal is to minimize the number of filters from the original network by assigning zero weights to the corresponding output feature-maps. In contrast to most of the existing methods, instead of relying on iterative pruning, our approach can prune the network (original network) in one go and, moreover, does not require specifying the degree of pruning for each layer (and can learn it instead). The compressed model produced by our approach is generic and does not need any special hardware/software support. Moreover, augmenting with other methods such as knowledge distillation, quantization, and connection pruning can increase the degree of compression for the proposed approach. We show the efficacy of our proposed approach for classification and object detection tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:yxmsSjX2EkcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Researchers have proposed various activation functions. These activation functions help the deep network to learn non-linear behavior with a significant effect on training dynamics and task performance. The performance of these activations also depends on the initial state of the weight parameters, ie, different initial state leads to a difference in the performance of a network. In this paper, we have proposed a cooperative initialization for training the deep network using ReLU activation function to improve the network performance. Our approach uses multiple activation functions in the initial few epochs for the update of all sets of weight parameters while training the network. These activation functions cooperate to overcome their drawbacks in the update of weight parameters, which in effect learn better"" feature representation"" and boost the network performance later. Cooperative initialization based training also helps in reducing the overfitting problem and does not increase the number of parameters, inference (test) time in the final model while improving the performance. Experiments show that our approach outperforms various baselines and, at the same time, performs well over various tasks such as classification and detection. The Top-1 classification accuracy of the model trained using our approach improves by 2.8% for VGG-16 and 2.1% for ResNet-56 on CIFAR-100 dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:prdVHNxh-e8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"In this work, we propose a modeling technique for jointly training image and video generation models by simultaneously learning to map latent variables with a fixed prior onto real images and interpolate over images to generate videos. The proposed approach models the variations in representations using residual vectors encoding the change at each time step over a summary vector for the entire video. We utilize the technique to jointly train an image generation model with a fixed prior along with a video generation model lacking constraints such as disentanglement. The joint training enables the image generator to exploit temporal information while the video generation model learns to flexibly share information across frames. Moreover, experimental results verify our approach's compatibility with pre-training on videos or images and training on datasets containing a mixture of both. A comprehensive set of quantitative and qualitative evaluations reveal the improvements in sample quality and diversity over both video generation and image generation baselines. We further demonstrate the technique's capabilities of exploiting similarity in features across frames by applying it to a model based on decomposing the video into motion and content. The proposed model allows minor variations in content across frames while maintaining the temporal dependence through latent vectors encoding the pose or motion features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:jU7OWUQzBzMC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Obtaining efficient Convolutional Neural Networks (CNNs) are imperative to enable their application for a wide variety of tasks (classification, detection, etc.). While several methods have been proposed to solve this problem, we propose a novel strategy for solving the same that is orthogonal to the strategies proposed so far. We hypothesize that if we add a fatuous auxiliary task, to a network which aims to solve a semantic task such as classification or detection, the filters devoted to solving this frivolous task would not be relevant for solving the main task of concern. These filters could be pruned and pruning these would not reduce the performance on the original task. We demonstrate that this strategy is not only successful, it in fact allows for improved performance for a variety of tasks such as object classification, detection and action recognition. An interesting observation is that the task needs to be fatuous so that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:CB2v5VPnA5kC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"Convolution Neural Networks (CNN) have been extremely successful in solving intensive computer vision tasks. The convolutional filters used in CNNs have played a major role in this success, by extracting useful features from the inputs. Recently researchers have tried to boost the performance of CNNs by re-calibrating the feature maps produced by these filters, eg, Squeeze-and-Excitation Networks (SENets). These approaches have achieved better performance by Exciting up the important channels or feature maps while diminishing the rest. However, in the process, architectural complexity has increased. We propose an architectural block that introduces much lower complexity than the existing methods of CNN performance boosting while performing significantly better than them. We carry out experiments on the CIFAR, ImageNet and MS-COCO datasets, and show that the proposed block can challenge the state-of-the-art results. Our method boosts the ResNet-50 architecture to perform comparably to the ResNet-152 architecture, which is a three times deeper network, on classification. We also show experimentally that our method is not limited to classification but also generalizes well to other tasks such as object detection.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:ubry08Y2EpUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2020,"We present a filter correlation based model compression approach for deep convolutional neural networks. Our approach iteratively identifies pairs of filters with the largest pairwise correlations and drops one of the filters from each such pair. However, instead of discarding one of the filters from each such pair naively, the model is re-optimized to make the filters in these pairs maximally correlated, so that discarding one of the filters from the pair results in minimal information loss. Moreover, after discarding the filters in each round, we further finetune the model to recover from the potential small loss incurred by the compression. We evaluate our proposed approach using a comprehensive set of experiments and ablation studies. Our compression method yields state-of-the-art FLOPs compression rates on various benchmarks, such as LeNet-5, VGG-16, and ResNet-50, 56, while still achieving excellent predictive performance for tasks such as object detection on benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:buQ7SEKw-1sC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"In this paper, we consider the problem of solving semantic tasks such as `Visual Question Answering' (VQA), where one aims to answers related to an image and `Visual Question Generation' (VQG), where one aims to generate a natural question pertaining to an image. Solutions for VQA and VQG tasks have been proposed using variants of encoder-decoder deep learning based frameworks that have shown impressive performance. Humans however often show generalization by relying on exemplar based approaches. For instance, the work by Tversky and Kahneman suggests that humans use exemplars when making categorizations and decisions. In this work, we propose the incorporation of exemplar based approaches towards solving these problems. Specifically, we incorporate exemplar based approaches and show that an exemplar based module can be incorporated in almost any of the deep learning architectures proposed in the literature and the addition of such a block results in improved performance for solving these tasks. Thus, just as the incorporation of attention is now considered de facto useful for solving these tasks, similarly, incorporating exemplars also can be considered to improve any proposed architecture for solving this task. We provide extensive empirical analysis for the same through various architectures, ablations, and state of the art comparisons.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:L1USKYWJimsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"This paper describes the Neural Machine Translation systems used by IIIT Hyderabad (CVIT-MT) for the translation tasks part of WAT-2019. We participated in tasks pertaining to Indian languages and submitted results for English-Hindi, Hindi-English, English-Tamil and Tamil-English language pairs. We employ Transformer architecture experimenting with multilingual models and methods for low-resource languages.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:7wO8s98CvbsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"In light of the recent breakthroughs in automatic machine translation systems, we propose a novel approach that we term as ""Face-to-Face Translation"". As today's digital communication becomes increasingly visual, we argue that there is a need for systems that can automatically translate a video of a person speaking in language A into a target language B with realistic lip synchronization. In this work, we create an automatic pipeline for this problem and demonstrate its impact in multiple real-world applications. First, we build a working speech-to-speech translation system by bringing together multiple existing modules from speech and language. We then move towards ""Face-to-Face Translation"" by incorporating a novel visual module, LipGAN for generating realistic talking faces from the translated audio. Quantitative evaluation of LipGAN on the standard LRW test set shows that it significantly outperforms existing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:FiytvqdAVhgC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"In order to successfully perform tasks specified by natural language instructions, an artificial agent operating in a visual world needs to map words, concepts, and actions from the instruction to visual elements in its environment. This association is termed as Task-Oriented Grounding. In this work, we propose a novel Dynamic Attention Network architecture for the efficient multi-modal fusion of text and visual representations which can generate a robust definition of state for the policy learner. Our model assumes no prior knowledge from visual and textual domains and is an end to end trainable. For a 3D visual world where the observation changes continuously, the attention on the visual elements tends to be highly co-related from a one-time step to the next. We term this as ""Dynamic Attention"". In this work, we show that Dynamic Attention helps in achieving grounding and also aids in the policy learning objective. Since most practical robotic applications take place in the real world where the observation space is continuous, our framework can be used as a generalized multi-modal fusion unit for robotic control through natural language. We show the effectiveness of using 1D convolution over Gated Attention Hadamard product on the rate of convergence of the network. We demonstrate that the cell-state of a Long Short Term Memory (LSTM) is a natural choice for modeling Dynamic Attention and shows through visualization that the generated attention is very close to how humans tend to focus on the environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:1taIhTC69MYC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Vision and language tasks have benefited from attention. There have been a number of different attention models proposed. However, the scale at which attention needs to be applied has not been well examined. Particularly, in this work, we propose a new method Granular Multi-modal Attention, where we aim to particularly address the question of the right granularity at which one needs to attend while solving the Visual Dialog task. The proposed method shows improvement in both image and text attention networks. We then propose a granular Multi-modal Attention network that jointly attends on the image and text granules and shows the best performance. With this work, we observe that obtaining granular attention and doing exhaustive Multi-modal Attention appears to be the best way to attend while solving visual dialog.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:kw52XkFRtyQC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Line art is arguably one of the fundamental and versatile modes of expression. We propose a pipeline for a robot to look at a grayscale line art and redraw it. The key novel elements of our pipeline are: a) we propose a novel task of mimicking line drawings, b) to solve the pipeline we modify the Quick-draw dataset to obtain supervised training for converting a line drawing into a series of strokes c) we propose a multi-stage segmentation and graph interpretation pipeline for solving the problem. The resultant method has also been deployed on a CNC plotter as well as a robotic arm. We have trained several variations of the proposed methods and evaluate these on a dataset obtained from Quick-draw. Through the best methods we observe an accuracy of around 98% for this task, which is a significant improvement over the baseline architecture we adapted from. This therefore allows for deployment of the method on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:-mN3Mh-tlDkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"We present a simple, yet effective, Neural Machine Translation system for Indian languages. We demonstrate the feasibility for multiple language pairs, and establish a strong baseline for further research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:7BrZ7Jt4UNcC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Domain adaptation is essential to enable wide usage of deep learning based networks trained using large labeled datasets. Adversarial learning based techniques have shown their utility towards solving this problem using a discriminator that ensures source and target distributions are close. However, here we suggest that rather than using a point estimate, it would be useful if a distribution based discriminator could be used to bridge this gap. This could be achieved using multiple classifiers or using traditional ensemble methods. In contrast, we suggest that a Monte Carlo dropout based ensemble discriminator could suffice to obtain the distribution based discriminator. Specifically, we propose a curriculum based dropout discriminator that gradually increases the variance of the sample based distribution and the corresponding reverse gradients are used to align the source and target feature representations. The detailed results and thorough ablation analysis show that our model outperforms state-of-the-art results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:nRpfm8aw39MC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Abnormal activity recognition requires detection of occurrence of anomalous events that suffer from a severe imbalance in data. In a video, normal is used to describe activities that conform to usual events while the irregular events which do not conform to the normal are referred to as abnormal. It is far more common to observe normal data than to obtain abnormal data in visual surveillance. In this paper, we propose an approach where we can obtain abnormal data by transforming normal data. This is a challenging task that is solved through a multi-stage pipeline approach. We utilize a number of techniques from unsupervised segmentation in order to synthesize new samples of data that are transformed from an existing set of normal examples. Further, this synthesis approach has useful applications as a data augmentation technique. An incrementally trained Bayesian convolutional neural network (CNN) is used …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:U4n9YNQMCAIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"In this paper, we solve the problem of adapting classifiers across domains. We consider the problem of domain adaptation for multi-class classification where we are provided a labeled set of examples in a source dataset and we are provided a target dataset with no supervision. In this setting, we propose an adversarial discriminator based approach. While the approach based on adversarial discriminator has been previously proposed; in this paper, we present an informed adversarial discriminator. Our observation relies on the analysis that shows that if the discriminator has access to all the information available including the class structure present in the source dataset, then it can guide the transformation of features of the target set of classes to a more structure adapted space. Using this formulation, we obtain state-of-the-art results for the standard evaluation on benchmark datasets. We further provide detailed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:BzfGm06jWhQC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Recent advances in reinforcement learning have proved that given an environment we can learn to perform a task in that environment if we have access to some form of a reward function (dense, sparse or derived from IRL). But most of the algorithms focus on learning a single best policy to perform a given set of tasks. In this paper, we focus on an algorithm that learns to not just perform a task but different ways to perform the same task. As we know when the environment is complex enough there always exists multiple ways to perform a task. We show that using the concept of information maximization it is possible to learn latent codes for discovering multiple ways to perform any given task in an environment.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:cK4Rrx0J3m0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Understanding videos of people speaking across international borders is hard as audiences from different demographies do not understand the language. Such speech videos are often supplemented with language subtitles. However, these hamper the viewing experience as the attention is shared. Simple audio dubbing in a different language makes the video appear unnatural due to unsynchronized lip motion. In this paper, we propose a system for automated cross-language lip synchronization for re-dubbed videos. Our model generates superior photorealistic lip-synchronization over original video in comparison to the current re-dubbing method. With the help of a user-based study, we verify that our method is preferred over unsynchronized videos.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:43bX7VzcjpAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"While convolutional neural networks (CNN) have achieved impressive performance on various classification/recognition tasks, they typically consist of a massive number of parameters. This results in significant memory requirement as well as computational overheads. Consequently, there is a growing need for filter-level pruning approaches for compressing CNN based models that not only reduce the total number of parameters but reduce the overall computation as well. We present a new min-max framework for filter-level pruning of CNNs. Our framework, called Play and Prune (PP), jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance. Our framework consists of two modules: (1) An adaptive filter pruning (AFP) module, which minimizes the number of filters in the model; and (2) A pruning rate controller (PRC) module, which maximizes the accuracy during pruning. Moreover, unlike most previous approaches, our approach allows directly specifying the desired error tolerance instead of pruning level. Our compressed models can be deployed at run-time, without requiring any special libraries or hardware. Our approach reduces the number of parameters of VGG-16 by an impressive factor of 17.5X, and number of FLOPS by 6.43X, with no loss of accuracy, significantly outperforming other state-of-the-art filter pruning methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:v1_lew4L6wgC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,This document describes the machine translation system used in the submissions of IIIT-Hyderabad CVIT-MT for the WAT-2018 English-Hindi translation task. Performance is evaluated on the associated corpus provided by the organizers. We experimented with convolutional sequence to sequence architectures. We also train with additional data obtained through backtranslation.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:zCSUwVk65WsC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Our goal is to spot words in silent speech videos without explicitly recognizing the spoken words, where the lip motion of the speaker is clearly visible and audio is absent. Existing work in this domain has mainly focused on recognizing a fixed set of words in word-segmented lip videos, which limits the applicability of the learned model due to limited vocabulary and high dependency on the model’s recognition performance. Our contribution is twofold: (1) we develop a pipeline for recognition-free retrieval and show its performance against recognition-based retrieval on a large-scale dataset and another set of out-of-vocabulary words. (2) We introduce a query expansion technique using pseudo-relevant feedback and propose a novel re-ranking method based on maximizing the correlation between spatiotemporal landmarks of the query and the top retrieval candidates. Our word spotting method achieves 35 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:48xauSegjOkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,AI intensive systems that operate upon user data face the challenge of balancing data utility with privacy concerns. We propose the idea and present the prototype of an open-source tool called Privacy Utility Trade-off (PUT) Workbench which seeks to aid software practitioners to take such crucial decisions. We pick a simple privacy model that doesn't require any background knowledge in Data Science and show how even that can achieve significant results over standard and real-life datasets. The tool and the source code is made freely available for extensions and usage.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:otzGkya1bYkC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"A system for making available at an end-user a media file, from a media provider comprising a media file patch related to at least one object, the system comprising: an encoding module at the media provider configured for determining at least one representation which resembles the media file patch, by comparing the media file patch with representations of said at least one object, and for including at least one identification corresponding with said representation in a skeleton file; a storage medium storing a dictionary including the representations of the at least one object at of the end-user and an intermediate node between the media provider and/or the end-user; a decoding module configured for decoding the skeleton file using the identification for looking up the corresponding representation in the dictionary of the storage medium and for rendering the media file patch based on the looked-up corresponding …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:_OXeSy2IsFwC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Convolutional neural networks (CNN) have achieved impressive performance on the wide variety of tasks (classification, detection, etc.) across multiple domains at the cost of high computational and memory requirements. Thus, leveraging CNNs for real-time applications necessitates model compression approaches that not only reduce the total number of parameters but reduce the overall computation as well. In this work, we present a stability-based approach for filter-level pruning of CNNs. We evaluate our proposed approach on different architectures (LeNet, VGG-16, ResNet, and Faster RCNN) and datasets and demonstrate its generalizability through extensive experiments. Moreover, our compressed models can be used at run-time without requiring any special libraries or hardware. Our model compression method reduces the number of FLOPS by an impressive factor of 6.03X and GPU memory footprint by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:wMgC3FpKEyYC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"We propose a framework for compressing state-of-the-art Single Shot MultiBox Detector (SSD). The framework addresses compression in the following stages: Sparsity Induction, Filter Selection, and Filter Pruning. In the Sparsity Induction stage, the object detector model is sparsified via an improved global threshold. In Filter Selection & Pruning stage, we select and remove filters using sparsity statistics of filter weights in two consecutive convolutional layers. This results in the model with the size smaller than most existing compact architectures. We evaluate the performance of our framework with multiple datasets and compare over multiple methods. Experimental results show that our method achieves state-of-the-art compression of 6.7X and 4.9X on PASCAL VOC dataset on models SSD300 and SSD512 respectively. We further show that the method produces maximum compression of 26X with SSD512 on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:QD3KBmkZPeQC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Biometric systems commonly utilize multi-biometric approaches where a person is verified or identified based on multiple biometric traits. However, requiring systems that are deployed usually require verification or identification from a large number of enrolled candidates. These are possible only if there are efficient methods that retrieve relevant candidates in a multi-biometric system. To solve this problem, we analyze the use of hashing techniques that are available for obtaining retrieval. We specifically based on our analysis recommend the use of supervised hashing techniques over deep learned features as a possible common technique to solve this problem. Our investigation includes a comparison of some of the supervised and unsupervised methods viz. Principal Component Analysis (PCA), Locality Sensitive Hashing (LSH), Locality-sensitive binary codes from shift-invariant kernels (SKLSH), Iterative …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:wKETBy42zhYC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"Understanding and explaining deep learning models is an imperative task. Towards this, we propose a method that obtains gradient-based certainty estimates that also provide visual attention maps. Particularly, we solve for visual question answering task. We incorporate modern probabilistic deep learning methods that we further improve by using the gradients for these estimates. These have two-fold benefits: a) improvement in obtaining the certainty estimates that correlate better with misclassified samples and b) improved attention maps that provide state-of-the-art results in terms of correlation with human attention regions. The improved attention maps result in consistent improvement for various methods for visual question answering. Therefore, the proposed technique can be thought of as a recipe for obtaining improved certainty estimates and explanation for deep learning models. We provide detailed empirical analysis for the visual question answering task on all standard benchmarks and comparison with state of the art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:j7_hQOaDUrUC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"The problem of domain adaptation has been extensively studied for object classification task. However, this problem has not been as well studied for recognizing actions. While, object recognition is well understood, the diverse variety of videos in action recognition make the task of addressing domain shift to be more challenging. We address this problem by proposing a new novel adaptation technique that we term as unsupervised deep action domain adaptation (U-DADA). The main concept that we propose is that of explicitly modeling density based adaptation and using them while adapting domains for recognizing actions. We show that these techniques work well both for domain adaptation through adversarial learning to obtain invariant features or explicitly reducing the domain shift between distributions. The method is shown to work well using existing benchmark datasets such as UCF50, UCF101 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:LdasjJ6CEcoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"In this paper, we aim to solve for unsupervised domain adaptation of classifiers where we have access to label information for the source domain while these are not available for a target domain. While various methods have been proposed for solving these including adversarial discriminator based methods, most approaches have focused on the entire image based domain adaptation. In an image, there would be regions that can be adapted better, for instance, the foreground object may be similar in nature. To obtain such regions, we propose methods that consider the probabilistic certainty estimate of various regions and specific focus on these during classification for adaptation. We observe that just by incorporating the probabilistic certainty of the discriminator while training the classifier, we are able to obtain state of the art results on various datasets as compared against all the recent methods. We provide a thorough empirical analysis of the method by providing ablation analysis, statistical significance test, and visualization of the attention maps and t-SNE embeddings. These evaluations convincingly demonstrate the effectiveness of the proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:kVjdVfd2voEC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2019,"We present a novel deep learning architecture in which the convolution operation leverages heterogeneous kernels. The proposed HetConv (Heterogeneous Kernel-Based Convolution) reduces the computation (FLOPs) and the number of parameters as compared to standard convolution operation while still maintaining representational efficiency. To show the effectiveness of our proposed convolution, we present extensive experimental results on the standard convolutional neural network (CNN) architectures such as VGG and ResNet. We find that after replacing the standard convolutional filters in these architectures with our proposed HetConv filters, we achieve 3X to 8X FLOPs based improvement in speed while still maintaining (and sometimes improving) the accuracy. We also compare our proposed convolutions with group/depth wise convolutions and show that it achieves more FLOPs reduction with significantly higher accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:jgBuDB5drN8C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"Although videos appear to be very high-dimensional in terms of duration × frame-rate × resolution, temporal smoothness constraints ensure that the intrinsic dimensionality for videos is much lower. In this paper, we use this idea for investigating Domain Adaptation (DA) in videos, an area that remains under-explored. An approach that has worked well for the image DA is based on the subspace modeling of the source and target domains, which works under the assumption that the two domains share a latent subspace where the domain shift can be reduced or eliminated. In this paper, first we extend three subspace based image DA techniques for human action recognition and then combine it with our proposed Eclectic Domain Mixing (EDM) approach to improve the effectiveness of the DA. Further, we use discrepancy measures such as Symmetrized KL Divergence and Target Density Around Source for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:AHdEip9mkN0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"Method for capturing an environment with objects, using a 3D camera, wherein the images of the cameras captured at different moments in time are used to generate 3D models, and wherein accuracy values are assigned to segments of the models allowing efficient refining of the models using the accuracy values.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:Aul-kAQHnToC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"Object detection methods like Single Shot Multibox Detector (SSD) provide highly accurate object detection that run in real-time. However, these approaches require a large number of annotated training images. Evidently, not all of these images are equally useful for training the algorithms. Moreover, obtaining annotations in terms of bounding boxes for each image is costly and tedious. In this paper, we aim to obtain a highly accurate object detector using only a fraction of the training images. We do this by adopting active learning that uses ‘human in the loop’paradigm to select the set of images that would be useful if annotated. Towards this goal, we make the following contributions: 1. We develop a novel active learning method which poses the layered architecture used in object detection as a ‘query by committee’paradigm to choose the set of images to be queried.
2. We introduce a framework to use the exploration/exploitation trade-off in our methods. 3. We analyze the results on standard object detection datasets which show that with only a third of the training data, we can obtain more than 95% of the localization accuracy of full supervision. Further our methods outperform classical uncertainty-based active learning algorithms like maximum entropy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:uDGL6kOW6j0C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"Generating natural questions from an image is a semantic task that requires using visual and language modality to learn multimodal representations. Images can have multiple visual and language contexts that are relevant for generating questions namely places, captions, and tags. In this paper, we propose the use of exemplars for obtaining the relevant context. We obtain this by using a Multimodal Differential Network to produce natural and engaging questions. The generated questions show a remarkable similarity to the natural questions as validated by a human study. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics (BLEU, METEOR, ROUGE, and CIDEr).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:0CzhzZyukY4C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"In this paper, we propose a method for obtaining sentence-level embeddings. While the problem of securing word-level embeddings is very well studied, we propose a novel method for obtaining sentence-level embeddings. This is obtained by a simple method in the context of solving the paraphrase generation task. If we use a sequential encoder-decoder model for generating paraphrase, we would like the generated paraphrase to be semantically close to the original sentence. One way to ensure this is by adding constraints for true paraphrase embeddings to be close and unrelated paraphrase candidate sentence embeddings to be far. This is ensured by using a sequential pair-wise discriminator that shares weights with the encoder that is trained with a suitable loss function. Our loss function penalizes paraphrase sentence embedding distances from being too large. This loss is used in combination with a sequential encoder-decoder network. We also validated our method by evaluating the obtained embeddings for a sentiment analysis task. The proposed method results in semantic embeddings and outperforms the state-of-the-art on the paraphrase generation and sentiment analysis task on standard datasets. These results are also shown to be statistically significant.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:LgRImbQfgY4C,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"Generative adversarial networks (GANs) while being very versatile in realistic image synthesis, still are sensitive to the input distribution. Given a set of data that has an imbalance in the distribution, the networks are susceptible to missing modes and not capturing the data distribution. While various methods have been tried to improve training of GANs, these have not addressed the challenges of covering the full data distribution. Specifically, a generator is not penalized for missing a mode. We show that these are therefore still susceptible to not capturing the full data distribution. In this paper, we propose a simple approach that combines an encoder based objective with novel loss functions for generator and discriminator that improves the solution in terms of capturing missing modes. We validate that the proposed method results in substantial improvements through its detailed analysis on toy and real datasets. The quantitative and qualitative results demonstrate that the proposed method improves the solution for the problem of missing modes and improves training of GANs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:tH6gc1N1XXoC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"In this paper we aim to answer questions based on images when provided with a dataset of question-answer pairs for a number of images during training. A number of methods have focused on solving this problem by using image based attention. This is done by focusing on a specific part of the image while answering the question. Humans also do so when solving this problem. However, the regions that the previous systems focus on are not correlated with the regions that humans focus on. The accuracy is limited due to this drawback. In this paper, we propose to solve this problem by using an exemplar based method. We obtain one or more supporting and opposing exemplars to obtain a differential attention region. This differential attention is closer to human attention than other image based attention methods. It also helps in obtaining improved accuracy when answering questions. The method is evaluated on challenging benchmark datasets. We perform better than other image based attention methods and are competitive with other state of the art methods that focus on both image and questions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:Bg7qf7VwUHIC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"Our goal is to spot words in silent speech videos without explicitly recognizing the spoken words, where the lip motion of the speaker is clearly visible and audio is absent. Existing work in this domain has mainly focused on recognizing a fixed set of words in word-segmented lip videos, which limits the applicability of the learned model due to limited vocabulary and high dependency on the model's recognition performance. Our contribution is two-fold: 1) we develop a pipeline for recognition-free retrieval, and show its performance against recognition-based retrieval on a large-scale dataset and another set of out-of-vocabulary words. 2) We introduce a query expansion technique using pseudo-relevant feedback and propose a novel re-ranking method based on maximizing the correlation between spatio-temporal landmarks of the query and the top retrieval candidates. Our word spotting method achieves 35 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:artPoR2Yc-kC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"In this supplementary material we provide additional results, insights and details regarding our paper",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:7H_MAutzIkAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"In the general settings of supervised learning, human action recognition has been a widely studied topic. The classifiers learned in this setting assume that the training and test data have been sampled from the same underlying probability distribution. However, in most of the practical scenarios, this assumption is not true, resulting in a suboptimal performance of the classifiers. This problem, referred to as Domain Shift, has been extensively studied, but mostly for image/object classification task. In this paper, we investigate the problem of Domain Shift in action videos, an area that has remained under-explored, and propose two new approaches named Action Modeling on Latent Subspace (AMLS) and Deep Adversarial Action Adaptation (DAAA). In the AMLS approach, the action videos in the target domain are modeled as a sequence of points on a latent subspace and adaptive kernels are successively learned between the source domain point and the sequence of target domain points on the manifold. In the DAAA approach, an end-to-end adversarial learning framework is proposed to align the two domains. The action adaptation experiments were conducted using various combinations of multi-domain action datasets, including six common classes of Olympic Sports and UCF50 datasets and all classes of KTH, MSR and our own SonyCam datasets. In this paper, we have achieved consistent improvements over chosen baselines and obtained some state-of-the-art results for the datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:4xDN1ZYqzskC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"We introduce a monaural audio source separation framework using a latent generative model. Traditionally, discriminative training for source separation is proposed using deep neural networks or non-negative matrix factorization. In this paper, we propose a principled generative approach using variational autoencoders (VAE) for audio source separation. VAE computes efficient Bayesian inference which leads to a continuous latent representation of the input data (spectrogram). It contains a probabilistic encoder which projects an input data to latent space and a probabilistic decoder which projects data from latent space back to input space. This allows us to learn a robust latent representation of sources corrupted with noise and other sources. The latent representation is then fed to the decoder to yield the separated source. Both encoder and decoder are implemented via multilayer perceptron (MLP). In contrast to prevalent techniques, we argue that VAE is a more principled approach to source separation. Experimentally, we find that the proposed framework yields reasonable improvements when compared to baseline methods available in the literature ie DNN and RNN with different masking functions and autoencoders. We show that our method performs better than best of the relevant methods with∼ 2 dB improvement in the source to distortion ratio.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:6yz0xqPARnAC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"Domain adaptation has been understood and adopted in vision. Recently with the advent of deep learning there are a number of techniques that propose methods for deep learning based domain adaptation. However, the methods proposed have been used for adapting object classification techniques. In this paper, we solve for domain adaptation of object detection that is more commonly used. We adapt deep adaptation techniques for the Faster R-CNN framework. The techniques that we adapt are the recent techniques based on Gradient Reversal and Maximum Mean Discrepancy (MMD) reduction based techniques. Among them we show that the MK-MMD based method when used appropriately provides the best results. We analyze our model with standard real world settings by using Pascal VOC as source and MS-COCO as target and show a gain of 2.5 mAP at IoU of 0.5 over a source only trained model. We show that this improvement is statistically significant.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:4X0JR2_MtJMC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"The prohibitive amounts of time required to review the large amounts of data captured by surveillance and other cameras has brought into question the very utility of large scale video logging. Yet, one recognizes that such logging and analysis are indispensable to security applications. The only way out of this paradox is to devise expedited browsing, by the creation of hyperlapse. We address the hyperlapse problem for the very challenging category of intensive egomotion which makes the hyperlapse highly jerky. We propose an economical approach for trajectory estimation based on Visual Odometry and implement cost functions to penalize pose and path deviations. Also, this is implemented on data taken by omni-directional camera, so that the viewer can opt to observe any direction while browsing. This requires many innovations, including handling the massive radial distortions and implementing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:vDZJ-YLwNdEC,https://vinaypn.github.io/
Vinay P. Namboodiri,"['Computer Vision', 'Image Processing', 'Machine Learning']",25,2629,2018,"We propose MAD-GAN, an intuitive generalization to the Generative Adversarial Networks (GANs) and its conditional variants to address the well known problem of mode collapse. First, MAD-GAN is a multi-agent GAN architecture incorporating multiple generators and one discriminator. Second, to enforce that different generators capture diverse high probability modes, the discriminator of MAD-GAN is designed such that along with finding the real and fake samples, it is also required to identify the generator that generated the given fake sample. Intuitively, to succeed in this task, the discriminator must learn to push different generators towards different identifiable modes. We perform extensive experiments on synthetic and real datasets and compare MAD-GAN with different variants of GAN. We show high quality diverse sample generations for challenging tasks such as image-to-image translation and face generation. In addition, we also show that MAD-GAN is able to disentangle different modalities when trained using highly challenging diverse-class dataset (eg dataset with images of forests, icebergs, and bedrooms). In the end, we show its efficacy on the unsupervised feature representation task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=JyHi9OoAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=JyHi9OoAAAAJ:fbc8zXXH2BUC,https://vinaypn.github.io/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2023,"Presently, 17 out of 30 Indian cities are ranked worst in air quality around the globe due to high emissions of fine particulate matter, PM 2.5 (particles less than 2.5 µm diameter). These particles can reach deeper into the lungs and cause serious health problems, including cardiovascular obstructive pulmonary disease, lung cancer, stroke, and asthma. To take prompt actions towards mitigating and controlling the adverse effects of air pollution, it is important to monitor the ambient air quality regularly and at the neighbourhood level. However, the distribution of the regulatory central ambient air quality monitoring stations (CAAQMS) in India is sparse, and many states and cities lack any regulatory stationary monitors (RSMs). Conventional air quality monitoring techniques are inefficient and incapable of mapping PM 2.5 at a sub-Km level. The heterogeneity of PM 2.5 concentrations at large-scale and high spatial …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:VnuxuLaQPLMC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2023,"Test-time adaptation is the problem of adapting a source pre-trained model using test inputs from a target domain without access to source domain data. Most of the existing approaches address the setting in which the target domain is stationary. Moreover, these approaches are prone to making erroneous predictions with unreliable uncertainty estimates when distribution shifts occur. Hence, test-time adaptation in the face of non-stationary target domain shift becomes a problem of significant interest. To address these issues, we propose a principled approach, PETAL (Probabilistic lifElong Test-time Adaptation with seLf-training prior), which looks into this problem from a probabilistic perspective using a partly data-dependent prior. A student-teacher framework, where the teacher model is an exponential moving average of the student model naturally emerges from this probabilistic perspective. In addition, the knowledge from the posterior distribution obtained for the source task acts as a regularizer. To handle catastrophic forgetting in the long term, we also propose a data-driven model parameter resetting mechanism based on the Fisher information matrix (FIM). Moreover, improvements in experimental results suggest that FIM based data-driven parameter restoration contributes to reducing the error accumulation and maintaining the knowledge of recent domain by restoring only the irrelevant parameters. In terms of predictive error rate as well as uncertainty based metrics such as Brier score and negative log-likelihood, our method achieves better results than the current state-of-the-art for online lifelong test time adaptation across various …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:a2necdfpwlEC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2023,"Modern deep neural networks achieve excellent predictive performance due to their massive scale, flexible architecture design and availability of large training datasets. However, several applications additionally demand reliable estimates of model and predictive uncertainty that help in making robust predictions with limited training data, enabling out-of-distribution generalization, etc. Neural networks do not offer such uncertainly estimates out-of-the-box. Although Bayesian approaches to deep learning do provide a natural way to quantify model and predictive uncertainty by inferring the posterior distribution of the model weights and averaging the model’s predictions over the entire posterior distribution, standard Bayesian inference methods such as MCMC and variational inference are difficult to design and scale to massive networks. An appealing and popular alternative is to learn an ensemble of model weights …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:eFf2swCANGcC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2022,"Diffusion Probabilistic models have been shown to generate state-of-the-art results on several competitive image synthesis benchmarks but lack a low-dimensional, interpretable latent space, and are slow at generation. On the other hand, Variational Autoencoders (VAEs) typically have access to a low-dimensional latent space but exhibit poor sample quality. Despite recent advances, VAEs usually require high-dimensional hierarchies of the latent codes to generate high-quality samples. We present DiffuseVAE, a novel generative framework that integrates VAE within a diffusion model framework, and leverage this to design a novel conditional parameterization for diffusion models. We show that the resulting model can improve upon the unconditional diffusion model in terms of sampling efficiency while also equipping diffusion models with the low-dimensional VAE inferred latent code. Furthermore, we show that the proposed model can generate high-resolution samples and exhibits synthesis quality comparable to state-of-the-art models on standard benchmarks. Lastly, we show that the proposed method can be used for controllable image synthesis and also exhibits out-of-the-box capabilities for downstream tasks like image super-resolution and denoising. For reproducibility, our source code is publicly available at \url{https://github.com/kpandey008/DiffuseVAE}.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:rFyVMFCKTwsC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2022,"In the task incremental learning problem, deep learning models suffer from catastrophic forgetting of previously seen classes/tasks as they are trained on new classes/tasks. This problem becomes even harder when some of the test classes do not belong to the training class set, i.e., the task incremental generalized zero-shot learning problem. We propose a novel approach to address the task incremental learning problem for both the non zero-shot and zero-shot settings. Our proposed approach, called Rectification-based Knowledge Retention (RKR), applies weight rectifications and affine transformations for adapting the model to any task. During testing, our approach can use the task label information (task-aware) to quickly adapt the network to that task. We also extend our approach to make it task-agnostic so that it can work even when the task label information is not available during testing. Specifically, given a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:Nufq_to8ts0C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2022,"Humans possess an innate ability to identify and differentiate instances that they are not familiar with, by leveraging and adapting the knowledge that they have acquired so far. Importantly, they achieve this without deteriorating the performance on their earlier learning. Inspired by this, we identify and formulate a new, pragmatic problem setting of NCDwF: Novel Class Discovery without Forgetting, which tasks a machine learning model to incrementally discover novel categories of instances from unlabeled data, while maintaining its performance on the previously seen categories. We propose 1) a method to generate pseudo-latent representations which act as a proxy for (no longer available) labeled data, thereby alleviating forgetting, 2) a mutual-information based regularizer which enhances unsupervised discovery of novel classes, and 3) a simple Known Class Identifier which aids generalized inference when …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:oYLFIHfuHKwC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2022,"For most existing federated learning algorithms, each round consists of minimizing a loss function at each client to learn an optimal model at the client, followed by aggregating these client models at the server. Point estimation of the model parameters at the clients does not take into account the uncertainty in the models estimated at each client. In many situations, however, especially in limited data settings, it is beneficial to take into account the uncertainty in the client models for more accurate and robust predictions. Uncertainty also provides useful information for other important tasks, such as active learning and out-of-distribution (OOD) detection. We present a framework for Bayesian federated learning where each client infers the posterior predictive distribution using its training data and present various ways to aggregate these client-specific predictive distributions at the server. Since communicating and aggregating predictive distributions can be challenging and expensive, our approach is based on distilling each client's predictive distribution into a single deep neural network. This enables us to leverage advances in standard federated learning to Bayesian federated learning as well. Unlike some recent works that have tried to estimate model uncertainty of each client, our work also does not make any restrictive assumptions, such as the form of the client's posterior distribution. We evaluate our approach on classification in federated setting, as well as active learning and OOD detection in federated settings, on which our approach outperforms various existing federated learning baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:wBLCggQE-ToC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2022,"Novel Class Discovery (NCD) is a learning paradigm, where a machine learning model is tasked to semantically group instances from unlabeled data, by utilizing labeled instances from a disjoint set of classes. In this work, we first characterize existing NCD approaches into single-stage and two-stage methods based on whether they require access to labeled and unlabeled data together while discovering new classes. Next, we devise a simple yet powerful loss function that enforces separability in the latent space using cues from multi-dimensional scaling, which we refer to as Spacing Loss. Our proposed formulation can either operate as a standalone method or can be plugged into existing methods to enhance them. We validate the efficacy of Spacing Loss with thorough experimental evaluation across multiple settings on CIFAR-10 and CIFAR-100 datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:K4-iKlO5MD4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"We present a continual learning approach for generative adversarial networks (GANs), by designing and leveraging parameter-efficient feature map transformations. Our approach is based on learning a set of global and task-specific parameters. The global parameters are fixed across tasks whereas the task-specific parameters act as local adapters for each task, and help in efficiently obtaining task-specific feature maps. Moreover, we propose an element-wise addition of residual bias in the transformed feature space, which further helps stabilize GAN training in such settings. Our approach also leverages task similarities based on the Fisher information matrix. Leveraging this knowledge from previous tasks significantly improves the model performance. In addition, the similarity measure also helps reduce the parameter growth in continual adaptation and helps to learn a compact model. In contrast to the recent approaches for continually-learned GANs, the proposed approach provides a memory-efficient way to perform effective continual data generation. Through extensive experiments on challenging and diverse datasets, we show that the feature-map-transformation approach outperforms state-of-the-art methods for continually-learned GANs, with substantially fewer parameters. The proposed method generates high-quality samples that can also improve the generative-replay-based continual learning for discriminative tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:T8_be82Iz5gC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"In Test-time Adaptation (TTA), given a model trained on some source data, the goal is to adapt it to make better predictions for test instances from a different distribution. Crucially, TTA assumes no access to the source data or even any additional labeled/unlabeled samples from the target distribution to finetune the source model. In this work, we consider TTA in a more pragmatic setting which we refer to as SITA (Single Image Test-time Adaptation). Here, when making each prediction, the model has access only to the given \emph{single} test instance, rather than a \emph{batch} of instances, as has typically been considered in the literature. This is motivated by the realistic scenarios where inference is needed in an on-demand fashion that may not be delayed to ""batch-ify"" incoming requests or the inference is happening on an edge device (like mobile phone) where there is no scope for batching. The entire adaptation process in SITA should be extremely fast as it happens at inference time. To address this, we propose a novel approach AugBN for the SITA setting that requires only forward propagation. The approach can adapt any off-the-shelf trained model to individual test instances for both classification and segmentation tasks. AugBN estimates normalisation statistics of the unseen test distribution from the given test image using only one forward pass with label-preserving transformations. Since AugBN does not involve any back-propagation, it is significantly faster compared to other recent methods. To the best of our knowledge, this is the first work that addresses this hard adaptation problem using only a single test image. Despite being very …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:9LpHyFPp1DQC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"A wide range of applications require learning image generation models whose latent space effectively captures the high-level factors of variation present in the data distribution. The extent to which a model represents such variations through its latent space can be judged by its ability to interpolate between images smoothly. However, most generative models mapping a fixed prior to the generated images lead to interpolation trajectories lacking smoothness and containing images of reduced quality. In this work, we propose a novel generative model that learns a flexible non-parametric prior over interpolation trajectories, conditioned on a pair of source and target images. Instead of relying on deterministic interpolation methods (such as linear or spherical interpolation in latent space), we devise a framework that learns a distribution of trajectories between two given images using Latent Second-Order Neural Ordinary Differential Equations. Through a hybrid combination of reconstruction and adversarial losses, the generator is trained to map the sampled points from these trajectories to sequences of realistic images that smoothly transition from the source to the target image. Through comprehensive qualitative and quantitative experiments, we demonstrate our approach's effectiveness in generating images of improved quality as well as its ability to learn a diverse distribution over smooth interpolation trajectories for any pair of real source and target images.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:3vbIHxFL9FgC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"Learning from data sequentially arriving, possibly in a non i.i.d. way, with changing task distribution over time is called continual learning. Much of the work thus far in continual learning focuses on supervised learning and some recent works on unsupervised learning. In many domains, each task contains a mix of labelled (typically very few) and unlabelled (typically plenty) training examples, which necessitates a semi-supervised learning approach. To address this in a continual learning setting, we propose a framework for semi-supervised continual learning called Meta-Consolidation for Continual Semi-Supervised Learning (MCSSL). Our framework has a hypernetwork that learns the meta-distribution that generates the weights of a semi-supervised auxiliary classifier generative adversarial network $(\textit{Semi-ACGAN})$ as the base network. We consolidate the knowledge of sequential tasks in the hypernetwork, and the base network learns the semi-supervised learning task. Further, we present $\textit{Semi-Split CIFAR-10}$, a new benchmark for continual semi-supervised learning, obtained by modifying the $\textit{Split CIFAR-10}$ dataset, in which the tasks with labelled and unlabelled data arrive sequentially. Our proposed model yields significant improvements in the continual semi-supervised learning setting. We compare the performance of several existing continual learning approaches on the proposed continual semi-supervised learning benchmark of the Semi-Split CIFAR-10 dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:wuD5JclIwkYC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"In this paper, we propose a new framework for fine-grained emotion prediction in the text through emotion definition modeling. Our approach involves a multi-task learning framework that models definitions of emotions as an auxiliary task while being trained on the primary task of emotion prediction. We model definitions using masked language modeling and class definition prediction tasks. Our models outperform existing state-of-the-art for fine-grained emotion dataset GoEmotions. We further show that this trained model can be used for transfer learning on other benchmark datasets in emotion prediction with varying emotion label sets, domains, and sizes. The proposed models outperform the baselines on transfer learning experiments demonstrating the generalization capability of the models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:inmFHauC9wsC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"Continual Learning is a learning paradigm where learning systems are trained on a sequence of tasks. The goal here is to perform well on the current task without suffering from a performance drop on the previous tasks. Two notable directions among the recent advances in continual learning with neural networks are (1) variational Bayes based regularization by learning priors from previous tasks, and,(2) learning the structure of deep networks to adapt to new tasks. So far, these two approaches have been largely orthogonal. We present a novel Bayesian framework based on continually learning the structure of deep neural networks, to unify these distinct yet complementary approaches. The proposed framework learns the deep structure for each task by learning which weights to be used, and supports inter-task transfer through the overlapping of different sparse subsets of weights learned by different tasks. An appealing aspect of our proposed continual learning framework is that it is applicable to both discriminative (supervised) and generative (unsupervised) settings. Experimental results on supervised and unsupervised benchmarks demonstrate that our approach performs comparably or better than recent advances in continual learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:BJtnxTr0fRcC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"We propose a novel approach for class incremental online learning in a limited data setting. This problem setting is challenging because of the following constraints: (1) Classes are given incrementally, which necessitates a class incremental learning approach; (2) Data for each class is given in an online fashion, i.e., each training example is seen only once during training; (3) Each class has very few training examples; and (4) We do not use or assume access to any replay/memory to store data from previous classes. Therefore, in this setting, we have to handle twofold problems of catastrophic forgetting and overfitting. In our approach, we learn robust representations that are generalizable across tasks without suffering from the problems of catastrophic forgetting and overfitting to accommodate future classes with limited samples. Our proposed method leverages the meta-learning framework with knowledge consolidation. The meta-learning framework helps the model for rapid learning when samples appear in an online fashion. Simultaneously, knowledge consolidation helps to learn a robust representation against forgetting under online updates to facilitate future learning. Our approach significantly outperforms other methods on several benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:0ngZmJvimKcC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"Traditional collaborative filtering (CF) based recommender systems tend to perform poorly when the user-item interactions/ratings are highly scarce. To address this, we propose a learning framework that improves collaborative filtering with a synthetic feedback loop (CF-SFL) to simulate the user feedback. The proposed framework consists of a recommender and a virtual user. The recommender is formulated as a CF model, recommending items according to observed user preference. The virtual user estimates rewards from the recommended items and generates a feedback in addition to the observed user preference. The recommender connected with the virtual user constructs a closed loop, that recommends users with items and imitates the unobserved feedback of the users to the recommended items. The synthetic feedback is used to augment the observed user preference and improve recommendation results. Theoretically, such model design can be interpreted as inverse reinforcement learning, which can be learned effectively via rollout (simulation). Experimental results show that the proposed framework is able to enrich the learning of user preference and boost the performance of existing collaborative filtering methods on multiple datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:ukw-9cB-YDkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"Many real-world classification problems often have classes with very few labeled training samples. Moreover, all possible classes may not be initially available for training, and may be given incrementally. Deep learning models need to deal with this two-fold problem in order to perform well in real-life situations. In this paper, we propose a novel Few-Shot Lifelong Learning (FSLL) method that enables deep learning models to perform lifelong/continual learning on few-shot data. Our method selects very few parameters from the model for training every new set of classes instead of training the full model. This helps in preventing overfitting. We choose the few parameters from the model in such a way that only the currently unimportant parameters get selected. By keeping the important parameters in the model intact, our approach minimizes catastrophic forgetting. Furthermore, we minimize the cosine similarity between the new and the old class prototypes in order to maximize their separation, thereby improving the classification performance. We also show that integrating our method with self-supervision improves the model performance significantly. We experimentally show that our method significantly outperforms existing methods on the miniImageNet, CIFAR-100, and CUB-200 datasets. Specifically, we outperform the state-of-the-art method by an absolute margin of 19.27% for the CUB dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:X4-KO54GjGYC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"Allowing effective inference of latent vectors while training GANs can greatly increase their applicability in various downstream tasks. Recent approaches, such as ALI and BiGAN frameworks, develop methods of inference of latent variables in GANs by adversarially training an image generator along with an encoder to match two joint distributions of image and latent vector pairs. We generalize these approaches to incorporate multiple layers of feedback on reconstructions, self-supervision, and other forms of supervision based on prior or learned knowledge about the desired solutions. We achieve this by modifying the discriminator's objective to correctly identify more than two joint distributions of tuples of an arbitrary number of random variables consisting of images, latent vectors, and other variables generated through auxiliary tasks, such as reconstruction and inpainting or as outputs of suitable pre-trained models. We design a non-saturating maximization objective for the generator-encoder pair and prove that the resulting adversarial game corresponds to a global optimum that simultaneously matches all the distributions. Within our proposed framework, we introduce a novel set of techniques for providing self-supervised feedback to the model based on properties, such as patch-level correspondence and cycle consistency of reconstructions. Through comprehensive experiments, we demonstrate the efficacy, scalability, and flexibility of the proposed approach for a variety of tasks. The appendix of the paper can be found at the following link: https://drive. google. com/file/d/1i99e682CqYWMEDXlnqkqrctGLVA9viiz/view? usp= sharing",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:Ej9njvOgR2oC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"We present a variational inference (VI) framework that unifies and leverages sequential Monte-Carlo (particle filtering) with \emph{approximate} rejection sampling to construct a flexible family of variational distributions. Furthermore, we augment this approach with a resampling step via Bernoulli race, a generalization of a Bernoulli factory, to obtain a low-variance estimator of the marginal likelihood. Our framework, Variational Rejection Particle Filtering (VRPF), leads to novel variational bounds on the marginal likelihood, which can be optimized efficiently with respect to the variational parameters and generalizes several existing approaches in the VI literature. We also present theoretical properties of the variational bound and demonstrate experiments on various models of sequential data, such as the Gaussian state-space model and variational recurrent neural net (VRNN), on which VRPF outperforms various existing state-of-the-art VI methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:cNe27ouKFcQC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"Deep learning models suffer from catastrophic forgetting when trained in an incremental learning setting. In this work, we propose a novel approach to address the task incremental learning problem, which involves training a model on new tasks that arrive in an incremental manner. The task incremental learning problem becomes even more challenging when the test set contains classes that are not part of the train set, ie, a task incremental generalized zero-shot learning problem. Our approach can be used in both the zero-shot and non zero-shot task incremental learning settings. Our proposed method uses weight rectifications and affine transformations in order to adapt the model to different tasks that arrive sequentially. Specifically, we adapt the network weights to work for new tasks by"" rectifying"" the weights learned from the previous task. We learn these weight rectifications using very few parameters. We additionally learn affine transformations on the outputs generated by the network in order to better adapt them for the new task. We perform experiments on several datasets in both zero-shot and non zero-shot task incremental learning settings and empirically show that our approach achieves state-of-the-art results. Specifically, our approach outperforms the state-of-the-art non zero-shot task incremental learning method by over 5% on the CIFAR-100 dataset. Our approach also significantly outperforms the state-of-the-art task incremental generalized zero-shot learning method by absolute margins of 6.91% and 6.33% for the AWA1 and CUB datasets, respectively. We validate our approach using various ablation studies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&sortby=pubdate&citation_for_view=D50grEgAAAAJ:RfUwGJFMQ-0C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"As neural networks are increasingly being applied to real-world applications, mechanisms to address distributional shift and sequential task learning without forgetting are critical. Methods incorporating network expansion have shown promise by naturally adding model capacity for learning new tasks while simultaneously avoiding catastrophic forgetting. However, the growth in the number of additional parameters of many of these types of methods can be computationally expensive at larger scales, at times prohibitively so. Instead, we propose a simple task-specific feature map transformation strategy for continual learning, which we call Efficient Feature Transformations (EFTs). These EFTs provide powerful flexibility for learning new tasks, achieved with minimal parameters added to the base architecture. We further propose a feature distance maximization strategy, which significantly improves task prediction in class incremental settings, without needing expensive generative models. We demonstrate the efficacy and efficiency of our method with an extensive set of experiments in discriminative (CIFAR-100 and ImageNet-1K) and generative (LSUN, CUB-200, Cats) sequences of tasks. Even with low single-digit parameter growth rates, EFTs can outperform many other continual learning methods in a wide range of settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:e84hm74t-eoC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2021,"We present a meta-learning based generative model for zero-shot learning (ZSL) towards a challenging setting when the number of training examples from each seen class is very few. This setup is in contrast to the conventional ZSL approaches, where training typically assumes the availability of a sufficiently large number of training examples from each of the seen classes. The proposed approach leverages meta-learning to train a deep generative model that integrates variational autoencoder an generative adversarial network. To simulate the ZSL behaviour in training, we propose a novel task distribution where meta-train and meta-validation classes are disjoint. Once trained, the model can generate synthetic examples from seen and unseen classes. Synthesize samples can then be used to train the ZSL framework in a supervised manner. The meta-learner enables our model to generates high-fidelity samples using only a small number of training examples from seen classes. We conduct extensive experiments and ablation studies on four benchmark datasets of ZSL and observe that the proposed model outperforms state-of-the-art approaches by a significant margin when the number of examples per seen class is very small.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:idthP5jqfYAC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"While usage of convolutional neural networks (CNN) is widely prevalent, methods proposed so far always have considered homogeneous kernels for this task. In this paper, we propose a new type of convolution operation using heterogeneous kernels. The proposed Heterogeneous Kernel-Based Convolution (HetConv) reduces the computation (FLOPs) and the number of parameters as compared to standard convolution operation while it maintains representational efficiency. To show the effectiveness of our proposed convolution, we present extensive experimental results on the standard CNN architectures such as VGG, ResNet, Faster-RCNN, MobileNet, and SSD. We observe that after replacing the standard convolutional filters in these architectures with our proposed HetConv filters, we achieve 1.5  to 8  FLOPs based improvement in speed while it maintains (sometimes improves) the accuracy. We also …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:U0iAMwwPxtsC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"Many applications, such as text modelling, high-throughput sequencing, and recommender systems, require analysing sparse, high-dimensional, and overdispersed discrete (count or binary) data. Recent deep probabilistic models based on variational autoencoders (VAE) have shown promising results on discrete data but may have inferior modelling performance due to the insufficient capability in modelling overdispersion and model misspecification. To address these issues, we develop a VAE-based framework using the negative binomial distribution as the data distribution. We also provide an analysis of its properties vis-à-vis other models. We conduct extensive experiments on three problems from discrete data analysis: text analysis/topic modelling, collaborative filtering, and multi-label learning. Our models outperform state-of-the-art approaches on these problems, while also capturing the phenomenon of overdispersion more effectively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:bVQMTfhMCi4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"While convolutional neural networks (CNNs) have achieved remarkable performance on various supervised and unsupervised learning tasks, they typically consist of a massive number of parameters. This results in significant memory requirements as well as a computational burden. Consequently, there is a growing need for filter-level pruning approaches for compressing CNN based models that not only reduce the total number of parameters but reduce the overall computation as well. We present a new min-max framework for the filter-level pruning of CNNs. Our framework jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance. Our framework consists of two modules: (1) An adaptive filter pruning (AFP) module, which minimizes the number of filters in the model; and (2) A pruning rate controller (PRC) module, which maximizes the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:JH5k92_tO-AC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"We present a probabilistic framework for community discovery and link prediction for graph-structured data, based on a novel, gamma ladder variational autoencoder (VAE) architecture. We model each node in the graph via a deep hierarchy of gamma-distributed embeddings, and define each link probability via a nonlinear function of the bottom-most layer's embeddings of its associated nodes. In addition to leveraging the representational power of multiple layers of stochastic variables via the ladder VAE architecture, our framework offers the following benefits:(1) Unlike existing ladder VAE architectures based on real-valued latent variables, the gamma-distributed latent variables naturally result in non-negativity and sparsity of the learned embeddings, and facilitate their direct interpretation as membership of nodes into (possibly multiple) communities/topics;(2) A novel recognition model for our gamma ladder VAE architecture allows fast inference of node embeddings; and (3) The framework also extends naturally to incorporate node side information (features and/or labels). Our framework is also fairly modular and can leverage a wide variety of graph neural networks as the VAE encoder. We report both quantitative and qualitative results on several benchmark datasets and compare our model with several state-of-the-art methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:3lUAU8Oskd0C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"Simple weighted averaging of word vectors often yields effective representations for sentences which outperform sophisticated seq2seq neural models in many tasks. While it is desirable to use the same method to represent documents as well, unfortunately, the effectiveness is lost when representing long documents involving multiple sentences. One of the key reasons is that a longer document is likely to contain words from many different topics; hence, creating a single vector while ignoring all the topical structure is unlikely to yield an effective document representation. This problem is less acute in single sentences and other short text fragments where the presence of a single topic is most likely. To alleviate this problem, we present P-SIF, a partitioned word averaging model to represent long documents. P-SIF retains the simplicity of simple weighted word averaging while taking a document's topical structure into account. In particular, P-SIF learns topic-specific vectors from a document and finally concatenates them all to represent the overall document. We provide theoretical justifications on the correctness of P-SIF. Through a comprehensive set of experiments, we demonstrate P-SIF's effectiveness compared to simple weighted averaging and many other baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:Y9VhQm-5nPIC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"Learning to classify unseen class samples at test time is popularly referred to as zero-shot learning (ZSL). If test samples can be from training (seen) as well as unseen classes, it is a more challenging problem due to the existence of strong bias towards seen classes. This problem is generally known as generalized zero-shot learning (GZSL). Thanks to the recent advances in generative models such as VAEs and GANs, sample synthesis based approaches have gained considerable attention for solving this problem. These approaches are able to handle the problem of class bias by synthesizing unseen class samples. However, these ZSL/GZSL models suffer due to the following key limitations:(i) Their training stage learns a class-conditioned generator using only seen class data and the training stage does not explicitly learn to generate the unseen class samples;(ii) They do not learn a generic optimal parameter which can easily generalize for both seen and unseen class generation; and (iii) If we only have access to a very few samples per seen class, these models tend to perform poorly. In this paper, we propose a meta-learning based generative model that naturally handles these limitations. The proposed model is based on integrating model-agnostic meta learning with a Wasserstein GAN (WGAN) to handle (i) and (iii), and uses a novel task distribution to handle (ii). Our proposed model yields significant improvements on standard ZSL as well as more challenging GZSL setting. In ZSL setting, our model yields 4.5%, 6.0%, 9.8%, and 27.9% relative improvements over the current state-of-the-art on CUB, AWA1, AWA2, and aPY datasets …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:9shLKfS_uJEC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"Recent works have shown that most deep learning models are often poorly calibrated, i.e., they may produce overconfident predictions that are wrong. It is therefore desirable to have models that produce predictive uncertainty estimates that are reliable. Several approaches have been proposed recently to calibrate classification models. However, there is relatively little work on calibrating regression models. We present a method for calibrating regression models based on a novel quantile regularizer defined as the cumulative KL divergence between two CDFs. Unlike most of the existing approaches for calibrating regression models, which are based on post-hoc processing of the model's output and require an additional dataset, our method is trainable in an end-to-end fashion without requiring an additional dataset. The proposed regularizer can be used with any training objective for regression. We also show that post-hoc calibration methods like Isotonic Calibration sometimes compound miscalibration whereas our method provides consistently better calibrations. We provide empirical results demonstrating that the proposed quantile regularizer significantly improves calibration for regression models trained using approaches, such as Dropout VI and Deep Ensembles.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:KI9T_ytC6pkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"We present an approach for lifelong/continual learning of convolutional neural networks (CNN) that does not suffer from the problem of catastrophic forgetting when moving from one task to the other. We show that the activation maps generated by the CNN trained on the old task can be calibrated using very few calibration parameters, to become relevant to the new task. Based on this, we calibrate the activation maps produced by each network layer using spatial and channel-wise calibration modules and train only these calibration parameters for each new task in order to perform lifelong learning. Our calibration modules introduce significantly less computation and parameters as compared to the approaches that dynamically expand the network. Our approach is immune to catastrophic forgetting since we store the task-adaptive calibration parameters, which contain all the task-specific knowledge and is exclusive to each task. Further, our approach does not require storing data samples from the old tasks, which is done by many replay based methods. We perform extensive experiments on multiple benchmark datasets (SVHN, CIFAR, ImageNet, and MS-Celeb), all of which show substantial improvements over state-of-the-art methods (eg, a 29% absolute increase in accuracy on CIFAR-100 with 10 classes at a time). On large-scale datasets, our approach yields 23.8% and 9.7% absolute increase in accuracy on ImageNet-100 and MS-Celeb-10K datasets, respectively, by employing very few (0.51% and 0.35% of model parameters) task-adaptive calibration parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:as0KMg8qHbkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"We present a filter pruning approach for deep model compression, using a multitask network. Our approach is based on learning aa pruner network to prune a pre-trained target network. The pruner is essentially a multitask deep neural network with binary outputs that help identify the filters from each layer of the original network that do not have any significant contribution to the model and can therefore be pruned. The pruner network has the same architecture as the original network except that it has a multitask/multi-output last layer containing binary-valued outputs (one per filter), which indicate which filters have to be pruned. The pruner's goal is to minimize the number of filters from the original network by assigning zero weights to the corresponding output feature-maps. In contrast to most of the existing methods, instead of relying on iterative pruning, our approach can prune the network (original network) in one go and, moreover, does not require specifying the degree of pruning for each layer (and can learn it instead). The compressed model produced by our approach is generic and does not need any special hardware/software support. Moreover, augmenting with other methods such as knowledge distillation, quantization, and connection pruning can increase the degree of compression for the proposed approach. We show the efficacy of our proposed approach for classification and object detection tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:vnF2_uLGgtgC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"We present an attention-based ranking framework for learning to order sentences given a paragraph. Our framework is built on a bidirectional sentence encoder and a self-attention based transformer network to obtain an input order invariant representation of paragraphs. Moreover, it allows seamless training using a variety of ranking based loss functions, such as pointwise, pairwise, and listwise ranking. We apply our framework on two tasks: Sentence Ordering and Order Discrimination. Our framework outperforms various state-of-the-art methods on these tasks on a variety of evaluation metrics. We also show that it achieves better results when using pairwise and listwise ranking losses, rather than the pointwise ranking loss, which suggests that incorporating relative positions of two or more sentences in the loss function contributes to better learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:BAanoTsO0WEC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"In this work, we propose a modeling technique for jointly training image and video generation models by simultaneously learning to map latent variables with a fixed prior onto real images and interpolate over images to generate videos. The proposed approach models the variations in representations using residual vectors encoding the change at each time step over a summary vector for the entire video. We utilize the technique to jointly train an image generation model with a fixed prior along with a video generation model lacking constraints such as disentanglement. The joint training enables the image generator to exploit temporal information while the video generation model learns to flexibly share information across frames. Moreover, experimental results verify our approach's compatibility with pre-training on videos or images and training on datasets containing a mixture of both. A comprehensive set of quantitative and qualitative evaluations reveal the improvements in sample quality and diversity over both video generation and image generation baselines. We further demonstrate the technique's capabilities of exploiting similarity in features across frames by applying it to a model based on decomposing the video into motion and content. The proposed model allows minor variations in content across frames while maintaining the temporal dependence through latent vectors encoding the pose or motion features.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:3A3nxV7CjKIC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"We present a domain adaptation based generative framework for zero shot learning. We address the problem of domain shift between the seen and unseen class distribution in Zero-Shot Learning (ZSL) and seek to minimize it by developing a generative model and training it via adversarial domain adaptation. Our approach is based on end-to-end learning of the class distributions of seen classes and unseen classes. To enable the model to learn the class distributions of unseen classes, we parameterize these class distributions in terms of the class attribute information (which is available for both seen and unseen classes). This provides a very simple way to learn the class distribution of any unseen class, given only its class attribute information, and no labeled training data. Training this model with adversarial domain adaptation provides robustness against the distribution mismatch between the data from seen and unseen classes. It also engenders a novel way for training neural net based classifiers to overcome the hubness problem in Zero-Shot learning. Through a comprehensive set of experiments, we show that our model yields superior accuracies as compared to various state-of-the-art zero shot learning models, on a variety of benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:TesyEGJKHF4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2020,"We present a filter correlation based model compression approach for deep convolutional neural networks. Our approach iteratively identifies pairs of filters with the largest pairwise correlations and drops one of the filters from each such pair. However, instead of discarding one of the filters from each such pair naively, the model is re-optimized to make the filters in these pairs maximally correlated, so that discarding one of the filters from the pair results in minimal information loss. Moreover, after discarding the filters in each round, we further finetune the model to recover from the potential small loss incurred by the compression. We evaluate our proposed approach using a comprehensive set of experiments and ablation studies. Our compression method yields state-of-the-art FLOPs compression rates on various benchmarks, such as LeNet-5, VGG-16, and ResNet-50, 56, while still achieving excellent predictive performance for tasks such as object detection on benchmark datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:hNSvKAmkeYkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"Despite the effectiveness of multitask deep neural network (MTDNN), there is a limited theoretical understanding on how the information is shared across different tasks in MTDNN. In this work, we establish a formal connection between MTDNN with infinitely-wide hidden layers and multitask Gaussian Process (GP). We derive multitask GP kernels corresponding to both single-layer and deep multitask Bayesian neural networks (MTBNN) and show that information among different tasks is shared primarily due to correlation across last layer weights of MTBNN and shared hyper-parameters, which is contrary to the popular hypothesis that information is shared because of shared intermediate layer weights. Our construction enables using multitask GP to perform efficient Bayesian inference for the equivalent MTDNN with infinitely-wide hidden layers. Prior work on the connection between deep neural networks and GP for single task settings can be seen as special cases of our construction. We also present an adaptive multitask neural network architecture that corresponds to a multitask GP with more flexible kernels, such as Linear Model of Coregionalization (LMC) and Cross-Coregionalization (CC) kernels. We provide experimental results to further illustrate these ideas on synthetic and real datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:eH23hyXCXa4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"We present an approximate inference method, based on a synergistic combination of R\'enyi -divergence variational inference (RDVI) and rejection sampling (RS). RDVI is based on minimization of R\'enyi -divergence between the true distribution and a variational approximation ; RS draws samples from a distribution using a proposal , s.t. . Our inference method is based on a crucial observation that equals where is the optimal value of the RS constant for a given proposal . This enables us to develop a \emph{two-stage} hybrid inference algorithm. Stage-1 performs RDVI to learn by minimizing an estimator of , and uses the learned to find an (approximately) optimal . Stage-2 performs RS using the constant to improve the approximate distribution and obtain a sample-based approximation. We prove that this two-stage method allows us to learn considerably more accurate approximations of the target distribution as compared to RDVI. We demonstrate our method's efficacy via several experiments on synthetic and real datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:aEW5N-EHWIMC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"Mixture-of-Experts (MoE) enable learning highly nonlinear models by combining simple expert models. Each expert handles a small region of the data space, as dictated by the gating network which generates the (soft) assignment of input to the corresponding experts. Despite their flexibility and renewed interest lately, existing MoE constructions pose several difficulties during model training. Crucially, neither of the two popular gating networks used in MoE, namely the softmax gating network and hierarchical gating network (the latter used in the hierarchical mixture of experts), have efficient inference algorithms. The problem is further exacerbated if the experts do not have conjugate likelihood and lack a naturally probabilistic formulation (e.g., logistic regression or large-margin classifiers such as SVM). To address these issues, we develop novel inference algorithms with closed-form parameter updates …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:yeL6HyUMUGUC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"We present a label embedding based approach to large-scale multi-label learning, drawing inspiration from ideas rooted in distributional semantics, specifically the Skip Gram Negative Sampling (SGNS) approach, widely used to learn word embeddings. Besides leading to a highly scalable model for multi-label learning, our approach highlights interesting connections between label embedding methods commonly used for multi-label learning and paragraph embedding methods commonly used for learning representations of text data. The framework easily extends to incorporating auxiliary information such as label-label correlations; this is crucial especially when many training instances are only partially annotated. To facilitate end-to-end learning, we develop a joint learning algorithm that can learn the embeddings as well as a regression model that predicts these embeddings for the new input to be annotated, via efficient gradient based methods. We demonstrate the effectiveness of our approach through an extensive set of experiments on a variety of benchmark datasets, and show that the proposed models perform favorably as compared to state-of-the-art methods for large-scale multi-label learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:W2uZP3ddy8sC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"While convolutional neural networks (CNN) have achieved impressive performance on various classification/recognition tasks, they typically consist of a massive number of parameters. This results in significant memory requirement as well as computational overheads. Consequently, there is a growing need for filter-level pruning approaches for compressing CNN based models that not only reduce the total number of parameters but reduce the overall computation as well. We present a new min-max framework for filter-level pruning of CNNs. Our framework, called Play and Prune (PP), jointly prunes and fine-tunes CNN model parameters, with an adaptive pruning rate, while maintaining the model's predictive performance. Our framework consists of two modules: (1) An adaptive filter pruning (AFP) module, which minimizes the number of filters in the model; and (2) A pruning rate controller (PRC) module, which maximizes the accuracy during pruning. Moreover, unlike most previous approaches, our approach allows directly specifying the desired error tolerance instead of pruning level. Our compressed models can be deployed at run-time, without requiring any special libraries or hardware. Our approach reduces the number of parameters of VGG-16 by an impressive factor of 17.5X, and number of FLOPS by 6.43X, with no loss of accuracy, significantly outperforming other state-of-the-art filter pruning methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:Y0-TYkg6YM4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"We present a probabilistic framework for multi-label learning based on a deep generative model for the binary label vector associated with each observation. Our generative model learns deep multi-layer latent embeddings of the binary label vector, which are conditioned on the input features of the observation. The model also has an interesting interpretation in terms of a deep topic model, with each label vector representing a bag-of-words document, with the input features being its meta-data. In addition to capturing the structural properties of the label space (eg, a near-low-rank label matrix), the model also offers a clean, geometric interpretation. In particular, the nonlinear classification boundaries learned by the model can be seen as the union of multiple convex polytopes. Our model admits a simple and scalable inference via efficient Gibbs sampling or EM algorithm. We compare our model with state-of-the-art baselines for multi-label learning on benchmark data sets, and also report some interesting qualitative results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:tz746QTLzJkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:d4tt_xEv1X8C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"Although multitask Deep Neural Networks have shown promise in jointly modeling multiple non-linear functions, they do not provide uncertainty estimates in predictions, which is crucial in applications, such as multitask Bayesian Optimization and multitask active learning. Also, the information sharing process in multitask Deep Neural Networks is not well understood, other than the fact that they learn a shared set of features that are potentially generalizable across tasks. In this work, we establish a formal connection between multitask Deep Neural Networks, with infinitely-wide hidden layers, and multitask Gaussian Process (GP). The latter has a well-understood, principled way of modeling task correlations. We derive the multitask GP covariance functions corresponding to both single layer and deep Bayesian multitask Neural Networks, and show how information is shared across the different tasks. Notably, our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:Kqc1aDSOPooC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"We present a probabilistic model for Sketch-Based Image Retrieval (SBIR) where, at retrieval time, we are given sketches from novel classes, that were not present at training time. Existing SBIR methods, most of which rely on learning class-wise correspondences between sketches and images, typically work well only for previously seen sketch classes, and result in poor retrieval performance on novel classes. To address this, we propose a generative model that learns to generate images, conditioned on a given novel class sketch. This enables us to reduce the SBIR problem to a standard image-to-image search problem. Our model is based on an inverse auto-regressive flow based variational autoencoder, with a feedback mechanism to ensure robust image generation. We evaluate our model on two very challenging datasets, Sketchy, and TU Berlin, with novel train-test split. The proposed approach significantly outperforms various baselines on both the datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:vVJNg6_NJEsC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"Stochastic blockmodels (SBM) and their variants, , mixed-membership and overlapping stochastic blockmodels, are latent variable based generative models for graphs. They have proven to be successful for various tasks, such as discovering the community structure and link prediction on graph-structured data. Recently, graph neural networks, , graph convolutional networks, have also emerged as a promising approach to learn powerful representations (embeddings) for the nodes in the graph, by exploiting graph properties such as locality and invariance. In this work, we unify these two directions by developing a sparse variational autoencoder for graphs, that retains the interpretability of SBMs, while also enjoying the excellent predictive performance of graph neural nets. Moreover, our framework is accompanied by a fast recognition model that enables fast inference of the node embeddings (which are of independent interest for inference in SBM and its variants). Although we develop this framework for a particular type of SBM, namely the overlapping stochastic blockmodel, the proposed framework can be adapted readily for other types of SBMs. Experimental results on several benchmarks demonstrate encouraging results on link prediction while learning an interpretable latent structure that can be used for community discovery.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:RMgMIBzvq-4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2019,"We present a novel deep learning architecture in which the convolution operation leverages heterogeneous kernels. The proposed HetConv (Heterogeneous Kernel-Based Convolution) reduces the computation (FLOPs) and the number of parameters as compared to standard convolution operation while still maintaining representational efficiency. To show the effectiveness of our proposed convolution, we present extensive experimental results on the standard convolutional neural network (CNN) architectures such as VGG and ResNet. We find that after replacing the standard convolutional filters in these architectures with our proposed HetConv filters, we achieve 3X to 8X FLOPs based improvement in speed while still maintaining (and sometimes improving) the accuracy. We also compare our proposed convolutions with group/depth wise convolutions and show that it achieves more FLOPs reduction with significantly higher accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:7H_jS4BsgvYC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2018,"Word embeddings have been widely adopted across several NLP applications. Most existing word embedding methods utilize sequential context of a word to learn its embedding. While there have been some attempts at utilizing syntactic context of a word, such methods result in an explosion of the vocabulary size. In this paper, we overcome this problem by proposing SynGCN, a flexible Graph Convolution based method for learning word embeddings. SynGCN utilizes the dependency context of a word without increasing the vocabulary size. Word embeddings learned by SynGCN outperform existing methods on various intrinsic and extrinsic tasks and provide an advantage when used with ELMo. We also propose SemGCN, an effective framework for incorporating diverse semantic knowledge for further enhancing learned word representations. We make the source code of both models available to encourage reproducible research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:KTwcwpFFj4wC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2018,"We present a probabilistic, fully Bayesian framework for multi-label learning. Our framework is based on the idea of learning a joint low-rank embedding of the label matrix and the label co-occurrence matrix. The proposed framework has the following appealing aspects:(1) It leverages the sparsity in the label matrix and the feature matrix, which results in very efficient inference, especially for sparse datasets, commonly encountered in multi-label learning problems, and (2) By effectively utilizing the label co-occurrence information, the model yields improved prediction accuracies, especially in the case where the amount of training data is low and/or the label matrix has a significant fraction of missing labels. Our framework enjoys full local conjugacy and admits a simple inference procedure via a scalable Gibbs sampler. We report experimental results on a number of benchmark datasets, on which it outperforms several state-of-the-art multi-label learning models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:c59VksA5Vz4C,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2018,"We present a deep generative model for Zero-Shot Learning (ZSL). Unlike most existing methods for this problem, that represent each class as a point (via a semantic embedding), we represent each seen/unseen class using a class-specific latent-space distribution, conditioned on class attributes. We use these latent-space distributions as a prior for a supervised variational autoencoder (VAE), which also facilitates learning highly discriminative feature representations for the inputs. The entire framework is learned end-to-end using only the seen-class training data. At test time, the label for an unseen-class test input is the class that maximizes the VAE lower bound. We further extend the model to a (i) semi-supervised/transductive setting by leveraging unlabeled unseen-class data via an unsupervised learning module, and (ii) few-shot learning where we also have a small number of labeled inputs from the unseen classes. We compare our model with several state-of-the-art methods through a comprehensive set of experiments on a variety of benchmark data sets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:2vr6o8x5NLkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2018,"We present a generative framework for zero-shot action recognition where some of the possible action classes do not occur in the training data. Our approach is based on modeling each action class using a probability distribution whose parameters are functions of the attribute vector representing that action class. In particular, we assume that the distribution parameters for any action class in the visual space can be expressed as a linear combination of a set of basis vectors where the combination weights are given by the attributes of the action class. These basis vectors can be learned solely using labeled data from the known (i.e., previously seen) action classes, and can then be used to predict the parameters of the probability distributions of unseen action classes. We consider two settings: (1) Inductive setting, where we use only the labeled examples of the seen action classes to predict the unseen action class …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:pQTOvowfQioC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:qmtmRrLr0tkC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2018,"The latent feature relational model (LFRM) is a generative model for graph-structured data to learn a binary vector representation for each node in the graph. The binary vector denotes the node's membership in one or more communities. At its core, the LFRM miller2009nonparametric is an overlapping stochastic blockmodel, which defines the link probability between any pair of nodes as a bilinear function of their community membership vectors. Moreover, using a nonparametric Bayesian prior (Indian Buffet Process) enables learning the number of communities automatically from the data. However, despite its appealing properties, inference in LFRM remains a challenge and is typically done via MCMC methods. This can be slow and may take a long time to converge. In this work, we develop a small-variance asymptotics based framework for the non-parametric Bayesian LFRM. This leads to an objective function that retains the nonparametric Bayesian flavor of LFRM, while enabling us to design deterministic inference algorithms for this model, that are easy to implement (using generic or specialized optimization routines) and are fast in practice. Our results on several benchmark datasets demonstrate that our algorithm is competitive to methods such as MCMC, while being much faster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:m4fbC6XIj1kC,https://www.cse.iitk.ac.in/users/piyush/
Piyush Rai,"['machine learning', 'probabilistic machine learning', 'artificial intelligence']",28,3816,2018,"Paraphrase generation is an important problem in NLP, especially in question answering, information retrieval, information extraction, conversation systems, to name a few. In this paper, we address the problem of generating paraphrases automatically. Our proposed method is based on a combination of deep generative models (VAE) with sequence-to-sequence models (LSTM) to generate paraphrases, given an input sentence. Traditional VAEs when combined with recurrent neural networks can generate free text but they are not suitable for paraphrase generation for a given sentence. We address this problem by conditioning the both, encoder and decoder sides of VAE, on the original sentence, so that it can generate the given sentence's paraphrases. Unlike most existing models, our model is simple, modular and can generate multiple paraphrases, for a given sentence. Quantitative evaluation of the proposed method on a benchmark paraphrase dataset demonstrates its efficacy, and its performance improvement over the state-of-the-art methods by a significant margin, whereas qualitative human evaluation indicate that the generated paraphrases are well-formed, grammatically correct, and are relevant to the input sentence. Furthermore, we evaluate our method on a newly released question paraphrase dataset, and establish a new baseline for future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=D50grEgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=D50grEgAAAAJ:X0DADzN9RKwC,https://www.cse.iitk.ac.in/users/piyush/
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2023,"Permissionless blockchain consensus protocols have been leveraged for defining decentralized economies for the (commercial or private) trade of virtual and physical assets, using cryptocurrencies. In most instances, the assets being traded are regulated, which mandates that the legal right to their trade and their trade value are determined by the governmental regulator of the jurisdiction in which the trade occurs. Unfortunately, existing blockchains do not formalize proposal of legal cryptocurrency transactions, as part of the execution of their respective consensus protocols, resulting in illegal activities in the associated crypto-economies. In this contribution, unlike existing non-consensus solutions, which are prone to be more compute-time and audit-time intensive, we present a novel regulatory framework for blockchain protocols, for ensuring legal transaction confirmation as part of the blockchain consensus. As …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:5ugPr518TE4C,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2022,"Accordingly, embodiment herein disclose a method for handling block chain operation in a block chain system. The method includes parallelizing, by the block chain system, a block creation along with a consensus mechanism. The block creation along with the consensus mechanism includes parallelly combining a pre-computed state of a succeeding block (at height “k” greater than the current block, where “k” is a positive integer parameter chosen by the system designer) with transactions in a current block to obtain state to be stored in a next succeeding block (at height “k+ 1” greater than the current block) along with running a consensus protocol to finalize transactions to include in an immediate next block (at height one greater than the current block). Further, the method includes handling, by the block chain system, the block chain operation based on parallelizing. The method can be used for scaling up …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:tS2w5q8j5-wC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2022,"We consider the problem of correctly identifying the mode of a discrete distribution with sufficiently high probability by observing a sequence of iid samples drawn from . This problem reduces to the estimation of a single parameter when has a support set of size . After noting that this special case is handled very well by prior-posterior-ratio (PPR) martingale confidence sequences (Waudby-Smith and Ramdas, 2020), we propose a generalisation to mode estimation, in which may take values. To begin, we show that the"" one-versus-one"" principle to generalise from to classes is more efficient than the"" one-versus-rest"" alternative. We then prove that our resulting stopping rule, denoted PPR-1v1, is asymptotically optimal (as the mistake probability is taken to 0). PPR-1v1 is simple and computationally light, and incurs significantly fewer samples than competitors even in the non-asymptotic regime. We demonstrate its gains in two practical applications of sampling: election forecasting and verification of smart contracts in blockchains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:5Ul4iDaHHb8C,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2022,"The present invention provides a computer implemented method in a blockchain system, wherein said method comprising: plurality of anchors, wherein said anchors includes a bitstring comprising (i) hash of a block in a main chain, and (ii) a Proof Of Work (PoW). The plurality of anchors generated, propagated and thereby accepted by plurality of peer nodes in a network on said blockchain system so as to increase the responsiveness and stability of a blockchain.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:q3oQSFYPqjQC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2022,"The Computer architecture research extensively studies system resource consumption by algorithms and applications. On the other hand, Machine Learning (ML) research focuses on obtaining high levels of accuracy without any computational constraint. The typical approach for addressing the need for higher compute power and system resources for ML tasks is to add more hardware and employ lighter frameworks (e.g., using TensorFlow Lite and PyTorch Mobile instead of TensorFlow and Pytorch, respectively). Extensive use of ML models for applications, especially in Internet of Things (IoT) security requires investigation of resource consumption of ML models. Most tasks employing Artificial Intelligence/ Machine Learning need to choose appropriate models judiciously considering the system resources consumed. Therefore it is required to investigate various ML techniques and benchmark them in terms of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:eflP2zaiRacC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2022,"Proof-of-work (PoW) consensus generates blocks at random time instants, and consequently, adds weight to the blockchain at these random instants. This unsteady increase in chain weight over time along with the large network delay of blocks is the root cause of many security and performance problems such as high fork resolution times, vulnerability to double-spend and selfish mining attacks, and also a high block confirmation time. In this paper, we propose a novel signaling scheme of PoW called Anchors that can be implemented on any PoW blockchain system to improve their stability, reduce fork resolution times, prevent forks, strengthen the system against double spend attacks and reduce block confirmation times by half. In a partially synchronous model with a general adversary, we prove that a system with anchors has faster, more stable chain growth as compared to PoW systems without anchors and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:eJXPG6dFmWUC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2021,"Proof-of-Work (PoW) based blockchains typically allocate only a tiny fraction (e.g., less than 1% for Ethereum) of the average interarrival time (I) between blocks for validating smart contracts present in transactions. In such systems, block validation and PoW mining are typically performed sequentially, the former by CPUs and the latter by ASICs. A trivial increase in validation time (τ) introduces the popularly known Verifier's Dilemma, and as we demonstrate, causes more forking and hurts fairness. Large τ also reduces the tolerance for safety against a Byzantine adversary. Solutions that offload validation to a set of non-chain nodes (a.k.a. off-chain approaches) suffer from trust and performance issues that are non-trivial to resolve. In this paper, we present Tuxedo, the first on-chain protocol to theoretically scale τ/I ≈1 in PoW blockchains. The key innovation in Tuxedo is to perform CPU-based block processing in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:VOx2b1Wkg3QC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2021,"Proof-of-Work (PoW) blockchains add blocks, and consequently the chain weight, randomly. The blocks added also have a significant network delay owing to their large size. Large delay combined with randomness causes forks that are responsible for many security problems. One can reduce fork occurrences by designing a system with large block intervals and size but this design compromises performance aspects such as confirmation time guarantees. The trade-off between security and performance in PoW blockchain is a well discussed topic in the literature. In this paper, we aim to reduce the conflict between security and performance through our novel concept of Links. Links are small, fast and frequent structures that can be incorporated on any new or existing PoW blockchains. Links help reduce the confirmation time of its underlying blockchain while preserving its consistency security guarantees. Our novel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:BrmTIyaxlBUC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2021,"Cryptocurrency networks are a promising infrastructure for pseudonymous online payments. However, low throughput has prevented their widespread acceptance. A promising solution to scale throughput is the Payment channel network (PCN), exemplified by the Lightning Network (LN), that uses a network of off-chain bidirectional payment channels between parties that wish to transact often. Since payments use the shortest paths with sufficient funds over this network, channel balances get exhausted in the direction transactions flow and eventually become unidirectional. This results in transactions failing and consequently a lower transaction success ratio. Our observations on the production LN show that over 63% of the channels lose over 80% of the channel balance in one direction over time, which makes the success ratio of a real-world workload drop from 71% to 29%. A unidirectional channel along a path …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:fQNAKQ3IYiAC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2021,"A botnet is a network of devices infected by the same malware, acting as a single entity and controlled by a botmaster. They are the biggest cybersecurity threat to carry out large-scale attacks from spamming, ransomware, data exfiltration, and denial-of-service attacks. Lightweight IoT devices without traditional security mechanisms have become favorite victims and agents to carry out botnet attacks. In our work, we seek to detect botnet-infected IoT nodes.
This paper presents BOND, a frugal Deep Learning analysis of network traffic for detecting IoT devices infected with botnet(s), correctly classifying Zero-Day attacks and newer benign traffic. BOND is designed considering the constraints of IoT gateways and betters the F1 score of standard benchmark ML algorithms and State-of-The-Art method - Kitsune, by at least 10%, with under 1 millisecond inference time and less than 150 KB of model memory.
This paper …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:LPZeul_q3PIC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2021,"We consider the problem of correctly identifying the\textit {mode} of a discrete distribution with sufficiently high probability by observing a sequence of iid samples drawn from . This problem reduces to the estimation of a single parameter when has a support set of size . After noting that this special case is tackled very well by prior-posterior-ratio (PPR) martingale confidence sequences\citep {waudby-ramdas-ppr}, we propose a generalisation to mode estimation, in which may take values. To begin, we show that the"" one-versus-one"" principle to generalise from to classes is more efficient than the"" one-versus-rest"" alternative. We then prove that our resulting stopping rule, denoted PPR-1v1, is asymptotically optimal (as the mistake probability is taken to ). PPR-1v1 is parameter-free and computationally light, and incurs significantly fewer samples than competitors even in the non …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:8AbLer7MMksC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2021,"A Blockchain system such as Ethereum is a peer to peer network where each node works in three phases: creation, mining, and validation phases. In the creation phase, it executes a subset of locally cached transactions to form a new block. In the mining phase, the node solves a cryptographic puzzle (Proof of Work-PoW) on the block it forms. On receiving a block from another peer, it starts the validation phase, where it executes the transactions in the received block in order to ensure all transactions are valid. This execution also updates the blockchain state, which must be completed before creating the next block. A long block validation time lowers the system's overall throughput and brings the well known Verifier's dilemma into play. Additionally, this leads to wasted mining power utilization (MPU).
Through extensive measurement of 2000 nodes from the production Ethereum network we find that during block …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:sSrBHYA8nusC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2021,"Permissionless blockchain consensus protocols have been designed primarily for defining decentralized economies for the commercial trade of assets, both virtual and physical, using cryptocurrencies. In most instances, the assets being traded are regulated, which mandates that the legal right to their trade and their trade value are determined by the governmental regulator of the jurisdiction in which the trade occurs. Unfortunately, existing blockchains do not formally recognise proposal of legal cryptocurrency transactions, as part of the execution of their respective consensus protocols, resulting in rampant illegal activities in the associated crypto-economies. In this contribution, we motivate the need for regulated blockchain consensus protocols with a case study of the illegal, cryptocurrency based, Silk Road darknet market. We present a novel regulatory framework for blockchain protocols, for ensuring legal transaction confirmation as part of the blockchain distributed consensus. As per our regulatory framework, we derive conditions under which legal transaction throughput supersedes throughput of traditional transactions, which are, in the worst case, an indifferentiable mix of legal and illegal transactions. Finally, we show that with a small change to the standard blockchain consensus execution policy (appropriately introduced through regulation), the legal transaction throughput in the blockchain network can be maximized.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:B3FOqHPlNUQC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2021,"In recent times, the world has seen a tremendous increase in the number of attacks on IoT devices. A majority of these attacks have been botnet attacks, where an army of compromised IoT devices is used to launch DDoS attacks on targeted systems. In this paper, we study how the choice of a dataset and the extracted features determine the performance of a Machine Learning model, given the task of classifying Linux Binaries (ELFs) as being benign or malicious. Our work focuses on Linux systems since embedded Linux is the more popular choice for building today’s IoT devices and systems. We propose using 4 different types of files as the dataset for any ML model. These include system files, IoT application files, IoT botnet files and general malware files. Further, we propose using static, dynamic as well as network features to do the classification task. We show that existing methods leave out one or the other …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:4fKUyHm3Qg0C,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2020,"Proof-of-Work~(PoW) based blockchains typically allocate only a tiny fraction (e.g., less than 1% for Ethereum) of the average interarrival time~() between blocks for validating transactions. A trivial increase in validation time~() introduces the popularly known Verifier's Dilemma, and as we demonstrate, causes more forking and increases unfairness. Large also reduces the tolerance for safety against a Byzantine adversary. Solutions that offload validation to a set of non-chain nodes (a.k.a. off-chain approaches) suffer from trust issues that are non-trivial to resolve. In this paper, we present Tuxedo, the first on-chain protocol to theoretically scale in PoW blockchains. The key innovation in Tuxedo is to separate the consensus on the ordering of transactions from their execution. We achieve this by allowing miners to delay validation of transactions in a block by up to blocks, where is a system parameter. We perform security analysis of Tuxedo considering all possible adversarial strategies in a synchronous network with end-to-end delay and demonstrate that Tuxedo achieves security equivalent to known results for longest chain PoW Nakamoto consensus. Additionally, we also suggest a principled approach for practical choices of parameter as per the application requirement. Our prototype implementation of Tuxedo atop Ethereum demonstrates that it can scale without suffering the harmful effects of naive scaling in existing blockchains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:08ZZubdj9fEC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2020,"The proliferation of application specific cyber-physical systems coupled with the emergence of a variety of attacks on such systems (malware such as Mirai and Hajime) underlines the need to secure such networks. Most existing security efforts have focused on only detection of the presence of malware. However given the ability of most attacks to spread through the network once they infect a few devices, it is important to contain the spread of a virus and at the same time systematically cleanse the impacted nodes using the communication capabilities of the network. Toward this end, we present Airmed - a method and system to not just detect corruption of the application software on a IoT node, but to self correct itself using its neighbors. Airmed's decentralized mechanisms prevent the spread of self-propagating malware and can also be used as a technique for updating application code on such IoT devices. Among the novelties of Airmed are a novel bloom-filter technique along with hardware support to identify position of the malware program from the benign application code, an adaptive self-check for computational efficiency, and a uniform random-backoff and stream signatures for secure and bandwidth efficient code exchange to correct corrupted devices. We assess the performance of Airmed, using the embedded systems security architecture of TrustLite in the OMNeT++ simulator. The results show that Airmed scales up to thousands of devices, ensures guaranteed update of the entire network, and can recover 95% of the nodes in 10 minutes in both internal and external propagation models. Moreover, we evaluate memory and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:tOudhMTPpwUC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2019,"One major shortcoming of permissionless blockchains such as Bitcoin and Ethereum is that they are unsuitable for running Computationally Intensive smart Contracts (CICs). This prevents such blockchains from running Machine Learning algorithms, Zero-Knowledge proofs, etc. which may need non-trivial computation. In this paper, we present YODA, which is to the best of our knowledge the first solution for efficient computation of CICs in permissionless blockchains with guarantees for a threat model with both Byzantine and selfish nodes. YODA selects one or more execution sets (ES) via Sortition to execute a particular CIC off-chain. One key innovation is the MultI-Round Adaptive Consensus using Likelihood Estimation (MIRACLE) algorithm based on sequential hypothesis testing. M I RACLE allows the execution sets to be small thus making YODA efficient while ensuring correct CIC execution with high probability. It adapts the number of ES sets automatically depending on the concentration of Byzantine nodes in the system and is optimal in terms of the expected number of ES sets used in certain scenarios. Through a suite of economic incentives and technical mechanisms such as the novel Randomness Inserted Contract Execution (RICE) algorithm, we force selfish nodes to behave honestly. We also prove that the honest behavior of selfish nodes is an approximate Nash Equilibrium. We present the system design and details of YODA and prove the security properties of MIRACLE and RICE. Our prototype implementation built on top of Ethereum demonstrates the ability of YODA to run CICs with orders of magnitude higher gas per unit time …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:XiSMed-E-HIC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2019,"We present a novel scheme called Decentralized Attestation for Device Swarms (DADS), which is, to the best of our knowledge, the first to accomplish decentralized attestation in device swarms. Device swarms are smart, mobile, and interconnected devices that operate in large numbers and are likely to be part of emerging applications in Cyber-Physical Systems (CPS) and Industrial Internet of Things (IIoTs). Swarm devices process and exchange safety, privacy, and mission-critical information. Thus, it is important to have a good code verification technique that scales to device swarms and establishes trust among collaborating devices. DADS has several advantages over current state-of-the-art swarm attestation techniques: It is decentralized, has no single point of failure, and can handle changing topologies after nodes are compromised. DADS assures system resilience to node compromise/failure while …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:K3LRdlH-MEoC,https://www.cse.iitb.ac.in/~vinayr
Vinay Ribeiro,"['Blockchains', 'Security', 'Networking', 'Indoor Positioning']",9,596,2018,"Recent worldwide cybersecurity attacks caused by Cryptographic Ransomware infected systems across countries and organizations with millions of dollars lost in paying extortion amounts. This form of malicious software takes user files hostage by encrypting them and demands a large ransom payment for providing the decryption key. Signature-based methods employed by Antivirus Software are insufficient to evade Ransomware attacks due to code obfuscation techniques and creation of new polymorphic variants everyday. Generic Malware Attack vectors are also not robust enough for detection as they do not completely track the specific behavioral patterns shown by Cryptographic Ransomware families. This work based on analysis of an extensive dataset of Ran-somware families presents RansomWall, a layered defense system for protection against Cryptographic Ransomware. It follows a Hybrid approach of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=XxeF6MkAAAAJ&sortby=pubdate&citation_for_view=XxeF6MkAAAAJ:P5F9QuxV20EC,https://www.cse.iitb.ac.in/~vinayr
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2023,"The negativity of the discrete Wigner functions (DWFs) is a measure of non-classicality and is often used to quantify the degree of quantum coherence in a system. The study of Wigner negativity and its evolution under different quantum channels can provide insight into the stability and robustness of quantum states under their interaction with the environment, which is essential for developing practical quantum computing systems. We investigate the variation of DWF negativity of qubit, qutrit, and two-qubit systems under the action of (non)-Markovian random telegraph noise (RTN) and amplitude damping (AD) quantum channels. We construct different negative quantum states which can be used as a resource for quantum computation and quantum teleportation. The success of quantum computation and teleportation is estimated for these states under (non)-Markovian evolutions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:pTM1p95iyDUC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2023,"In this article, single, and two‐qubit central spin systems interacting with spin baths are considered and their dynamical properties are discussed. The cases of interacting and non‐interacting spin baths are considered and the quantum speed limit (QSL) time of evolution is investigated. The impact of the size of the spin bath on the quantum speed limit for a single qubit central spin model is analyzed. The quantum correlations for (non‐)interacting two central spin qubits are estimated and their dynamical behavior with that of QSL time under various conditions are compared. How QSL time could be availed to analyze the dynamics of quantum correlations is shown.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:jV6U92sR5-kC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"The impact of a noisy Gaussian channel on a wide range of non-Gaussian input states is studied in this work. The nonclassical nature of the states, both input and output, is developed by studying the corresponding photon statistics and quasi-probability distributions. It is found that photon addition has more robust quantum mechanical properties as compared to the photon subtraction case. The threshold value of the noise parameter corresponding to the transition from partial negative (W and P ) and zero (Q) to completely positive definite, at the center of phase space, depends not only on the average number of thermal photons in the state, but also on the squeezing parameter. In addition it is observed that the nonclassicality of the kth-number filtrated thermal state could be further enhanced by adding photon(s).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:pdtoNNNhT-IC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"In this article we derive the exact dynamics of a two-qubit (spin 1/2) system interacting centrally with separate spin baths composed of qubits in a thermal state. Furthermore, each spin of the bath is coupled to every other spin of the same bath. The corresponding dynamical map is constructed. It is used to analyze the non-Markovian nature of the two qubit central spin dynamics. We further observe the evolution of quantum correlations like entanglement and discord under the influence of the environmental interaction. Moreover, we demonstrate the comparison between this exact two-qubit dynamics and the locally acting central spin model in a spin bath. This work is a stepping stone towards the realization of non-Markovian heat engines and other quantum thermal devices.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:23fPMagKWYUC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"Quantum speed limit time defines the limit on the minimum time required for a quantum system to evolve between two states. Investigation of bounds on speed limit time of quantum system under non-unitary evolution is of fundamental interest, as it reveals interesting connections to quantum (non-)Markovianity. Here, we discuss the characteristics of quantum speed limit time as a function of quantum memory, quantified as the deviation from temporal self-similarity of quantum dynamical maps for CP-divisible as well as indivisible maps, and show that the presence of quantum memory can speed up quantum evolution. This demonstrates the enhancement of the speed of quantum evolution in the presence of quantum memory for a wider class of channels than indicated by the CP-indivisibility criterion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:AimQIn9zGmEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"Quantum heat engines form an active field of research due to their potential applications. There are several phenomena that are unique to the quantum regime, some of which are known to give these engines an edge over their classical counterparts. In this work, we focus on the study of one and two-qubit finite-time Otto engines interacting with squeezed thermal baths, and discuss their important distinctions as well as the advantage of using the two-qubit engine. In particular, the two-qubit engine offers an interesting study of the interplay between the degree of squeezing and that of the coherence between the two qubits. We find that the two-qubit engine generally yields higher power than its one-qubit counterpart. The effective temperature of the squeezed baths can be calculated both for the one and two-qubit engines, and they tend to show an exponential growth with increase in squeezing parameters and . It is also observed that by tuning the squeezing parameters, the machine can be made to work either in the engine or in the refrigerator mode. Additional effects due to the change in the inter-qubit separation have been studied.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:thyth0UfN58C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"We apply the recently proposed quantum probing protocols with an unknown system-probe coupling to probe the convex coefficients in mixtures of commuting states. By using two reference states instead of one as originally suggested, we are able to probe both the lower and upper bounds for the convex coefficient. We perform extensive analysis for the roles of the parameters characterizing the double peaked Gaussian frequency spectrum in the Markovian-to-non-Markovian transition of the polarization dynamics of a single photon. We apply the probing of the convex coefficient to the transition-inducing frequency parameter and show that the non-Markovianity of the polarization dynamics can be confirmed with a single snapshot measurement of the polarization qubit performed at unknown time. Furthermore, we change the “known” measurement coupling that corresponds to our dynamics of interest to unknown …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:XGCB9NUBGnMC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"We probe the quantum speed limit (QSL) of an electron when it is trapped in a non-uniform magnetic field. We show that the QSL increases to a large value, but within the regime of causality, by choosing a proper variation in magnetic fields. We also probe the dependence of QSL on spin of electron and find that it is higher for spin-down electron in the relativistic regime. This can be useful in achieving faster speed of transmission of quantum information. Further, we use the Bremermann–Bekenstein bound to find a critical magnetic field that bridges the gap between non-relativistic and relativistic treatments and relates to the stability of matter. An analytical framework is developed. We also provide a plausible experimental design to supplement our theory.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:jldLm8U3Uk0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"We study the dynamics of the spin and cavity field of the Tavis-Cummings model using quasi-probability distribution functions and second order coherence function, respectively. The effects of (non)-Markovian noise are considered. The relationship between the evolution of the cavity photon number, spin excitation, and atomic inversion under different quantum channels is observed. The equal-time second-order coherence function is used to study the sub-Poissonian behavior of light, and is compared with the two-time second-order coherence function in order to highlight the (anti)-bunching properties of the cavity radiation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:gjFswcl-TRQC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"We investigate the quantum speed limit time for neutral and mesons, both single as well as correlated, within the framework of open quantum systems. The role of coherence-mixing on quantum speed limit is studied. The impact of decoherence and CP violation on quantum speed limit time is also investigated. Quantum speed limit time increases with the evolution time for the single mesons. Correlated mesons are seen to be evolved faster, suggesting that quantum correlations can speed up the evolution.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:w9tx7uSMUCIC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"We derive Margolus-Levitin and Mandelstamm-Tamm type bound on the quantum speed limit time for the creation and decay of quantum correlations by an amount in a quantum system evolving under the influence of its ambient environment. The minimum distance of a non-classical state from an appropriate set of classical states is a legitimate measure of the quantumness of the state. We consider entanglement and quantum discord measures of quantum correlations, quantified using the Bures distance-based measure. To demonstrate the impact of quantum noise on this speed limit time for quantum correlations, we estimate the quantum speed limit time for the creation and decay of quantum correlations for a two-qubit system under modified OUN dephasing and collective two-qubit decoherence channels.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:8_Ku1U0RzzYC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"In this article we derive the exact dynamics of a two qubit (spin 1/2) system interacting centrally with separate fermionic baths composed of qubits in thermal state. Further, each spin of a bath is coupled to every other spin of the same bath. The corresponding dynamical map is constructed. It is used to analyse the non-Markovian nature of the two qubit central spin dynamics. We further observe the evolution of quantum correlations like entanglement and discord under the influence of the environmental interaction. Moreover, we demonstrate the comparison between this exact two qubit dynamics and the locally acting fermionic central spin model. This work is a stepping stone towards the realization of non-Markovian heat engines and other quantum thermal devices.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:NVvf8e-c9oUC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"The eternally non-Markovian (ENM) Pauli channel is an example of a unital channel characterized by a negative decay rate for all time . Here we consider the problem of constructing an analogous non-unital channel, and show that in particular the qubit generalized amplitude damping (GAD) channel cannot be ENM. We construct a quasi-ENM GAD channel, characterized by a time , such that the channel is non-Markovian only and for all time . We point out that the impossibility of the ENM property does not hold for a general qubit or higher-dimensional non-unital channel.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:279hWsFo9KEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"Generalizing to relativistic exponential scaling and using the theory of noise from quantum fluctuations, it has been shown that one vacuum (Rindler, Hartle-Hawking, or Gibbons-Hawking for the cases of the uniformly accelerated detector, black hole, and de Sitter universe, respectively) can be understood as resulting from the scaling of quantum noise in another vacuum. We explore this idea more generally to establish a flat spacetime and curved spacetime analogy. For this purpose, we start by examining noise kernels for free fields in some well-known curved spacetimes, eg, the spacetime of a charged black hole, the spacetime of a Kerr black hole, Schwarzschild-de Sitter, Schwarzschild anti–de Sitter, and Reissner-Nordstrom de Sitter spacetimes. Here, we consider a maximal analytical extension for all these spacetimes and different vacuum states. We show that the exponential scale transformation is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:LRFP056OPQYC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,The minimum evolution time between multi-qubit quantum states is estimated for non-Markovian quantum channels. We consider the maximally coherent pure and mixed states as well as multi-qubit states as initial states and discuss the impacts of initial coherence on their speed of evolution for both dephasing and dissipative processes. The role of the non-zero value of initial coherence under information backflow conditions for the dissipative process is revealed by the flow of quantum speed limit time. The trade-off between mixedness and coherence on the speed limit time reveals the nature of the quantum process the states undergo. The complementarity effect between mixedness and coherence is more prominent in the quantum dissipation process. The parametric trajectory of speed limit time vividly depicts the difference in the evolution of pure and mixed initial states. Our investigation of quantum speed limit time on multi-qubit entangled states reveals that can be identified as a potential dynamical witness to distinguish multi-qubit states in the course of evolution.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:xx6dpm3-DsgC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2022,"IIn this letter, we study the indirect detection of Cosmological Constant from an open quantum system of N entangled spins, weakly interacting with a thermal bath, a massless scalar field minimally coupled with the static De Sitter background, by computing the spectroscopic shifts. By assuming pairwise entanglement between spins, we construct entangled N states using a generalisation of the superposition principle. We have found that in the realistic large N limit, where the system consists of N∼ O (103− 104) spins, the corresponding spectroscopic shifts, caused by the effective Hamiltonian of the system due to Casimir Polder interaction with the bath, play a crucial role to determine the observationally consistent Cosmological Constant, Λ∼ O (10− 122)(Planckian units) in the static patch of De Sitter space.
In recent times the study of the quantum systems that are interacting with their surroundings has acquired a lot of attention in different fields ranging from condensed matter [1–4], quantum information [5], subatomic physics [6–11], quantum dissipative systems [12], holography [13, 14] to cosmology [5, 15–46] for a sample of the relevant literature. Here our interest is the study of the curvature of the static patch of De Sitter space as well as the Cosmological Constant from the spectroscopic Lamb shift [47–49]. The system under consideration is an open quantum system of N entangled spins which are weakly coupled to their environment, modelled by a massless scalar field minimally coupled to static patch of De Sitter space-time. We are interested to study how the entangled states of the system and the Lamb shift change affect the curvature of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:etrBy31LU9kC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"The non-Markovianity of the stochastic process called the quantum semi-Markov (QSM) process is studied using a recently proposed quantification of memory based on the deviation from semigroup evolution, that provides a unified description of divisible and indivisible channels. This is shown to bring out the property of QSM processes to exhibit memory effects even in the CP-divisible regime, in agreement with an earlier result. An operational meaning to the non-Markovian nature of semi-Markov processes is also provided.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:WKZfnVNUP7sC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"Work fluctuation theorems have been one of the important achievements in the field of nonequilibrium Statistical Physics, both in the classical and quantum regimes. Conventionally, the work done on a quantum system is defined by means of a two-point measurement scheme, where a projective measurement of the Hamiltonian is performed both at the beginning and at the end of the process. Recently, quantum work fluctuation theorems in the context of generalized measurements have received a lot of attention. Here, we define a weak value of work, within the broad frame-work of generalized measurements and show that the deviation from the exact work fluctuation theorems are much less in this formalism as compared to previous efforts in the literature, using a two-level system as the model. We find that the original form of Jarzynski equality (valid for projective two-point measurements) does not remain exact in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:xmdbLjM3F_sC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"The action of qubit channels on projective measurements on a qubit state is used to establish an equivalence between channels and properties of generalized measurements characterized by bias and sharpness parameters. This can be interpreted as shifting the description of measurement dynamics from the Schrodinger to the Heisenberg picture. In particular, unital quantum channels are shown to induce unbiased measurements. The Markovian channels are found to be equivalent to measurements for which sharpness is a monotonically decreasing function of time. These results are illustrated by considering various noise channels. The effect of bias and sharpness parameters on various quantum correlations and on the energy cost of measurements is discussed. Further, we illustrate the quantum circuit implementation of the two element positive operator-valued measures characterized by the bias and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:KT8ZRUJCfZgC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"The family of quantum graph and hypergraph states are ubiquitous in quantum information. They have diverse applications ranging from quantum network protocols to measurement based quantum computing. The hypergraph states are a generalization of graph states, a well-known family of entangled multi-qubit quantum states. We can map these states to qudit states. In this work, we analyze a number of noisy quantum channels for qudits, on the family of qudit hypergraph states. The channels studied are the dit-flip noise, phase flip noise, dit-phase flip noise, depolarizing noise, non-Markovian Amplitude Damping Channel (ADC), dephasing noise, and depolarization noise. To gauge the effect of noise on quantum hypergraph states, the fidelity between the original and the final states is studied. The change of coherence under the action of noisy channels is also studied, both analytically and numerically.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:0-VSGmPhd2EC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"The success of the S-matrix in quantum field theory in Minkowski spacetime naturally demands the extension of the construction of the S-matrix in a general curved spacetime in a covariant manner. However, it is well-known that a global description of the S-matrix may not exist in an arbitrary curved spacetime. Here, we give a local construction of S-matrix in quantum field theory in curved spacetime using Riemann-normal coordinates which mimics the methods, generally used in Minkowski spacetime. Using this construction, the scattering amplitudes and cross sections of some scattering processes are computed in a generic curved spacetime. Further, it is also shown that these observables can be used to probe features of curved spacetime as these local observables carry curvature-dependent corrections. Moreover, the compatibility of the local construction of the S-matrix with the spacetime symmetries is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:Ev0xxeg9YZcC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"Discrete quantum walks are operations on the states comprised of an external position space and an internal coin space. The interactions between the two spaces governed by quantum walk operation greatly influence the properties of the states and have important consequences for the quantum algorithms and quantum simulation protocols for which they are used extensively. In this work, we study the effect of symmetric non-Hermitian walk operation on the interactions between the coin and the position spaces of the state. Such an evolution mimics a quantum walk which is interacting with an external environment. To understand this interaction, we study the non-Markovianity of the reduced dynamics and also the entanglement between the two spaces. The non-Hermitian evolution is studied from the two perspectives: the normalised state method, and the metric formalism which relies on a redefinition of the Hilbert space. We argue that metric formalism provides a more consistent measurement of the non-Markovianity under the non-Hermitian dynamics compared to the case under the normalised state method. It can also provide a better indicator of the breakdown of symmetry across the exceptional point. We also show that the non-unitary walks preserve the purity of the state under the metric formulation, due to which one can study entanglement under non-Hermiticity using entanglement entropy. We also find the indications that the coin-position entanglement is more robust in the asymmetric quantum walks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:eqBG2gARfNgC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"In this article we revisit the theory of open quantum systems from the perspective of fermionic baths. Specifically, we concentrate on the dynamics of a central spin half particle interacting with a spin bath. We have calculated the exact reduced dynamics of the central spin and constructed the Kraus operators in relation to that. Further, the exact Lindblad type cannonical master equation corresponding to the reduced dynamics is constructed. We have also briefly touch upon the aspect of non-Markovianity from the backdrop of the reduced dynamics of the central spin.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:nqaVwkbM98IC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"Corresponding to a hypergraph G with d vertices, a quantum hypergraph state is defined by , where f is a d-variable Boolean function depending on the hypergraph G, and denotes a binary vector of length 2 d with 1 at the nth position for n= 0, 1,...(2 d− 1). The nonclassical properties of these states are studied. We consider the annihilation and creation operator on the Hilbert space of dimension 2 d acting on the number states . The Hermitian number and phase operators, in finite dimensions, are constructed. The number-phase uncertainty for these states leads to the idea of phase squeezing. We establish that these states are squeezed in the phase quadrature only and satisfy the Agarwal–Tara criterion for nonclassicality, which only depends on the number of vertices of the hypergraphs. We also point out that coherence is observed in the phase quadrature.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:OeO3PiPA3c0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"We apply the recently proposed quantum probing protocols with an unknown system-probe coupling to probe the convex coefficients in mixtures of commuting states. By using two reference states instead of one as originally suggested, we are able to probe both lower and upper bounds for the convex coefficient. We perform extensive analysis for the roles of the parameters characterizing the double peaked Gaussian frequency spectrum in the Markovian-to-non-Markovian transition of the polarization dynamics of a single photon. We apply the probing of the convex coefficient to the transition-inducing frequency parameter and show that the non-Markovianity of the polarization dynamics can be confirmed with a single snapshot measurement of the polarization qubit performed at unknown time and even with unknown coupling. We also show how the protocol can identify Markovian and non-Markovian time intervals in the dynamics. The results are validated with single photon experiments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:XVBKMArtY_gC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"Quantum speed limit time defines the limit on the minimum time required for a quantum system to evolve between two states. Investigation of bounds on speed limit time of quantum system under non-unitary evolution is of fundamental interest, as it reveals interesting connections to quantum (non-) Markovianity. Here, we discuss the characteristics of quantum speed limit time as a function of quantum memory, quantified as the deviation from temporal self-similarity of quantum dynamical maps for CP-divisible as well as indivisible maps. This provides an operational meaning to CP-divisible (non-) Markovianity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:SmHiq6L9e_wC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"We report an unusual buildup of the quantum coherence in a qubit subjected to non-Hermitian evolution generated by a parity-time () symmetric Hamiltonian, which is reinterpreted as a Hermitian system in a higher dimensional space using Naimark dilation. The coherence is found to be maximum about the exceptional points (EPs), ie the points of coalescence of the eigenvalues as well as the eigenvectors. The nontrivial physics about EPs has been observed in various systems, particularly in photonic systems. As a consequence of enhancement in coherence, the various formulations of Leggett–Garg inequality tests show maximal violation about the EPs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:BvbJ36a9xgsC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"In this article, we study the quantum field theoretic generalization of the Caldeira-Leggett model to describe the Brownian Motion in general curved space-time considering interactions between two scalar fields in a classical gravitational background. The thermalization phenomena is then studied from the obtained de Sitter solution using quantum quench from one scalar field model obtained from path integrated effective action in Euclidean signature. We consider an instantaneous quench in the time-dependent mass protocol of the field of our interest. We find that the dynamics of the field post-quench can be described in terms of the state of the generalized Calabrese-Cardy (gCC) form and computed the different types of two-point correlation functions in this context. We explicitly found the conserved charges of algebra that represents the gCC state after a quench in de Sitter space and found it to be significantly different from the flat space-time results. We extend our study for the different two-point correlation functions not only considering the pre-quench state as the ground state, but also a squeezed state. We found that irrespective of the pre-quench state, the post quench state can be written in terms of the gCC state showing that the subsystem of our interest thermalizes in de Sitter space. Furthermore, we provide a general expression for the two-point correlators and explicitly show the thermalization process by considering a thermal Generalized Gibbs ensemble (GGE). Finally, from the equal time momentum dependent counterpart of the obtained results for the two-point correlators, we have studied the hidden features of the power spectra …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:4Ol-GlP6dRYC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"The direct detection of gravitational waves from binary mergers has been hailed as the discovery of the century. In the light of recent evidence on the existence of gravitational waves, it is now possible to know about the properties of matter under extreme conditions in compact astrophysical objects and different dynamical spacetimes. The foremost theme of the present article is to bring out the various features of the interaction between photons and gravitons that can be used in astrophysical observations. The effective action of interacting photons containing light–matter coupling and self-interaction term is constructed by eliminating the graviton degrees of freedom coupled to both matter and photons. It is shown that the equation of state of matter can be probed from the dynamics of light in this theory. The vacuum birefringence is also shown to be a generic property in this theory that arises from the nonlinear …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:NOsVDcwM7ZYC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"We investigate the dynamics of quantum correlation (QC) under the effects of reservoir memory, as a resource for quantum information and computation tasks. Quantum correlations of two-qubit systems are used for implementing quantum teleportation successfully, and for investigating how teleportation fidelity, violation of Bell-CHSH inequality, quantum steering and entanglement are connected with each other under the influence of noisy environments. Both Markovian and non-Markovian channels are considered, and it is shown that the decay and revival of correlations follow the hierarchy of quantum correlations in the state space. Noise tolerance of quantum correlations is checked for different types of unital and non-unital quantum channels, with and without memory. The quantum speed limit time is investigated from the perspective of memory of quantum noise, and the corresponding dynamics …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:oe-dhlAyNXgC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"The action of qubit channels on projective measurements on a qubit state is used to establish an equivalence between channels and properties of generalized measurements characterized by bias and sharpness parameters. This can be interpreted as shifting the description of measurement dynamics from the Schrodinger to the Heisenberg picture. In particular, unital (non-unital) quantum channels are shown to induce unbiased (biased) measurements. The Markovian channels are found to be equivalent to measurements for which sharpness is a monotonically decreasing function of time. These results are illustrated by considering various noise channels. Further, the effect of bias and sharpness parameters on the energy cost of a measurement and its interplay with the non-Markovian dynamics is also discussed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:ptKmfjyPmtwC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2021,"The reliability of quantum channels for transmitting information is of profound importance from the perspective of quantum information. This naturally leads to the question as how well a quantum state is preserved when subjected to a quantum channel. We propose a measure of quantumness of channels based on non-commutativity of quantum states that is intuitive and easy to compute. We apply the proposed measure to some well-known noise channels, both Markovian and non-Markovian, and find that the results are in good agreement with those from a recently introduced -norm coherence based measure.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:gC9vZy1QUBAC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"We study a class of qubit non-Markovian general Pauli dynamical maps with multiple singularities in the generator. We discuss a few easy examples involving trigonometric or other nonmonotonic time dependence of the map, and discuss in detail the structure of channels which don’t have any trigonometric functional dependence. We demystify the concept of a singularity here, showing that it corresponds to a point where the dynamics can be regular but the map is momentarily noninvertible, and this gives a basic guideline to construct such non-invertible non-Markovian channels. Most members of the channels in the considered family are quasi-eternally non-Markovian (QENM), which is a broader class of non-Markovian channels than the eternal non-Markovian channels. Specifically, the measure of quasi-eternal non-Markovian (QENM) channels in the considered class is shown to be in the isotropic case, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:dWFDXTerv58C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,The non-Markovianity of the stochastic process called the quantum semi-Markov (QSM) process is studied using a recently proposed quantification of memory based on the deviation from semigroup evolution and thus providing a unified description of divisible and indivisible channels. This is shown to bring out the property of QSM process to exhibit memory effects in the CP-divisible regime. An operational meaning to the non-Markovian nature of semi-Markov processes is also provided.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:Ip0yah2EK7AC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"Quantum bits or qubits play a vital role in Quantum computation and to be able to manufacture qubits at will is a prerequisite for any quantum lab. Qubits differ from normal bits in the fact that instead of being limited to either 1 or 0, it exists in superposition and can be entangled. Our short term goal was to manufacture and characterize two qubit Bell states using spontaneous parametric downconversion (SPDC) which would act as the groundwork for future quantum experiments. Bell states are four maximally entangled 2 qubit states, all of which have a maximal value of. These are 2 qubit states which are in an equal superposition that takes one of the following four forms
To confirm that we are indeed producing the Bell state or any other entangled state we choose, some means of characterizing and also representing the produced state needs to be adopted and quantum state tomography is just that.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:tC_cyO4PokcC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"Here, we review some of the recent developments in quantum optics. After a brief introduction to the historical development of the subject, we discuss some of the modern aspects of quantum optics including atom field interactions, quantum state engineering, metamaterials and plasmonics, optomechanical systems, PT (parity-time) symmetry in quantum optics, as well as, quasi-probability distributions and quantum state tomography. Further, the recent developments in topological photonics is briefly discussed. The potent role of the subject in the development of our understanding of quantum physics and modern technologies is highlighted.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:EHjGVGKDnHoC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"The Leggett–Garg inequalities impose restrictions on the values taken by some combinations of the two-time correlation functions of observables in order to be explainable by a noninvasive realist classical model. While in the unitary dynamics, it is straightforward to compute these correlation functions, open system effects bring in subtleties. Specifically, for non-Markovian dynamics, which involves setting up of system–bath correlations, the Leggett–Garg measurements disrupt these correlations, making a full system–bath Hamiltonian approach natural. However, here we point out that the problem can also be dealt with from a reduced dynamics perspective. The key point is that the noise superoperator acting on the system must be suitably updated after measurement interventions. Also considered is the effect of Markovian versus non-Markovian behavior as well as classically non-Markovian processes on the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:tL4NlYW7KOUC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"The problem of defining quantum non-Markovianity has proven elusive, with various in-equivalent criteria put forth to address it. The concept of CP-indivisibility and the hierarchy of stronger divisibility criteria going up to P-indivisibility, capture a fundamental aspect of memory in quantum non-Markovianity. In practice, however, there can be a memory-like influence associated with divisible channels in the form of weakening, if not reversing, the effects of decoherence. Arguably, such a facet of memory relates to CP-indivisibility as quantum discord relates to entanglement. We concretize this weaker notion of non-Markovianity by identifying it with deviation from “temporal self-similarity”, the property of a system dynamics whereby the propagator between two intermediate states is independent of the initial time . We illustrate this idea through examples, and propose a geometric quantification of temporal self-similarity …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:2K5qSjdd3awC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"In any natural science, measurements are the essential link between theory and observable reality. Is it possible to obtain accurate and relevant information via measurement whose action on the probed system is unknown? In other words, can one be convinced to know something about the nature without knowing in detail how the information was obtained? In this paper, we show that the answer is, surprisingly, yes. We construct and experimentally implement a quantum optical probing measurement where measurements on the probes, ie, the photons' polarization states, are used to extract information on the systems, ie, the frequency spectra of the same photons. Unlike the preexisting probing protocols, our measurement does not require any knowledge of the interaction between the probe and the system.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:TaF7eNGHiZkC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"For combining different single photon channels into a single path, we use an effective and reliable technique which is known as quantum multiple access. We take advantage of an add-drop multiplexer capable of pushing and withdrawing a single photon into an optical fiber cable which carries quantum bits from multiusers. In addition to this, spreading spreads the channel noise at receiver side and use of filters stop the overlapping of adjacent channels, which helps in reducing the noise level and improved signal-to-noise ratio. In this way, we obtain enhanced performance of code division multiple access-based QKD links with a single photon without necessity of amplifiers and modulators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:-QO_JlXAMEAC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"We study various formulations of Leggett–Garg inequality (LGI), specifically, the Wigner and Clauser–Horne forms of LGI, in the context of subatomic systems, in particular, three flavor neutrino as well as meson systems. The optimal forms of various LGIs for either neutrinos or mesons are seen to depend on measurement settings. For the neutrinos, some of these inequalities can be written completely in terms of experimentally measurable probabilities. Hence, the Wigner and Clauser–Horne forms of LGI are found to be more suitable as compared to the standard LGI from the experimental point of view for the neutrino system. Further, these inequalities exhibit maximum quantum violation around the energies roughly corresponding to the maximum neutrino flux. The Leggett–Garg type inequality is seen to be more suited for the meson dynamics. The meson system being inherently a decaying system allows one to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:9nzIJd-pbyIC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"Various nonclassical and quantum phase properties of photon added then subtracted displaced Fock state have been examined systematically and rigorously. Higher-order moments of the relevant bosonic operators are computed to test the nonclassicality of the state of interest, which reduces to various quantum states (having applications in quantum optics, metrology and information processing) in different limits ranging from the coherent (classical) state to the Fock (most nonclassical) states. The nonclassical features are discussed using Klyshko’s, Vogel’s, and Agarwal–Tara’s criteria as well as the criteria of lower-and higher-order antibunching, sub-Poissonian photon statistics and squeezing. In addition, phase distribution function and quantum phase fluctuation have been studied. These properties are examined for various combinations of number of photon addition and/or subtraction and Fock parameter …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:grZTYWtF7b0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"We propose and study in detail a class of qubit depolarizing channels that are asymmetrically non-Markovian and are characterized by up to three singularities in the generator. The three canonical decoherence rates are shown to flip sign after each singularity. Most members of the channels in the family are quasi-eternally non-Markovian (QENM) channels, whereby there is a finite time , such that the channel is CP-indivisible for all . In specific, the measure of QENM channels in the symmetric case is , and that in the asymmetric case is about 0.96.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:xV_PwZns_iUC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"In this work, we derive a quantum information theoretic quantity similar to the Leggett-Garg inequality, which can be defined in terms of neutrino transition probabilities. For the case of ν μ→ ν e/ν¯ μ→ ν¯ e transitions, this quantity is sensitive to CP violating effects as well as the neutrino mass-hierarchy, namely which neutrino mass eigenstate is heavier than the other ones. The violation of the inequality for this quantity shows an interesting dependence on mass-hierarchy. For normal (inverted) mass-hierarchy, it is significant for ν μ→ ν e (ν¯ μ→ ν¯ e) transitions. This is applied to the two ongoing accelerator experiments T2K and NOνA as well as the future experiment DUNE.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:KgQn5aR88cEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"Quantum non-Markovianity modifies the environmental decoherence of a system. This situation is enriched in complex systems owing to interactions among subsystems. We consider the problem of distinguishing the multiple sources of non-Markovianity using a simple power spectrum technique, applied to a qubit interacting with another qubit via a Jaynes–Cummings-type Hamiltonian and simultaneously subjected to some well-known noise channels, such as the random telegraph noise and non-Markovian amplitude damping, which exhibit both Markovian as well as non-Markovian dynamics under different parameter ranges.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:GU5qFXB69o4C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"We make a detailed analysis of quantumness for various quantum noise channels, both Markovian and non-Markovian. The noise channels considered include dephasing channels like random telegraph noise, non-Markovian dephasing and phase damping, as well as the non-dephasing channels such as generalized amplitude damping and Unruh channels. We make use of a recently introduced witness for quantumness based on the square norm of coherence. It is found that the increase in the degree of non-Markovianity increases the quantumness of the channel. This may be attributed to the fact that the non-Markovian dynamics involves the generation of entanglement between the system and environment degrees of freedom.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:xdWr7vBG5PQC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2020,"The effect of two quantum state engineering processes that can be used to burn a hole at vacuum in the photon number distribution of quantum states of radiation field is compared using various witnesses of lower‐ and higher‐order nonclassicality as well as a measure of nonclassicality. Specifically, the modification in nonclassical properties due to vacuum state filtration and a single photon addition on an even coherent state, binomial state, and Kerr state are investigated using the criteria of lower‐ and higher‐order antibunching, squeezing, and sub‐Poissonian photon statistics. Further, the amount of nonclassicality present in these engineered quantum states having enormous applications in continuous variable quantum communication is quantified and analyzed by using an linear entropy‐based entanglement potential. It is observed that all the quantum states studied here are highly nonclassical, and the hole …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:0a-0BRjGxG0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"The violation of Leggett-Garg-type inequalities (LGtIs) is studied on a two-level atom, driven by an external field in the presence of a squeezed thermal reservoir. The violations are observed in the underdamped regime where the spontaneous transition rate is much smaller compared to the Rabi frequency. An increase in thermal effects is found to decrease the extent of violation as well as the time over which the violation lasts. With the increase in the value of the squeezing parameter the extent of violation of LGtIs is seen to reduce. The violation of LGtIs is favored by an increase in the driving frequency. Further, the interplay of the degree of violation and strength of the measurements is studied. It is found that the maximum violation occurs for ideal projective measurements.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:yd8rdvfCKnwC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"In article 1900141, Priya Malpani, Anirban Pathak, and co-workers studied different aspects of quantum phase properties of a set of engineered quantum states, which can be reduced from photon added/subtracted displaced Fock state, in view of their applications in quantum technology. This image represents the polar plot for quantum phase distribution of this set of engineered quantum states.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:r0ARIG2f-gUC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"Quantum phase properties of photon added and subtracted displaced Fock states (and their limiting cases) are investigated from a number of perspectives, and it is shown that the quantum phase properties are dependent on the quantum state engineering operations performed. Specifically, the analytic expressions for quantum phase distributions and angular Q distribution as well as measures of quantum phase fluctuation and phase dispersion are obtained. The uniform phase distribution of the initial Fock states is observed to be transformed by the unitary operation (i.e., displacement operator) into non‐Gaussian shape, except for the initial vacuum state. It is observed that the phase distribution is symmetric with respect to the phase of the displacement parameter and becomes progressively narrower as its amplitude increases. The non‐unitary (photon addition/subtraction) operations make it even narrower in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:g2bnS7N2_ggC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"Gravity induced neutrino-antineutrino oscillations are studied in the context of one-and two-flavor scenarios. This allows one to investigate the particle-antiparticle correlations in two and four level systems, respectively. Flavor entropy is used to probe the entanglement in the system. The well known witnesses of nonclassicality such as Mermin and Svetlichny inequalities are investigated. Since the extent of neutrino-antineutrino oscillation is governed by the strength of the gravitational field, the behavior of nonclassicality shows interesting features as one varies the strength of the gravitational field. Specifically, the suppression of the entanglement with the increase of the gravitational field is observed which is witnessed in the form of decrease in the flavor entropy of the system. The features of the Mermin and the Svetlichny inequalities allow one to make statements about the degeneracy of neutrino mass eigenstates.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:QhyW1pcpMSYC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"If an Unruh-DeWitt detector moves with a uniform acceleration in Fock-space vacuum, then the transition rate of the detector is proportional to the thermal spectrum. It is well known that the transition rate of the detector crucially depends on the two-point function along the detectors trajectory and in order to compute it the standard """" regularization is used for Fock space. Numerically, we show here that the regulator is generic in polymer quantization, the quantization method used in \emph{loop quantum gravity} with a finite value , which leads to non-thermal spectrum for the uniformly accelerated detector. We also discuss the response of a spatially smeared detector.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:dhlC0B1VZgkC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"A three-level atom in Λ configuration is reduced to an effective two-level system, under appropriate conditions, and its PT symmetric properties are investigated. This effective qubit system, when subjected to a beam-splitter type of interaction, provides the scope of directly (indirectly) probing the nonclassical properties of the output (input) state. Here, we study nonclassical properties of the output state by using some well-known measures of nonclassical correlations like the measurement-induced disturbance, concurrence, and negativity. The nonclassical features are found to enhance in the PT symmetric (PTS) phase compared to the PT symmetry broken (PTB) phase. Further, the output ports of the beam splitter are subjected to different quantum noise channels, both non-Markovian, eg, random telegraph noise as well as Markovian, eg, phase damping and amplitude damping noise. The application of noise …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:_obbd28Je0oC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"The present work is devoted to the characterization of the Leggett-Garg inequality (LGI) for three flavored neutrino oscillations in the presence of both matter and charge-conjugation and parity violating effects. This study complements and completes the recent one put forward in arXiv: 1710.05562 by relaxing the stationary condition. At variance with the latter case, the LGI contains interference terms which cannot be expressed in terms of experimentally measurable quantities, thus drawing a clear-cut distinction between the two scenarios, as well as highlighting the role of the stationary assumption on such systems. We find that the additional terms are small for a high energy neutrino beam compared to the maximum value attained by the Leggett-Garg parameter.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:rlkjS_mI7T0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"We consider two non-Markovian models: random telegraph noise and non-Markovian dephasing. The memory in these models is studied from the perspective of quantum Fisher information flow. This is found to be consistent with the other well-known witnesses of non-Markovianity. The two noise channels are characterized quantum information theoretically by studying their gate and channel fidelities. Further, the quantum coherence and its balance with mixedness is studied. This helps to put in perspective the role that the two noise channels can play in various facets of quantum information processing and quantum communication.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:MhMRrlfrL94C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"A three level atom in configuration is reduced to an effective two level system, under appropriate conditions, and its symmetric properties are investigated. This effective qubit system when subjected to a beam-splitter type of interaction, it provides the scope of directly (indirectly) probing the nonclassical properties of the output (input) state. Here, we study nonclassical properties of the output state by using some well known measures of nonclassical correlations like the measurement induced disturbance, concurrence and negativity. The nonclassical features are found to enhance in the symmetric (PTS) phase compared to the symmetry broken (PTSB) phase. Further, the output ports of the beam-splitter are subjected to different quantum noise channels, both non-Markovian, e.g., random telegraph noise as well as Markovian, e.g., phase damping, and amplitude damping noise. The application of noise channels is found to decrease the degree of nonclassicality, though continuing to exhibit distinct behavior in PTS and PTSB phases, with the dominant behavior appearing in the former case.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:nDos0PVUvP8C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"This work is at the interface of graph theory and quantum mechanics. Quantum correlations epitomize the usefulness of quantum mechanics. Quantum discord is an interesting facet of bipartite quantum correlations. Earlier, it was shown that every combinatorial graph corresponds to quantum states whose characteristics are reflected in the structure of the underlined graph. A number of combinatorial relations between quantum discord and simple graphs were studied. To extend the scope of these studies, we need to generalize the earlier concepts applicable to simple graphs to weighted graphs, corresponding to a diverse class of quantum states. To this effect, we determine the class of quantum states whose density matrix representation can be derived from graph Laplacian matrices associated with a weighted directed graph and call them graph Laplacian quantum states. We find the graph theoretic conditions for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:WliCQ7fkH-wC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"Quantum key distribution (QKD) is a key exchange protocol which is implemented over free space optical links or optical fiber cable. When direct communication is not possible, QKD is performed over fiber cables, but the imperfections in detectors used at the receiver side and also the material properties of fiber cables limit the long-distance communication. Free space-based QKD is free from such limitations and can pave the way for satellite-based quantum communication to set up a global network for sharing secret messages. To implement free space optical links, it is essential to study the effect of atmospheric turbulence. Here, an analysis is made for satellite-based quantum communication using QKD protocols. We assume two specific attacks, namely PNS (photon number splitting) and IRUD (intercept-resend with unambiguous discrimination), which could be main threats for future QKD-based satellite …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:Cd1N8iHLSCsC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"Here we review some of the recent developments in Quantum Optics. After a brief introduction to the historical development of the subject, we discuss some of the modern aspects of quantum optics including atom field interactions, quantum state engineering, metamaterials and plasmonics, optomechanical systems, PT (Parity-Time) symmetry in quantum optics as well as quasi-probability distributions and quantum state tomography. Further, the recent developments in topological photonics is briefly discussed. The potent role of the subject in the development of our understanding of quantum physics and modern technologies is brought out.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:rt76XxiL7BoC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"The interplay between the nonclassical features and the parity-time (PT) symmetry (or its breaking) is studied here by considering a PT-symmetric system consisting of two cavities with gain and loss. The conditions for PT invariance are obtained for this system. The behavior of the average photon number corresponding to the gain and loss modes for different initial states (eg, vacuum, NOON, coherent, and thermal states) has also been obtained. With the help of the number operators, quantum Zeno and anti-Zeno effects are studied, and the observed behavior is compared in PT-symmetric (PTS) and PT-symmetry-broken (PTSB) regimes. It has been observed that the relative phase of the input coherent fields plays a key role in the occurrence of these effects. Further, some nonclassicality features are witnessed using criteria based on the number operator (s). Specifically, intermodal antibunching, sum, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:W-zclTkWZekC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"We study the interplay between coherence and mixedness in meson and neutrino systems. The dynamics of the meson system is treated using the generic decoherence model taking into account the decaying nature of the system. Neutrino dynamics is studied in the context of three flavour oscillations within the framework of a decoherence model recently used in the context of LSND (Liquid Scintillator Neutrino Detector) experiment. For meson systems, the decoherence effect is negligible in the limit of zero CP violation. Interestingly, the average mixedness increases with time for about one lifetime of these particles. For neutrino system, in the context of the model considered, the decoherence effect is maximum for neutrino energy around 30 MeV. Further, the effect of CP violating phase is found to decrease (increase) the coherence in the upper (lower ) half plane.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:hmHAmvAdi5MC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"Nonclassical properties of photon added and subtracted displaced Fock states are studied using various witnesses of lower‐ and higher‐order nonclassicality. Compact analytic expressions are obtained for the nonclassicality witnesses. Using those expressions, it is established that these states and the states that can be obtained as their limiting cases (except coherent states) are highly nonclassical as they show the existence of lower‐ and higher‐order antibunching and sub‐Poissonian photon statistics, in addition to the nonclassical features revealed through the Mandel parameter, zeros of Q function, Klyshko's criterion, and Agarwal–Tara criterion. Further, some comparison between the nonclassicality of photon added and subtracted displaced Fock states have been performed using witnesses of nonclassicality. This has established that between the two types of non‐Gaussianity inducing operations (i.e …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:mdGv78FIKkEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2019,"Spread-spectrum techniques are widely used in radio communication and telecommunication. Any signal like acoustic, electrical, and electromagnetic signal produced with a specific bandwidth is spread in frequency hence results in a wider bandwidth. Spread spectrum techniques are deployed in telecommunication because of many significant advantages, eg, to achieve secure communications, to detect the eavesdropping, to resist natural interference, to bound power flux density for satellite down links and resistance to noise and jamming. In spread spectrum technique, frequency hopping (FH) is used as a basic modulation technique by which any telecommunication signal can be transmitted on a wider bandwidth (radio bandwidth) as compared to frequency value of the original signal. Spread spectrum techniques deploy FH, direct sequence (DS), or mix of both methods so that it can be used for multiple access and reduces the interference to other receivers to get the overall privacy. At the receiver side, the received signals are correlated to extract the original information being sent. The two main motivation behind spread spectrum are: to create anti-jamming for unauthenticated person and to provide low probability of interception. Spread spectrum technique includes chirp spread spectrum (CSS), directsequence spread spectrum (DSSS), frequency-hopping spread spectrum (FHSS), and time-hopping spread spectrum (THSS). In all these methods pseudorandom number sequences are used throughout the bandwidth to confirm and to adjust the spreading pattern. IEEE 802.11 wireless standard uses DSSS or FHSS in radio communication …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:T3x1S4x-kFYC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:sc_hyC0iex0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"Many facets of nonclassicality are probed in the context of three flavour neutrino oscillations including matter effects and CP violation. The analysis is carried out for parameters relevant to two ongoing experiments and T2K, and also for the upcoming experiment DUNE. The various quantum correlations turn out to be sensitive to the mass-hierarchy problem in neutrinos. This sensitivity is found to be more prominent in DUNE experiment as compared to and T2K experiments. This can be attributed to the large baseline and high energy of the DUNE experiment. Further, we find that to probe these correlations, the neutrino (antineutrino) beam should be preferred if the sign of mass square difference turns out to be positive (negative).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:9djSGow2EaoC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"Quantum non-Markovianity of a quantum noisy channel is typically identified with information backflow or, more generally, with departure of the intermediate map from complete positivity. But here, we also indicate certain non-Markovian channels that cannot be witnessed by the CP-divisibility criterion. In complex systems, non-Markovianity becomes more involved on account of subsystem dynamics. Here we study various facets of non-Markovian evolution, in the context of coined quantum walks, with particular stress on disambiguating the internal vs. environmental contributions to non-Markovian backflow. For the above problem of disambiguation, we present a general power-spectral technique based on a distinguishability measure such as trace-distance or correlation measure such as mutual information. We also study various facets of quantum correlations in the transition from quantum to classical random …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:EGhj4itiAA0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"We introduce a method to construct non-Markovian variants of completely positive (CP) dynamical maps, particularly, qubit Pauli channels. We identify non-Markovianity with the breakdown in CP divisibility of the map, ie, appearance of a not-completely positive intermediate map. In particular, we consider the case of non-Markovian dephasing in detail. The eigenvalues of the Choi matrix of the intermediate map crossover at a point which corresponds to a singularity in the canonical decoherence rate of the corresponding master equation and thus to a momentary noninvertibility of the map. Thereafter, the rate becomes negative, indicating non-Markovianity. We quantify the non-Markovianity by two methods, one based on CP divisibility [Hall et al., Phys. Rev. A 89, 042120 (2014)], which does not require optimization but requires normalization to handle the singularity, and another method, based on distinguishability …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:xZ4F5NOCMJ0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"A master equation has been constructed for a global system–bath interaction in the both absence and presence of non-Markovian noise. For the memoryless case, it has been exactly solved for a paradigmatic class of two qubit states in high- and zero-temperature thermal environment. For the non-Markovian model, it has been solved for zero-temperature bath. The evolution of quantum coherence and entanglement has been observed in the presence of the above-mentioned interactions. We show that the global part of the system–bath interaction compensates for the decoherence, resulting in slowdown of coherence and entanglement decay. For an appropriately defined limiting case, both coherence and entanglement show freezing behavior for the high-temperature bath. In case of zero-temperature bath, the mentioned interaction not only stabilizes the non-classical correlations, but also enhances them …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:J_g5lzvAfSwC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"In quantum key distribution, one conservatively assumes that the eavesdropper Eve is restricted only by physical laws, whereas the legitimate parties, namely the sender Alice and receiver Bob, are subject to realistic constraints, such as noise due to environment-induced decoherence. In practice, Eve too may be bound by the limits imposed by noise, which can give rise to the possibility that decoherence works to the advantage of the legitimate parties. A particular scenario of this type is one where Eve can’t replace the noisy communication channel with an ideal one, but her eavesdropping channel itself remains noiseless. Here, we point out such a situation, where the security of the ping–pong protocol (modified to a key distribution scheme) against a noise-restricted adversary improves under a non-unital noisy channel, but deteriorates under unital channels. This highlights the surprising fact that, contrary …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:bB6ab1qDjH0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"Quantum key distribution is an effective encryption technique which can be used to perform secure quantum communication between satellite and ground stations. Quantum cryptography enhances security in various networks such as optical fibers and wireless networks. In addition to this, these networks become vulnerable in presence of high attenuation due to atmospheric effects and noise. Hence, errors occurs due to decoherence. The noisy quantum channel is modeled and implemented by the redundancy-free quantum error correction scheme which provides better security and throughput efficiency as shown in simulation results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:iMbXGt5dmAEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"Entropic Leggett–Garg inequality is studied in systems like neutrinos in the context of two and three flavor neutrino oscillations and in neutral, and K mesons. The neutrino dynamics is described with the matter effect taken into consideration. For the decohering B/K meson systems, the effect of decoherence and CP violation have also been taken into account, using the techniques of open quantum systems. Enhancement in the violation with increase in the number of measurements has been found, in consistency with findings in spin-s systems. The effect of decoherence is found to bring the deficit parameter closer to its classical value zero, as expected. The violation of entropic Leggett–Garg inequality lasts for a much longer time in K meson system than in and systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:9bzyojSiTPoC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"We study the geometric phase for neutrinos at various man-made facilities, such as the reactor and accelerator neutrino experiments. The analysis is done for the three flavor neutrino scenario, in the presence of matter and for general, noncyclic paths. The geometric phase is seen to be sensitive to the CP violating phase in the leptonic sector and the sign ambiguity in . We find that for neutrino experimental facilities where the geometric phase can complete one cycle, all the phase curves corresponding to different values of CP violating phase, converge to a single point, called the cluster point. There are two distinct cluster points for positive and negative signs of Δ 31. Thus, the geometric phase can contribute to our understanding of the neutrino mass hierarchy problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:9Nmd_mFXekcC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"The possibility of observing nonclassical features in a physical system comprised of a cavity with two ensembles of two-level atoms has been investigated by considering different configurations of the ensembles with respect to the node and antinode of the cavity field under the framework of open quantum systems. The study reveals the strong presence of nonclassical characters in the physical system by establishing the existence of many facets of nonclassicality, such as the sub-Poissonian boson statistics and squeezing in single modes, intermodal squeezing, intermodal entanglement, antibunching, and steering. The effect of a number of parameters, characterizing the physical system, on the different aspects of nonclassicality is also investigated. Specifically, it is observed that the depth of the nonclassicality witnessing parameters can be enhanced by externally driving one of the ensembles with an optical field …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:lsEYeSe2tpEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"Non-Markovian quantum effects are typically observed in systems interacting with structured reservoirs. Discrete-time quantum walks are prime example of such systems in which, quantum memory arises due to the controlled interaction between the coin and position degrees of freedom. Here we show that the information backflow that quantifies memory effects can be enhanced when the particle is subjected to uncorrelated static or dynamic disorder. The presence of disorder in the system leads to localization effects in 1-dimensional quantum walks. We shown that it is possible to infer about the nature of localization in position space by monitoring the information backflow in the reduced system. Further, we study other useful properties of quantum walk such as entanglement, interference and its connection to quantum non-Markovianity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:UIW7YHcmbUEC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"We show that non-Markovian effects of the reservoirs can be used as a resource to extract work from an Otto cycle. The state transformation under non-Markovian dynamics is achieved via a two-step process, namely an isothermal process using a Markovian reservoir followed by an adiabatic process. From second law of thermodynamics, we show that the maximum amount of extractable work from the state prepared under the non-Markovian dynamics quantifies a lower bound of non-Markovianity. We illustrate our ideas with an explicit example of non-Markovian evolution.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:8baWPQ8fTxwC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"We study the violations of Leggett-Garg (LG) inequality in a qubit subjected to non-Markovian noisy channels such as Random Telegraph Noise (RTN) and Ornstein-Uhlenbeck Noise (OUN). Quite generally, the state-independence of the violation in the noiseless case is preserved under the application of noise. Within a given family of noisy channels (in specific, RTN or OUN), we find an enhancement in the violation in the non-Markovian case as compared to the Markovian case. We thus find that non-Markovianity provides a stronger demonstration of quantumness of the system.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:L7JqRCIhofwC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"In this work we study temporal quantum correlations, quantified by Leggett-Garg (LG) and LG-type inequalities, in the B and K meson systems. We use the tools of open quantum systems to incorporate the effect of decoherence which is quantified by a single phenomenological parameter. The effect of C P violation is also included in our analysis. We find that the LG inequality is violated for both B and K meson systems, the violation being most prominent in the case of K mesons and least for B s system. Since the systems with no coherence do not violate LGI, incorporating decoherence is expected to decrease the extent of violation of LGI and is clearly brought out in our results. We show that the expression for the LG functions depends upon an additional term, apart from the experimentally measurable meson transition probabilities. This term vanishes in the limit of zero decoherence. On the other hand, the LG-type …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:Zrzg8MEyHc4C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"This chapter is devoted to the dissipative harmonic oscillator, a paradigm model of open quantum systems. We present two well known approaches to this problem, viz., the semigroup or the Lindbladian approach and the quantum Brownian approach. The physical conditions under which each regime is operational are spelled out.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:-l7FTdOV6Y0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"Tunneling is a bonafide quantum mechanical effect [168, 169]. Since it involves barrier penetration, it is also an inherently non-perturbative process. It serves a crucial role in the test of quantum coherence in macroscopic regimes, also known as Macroscopic Quantum Coherence (MQC) [66].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:aEPHIGigqugC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"In this chapter, we will discuss the foundations of open quantum systems whose roots are in (non) equilibrium (quantum) statistical mechanics. The approach to this problem is to begin with the Liouville equation, which is the equation of motion in (quantum) statistical mechanics, and then develop a scheme that ensures irreversible dynamics emerging from it [53, 54]. Irreversible dynamics is the observed macroscopic behavior and hence the need to understand how it emerges from the underlying reversible microscopic dynamics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:AVQCy-ZCKIsC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"A number of phenomena in nature can be explained by means of a two-state model wherein a particle tunnels between two different localized states. Such a system is usually strongly affected by the ambient environment. The existence of two-level systems in glasses was proposed in [148, 149] in order to help understand low temperature anomalies of specific heat in them.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:l04XxKJJ8swC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"This chapter is devoted to some of the recent trends in open quantum systems and includes a foray into relativistic phenomena such as the Unruh effect as well as sub-atomic physics, including neutrinos and mesons. Unruh effect is the sobriquet given to the thermal like effect due to accelerated motion and is the flat space analogue of the celebrated Hawking effect. Unruh effect as a thermal like effect suggests an open quantum system, in the language of quantum information processing, a quantum channel, characterization of which should elucidate the general properties of the effect.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:CQX_Vi8q7s0C,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"This chapter is devoted to the interface between open system ideas and the burgeoning field of quantum information. Quantum information [37, 201] is, as the name suggests, the broad name given to information tasks that make use of the laws of quantum mechanics. It encompasses within its purview, communication, computation and foundational information theoretical tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:OiA2aNrLN7MC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"The study of the dynamics of Open Quantum Systems, as already introduced before, essentially involves the dynamics of the system of interest taking into account the effect of the ambient environment [91, 1, 2]. Information from the system leaks into the environment and is interpreted as dissipation as well as loss of coherence, decoherence. When the dynamics of the system is undeterministic, the most successful approach to study the system dynamics is the functional (path) integral formalism.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:yHo2-vvHkLQC,http://home.iitj.ac.in/~subhashish
Subhashish Banerjee,"['Open quantum systems', 'quantum information', 'quantum field theory', 'quantum optics', 'foundations']",25,1943,2018,"In this chapter, we will focus on some of the basic tools of quantum statistical mechanics as well as get introduced to the subject of path integration. These are vast enterprises in themselves and are needed to have an understanding of the subject of open quantum systems. Here we introduce some of the basic concepts in quantum statistical mechanics and path integration.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UU9KftAAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UU9KftAAAAAJ:gD_FYv0mKhcC,http://home.iitj.ac.in/~subhashish
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2022,"Deep learning Processor Units (DPUs) from Xilinx are design-time configurable CNN accelerators for FPGAs. We propose EXPRESS, which predicts the execution time of any given CNN on a DPU. EXPRESS incorporates the effect of bus connections into prediction. As a DPU is invoked by a host CPU to process a CNN layer by layer, EXPRESS considers the CPU and the DPU execution time for predicting the end-to-end processing time. EXPRESS has an average prediction error of 2.2% and significantly outperforms state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:RGFaLdJalmkC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2022,"Road traffic congestion increases vehicular emissions and air pollution. Traffic rule violation causes road accidents. Both pollution and accidents take tremendous social and economic toll worldwide, and more so in developing countries where the skewed vehicle to road infrastructure ratio amplifies the problems. Automating traffic intersection management to detect and penalize traffic rule violations and reduce traffic congestion, is the focus of this paper, using state-of-the-art Convolutional Neural Network (CNN) on traffic camera feeds. There are however non-trivial challenges in handling the chaotic, non-laned traffic scenes in developing countries. Maintaining high throughput is one of the challenges, as broadband connectivity to remote GPU servers is absent in developing countries, and embedded GPU platforms on roads need to be low cost due to budget constraints. Additionally, ambient temperatures in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:NMxIlDl6LWMC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2022,"Developing countries are home to the most polluted cities in the world. Particulate Matter (PM), one of the most serious air pollutants, needs to be measured at scale across urban areas in such countries. Factors potentially affecting PM like road traffic, green cover, industrial emissions etc., also need to be quantified, to enable fine-grained correlation analyses among PM and its causes. This paper presents an IoT platform with multiple sensors, latest deep neural network based edge-computing, local storage and communication support – to measure PM and its associated factors. Through real world deployments, the first in depth empirical analysis of a government enforced traffic control policy for pollution control, is presented as a use case of our IoT platform. We demonstrate the potential of IoT and edge computing in urban sustainability questions in this paper, especially in a developing region context. At the same …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:hMod-77fHWUC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2021,"Machine Learning (EdgeML) algorithms on edge devices facilitate safety-critical applications like building security management and smart city interventions. However, their wired/wireless connections with the Internet make such platforms vulnerable to attacks compromising the embedded software. We find that in the prior works, the issue of regular runtime integrity assessment of the deployed software with negligible EdgeML performance degradation is still unresolved. In this paper, we present PracAttest, a practical runtime attestation framework for embedded devices running compute-heavy EdgeML applications. Unlike the conventional remote attestation schemes that check the entire software in each attestation event, PracAttest segments the software and randomizes the integrity check of these segments over short random attestation intervals. The segmentation coupled with the randomization leads to a novel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:maZDTaKrznsC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2021,"Edge devices are seeing tremendous growth in sensing and computational capabilities. Running state-of-the-art deep neural network (NN) based data processing on multi-core CPU processors, embedded Graphics Processing Units (GPU), Tensor Processing Units (TPU), Neural Processing Units (NPU), Deep Learning Accelerators (DLA) etc., edge devices are now able to handle heavy data computations with limited or without cloud connectivity. In addition to hardware resources, software frameworks that optimize a trained neural network (NN) model through weight clustering and pruning, weight and input-output quantization to fewer bits, fusing NN layers etc., for more efficient execution of NN inferences on edge platforms, play an important role in making machine learning at the edge (namely EdgeML) a reality. This paper is a first effort in characterizing these software frameworks for DNN inference …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:JV2RwH3_ST0C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2021,"Convolutional Neural Networks (CNNs) are increasingly becoming popular in embedded and energy limited mobile applications. Hardware designers have proposed various accelerators to speed up the execution of CNNs on embedded platforms. Deep Learning Processor Unit (DPU) is one such generic CNN accelerator for Xilinx platforms that can execute any CNN on one or more DPUs configured on an FPGA. In a period of rapid growth in CNN algorithms and the availability of multiple configurations of CNN accelerators (like DPU), the design space is expanding fast. These design points show significant trade-off in execution time, energy consumption and application performance measured in terms of accuracy. To be able to perform this trade-off, we propose a methodology for energy estimation of a CNN running on a DPU. We build an energy model using characteristics of few CNNs and use this model for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:M3NEmzRMIkIC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2021,"Companies providing services like cab sharing, e-commerce logistics, food delivery are willing to instrument their vehicles for scaling up measurements of traffic congestion, travel time, road surface quality, air quality, etc.[1]. Analyzing fine-grained sensors data from such large fleets can be highly beneficial; however, this sensor information reveals the locations and the number of vehicles in the deployed fleet. This sensitive data is of high business value to rival companies in the same business domain, eg, Uber vs. Ola, Uber vs. Lyft in cab sharing, or Amazon vs. Alibaba in the e-commerce domain. This paper provides privacy guarantees for the scenario mentioned above using Gaussian Process Regression (GPR) based interpolation, Differential Privacy (DP), and Secure two-party computations (2PC). The sensed values from instrumented vehicle fleets are made available preserving fleet and client privacy, along with client utility. Our system has efficient latency and bandwidth overheads, even for resource-constrained mobile clients. To demonstrate our end-to-end system, we build a sample Android application that gives the least polluted route alternatives given a source-destination pair in a privacy preserved manner.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:blknAaTinKkC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2020,"Deep Learning Processor Unit (DPU) from XILINX is among the numerous accelerators that have been proposed to speed up the execution of Convolutional Neural Networks (CNNs) on embedded platforms. DPUs are available in different configurable sizes and can execute any given CNN. Neural network researchers are also rapidly bringing out newer CNN algorithms with improved performance (typically higher prediction accuracy) with a trade-off in size or energy consumption for embedded applications. To enable quick evaluation of choices among evolving CNN algorithms and accelerator configurations, we propose INFER (INterFerence-aware Estimation of Runtime). INFER is a framework to estimate the execution time of any CNN on a given size of DPU without actual implementation. Further, current FPGA platforms are capable of implementing multiple DPUs whereas many applications consist of multiple …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:TFP_iSt0sucC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2020,"Many emerging systems concurrently execute multiple applications that use deep neural network (DNN) as a key portion of the computation. To speedup the execution of such DNNs, various hardware accelerators have been proposed in recent works. Deep learning processor unit (DPU) from Xilinx is one such accelerator targeted for field programmable gate array (FPGA)-based systems. We study the runtime and energy consumption for different DNNs on a range of DPU configurations and derive useful insights. Using these insights, we formulate a design space exploration (DSE) strategy to explore tradeoffs in accuracy, runtime, cost, and energy consumption arising due to flexibility in choosing DNN topology, DPU configuration, and FPGA model. The proposed strategy provides a reduction of 28× in the number of design points to be simulated and 23× in the pruning time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:r0BpntZqJG4C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2020,"Effective intersection control can play an important role in reducing traffic congestion and associated vehicular emissions. This is vitally needed in developing countries, where air pollution is reaching life threatening levels. This paper presents EcoLight intersection control for developing regions, where budget is constrained and network connectivity is very poor. EcoLight learns effective control offline using state-of-the-art Deep Reinforcement Learning methods, but deploys highly efficient runtime control algorithms on low cost embedded devices that work stand-alone on road without server connectivity. EcoLight optimizes both average case and worst case values of throughput, travel time and other metrics, as evaluated on open-source datasets from New York and on a custom developing region dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:iH-uZ7U-co4C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2019,"Travel time estimates are highly useful in planning urban mobility events. This paper investigates the quality of travel time estimates in the Indian capital city of Delhi and the National Capital Region (NCR). Using Uber mobile and web applications, we collect data about 610 trips from 34 Uber users. We empirically show the unpredictability of travel time estimates for Uber cabs. We also discuss the adverse effects of such unpredictability on passengers waiting for the cabs, leading to a whopping 28.4% of the requested trips being cancelled. Our empirical observations differ significantly from the high accuracies reported in travel time estimation literature. These pessimistic results will hopefully trigger useful investigations in future on why the travel time estimates are mismatching the high accuracy levels reported in literature - (a) is it a lack of training data issue for developing countries or (b) an algorithmic shortcoming …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:RHpTSmoSYBkC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2019,"Classifying and counting vehicles in road traffic has numerous applications in the transportation engineering domain. However, the wide variety of vehicles (two-wheelers, three-wheelers, cars, buses, trucks etc.) plying on roads of developing regions without any lane discipline, makes vehicle classification and counting a hard problem to automate. In this paper, we use state of the art Convolutional Neural Network (CNN) based object detection models and train them for multiple vehicle classes using data from Delhi roads. We get upto 75% MAP on an 80-20 train-test split using 5562 video frames from four different locations. As robust network connectivity is scarce in developing regions for continuous video transmissions from the road to cloud servers, we also evaluate the latency, energy and hardware cost of embedded implementations of our CNN model based inferences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:mB3voiENLucC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2019,"Classifying and counting vehicles in road traffic has numerous applications in the transportation engineering domain. However, the wide variety of vehicles (two-wheelers, three-wheelers, cars, buses, trucks etc.) plying on roads of developing regions without any lane discipline, makes vehicle classification and counting a hard problem to automate. In this paper, we use state of the art Convolutional Neural Network (CNN) based object detection models and train them for multiple vehicle classes using data from Delhi roads. We get upto 75% MAP on an 80-20 train-test split using 5562 video frames from four different locations. As robust network connectivity is scarce in developing regions for continuous video transmissions from the road to cloud servers, we also evaluate the latency, energy and hardware cost of embedded implementations of our CNN model based inferences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:j3f4tGmQtD8C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2018,"This poster describes a low-cost and robust embedded platform, designed for vehicle mounted sensing of particulate matter (PM2.5 and PM10). The prototype is specifically designed to be mounted on the Delhi Integrated Multi-Modal Transit System (DIMTS) buses. Movement of the buses adds noise to pollution data. Error in GPS measurement causes issues in detecting moving vs. stationary state of the buses, useful to filter out noisy pollution data collected in the moving state. Intermittent cellular network connectivity causes frequent disconnects with the remote server. Our prototype is designed to handle such real world deployment challenges. Pilot deployment with this platform is currently ongoing. Preliminary data analysis from the pilot deployment will be discussed as part of the poster presentation, along with demonstration of the prototype sensor platform. This hardware prototype has the potential of creating …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:hFOr9nPyWt4C,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2018,"Reliable on-off control of peripherals on smart devices is a key to security and privacy in many scenarios. Journalists want to reliably turn off radios to protect their sources during investigative reporting. Users wish to ensure cameras and microphones are reliably off during private meetings. In this paper, we present SeCloak, an ARM TrustZone-based solution that ensures reliable on-off control of peripherals even when the platform software is compromised. We design a secure kernel that co-exists with software running on mobile devices (e.g., Android and Linux) without requiring any code modifications. An Android prototype demonstrates that mobile peripherals like radios, cameras, and microphones can be controlled reliably with a very small trusted computing base and with minimal performance overhead.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:ZeXyd9-uunAC,http://www.cse.iitd.ac.in/~rijurekha/
Rijurekha Sen,"['Mobile and embedded systems', 'mobile privacy and security', 'applied machine learning', 'road traffic and pollution measurements']",14,1231,2018,"In its most basic form, the spatial capital of a neighborhood entails that most aspects of daily life are located close at hand. Urban planning researchers have widely recognized its importance, not least because it can be transformed in other forms of capital such as economical capital (e.g., house prices, retail sales) and social capital (e.g., neighborhood cohesion). Researchers have already studied spatial capital from official city data. Their work led to important planning decisions, yet it also relied on data that is costly to create and update, and produced metrics that are difficult to compare across cities. By contrast, we propose to measure spatial capital in cheap and standardized ways around the world. Hence the name of our project “World Wide Spatial Capital”. Our measures are cheap as they rely on the most basic information about a city that is currently available on the Web (i.e., which amenities are available and where). They are also standardized because they can be applied in any city in the five continents (as opposed to previous metrics that were mainly applied in USA and UK). We show that, upon these metrics, one could produce insights at the core of the urban planning discipline: which areas would benefit the most from urban interventions; how to inform planning depending on whether a city’s activity is mono- or poly-centric; how different cities fare against each other; and how spatial capital correlates with other urban characteristics such as mobility patterns and road network structure.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=yTPVlzgAAAAJ&sortby=pubdate&citation_for_view=yTPVlzgAAAAJ:L8Ckcad2t8MC,http://www.cse.iitd.ac.in/~rijurekha/
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2023,"Serverless computing systems are becoming very popular. Large corporations such as Netflix, Airbnb, and Coca-Cola use such systems for running their websites and IT systems. The advantages of such systems include superior support for auto-scaling, load balancing, and fast distributed processing. These are multi-QoS systems where different classes of applications have different latency and jitter (variation in the latency) requirements: we consider a mix of latency-sensitive (LS) and latency-desirable (LD) applications. Ensuring proper schedulability and QoS enforcement of LS applications is non-trivial. We need to minimize the jitter without increasing the response latency of LS applications, and we also need to keep the degradation of the response latency of LD applications in check. This is the first paper in this domain that achieves a trade-off between the jitter suffered by LS applications and the response latency of LD applications. We minimize the former with a bound on the latter using a reinforcement learning (RL) based scheme. To design such an RL scheme, we performed detailed characterization studies to find the input variables of interest, defined novel state representations, and proposed a bespoke reward function that allows us to achieve this trade-off. For an aggressive use case comprising five popular LS and LD applications each, we show a reduction in response time variance and mean latency of 50.31% and 27.4%, respectively, for LS applications. The mean degradation in the execution latency of LD applications was limited to 19.88%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:9Nmd_mFXekcC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2023,"Securing deep neural networks (DNNs) is a problem of significant interest since an ML model incorporates high-quality intellectual property, features of data sets painstakingly collated by mechanical turks, and novel methods of training on large cluster computers. Sadly, attacks to extract model parameters are on the rise, and thus designers are being forced to create architectures for securing such models. State-of-the-art proposals in this field take the deterministic memory access patterns of such networks into cognizance (albeit partially), group a set of memory blocks into a tile, and maintain state at the level of tiles (to reduce storage space). For providing integrity guarantees (tamper avoidance), they don’t propose any significant optimizations, and still maintain block-level state.We observe that it is possible to exploit the deterministic memory access patterns of DNNs even further, and maintain state information for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:_Ybze24A_UAC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2023,"NVM-based systems are naturally fit candidates for incorporating periodic checkpointing (or snapshotting). This increases the reliability of the system, makes it more immune to power failures, and reduces wasted work in especially an HPC setup. The traditional line of thinking is to design a system that is conceptually similar to transactional memory, where we log updates all the time, and minimize the wasted work or alternatively the MTTR (mean time to recovery). Such ``instant recovery'' systems allow the system to recover from a point that is quite close to the point of failure. The penalty that we pay is the prohibitive number of additional writes to the NVM. We propose a paradigmatically different approach in this paper, where we argue that in most practical settings such as regular HPC workloads or neural network training, there is no need for such instant recovery. This means that we can afford to lose some work, take periodic software-initiated checkpoints and still meet the goals of the application. The key benefit of our scheme is that we reduce write amplification substantially; this extends the life of NVMs by roughly the same factor. We go a step further and design an adaptive system that can minimize the WA given a target checkpoint latency, and show that our control algorithm almost always performs near-optimally. Our scheme reduces the WA by 2.3-96\% as compared to the nearest competing work.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:XD-gHx7UXLsC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2023,"With the advent of low-power ultra-fast hardware and GPUs, virtual reality (VR) has gained a lot of prominence in the last few years and is being used in various areas such as education, entertainment, scientific visualization, and computer-aided design. VR-based applications are highly interactive, and one of the most important performance metrics for these applications is the motion-to-photon-delay (MPD). MPD is the delay from the users head movement to the time at which the image gets updated on the VR screen. Since the human visual system can even detect an error of a few pixels (very spatially sensitive), the MPD should be as small as possible. Popular VR vendors use the GPU-accelerated Asynchronous Time Warp (ATW) algorithm to reduce the MPD. ATW reduces the MPD if and only if the warping operation finishes just before the display refreshes. However, due to the competition between applications for the shared GPU, the GPU-accelerated ATW algorithm suffers from an unpredictable ATW latency, making it challenging to find the ideal time instance for starting the time warp and ensuring that it completes with the least amount of lag relative to the screen refresh. Hence, the state-of-the-art is to use a separate hardware unit for the time warping operation. Our approach, PredATW, uses an ML-based predictor to predict the ATW latency for a VR application, and then schedule it as late as possible. This is the first work to do so. Our predictor achieves an error of 0.77 ms across several popular VR applications for predicting the ATW latency. As compared to the baseline architecture, we reduce deadline misses by 73.1%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:t7zJ5fGR-2UC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Present-day path planning algorithms for UAVs rely on various parameters that need to be tuned at runtime to be able to plan the best possible route. For example, for a sampling-based algorithm, the number of samples plays a crucial role. The dimension of the space that is being searched to plan the path, the minimum distance for extending a path in a direction, and the minimum distance that the drone should maintain with respect to obstacles while traversing the planned path are all important variables. Along with this, we have a choice of vision algorithms, their parameters, and platforms.
Finding a suitable configuration for all these parameters at runtime is very challenging because we need to solve a complicated optimization problem, and that too within tens of milliseconds. The area of theoretical exploration of the optimization problems that arise in such settings is dominated by traditional approaches that use …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:uJ-U7cs_P_0C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Different areas of computer science have different challenges with respect to curriculum development, textbook writing, and teaching. Computer architecture represents one extrema in this hyper-dimensional space: it is an applied discipline, the theory for many sub-areas is still in development, and unlike traditional theoretical areas, problem-solving and tutorial based teaching is still uncommon. Students typically appreciate the rigor of traditional algorithm courses because they are similar to the courses they have seen in high school, however computer architecture is an engineering discipline: it is a science, an art, and sometimes a combination of both. As the name suggests, it is quite like traditional ""architecture"" (designing beautiful buildings...).
To further complicate matters, most textbooks in this subject have originally been written in the late nineties and fail to capture most of the developments that have …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:VLnqNzywnoUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Modern software programs have dedicated license-check modules that restrict access to users, who possess valid credentials. They also have a large number of add-on pluggable modules that can be separately purchased and have their dedicated license managers. Sadly, recent work shows that regardless of their complexity, it is possible to break their security using a novel class of attacks known as control flow bending attacks (CFB attacks), where the program is run on a virtual CPU, unbeknownst to it.
In this paper, we propose SecureLease -- a novel approach that efficiently solves this problem by running the license managers and other parts of the application in a trusted execution environment (TEE) (hardware managed sandbox). Since it is not enough to just move the license managers to the TEE because they can be circumvented using CFB attacks, we need to further handicap the attacker by also moving key …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:kzcrU_BdoSEC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"In the last 15 years, we have witnessed a never ending arm’s race between the attacker and the defender with respect to cache-based side-channel attacks. We have seen a slew of attacks, countermeasures (CMs), counterattacks, counter-countermeasures and so on. We analyze the evolution of this area, propose three necessary conditions for designing a successful CM, and then analyze timing and address-based CMs for popular algorithms such as AES and PRESENT. We show that an optimal yet trivial solution for timing-based CMs is possible. Furthermore, address-based CMs are inferior to timing-based CMs, and they can be broken in O(nlog(log(n))) time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:fEOibwPWpKIC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Testing of integrated circuits (IC) is a highly expensive process but also the most important one in determining the defect level of an IC. Manufacturing defects in the IC are modeled using stuck-at-fault models. Stuck-at-fault models cover most of the physical faults that occur during the manufacturing process. With decreasing feature sizes due to the advancement of semiconductor technology, the defects are also getting smaller in size. Tests for these hard-to-detect defects are generated using deterministic test generation (DTG) algorithms. Our work aims at reducing the cost of Path Oriented Decision Making: PODEM (a DTG algorithm) without compromising the test quality. We trained a meta predictor to choose the best model given the circuit and the target net. This ensemble chooses the best probability prediction model with a 95% accuracy. This leads to a reduced number of backtracking decisions and much better performance of PODEM in terms of its CPU time. We show that our ML- guided PODEM algorithm with a meta predictor outperforms the baseline PODEM by 34% and other state-of-the-art ML-guided algorithms by at least 15% for ISCAS85 benchmark circuits.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:j8SEvjWlNXcC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Today, a vast amount of sensitive data worth millions of dollars is processed in untrusted data centers; hence, the confidentiality and integrity of the code and data are of paramount importance. Given the high incentive of mounting a successful attack, the complexity of attack methods has grown rapidly over the years. The attack methods rely on vulnerabilities present in the system to hijack the control flow of a process and use it to either steal sensitive information or degrade the quality of service.
To thwart these attacks, the complexity of the defense methods has also increased in tandem. Researchers have explored different methods to ensure the secure execution of an application. The defense methods range from software-only to hardware-only to hybrid defense methods.
In this survey, we focus on the relatively new hybrid form of defense methods where software and hardware work in tandem to protect the control …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:7T2F9Uy0os0C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"JSON (JavaScript Object Notation) is quickly becoming the default currency for semi-structured data exchange on the web; hence, it is heavily used in analytics pipelines. State-of-the-art analytics pipelines can now process data at a rate that exceeds 50 Gbps owing to recent advances in RDMA, NVM, and network technology (notably Infiniband). The peak throughput of the best-performing software solutions for parsing, querying, and validating JSON data is 20 Gbps, which is far lower than the current requirement. We propose a novel HW-based accelerator, HAJPAQUE, that ingests 16-bytes of JSON data at a time and processes all the 16 bytes in parallel as opposed to competing approaches that process such data byte by byte. Our novel solution comprises lookup tables, parallel sliding windows, and recursive computation. Together, they ensure that our online pipeline does not encounter any stalls while …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:-_dYPAW6P2MC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Small sub-mW sensor devices that rely on energy harvesting often have limited computation capability to locally process, query, and update data. Such energy harvesting devices (EHDs) need to operate under a strict power constraint and are also extremely cost-sensitive. Based on current costs and estimated near-term trends, we observe that the price of the nonvolatile memory component dominates (in 20 USD devices). Hence, there is a pressing need to reduce the overall memory footprint in a data-intensive setting. This paper is the first to propose a generic hardware architecture, CmpctArch, for implementing compact data structures (CDSs) on such devices. They reduce the memory footprint by up to without significantly increasing the overall energy consumption or time taken (max. additional energy and time ). The hardware implementations are 160- more energy-efficient and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:_Re3VWB3Y0AC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Trusted execution environments (TEEs) such as Intel SGX facilitate the secure execution of an application on untrusted machines. A plethora of work focuses on improving the performance of such environments necessitating the need for a standard, widely accepted benchmark suite. We present SGXGauge, a benchmark suite for SGX containing a diverse set of workloads from different domains. We also thoroughly characterize the behavior of the benchmark suite on a native platform and on a platform that uses a library OS-based shim layer (GrapheneSGX).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:NJ774b8OgUMC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Trusted execution environments (TEEs) such as \intelsgx facilitate the secure execution of an application on untrusted machines. Sadly, such environments suffer from serious limitations and performance overheads in terms of writing back data to the main memory, their interaction with the OS, and the ability to issue I/O instructions. There is thus a plethora of work that focuses on improving the performance of such environments -- this necessitates the need for a standard, widely accepted benchmark suite (something similar to SPEC and PARSEC). To the best of our knowledge, such a suite does not exist. Our suite, SGXGauge, contains a diverse set of workloads such as blockchain codes, secure machine learning algorithms, lightweight web servers, secure key-value stores, etc. We thoroughly characterizes the behavior of the benchmark suite on a native platform and on a platform that uses a library OS-based shimming layer (GrapheneSGX). We observe that the most important metrics of interest are performance counters related to paging, memory, and TLB accesses. There is an abrupt change in performance when the memory footprint starts to exceed the size of the EPC size in Intel SGX, and the library OS does not add a significant overhead (~ +- 10%).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:W5xh706n7nkC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Polar codes have hitherto been used in the control plane of 5G-NR systems. However, in line with other contemporary works, we propose a novel use of them in the data plane by leveraging their natural property: different bit positions suffer from different degrees of errors. The idea is to map different components of web pages to different bit positions (based on their priority). We evaluate our approach for web page transmission over a wireless link that traditionally uses TCP and demonstrate benefits for image and video-based web pages. For an image-based web page, there is a 47.96% to 81.12% gain in performance, while the received image quality score varies between 0.97 and 0.99. We observe up to a 63.56% gain in performance for web pages with embedded videos with only a 7.45% loss in the received video quality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:Fu2w8maKXqMC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"The unprecedented growth of edge computing and 5G has led to an increased offloading of mobile applications to cloud servers or edge cloudlets. The most prominent workloads comprise computer vision applications. Conventional wisdom suggests that computer vision workloads perform significantly well on SIMD/SIMT architectures such as GPUs owing to the dominance of linear algebra kernels in their composition. In this work, we debunk this popular belief by performing a lot of experiments with the concurrent execution of these workloads, which is the most popular pattern in which these workloads are executed on cloud servers. We show that the performance of these applications on GPUs does not scale well with an increase in the number of concurrent applications primarily because of contention at the shared resources and lack of efficient virtualization techniques for GPUs. Hence, there is a need to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:JQOojiI6XY0C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"With the advent of ultra-low-power embedded processors, energy harvesting devices (EHDs) are becoming exceedingly prevalent. These devices are highly portable, self-sustainable, and once deployed, they can run for an extremely long time. They can thus be installed at hard-to-reach locations. Despite the benefits, it is challenging to use these devices as they rely on sporadic and variable sources of ambient energy, and are equipped with very small memories. The intermittent nature of the ambient energy leads to a loss of device state. Such repeated failures might cause non-termination of the programs executing on these devices. To achieve termination, we need to use state retention techniques that guarantee the programs’ forward progress.
Checkpointing is the most common state retention technique. However, performing checkpointing arbitrarily can lead to inefficient and incorrect execution of the program …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:uLbwQdceFCQC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"In this paper, we propose NanoLeak, a comprehensive temperature simulator that incorporates both classical heat transfer mechanisms and nanoscale effects. It performs both steady state and transient analyses while automatically taking leakage into account. We derive closed-form expressions for the Green’s function (impulse response of a power source) for all scenarios with leakage; there is no need for the traditional, time-consuming iterative solutions. We show a speedup of 1250X for the classical heat transfer case (Fourier’s heat equation) with an error limited to 2.4% in computing the steady-state thermal profile. At nanoscale levels, the Boltzmann transport equation (BTE) is solved to analyze the temperature profile. In this paper, we analytically compute the leakage-aware solution for the gray-BTE model and compare the results against competing, state-of-the-art work (211-2580X speedup).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:dQ2og3OwTAUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2022,"Stereo vision algorithms are important building blocks of self-driving applications. The two primary requirements of a self-driving vehicle are real-time operation and nearly 100% accuracy in constructing the 3D scene regardless of the weather conditions and the degree of ambient light. Sadly, most real-time systems as of today provide a level of accuracy that is inadequate and this endangers the life of the passengers; consequently, it is necessary to supplement such systems with expensive LiDAR-based sensors. We observe that for a given scene, different stereo matching algorithms can have vastly different accuracies, and among these algorithms, there is no clear winner. This makes the case for a hybrid stereo vision system where the best stereo vision algorithm for a stereo image pair is chosen by a predictor dynamically, in real-time. We implement such a system called PredStereo in ASIC that combines two diametrically different stereo vision algorithms, CNN-based and traditional, and chooses the best one at runtime. In addition, it associates a confidence with the chosen algorithm, such that the higher-level control system can be switched on in case of a low confidence value. We show that designing a predictor that is explainable and a system that respects soft real-time constraints is non-trivial. Hence, we propose a variety of hardware optimizations that enable our system to work in real-time. Overall, PredStereo improves the disparity estimation error over a state-of-the-art CNN-based stereo vision system by up to 18%(on average 6.25%) with a negligible area overhead (0.003 mm^ 2) while respecting real-time constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:Y5dfb0dijaUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"Silicon photonics is beginning to play an important role in driving innovations in communication and computation for an increasing number of applications, from health care and biomedical sensors to autonomous driving, datacenter networking, and security. In recent years, there has been a significant amount of effort in industry and academia to innovate, design, develop, analyze, optimize, and fabricate systems employing silicon photonics, shaping the future of not only Datacom and telecom technology but also high-performance computing and emerging computing paradigms, such as optical computing and artificial intelligence. Different from existing books in this area, Silicon Photonics for High-Performance Computing and Beyond presents a comprehensive overview of the current state-of-the-art technology and research achievements in applying silicon photonics for communication and computation. It focuses on various design, development, and integration challenges, reviews the latest advances spanning materials, devices, circuits, systems, and applications. Technical topics discussed in the book include:• Requirements and the latest advances in high-performance computing systems• Device-and system-level challenges and latest improvements to deploy silicon photonics in computing systems• Novel design solutions and design automation techniques for silicon photonic integrated circuits• Novel materials, devices, and photonic integrated circuits on silicon• Emerging computing technologies and applications based on silicon photonics Silicon Photonics for High-Performance Computing and Beyond presents a compilation of 19 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:UHK10RUVsp4C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"On-chip photonics is a disruptive technology that can offer substantial gains in terms of performance and power efficiency in large server processors. However, before this technology becomes commonplace, it is necessary to fix one of its most important problems, namely static power dissipation. Unlike electrical networks, optical networks are naturally constrained by their basic physics, which entails lasers to be continuously on while transmitting messages. Given that it is not possible to store photons, a logical zero or one is deduced based on the presence or absence of laser light. This leads to a significant amount of power dissipation because many a time, lasers are on, even though there is no network activity. Hence, there is a need to accurately predict network activity and modulate lasers accordingly. Over the past few years, a lot of work has been done in this space. In this chapter, some of the important …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:eMMeJKvmdy0C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"A trusted execution environment or a TEE facilitates the secure execution of an application on a remote untrusted server. In a TEE, the confidentiality, integrity, and freshness properties for the code and data hold throughout the execution. In a TEE setting, specifically Intel SGX, even the operating system (OS) is not trusted. This results in certain limitations of a secure application’s functionality, such as no access to the file system and network – as it requires OS support.
Prior works have focused on alleviating this problem by allowing an application to access the file system securely. However, we show that they are susceptible to replay attacks, where replaying an old encrypted version of a file may remain undetected. Furthermore, they do not consider the impact of Intel SGX operations on the design of the file system.
To this end, we present SecureFS, a secure, efficient, and scalable file system for Intel SGX that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:AXPGKjj_ei8C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"Recent years have witnessed a significant interest in the “generative adversarial networks” (GANs) due to their ability to generate high-fidelity data. Many models of GANs have been proposed for a diverse range of domains ranging from natural language processing to image processing. GANs have a high compute and memory requirements. Also, since they involve both convolution and deconvolution operation, they do not map well to the conventional accelerators designed for convolution operations. Evidently, there is a need of customized accelerators for achieving high efficiency with GANs. In this work, we present a survey of techniques and architectures for accelerating GANs. We organize the works on key parameters to bring out their differences and similarities. Finally, we present research challenges that are worthy of attention in near future. More than summarizing the state-of-art, this survey seeks to spark …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:WA5NYHcadZ8C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"Modern enterprise servers are increasingly embracing tiered memory systems with a combination of low latency DRAMs and large capacity but high latency non-volatile main memories (NVMMs) such as Intel’s Optane DC PMM. Prior works have focused on the efficient placement and migration of data on a tiered memory system, but have not studied the optimal placement of page tables.
Explicit and efficient placement of page tables is crucial for large memory footprint applications with high TLB miss rates because they incur dramatically higher page walk latency when page table pages are placed in NVMM. We show that (i) page table pages can end up on NVMM even when enough DRAM memory is available and (ii) page table pages that spill over to NVMM due to DRAM memory pressure are not migrated back later when memory is available in DRAM.
We study the performance impact of page table …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:t6usbXjVLHcC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"Modern enterprise servers are increasingly embracing tiered memory systems with a combination of low latency DRAMs and large capacity but high latency non-volatile main memories (NVMMs) such as Intel's Optane DC PMM. Prior works have focused on efficient placement and migration of data on a tiered memory system, but have not studied the optimal placement of page tables. Explicit and efficient placement of page tables is crucial for large memory footprint applications with high TLB miss rates because they incur dramatically higher page walk latency when page table pages are placed in NVMM. We show that (i) page table pages can end up on NVMM even when enough DRAM memory is available and (ii) page table pages that spill over to NVMM due to DRAM memory pressure are not migrated back later when memory is available in DRAM. We study the performance impact of page table placement in a tiered memory system and propose an efficient and transparent page table management technique that (i) applies different placement policies for data and page table pages, (ii) introduces a differentiating policy for page table pages by placing a small but critical part of the page table in DRAM, and (iii) dynamically and judiciously manages the rest of the page table by transparently migrating the page table pages between DRAM and NVMM. Our implementation on a real system equipped with Intel's Optane NVMM running Linux reduces the page table walk cycles by 12% and total cycles by 20% on an average. This improves the runtime by 20% on an average for a set of synthetic and real-world large memory footprint applications …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:XiVPGOgt02cC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"With rising power densities in modern-day electronic systems, temperature has emerged as a fundamental design constraint. This has led to the advent of a range of thermal-aware design and runtime management techniques. However, such techniques are heavily dependent on a fast and accurate thermal modeling method. These methods need to account for manufacturing variability, that significantly impacts the chip's power and performance. Similarly, leakage power too contributes to a substantial portion of the total power. Thus a thermal modeling method can be accurate only if it is capable of incorporating the effects of process variation as well as leakage power. In this paper, we propose a simple and elegant residual convolutional neural network for thermal estimation in the presence of variability, which leverages the physics of heat transfer. Our approach is capable of modeling modern-day 3D chips with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:5ugPr518TE4C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"Modern UAV s are incredibly complex systems with numerous tunable knobs such as the battery capacity, camera settings, sampling rate, constraints on the route, etc. The area of theoretical exploration of the optimization problems that arise in such settings is dominated by traditional approaches that use regular nonlinear optimization often enhanced with AI-based techniques such as genetic algorithms. These techniques are sadly rather slow, have convergence issues, and are typically not suitable for use at runtime. In this paper, we leverage recent and promising research results that propose to convert the optimization problem into a game and then find the set of equilibrium strategies of different players. The strategies can then be mapped to the optimal values of the tunable parameters. With simulation studies in virtual worlds, we show that our solutions are 5-21% better than those produced by traditional …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:wbdj-CoPYUoC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"Designing the ISA (instruction set architecture) is a very critical activity in the entire ASIP (application-specific instruction set processor) design process. There is a long history of using automated tools that suggest custom instructions based on an analysis of the data flow graphs (DFGs) of target programs. Such approaches often create an ISA that is overspecialized for a small set of applications and they often suggest a plethora of custom instructions that cannot be practically implemented. A survey of recent work indicates that adding custom instructions to freely available ISAs such as RISC-V still relies on bespoke analyses and institutional memory. In this paper, we focus on such modern applications, where we only need to add a few instructions to an existing ISA such as RISC-V. The aim is to either supplant or complement the extensive manual analysis that goes into such decision making. We propose an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:J-pR_7NvFogC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"In this paper, we present a fast, compact thermal model for modeling the temperature of smartphones. Existing approaches use the finite element (FEM) or finite difference (FDM) based methods that are very slow. Even fast Green's function-based approaches always use such FEM/FDM based approaches to compute the Green's function (impulse response of a power source) in the first place. This significantly slows down the process of design space exploration. To ameliorate this, we propose an ultra-fast model that can be used to model the temperature of mobile phones: we use simple polynomial or exponential expressions to compute the Green's functions. These expressions can be evaluated very quickly and can be generalized for a wide variety of electronic components. In a smartphone, analysis of the temperature hotspots is very crucial in the design process. We can estimate the location of hotspots and the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:1qzjygNMrQYC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"Convolutional neural networks (CNNs) have proven to be a disruptive technology in most vision, speech and image processing tasks. Given their ubiquitous acceptance, the research community is investing a lot of time and resources on deep neural networks. Custom hardware such as ASICs are proving to be extremely worthy platforms for running such programs. However, the ever-increasing complexity of these algorithms poses challenges in achieving real-time performance. Specifically, CNNs have prohibitive costs in terms of computation time, throughput, latency, storage space, memory bandwidth, and power consumption.
Hence, in the last 5 years, a lot of work has been done by the scientific community to mitigate these costs. Researchers have primarily focused on reducing the computation time, the number of computations, the memory access time, and the size of the memory footprint. In this survey paper …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:VOx2b1Wkg3QC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2021,"Energy harvesting devices (EHDs) are becoming extremely prevalent in remote and hazardous environments. They sense the ambient parameters and compute some statistics on them, which are then sent to a remote server. Due to the resource-constrained nature of EHDs, it is challenging to perform exact computations on streaming data; however, if we are willing to tolerate a slight amount of inaccuracy, we can leverage the power of sketching algorithms to provide quick answers with significantly lower energy consumption.
In this paper, we propose a novel hardware architecture called EHDSktch -- a set of IP blocks that can be used to implement most of the popular sketching algorithms. We demonstrate an energy savings of 4-10X and a speedup of more than 10X over state-of-the-art software implementations. Leveraging the temporal locality further provides us a performance gain of 3-20% in energy and time …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:V3AGJWp-ZtQC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2020,"With the growth of edge computing, applicationspecific workloads based on computer vision are steadily migrating to edge cloudlets. Scheduling has been identified to be a major problem in these cloudlets. In this article, we propose a generic architectural solution, VisSched, that leverages the fact that most vision workloads share similar code kernels (such as library code for linear algebra), and as a result, they tend to exhibit similar phase behavior. This allows us to create an auction theory-based scheduling mechanism, where we give each thread a replenishable virtual wallet, and threads are scheduled based on the amounts that they bid for executing on a free core. We show that in 20%-40% of the cases, our scheduling algorithm is theoretically optimal, and in the remaining cases, it reaches a global optimum obtained using Monte Carlo simulations 90%-95% of the time. Our results for the MEVBench vision …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:BrmTIyaxlBUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2020,"In this article, we propose a fast thermal modeling tool, 3DSim, using a Green's-function-based approach. Green's-function-based approaches have been shown to be faster than the traditional finite-difference-based techniques. Our proposed tool can model steady-state and transient thermal profiles for both 2-D and 3-D chips, which may contain multiple active layers and fluid-carrying microchannels for heat removal. The unique advantage of our tool is that it models leakage power analytically using a piecewise-linear leakage model, thereby eliminating the need to iterate multiple times through the leakage-temperature feedback loop. We use several algebraic techniques and transforms to compute the thermal profile analytically and thereby speedup the process of calculation. To the best of our knowledge, transform-based approaches have not been used before to model the temperature in 3-D chips with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:eflP2zaiRacC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2020,"Photonic networks are already commercially available at the board-level, and many fabrication facilities can fabricate optical networks and integrate them with traditional silicon-based SoCs. Almost all the research in on-chip photonics has been in the areas of performance enhancement and static power reduction. However, before the large-scale adoption of such technologies, it is necessary to solve security problems. As opposed to electrical NoCs, optical NoCs are shared to a much larger extent, and are significantly more sensitive to the latencies of cryptographic operations. Hence, it is necessary to design a novel protocol for securing such networks. We propose a novel, secure, and efficient optical network in this paper (SecONet) that is immune to eavesdropping, spoofing, replay, and message-removal attacks. Using a combination of speculative execution and pre-computation, we reduce the performance …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:D_sINldO8mEC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2020,"On-chip photonics is a disruptive technology, and such NoCs are superior to traditional electrical NoCs in terms of latency, power, and bandwidth. Hence, researchers have proposed a wide variety of optical networks for multicore processors. The high bandwidth and low latency features of photonic NoCs have led to the overall improvement in the system performance. However, there are very few proposals that discuss the usage of optical interconnects in Graphics Processor Units (GPUs). GPUs can also substantially gain from such novel technologies, because they need to provide significant computational throughput without further stressing their power budgets.
The main shortcoming of optical networks is their high static power usage, because the lasers are turned on all the time by default, even when there is no traffic inside the chip, and thus sophisticated laser modulation schemes are required. Such …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:eJXPG6dFmWUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2020,"With the advent of edge computing and 5G, multiple mobile applications are being offloaded to cloud servers to meet their computational demands. Computer vision workloads dominate this space. Since the vision workloads are composed of linear algebra kernels, they perform significantly well on SIMT/SIMD architectures such as GPUs. While an application can maximize its performance on a GPU when it is the sole consumer of the GPU's resources, it fails to maintain that performance in a multi-application scenario. The primary cause of this problem is the lack of efficient virtualization techniques for GPUs and contention among the applications for the shared resources. Sadly, most of the prior work in this area is devoted to predicting single application performance. To the best of our knowledge we propose the first machine learning based predictor to predict the performance of an ensemble of applications on a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2020,"Some of the fastest thermal estimation techniques at the architectural level are based on Green’s functions (impulse response of a unit power source). The resultant temperature profile can be easily obtained by computing a convolution of the Green’s function and the power profile. Sadly, existing approaches do not take process and temperature variation into account, which are integral aspects of today’s technologies. This problem is still open. In this paper, we provide a closed-form solution for the Green’s function after taking process, temperature, and thermal conductivity variation into account. Moreover, during the process of computing the thermal map, we reduce the amount of redundant work by identifying similar regions in the chip using an unsupervised learning-based approach. We were able to obtain a 700,000X speedup over state-of-the-art proposals with a mean absolute error limited to 0.7 ◦ C (1.5%).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:5Ul4iDaHHb8C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2020,"Over the past two decades, a rich ecosystem of open-source software has evolved. For every type of application, there are a wide variety of alternatives. We observed that even if different applications that perform similar tasks and compiled with the same versions of the compiler and the libraries, they perform very differently while running on the same system. Sadly prior work in this area that compares two code bases for similarities does not help us in finding the reasons for the differences in performance.
In this paper, we develop a tool, SoftMon, that can compare the codebases of two separate applications and pinpoint the exact set of functions that are disproportionately responsible for differences in performance. Our tool uses machine learning and NLP techniques to analyze why a given open-source application has a lower performance as compared to its peers, design bespoke applications that can incorporate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:8AbLer7MMksC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2020,"Research in computer architecture is commonly done using software simulators. The simulation speed of such simulators is therefore critical to the rate of progress in research. One of the less commonly used ways to increase the simulation speed is to decompose the benchmark’s execution into contiguous chunks of instructions and simulate these chunks in parallel. Two issues arise from this approach. The first is of correctness, as each chunk (other than the first chunk) starts from an incorrect state. The second is of performance: The decomposition must be done in such a way that the simulation of all chunks finishes at nearly the same time, allowing for maximum speedup. In this article, we study these two aspects and compare three different chunking approaches (two of them are novel) and two warmup approaches (one of them is novel). We demonstrate that average speedups of up to 5.39X can be achieved …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:08ZZubdj9fEC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2020,"Systems-on-chip (SoCs) are increasingly being composed of designs provided by different organizations. When such an SoC miscomputes or performs below expectation in-field, it is unclear which of the on-chip components caused the failure. The customer would like to use SoCs that provide the property of accountability, wherein the failure-causing component, and consequently its designing organization, can be unambiguously detected. Since it is a matter of trust, the various parties involved desire formal guarantees regarding any accountability solution. The solution must find the guilty component(s) in the event of a chip failure. Additionally, the solution must not falsely implicate any component that functioned correctly. This article formally describes the property of accountability, a formal methodology of constructing an accountability solution, and a formal game-theory based methodology to reason about and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:4fKUyHm3Qg0C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"Temperature simulation is a classic problem in EDA, and researchers have been working on it for at least the last 15 years. In this paper, we focus on fast Green's function based approaches, where computing the temperature profile is as simple as computing the convolution of the power profile with the Green's function. We observe that for many problems of interest the process of computing the Green's function is the most time consuming phase, because we need to compute it with the slower finite difference or finite element based approaches. In this paper we propose a solution, NanoTherm, to compute the Green's function using a fast analytical approach that exploits the symmetry in the thermal distribution. Secondly, conventional analyses based on the Fourier's heat transfer equation fail to hold at the nanometer level. To accurately compute the temperature at the level of a standard cell, it is necessary to solve …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:tOudhMTPpwUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"In this paper, we propose an energy efficient and scalable optical interconnect for GPUs. We intelligently divide the components in a GPU into different types of clusters and enable these clusters to communicate optically with each other. In order to reduce the network delay, we use separate networks for coherence and non-coherence traffic. Moreover, to reduce the static power consumption in optical interconnects, we modulate the off-chip light source by proposing a novel GPU specific prediction scheme for on-chip network traffic. Using our design, we were able to increase the performance by 17% and achieve a 65% reduction in ED2 as compared to a state-of-the-art optical topology.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:738O_yMBCRsC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"High static power consumption is widely regarded as one of the largest bottlenecks in creating scalable optical NoCs. The standard techniques to reduce static power are based on sharing optical channels and modulating the laser. We show in this article that state-of-the-art techniques in these areas are suboptimal, and there is a significant room for further improvement. We propose two novel techniques—a neural network--based method for laser modulation by predicting optical traffic and a distributed and altruistic algorithm for channel sharing—that are significantly closer to a theoretically ideal scheme. In spite of this, a lot of laser power still gets wasted. We propose to reuse this energy to heat micro-ring resonators (achieve thermal tuning) by efficiently recirculating it. These three methods help us significantly reduce the energy requirements. Our design consumes 4.7× lower laser power as compared to other …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:K3LRdlH-MEoC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"We use license servers to verify users' credentials and to restrict access to proprietary software. Due to logistical reasons, it is often economical to use third-party servers to manage licenses. Sadly, users on client machines can mount sophisticated attacks on the executables and try to circumvent the license check. This can be used to crack the software, and thus it is necessary for software writers to prevent such attacks, which include the use of additional code to check the integrity of the binary and the control flow. In spite of such techniques, modern control flow bending(CFB) techniques that rely on running instrumented binaries on virtual machines can circumvent such checks and change the behavior of branches and jumps at runtime. They are however extremely computationally inefficient. We propose an AI-based technique that is an order of magnitude faster than the state-of-the-art and show its efficacy by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:WbkHhVStYXYC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"In this paper, we present a novel optical power splitter having an arbitrary split-ratio that can be tuned over a wide range by employing relatively low voltage levels. It is based on a slotted ring resonator. A 120 nm electro-optic polymer-filled slot is created throughout the circumference of the ring. The hybrid ring resonator is made to work between the full and off resonance states, allowing it to work as a power splitter. This is done by changing the refractive index of the electro-optic polymer inside the slot by the application of an external electric field. The splitter combines the electro-optic functionality of the polymer with the high index contrast of the silicon, resulting in a low tuning voltage power splitter. Over a small voltage range of 0–1 V, it is possible to change the split-ratio of this splitter from 0.031–16.738, making it 10 times better than other competing designs. In addition, it takes less than 500 ps to reconfigure the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:OU6Ihb5iCvQC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"The vision encompassing Smart and Software-defined Buildings (SSDB) is becoming more popular and its implementation is now more accessible due to the widespread adoption of the Internet of Things (IoT) infrastructure. Some of the most important applications sustaining this vision are energy management, environmental comfort, safety and surveillance. This paper surveys IoT and SSB technologies and their cooperation towards the realization of smart spaces. We propose a four-layer reference architecture and we organize related concepts around it. This conceptual frame is useful to identify the current literature on the topic and to connect the dots into a coherent vision of the future of residential and commercial buildings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:SP6oXDckpogC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"Thermal modeling and simulation have become imperative in recent years owing to the increased power density of high performance microprocessors. Temperature is a first-order design criteria, and hence special consideration has to be given to it in every stage of the design process. If not properly accounted for, temperature can have disastrous effects on the performance of the chip, often leading to failure. To streamline research efforts, there is a strong need for a comprehensive survey of the techniques and tools available for thermal simulation. This will help new researchers entering the field to quickly familiarize themselves with the state of the art and enable existing researchers to further improve upon their proposed techniques. In this article, we present a survey of the package level thermal simulation techniques developed over the past two decades.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:u9iWguZQMMsC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"Ensuring the functional correctness of networks-on-chip (NoCs) can be particularly challenging, and communication-centric debug methodologies have been widely used by engineers to validate NoC functionality during post-silicon validation. Design-for-debug structures, such as trace buffers and monitors, are usually inserted in such systems-on-chip to enhance signal visibility. However, this debug hardware becomes underutilized once the chip goes into production. While the size and organization of the router buffers directly impact network throughput, these buffers also dominate the on-chip router area. We propose a scheme augmented virtual channel (AugVC) to reuse trace buffers to augment router buffers, with the objective of improving the overall network performance. The experimental results for a 64-node mesh network show that our proposed approach can reduce latency by up to 38.25% for transpose …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:XiSMed-E-HIC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"With the advent of 5G and M2M architectures, energy harvesting devices are expected to become far more prevalent. Such devices harvest energy from ambient sources such as solar energy or vibration energy (from machines) and use it for sensing the environmental parameters and further processing them. Given that the rate of energy consumption is more than the rate of energy production, it is necessary to frequently halt the processor and accumulate energy from the environment. During this period it is mandatory to take a checkpoint to avoid the loss of data. State of the art algorithms use software based methods that extensively rely on compiler analyses. In this paper, we provide the first formal model for such systems, and show that we can arrive at an optimal check-pointing schedule using a quadratically constrained linear program (QCLP) solver. Using this as a baseline, we show that existing algorithms for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:Tiz5es2fbqcC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"In this letter, we present a novel optical power splitter having an arbitrary split-ratio that can be tuned over a wide range by employing relatively low voltage levels. It is based on a slotted ring resonator. A 120 nm electro-optic polymer-filled slot is created throughout the circumference of the ring. The hybrid ring resonator is made to work between the full and off resonance states, allowing it to work as a power splitter. This is done by changing the refractive index of the electrooptic polymer inside the slot by the application of an external electric field. The splitter combines the electro-optic functionality of the polymer with the high index contrast of the silicon, resulting in a low tuning voltage power splitter. Over a small voltage range of 0-1 V, it is possible to change the split-ratio of this splitter from 0.031-16.738, making it 10 times better than other competing designs. In addition, it takes less than 500 ps to reconfigure the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:p2g8aNsByqUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"A spoofing attack is a critical issue in wireless communication in which a malicious transmitter outside a system attempts to be genuine. As a countermeasure against this, we propose a device-authentication method based on position identification using radio-propagation characteristics (RPCs). Not depending on information processing such as encryption technology, this method can be applied to sensing devices etc. which commonly have many resource restrictions. We call the space from which attacks achieve success as the"" attack space."" In order to confine the attack space inside of the target system to prevent spoofing attacks from the outside, formulation of the relationship between combinations of transceivers and the attack space is necessary. In this research, we consider two RPCs, the received signal strength ratio (RSSR) and the time difference of arrival (TDoA), and construct the attack-space model which uses these RPCs simultaneously. We take a tire pressure monitoring system (TPMS) as a case study of this method and execute a security evaluation based on radio-wave-propagation simulation. The simulation results assuming multiple noise environments all indicate that it is possible to eliminate the attack possibility from a distant location.------------------------------This is a preprint of an article intended for publication Journal ofInformation Processing (JIP). This preprint should not be cited. Thisarticle should be cited as: Journal of Information Processing Vol. 27 (2019)(online)------------------------------A spoofing attack is a critical issue in wireless communication in which a malicious transmitter outside a system attempts to be genuine. As …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:z_wVstp3MssC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"Numerous challenges present themselves when scaling traditional on-chip electrical networks to large manycore processors. Some of these challenges include high latency, limitations on bandwidth, and power consumption. Researchers have therefore been looking for alternatives. As a result, on-chip nanophotonics has emerged as a strong substitute for traditional electrical NoCs.
As of 2017, on-chip optical networks have moved out of textbooks and found commercial applicability in short-haul networks such as links between servers on the same rack or between two components on the motherboard. It is widely acknowledged that in the near future, optical technologies will move beyond research prototypes and find their way into the chip. Optical networks already feature in the roadmaps of major processor manufacturers and most on-chip optical devices are beginning to show signs of maturity.
This article is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:xtRiw3GOFMkC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"This article presents BigBus, a novel design of an on-chip photonic network for a 1,024-node system. For such a large on-chip network, performance and power reduction are two mutually conflicting goals. This article uses a combination of strategies to reduce static power consumption while simultaneously improving performance and the energy-delay2 (ED2) product. The crux of the article is to segment the entire system into smaller clusters of nodes and adopt a hybrid strategy for each segment that includes conventional laser modulation, as well as a novel technique for sharing power across nodes dynamically. We represent energy internally as tokens, where one token will allow a node to send a message to any other node in its cluster. We allow optical stations to arbitrate for tokens at a global level, and then we predict the number of token equivalents of power that the off-chip laser needs to generate. Using …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:NhqRSupF_l8C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2019,"A spoofing attack is a critical issue in wireless communication in which a malicious transmitter outside a system attempts to be genuine. As a countermeasure against this, we propose a device-authentication method based on position identification using radio-propagation characteristics (RPCs). Not depending on information processing such as encryption technology, this method can be applied to sensing devices etc. which commonly have many resource restrictions. We call the space from which attacks achieve success as the “attack space.” In order to confine the attack space inside of the target system to prevent spoofing attacks from the outside, formulation of the relationship between combinations of transceivers and the attack space is necessary. In this research, we consider two RPCs, the received signal strength ratio (RSSR) and the time difference of arrival (TDoA), and construct the attack-space model which uses these RPCs simultaneously. We take a tire pressure monitoring system (TPMS) as a case study of this method and execute a security evaluation based on radio-wave-propagation simulation. The simulation results assuming multiple noise environments all indicate that it is possible to eliminate the attack possibility from a distant location.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:uWQEDVKXjbEC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2018,"Researchers have proposed numerous consistency models in distributed systems that offer higher performance than classical sequential consistency (SC). Even though these models do not guarantee sequential consistency; they either behave like an SC model under certain restrictive scenarios, or ensure SC behavior for a part of the system. We propose a different line of thinking where we try to accurately estimate the number of SC violations, and then try to adapt our system to optimally tradeoff performance, resource usage, and the number of SC violations. In this paper, we propose a generic theoretical model that can be used to analyze systems that are comprised of multiple sub-domains - each sequentially consistent. It is validated with real world measurements. Next, we use this model to propose a new form of consistency called social consistency, where socially connected users perceive an SC execution …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:CHSYGLWDkRkC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2018,"When modern systems-on-chip (SoCs), containing designs from different organizations, miscompute or underperform in the field, discerning the responsible component is a non-trivial task. A perfectly accountable system is one in which the on-chip component at fault is always unambiguously detected. The achievement of accountability can be greatly aided by the collection of runtime information that captures the events in the system that led to the error. Such information collection must be fair and impartial to all parties. In this article, we prove that logging messages communicated between components from different organizations is sufficient to provide accountability, provided the logs are authentic. We then construct a solution based on this premise, with an on-chip trusted auditing system to authenticate the logs. We present a thorough design of the auditing system, and demonstrate that its performance overhead …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:b0M2c_1WBrUC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2018,"In this work, we present a study of the leakage power modeling techniques commonly used in the architecture community. We further provide an analysis of the error in leakage power estimation using the various modeling techniques. We strongly believe that this study will help researchers determine an appropriate leakage model to use in their work, based on the desired modeling accuracy and speed.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:abG-DnoFyZgC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2018,"We have moved into an era where modern multicore systems must deal with several critical challenges such as increased power density and high temperatures. In addition to this, ITRS projects that heterogeneity due to manufacturing process variations would continue to rapidly increase in sub-nanometer technology nodes. Spatial heat influence or the lateral heat transfer is becoming more prevalent in manycore systems and has a significant impact on the processor power consumption. Thus it is becoming increasingly difficult to meet the application throughput requirements while adhering to the system power budget and thermal constraints. Many of the existing task mapping schemes that does not take into account the underlying variations in core frequency and leakage power consumption will result in sub-optimal solutions. In this work, we first formulate the mapping problem as an optimization problem and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:D03iK_w7-QYC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2018,"With the increasing complexity of modern systems-on-chip, the possibility of functional errors escaping design verification is growing. Postsilicon validation targets the discovery of these errors in early hardware prototypes. Due to limited visibility and observability, dedicated design-for-debug (DFD) hardware, such as trace buffers, is inserted to aid postsilicon validation. In spite of its benefit, such hardware incurs area overheads that impose size limitations. However, the effective overhead could be reduced if the area dedicated to DFD could be reused in-field. In this paper, we present a novel method for reusing an existing trace buffer as a victim cache of a processor to enhance the performance. The trace buffer storage space is reused for the victim cache with a small additional controller logic. Simultaneous multithreading allows further fine-grained control of the victim cache, which can be shared between the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:pyW8ca7W8N0C,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2018,"The Internet of Things (IoT) is poised to be one of the most disruptive technologies over the next decade. It is speculated, that we shall have billions of devices with communication capabilities very soon. Minimizing energy consumption is one of the most important problems in such IoT networks mainly because IoT nodes are distributed in the field with limited, unreliable, and intermittent sources of power. Even though the area of reducing power for stand-alone machines is very rich, there are very few references in the area of co-operative power minimization in a system with many IoT nodes. We propose two algorithms in this paper, which are at the two ends of the spectrum: Local exchanges information between neighboring nodes, and Global uses a global server that has recent snapshots of the global state of the network. We show that both these algorithms reduce energy consumption by roughly 40% for settings …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:f2IySw72cVMC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:_xSYboBqXhAC,http://www.cse.iitd.ac.in/~srsarangi
Smruti R. Sarangi,"['computer architecture', 'operating systems']",15,2534,2018,"State of the art XML parsing approaches read an XML file byte by byte, and use complex finite state machines to process each byte. In this paper, we propose a new parser, HPXA, which reads and processes 16 bytes at a time. We designed most of the components ab initio, to ensure that they can process multiple XML tokens and tags in parallel. We propose two basic elements - a sparse 1D array compactor, and a hardware unit called LTMAdder that takes its decisions based on adding the rows of a lower triangular matrix. We demonstrate that we are able to process 16 bytes in parallel with very few pipeline stalls for a suite of widely used XML benchmarks. Moreover, for a 28nm technology node, we can process XML data at 106 Gbps, which is roughly 6.5X faster than competing prior work.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=-5JfCRsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=-5JfCRsAAAAJ:a0OBvERweLwC,http://www.cse.iitd.ac.in/~srsarangi
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2022,"In this paper, we consider the problem of locating service and charging stations to serve commuters. In the service station location problem we are given the paths followed by m clients and wish to locate k service stations, from a set of feasible locations, such that the maximum detour that a client has to take is minimized. We give a solution that has a maximum detour \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$3\texttt{OPT}+L$$\end{document} where L is the length of the longest client-path.
Electric vehicles have a limited range and charging stations need to be located so that a client can drive from the source to destination without running out of charge. We consider two variants of the problem …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:S16KYo8Pm5AC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2022,"We study the fair and efficient allocation of a set of indivisible goods among agents, where each good has several copies, and each agent has an additively separable concave valuation function with a threshold. These valuations capture the property of diminishing marginal returns, and they are more general than the well-studied case of additive valuations. We present a polynomial-time algorithm that approximates the optimal Nash social welfare (NSW) up to a factor of e 1/e≈ 1.445. This matches with the state-of-the-art approximation factor for additive valuations. The computed allocation also satisfies the popular fairness guarantee of envy-freeness up to one good (EF1) up to a factor of 2+ ε. For instances without thresholds, it is also approximately Pareto-optimal. For instances satisfying a large market property, we show an improved approximation factor. Lastly, we show that the upper bounds on the optimal NSW introduced in Cole and Gkatzelis (2018) and Barman et al.(2018) have the same value.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:WZBGuue-350C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2021,"In this paper, we bound the integrality gap and the approximation ratio for maximum plane multiflow problems and deduce bounds on the flow-multicut-gap. We consider instances where the union of the supply and demand graphs is planar and prove that there exists a multiflow of value at least half the capacity of a minimum multicut. We then show how to convert any multiflow into a half-integer flow of value at least half the original multiflow. Finally, we round any half-integer multiflow into an integer multiflow, losing at most half the value thus providing a 1/4-approximation algorithm and integrality gap for maximum integer multiflows in the plane.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:k8Z6L05lTy4C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2021,"Vehicle routing problems are a broad class of combinatorial optimization problems that can be formulated as the problem of finding a tour in a weighted graph that optimizes some function of the visited vertices. For instance, a canonical and extensively studied vehicle routing problem is the orienteering problem where the goal is to find a tour that maximizes the number of vertices visited by a given deadline. In this paper, we consider the computational tractability of a well-known generalization of the orienteering problem called the Orient-MTW problem. The input to Orient-MTW consists of a weighted graph G(V, E) where for each vertex v ∊ V we are given a set of time instants Tv ⊆ [T], and a source vertex s. A tour starting at s is said to visit a vertex v if it transits through v at any time in the set Tv. The goal is to find a tour starting at the source vertex that maximizes the number of vertices visited. It is known that this …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:ML0RJ9NH7IQC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2020,"Given an edge weighted graph and a forest $F$, the $\textit{2-edge connectivity augmentation problem}$ is to pick a minimum weighted set of edges, $E'$, such that every connected component of $E'\cup F$ is 2-edge connected. Williamson et al. gave a 2-approximation algorithm (WGMV) for this problem using the primal-dual schema. We show that when edge weights are integral, the WGMV procedure can be modified to obtain a half-integral dual. The 2-edge connectivity augmentation problem has an interesting connection to routing flow in graphs where the union of supply and demand is planar. The half-integrality of the dual leads to a tight 2-approximate max-half-integral-flow min-multicut theorem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:BwyfMAYsbu0C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2020,"In the weighted flow-time problem on a single machine, we are given a set of jobs, where each job has a processing requirement , release date , and weight . The goal is to find a preemptive schedule which minimizes the sum of weighted flow-time of jobs, where the flow-time of a job is the difference between its completion time and its released date. We give the first pseudo-polynomial time constant approximation algorithm for this problem. The algorithm also extends directly to the problem of minimizing the norm of weighted flow-times. The running time of our algorithm is polynomial in , the number of jobs, and , which is the ratio of the largest to the smallest processing requirement of a job. Our algorithm relies on a novel reduction of this problem to a generalization of the multicut problem on trees, which we call the Demand MultiCut problem. Even though we do not give a constant factor …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:TIZ-Mc8IlK0C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2020,"Given n jobs with release dates, deadlines and processing times we consider the problem of scheduling them on m parallel machines so as to minimize the total energy consumed. Machines can enter a sleep state and they consume no energy in this state. Each machine requires L units of energy to awaken from the sleep state and in its active state the machine can process jobs and consumes a unit of energy per unit time. We allow for preemption and migration of jobs and provide the first constant approximation algorithm for this problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:EYYDruWGBe4C,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2019,"We consider the online problem of scheduling jobs on identical machines, where jobs have precedence constraints. We are interested in the demanding setting where the jobs sizes are not known up-front, but are revealed only upon completion (the non-clairvoyant setting). Such precedence-constrained scheduling problems routinely arise in map-reduce and large-scale optimization. In this paper, we make progress on this problem. For the objective of total weighted completion time, we give a constant-competitive algorithm. And for total weighted flow-time, we give an -competitive algorithm under -speed augmentation and a natural ``no-surprises'' assumption on release dates of jobs (which we show is necessary in this context). Our algorithm proceeds by assigning {\em virtual rates} to all the waiting jobs, including the ones which are dependent on other uncompleted jobs, and then use these virtual rates to decide on the actual rates of minimal jobs (i.e., jobs which do not have dependencies and hence are eligible to run). Interestingly, the virtual rates are obtained by allocating time in a fair manner, using a Eisenberg-Gale-type convex program (which we can also solve optimally using a primal-dual scheme). The optimality condition of this convex program allows us to show dual-fitting proofs more easily, without having to guess and hand-craft the duals. We feel that this idea of using fair virtual rates should have broader applicability in scheduling problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:g3aElNc5_aQC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2018,"For a 3-edge-connected cubic graph G=(V, E), we give an algorithm to construct a connected Eulerian subgraph of 2 G using at most⌊ 4| V|∕ 3⌋ edges.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:KUbvn5osdkgC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2018,"The notion of competitive ratio often turns out to be too pessimistic for the analysis of online algorithms. Although the approach of resource augmentation (introduced by Kalyanasundaram and Pruhs) has been very successful in dealing with a variety of objective functions, there are problems for which even a (arbitrary) constant speedup cannot lead to a constant competitive algorithm. Here we propose a rejection model which permits the online algorithm to not serve epsilon-fraction of requests. We present O (log 2⁡ 1/ε) and O (1/ε 4)-competitive algorithms for the problems of load balancing and minimizing maximum flow time in the restricted assignment setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:nrtMV_XWKgEC,http://www.cse.iitd.ac.in/~naveen/
Naveen Garg,"['Algorithms and Complexity', 'Optimization']",22,1752,2018,"In this paper, we propose and analyze a local search algorithm for the Universal facility location problem. Our algorithm improves the approximation ratio of this problem from 5.83, given by Angel et al., to 5. A second major contribution of the paper is that it gets rid of the expensive multi operation that was a mainstay of all previous local search algorithms for capacitated facility location and universal facility location problem. The only operations that we require to prove the 5-approximation are add, open, and close. A multi operation is basically a combination of the open and close operations. The 5-approximation algorithm for the capacitated facility location problem, given by Bansal et al., also uses the multi operation. However, on careful observation, it turned out that add, open, and close operations are sufficient to prove a 5-factor for the problem. This resulted into an improved algorithm for the universal facility location problem, with an improved factor.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=wNRE148AAAAJ&sortby=pubdate&citation_for_view=wNRE148AAAAJ:gsN89kCJA0AC,http://www.cse.iitd.ac.in/~naveen/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",9,486,2022,"Improving software performance through configuration parameter tuning is a common activity during software maintenance. Beyond traditional performance metrics like latency, mobile app developers are interested in reducing app energy usage. Some mobile apps have centralized locations for parameter tuning, similar to databases and operating systems, but it is common for mobile apps to have hundreds of parameters scattered around the source code. The correlation between these “deep” parameters and app energy usage is unclear. Researchers have studied the energy effects of deep parameters in specific modules, but we lack a systematic understanding of the energy impact of mobile deep parameters. In this paper we empirically investigate this topic, combining a developer survey with systematic energy measurements. Our motivational survey of 25 Android developers suggests that developers do not …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&sortby=pubdate&citation_for_view=_af8suQAAAAJ:NhqRSupF_l8C,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",9,486,2021,"In this paper, we report on our 6-year experience developing Eagle Tester (eTester for short) - a mobile battery drain testing and diagnostic tool. We show how eTester evolved from an ""academic"" prototype to a fully automated tool usable by the mobile industry.
We first present the design of our initial research prototype and discuss 8 key requirements for a usable battery drain testing and diagnostic tool gathered from some of the most popular software vendors in the Android ecosystem. These requirements posed interesting scientific and engineering challenges such as how to accurately estimate battery drain without requiring a priori power modeling, work on unmodified devices, and automatically monitor code evolution to generate high-fidelity battery spike alerts with actionable insights. These requirements motivated a complete overhaul of the eTester design and led to the creation of a novel battery drain …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&sortby=pubdate&citation_for_view=_af8suQAAAAJ:b0M2c_1WBrUC,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",9,486,2021,"Embodiments of the present invention provide a system and methods for detecting power bugs. In one embodiment, a computer-implemented method for analyzing a computer code includes generating a control flow graph for at least a portion of the computer code at a processor. The method further includes identifying power bugs by traversing the control flow graph if the control flow graph exits without performing a function call to deactivate power to any component of a device configured to execute computer executable instructions based on the computer code after performing a function call to activate power.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&sortby=pubdate&citation_for_view=_af8suQAAAAJ:abG-DnoFyZgC,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",9,486,2020,"Embodiments of the present invention provide a system and methods for detecting power bugs. In one embodiment, a computer-implemented method for analyzing a computer code includes generating a control flow graph for at least a portion of the computer code at a processor. The method further includes identifying power bugs by traversing the control flow graph if the control flow graph exits without performing a function call to deactivate power to any component of a device configured to execute computer executable instructions based on the computer code after performing a function call to activate power.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&sortby=pubdate&citation_for_view=_af8suQAAAAJ:EUQCXRtRnyEC,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",9,486,2020,"In this paper, we observe that modern mobile apps come with a large number of parameters that control the app behavior which indirectly affect the app energy drain, and using incorrect or non-optimal values for such app parameters can lead to app energy drain deficiency or even energy bugs. We argue conventional app energy optimization using an energy profiler which pinpoints energy hotspot code segments in the app source code may be ineffective in detecting such parameter-induced app energy deficiency. We propose app parameter energy profiling which identifies tunable app parameters that can reduce app energy drain without affecting app functions as a potentially more effective solution for debugging such app energy deficiency. We present the design and implementation of Medusa, an app parameter energy profiling framework. Medusa overcomes three key design challenges: how to filter out and narrow down candidate parameters, how to pick alternative parameter values, and how to perform reliable energy drain testing of app versions with mutated parameter values. We demonstrate the effectiveness of Medusa by applying it to a set of Android apps which successfully identifies tunable energy-reducing parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&sortby=pubdate&citation_for_view=_af8suQAAAAJ:bFI3QPDXJZMC,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",9,486,2020,"A differential resource analyzer performs differential resource profiling of two applications. The two applications are made to perform an operation. The differential resource analyzer matches a first application task of a first application to a second application task of a second application based on a determination that the first application task is similar to the second application task, and measures resource consumed in the first application task and the second application task. Responsive to determining that the second application task consumes less resource than the first application task, the differential resource analyzer performs an action to reduce resource consumption by the first application based on the second application task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&sortby=pubdate&citation_for_view=_af8suQAAAAJ:_xSYboBqXhAC,http://abhilash-jindal.com/
abhilash jindal,"['OS', 'Debugging', 'Mobile']",9,486,2018,"Mobile app energy profilers provide a foundational energy diagnostic tool by identifying energy hotspots in the app source code. However, they only tackle the first challenge faced by developers, as, after presented with the energy hotspots, developers typically do not have any guidance on how to proceed with the remaining optimization process:(1) Is there a more energy-efficient implementation for the same app task?(2) How to come up with the more efficient implementation?",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=_af8suQAAAAJ&sortby=pubdate&citation_for_view=_af8suQAAAAJ:pyW8ca7W8N0C,http://abhilash-jindal.com/
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2023,"Physical systems are commonly represented as a combination of particles, the individual dynamics of which govern the system dynamics. However, traditional approaches require the knowledge of several abstract quantities such as the energy or force to infer the dynamics of these particles. Here, we present a framework, namely, Lagrangian graph neural network (LGnn), that provides a strong inductive bias to learn the Lagrangian of a particle-based system directly from the trajectory. We test our approach on challenging systems with constraints and drag—LGnn outperforms baselines such as feed-forward Lagrangian neural network (Lnn) with improved performance. We also show the zero-shot generalizability of the system by simulating systems two orders of magnitude larger than the trained one and also hybrid systems that are unseen by the model, a unique feature. The graph architecture of LGnn …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:-DxkuPiZhfEC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2023,"Influence maximization (IM) refers to the problem of finding a subset of nodes in a network through which we could maximize our reach to other nodes in the network. This set is often called the ""seed set"", and its constituent nodes maximize the social diffusion process. IM has previously been studied in various settings, including under a time deadline, subject to constraints such as that of budget or coverage, and even subject to measures other than the centrality of nodes. The solution approach has generally been to prove that the objective function is submodular, or has a submodular proxy, and thus has a close greedy approximation. In this paper, we explore a variant of the IM problem where we wish to reach out to and maximize the probability of infection of a small subset of bounded capacity K. We show that this problem does not exhibit the same submodular guarantees as the original IM problem, for which we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:1tZ8xJnm2c8C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2023,"Graph neural networks (GNNs) find applications in various domains such as computational biology, natural language processing, and computer security. Owing to their popularity, there is an increasing need to explain GNN predictions since GNNs are black-box machine learning models. One way to address this is counterfactual reasoning where the objective is to change the GNN prediction by minimal changes in the input graph. Existing methods for counterfactual explanation of GNNs are limited to instance-specific local reasoning. This approach has two major limitations of not being able to offer global recourse policies and overloading human cognitive ability with too much information. In this work, we study the global explainability of GNNs through global counterfactual reasoning. Specifically, we want to find a small set of representative counterfactual graphs that explains all input graphs. Towards this goal, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:kJDgFkosVoMC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2023,"Optimization of atomic structures presents a challenging problem, due to their highly rough and non-convex energy landscape, with wide applications in the fields of drug design, materials discovery, and mechanics. Here, we present a graph reinforcement learning approach, StriderNET, that learns a policy to displace the atoms towards low energy configurations. We evaluate the performance of StriderNET on three complex atomic systems, namely, binary Lennard-Jones particles, calcium silicate hydrates gel, and disordered silicon. We show that StriderNET outperforms all classical optimization algorithms and enables the discovery of a lower energy minimum. In addition, StriderNET exhibits a higher rate of reaching minima with energies, as confirmed by the average over multiple realizations. Finally, we show that StriderNET exhibits inductivity to unseen system sizes that are an order of magnitude different from the training system.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:ghEM2AJqZyQC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2023,"Social commerce platforms are emerging businesses where producers sell products through re-sellers who advertise the products to other customers in their social network. Due to the increasing popularity of this business model, thousands of small producers and re-sellers are starting to depend on these platforms for their livelihood; thus, it is important to provide fair earning opportunities to them. The enormous product space in such platforms prohibits manual search, and motivates the need for recommendation algorithms to effectively allocate product exposure and, consequently, earning opportunities. In this work, we focus on the fairness of such allocations in social commerce platforms and formulate the problem of assigning products to re-sellers as a fair division problem with indivisible items under two-sided cardinality constraints, wherein each product must be given to at least a certain number of re-sellers and each re-seller must get a certain number of products. Our work systematically explores various well-studied benchmarks of fairness—including Nash social welfare, envy-freeness up to one item (𝐸𝐹1), and equitability up to one item (𝐸𝑄1)—from both theoretical and experimental perspectives. We find that the existential and computational guarantees of these concepts known from the unconstrained setting do not extend to our constrained model. To address this limitation, we develop a mixed-integer linear program and other scalable heuristics that provide near-optimal approximation of Nash social welfare in simulated and real social commerce datasets. Overall, our work takes the first step towards achieving provable fairness …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:2ywjKiB__4kC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2023,"Understanding the evolution of communities and the factors that contribute to their development, stability and disappearance over time is a fundamental problem in the study of temporal networks. The concept of𝑘-core is one of the most popular metrics to detect communities. Since the 𝑘-core of a temporal network changes with time, an important question arises: Are there nodes that always remain within the 𝑘-core? In this paper, we explore this question by introducing the notion of core-invariant nodes. Given a temporal window∆ and a parameter K, the core-invariant nodes are those that are part of the K-core throughout∆. Coreinvariant nodes have been shown to dictate the stability of networks, while being also useful in detecting anomalous behavior. The complexity of finding core-invariant nodes is 𝑂 (|∆|×| 𝐸|), which is exorbitantly high for million-scale networks. We overcome this computational bottleneck by designing an algorithm called Kwiq. Kwiq efficiently processes the cascading impact of network updates through a novel data structure called orientation graph. Through extensive experiments on real temporal networks containing millions of nodes, we establish that the proposed pruning strategies are more than 5 times faster than baseline strategies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:27LrP4qxOz0C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"Lagrangian and Hamiltonian neural networks LNN and HNNs, respectively) encode strong inductive biases that allow them to outperform other models of physical systems significantly. However, these models have, thus far, mostly been limited to simple systems such as pendulums and springs or a single rigid body such as a gyroscope or a rigid rotor. Here, we present a Lagrangian graph neural network (LGNN) that can learn the dynamics of articulated rigid bodies by exploiting their topology. We demonstrate the performance of LGNN by learning the dynamics of ropes, chains, and trusses with the bars modeled as rigid bodies. LGNN also exhibits generalizability---LGNN trained on chains with a few segments exhibits generalizability to simulate a chain with large number of links and arbitrary link length. We also show that the LGNN can simulate unseen hybrid systems including bars and chains, on which they have not been trained on. Specifically, we show that the LGNN can be used to model the dynamics of complex real-world structures such as the stability of tensegrity structures. Finally, we discuss the non-diagonal nature of the mass matrix and its ability to generalize in complex systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:wE-fMHVdjMkC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"Similarity search in graph databases is one of the most fundamental operations in graph analytics. Among various distance functions, graph and subgraph edit distances (GED and SED respectively) are two of the most popular and expressive measures. Unfortunately, exact computations for both are NP-hard. To overcome this computational bottleneck, neural approaches to learn and predict edit distance in polynomial time have received much interest. While considerable progress has been made, there exist limitations that need to be addressed. First, the efficacy of an approximate distance function lies not only in its approximation accuracy, but also in the preservation of its properties. To elaborate, although GED is a metric, its neural approximations do not provide such a guarantee. This prohibits their usage in higher order tasks that rely on metric distance functions, such as clustering or indexing. Second, several existing frameworks for GED do not extend to SED due to SED being asymmetric. In this work, we design a novel siamese graph neural network called Greed, which through a carefully crafted inductive bias, learns GED and SED in a property-preserving manner. Through extensive experiments across real graph datasets containing up to million edges, we establish that Greed is not only more accurate than the state of the art, but also up to orders of magnitude faster. Even more significantly, due to preserving the triangle inequality, the generated embeddings are indexable and consequently, even in a CPU-only environment, Greed is up to times faster than GPU-powered computations of the closest baseline.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:zdjWy_NXXwUC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"Recently, graph neural networks have been gaining a lot of attention to simulate dynamical systems due to their inductive nature leading to zero-shot generalizability. Similarly, physics-informed inductive biases in deep-learning frameworks have been shown to give superior performance in learning the dynamics of physical systems. There is a growing volume of literature that attempts to combine these two approaches. Here, we evaluate the performance of thirteen different graph neural networks, namely, Hamiltonian and Lagrangian graph neural networks, graph neural ODE, and their variants with explicit constraints and different architectures. We briefly explain the theoretical formulation highlighting the similarities and differences in the inductive biases and graph architecture of these systems. We evaluate these models on spring, pendulum, gravitational, and 3D deformable solid systems to compare the performance in terms of rollout error, conserved quantities such as energy and momentum, and generalizability to unseen system sizes. Our study demonstrates that GNNs with additional inductive biases, such as explicit constraints and decoupling of kinetic and potential energies, exhibit significantly enhanced performance. Further, all the physics-informed GNNs exhibit zero-shot generalizability to system sizes an order of magnitude larger than the training system, thus providing a promising route to simulate large-scale realistic systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:g5Ck-dwhA_QC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"Neural networks with physics based inductive biases such as Lagrangian neural networks (LNN), and Hamiltonian neural networks (HNN) learn the dynamics of physical systems by encoding strong inductive biases. Alternatively, Neural ODEs with appropriate inductive biases have also been shown to give similar performances. However, these models, when applied to particle based systems, are transductive in nature and hence, do not generalize to large system sizes. In this paper, we present a graph based neural ODE, GNODE, to learn the time evolution of dynamical systems. Further, we carefully analyse the role of different inductive biases on the performance of GNODE. We show that, similar to LNN and HNN, encoding the constraints explicitly can significantly improve the training efficiency and performance of GNODE significantly. Our experiments also assess the value of additional inductive biases, such as Newtons third law, on the final performance of the model. We demonstrate that inducing these biases can enhance the performance of model by orders of magnitude in terms of both energy violation and rollout error. Interestingly, we observe that the GNODE trained with the most effective inductive biases, namely MCGNODE, outperforms the graph versions of LNN and HNN, namely, Lagrangian graph networks (LGN) and Hamiltonian graph networks (HGN) in terms of energy violation error by approx 4 orders of magnitude for a pendulum system, and approx 2 orders of magnitude for spring systems. These results suggest that competitive performances with energy conserving neural networks can be obtained for NODE based systems …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:X9ykpCP0fEIC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"Mixed Integer programs (MIPs) are typically solved by the Branch-and-Bound algorithm. Recently, Learning to imitate fast approximations of the expert strong branching heuristic has gained attention due to its success in reducing the running time for solving MIPs. However, existing learning-to-branch methods assume that the entire training data is available in a single session of training. This assumption is often not true, and if the training data is supplied in continual fashion over time, existing techniques suffer from catastrophic forgetting. In this work, we study the hitherto unexplored paradigm of Lifelong Learning to Branch on Mixed Integer Programs. To mitigate catastrophic forgetting, we propose LIMIP, which is powered by the idea of modeling an MIP instance in the form of a bipartite graph, which we map to an embedding space using a bipartite Graph Attention Network. This rich embedding space avoids catastrophic forgetting through the application of knowledge distillation and elastic weight consolidation, wherein we learn the parameters key towards retaining efficacy and are therefore protected from significant drift. We evaluate LIMIP on a series of NP-hard problems and establish that in comparison to existing baselines, LIMIP is up to 50% better when confronted with lifelong learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:v6i8RKmR8ToC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"Along with the rapid growth and rise to prominence of food delivery platforms, concerns have also risen about the terms of employment of the``gig workers''underpinning this growth. Our analysis on data derived from a real-world food delivery platform across three large cities from India show that there is significant inequality in the money delivery agents earn. In this paper, we formulate the problem of fair income distribution among agents while also ensuring timely food delivery. We establish that the problem is not only NP-hard but also inapproximable in polynomial time. We overcome this computational bottleneck through a novel matching algorithm called FairFoody. Extensive experiments over real-world food delivery datasets show FairFoody imparts up to 10 times improvement in equitable income distribution when compared to baseline strategies, while also ensuring minimal impact on customer experience.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:DyXnQzXoVgIC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"There has been a recent surge in learning generative models for graphs. While impressive progress has been made on static graphs, work on generative modeling of temporal graphs is at a nascent stage with significant scope for improvement. First, existing generative models do not scale with either the time horizon or the number of nodes. Second, existing techniques are transductive in nature and thus do not facilitate knowledge transfer. Finally, due to relying on one-to-one node mapping from source to the generated graph, existing models leak node identity information and do not allow up-scaling/down-scaling the source graph size. In this paper, we bridge these gaps with a novel generative model called TIGGER. TIGGER derives its power through a combination of temporal point processes with auto-regressive modeling enabling both transductive and inductive variants. Through extensive experiments on real datasets, we establish TIGGER generates graphs of superior fidelity, while also being up to 3 orders of magnitude faster than the state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:SIv7DqKytYAC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"Learning the structure--dynamics correlation in disordered systems is a long-standing problem. Here, we use unsupervised machine learning employing graph neural networks (GNN) to investigate the local structures in disordered systems. We test our approach on 2D binary A65B35 LJ glasses and extract structures corresponding to liquid, supercooled and glassy states at different cooling rates. The neighborhood representation of atoms learned by a GNN in an unsupervised fashion, when clustered, reveal local structures with varying potential energies. These clusters exhibit dynamical heterogeneity in the structure in congruence with their local energy landscape. Altogether, the present study shows that unsupervised graph embedding can reveal the structure--dynamics correlation in disordered structures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:2v_ZtQDX9iAC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"With the increasing popularity of food delivery platforms, it has become pertinent to look into the working conditions of the 'gig' workers in these platforms, especially providing them fair wages, reasonable working hours, and transparency on work availability. However, any solution to these problems must not degrade customer experience and be cost-effective to ensure that platforms are willing to adopt them. We propose WORK4FOOD, which provides income guarantees to delivery agents, while minimizing platform costs and ensuring customer satisfaction. WORK4FOOD ensures that the income guarantees are met in such a way that it does not lead to increased working hours or degrade environmental impact. To incorporate these objectives, WORK4FOOD balances supply and demand by controlling the number of agents in the system and providing dynamic payment guarantees to agents based on factors such as agent location, ratings, etc. We evaluate WORK4FOOD on a real-world dataset from a leading food delivery platform and establish its advantages over the state of the art in terms of the multi-dimensional objectives at hand.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:8Xgff_V0N9gC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2022,"Food delivery, today, is a multi-billion dollar industry. Minimizing food delivery time is a key contributor towards building positive customer experiences. More precisely, given a stream of food orders and available delivery vehicles, how should orders be assigned to vehicles so the delivery time is minimized? Several decisions have to be made: (1) assignment of orders to vehicles, (2) grouping orders into batches to cope with limited vehicle availability, (3) adapting to dynamic positions of delivery vehicles, and (4) ensuring scalability to the demands of real-world workloads. We show that the minimization problem is not only NP-hard but inapproximable in polynomial time. To mitigate this computational bottleneck, we develop an algorithm called FoodMatch, which maps the vehicle assignment problem to that of minimum weight perfect matching on a bipartite graph. To further reduce the quadratic construction cost of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:UmS_249rOGwC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2021,"Graph neural networks (GNNs) have witnessed significant adoption in the industry owing to impressive performance on various predictive tasks. Performance alone, however, is not enough. Any widely deployed machine learning algorithm must be robust to adversarial attacks. In this work, we investigate this aspect for GNNs, identify vulnerabilities, and link them to graph properties that may potentially lead to the development of more secure and robust GNNs. Specifically, we formulate the problem of task and model agnostic evasion attacks where adversaries modify the test graph to affect the performance of any unknown downstream task. The proposed algorithm, GRAND (aph ttack via eighborhood istortion) shows that distortion of node neighborhoods is effective in drastically compromising prediction performance. Although neighborhood distortion is an NP-hard problem, GRAND designs an effective heuristic through a novel combination of Graph Isomorphism Network with deep -learning. Extensive experiments on real datasets show that, on average, GRAND is up to more effective than state of the art techniques, while being more than times faster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:LXmCCkuhhTsC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2021,"Predicting the most likely route from a source location to a destination is a core functionality in mapping services. Although the problem has been studied in the literature, two key limitations remain to be addressed. First, our study reveals that a significant portion of the routes recommended by existing methods fail to reach the destination. Second, existing techniques are transductive in nature; hence, they fail to recommend routes if unseen roads are encountered at inference time. In this paper, we address these limitations through an inductive algorithm called NeuroMLR. NeuroMLR learns a generative model from historical trajectories by conditioning on three explanatory factors: the current location, the destination, and real-time traffic conditions. The conditional distributions are learned through a novel combination of Lipschitz embedding with Graph Convolutional Networks (GCN) using historical trajectory data. Through in-depth experiments on real-world datasets, we establish that NeuroMLR imparts significant improvement in accuracy over the state of the art. More importantly, NeuroMLR generalizes dramatically better to unseen data and the recommended routes reach the destination with much higher likelihood than existing techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:Hck25ST_3aIC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2021,"Realistic models of physical world rely on differentiable symmetries that, in turn, correspond to conservation laws. Recent works on Lagrangian and Hamiltonian neural networks show that the underlying symmetries of a system can be easily learned by a neural network when provided with an appropriate inductive bias. However, these models still suffer from issues such as inability to generalize to arbitrary system sizes, poor interpretability, and most importantly, inability to learn translational and rotational symmetries, which lead to the conservation laws of linear and angular momentum, respectively. Here, we present a momentum conserving Lagrangian neural network (MCLNN) that learns the Lagrangian of a system, while also preserving the translational and rotational symmetries. We test our approach on linear and non-linear spring systems, and a gravitational system, demonstrating the energy and momentum conservation. We also show that the model developed can generalize to systems of any arbitrary size. Finally, we discuss the interpretability of the MCLNN, which directly provides physical insights into the interactions of multi-particle systems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:UuEBAcK4md4C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2021,"Regular simple path query (RPQ) is one of the fundamental operators in graph analytics. In an RPQ, the input is a graph, a source node and a regular expression. The goal is to identify all nodes that are connected to the source through a simple path whose label sequence satisfies the given regular expression. The regular expression acts as a formal specification of the search space that is of interest to the user. Although regular expressions have high expressive power, they act as barrier to non-technical users. Furthermore, to fully realize the power of regular expressions, the user must be familiar with the domain of the graph dataset. In this study, we address this bottleneck by bridging RPQs with the query-by-example paradigm. More specifically, we ask the user for an exemplar pair that characterizes the paths of interest, and the regular expression is automatically inferred from this exemplar. This novel problem …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:aIdbFUkbNIkC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2021,"Given a stream of food orders and available delivery vehicles, how should orders be assigned to vehicles so that the delivery time is minimized? For a successful assignment strategy, two key decisions need to be made: (1) assignment of orders to vehicles, (2) grouping orders into batches to cope with limited vehicle availability. We show that the minimization problem is not only NP-hard but inapproximable in polynomial time. To mitigate this computational bottleneck, we develop an algorithm called FOODMATCH, which maps the vehicle assignment problem to that of minimum weight perfect matching on a bipartite graph. The solution quality is further enhanced by reducing batching to a graph clustering problem. Extensive experiments on food-delivery data from large metropolitan cities establish that FOODMATCH is substantially better than baseline strategies on a number of metrics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:HJSXoJQnj-YC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2021,"In signed networks, each edge is labeled as either positive or negative. The edge sign captures the polarity of a relationship. Balance of signed networks is a well-studied property in graph theory. In a balanced (sub)graph, the vertices can be partitioned into two subsets with negative edges present only across the partitions. Balanced portions of a graph have been shown to increase coherence among its members and lead to better performance. While existing works have focused primarily on finding the largest balanced subgraph inside a graph, we study the network design problem of maximizing balance of a target community (subgraph). In particular, given a budget b and a community of interest within the signed network, we aim to make the community as close to being balanced as possible by deleting up to b edges. Besides establishing NP-hardness, we also show that the problem is non-monotone and non …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:PkcyUWeTMh0C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2021,"Instead of measuring the betweenness of a node with respect to an individual source and an individual target node, we consider the case where the source, as well as the target, are two groups of nodes. To concretize this, we present Group-to-group random walk betweenness centrality, which is a generalization of random walk betweenness proposed by Newman (2005). We also show an interesting connection between the Laplacian equations and the hitting times of random walks, which allows us to use Laplacian solvers to compute our metric efficiently. Using our new centrality, we study a setting where a source group of nodes is infected and we wish to vaccinate or quarantine a limited number of uninfected nodes in such a way that the target group of nodes is protected and the infection is controlled. Empirical evaluation on real-world networks establishes that our group-to-group centrality metric is more …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:IsPWOBWtZBwC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2020,"We have developed a new algorithm for tracking 3D seismic horizons. The algorithm combines an inversion-based, seismic-dip flattening technique with conventional, similarity-based autotracking. The inversion part of the algorithm aims to minimize the error between horizon dips and computed seismic dips. After each cycle in the inversion loop, more seeds are added to the horizon by the similarity-based autotracker. In the example data set, the algorithm is first used to quickly track a set of framework horizons, each guided by a small set of user-picked seed positions. Next, the intervals bounded by the framework horizons are infilled to generate a dense set of horizons, also known as HorizonCube. This is done under the supervision of a human interpreter in a similar manner. The results show that the algorithm behaves better than unconstrained flattening techniques in intervals with trackable events …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:TlpoogIpr_IC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2020,"Majority of the existing graph neural networks (GNN) learn node embeddings that encode their local neighborhoods but not their positions. Consequently, two nodes that are vastly distant but located in similar local neighborhoods map to similar embeddings in those networks. This limitation prevents accurate performance in predictive tasks that rely on position information. In this paper, we develop GraphReach, a position-aware inductive GNN that captures the global positions of nodes through reachability estimations with respect to a set of anchor nodes. The anchors are strategically selected so that reachability estimations across all the nodes are maximized. We show that this combinatorial anchor selection problem is NP-hard and, consequently, develop a greedy (1-1/e) approximation heuristic. Empirical evaluation against state-of-the-art GNN architectures reveal that GraphReach provides up to 40% relative improvement in accuracy. In addition, it is more robust to adversarial attacks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:JTqpx9DYBaYC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2020,"We investigate the problem of correlated subgraphs mining (CSM) where the goal is to identify pairs of subgraph patterns that frequently co-occur in proximity within a single graph. Correlated subgraph patterns are different from frequent subgraphs due to the flexibility in connections between constituent subgraph instances and thus, existing frequent subgraphs mining algorithms cannot be directly applied for CSM. Moreover, computing the degree of correlation between two patterns requires enumerating and finding distances between every pair of subgraph instances of both patterns - a task that is both memory-intensive as well as computationally demanding. To this end, we propose two holistic best-first exploration algorithms: CSM-E (an exact method) and CSM-A (a more efficient approximate method with near-optimal quality). To further improve efficiency, we propose a top-k pruning strategy, while to reduce …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:SnGPuo6Feq8C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2020,"Graph generative models have been extensively studied in the data mining literature. While traditional techniques are based on generating structures that adhere to a pre-decided distribution, recent techniques have shifted towards learning this distribution directly from the data. While learning-based approaches have imparted significant improvement in quality, some limitations remain to be addressed. First, learning graph distributions introduces additional computational overhead, which limits their scalability to large graph databases. Second, many techniques only learn the structure and do not address the need to also learn node and edge labels, which encode important semantic information and influence the structure itself. Third, existing techniques often incorporate domain-specific rules and lack generalizability. Fourth, the experimentation of existing techniques is not comprehensive enough due to either …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:69ZgNCALVd0C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2020,"There has been an increased interest in discovering heuristics for combinatorial problems on graphs through machine learning. While existing techniques have primarily focused on obtaining high-quality solutions, scalability to billion-sized graphs has not been adequately addressed. In addition, the impact of a budget-constraint, which is necessary for many practical scenarios, remains to be studied. In this paper, we propose a framework called GCOMB to bridge these gaps. GCOMB trains a Graph Convolutional Network (GCN) using a novel probabilistic greedy mechanism to predict the quality of a node. To further facilitate the combinatorial nature of the problem, GCOMB utilizes a Q-learning framework, which is made efficient through importance sampling. We perform extensive experiments on real graphs to benchmark the efficiency and efficacy of GCOMB. Our results establish that GCOMB is 100 times faster and marginally better in quality than state-of-the-art algorithms for learning combinatorial algorithms. Additionally, a case-study on the practical combinatorial problem of Influence Maximization (IM) shows GCOMB is 150 times faster than the specialized IM algorithm IMM with similar quality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:CYCckWUYoCcC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2020,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:rbm3iO8VlycC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2019,"Horizons in a seismic image are geologically signficant surfaces that can be used for understanding geological structures and stratigraphy models. However, horizon tracking in seismic data is a time consuming and challenging task. Saving geologist's time from this seismic interpretation task is essential given the time constraints for the decision making in the oil & gas industry. We take advantage of the deep convolutional neural networks (CNN) to track the horizons directly from the seismic images. We propose a novel automatic seismic horizon tracking method that can reduce the time needed for interpretation, as well as increase the accuracy for the geologists. We show the performance comparison of the proposed CNN model for different training data set sizes and different methods of balancing the classes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:QUX0mv85b1cC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2019,"The present disclosure relates to a method performed by a network node (54) in a communication network (50) comprising a plurality of communication devices (51), for finding temporally connected connection patterns of the communication devices in the network. The method comprises identifying signalling between the communication devices during a predefined time duration to form a main communication graph in which the plurality of communication devices are nodes. The method also comprises partitioning the main communication graph for a time period comprised in said time duration to capture temporally connected signalling between some of the communication devices as illustrated in the main communication graph in a partitioned communication graph. The method also comprises forming at least one subgraph from the partitioned communication graph, comprising m nodes corresponding to m …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:-nhnvRiOwuoC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2019,"A fundamental query in labeled graphs is to determine if there exists a path between a given source and target vertices, such that the path satisfies a given label constraint. One of the powerful forms of specifying label constraints is through regular expressions, and the resulting problem of reachability queries under regular simple paths (RSP) form the core of many practical graph query languages such as SPARQL from W3C, Cypher of Neo4J, Oracle's PGQL and LDBC's G-CORE. Despite its importance, since it is known that answering RSP queries is NP-Hard, there are no scalable and practical solutions for answering reachability with full-range of regular expressions as constraints. In this paper, we circumvent this computational bottleneck by designing a random-walk based sampling algorithm called ARRIVAL, which is backed by theoretical guarantees on its expected quality. Extensive experiments on billion …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:2l5NCbZemmgC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2019,"The phenomenal growth of graph data from a wide variety of real-world applications has rendered graph querying to be a problem of paramount importance. Traditional techniques use structural as well as node similarities to find matches of a given query graph in a (large) target graph. However, almost all existing techniques have tacitly ignored the presence of relationships in graphs, which are usually encoded through interactions between node and edge labels. In this paper, we propose RAQ-Relationship-Aware Graph Querying-to mitigate this gap. Given a query graph, RAQ identifies the k best matching subgraphs of the target graph that encode similar relationships as in the query graph. To assess the utility of RAQ as a graph querying paradigm for knowledge discovery and exploration tasks, we perform a user survey on the Internet Movie Database (IMDb), where an overwhelming 86% of the 170 surveyed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:DkZNVXde3BIC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2019,"In taxi ride-sharing, multiple customers are allotted to the same taxi as long as they are compatible, i.e., if none of them suffers a detour beyond a permissible threshold. To attract customers to ride-sharing, taxi operators promise a reduced fare upfront. As a result, if the taxi fails to pair the initial customer with additional compatible passengers, the taxi operator incurs a financial loss. Hence, it is important to ensure that the taxi finds compatible customers once it has picked up the initial customer. In the current scenario, the appearance of subsequent compatible customers is left to luck: a taxi moves along the shortest (or quickest) path for the existing customer and hopes to find additional compatible customers on its way. In this paper, we ask: Is the shortest path the optimal path for ride-sharing? To investigate this question, we develop a route recommendation algorithm called Share, which predicts the route with the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:SGW5VrABaM0C,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2019,"Several services today are annotated with points of interest (PoIs) such as ""coffee shop"", ""park"", etc. In this paper, we study the query where a user provides a set of relevant PoIs and wants to identify the optimal route covering these PoIs. Ideally, the route should be small in length so that the user can conveniently explore the PoIs. On the other hand, the route should cover as many of the input PoIs as possible. These conflicting requirements of the optimal route raise an intriguing question: how do you balance the importance of route length vs. PoI coverage? If the route is to be covered on foot, and it is raining, length is critical for convenience. On the other hand, if the weather conditions are good, or the user is equipped with a vehicle, coverage is more important. In essence, the relative importance depends on several latent factors and we solve this dilemma through skyline route queries. Skyline routes subsume the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:pS0ncopqnHgC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2019,"The ability to search for a query molecule on massive molecular repositories is a fundamental task in chemoinformatics and drug-discovery. Chemical fingerprints are commonly used to characterize the structure and properties of molecules. Some fingerprints, particularly unfolded fingerprints, are often of extreme high dimension and sparse where only few features have a positive value. In this work, we propose a new searching algorithm, RISC, which exploits sparsity in high-dimensional fingerprints to derive effective pruning mechanisms and dramatically speed-up searching efficiency. RISC is robust enough to work on both binary and nonbinary chemical fingerprints. Extensive experiments on Range Queries and Top-k Queries across several molecular repositories demonstrate that at fingerprints of dimension 2048 and above, which is often the case with unfolded fingerprints, RISC is consistently faster than the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:An6A6Jpfc1oC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2019,"The steady growth of graph data from social networks has resulted in wide-spread research on the influence maximization (IM) problem. This results in extension of the state-of-the-art almost every year. With the recent explosion in the application of IM in solving real-world problems, it is no longer a theoretical exercise. Today, IM is used in a plethora of real-world scenarios, with OnePlus 1 series of mobile phones, Hokey Pokey 2 ice-creams, and galleri5 influencer marketplace 3 being the most prominent industrial use-cases. Given this scenario, navigating the maze of IM techniques to get an in-depth understanding of their utilities is of prime importance. In this tutorial, we address this paramount issue and solve the dilemma of “Which IM technique to use and under What scenarios”?“What does it really mean to claim to be the state-of-the-art”?
This tutorial builds upon our benchmarking study [1], and will provide a concise and intuitive overview of the most important IM techniques, which is usually lost in the technical literature. Specifically, we will unearth a series of incorrect claims made by prominent IM papers, disseminate the inherent deficiencies of existing approaches, and surface the open challenges in IM even after a decade of research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:eO3_k5sD8BwC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2018,"We study the problem of route recommendation to idle taxi drivers such that the distance between the taxi and an anticipated customer request is minimized. Minimizing the distance to the next anticipated customer leads to more productivity for the taxi driver and less waiting time for the customer. To anticipate when and where future customer requests are likely to come from and accordingly recom- mend routes, we develop a route recommendation engine called MDM: Minimizing Distance through Monte Carlo Tree Search. In contrast to existing techniques, MDM employs a continuous learning platform where the underlying model to predict future customer requests is dynamically updated. Extensive experiments on real taxi data from New York and San Francisco reveal that MDM is up to 70% better than the state of the art and robust to anomalous events such as concerts, sporting events, etc.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:YsrPvlHIBpEC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2018,"A search query, being a very concise grounding of user intent, could potentially have many possible interpretations. Search engines hedge their bets by diversifying top results to cover multiple such possibilities so that the user is likely to be satisfied, whatever be her intended interpretation. Diversified Query Expansion is the problem of diversifying query expansion suggestions, so that the user can specialize the query to better suit her intent, even before perusing search results. In this paper, we consider the usage of semantic resources and tools to arrive at improved methods for diversified query expansion. In particular, we develop two methods, those that leverage Wikipedia and pre-learnt distributional word embeddings respectively. Both the approaches operate on a common three-phase framework; that of first taking a set of informative terms from the search results of the initial query, then building a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:uVUOdF_882EC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2018,"In several domains, the flow of data is governed by an underlying network. Reduction of delays in end-to-end data flow is an important network optimization task. Reduced delays enable shorter travel times for vehicles in road networks, faster information flow in social networks, and increased rate of packets in communication networks. While techniques for network delay minimization have been proposed, they fail to provide any noticeable reduction in individual data flows. Furthermore, they treat all nodes as equally important, which is often not the case in real-world networks. In this paper, we incorporate these practical aspects and propose a network design problem where the goal is to perform k network upgrades such that it maximizes the number of flows in the network with a noticeable reduction in delay. We show that the problem is NP-hard, APX-hard, and non-submodular. We overcome these computational …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:ziOE8S1-AIUC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2018,"The inherent conflict between noncovalent interactions and the large conformational entropy of the polypeptide chain forces folding reactions and their mechanisms to deviate significantly from chemical reactions. Accordingly, measures of structure in the transition state ensemble (TSE) are strongly influenced by the underlying distributions of microscopic folding pathways that are challenging to discern experimentally. Here, we present a detailed analysis of 150,000 folding transition paths of five proteins at three different thermodynamic conditions from an experimentally consistent statistical mechanical model. We find that the underlying TSE structural distributions are rarely unimodal, and the average experimental measures arise from complex underlying distributions. Unfolding pathways also exhibit subtle differences from folding counterparts due to a combination of Hammond behavior and native-state …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:oi2SiIJ9l4AC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2018,"An efficient public bus transit service is critical to achieving sustainable urban transport. To design an efficient bus transit system, a fundamental requirement is the complete list of all bus stops in the city. Often the bus stops are owned and maintained by a different government entity from that which plans and operates the buses. As a result, bus stop information is incomplete, erroneous, and outdated leading to sub-optimal planning and operations and consequent reduction in the transit agency's ridership. In this work, we propose an algorithm to mine bus stops automatically from bus GPS trajectories. The proposed technique is powered by a novel combination of feature mining with classification algorithms to predict bus stops in a city. Our technique negates the need for manual field visits to annotate bus stops and saves time and cost for transit agencies. We perform extensive empirical analysis on real datasets …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:mUJArPsKIAAC,http://www.cse.iitd.ac.in/~sayan
Sayan Ranu,"['Machine Learning and Data Mining for Graphs', 'Spatio-temporal data analytics']",18,1274,2018,"Mining subgraph patterns is an active area of research due to its wide-ranging applications. Examples include frequent subgraph mining, discriminative subgraph mining, statistically significant subgraphs. Existing research has primarily focused on mining all subgraph patterns in the database. However, due to the exponential subgraph search space, the number of patterns mined, typically, is too large for any human-mediated analysis. Consequently, deriving insights from the mined patterns is hard for domain scientists. In addition, subgraph pattern mining is posed in multiple forms: the function that models if a subgraph is a pattern varies based on the application and the database could be over multiple graphs or a single, large graph. In this paper, we ask the following question: Given a subgraph importance function and a budget k, which are the k subgraph patterns that best represent all other patterns of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=K4w5qYUAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=K4w5qYUAAAAJ:3bvyWxjaHKcC,http://www.cse.iitd.ac.in/~sayan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2023,"We focus on the problem of LiDAR point cloud based loop detection (or Finding) and closure (LDC) in a multi-agent setting. State-of-the-art (SOTA) techniques directly generate learned embeddings of a given point cloud, require large data transfers, and are not robust to wide variations in 6 Degrees-of-Freedom (DOF) viewpoint. Moreover, absence of strong priors in an unstructured point cloud leads to highly inaccurate LDC. In this original approach, we propose independent roll and pitch canonicalization of the point clouds using a common dominant ground plane. Discretization of the canonicalized point cloud along the axis perpendicular to the ground plane leads to an image similar to Digital Elevation Maps (DEMs), which exposes strong spatial priors in the scene. Our experiments show that LDC based on learnt embeddings of such DEMs is not only data efficient but also significantly more robust, and generalizable than the current SOTA. We report significant performance gain in terms of Average Precision for loop detection and absolute translation/rotation error for relative pose estimation (or loop closure) on Kitti, GPR and Oxford Robot Car over multiple SOTA LDC methods. Our encoder technique allows to compress the original point cloud by over 830 times. To further test the robustness of our technique we create and opensource a custom dataset called Lidar-UrbanFly Dataset (LUF) which consists of point clouds obtained from a LiDAR mounted on a quadrotor.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:Tiz5es2fbqcC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2023,"Modern deep neural network models are known to erroneously classify out-of-distribution (OOD) test data into one of the in-distribution (ID) training classes with high confidence. This can have disastrous consequences for safety-critical applications. A popular mitigation strategy is to train a separate classifier that can detect such OOD samples at test time. In most practical settings OOD examples are not known at train time, and hence a key question is: how to augment theID data with syntheticOOD samples for training such anOOD detector? In this paper, we propose a novel Compounded Corruption (CnC) technique for the OOD data augmentation. One of the major advantages of CnC is that it does not require any hold-out data apart from training set. Further, unlike current state-of-the-art (SOTA) techniques, CnC does not require backpropagation or ensembling at the test time, making our method much faster at …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:CHSYGLWDkRkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2023,"Egocentric videos are recorded in a hands-free, always-on, under enhanced privacy-sensitive scenario and are often collected from day to weeks. For efficient consumption, such videos require robust video analysis techniques that can deal with extremely long sequences in an unsupervised setting. This dissertation explores a novel research area by developing video analysis tasks for extremely long and sequential data (ranging from a day to weeks long) in a self supervised /unsupervised setting. In this dissertation, we address the three key video analysis problems, namely temporal segmentation, summa-rization, and recovering activity patterns, specifically designed to deal with the issues of scalability, privacy, and unlabeled data.There are a plethora of works in the literature for third person video analysis. How-ever, third person videos are often recorded from point-and-shoot cameras, thus gener-ating small …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:WbkHhVStYXYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2023,"Minimally invasive surgeries and related applications demand surgical tool classification and segmentation at the instance level. Surgical tools are similar in appearance and are long, thin, and handled at an angle. The fine-tuning of state-of-the-art (SOTA) instance segmentation models trained on natural images for instrument segmentation has difficulty discriminating instrument classes. Our research demonstrates that while the bounding box and segmentation mask are often accurate, the classification head misclassifies the class label of the surgical instrument. We present a new neural network framework that adds a classification module as a new stage to existing instance segmentation models. This module specializes in improving the classification of instrument masks generated by the existing model. The module comprises multi-scale mask attention, which attends to the instrument region and masks the distracting background features. We propose training the proposed classifier module using metric learning with arc loss to handle low inter-class variance of surgical instruments. We conduct exhaustive experiments on the benchmark datasets EndoVis2017 and EndoVis2018. We demonstrate that our method outperforms all (more than 18) SOTA methods compared with and improves the\sota performance by at least 12 points (20%) on the EndoVis2017 benchmark challenge and generalizes effectively across the datasets. Project page with source code is available at nets-iitd. github. io/s3net.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:XiSMed-E-HIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2023,"We propose a novel deep neural network architecture to learn interpretable representation for medical image analysis. Our architecture generates a global attention for region of interest, and then learns bag of words style deep feature embeddings with local attention. The global, and local feature maps are combined using a contemporary transformer architecture for highly accurate Gallbladder Cancer (GBC) detection from Ultrasound (USG) images. Our experiments indicate that the detection accuracy of our model beats even human radiologists, and advocates its use as the second reader for GBC diagnosis. Bag of words embeddings allow our model to be probed for generating interpretable explanations for GBC detection consistent with the ones reported in medical literature. We show that the proposed model not only helps understand decisions of neural network models but also aids in discovery of new visual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:u9iWguZQMMsC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2023,"Monocular Depth Estimation (MDE) aims to predict pixel-wise depth given a single RGB image. For both, the convolutional as well as the recent attention-based models, encoder-decoder-based architectures have been found to be useful due to the simultaneous requirement of global context and pixel-level resolution. Typically, a skip connection module is used to fuse the encoder and decoder features, which comprises of feature map concatenation followed by a convolution operation. Inspired by the demonstrated benefits of attention in a multitude of computer vision problems, we propose an attention-based fusion of encoder and decoder features. We pose MDE as a pixel query refinement problem, where coarsest-level encoder features are used to initialize pixel-level queries, which are then refined to higher resolutions by the proposed Skip Attention Module (SAM). We formulate the prediction problem as ordinal regression over the bin centers that discretize the continuous depth range and introduce a Bin Center Predictor (BCP) module that predicts bins at the coarsest level using pixel queries. Apart from the benefit of image adaptive depth binning, the proposed design helps learn improved depth embedding in initial pixel queries via direct supervision from the ground truth. Extensive experiments on the two canonical datasets, NYUV2 and KITTI, show that our architecture outperforms the state-of-the-art by 5.3% and 3.9%, respectively, along with an improved generalization performance by 9.4% on the SUNRGBD dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:p2g8aNsByqUC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2023,"In Active Domain Adaptation (ADA), one uses Active Learning (AL) to select target domain frames to annotate for Domain Adaptation (DA). Thus, ADA creates a continuum of cost-performance trade-off models, with unsupervised, and fully supervised DA techniques at the two ends. We observe that in ADA not all regions of a selected frame contribute equally to a model's performance, and there is a strong correlation between annotating certain hard/unique/novel object/stuff instances, and a model's performance. Eg, road regions in a target dataset may look mostly similar to source domain except for certain curved instances, where annotation may be more useful. Based on the observation, we propose Anchor-based and Augmentation-based ADA techniques, which, given a selected frame, determine certain'hard'semantic regions to be annotated in that frame, such that the selected regions are complementary and diverse in the context of the current labeled set. The proposed techniques carefully avoid the pitfall of region based AL techniques which try to choose most uncertain regions in a frame, but ends up selecting all edge pixels, and similar annotation cost as the whole frame. We show that our approach achieves 66.6\miou on\gta->\cityscapes dataset with a budget of 4.7% in comparison to 64.9\miou by MADA [??]. Our technique can also be used as a decorator for any existing frame-based AL technique. Eg, we report 1.5% performance improvement for CDAL [??] on\cityscapes using our approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:OU6Ihb5iCvQC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2023,"Annotation is a crucial first step in the semantic segmentation of urban images that facilitates the development of autonomous navigation systems. However, annotating complex urban images is time-consuming and challenging. It requires significant human effort making it expensive and error-prone. To reduce human effort during annotation, multiple images need to be annotated in a short time-span. In this paper, we introduce ScribbleNet, an interactive image segmentation algorithm to address this issue. Our approach provides users with a pre-segmented image that iteratively improves the segmentation using scribble as an annotation input. This method is based on conditional inference and exploits the learnt correlations in a deep neural network (DNN). ScribbleNet can:(1) work with urban city scenes captured in unseen environments,(2) annotate new classes not present in the training set, and (3) correct …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:dshw04ExmUIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Procedure learning involves identifying the key-steps and determining their logical order to perform a task. Existing approaches commonly use third-person videos for learning the procedure, making the manipulated object small in appearance and often occluded by the actor, leading to significant errors. In contrast, we observe that videos obtained from first-person (egocentric) wearable cameras provide an unobstructed and clear view of the action. However, procedure learning from egocentric videos is challenging because (a) the camera view undergoes extreme changes due to the wearer’s head motion, and (b) the presence of unrelated frames due to the unconstrained nature of the videos. Due to this, current state-of-the-art methods’ assumptions that the actions occur at approximately the same time and are of the same duration, do not hold. Instead, we propose to use the signal provided by the temporal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:abG-DnoFyZgC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Computer vision systems for autonomous navigation must generalize well in adverse weather and illumination conditions expected in the real world. However, semantic segmentation of images captured in such conditions remains a challenging task for current state-of-the-art (SOTA) methods trained on broad daylight images, due to the associated distribution shift. On the other hand, domain adaptation techniques developed for the purpose rely on the availability of the source data, (un)labeled target data and/or its auxiliary information (e.g., GPS). Even then, they typically adapt to a single(specific) target domain(s). To remedy this, we propose a novel, fully test time, adaptation technique, named Master of ALL (MALL), for simultaneous generalization to multiple target domains. MALL learns to generalize on unseen adverse weather images from multiple target domains directly at the inference time. More specifically …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:nb7KW1ujOQ8C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Object detection plays an essential role in providing localization, path planning, and decision making capabilities in autonomous navigation systems. However, existing object detection models are trained and tested on a fixed number of known classes. This setting makes the object detection model difficult to generalize well in real-world road scenarios while encountering an unknown object. We address this problem by introducing our framework that handles the issue of unknown object detection and updates the model when unknown object labels are available. Next, our solution includes three major components that address the inherent problems present in the road scene datasets. The novel components are a) Feature-Mix that improves the unknown object detection by widening the gap between known and unknown classes in latent feature space, b) Focal regression loss handling the problem of improving …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:P5F9QuxV20EC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Attention-based models such as transformers have shown outstanding performance on dense prediction tasks, such as semantic segmentation, owing to their capability of capturing long-range dependency in an image. However, the benefit of transformers for monocular depth prediction has seldom been explored so far. This paper benchmarks var-ious transformer-based models for the depth estimation task on an indoor NYUV2 dataset and an outdoor KITTI dataset. We propose a novel attention-based architecture, Depthformer for monocular depth estimation that uses multi-head self-attention to produce the multiscale feature maps, which are effectively combined by our proposed de-coder network. We also propose a Transbins module that divides the depth range into bins whose center value is estimated adaptively per image. The final depth estimated is a linear combination of bin centers for each pixel. Trans …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:uWQEDVKXjbEC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Surgical simulators provide hands-on training and learning of the necessary psychomotor skills. Automated skill evaluation of the trainee doctors based on the video of a task being performed by them is an important key step for the optimal utilization of such simulators. However, current skill evaluation techniques require accurate tracking information of the instruments which restricts their applicability to robot assisted surgeries only. In this paper, we propose a novel neural network architecture that can perform skill evaluation using video data alone (and no tracking information). Given the small dataset available for training such a system, the network trained using ℓ 2 regression loss easily overfits the training data. We propose a novel rank loss to help learn robust representation, leading to 5% improvement for skill score prediction on the benchmark JIGSAWS dataset. To demonstrate the applicability of our method …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:KxtntwgDAa4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Rich temporal information and variations in viewpoints make video data an attractive choice for learning image representations using unsupervised contrastive learning (UCL) techniques. State-of-the-art (SOTA) contrastive learning techniques consider frames within a video as positives in the embedding space, whereas the frames from other videos are considered negatives. We observe that unlike multiple views of an object in natural scene videos, an Ultrasound (US) video captures different 2D slices of an organ. Hence, there is almost no similarity between the temporally distant frames of even the same US video. In this paper we propose to instead utilize such frames as hard negatives. We advocate mining both intra-video and cross-video negatives in a hardness-sensitive negative mining curriculum in a UCL framework to learn rich image representations. We deploy our framework to learn the representations …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:xtRiw3GOFMkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"A system and method for generating an optimized image with scribble-based interactive image segmentation model using a machine learning are provided. The method includes,(i) segmenting, using a machine learning model, an image to classify into classes each class is represented with a label,(ii) displaying the classified image which specifies the classes on the classified image with outlines,(iii) enabling a user to scribble on the classified image to annotate the classes if an area is not classified,(iv) assigning a color mask for each scribbled area,(v) computing, using the machine learning model, a loss function for a location of pixels based on color mask,(vi) modifying pre-defined weights for each scribbled area to match the annotated image and a determined class on the classified image, and (vii) generating the optimized image if the annotated image is matched with the determined class on the classified image.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:UxriW0iASnsC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:bFI3QPDXJZMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"A system and method generating an optimized medical image using a machine learning model are provided. The method includes (i) receiving one or more medical images,(ii) segmenting to generate a transformed medical image for detecting a plurality of target elements,(iii) displaying the transformed medical image,(iv) receiving markings and scribblings associated with scribble locations from a user,(v) identifying errors associated with an outline of a target element,(vi) computing a loss function for a location of pixels where the target element is located on the transformed medical image,(vii) modifying the pre-defined weights (w) to match the segmentation output and the determined target element,(viii) determining whether the segmentation output is matched with the target element and (ix) generating the optimized medical image if the segmentation output is matched with the determined target element.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:NhqRSupF_l8C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"BACKGROUND
Performing ultrasound during the current pandemic time is quite challenging. To reduce the chances of cross-infection and keep healthcare workers safe, a robotic ultrasound system was developed, which can be controlled remotely. It will also pave way for broadening the reach of ultrasound in remote distant rural areas as well.
AIM
To assess the feasibility of a robotic system in performing abdominal ultrasound and compare it with the conventional ultrasound system.
METHODS
A total of 21 healthy volunteers were recruited. Ultrasound was performed in two settings, using the robotic arm and conventional hand-held procedure. Images acquired were analyzed by separate radiologists.
RESULTS
Our study showed that the robotic arm model was feasible, and the results varied based on the organ imaged. The liver images showed no significant difference. For other organs, the need for repeat imaging was higher in the robotic arm, which could be attributed to the radiologist’s learning curve and ability to control the haptic device. The doctor and volunteer surveys also showed significant comfort with acceptance of the technology and they expressed their desire to use it in the future.
CONCLUSION
This study shows that robotic ultrasound is feasible and is the need of the hour during the pandemic.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:b0M2c_1WBrUC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Attention-based models such as transformers have shown outstanding performance on dense prediction tasks, such as semantic segmentation, owing to their capability of capturing long-range dependency in an image. However, the benefit of transformers for monocular depth prediction has seldom been explored so far. This paper benchmarks various transformer-based models for the depth estimation task on an indoor NYUV2 dataset and an outdoor KITTI dataset. We propose a novel attention-based architecture, Depthformer for monocular depth estimation that uses multi-head self-attention to produce the multiscale feature maps, which are effectively combined by our proposed decoder network. We also propose a Transbins module that divides the depth range into bins whose center value is estimated adaptively per image. The final depth estimated is a linear combination of bin centers for each pixel. Transbins module takes advantage of the global receptive field using the transformer module in the encoding stage. Experimental results on NYUV2 and KITTI depth estimation benchmark demonstrate that our proposed method improves the state-of-the-art by 3.3%, and 3.3% respectively in terms of Root Mean Squared Error (RMSE).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:EUQCXRtRnyEC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"While detection of malignancies on mammography has received a boost with the use of Convolutional Neural Networks (CNN), detection of cancers of very small size remains challenging. This is however clinically significant as the purpose of mammography is early detection of cancer, making it imperative to pick them up when they are still very small. Mammography has the highest spatial resolution (image sizes as high as 3328 × 4096 pixels) out of all imaging modalities, a requirement that stems from the need to detect fine features of the smallest cancers on screening. However due to computational constraints, most state of the art CNNs work on reduced resolution images. Those that work on higher resolutions, compromise on global context and work at single scale. In this work, we show that resolution, scale and image-context are all important independent factors in detection of small masses. We thereby use …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:_xSYboBqXhAC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Initiation, monitoring, and evaluation of development programmes can involve field-based data collection about project activities. This data collection through digital devices may not always be feasible though, for reasons such as unaffordability of smartphones and tablets by field-based cadre, or shortfalls in their training and capacity building. Paper-based data collection has been argued to be more appropriate in several contexts, with automated digitization of the paper forms through OCR (Optical Character Recognition) and OMR (Optical Mark Recognition) techniques. We contribute with providing a large dataset of handwritten digits, and deep learning based models and methods built using this data, that are effective in real-world environments. We demonstrate the deployment of these tools in the context of a maternal and child health and nutrition awareness project, which uses IVR (Interactive Voice …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:D03iK_w7-QYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"With the rapid integration of artificial intelligence (AI) into medical practice, there has been an exponential increase in the number of scientific papers and industry players offering models designed for various tasks. Understanding these, however, is difficult for a radiologist in practice, given the core mathematical principles and complicated terminology involved. This review aims to elucidate the core mathematical concepts of both machine learning and deep learning models, explaining the various steps and common terminology in common layman language. Thus, by the end of this article, the reader should be able to understand the basics of how prediction models are built and trained, including challenges faced and how to avoid them. The reader would also be equipped to adequately evaluate various models, and take a decision on whether a model is likely to perform adequately in the real-world setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:dfsIfKJdRG4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"A large proportion of videos captured today are first per-son videos shot from wearable cameras. Similar to other computer vision tasks, Deep Neural Networks (DNNs) are the workhorse for most state-of-the-art (SOTA) egocentric vision techniques. On the other hand DNNs are known to be susceptible to Adversarial Attacks (AAs) which add im-perceptible noise to the input. Both black-box, as well as white-box attacks on image as well as video analysis tasks have been shown. We observe that most AA techniques basically add intensity perturbation to an image. Even for videos, the same process is essentially repeated for each frame independently. We note that the definition of imperceptibility used for images may not be applicable for videos, where a small intensity change happening randomly in two consecutive frames may still be perceptible. In this paper we make a key novel suggestion to use perturbation in optical flow to carry out AAs on a video analysis system. Such perturbation is especially useful for egocentric videos, because there is a lot of shake in the egocentric videos anyways, and adding a little more, keeps it highly imperceptible. In general, our idea can be seen as adding structured, para-metric noise as the adversarial perturbation. Our implementation of the idea by adding 3D rotations to the frames reveal that using our technique, one can mount a black-box AA on an egocentric activity detection system in one-third of the queries compared to the SOTA AA technique.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:cFHS6HbyZ2cC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"We explore the potential of CNN-based models for gallbladder cancer (GBC) detection from ultrasound (USG) images as no prior study is known. USG is the most common diagnostic modality for GB diseases due to its low cost and accessibility. However, USG images are challenging to analyze due to low image quality, noise, and varying viewpoints due to the handheld nature of the sensor. Our exhaustive study of state-of-the-art (SOTA) image classification techniques for the problem reveals that they often fail to learn the salient GB region due to the presence of shadows in the USG images. SOTA object detection techniques also achieve low accuracy because of spurious textures due to noise or adjacent organs. We propose GBCNet to tackle the challenges in our problem. GBCNet first extracts the regions of interest (ROIs) by detecting the GB (and not the cancer), and then uses a new multi-scale, second-order pooling architecture specializing in classifying GBC. To effectively handle spurious textures, we propose a curriculum inspired by human visual acuity, which reduces the texture biases in GBCNet. Experimental results demonstrate that GBCNet significantly outperforms SOTA CNN models, as well as the expert radiologists. Our technical innovations are generic to other USG image analysis tasks as well. Hence, as a validation, we also show the efficacy of GBCNet in detecting breast cancer from USG images. Project page with source code, trained models, and data is available at https://gbc-iitd. github. io/gbcnet.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:4OULZ7Gr8RgC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Deep Neural Networks (DNNs) are known to make overconfident mistakes, which makes their use problematic in safety-critical applications. State-of-the-art (SOTA) calibration techniques improve on the confidence of predicted labels alone, and leave the confidence of non-max classes (eg top-2, top-5) uncalibrated. Such calibration is not suitable for label refinement using post-processing. Further, most SOTA techniques learn a few hyper-parameters post-hoc, leaving out the scope for image, or pixel specific calibration. This makes them unsuitable for calibration under domain shift, or for dense prediction tasks like semantic segmentation. In this paper, we argue for intervening at the train time itself, so as to directly produce calibrated DNN models. We propose a novel auxiliary loss function: Multi-class Difference in Confidence and Accuracy (MDCA), to achieve the same. MDCA can be used in conjunction with other application/task specific loss functions. We show that training with MDCA leads to better calibrated models in terms of Expected Calibration Error (ECE), and Static Calibration Error (SCE) on image classification, and segmentation tasks. We report ECE (SCE) score of 0.72 (1.60) on the CIFAR100 dataset, in comparison to 1.90 (1.71) by the SOTA. Under domain shift, a ResNet-18 model trained on PACS dataset using MDCA gives a average ECE (SCE) score of 19.7 (9.7) across all domains, compared to 24.2 (11.8) by the SOTA. For segmentation task, we report a 2x reduction in calibration error on PASCAL-VOC dataset in comparison to Focal Loss. Finally, MDCA training improves calibration even on imbalanced data, and for natural …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:u_35RYKgDlwC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Self-supervised methods have shown promising results in denoising and dehazing tasks, where the collection of the paired dataset is challenging and expensive. However, we find that these methods fail to remove the rain streaks when applied for image deraining tasks. The method's poor performance is due to the explicit assumptions:(i) the distribution of noise or haze is uniform and (ii) the value of a noisy or hazy pixel is independent of its neighbors. The rainy pixels are non-uniformly distributed, and it is not necessarily dependant on its neighboring pixels. Hence, we conclude that the self-supervised method needs to have some prior knowledge about rain distribution to perform the deraining task. To provide this knowledge, we hypothesize a network trained with minimal supervision to estimate the likelihood of rainy pixels. This leads us to our proposed method called FLUID: Few Shot Self-Supervised Image Deraining. We perform extensive experiments and comparisons with existing image deraining and few-shot image-to-image translation methods on Rain 100L and DDN-SIRR datasets containing real and synthetic rainy images. In addition, we use the Rainy Cityscapes dataset to show that our method trained in a few-shot setting can improve semantic segmentation and object detection in rainy conditions. Our approach obtains a mIoU gain of 51.20 over the current best-performing deraining method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:zA6iFVUQeVQC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Few-Shot Object Detectors (FSOD) are tasked to localize and classify objects in an image given only a few data samples. Recent trends in FSOD research show the adoption of metric and meta-learning techniques, which are prone to catastrophic forgetting and class confusion. To overcome these pitfalls in metric learning based FSOD techniques, we introduce an Attention Guided Cosine Margin (AGCM) that facilitates the creation of tighter and well separated class-specific feature clusters in the classification head of the object detector. The Attentive Proposal Fusion (APF) module introduced in AGCM minimizes catastrophic forgetting by reducing the intra-class variance among co-occurring classes. At the same time, the Cosine Margin penalty in AGCM increases the angular margin between confusing classes to overcome the challenge of class confusion between already learned (base) and newly added (novel) classes. We conduct our experiments on the India Driving Dataset (IDD), which presents a real-world class-imbalanced setting alongside popular FSOD benchmark PASCAL-VOC. Our method outperforms existing approaches by up to 6.4 mAP points on the IDD-OS and up to 2.0 mAP points on the IDD-10 splits for the 10-shot setting. On the PASCAL-VOC dataset, we outperform existing approaches by up to 4.9 mAP points.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:g5m5HwL7SMYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Advancements in adaptive object detection can lead to tremendous improvements in applications like autonomous navigation, as they alleviate the distributional shifts along the detection pipeline. Prior works adopt adversarial learning to align image features at global and local levels, yet the instance-specific misalignment persists. Also, adaptive object detection remains challenging due to visual diversity in background scenes and intricate combinations of objects. Motivated by structural importance, we aim to attend prominent instance-specific regions, overcoming the feature misalignment issue. We propose a novel resIduaL seLf-attentive featUre alignMEnt (ILLUME) method for adaptive object detection. ILLUME comprises Self-Attention Feature Map (SAFM) module that enhances structural attention to object-related regions and thereby generates domain invariant features. Our approach significantly reduces the domain distance with the improved feature alignment of the instances. Qualitative results demonstrate the ability of ILLUME to attend important object instances required for alignment. Experimental results on several benchmark datasets show that our method outperforms the existing state-of-the-art approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:2P1L_qKh6hAC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Contextual information is a valuable cue for Deep Neural Networks (DNNs) to learn better representations and improve accuracy. However, co-occurrence bias in the training dataset may hamper a DNN model's generalizability to unseen scenarios in the real world. For example, in COCO [??], many object categories have a much higher co-occurrence with men compared to women, which can bias a DNN's prediction in favor of men. Recent works have focused on task-specific training strategies to handle bias in such scenarios, but fixing the available data is often ignored. In this paper, we propose a novel and more generic solution to address the contextual bias in the datasets by selecting a subset of the samples, which is fair in terms of the co-occurrence with various classes for a protected attribute. We introduce a data repair algorithm using the coefficient of variation (c_v), which can curate fair and contextually balanced data for a protected class (es). This helps in training a fair model irrespective of the task, architecture or training methodology. Our proposed solution is simple, effective and can even be used in an active learning setting where the data labels are not present or being generated incrementally. We demonstrate the effectiveness of our algorithm for the task of object detection and multi-label image classification across different datasets. Through a series of experiments, we validate that curating contextually fair data helps make model predictions fair by balancing the true positive rate for the protected class across groups without compromising on the model's overall performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:RYcK_YlVTxYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2022,"Recent efforts in multi-domain learning for semantic segmentation attempt to learn multiple geographical datasets in a universal, joint model. A simple fine-tuning experiment performed sequentially on three popular road scene segmentation datasets demonstrates that existing segmentation frameworks fail at incrementally learning on a series of visually disparate geographical domains. When learning a new domain, the model catastrophically forgets previously learned knowledge. In this work, we pose the problem of multi-domain incremental learning for semantic segmentation. Given a model trained on a particular geographical domain, the goal is to (i) incrementally learn a new geographical domain,(ii) while retaining performance on the old domain,(iii) given that the previous domain's dataset is not accessible. We propose a dynamic architecture that assigns universally shared, domain-invariant parameters to capture homogeneous semantic features present in all domains, while dedicated domain-specific parameters learn the statistics of each domain. Our novel optimization strategy helps achieve a good balance between retention of old knowledge (stability) and acquiring new knowledge (plasticity). We demonstrate the effectiveness of our proposed solution on domain incremental settings pertaining to real-world driving scenes from roads of Germany (Cityscapes), the United States (BDD100k), and India (IDD).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:NaGl4SEjCO4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:3s1wT3WcHBgC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"Few-shot object detection (FSOD) localizes and classifies objects in an image given only a few data samples. Recent trends in FSOD research show the adoption of metric and meta-learning techniques, which are prone to catastrophic forgetting and class confusion. To overcome these pitfalls in metric learning based FSOD techniques, we introduce Attention Guided Cosine Margin (AGCM) that facilitates the creation of tighter and well separated class-specific feature clusters in the classification head of the object detector. Our novel Attentive Proposal Fusion (APF) module minimizes catastrophic forgetting by reducing the intra-class variance among co-occurring classes. At the same time, the proposed Cosine Margin Cross-Entropy loss increases the angular margin between confusing classes to overcome the challenge of class confusion between already learned (base) and newly added (novel) classes. We conduct our experiments on the challenging India Driving Dataset (IDD), which presents a real-world class-imbalanced setting alongside popular FSOD benchmark PASCAL-VOC. Our method outperforms State-of-the-Art (SoTA) approaches by up to 6.4 mAP points on the IDD-OS and up to 2.0 mAP points on the IDD-10 splits for the 10-shot setting. On the PASCAL-VOC dataset, we outperform existing SoTA approaches by up to 4.9 mAP points.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:pyW8ca7W8N0C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"Video object detection is the task of detecting objects in a sequence of frames, typically, with a significant overlap in content among consecutive frames. Mean Average Precision (mAP) was originally proposed for evaluating object detection techniques in independent frames, but has been used for evaluating video based object detectors as well. This is undesirable since the average precision over all frames masks the biases that a certain object detector might have against certain types of objects depending on the number of frames for which the object is present in a video sequence. In this paper we show several disadvantages of mAP as a metric for evaluating video based object detection. Specifically, we show that: (a) some object detectors could be severely biased against some specific kind of objects, such as small, blurred, or low contrast objects, and such differences may not reflect in mAP based evaluation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:vV6vV6tmYwMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"Manipulators are helpful in performing various hazardous tasks like sanitization with chemicals in germs infected areas, spraying pesticides in fields, pick and place of heavy and hazardous materials where direct human intervention is difficult. For manipulators to perform its assigned task accurately, prior estimation of its pose needs to be pinpointed. End-effector grasping and arm manipulation require estimation of 3D object poses. Recently, a number of procedures and databases for vision-based estimation of object pose have been advised. However, it is not clear about the performance of the developed algorithms for visual pose estimation of robot manipulation. In this paper we present the pose estimation of a 5-dof PhantomX Reactor Arm using On-Body/Aruco Markers. Forward and inverse kinematics were used to estimate the pose from the position coordinates calculated using computer vision techniques …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:HoB7MX3m0LUC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"The popularity of egocentric cameras and their always-on nature has lead to the abundance of day long first-person videos. The highly redundant nature of these videos and extreme camera-shakes make them difficult to watch from beginning to end. These videos require efficient summarization tools for consumption. However, traditional summarization techniques developed for static surveillance videos or highly curated sports videos and movies are either not suitable or simply do not scale for such hours long videos in the wild. On the other hand, specialized summarization techniques developed for egocentric videos limit their focus to important objects and people. This paper presents a novel unsupervised reinforcement learning framework to summarize egocentric videos both in terms of length and the content. The proposed framework facilitates incorporating various prior preferences such as faces, places, or …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:lSLTfruPkqcC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"Backdoor attacks embed a hidden functionality into deep neural networks, causing the network to display anomalous behavior when activated by a predetermined pattern in the input (Trigger), while behaving well otherwise on public test data. Recent works have shown that backdoored face recognition (FR) systems can respond to natural-looking triggers like a particular pair of sunglasses. Such attacks pose a serious threat to the applicability of FR systems in high-security applications. We propose a novel technique to (1) detect whether an FR network is compromised with a natural, physically realizable trigger, and (2) identify such triggers given a compromised network. We demonstrate the effectiveness of our methods with a compromised FR network, where we are able to identify the trigger (e.g. green-sunglasses or redbowtie) with a top-5 accuracy of 74%, whereas a naïve brute force baseline achieves 56 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:35N4QoGY0k4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"Objectives
To study whether a trained convolutional neural network (CNN) can be of assistance to radiologists in differentiating Coronavirus disease (COVID)–positive from COVID-negative patients using chest X-ray (CXR) through an ambispective clinical study. To identify subgroups of patients where artificial intelligence (AI) can be of particular value and analyse what imaging features may have contributed to the performance of AI by means of visualisation techniques.
Methods
CXR of 487 patients were classified into [4] categories—normal, classical COVID, indeterminate, and non-COVID by consensus opinion of 2 radiologists. CXR which were classified as “normal” and “indeterminate” were then subjected to analysis by AI, and final categorisation provided as guided by prediction of the network. Precision and recall of the radiologist alone and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:RGFaLdJalmkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"During the COVID-19 pandemic, the lives of healthcare professionals are at significant threat because of the enormous workload and cross-infection risk. Ultrasound (US) imaging plays a vital role in the diagnosis and follow-up of COVID-19 patients; however, it requires a close-physical contact by the sonographer. In this context, this paper presents a Telerobotic Ultrasound (TR-US) system for complete remote control of the US probe, thereby preventing direct physical contact between patients and sonographers. The system consists of a 6-DOF robot arm at the remote site and a haptic device at the doctor’s site. The control architecture precisely transmits the intended position and orientation of the US probe to the remote location for transversal and sagittal plane scanning. This architecture, when integrated with an admittance controller-based force modulation and feedback transmission, enables the radiologists to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:yD5IFk8b50cC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"Scene Text Recognition (STR) refers to the task of recognition of text in natural scenes. The success of OCR models is hard to achieve on natural scene images due to a variety of challenges, including - variation in orientation and pixel intensities in images, low resolution and errors in bounding box detection, as well as variation in fonts and shapes of print of characters. Our main objective is to obtain a model that achieves near State of the Art performance out custom MAVI dataset, which will allow it to be used in the real world application of assisting a visually impaired person to read signboards in order to obtain directions. We provide an end-to-end detection and recognition system for the same. Problems arise when the distribution of data seen during test time differs from the training data. The model cannot make reliable predictions in such a scenario. We perform experiments to demonstrate how the model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:fPk4N6BV_jEC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"Object detection is a key component in autonomous navigation systems that enables localization and classification of the objects in a road scene. Existing object detection methods are trained and inferred on a fixed number of known classes present in road scenes. However, in real-world or open-world road scenes, while inference, we come across unknown objects that the detection model hasn’t seen while training. Hence, we propose Open World Object Detection on Road Scenes (ORDER) to address the aforementioned problem for road scenes. Firstly, we introduce Feature-Mix to improve the unknown object detection capabilities of an object detector. Feature-Mix widens the gap between known and unknown classes in latent feature space that helps improve the unknown object detection. Next, we identify that the road scene dataset compared to generic object dataset contains a significant proportion of small objects and has higher intra-class bounding box scale variations, making it challenging to detect the known and unknown objects. We propose a novel loss: Focal regression loss that collectively addresses the problem of small object detection and intra-class bounding box by penalizing more the small bounding boxes and dynamically changing the loss according to object size. Further, the detection of small objects is improved by curriculum learning. Finally, we present an extensive evaluation on two road scene datasets: BDD and IDD. Our experimental evaluations on BDD and IDD shows consistent improvement over the current state-of-the-art method. We believe that this work will lay the foundation for real-world object detection for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:pqnbT2bcN3wC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"Semantic segmentation of medical images is an essential first step in computer-aided diagnosis systems for many applications. However, given many disparate imaging modalities and inherent variations in the patient data, it is difficult to consistently achieve high accuracy using modern deep neural networks (DNNs). This has led researchers to propose interactive image segmentation techniques where a medical expert can interactively correct the output of a DNN to the desired accuracy. However, these techniques often need separate training data with the associated human interactions, and do not generalize to various diseases, and types of medical images. In this paper, we suggest a novel conditional inference technique for DNNs which takes the intervention by a medical expert as test time constraints and performs inference conditioned upon these constraints. Our technique is generic can be used …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:70eg2SAEIzsC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2021,"In egocentric videos, the face of a wearer capturing the video is never captured. This gives a false sense of security that the wearer's privacy is preserved while sharing such videos. However, egocentric cameras are typically harnessed to wearer's head, and hence, also capture wearer's gait. Recent works have shown that wearer gait signatures can be extracted from egocentric videos, which can be used to determine if two egocentric videos have the same wearer. In a more damaging scenario, one can even recognize a wearer using hand gestures from egocentric videos, or identify a wearer in third person videos such as from a surveillance camera. We believe, this could be a death knell in sharing of egocentric videos, and fatal for egocentric vision research. In this work, we suggest a novel technique to anonymize egocentric videos, which create carefully crafted, but small, and imperceptible optical flow perturbations in an egocentric video's frames. Importantly, these perturbations do not affect object detection or action/activity recognition from egocentric videos but are strong enough to dis-balance the gait recovery process. In our experiments on benchmark\epic dataset, the proposed perturbation degrades the wearer recognition performance of [??], from 66.3% to 13.4%, while preserving the activity recognition performance of [??] from 89.6% to 87.4%. To test our anonymization with more wearer recognition techniques, we also developed a stronger, and more generalizable wearer recognition method based on camera egomotion cues. The approach achieves state-of-the-art (SOTA) performance of 59.67% on\epicns, compared to 55.06% by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:J_g5lzvAfSwC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2020,"Wearable egocentric cameras are typically harnessed to a wearer's head, giving them the unique advantage of capturing their points of view. Hoshen and Peleg have shown that egocentric cameras indirectly capture the wearer's gait, which can be used to identify a wearer based on their egocentric videos. The authors have shown a wearer recognition accuracy of up to 77% over 32 subjects. However, an important limitation of their work is that such gait features can be extracted only from walking sequences of a wearer. In this work, we take the privacy threat a notch higher and show that even the wearer's hand gestures, as seen through an egocentric video, leak wearer's identity. We have designed a model to extract and match hand gesture signatures from egocentric videos. We demonstrate the threat on the EPIC kitchen dataset containing 55 hours of the egocentric videos acquired from 32 subjects doing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:O3NaXMp0MMsC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2020,"The long and unconstrained nature of egocentric videos makes it imperative to use temporal segmentation as an important pre-processing step for many higher-level inference tasks. Activities of the wearer in an egocentric video typically span over hours and are often separated by slow, gradual changes. Furthermore, the change of camera viewpoint due to the wearer's head motion causes frequent and extreme, but, spurious scene changes. The continuous nature of boundaries makes it difficult to apply traditional Markov Random Field (MRF) pipelines relying on temporal discontinuity, whereas deep Long Short Term Memory (LSTM) networks gather context only upto a few hundred frames, rendering them ineffective for egocentric videos. In this paper, we present a novel unsupervised temporal segmentation technique especially suited for day-long egocentric videos. We formulate the problem as detecting concept …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:BqipwSGYUEgC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2020,"Requirement of large annotated datasets restrict the use of deep convolutional neural networks (CNNs) for many practical applications. The problem can be mitigated by using active learning (AL) techniques which, under a given annotation budget, allow to select a subset of data that yields maximum accuracy upon fine tuning. State of the art AL approaches typically rely on measures of visual diversity or prediction uncertainty, which are unable to effectively capture the variations in spatial context. On the other hand, modern CNN architectures make heavy use of spatial context for achieving highly accurate predictions. Since the context is difficult to evaluate in the absence of ground-truth labels, we introduce the notion of contextual diversity that captures the confusion associated with spatially co-occurring classes. Contextual Diversity (CD) hinges on a crucial observation that the probability vector predicted …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:M05iB0D1s5AC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2020,"Easy availability of wearable egocentric cameras, and the sense of privacy propagated by the fact that the wearer is never seen in the captured videos, has led to a tremendous rise in public sharing of such videos. Unlike hand-held cameras, egocentric cameras are harnessed on the wearer’s head, which makes it possible to track the wearer’s head motion by observing optical flow in the egocentric videos. In this work, we create a novel kind of privacy attack by extracting the wearer’s gait profile, a well known biometric signature, from such optical flow in the egocentric videos. We demonstrate strong wearer recognition capabilities based on extracted gait features, an unprecedented and critical weakness completely absent in hand-held videos. We demonstrate the following attack scenarios: (1) In a closed-set scenario, we show that it is possible to recognize the wearer of an egocentric video with an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:YFjsv_pBGBYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2020,"Many computer vision problems can be formulated as finding the best labeling configuration. If labelings satisfy Markov property then finding best labeling configuration becomes MRF (Markov Random Field)- MAP (Maximum A Priori Posteriori) inference problem. Which is the minimization of cost of assigning labels to individual pixels and cost of assigning labelings to a collection of pixels (cliques). If we assume clique costs (or clique potentials) to be submodular then MRF-MAP inference becomes minimization of sum of submodular functions and can be done in polynomial time. Standard way to minimize a submodular function is by minimizing an equivalent dual objective defined on submodular polyhendron. As the first part of thesis in chapter 3, we develop an efficient inference algorithm for 2 label MRF-MAP problem named SoS-MNP. We show that the dual problem can be decomposed over cliques which enables the efficient optimization of dual in block co-ordinate descent (BCD) style. In our experiments we look at the image segmentation problem with clique size as large as 1000. We show that SoSMNP is very efficient and scalable to large cliques as compared to state of the art methods which scales only upto clique size of 16. In the second part of thesis in chapter 4, we develop the inference algorithm for 2-label MRF-MAP problem with a mix of small and large cliques. In such a configuration there are large number of small cliques which makes BCD style SoSMNP to be very slow. On the other hand there are other state of the art methods like Generic Cuts (GC) which run very fast for the problems with large number of small cliques but do …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:ns9cj8rnVeAC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2020,"Background
Minimally invasive neurosurgical approaches reduce patient morbidity by providing the surgeon with better visualization and access to complex lesions, with minimal disruption to normal anatomy. The use of rigid or flexible neuroendoscopes, supplemented with a conventional stereoscopic operating microscope, has been integral to the adoption of these techniques. Neurosurgeons commonly use neuroendoscopes to perform the ventricular and endonasal approaches. It is challenging to learn neuroendoscopy skills from the existing apprenticeship model of surgical education. The training methods, which use simulation-based systems, have achieved wide acceptance. Physical simulators provide anatomic orientation and hands-on experience with repeatability. Our aim is to review the existing physical simulators on the basis of the skills training of neuroendoscopic procedures.
Methods
We searched …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:k_IJM867U9cC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2020,"The exponential increase in COVID-19 patients is overwhelming healthcare systems across the world. With limited testing kits, it is impossible for every patient with respiratory illness to be tested using conventional techniques (RT-PCR). The tests also have long turn-around time, and limited sensitivity. Detecting possible COVID-19 infections on Chest X-Ray may help quarantine high risk patients while test results are awaited. X-Ray machines are already available in most healthcare systems, and with most modern X-Ray systems already digitized, there is no transportation time involved for the samples either. In this work we propose the use of chest X-Ray to prioritize the selection of patients for further RT-PCR testing. This may be useful in an inpatient setting where the present systems are struggling to decide whether to keep the patient in the ward along with other patients or isolate them in COVID-19 areas. It would also help in identifying patients with high likelihood of COVID with a false negative RT-PCR who would need repeat testing. Further, we propose the use of modern AI techniques to detect the COVID-19 patients using X-Ray images in an automated manner, particularly in settings where radiologists are not available, and help make the proposed testing technology scalable. We present CovidAID: COVID-19 AI Detector, a novel deep neural network based model to triage patients for appropriate testing. On the publicly available covid-chestxray-dataset [2], our model gives 90.5% accuracy with 100% sensitivity (recall) for the COVID-19 infection. We significantly improve upon the results of Covid-Net [10] on the same dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:maZDTaKrznsC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2020,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:GnPB-g6toBAC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2020,"In this paper, we propose an algorithm for optimal solutions to submodular higher order multi-label MRF-MAP energy functions which can handle practical computer vision problems with up to 16 labels and cliques of size 100. The algorithm uses a transformation which transforms a multi-label problem to a 2-label problem on a much larger clique. Earlier algorithms based on this transformation could not handle problems larger than 16 labels on cliques of size 4. The proposed algorithm optimizes the resultant 2-label problem using the submodular polyhedron based Min Norm Point algorithm. The task is challenging because the state space of the transformed problem has a very large number of invalid states. For polyhedral based algorithms the presence of invalid states poses a challenge as apart from numerical instability, the transformation also increases the dimension of the polyhedral space making the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:NMxIlDl6LWMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2019,"The popularity of egocentric cameras and their always-on nature has lead to the abundance of day-long first-person videos. Because of the extreme shake and highly redundant nature, these videos are difficult to watch from beginning to end and often require summarization tools for their efficient consumption. However, traditional summarization techniques developed for static surveillance videos, or highly curated sports videos and movies are, either, not suitable or simply do not scale for such hours long videos in the wild. On the other hand, specialized summarization techniques developed for egocentric videos limit their focus to important objects and people. In this paper, we present a novel unsupervised reinforcement learning technique to generate video summaries from day long egocentric videos. Our approach can be adapted to generate summaries of various lengths making it possible to view even 1 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:RHpTSmoSYBkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2019,"With the improvement in technology, both the cost and the power requirement of cameras, as well as other sensors have come down significantly. It has allowed these sensors to be integrated into portable as well as wearable systems. Such systems are usually operated in a hands-free and always-on manner where they need to function continuously in a variety of scenarios. In such situations, relying on a single sensor or a fixed sensor combination can be detrimental to both performance as well as energy requirements. Consider the case of an obstacle detection task. Here using an RGB camera helps in recognizing the obstacle type but takes much more energy than an ultrasonic sensor. Infrared cameras can perform better than RGB camera at night but consume twice the energy. Therefore, an efficient system must use a combination of sensors, with an adaptive control that ensures the use of the sensors …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:4JMBOYKVnBMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2019,"Gait recognition is a non-invasive biometric technology that can be used to identify humans in surveillance systems. It is based on the style or manner in which a person walk and can be realized with minimal amount of individual cooperation for its acquisition. However, it may causes many challenges in the form of varying viewpoints, carrying conditions and clothing variations. To tackle such limitations, we present a view-invariant gait recognition network that divide the gait cycle into five segments (GCS). The intra gait-cycle-segment (GCS) convolutional spatio-temporal relationships has been obtained by employing a 3D-CNN via. transfer learning mechanism. Later, a stacked LSTM has been trained over spatio-temporal features to learn the long and short relationship between inter gait-cycle-segment.
The first step in our work is data pre-processing, in which we create silhouette stereo map (SSM) from the binary …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:_Qo2XoVZTnwC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:r0BpntZqJG4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2019,"A method and a system for generating adaptive fast forward of egocentric videos are provided here. The method may include the following steps: obtaining a video footage containing a sequence of image frames captured by a non-stationary capturing device; estimating a moving direction of the non-stationary capturing device for a plurality of frames in the sequence of image frames; and generating a shortened video footage having fewer frames than said video footage, by sampling the sequence of image frames, wherein the sampling is carried out by selecting specific image frames and that minimize an overall cost associated with a deviation from a specific direction related to the moving direction, calculated for each of said plurality of image frames.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:qUcmZB5y_30C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2019,"Regardless of the tremendous progress, a truly general purpose pipeline for Simultaneous Localization and Mapping (SLAM) remains a challenge. We investigate the reported failure of state of the art (SOTA) SLAM techniques on egocentric videos. We find that the dominant 3D rotations, low parallax between successive frames, and primarily forward motion in egocentric videos are the most common causes of failures. The incremental nature of SOTA SLAM, in the presence of unreliable pose and 3D estimates in egocentric videos, with no opportunities for global loop closures, generates drifts and leads to the eventual failures of such techniques. Taking inspiration from batch mode Structure from Motion (SFM) techniques, we propose to solve SLAM as an SFM problem over the sliding temporal windows. This makes the problem well constrained. Further, we propose to initialize the camera poses using 2D rotation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:TQgYirikUcIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2019,"Independent mobility of visually impaired people is key to making an inclusive society for them. Unstructured infrastructure in developing countries pose significant challenges in developing aids to address the mobility problem of visually impaired. Most of the assistive devices available internationally assume a structured and controlled environment severely restricting the applicability of such devices. In this paper, we assess the ability of state-of-the-art assistive devices for addressing the independent outdoor mobility needs of the visually impaired in an unstructured environment. We have created realistic datasets for various scenarios and evaluate deep neural networks for object detection on these datasets. We also present a portable prototype for the task. Further, we have also developed a cloud based solution to address the mobility requirements. We compare the local device based and cloud based solutions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:e5wmG9Sq2KIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Auxiliary information can be exploited in machine learning models using the paradigm of evidence based conditional inference. Multi-modal techniques in Deep Neural Networks (DNNs) can be seen as perturbing the latent feature representation for incorporating evidence from the auxiliary modality. However, they require training a specialized network which can map sparse evidence to a high dimensional latent space vector. Designing such a network, as well as collecting jointly labeled data for training is a non-trivial task. In this paper, we present a novel multi-task learning (MTL) based framework to perform evidence based conditional inference in DNNs which can overcome both these shortcomings. Our framework incorporates evidence as the output of secondary task(s), while modeling the original problem as the primary task of interest. During inference, we employ a novel Bayesian formulation to change the joint latent feature representation so as to maximize the probability of the observed evidence. Since our approach models evidence as prediction from a DNN, this can often be achieved using standard pre-trained backbones for popular tasks, eliminating the need for training altogether. Even when training is required, our MTL architecture ensures the same can be done without any need for jointly labeled data. Exploiting evidence using our framework, we show an improvement of 3.9% over the state-of-the-art, for predicting semantic segmentation given the image tags, and 2.8% for predicting instance segmentation given image captions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:JV2RwH3_ST0C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Auxiliary information can be exploited in machine learning models using the paradigm of evidence based conditional inference. Multi-modal techniques in Deep Neural Networks (DNNs) can be seen as perturbing the latent feature representation for incorporating evidence from the auxiliary modality. However, they require training a specialized network which can map sparse evidence to a high dimensional latent space vector. Designing such a network, as well as collecting jointly labeled data for training is a non-trivial task. In this paper, we present a novel multi-task learning (MTL) based framework to perform evidence based conditional inference in DNNs which can overcome both these shortcomings. Our framework incorporates evidence as the output of secondary task(s), while modeling the original problem as the primary task of interest. During inference, we employ a novel Bayesian formulation to change the joint latent feature representation so as to maximize the probability of the observed evidence. Since our approach models evidence as prediction from a DNN, this can often be achieved using standard pre-trained backbones for popular tasks, eliminating the need for training altogether. Even when training is required, our MTL architecture ensures the same can be done without any need for jointly labeled data. Exploiting evidence using our framework, we show an improvement of 3.9% over the state-of-the-art, for predicting semantic segmentation given the image tags, and 2.8% for predicting instance segmentation given image captions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:M3NEmzRMIkIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"We focus on the problem of fine-grained visual classification (FGVC). We posit that unreasonable effectiveness of the state-of-the-art in this area is because of similar object categories present in the ImageNet dataset, which allows such models to be pretrained on a much larger set of samples and learn generic features for those object categories. We observe an important and often ignored additional structure present in an FGVC problem: the objects are captured from a small set of viewing angles only. We notice that subtle differences between object categories are difficult to pick from an arbitrary angle but easier to identify from a similar pose. We show in this paper that training specialized pose experts, focusing on classification from a single, fixed pose, and combining them in an ensemble style framework successfully exploits the structure in the problem. We demonstrate the effectiveness of the proposed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:mB3voiENLucC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"With the success of deep neural networks (DNNs), the robustness of such models under adversarial or fooling attacks has become extremely important. It has been shown that a simple perturbation of the image, invisible to a human observer, is sufficient to fool a deep network. Building on top of such work, methods have been proposed to generate adversarial samples which are robust to natural perturbations (camera noise, rotation, shift, scaling etc.). In this paper, we review multiple such fooling algorithms and show that the generated adversarial samples exhibit distributions largely different from the true distribution of the training samples, and thus are easily detectable by a simple meta classifier. We argue that for truly practical DNN fooling, not only should the adversarial samples be robust against various distortions, but must also follow the training set distribution and be undetectable from such meta classifiers …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:hFOr9nPyWt4C,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"We focus on first-person action recognition from egocentric videos. Unlike third person domain, researchers have divided first-person actions into two categories: involving hand-object interactions and the ones without, and developed separate techniques for the two action categories. Further, it has been argued that traditional cues used for third person action recognition do not suffice, and egocentric specific features, such as head motion and handled objects have been used for such actions. Unlike the state-of-the-art approaches, we show that a regular two stream Convolutional Neural Network (CNN) with Long Short-Term Memory (LSTM) architecture, having separate streams for objects and motion, can generalize to all categories of first-person actions. The proposed approach unifies the feature learned by all action categories, making the proposed architecture much more practical. In an important observation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:-f6ydRqryjwC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Developing recommendation system for fashion images is challenging due to the inherent ambiguity associated with what criterion a user is looking at. Suggesting multiple images where each output image is similar to the query image on the basis of a different feature or part is one way to mitigate the problem. Existing works for fashion recommendation have used Siamese or Triplet network to learn features between a similar pair and a similar-dissimilar triplet respectively. However, these methods do not provide basic information such as, how two clothing images are similar, or which parts present in the two images make them similar. In this paper, we propose to recommend images by explicitly learning and exploiting part based similarity. We propose a novel approach of learning discriminative features from weakly-supervised data by using visual attention over the parts and a texture encoding network. We show …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:hC7cP41nSMkC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Automated brain tissue segmentation into white matter (WM), gray matter (GM), and cerebro-spinal fluid (CSF) from magnetic resonance images (MRI) is helpful in the diagnosis of neuro-disorders such as epilepsy, Alzheimer's, multiple sclerosis, etc. However, thin GM structures at the periphery of cortex and smooth transitions on tissue boundaries such as between GM and WM, or WM and CSF pose difficulty in building a reliable segmentation tool. This paper proposes a Fully Convolutional Neural Network (FCN) tool, that is a hybrid of two widely used deep learning segmentation architectures SegNet and U-Net, for improved brain tissue segmentation. We propose a skip connection inspired from U-Net, in the SegNet architetcure, to incorporate fine multiscale information for better tissue boundary identification. We show that the proposed U-SegNet architecture, improves segmentation performance, as measured …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:IWHjjKOFINEC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"We focus on the problem of parsing fashion images for detecting various types of clothing and style. The current state-of-the-art techniques for the problem are mostly based on variations of the SegNet model. The techniques formulate the problem as segmentation and typically rely on geometrical shapes and position to segment the image. However, specifically for fashion images, each clothing item is made of specific type of materials with characteristic visual texture patterns. Exploiting the texture for recognizing the clothing type is an important cue which has been ignored so far by the state-of-the-art. In this paper, we propose a two-stream deep neural network architecture for fashion image parsing. While the first stream uses the regular fully convolutional network segmentation architecture to give accurate spatial segments, the second stream provides texture features learned from hand-crafted Gabor feature …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:dhFuZR0502QC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"The possibility of sharing one's point of view makes the use of wearable cameras compelling. These videos are often long, boring, and coupled with extreme shaking, as the camera is worn on a moving person. Fast-forwarding (i.e., frame sampling) is a natural choice for quick video browsing. However, this accentuates the shake caused by natural head motion in an egocentric video, making the fast-forwarded video useless. We propose EgoSampling, an adaptive frame sampling that gives stable, fast-forwarded, hyperlapse videos. Adaptive frame sampling is formulated as an energy minimization problem, whose optimal solution can be found in polynomial time. We further turn the camera shake from a drawback into a feature, enabling the increase in field of view of the output video. This is obtained when each output frame is mosaiced from several input frames. The proposed technique also enables the generation …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:MXK_kJrjxJIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"The 6th National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2017) was held at Mandi, Himachal Pradesh, during December 16–19, 2017. NCVPRIPG 2017 was organized by the Indian Institute of Technology Mandi in association with the Indian Unit for Pattern Recognition and Artificial Intelligence (IUPRAI). The NCVPRIPG series of conferences aims to bring together researchers and practitioners from the allied areas of computer vision, graphics, image processing, and pattern recognition, in order to promote community-wide discussions of ideas that will influence and foster continued research in the field. Over the years the conference has grown into a vibrant national conference with participations from many students and researchers in the field. These proceedings contain the papers accepted and presented at the conference (including those presented in the oral as well as poster sessions). The papers showcased original contemporary research spanning various broad themes such as video processing, image and signal processing, segmentation, retrieval, captioning, and various pattern recognition applications. Out of a total of 147 papers submitted to the conference, 48 were accepted and presented, following an elaborate double-blind review process. After the review process, the final decision process was carried out by the Program Chairs based on the review comments. The conference involved eight oral sessions with a total of 25 papers presented, and two poster sessions containing a total of 23 papers. The papers in the proceedings are the revised versions which were …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:7PzlFSSx8tAC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"In this paper, we address the problem of road segmentation and free space detection in the context of autonomous driving. Traditional methods either use 3-dimensional (3D) cues such as point clouds obtained from LIDAR, RADAR or stereo cameras or 2-dimensional (2D) cues such as lane markings, road boundaries and object detection. Typical 3D point clouds do not have enough resolution to detect fine differences in heights such as between road and pavement. Image based 2D cues fail when encountering uneven road textures such as due to shadows, potholes, lane markings or road restoration. We propose a novel free road space detection technique combining both 2D and 3D cues. In particular, we use CNN based road segmentation from 2D images and plane/box fitting on sparse depth data obtained from SLAM as priors to formulate an energy minimization using conditional random field (CRF), for road …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:4DMP91E08xMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"The use of 360 degree cameras, enabling one to record and share full-spherical 360° X 180° view without any cropping in the viewing angle, is on the rise. Shake in such videos is problematic, especially when used in conjunction with VR headsets causing cybersickness to the viewer. The current state-of-the-art video stabilization algorithm [17] designed specifically for 360 degree videos considers the special geometrical constraints in such videos. However, the specific steps in the algorithm can abruptly change the viewing direction in a video leading to unnatural experience for the viewer. In this paper, we propose to fix this anomaly by the use of L1 smoothness constraints on the camera path, as suggested by Grundmann et al. [7]. The modified algorithm is generic and our experiments indicate that the proposed algorithm not only gives a more natural and smoother stabilization for 360 degree videos but can be …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:L8Ckcad2t8MC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Higher order MRF-MAP formulation has been shown to improve solutions in many popular computer vision problems. Most of these approaches have considered hand tuned clique potentials only. Over the last few years, while there has been steady improvement in inference techniques making it possible to perform tractable inference for clique sizes even up to few hundreds, the learning techniques for such clique potentials have been limited to clique size of merely 3 or 4. In this paper, we investigate learning of higher order clique potentials up to clique size of 16. We use structural support vector machine (SSVM), a large-margin learning framework, to learn higher order potential functions from data. It formulates the training problem as a quadratic programming problem (QP) that requires solving MAP inference problems in the inner iteration. We introduce multiple innovations in the formulation by introducing soft …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:9ZlFYXVOiuMC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Applications like autonomous driving, industrial robotics, surveillance, and wearable assistive technology rely on object detectors as an integral part of the system. Thus, an increase in performance of object detectors directly affects the quality of such systems. In the recent years, convolutional neural networks (CNNs) and its variants emerged as the state of art in object detection, where performance is usually measured either in terms of mean average precision (mAP) or number of frames processed per second (fps). Many applications which use object detectors are resource constrained in practice. Even though it is clear from the published results, that a frame-level analysis of the system in terms of mAP or fps proves the superiority of one algorithm over the other, we observe that such metrics do not necessarily apply to real time applications with resource constraints. A slower algorithm even though highly accurate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:mVmsd5A6BfQC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Summary form only given, as follows. Census 2011 classifies more that 5 million people as visually disabled In India. AssisTech (Assistive Technology) group at IIT Delhi aims to develop technological solutions to address their two key challenges; namely independent mobility and access to education. In this tutorial, we will firstly brief about the challenge of mobility and education for visually impaired people. Solutions addressing these challenges could be developed using embedded sensors or with embedded computer vision. Our existing products like SmartCaneTM and OnBoard are embedded system based solutions and are aimed towards facilitating independent mobility. There have been major advances in vision based techniques including possibility of their implementation on low cost embedded platforms. This has encouraged us to visualize a device named MAVI (Mobility Assistant for Visually Impaired …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:QIV2ME_5wuYC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Many prediction tasks, especially in computer vision, are often inherently ambiguous. For example, the output of semantic segmentation may depend on the scale one is looking at. Similarly, image saliency or video summarization is often user or context dependent. Arguably, in such scenarios, exploiting instance specific evidence, such as scale or user context, can help resolve the underlying ambiguity leading to the improved predictions. While existing literature has considered incorporating such evidence in classical models such as probabilistic graphical models (PGMs), there is limited (or no) prior work looking at this problem in the context of deep neural network (DNN) models. In this paper, we present a generic multi-task learning (MTL) based framework which handles the evidence as the output of one or more secondary tasks, while modeling the original problem as the primary task of interest. Our training phase is identical to the one used by standard MTL architectures. During prediction, we back-propagate the loss on secondary task (s) such that network weights are re-adjusted to match the evidence. An early stopping or two norm based regularizer ensures weights do not deviate significantly from the ones learned originally. Implementation in a scenario of predicting semantic segmentation given the image level tags clearly demonstrates the effectiveness of our proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:isC4tDSrTZIC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"A system and method are disclosed, that solve for rotational updates in 360 videos by removing camera shakes, while preserving user intended motions. The method uses a constrained nonlinear optimization approach in quaternion space. At first, optimal 3D camera rotations are computed between key frames. 3D camera rotations between consecutive frames are then computed. The first, second, and third derivatives of the resulting camera path are minimized, to stabilize the camera orientation path. The computation strives to find a smooth path, while also limiting its deviation from the original path. The system keeps the orientations close to the original, for example, even when the videographer takes a turn. Each frame is then warped to the stabilized path, which results in a smoother video. The rotational camera updates may be applied to the input stream at source or added as metadata. The technology may influence standards by making rotational updates metadata a component of 360 videos.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:R3hNpaxXUhUC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Many prediction tasks, especially in computer vision, are often inherently ambiguous. For example, the output of semantic segmentation may depend on the scale one is looking at. Similarly, image saliency or video summarization is often user or context dependent. Arguably, in such scenarios, exploiting instance specific evidence, such as scale or user context, can help resolve the underlying ambiguity leading to the improved predictions. While existing literature has considered incorporating such evidence in classical models such as probabilistic graphical models (PGMs), there is limited (or no) prior work looking at this problem in the context of deep neural network (DNN) models. In this paper, we present a generic multi-task learning (MTL) based framework which handles the evidence as the output of one or more secondary tasks, while modeling the original problem as the primary task of interest. Our training phase is identical to the one used by standard MTL architectures. During prediction, we back-propagate the loss on secondary task (s) such that network weights are re-adjusted to match the evidence. An early stopping or two norm based regularizer ensures weights do not deviate significantly from the ones learned originally. Implementation in a scenario of predicting semantic segmentation given the image level tags clearly demonstrates the effectiveness of our proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:HDshCWvjkbEC,http://www.cse.iitd.ac.in/~chetan
Chetan Arora,"['Computer Vision', 'Machine Learning']",16,1249,2018,"Higher Order MRF-MAP formulation has been a popular technique for solving many problems in computer vision. Inference in a general MRF-MAP problem is NP Hard, but can be performed in polynomial time for the special case when potential functions are submodular. Two popular combinatorial approaches for solving such formulations are flow based and polyhedral approaches. Flow based approaches work well with small cliques and in that mode can handle problems with millions of variables. Polyhedral approaches can handle large cliques but in small numbers. We show in this paper that the variables in these seemingly disparate techniques can be mapped to each other. This allows us to combine the two styles in a joint framework exploiting the strength of both of them. Using the proposed joint framework, we are able to perform tractable inference in MRF-MAP problems with millions of variables and a mix of small and large cliques, a formulation which can not be solved by either of the two styles individually. We show applicability of this hybrid framework on object segmentation problem as an example of a situation where quality of results is significantly better than systems which are based only on the use of small or large cliques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Q8cTLNMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=Q8cTLNMAAAAJ:ZeXyd9-uunAC,http://www.cse.iitd.ac.in/~chetan
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2023,"Class imbalance is a common phenomenon in multiple application domains such as healthcare, where the sample occurrence of one or few class categories is more prevalent in the dataset than the rest. This work addresses the class-imbalance issue by proposing an over-sampling method for the minority classes in the latent space of a Regularized Auto-Encoder (RAE). Specifically, we construct a latent space by maximizing the conditional data likelihood using an Encoder-Decoder structure, such that oversampling through convex combinations of latent samples preserves the class identity. A jointly-trained linear classifier that separates convexly coupled latent vectors from different classes is used to impose this property on the AE’s latent space. Further, the aforesaid linear classifier is used for final classification without retraining. We theoretically show that our method can achieve a low variance risk estimate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:1qzjygNMrQYC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2023,"Multi-modal learning aims at simultaneously modelling data from several modalities such as image, text and speech. The goal is to simultaneously learn representations and make them disentangled so that a variety of downstream tasks such as causal reasoning, fair ML and domain adaptation are well supported. In this work, we propose a novel semi-supervised method to learn disentangled representations for multi-modal data using variational inference. We incorporate a two-component latent space in a Variational Auto-Encoder (VAE) that comprises of domain-invariant (shared) and domain-specific (private) representations across modalities with partitioned discrete and continuous components. We combine the shared continuous and discrete latent spaces via Product-of-experts and statistical ensembles, respectively. We conduct several experiments on multiple multimodal datasets (dSprite-Text, Shaped3D …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:8AbLer7MMksC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2022,"Image manipulation via natural language text -- an extremely useful task for multiple AI applications but requires complex reasoning over multi-modal spaces. Neuro-symbolic approaches has been quite effective in solving such tasks as they offer better modularity, interpretability, and generalizability. A noteworthy such approach is NSCL [10] developed for the task of Visual Question Answering (VQA). We extend NSCL for the image manipulation task and propose a solution referred to as NEUROSIM. Unlike previous works, which either require supervised data training or can only deal with simple reasoning instructions over single object scenes; NEUROSIM can perform complex multi-hop reasoning over multi-object scenes and requires only weak supervision in the form of annotated data for the VQA task. On the language side, NEUROSIM contains neural modules that parse an instruction into a symbolic program over a Domain Specific Language (DSL) comprising manipulation operations that guide the manipulation. On the perceptual side, NEUROSIM contains neural modules which first generate a scene graph of the input image and then change the scene graph representation following the parsed instruction. To train these modules, we design novel loss functions capable of testing the correctness of manipulated object and scene graph representations via query networks. An image decoder is trained to render the final image from the manipulated scene graph representation. Extensive experiments demonstrate that NEUROSIM is highly competitive with state-of-the-art supervised baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:eJXPG6dFmWUC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2022,"Given a natural language instruction, and an input and an output scene, our goal is to train a neuro-symbolic model which can output a manipulation program that can be executed by the robot on the input scene resulting in the desired output scene. Prior approaches for this task possess one of the following limitations: (i) rely on hand-coded symbols for concepts limiting generalization beyond those seen during training [1] (ii) infer action sequences from instructions but require dense sub-goal supervision [2] or (iii) lack semantics required for deeper object-centric reasoning inherent in interpreting complex instructions [3]. In contrast, our approach is neuro-symbolic and can handle linguistic as well as perceptual variations, is end-to-end differentiable requiring no intermediate supervision, and makes use of symbolic reasoning constructs which operate on a latent neural object-centric representation, allowing for deeper reasoning over the input scene. Central to our approach is a modular structure, consisting of a hierarchical instruction parser, and a manipulation module to learn disentangled action representations, both trained via RL. Our experiments on a simulated environment with a 7-DOF manipulator, consisting of instructions with varying number of steps, as well as scenes with different number of objects, and objects with unseen attribute combinations, demonstrate that our model is robust to such variations, and significantly outperforms existing baselines, particularly in generalization settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:D_sINldO8mEC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2022,"There is a recent focus on designing architectures that have an Integer Linear Programming (ILP) layer within a neural model (referred to as Neural ILP in this paper). Neural ILP architectures are suitable for pure reasoning tasks that require data-driven constraint learning or for tasks requiring both perception (neural) and reasoning (ILP). A recent SOTA approach for end-to-end training of Neural ILP explicitly defines gradients through the ILP black box (Paulus et al. 2021) - this trains extremely slowly, owing to a call to the underlying ILP solver for every training data point in a minibatch. In response, we present an alternative training strategy that is solver-free, i.e., does not call the ILP solver at all at training time. Neural ILP has a set of trainable hyperplanes (for cost and constraints in ILP), together representing a polyhedron. Our key idea is that the training loss should impose that the final polyhedron separates the positives (all constraints satisfied) from the negatives (at least one violated constraint or a suboptimal cost value), via a soft-margin formulation. While positive example(s) are provided as part of the training data, we devise novel techniques for generating negative samples. Our solution is flexible enough to handle equality as well as inequality constraints. Experiments on several problems, both perceptual as well as symbolic, which require learning the constraints of an ILP, show that our approach has superior performance and scales much better compared to purely neural baselines and other state-of-the-art models that require solver-based training. In particular, we are able to obtain excellent performance in 9 x 9 symbolic and visual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2022,"Relational MDPs (RMDPs) compactly represent an infinite set of MDPs with an unbounded number of objects. Solving an RMDP requires a generalized policy that applies to all instances of a domain. Recently, Garg et al. proposed SymNet for this task–it constructs a graph neural network that shares parameters across all instances in a domain, thus making it applicable to any instance in a zero-shot manner. Our analysis of SymNet reveals that it performs no better than random on 1/4th of planning competition domains. The key reasons are its design choices: it misses important information during graph construction, leading to (1) poor generalizability, and (2) potential non-identifiability of different actions. In response, our solution, SymNet2. 0, substantially augments SymNet’s graph construction approach by introducing additional nodes and edges which allow a better transfer of important information about a domain. It also improves SymNet’s action decoders with relevant information from objects to make different actions identifiable during scoring. Extensive experiments on twelve competition domains, where we use imitation learning over data generated from the PROST planner, demonstrate that SymNet2. 0 performs vastly better than SymNet. Interestingly, even though SymNet2. 0 is trained over data from PROST, it outperforms the planner on several test instances due to former’s ability to scale to large instances in a zero-shot manner.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:tS2w5q8j5-wC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2022,"Neural models for distantly supervised relation extraction (DS-RE) encode each sentence in an entity-pair bag separately. These are then aggregated for bag-level relation prediction. Since, at encoding time, these approaches do not allow information to flow from other sentences in the bag, we believe that they do not utilize the available bag data to the fullest. In response, we explore a simple baseline approach (PARE) in which all sentences of a bag are concatenated into a passage of sentences, and encoded jointly using BERT. The contextual embeddings of tokens are aggregated using attention with the candidate relation as query–this summary of whole passage predicts the candidate relation. We find that our simple baseline solution outperforms existing state-of-the-art DS-RE models in both monolingual and multilingual DS-RE datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:vRqMK49ujn8C,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2022,"Recently many neural models have been proposed to solve combinatorial puzzles by implicitly learning underlying constraints using their solved instances, such as sudoku or graph coloring (GCP). One drawback of the proposed architectures, which are often based on Graph Neural Networks (GNN), is that they cannot generalize across the size of the output space from which variables are assigned a value, for example, set of colors in a GCP, or board-size in sudoku. We call the output space for the variables as 'value-set'. While many works have demonstrated generalization of GNNs across graph size, there has been no study on how to design a GNN for achieving value-set invariance for problems that come from the same domain. For example, learning to solve 16 x 16 sudoku after being trained on only 9 x 9 sudokus. In this work, we propose novel methods to extend GNN based architectures to achieve value-set invariance. Specifically, our model builds on recently proposed Recurrent Relational Networks. Our first approach exploits the graph-size invariance of GNNs by converting a multi-class node classification problem into a binary node classification problem. Our second approach works directly with multiple classes by adding multiple nodes corresponding to the values in the value-set, and then connecting variable nodes to value nodes depending on the problem initialization. Our experimental evaluation on three different combinatorial problems demonstrates that both our models perform well on our novel problem, compared to a generic neural reasoner. Between two of our models, we observe an inherent trade-off: while the binarized …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:08ZZubdj9fEC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"Objective:
Since its outbreak, the rapid spread of COrona VIrus Disease 2019 (COVID-19) across the globe has pushed the health care system in many countries to the verge of collapse. Therefore, it is imperative to correctly identify COVID-19 positive patients and isolate them as soon as possible to contain the spread of the disease and reduce the ongoing burden on the healthcare system. The primary COVID-19 screening test, RT-PCR although accurate and reliable, has a long turn-around time. In the recent past, several researchers have demonstrated the use of Deep Learning (DL) methods on chest radiography (such as X-ray and CT) for COVID-19 detection. However, existing CNN based DL methods fail to capture the global context due to their inherent image-specific inductive bias.
Methods:
Motivated by this, in this work, we propose the use of vision transformers (instead of convolutional networks) for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:XiSMed-E-HIC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"Auto-Encoder (AE) based neural generative frameworks model the joint-distribution between the data and the latent space using an Encoder-Decoder pair, with regularization imposed in terms of a prior over the latent space. Despite their advantages, such as stability in training, efficient inference, the performance of AE based models has not reached the superior standards of the other generative models such as Generative Adversarial Networks (GANs). Motivated by this, we examine the effect of the latent prior on the generation quality of deterministic AE models in this paper. Specifically, we consider the class of Generative AE models with deterministic Encoder-Decoder pair (such as Wasserstein Auto-Encoder (WAE), Adversarial Auto-Encoder (AAE)), and show that having a fixed prior distribution, a priori, oblivious to the dimensionality of the ‘true’latent space, will lead to the infeasibility of the optimization problem considered. As a remedy to the issue mentioned above, we introduce an additional state space in the form of flexibly learnable latent priors, in the optimization objective of WAE/AAE. Additionally, we employ a latent-space interpolation based smoothing scheme to address the non-smoothness that may arise from highly flexible priors. We show the efficacy of our proposed models, called FlexAE and FlexAE-SR, through several experiments on multiple datasets, and demonstrate that FlexAE-SR is the new state-of-the-art for the AE based generative models in terms of generation quality as measured by several metrics such as Fr\’echet Inception Distance, Precision/Recall score.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:u9iWguZQMMsC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"We introduce the novel and challenging task of answering Points-of-interest (POI) recommendation questions, using a collection of reviews that describe candidate answer entities (POIs). We harvest a QA dataset that contains 47,124 paragraph-sized real user questions from travelers seeking POI recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate entities to choose from and each candidate is associated with a collection of unstructured reviews. Questions can include requirements based on physical location, budget, timings as well as other subjective considerations related to ambience, quality of service etc. We find that commonly used neural architectures for QA are prohibitively expensive for reasoning over the large number of candidate answer entities found in our dataset (over 5300 per question on average). Further, commonly used retriever-ranker based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:q3oQSFYPqjQC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"We introduce the novel and challenging task of answering Points-of-interest (POI) recommendation questions, using a collection of reviews that describe candidate answer entities (POIs). We harvest a QA dataset that contains 47,124 paragraph-sized user questions from travelers seeking POI recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate entities to choose from and each candidate is associated with a collection of unstructured reviews. Questions can include requirements based on physical location, budget, timings as well as other subjective considerations related to ambience, quality of service etc. Our dataset requires reasoning over a large number of candidate answer entities (over 5300 per question on average) and we find that running commonly used neural architectures for QA is prohibitively expensive. Further, commonly used retriever-ranker …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:tOudhMTPpwUC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"Distantly supervised relation extraction (DS-RE) is generally framed as a multi-instance multi-label (MI-ML) task, where the optimal aggregation of information from multiple instances is of key importance. Intra-bag attention (Lin et al., 2016) is an example of a popularly used aggregation scheme for this framework. Apart from this scheme, however, there is not much to choose from in the DS-RE literature as most of the advances in this field are focused on improving the instance-encoding step rather than the instance-aggregation step. With recent works leveraging large pre-trained language models as encoders, the increased capacity of models might allow for more flexibility in the instance-aggregation step. In this work, we explore this hypothesis and come up with a novel aggregation scheme which we call Passage-Att. Under this aggregation scheme, we combine all instances mentioning an entity pair into a ""passage of instances"", which is summarized independently for each relation class. These summaries are used to predict the validity of a potential triple. We show that our Passage-Att with BERT as passage encoder achieves state-of-the-art performance in three different settings (monolingual DS, monolingual DS with manually-annotated test set, multilingual DS).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"CommonsenseQA (CQA)(Talmor et al., 2019) dataset was recently released to advance the research on common-sense question answering (QA) task. Whereas the prior work has mostly focused on proposing QA models for this dataset, our aim is to retrieve as well as generate explanation for a given (question, correct answer choice, incorrect answer choices) tuple from this dataset. Our explanation definition is based on certain desiderata, and translates an explanation into a set of positive and negative common-sense properties (aka facts) which not only explain the correct answer choice but also refute the incorrect ones. We human-annotate a first-of-its-kind dataset (called ECQA) of positive and negative properties, as well as free-flow explanations, for 11K QA pairs taken from the CQA dataset. We propose a latent representation based property retrieval model as well as a GPT-2 based property generation model with a novel two step fine-tuning procedure. We also propose a free-flow explanation generation model. Extensive experiments show that our retrieval model beats BM25 baseline by a relative gain of 100% in F 1 score, property generation model achieves a respectable F 1 score of 36.4, and free-flow generation model achieves a similarity score of 61.9, where last two scores are based on a human correlated semantic similarity metric.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:738O_yMBCRsC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"Clustering single-cell RNA sequence (scRNA-seq) data poses statistical and computational challenges due to their high-dimensionality and data-sparsity, also known as ‘dropout’ events. Recently, Regularized Auto-Encoder (RAE) based deep neural network models have achieved remarkable success in learning robust low-dimensional representations. The basic idea in RAEs is to learn a non-linear mapping from the high-dimensional data space to a low-dimensional latent space and vice-versa, simultaneously imposing a distributional prior on the latent space, which brings in a regularization effect. This paper argues that RAEs suffer from the infamous problem of bias-variance trade-off in their naive formulation. While a simple AE wita latent regularization results in data over-fitting, a very strong prior leads to under-representation and thus bad clustering. To address the above issues, we propose a modified RAE …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:WbkHhVStYXYC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"We focus on the task of future frame prediction in video governed by underlying physical dynamics. We work with models which are object-centric, i.e., explicitly work with object representations, and propagate a loss in the latent space. Specifically, our research builds on recent work by Kipf et al. \cite{kipf&al20}, which predicts the next state via contrastive learning of object interactions in a latent space using a Graph Neural Network. We argue that injecting explicit inductive bias in the model, in form of general physical laws, can help not only make the model more interpretable, but also improve the overall prediction of model. As a natural by-product, our model can learn feature maps which closely resemble actual object positions in the image, without having any explicit supervision about the object positions at the training time. In comparison with earlier works \cite{jaques&al20}, which assume a complete knowledge of the dynamics governing the motion in the form of a physics engine, we rely only on the knowledge of general physical laws, such as, world consists of objects, which have position and velocity. We propose an additional decoder based loss in the pixel space, imposed in a curriculum manner, to further refine the latent space predictions. Experiments in multiple different settings demonstrate that while Kipf et al. model is effective at capturing object interactions, our model can be significantly more effective at localising objects, resulting in improved performance in 3 out of 4 domains that we experiment with. Additionally, our model can learn highly intrepretable feature maps, resembling actual object positions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:Tiz5es2fbqcC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"Our goal is to answer real-world tourism questions that seek Points-of-Interest (POI) recommendations. Such questions express various kinds of spatial and non-spatial constraints, necessitating a combination of textual and spatial reasoning. In response, we develop the first joint spatio-textual reasoning model, which combines geo-spatial knowledge with information in textual corpora to answer questions. We first develop a modular spatial-reasoning network that uses geo-coordinates of location names mentioned in a question, and of candidate answer POIs, to reason over only spatial constraints. We then combine our spatial-reasoner with a textual reasoner in a joint model and present experiments on a real world POI recommendation task. We report substantial improvements over existing models without joint spatio-textual reasoning. To the best of our knowledge, we are the first to develop a joint QA model that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:UxriW0iASnsC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"Pre-trained language models (LMs) like BERT have shown to store factual knowledge about the world. This knowledge can be used to augment the information present in Knowledge Bases, which tend to be incomplete. However, prior attempts at using BERT for task of Knowledge Base Completion (KBC) resulted in performance worse than embedding based techniques that rely only on the graph structure. In this work we develop a novel model, Cross-Entity Aware Reranker (CEAR), that uses BERT to re-rank the output of existing KBC models with cross-entity attention. Unlike prior work that scores each entity independently, CEAR uses BERT to score the entities together, which is effective for exploiting its factual knowledge. CEAR achieves a new state of art for the OLPBench dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:p2g8aNsByqUC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"We introduce the novel and challenging task of answering Pointsof-interest (POI) recommendation questions, using a collection of reviews that describe candidate answer entities (POIs). We harvest a QA dataset that contains 47,124 paragraph-sized user questions from travelers seeking POI recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate entities to choose from and each candidate is associated with a collection of unstructured reviews. Questions can include requirements based on physical location, budget, timings as well as other subjective considerations related to ambience, quality of service etc. Our dataset requires reasoning over a large number of candidate answer entities (over 5300 per question on average) and we find that running commonly used neural architectures for QA is prohibitively expensive. Further, commonly used retriever-ranker based methods also do not work well for our task due to the nature of review-documents. Thus, as a first attempt at addressing some of the novel challenges of reasoning-at-scale posed by our task, we present a task specific baseline model that uses a three-stage cluster-select-rerank architecture. The model first clusters text for each entity to identify exemplar sentences describing an entity. It then uses a neural information retrieval (IR) module to select a set of potential entities from the large candidate set. A reranker uses a deeper attention-based architecture to pick the best answers from the selected entities. This strategy performs better than a pure retrieval or a pure attention-based reasoning approach yielding nearly 25% relative …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:K3LRdlH-MEoC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2021,"We present the novel task of understanding multi-sentence entity-seeking questions (MSEQs), that is, the questions that may be expressed in multiple sentences, and that expect one or more entities as an answer. We formulate the problem of understanding MSEQs as a semantic labeling task over an open representation that makes minimal assumptions about schema or ontology-specific semantic vocabulary. At the core of our model, we use a BiLSTM (bidirectional LSTM) conditional random field (CRF), and to overcome the challenges of operating with low training data, we supplement it by using BERT embeddings, hand-designed features, as well as hard and soft constraints spanning multiple sentences. We find that this results in a 12–15 points gain over a vanilla BiLSTM CRF. We demonstrate the strengths of our work using the novel task of answering real-world entity-seeking questions from the tourism …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:abG-DnoFyZgC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2020,"In this paper, we describe IIT Delhi’s submissions to the WMT 2020 task on Similar Language Translation for four language directions: Hindi<-> Marathi and Spanish<-> Portuguese. We try out three different model settings for the translation task and select our primary and contrastive submissions on the basis of performance of these three models. For our best submissions, we fine-tune the mBART model on the parallel data provided for the task. The pre-training is done using self-supervised objectives on a large amount of monolingual data for many languages. Overall, our models are ranked in the top four of all systems for the submitted language pairs, with first rank in Spanish-> Portuguese.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:SP6oXDckpogC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2020,"Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any one of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks, demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:KxtntwgDAa4C,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2020,"Regularized Auto-Encoders (RAEs) form a rich class of neural generative models. They effectively model the joint-distribution between the data and the latent space using an Encoder-Decoder combination, with regularization imposed in terms of a prior over the latent space. Despite their advantages, such as stability in training, the performance of AE based models has not reached the superior standards as that of the other generative models such as Generative Adversarial Networks (GANs). Motivated by this, we examine the effect of the latent prior on the generation quality of deterministic AE models in this paper. Specifically, we consider the class of RAEs with deterministic Encoder-Decoder pairs, Wasserstein Auto-Encoders (WAE), and show that having a fixed prior distribution, \textit{a priori}, oblivious to the dimensionality of the `true' latent space, will lead to the infeasibility of the optimization problem considered. Further, we show that, in the finite data regime, despite knowing the correct latent dimensionality, there exists a bias-variance trade-off with any arbitrary prior imposition. As a remedy to both the issues mentioned above, we introduce an additional state space in the form of flexibly learnable latent priors, in the optimization objective of the WAEs. We implicitly learn the distribution of the latent prior jointly with the AE training, which not only makes the learning objective feasible but also facilitates operation on different points of the bias-variance curve. We show the efficacy of our model, called FlexAE, through several experiments on multiple datasets, and demonstrate that it is the new state-of-the-art for the AE based generative models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:CHSYGLWDkRkC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2020,"State-of-the-art models for Knowledge Base Completion (KBC) are based on tensor factorization (TF), e.g, DistMult, ComplEx. While they produce good results, they cannot expose any rationale behind their predictions, potentially reducing the trust of a user in the model. Previous works have explored creating an inherently explainable model, e.g. Neural Theorem Proving (NTP), DeepPath, MINERVA, but explainability comes at the cost of performance. Others have tried to create an auxiliary explainable model having high fidelity with the underlying TF model, but unfortunately, they do not scale on large KBs such as FB15k and YAGO. In this work, we propose OxKBC -- an Outcome eXplanation engine for KBC, which provides a post-hoc explanation for every triple inferred by an (uninterpretable) factorization based model. It first augments the underlying Knowledge Graph by introducing weighted edges between entities based on their similarity given by the underlying model. In the augmented graph, it defines a notion of human-understandable explanation paths along with a language to generate them. Depending on the edges, the paths are aggregated into second-order templates for further selection. The best template with its grounding is then selected by a neural selection module that is trained with minimal supervision by a novel loss function. Experiments over Mechanical Turk demonstrate that users find our explanations more trustworthy compared to rule mining.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:P5F9QuxV20EC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2019,"The field of neural generative models is dominated by the highly successful Generative Adversarial Networks (GANs) despite their challenges, such as training instability and mode collapse. Auto-Encoders (AE) with regularized latent space provide an alternative framework for generative models, albeit their performance levels have not reached that of GANs. In this work, we hypothesise that the dimensionality of the AE model's latent space has a critical effect on the quality of generated data. Under the assumption that nature generates data by sampling from a ""true"" generative latent space followed by a deterministic function, we show that the optimal performance is obtained when the dimensionality of the latent space of the AE-model matches with that of the ""true"" generative latent space. Further, we propose an algorithm called the Mask Adversarial Auto-Encoder (MaskAAE), in which the dimensionality of the latent space of an adversarial auto encoder is brought closer to that of the ""true"" generative latent space, via a procedure to mask the spurious latent dimensions. We demonstrate through experiments on synthetic and several real-world datasets that the proposed formulation yields betterment in the generation quality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:dshw04ExmUIC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2019,"We introduce the novel task of answering entity-seeking recommendation questions using a collection of reviews that describe candidate answer entities. We harvest a QA dataset that contains 47,124 paragraph-sized real user questions from travelers seeking recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate answers to choose from and each candidate is associated with a collection of unstructured reviews. This dataset is especially challenging because commonly used neural architectures for reasoning and QA are prohibitively expensive for a task of this scale. As a solution, we design a scalable cluster-select-rerank approach. It first clusters text for each entity to identify exemplar sentences describing an entity. It then uses a scalable neural information retrieval (IR) module to select a set of potential entities from the large candidate set. A reranker uses a deeper attention-based architecture to pick the best answers from the selected entities. This strategy performs better than a pure IR or a pure attention-based reasoning approach yielding nearly 25% relative improvement in Accuracy@3 over both approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:bFI3QPDXJZMC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2019,"Symmetry breaking is a popular technique to reduce the search space for SAT solving by exploiting the underlying symmetry over variables and clauses in a formula. The key idea is to first identify sets of assignments which fall in the same symmetry class, and then impose ordering constraints, called Symmetry Breaking Predicates (SBPs), such that only one (or a small subset) of these assignments is allowed to be a solution of the original SAT formula. While this technique has been exploited extensively in the SAT literature, there is little work on using symmetry breaking for SAT Modulo Theories (SMT). In SMT, logical constraints in SAT theories are combined with another set of theory operations defined over non-Boolean variables such as integers, reals, etc. SMT solvers typically use a combination of SAT solving techniques augmented with calls to the theory solver. In this work, we take up the advances in SAT symmetry breaking and apply them to the domain of SMT. Our key technical contribution is the formulation of symmetry breaking over the Boolean skeleton variables, which are placeholders for actual theory operations in SMT solving. These SBPs are then applied over the SAT solving part of the SMT solver. We implement our SBP ideas on top of CVC4, which is a state-of-the-art SMT solver. Our approach can result in significantly faster solutions on several benchmark problems compared to the state-of-the-art. Our final solver is a hybrid of the original CVC4 solver, and an SBP based solver, and can solve up to 3.8% and 3.1% more problems in the QF_NIA category of 2018 and 2019 SMT benchmarks, respectively, compared to CVC4 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:NhqRSupF_l8C,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2019,"Fluctuations in food prices can cause distress among both consumers and producers, and are often exacerbated by trading networks especially in developing economies where marketplaces may not be operating under conditions of perfect competition for various contextual reasons. We look at onion and potato trading in India and present the evaluation of a price forecasting model, and an anomaly detection and classification system to identify incidents of hoarding of stock by the traders. Our dataset is composed of time series of wholesale prices and arrival volumes of the agricultural commodities at several village-level marketplaces, and retail prices of the commodities at the city centers. We also provide an in-depth qualitative analysis of the effect on these time series of events such as hoarding, weather disturbances, and external shocks. Our results are encouraging and point towards the possibility of building …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:D03iK_w7-QYC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2019,"Several domains in AI need to represent the relational structure as well as model uncertainty. Markov Logic is a powerful formalism which achieves this by attaching weights to formulas in finite first-order logic. Though Markov Logic Networks (MLNs) have been used for a wide variety of applications, a significant challenge remains that weights do not generalize well when training domain sizes are different from those seen during testing. In particular, it has been observed that marginal probabilities tend to extremes in the limit of increasing domain sizes. As the first contribution of our work, we further characterize the distribution and show that marginal probabilities tend to a constant independent of weights and not always to extremes as was previously observed. As our second contribution, we present a principled solution to this problem by defining Domain-size Aware Markov Logic Networks (DA-MLNs) which can be seen as re-parameterizing the MLNs after taking domain size into consideration. For some simple but representative MLN formulas, we formally prove that probabilities defined by DA-MLNs are well behaved. On a practical side, DA-MLNs allow us to generalize the weights learned over small-sized training data to much larger domains. Experiments on three different benchmark MLNs show that our approach results in significant performance gains compared to existing methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:yD5IFk8b50cC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2019,"The field of neural generative models is dominated by the highly successful Generative Adversarial Networks (GANs) despite their challenges, such as training instability and mode collapse. Auto-Encoders (AE) with regularized latent space provides an alternative framework for generative models, albeit their performance levels have not reached that of GANs. In this work, we identify one of the causes for the under-performance of AE-based models and propose a remedial measure. Specifically, we hypothesise that the dimensionality of the AE model’s latent space has a critical effect on the quality of the generated data. Under the assumption that nature generates data by sampling from a “true” generative latent space followed by a deterministic non-linearity, we show that the optimal performance is obtained when the dimensionality of the latent space of the AE-model matches with that of the “true” generative latent space. Further, we propose an algorithm called the Latent Masked Generative Auto-Encoder (LMGAE), in which the dimensionality of the model’s latent space is brought closer to that of the “true” generative latent space, via a novel procedure to mask the spurious latent dimensions. We demonstrate through experiments on synthetic and several realworld datasets that the proposed formulation yields generation quality that is better than the state-of-the-art AE-based generative models and is comparable to that of GANs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:b0M2c_1WBrUC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2019,"For several problems of interest, there are natural constraints which exist over the output label space. For example, for the joint task of NER and POS labeling, these constraints might specify that the NER label ‘organization’is consistent only with the POS labels ‘noun’and ‘preposition’. These constraints can be a great way of injecting prior knowledge into a deep learning model, thereby improving overall performance. In this paper, we present a constrained optimization formulation for training a deep network with a given set of hard constraints on output labels. Our novel approach first converts the label constraints into soft logic constraints over probability distributions outputted by the network. It then converts the constrained optimization problem into an alternating min-max optimization with Lagrangian variables defined for each constraint. Since the constraints are independent of the target labels, our framework easily generalizes to semi-supervised setting. We experiment on the tasks of Semantic Role Labeling (SRL), Named Entity Recognition (NER) tagging, and fine-grained entity typing and show that our constraints not only significantly reduce the number of constraint violations, but can also result in state-of-the-art performance",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:EUQCXRtRnyEC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2019,"We present the novel task of understanding multi-sentence entity-seeking questions (MSEQs) ie, questions that may be expressed in multiple sentences, and that expect one or more entities as an answer. We formulate the problem of understanding MSEQs as a semantic labeling task over an open representation that makes minimal assumptions about schema or ontology specific semantic vocabulary. At the core of our model, we use a BiDiLSTM (bi-directional LSTM) CRF and to overcome the challenges of operating with low training data, we supplement it by using hand-designed features, as well as hard and soft constraints spanning multiple sentences. We find that this results in a 6-7pt gain over a vanilla BiDiL-STM CRF. We demonstrate the strengths of our work using the novel task of answering real-world entity-seeking questions from the tourism domain. The use of our labels helps answer 53% more questions with 42% more accuracy as compared to baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:_xSYboBqXhAC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2019,"We present CVC4-SymBreak, a derived SMT solver based on CVC4 [1], and a noncompeting participant of SMT-COMP 2019 [13]. Our technique exploits symmetries over the Boolean skeleton variables in an SMT problem to prune the search space. We use an ensemble of a solver with and without symmetries to be more effective. Our approach results in significantly faster solutions on a subset of available SMT benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:pyW8ca7W8N0C,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2018,"Auxiliary information can be exploited in machine learning models using the paradigm of evidence based conditional inference. Multi-modal techniques in Deep Neural Networks (DNNs) can be seen as perturbing the latent feature representation for incorporating evidence from the auxiliary modality. However, they require training a specialized network which can map sparse evidence to a high dimensional latent space vector. Designing such a network, as well as collecting jointly labeled data for training is a non-trivial task. In this paper, we present a novel multi-task learning (MTL) based framework to perform evidence based conditional inference in DNNs which can overcome both these shortcomings. Our framework incorporates evidence as the output of secondary task(s), while modeling the original problem as the primary task of interest. During inference, we employ a novel Bayesian formulation to change the joint latent feature representation so as to maximize the probability of the observed evidence. Since our approach models evidence as prediction from a DNN, this can often be achieved using standard pre-trained backbones for popular tasks, eliminating the need for training altogether. Even when training is required, our MTL architecture ensures the same can be done without any need for jointly labeled data. Exploiting evidence using our framework, we show an improvement of 3.9% over the state-of-the-art, for predicting semantic segmentation given the image tags, and 2.8% for predicting instance segmentation given image captions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:1sJd4Hv_s6UC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2018,"Combining logic and probability has been a long stand- ing goal of AI research. Markov Logic Networks (MLNs) achieve this by attaching weights to formulas in first-order logic, and can be seen as templates for constructing features for ground Markov networks. Most techniques for learning weights of MLNs are domain-size agnostic, i.e., the size of the domain is not explicitly taken into account while learn- ing the parameters of the model. This often results in ex- treme probabilities when testing on domain sizes different from those seen during training. In this paper, we propose Domain Aware Markov logic Networks (DA-MLNs) which present a principled solution to this problem. While defin- ing the ground network distribution, DA-MLNs divide the ground feature weight by a scaling factor which is a function of the number of connections the ground atoms appearing in the feature are involved in. We show that standard MLNs fall out as a special case of our formalism when this func- tion evaluates to a constant equal to 1. Experiments on the benchmark Friends & Smokers domain show that our ap- proach results in significantly higher accuracies compared to existing methods when testing on domains whose sizes different from those seen during training.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:3s1wT3WcHBgC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2018,"Lifted inference reduces the complexity of inference in relational probabilistic models by identifying groups of constants (or atoms) which behave symmetric to each other. A number of techniques have been proposed in the literature for lifting marginal as well MAP inference. We present the first application of lifting rules for marginal-MAP (MMAP), an important inference problem in models having latent (random) variables. Our main contribution is two fold: (1) we define a new equivalence class of (logical) variables, called Single Occurrence for MAX (SOM), and show that solution lies at extreme with respect to the SOM variables, i.e., predicate groundings differing only in the instantiation of the SOM variables take the same truth value (2) we define a sub-class {\em SOM-R} (SOM Reduce) and exploit properties of extreme assignments to show that MMAP inference can be performed by reducing the domain of SOM-R variables to a single constant.We refer to our lifting technique as the {\em SOM-R} rule for lifted MMAP. Combined with existing rules such as decomposer and binomial, this results in a powerful framework for lifted MMAP. Experiments on three benchmark domains show significant gains in both time and memory compared to ground inference as well as lifted approaches not using SOM-R.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:f2IySw72cVMC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2018,"One popular way for lifted inference in probabilistic graphical models is to first merge symmetric states into a single cluster (orbit) and then use these for downstream inference, via variations of orbital MCMC [Niepert, 2012]. These orbits are represented compactly using permutations over variables, and variable-value (VV) pairs, but they can miss several state symmetries in a domain. We define the notion of permutations over block-value (BV) pairs, where a block is a set of variables. BV strictly generalizes VV symmetries, and can compute many more symmetries for increasing block sizes. To operationalize use of BV permutations in lifted inference, we describe 1) an algorithm to compute BV permutations given a block partition of the variables, 2) BV-MCMC, an extension of orbital MCMC that can sample from BV orbits, and 3) a heuristic to suggest good block partitions. Our experiments show that BV-MCMC can mix much faster compared to vanilla MCMC and orbital MCMC.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:ZHo1McVdvXMC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2018,"Higher order MRF-MAP formulation has been shown to improve solutions in many popular computer vision problems. Most of these approaches have considered hand tuned clique potentials only. Over the last few years, while there has been steady improvement in inference techniques making it possible to perform tractable inference for clique sizes even up to few hundreds, the learning techniques for such clique potentials have been limited to clique size of merely 3 or 4. In this paper, we investigate learning of higher order clique potentials up to clique size of 16. We use structural support vector machine (SSVM), a large-margin learning framework, to learn higher order potential functions from data. It formulates the training problem as a quadratic programming problem (QP) that requires solving MAP inference problems in the inner iteration. We introduce multiple innovations in the formulation by introducing soft …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:pqnbT2bcN3wC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2018,"We introduce the first system towards the novel task of answering complex multisentence recommendation questions in the tourism domain. Our solution uses a pipeline of two modules: question understanding and answering. For question understanding, we define an SQL-like query language that captures the semantic intent of a question; it supports operators like subset, negation, preference and similarity, which are often found in recommendation questions. We train and compare traditional CRFs as well as bidirectional LSTM-based models for converting a question to its semantic representation. We extend these models to a semisupervised setting with partially labeled sequences gathered through crowdsourcing. We find that our best model performs semi-supervised training of BiDiLSTM+CRF with hand-designed features and CCM(Chang et al., 2007) constraints. Finally, in an end to end QA system, our answering component converts our question representation into queries fired on underlying knowledge sources. Our experiments on two different answer corpora demonstrate that our system can significantly outperform baselines with up to 20 pt higher accuracy and 17 pt higher recall.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:2P1L_qKh6hAC,http://www.cse.iitd.ac.in/~parags
Parag Singla,"['Neuro-Symbolic Reasoning', 'Machine Learning', 'Artificial Intelligence']",18,1133,2018,"Many prediction tasks, especially in computer vision, are often inherently ambiguous. For example, the output of semantic segmentation may depend on the scale one is looking at. Similarly, image saliency or video summarization is often user or context dependent. Arguably, in such scenarios, exploiting instance specific evidence, such as scale or user context, can help resolve the underlying ambiguity leading to the improved predictions. While existing literature has considered incorporating such evidence in classical models such as probabilistic graphical models (PGMs), there is limited (or no) prior work looking at this problem in the context of deep neural network (DNN) models. In this paper, we present a generic multi-task learning (MTL) based framework which handles the evidence as the output of one or more secondary tasks, while modeling the original problem as the primary task of interest. Our training phase is identical to the one used by standard MTL architectures. During prediction, we back-propagate the loss on secondary task (s) such that network weights are re-adjusted to match the evidence. An early stopping or two norm based regularizer ensures weights do not deviate significantly from the ones learned originally. Implementation in a scenario of predicting semantic segmentation given the image level tags clearly demonstrates the effectiveness of our proposed approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=V49BsgMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=V49BsgMAAAAJ:zA6iFVUQeVQC,http://www.cse.iitd.ac.in/~parags
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2023,"Multi-class cell detection and counting is an essential task for many pathological diagnoses. Manual counting is tedious and often leads to inter-observer variations among pathologists. While there exist multiple, general-purpose, deep learning-based object detection and counting methods, they may not readily transfer to detecting and counting cells in medical images, due to the limited data, presence of tiny overlapping objects, multiple cell types, severe class-imbalance, minute differences in size/shape of cells, etc. In response, we propose guided posterior regularization (DeGPR), which assists an object detector by guiding it to exploit discriminative features among cells. The features may be pathologist-provided or inferred directly from visual data. We validate our model on two publicly available datasets (CoNSeP and MoNuSAC), and on MuCeD, a novel dataset that we contribute. MuCeD consists of 55 biopsy images of the human duodenum for predicting celiac disease. We perform extensive experimentation with three object detection baselines on three datasets to show that DeGPR is model-agnostic, and consistently improves baselines obtaining up to 9% (absolute) mAP gains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:RfUwGJFMQ-0C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"Automated completion of open knowledge bases (KBs), which are constructed from triples of the form (subject phrase, relation phrase, object phrase) obtained via open information extraction (IE) from text, is useful for discovering novel facts that may not directly be present in the text. However, research in open knowledge base completion (KBC) has so far been limited to resource-rich languages like English. Using the latest advances in multilingual open IE, we construct the first multilingual open KBC dataset, called mOKB6, that contains facts from Wikipedia in six languages (including English). Improving the previous open KB construction pipeline by doing multilingual coreference resolution and keeping only entity-linked triples, we create a dense open KB. We experiment with several baseline models that have been proposed for both open and closed KBs and observe a consistent benefit of using knowledge gained from other languages. The dataset and accompanying code will be made publicly available.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:RXiHnyRawswC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"Proper noun compounds, e.g., ""Covid vaccine"", convey information in a succinct manner (a ""Covid vaccine"" is a ""vaccine that immunizes against the Covid disease""). These are commonly used in short-form domains, such as news headlines, but are largely ignored in information-seeking applications. To address this limitation, we release a new manually annotated dataset, ProNCI, consisting of 22.5K proper noun compounds along with their free-form semantic interpretations. ProNCI is 60 times larger than prior noun compound datasets and also includes non-compositional examples, which have not been previously explored. We experiment with various neural models for automatically generating the semantic interpretations from proper noun compounds, ranging from few-shot prompting to supervised learning, with varying degrees of knowledge about the constituent nouns. We find that adding targeted knowledge, particularly about the common noun, results in performance gains of upto 2.8%. Finally, we integrate our model generated interpretations with an existing Open IE system and observe an 7.5% increase in yield at a precision of 85%. The dataset and code are available at https://github.com/dair-iitd/pronci.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:M_lZXyI38BkC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"There is a recent focus on designing architectures that have an Integer Linear Programming (ILP) layer within a neural model (referred to as Neural ILP in this paper). Neural ILP architectures are suitable for pure reasoning tasks that require data-driven constraint learning or for tasks requiring both perception (neural) and reasoning (ILP). A recent SOTA approach for end-to-end training of Neural ILP explicitly defines gradients through the ILP black box (Paulus et al. 2021) - this trains extremely slowly, owing to a call to the underlying ILP solver for every training data point in a minibatch. In response, we present an alternative training strategy that is solver-free, i.e., does not call the ILP solver at all at training time. Neural ILP has a set of trainable hyperplanes (for cost and constraints in ILP), together representing a polyhedron. Our key idea is that the training loss should impose that the final polyhedron separates the positives (all constraints satisfied) from the negatives (at least one violated constraint or a suboptimal cost value), via a soft-margin formulation. While positive example(s) are provided as part of the training data, we devise novel techniques for generating negative samples. Our solution is flexible enough to handle equality as well as inequality constraints. Experiments on several problems, both perceptual as well as symbolic, which require learning the constraints of an ILP, show that our approach has superior performance and scales much better compared to purely neural baselines and other state-of-the-art models that require solver-based training. In particular, we are able to obtain excellent performance in 9 x 9 symbolic and visual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:uUvzmPk0f8oC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"Relational MDPs (RMDPs) compactly represent an infinite set of MDPs with an unbounded number of objects. Solving an RMDP requires a generalized policy that applies to all instances of a domain. Recently, Garg et al. proposed SymNet for this task–it constructs a graph neural network that shares parameters across all instances in a domain, thus making it applicable to any instance in a zero-shot manner. Our analysis of SymNet reveals that it performs no better than random on 1/4th of planning competition domains. The key reasons are its design choices: it misses important information during graph construction, leading to (1) poor generalizability, and (2) potential non-identifiability of different actions. In response, our solution, SymNet2. 0, substantially augments SymNet’s graph construction approach by introducing additional nodes and edges which allow a better transfer of important information about a domain. It also improves SymNet’s action decoders with relevant information from objects to make different actions identifiable during scoring. Extensive experiments on twelve competition domains, where we use imitation learning over data generated from the PROST planner, demonstrate that SymNet2. 0 performs vastly better than SymNet. Interestingly, even though SymNet2. 0 is trained over data from PROST, it outperforms the planner on several test instances due to former’s ability to scale to large instances in a zero-shot manner.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:Ej9njvOgR2oC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"A crucial component in the curation of KB for a scientific domain is information extraction from tables in the domain's published articles -- tables carry important information (often numeric), which must be adequately extracted for a comprehensive machine understanding of an article. Existing table extractors assume prior knowledge of table structure and format, which may not be known in scientific tables. We study a specific and challenging table extraction problem: extracting compositions of materials (e.g., glasses, alloys). We first observe that materials science researchers organize similar compositions in a wide variety of table styles, necessitating an intelligent model for table understanding and composition extraction. Consequently, we define this novel task as a challenge for the ML community and create a training dataset comprising 4,408 distantly supervised tables, along with 1,475 manually annotated dev and test tables. We also present DiSCoMaT, a strong baseline geared towards this specific task, which combines multiple graph neural networks with several task-specific regular expressions, features, and constraints. We show that DiSCoMaT outperforms recent table processing architectures by significant margins.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:JH5k92_tO-AC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"Robots assisting us in environments such as factories or homes must learn to make use of objects as tools to perform tasks, for instance, using a tray to carry objects. We consider the problem of learning common sense knowledge of when a tool may be useful and how its use may be composed with other tools to accomplish a high-level task instructed by a human. Specifically, we introduce a novel neural model, termed TOOLTANGO, that first predicts the next tool to be used, and then uses this information to predict the next action. We show that this joint model can inform learning of a fine-grained policy enabling the robot to use a particular tool in sequence and adds a significant value in making the model more accurate. TOOLTANGO encodes the world state, comprising objects and symbolic relationships between them, using a graph neural network and is trained using demonstrations from human teachers instructing a virtual robot in a physics simulator. The model learns to attend over the scene using knowledge of the goal and the action history, finally decoding the symbolic action to execute. Crucially, we address generalization to unseen environments where some known tools are missing, but unseen alternative tools are present. We show that by augmenting the representation of the environment with pre-trained embeddings derived from a knowledge-base, the model can generalize effectively to novel environments. Experimental results show at least 48.8-58.1% absolute improvement over the baselines in predicting successful symbolic plans for a simulated mobile manipulator in novel environments with unseen objects. This work takes a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:vVJNg6_NJEsC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"Our goal is to enable a robot to learn how to sequence its actions to perform tasks specified as natural language instructions, given successful demonstrations from a human partner. The ability to plan high-level tasks can be factored as (i) inferring specific goal predicates that characterize the task implied by a language instruction for a given world state and (ii) synthesizing a feasible goal-reaching action-sequence with such predicates. For the former, we leverage a neural network prediction model, while utilizing a symbolic planner for the latter. We introduce a novel neuro-symbolic model, GoalNet, for contextual and task dependent inference of goal predicates from human demonstrations and linguistic task descriptions. GoalNet combines (i) learning, where dense representations are acquired for language instruction and the world state that enables generalization to novel settings and (ii) planning, where the cause-effect modeling by the symbolic planner eschews irrelevant predicates facilitating multi-stage decision making in large domains. GoalNet demonstrates a significant improvement (51%) in the task completion rate in comparison to a state-of-the-art rule-based approach on a benchmark data set displaying linguistic variations, particularly for multi-stage instructions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:QaSi33NTfwYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"Neural models for distantly supervised relation extraction (DS-RE) encode each sentence in an entity-pair bag separately. These are then aggregated for bag-level relation prediction. Since, at encoding time, these approaches do not allow information to flow from other sentences in the bag, we believe that they do not utilize the available bag data to the fullest. In response, we explore a simple baseline approach (PARE) in which all sentences of a bag are concatenated into a passage of sentences, and encoded jointly using BERT. The contextual embeddings of tokens are aggregated using attention with the candidate relation as query–this summary of whole passage predicts the candidate relation. We find that our simple baseline solution outperforms existing state-of-the-art DS-RE models in both monolingual and multilingual DS-RE datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:natZJ_-F0IUC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"Progress with supervised Open Information Extraction (OpenIE) has been primarily limited to English due to the scarcity of training data in other languages. In this paper, we explore techniques to automatically convert English text for training OpenIE systems in other languages. We introduce the Alignment-Augmented Constrained Translation (AACTrans) model to translate English sentences and their corresponding extractions consistently with each other—with no changes to vocabulary or semantic meaning which may result from independent translations. Using the data generated with AACTrans, we train a novel two-stage generative OpenIE model, which we call Gen2OIE, that outputs for each sentence: 1) relations in the first stage and 2) all extractions containing the relation in the second stage. Gen2OIE increases relation coverage using a training data transformation technique that is generalizable to multiple languages, in contrast to existing models that use an English-specific training loss. Evaluations on 5 languages—Spanish, Portuguese, Chinese, Hindi and Telugu—show that the Gen2OIE with AACTrans data outperforms prior systems by a margin of 6-25% in F1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:wyM6WWKXmoIC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:3lUAU8Oskd0C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"This paper studies a novel reviewer-paper matching approach that was recently deployed in the 35th AAAI Conference on Artificial Intelligence (AAAI 2021), and has since been adopted by other conferences including AAAI 2022 and ICML 2022. This approach has three main elements: (1) collecting and processing input data to identify problematic matches and generate reviewer-paper scores; (2) formulating and solving an optimization problem to find good reviewer-paper matchings; and (3) the introduction of a novel, two-phase reviewing process that shifted reviewing resources away from papers likely to be rejected and towards papers closer to the decision boundary. This paper also describes an evaluation of these innovations based on an extensive post-hoc analysis on real data -- including a comparison with the matching algorithm used in AAAI's previous (2020) iteration -- and supplements this with additional numerical experimentation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:xGWFX6Gbr9MC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"Recently many neural models have been proposed to solve combinatorial puzzles by implicitly learning underlying constraints using their solved instances, such as sudoku or graph coloring (GCP). One drawback of the proposed architectures, which are often based on Graph Neural Networks (GNN), is that they cannot generalize across the size of the output space from which variables are assigned a value, for example, set of colors in a GCP, or board-size in sudoku. We call the output space for the variables as 'value-set'. While many works have demonstrated generalization of GNNs across graph size, there has been no study on how to design a GNN for achieving value-set invariance for problems that come from the same domain. For example, learning to solve 16 x 16 sudoku after being trained on only 9 x 9 sudokus. In this work, we propose novel methods to extend GNN based architectures to achieve value-set invariance. Specifically, our model builds on recently proposed Recurrent Relational Networks. Our first approach exploits the graph-size invariance of GNNs by converting a multi-class node classification problem into a binary node classification problem. Our second approach works directly with multiple classes by adding multiple nodes corresponding to the values in the value-set, and then connecting variable nodes to value nodes depending on the problem initialization. Our experimental evaluation on three different combinatorial problems demonstrates that both our models perform well on our novel problem, compared to a generic neural reasoner. Between two of our models, we observe an inherent trade-off: while the binarized …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:YPNY0knpFBYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2022,"Distant supervision (DS) is a well established technique for creating large-scale datasets for relation extraction (RE) without using human annotations. However, research in DS-RE has been mostly limited to the English language. Constraining RE to a single language inhibits utilization of large amounts of data in other languages which could allow extraction of more diverse facts. Very recently, a dataset for multilingual DS-RE has been released. However, our analysis reveals that the proposed dataset exhibits unrealistic characteristics such as 1) lack of sentences that do not express any relation, and 2) all sentences for a given entity pair expressing exactly one relation. We show that these characteristics lead to a gross overestimation of the model performance. In response, we propose a new dataset, DiS-ReX, which alleviates these issues. Our dataset has more than 1.5 million sentences, spanning across 4 languages with 36 relation classes + 1 no relation (NA) class. We also modify the widely used bag attention models by encoding sentences using mBERT and provide the first benchmark results on multilingual DS-RE. Unlike the competing dataset, we show that our dataset is challenging and leaves enough room for future research to take place in this field.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:PlWzFYVEG4EC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"We introduce the novel and challenging task of answering Points-of-interest (POI) recommendation questions, using a collection of reviews that describe candidate answer entities (POIs). We harvest a QA dataset that contains 47,124 paragraph-sized user questions from travelers seeking POI recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate entities to choose from and each candidate is associated with a collection of unstructured reviews. Questions can include requirements based on physical location, budget, timings as well as other subjective considerations related to ambience, quality of service etc. Our dataset requires reasoning over a large number of candidate answer entities (over 5300 per question on average) and we find that running commonly used neural architectures for QA is prohibitively expensive. Further, commonly used retriever-ranker …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:WwIwg2wKZ0QC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"End-to-End task-oriented dialogue systems generate responses based on dialog history and an accompanying knowledge base (KB). Inferring those KB entities that are most relevant for an utterance is crucial for response generation. Existing state of the art scales to large KBs by softly filtering over irrelevant KB information. In this paper, we propose a novel filtering technique that consists of (1) a pairwise similarity based filter that identifies relevant information by respecting the n-ary structure in a KB record. and, (2) an auxiliary loss that helps in separating contextually unrelated KB information. We also propose a new metric -- multiset entity F1 which fixes a correctness issue in the existing entity F1 metric. Experimental results on three publicly available task-oriented dialog datasets show that our proposed approach outperforms existing state-of-the-art models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:PQEM9vzQD9gC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"We propose the novel task of answering regular expression queries (containing disjunction () and Kleene plus () operators) over incomplete KBs. The answer set of these queries potentially has a large number of entities, hence previous works for single-hop queries in KBC that model a query as a point in high-dimensional space are not as effective. In response, we develop RotatE-Box -- a novel combination of RotatE and box embeddings. It can model more relational inference patterns compared to existing embedding based models. Furthermore, we define baseline approaches for embedding based KBC models to handle regex operators. We demonstrate performance of RotatE-Box on two new regex-query datasets introduced in this paper, including one where the queries are harvested based on actual user query logs. We find that our final RotatE-Box model significantly outperforms models based on just RotatE and just box embeddings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:lg2tdxc6qMwC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"Neural models and symbolic algorithms have recently been combined for tasks requiring both perception and reasoning. Neural models ground perceptual input into a conceptual vocabulary, on which a classical reasoning algorithm is applied to generate output. A key limitation is that such neural-to-symbolic models can only be trained end-to-end for tasks where the output space is symbolic. In this paper, we study neural-symbolic-neural models for reasoning tasks that require a conversion from an image input (e.g., a partially filled sudoku) to an image output (e.g., the image of the completed sudoku). While designing such a three-step hybrid architecture may be straightforward, the key technical challenge is end-to-end training -- how to backpropagate without intermediate supervision through the symbolic component. We propose NSNnet, an architecture that combines an image reconstruction loss with a novel output encoder to generate a supervisory signal, develops update algorithms that leverage policy gradient methods for supervision, and optimizes loss using a novel subsampling heuristic. We experiment on problem settings where symbolic algorithms are easily specified: a visual maze solving task and a visual Sudoku solver where the supervision is in image form. Experiments show high accuracy with significantly less data compared to purely neural approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:e84hm74t-eoC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"Robots assisting us in factories or homes must learn to make use of objects as tools to perform tasks, e.g., a tray for carrying objects. We consider the problem of learning commonsense knowledge of when a tool may be useful and how its use may be composed with other tools to accomplish a high-level task instructed by a human. We introduce a novel neural model, termed TANGO, for predicting task-specific tool interactions, trained using demonstrations from human teachers instructing a virtual robot. TANGO encodes the world state, comprising objects and symbolic relationships between them, using a graph neural network. The model learns to attend over the scene using knowledge of the goal and the action history, finally decoding the symbolic action to execute. Crucially, we address generalization to unseen environments where some known tools are missing, but alternative unseen tools are present. We show that by augmenting the representation of the environment with pre-trained embeddings derived from a knowledge-base, the model can generalize effectively to novel environments. Experimental results show a 60.5-78.9% absolute improvement over the baseline in predicting successful symbolic plans in unseen settings for a simulated mobile manipulator.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:wSy_KLzO7YEC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"Pre-trained language models (LMs) like BERT have shown to store factual knowledge about the world. This knowledge can be used to augment the information present in Knowledge Bases, which tend to be incomplete. However, prior attempts at using BERT for task of Knowledge Base Completion (KBC) resulted in performance worse than embedding based techniques that rely only on the graph structure. In this work we develop a novel model, Cross-Entity Aware Reranker (CEAR), that uses BERT to re-rank the output of existing KBC models with cross-entity attention. Unlike prior work that scores each entity independently, CEAR uses BERT to score the entities together, which is effective for exploiting its factual knowledge. CEAR achieves a new state of art for the OLPBench dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:BOlwja0KXvYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"Task-oriented dialog (TOD) systems often need to formulate knowledge base (KB) queries corresponding to the user intent and use the query results to generate system responses. Existing approaches require dialog datasets to explicitly annotate these KB queries—these annotations can be time consuming, and expensive. In response, we define the novel problems of predicting the KB query and training the dialog agent, without explicit KB query annotation. For query prediction, we propose a reinforcement learning (RL) baseline, which rewards the generation of those queries whose KB results cover the entities mentioned in subsequent dialog. Further analysis reveals that correlation among query attributes in KB can significantly confuse memory augmented policy optimization (MAPO), an existing state of the art RL agent.
To address this, we improve the MAPO baseline with simple but important …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:yY3RG6sOEgwC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"We propose a novel problem within end-to-end learning of task-oriented dialogs (TOD), in which the dialog system mimics a troubleshooting agent who helps a user by diagnosing their problem (e.g., car not starting). Such dialogs are grounded in domain-specific flowcharts, which the agent is supposed to follow during the conversation. Our task exposes novel technical challenges for neural TOD, such as grounding an utterance to the flowchart without explicit annotation, referring to additional manual pages when user asks a clarification question, and ability to follow unseen flowcharts at test time. We release a dataset (FloDial) consisting of 2,738 dialogs grounded on 12 different troubleshooting flowcharts. We also design a neural model, FloNet, which uses a retrieval-augmented generation architecture to train the dialog agent. Our experiments find that FloNet can do zero-shot transfer to unseen flowcharts, and sets a strong baseline for future research.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:V_vSwabWVtYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"Recent research has proposed neural architectures for solving combinatorial problems in structured output spaces. In many such problems, there may exist multiple solutions for a given input, e.g. a partially filled Sudoku puzzle may have many completions satisfying all constraints. Further, we are often interested in finding any one of the possible solutions, without any preference between them. Existing approaches completely ignore this solution multiplicity. In this paper, we argue that being oblivious to the presence of multiple solutions can severely hamper their training ability. Our contribution is two fold. First, we formally define the task of learning one-of-many solutions for combinatorial problems in structured output spaces, which is applicable for solving several problems of interest such as N-Queens, and Sudoku. Second, we present a generic learning framework that adapts an existing prediction network for a combinatorial problem to handle solution multiplicity. Our framework uses a selection module, whose goal is to dynamically determine, for every input, the solution that is most effective for training the network parameters in any given learning iteration. We propose an RL based approach to jointly train the selection module with the prediction network. Experiments on three different domains, and using two different prediction networks, demonstrate that our framework significantly improves the accuracy in our setting, obtaining up to 21 pt gain over the baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:xyvS_IvSCKsC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"Knowledge Graph Completion (KGC) predicts missing facts in an incomplete Knowledge Graph. Almost all of existing KGC research is applicable to only one KG at a time, and in one language only. However, different language speakers may maintain separate KGs in their language and no individual KG is expected to be complete. Moreover, common entities or relations in these KGs have different surface forms and IDs, leading to ID proliferation. Entity alignment (EA) and relation alignment (RA) tasks resolve this by recognizing pairs of entity (relation) IDs in different KGs that represent the same entity (relation). This can further help prediction of missing facts, since knowledge from one KG is likely to benefit completion of another. High confidence predictions may also add valuable information for the alignment tasks. In response, we study the novel task of jointly training multilingual KGC, relation alignment and entity alignment models. We present ALIGNKGC, which uses some seed alignments to jointly optimize all three of KGC, EA and RA losses. A key component of ALIGNKGC is an embedding based soft notion of asymmetric overlap defined on the (subject, object) set signatures of relations this aids in better predicting relations that are equivalent to or implied by other relations. Extensive experiments with DBPedia in five languages establish the benefits of joint training for all tasks, achieving 10-32 MRR improvements of ALIGNKGC over a strong state-of-the-art single-KGC system completion model over each monolingual KG . Further, ALIGNKGC achieves reasonable gains in EA and RA tasks over a vanilla completion model over a KG that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:KI9T_ytC6pkC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2021,"A large amount of materials science knowledge is generated and stored as text published in peer-reviewed scientific literature. While recent developments in natural language processing, such as Bidirectional Encoder Representations from Transformers (BERT) models, provide promising information extraction tools, these models may yield suboptimal results when applied on materials domain since they are not trained in materials science specific notations and jargons. Here, we present a materials-aware language model, namely, MatSciBERT, trained on a large corpus of peer-reviewed materials science publications. We show that MatSciBERT outperforms SciBERT, a language model trained on science corpus, and establish state-of-the-art results on three downstream tasks, named entity recognition, relation classification, and abstract classification. We make the pre-trained weights of MatSciBERT publicly …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:KTwcwpFFj4wC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"A Relational Markov Decision Process (RMDP) is a first-order representation to express all instances of a single probabilistic planning domain with possibly unbounded number of objects. Early work in RMDPs outputs generalized (instance-independent) first-order policies or value functions as a means to solve all instances of a domain at once. Unfortunately, this line of work met with limited success due to inherent limitations of the representation space used in such policies or value functions. Can neural models provide the missing link by easily representing more complex generalized policies, thus making them effective on all instances of a given domain? We present SymNet, the first neural approach for solving RMDPs that are expressed in the probabilistic planning language of RDDL. SymNet trains a set of shared parameters for an RDDL domain using training instances from that domain. For each instance, SymNet first converts it to an instance graph and then uses relational neural models to compute node embeddings. It then scores each ground action as a function over the first-order action symbols and node embeddings related to the action. Given a new test instance from the same domain, SymNet architecture with pre-trained parameters scores each ground action and chooses the best action. This can be accomplished in a single forward pass without any retraining on the test instance, thus implicitly representing a neural generalized policy for the whole domain. Our experiments on nine RDDL domains from IPPC demonstrate that SymNet policies are significantly better than random and sometimes even more effective than training a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:37UQlXuwjP4C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"A recent state-of-the-art neural open information extraction (OpenIE) system generates extractions iteratively, requiring repeated encoding of partial outputs. This comes at a significant computational cost. On the other hand, sequence labeling approaches for OpenIE are much faster, but worse in extraction quality. In this paper, we bridge this trade-off by presenting an iterative labeling-based system that establishes a new state of the art for OpenIE, while extracting 10x faster. This is achieved through a novel Iterative Grid Labeling (IGL) architecture, which treats OpenIE as a 2-D grid labeling task. We improve its performance further by applying coverage (soft) constraints on the grid at training time. Moreover, on observing that the best OpenIE systems falter at handling coordination structures, our OpenIE system also incorporates a new coordination analyzer built with the same IGL architecture. This IGL based coordination analyzer helps our OpenIE system handle complicated coordination structures, while also establishing a new state of the art on the task of coordination analysis, with a 12.3 pts improvement in F1 over previous analyzers. Our OpenIE system, OpenIE6, beats the previous systems by as much as 4 pts in F1, while being much faster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:TaaCk18tZOkC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"Our goal is to answer real-world tourism questions that seek Points-of-Interest (POI) recommendations. Such questions express various kinds of spatial and non-spatial constraints, necessitating a combination of textual and spatial reasoning. In response, we develop the first joint spatio-textual reasoning model, which combines geo-spatial knowledge with information in textual corpora to answer questions. We first develop a modular spatial-reasoning network that uses geo-coordinates of location names mentioned in a question, and of candidate answer POIs, to reason over only spatial constraints. We then combine our spatial-reasoner with a textual reasoner in a joint model and present experiments on a real world POI recommendation task. We report substantial improvements over existing models without joint spatio-textual reasoning. To the best of our knowledge, we are the first to develop a joint QA model that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:_AeoHAGD03cC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:NMlhSUseqAsC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"Knowledge Base Completion (KBC) has been a very active area lately. Several recent KBCpapers propose architectural changes, new training methods, or even new formulations. KBC systems are usually evaluated on standard benchmark datasets: FB15k, FB15k-237, WN18, WN18RR, and Yago3-10. Most existing methods train with a small number of negative samples for each positive instance in these datasets to save computational costs. This paper discusses how recent developments allow us to use all available negative samples for training. We show that Complex, when trained using all available negative samples, gives near state-of-the-art performance on all the datasets. We call this approach COMPLEX-V2. We also highlight how various multiplicative KBC methods, recently proposed in the literature, benefit from this train-ing regime and become indistinguishable in terms of performance on most datasets. Our work calls for a reassessment of their individual value, in light of these findings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:c1e4I3QdEKYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"Pooling-based recurrent neural architectures consistently outperform their counterparts without pooling. However, the reasons for their enhanced performance are largely unexamined. In this work, we examine three commonly used pooling techniques (mean-pooling, max-pooling, and attention), and propose max-attention, a novel variant that effectively captures interactions among predictive tokens in a sentence. We find that pooling-based architectures substantially differ from their non-pooling equivalents in their learning ability and positional biases--which elucidate their performance benefits. By analyzing the gradient propagation, we discover that pooling facilitates better gradient flow compared to BiLSTMs. Further, we expose how BiLSTMs are positionally biased towards tokens in the beginning and the end of a sequence. Pooling alleviates such biases. Consequently, we identify settings where pooling offers large benefits: (i) in low resource scenarios, and (ii) when important words lie towards the middle of the sentence. Among the pooling techniques studied, max-attention is the most effective, resulting in significant performance gains on several text classification tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:EsEWqaRxkBgC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"Temporal knowledge bases associate relational (s,r,o) triples with a set of times (or a single time instant) when the relation is valid. While time-agnostic KB completion (KBC) has witnessed significant research, temporal KB completion (TKBC) is in its early days. In this paper, we consider predicting missing entities (link prediction) and missing time intervals (time prediction) as joint TKBC tasks where entities, relations, and time are all embedded in a uniform, compatible space. We present TIMEPLEX, a novel time-aware KBC method, that also automatically exploits the recurrent nature of some relations and temporal interactions between pairs of relations. TIMEPLEX achieves state-of-the-art performance on both prediction tasks. We also find that existing TKBC models heavily overestimate link prediction performance due to imperfect evaluation mechanisms. In response, we propose improved TKBC evaluation protocols for both link and time prediction tasks, dealing with subtle issues that arise from the partial overlap of time intervals in gold instances and system predictions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:QsKbpXNoaWkC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"State-of-the-art models for multi-hop question answering typically augment large-scale language models like BERT with additional, intuitively useful capabilities such as named entity recognition, graph-based reasoning, and question decomposition. However, does their strong performance on popular multi-hop datasets really justify this added design complexity? Our results suggest that the answer may be no, because even our simple pipeline based on BERT, named Quark, performs surprisingly well. Specifically, on HotpotQA, Quark outperforms these models on both question answering and support identification (and achieves performance very close to a RoBERTa model). Our pipeline has three steps: 1) use BERT to identify potentially relevant sentences independently of each other; 2) feed the set of selected sentences as context into a standard BERT span prediction model to choose an answer; and 3) use the sentence selection model, now with the chosen answer, to produce supporting sentences. The strong performance of Quark resurfaces the importance of carefully exploring simple model designs before using popular benchmarks to justify the value of complex techniques.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:Vr2j17o0sqMC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"While traditional systems for Open Information Extraction were statistical and rule-based, recently neural models have been introduced for the task. Our work builds upon CopyAttention, a sequence generation OpenIE model (Cui et. al., 2018). Our analysis reveals that CopyAttention produces a constant number of extractions per sentence, and its extracted tuples often express redundant information. We present IMoJIE, an extension to CopyAttention, which produces the next extraction conditioned on all previously extracted tuples. This approach overcomes both shortcomings of CopyAttention, resulting in a variable number of diverse extractions per sentence. We train IMoJIE on training data bootstrapped from extractions of several non-neural systems, which have been automatically filtered to reduce redundancy and noise. IMoJIE outperforms CopyAttention by about 18 F1 pts, and a BERT-based strong baseline by 2 F1 pts, establishing a new state of the art for the task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:jtI9f0ekYq0C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"State-of-the-art models for Knowledge Base Completion (KBC) are based on tensor factorization (TF), e.g, DistMult, ComplEx. While they produce good results, they cannot expose any rationale behind their predictions, potentially reducing the trust of a user in the model. Previous works have explored creating an inherently explainable model, e.g. Neural Theorem Proving (NTP), DeepPath, MINERVA, but explainability comes at the cost of performance. Others have tried to create an auxiliary explainable model having high fidelity with the underlying TF model, but unfortunately, they do not scale on large KBs such as FB15k and YAGO. In this work, we propose OxKBC -- an Outcome eXplanation engine for KBC, which provides a post-hoc explanation for every triple inferred by an (uninterpretable) factorization based model. It first augments the underlying Knowledge Graph by introducing weighted edges between entities based on their similarity given by the underlying model. In the augmented graph, it defines a notion of human-understandable explanation paths along with a language to generate them. Depending on the edges, the paths are aggregated into second-order templates for further selection. The best template with its grounding is then selected by a neural selection module that is trained with minimal supervision by a novel loss function. Experiments over Mechanical Turk demonstrate that users find our explanations more trustworthy compared to rule mining.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:LGlY6t8CeOMC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2020,"We present the novel task of understanding multi-sentence entity-seeking questions (MSEQs), that is, the questions that may be expressed in multiple sentences, and that expect one or more entities as an answer. We formulate the problem of understanding MSEQs as a semantic labeling task over an open representation that makes minimal assumptions about schema or ontology-specific semantic vocabulary. At the core of our model, we use a BiLSTM (bidirectional LSTM) conditional random field (CRF), and to overcome the challenges of operating with low training data, we supplement it by using BERT embeddings, hand-designed features, as well as hard and soft constraints spanning multiple sentences. We find that this results in a 12–15 points gain over a vanilla BiLSTM CRF. We demonstrate the strengths of our work using the novel task of answering real-world entity-seeking questions from the tourism …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:z6xuaG2dYH0C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2019,"Open Information Extraction (Open IE) systems have been traditionally evaluated via manual annotation. Recently, an automated evaluator with a benchmark dataset (OIE2016) was released–it scores Open IE systems automatically by matching system predictions with predictions in the benchmark dataset. Unfortunately, our analysis reveals that its data is rather noisy, and the tuple matching in the evaluator has issues, making the results of automated comparisons less trustworthy. We contribute CaRB, an improved dataset and framework for testing Open IE systems. To the best of our knowledge, CaRB is the first crowdsourced Open IE dataset and it also makes substantive changes in the matching code and metrics. NLP experts annotate CaRB’s dataset to be more accurate than OIE2016. Moreover, we find that on one pair of Open IE systems, CaRB framework provides contradictory results to OIE2016. Human assessment verifies that CaRB’s ranking of the two systems is the accurate ranking. We release the CaRB framework along with its crowdsourced dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:DyXnQzXoVgIC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2019,"We introduce the novel task of answering entity-seeking recommendation questions using a collection of reviews that describe candidate answer entities. We harvest a QA dataset that contains 47,124 paragraph-sized real user questions from travelers seeking recommendations for hotels, attractions and restaurants. Each question can have thousands of candidate answers to choose from and each candidate is associated with a collection of unstructured reviews. This dataset is especially challenging because commonly used neural architectures for reasoning and QA are prohibitively expensive for a task of this scale. As a solution, we design a scalable cluster-select-rerank approach. It first clusters text for each entity to identify exemplar sentences describing an entity. It then uses a scalable neural information retrieval (IR) module to select a set of potential entities from the large candidate set. A reranker uses a deeper attention-based architecture to pick the best answers from the selected entities. This strategy performs better than a pure IR or a pure attention-based reasoning approach yielding nearly 25% relative improvement in Accuracy@3 over both approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:silx2ntsSuwC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2019,"Neural planners for RDDL MDPs produce deep reactive policies in an offline fashion. These scale well with large domains, but are sample inefficient and time-consuming to train from scratch for each new problem. To mitigate this, recent work has studied neural transfer learning, so that a generic planner trained on other problems of the same domain can rapidly transfer to a new problem. However, this approach only transfers across problems of the same size. We present the first method for neural transfer of RDDL MDPs that can transfer across problems of different sizes. Our architecture has two key innovations to achieve size independence:(1) a state encoder, which outputs a fixed length state embedding by max pooling over varying number of object embeddings,(2) a single parameter-tied action decoder that projects object embeddings into action probabilities for the final policy. On the three challenging RDDL domains of SysAdmin, Game Of Life and Academic Advising, our approach powerfully transfers across problem sizes and has superior learning curves over training from scratch.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:D_tqNUsBuKoC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2019,"For several problems of interest, there are natural constraints which exist over the output label space. For example, for the joint task of NER and POS labeling, these constraints might specify that the NER label ‘organization’is consistent only with the POS labels ‘noun’and ‘preposition’. These constraints can be a great way of injecting prior knowledge into a deep learning model, thereby improving overall performance. In this paper, we present a constrained optimization formulation for training a deep network with a given set of hard constraints on output labels. Our novel approach first converts the label constraints into soft logic constraints over probability distributions outputted by the network. It then converts the constrained optimization problem into an alternating min-max optimization with Lagrangian variables defined for each constraint. Since the constraints are independent of the target labels, our framework easily generalizes to semi-supervised setting. We experiment on the tasks of Semantic Role Labeling (SRL), Named Entity Recognition (NER) tagging, and fine-grained entity typing and show that our constraints not only significantly reduce the number of constraint violations, but can also result in state-of-the-art performance",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:2v_ZtQDX9iAC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2019,"The Knowledge Base (KB) used for real-world applications, such as booking a movie or restaurant reservation, keeps changing over time. End-to-end neural networks trained for these task-oriented dialogs are expected to be immune to any changes in the KB. However, existing approaches breakdown when asked to handle such changes. We propose an encoder-decoder architecture (BoSsNet) with a novel Bag-of-Sequences (BoSs) memory, which facilitates the disentangled learning of the response's language model and its knowledge incorporation. Consequently, the KB can be modified with new knowledge without a drop in interpretability. We find that BoSsNet outperforms state-of-the-art models, with considerable improvements (> 10\%) on bAbI OOV test sets and other human-human datasets. We also systematically modify existing datasets to measure disentanglement and show BoSsNet to be robust to KB modifications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:65Yg0jNCQDAC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2019,"We present the novel task of understanding multi-sentence entity-seeking questions (MSEQs) ie, questions that may be expressed in multiple sentences, and that expect one or more entities as an answer. We formulate the problem of understanding MSEQs as a semantic labeling task over an open representation that makes minimal assumptions about schema or ontology specific semantic vocabulary. At the core of our model, we use a BiDiLSTM (bi-directional LSTM) CRF and to overcome the challenges of operating with low training data, we supplement it by using hand-designed features, as well as hard and soft constraints spanning multiple sentences. We find that this results in a 6-7pt gain over a vanilla BiDiL-STM CRF. We demonstrate the strengths of our work using the novel task of answering real-world entity-seeking questions from the tourism domain. The use of our labels helps answer 53% more questions with 42% more accuracy as compared to baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:U_HPUtbDl20C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2018,"We define the novel problem of extracting and predicting occurrence dates for a class of recurrent events that are held periodically as per a near-regular schedule (e.g., conferences, film festivals, sports championships). Knowledge-bases such as Freebase contain a large number of such recurring events, but they also miss substantial information regarding specific event instances and their occurrence dates. We develop a temporal extraction and inference engine to fill in the missing dates as well as to predict their future occurrences. Our engine performs joint inference over several knowledge sources - (1) information about an event instance and its date extracted from text by our temporal extractor, (2) information about the typical schedule (e.g., ""every second week of June"") for a recurrent event extracted by our schedule extractor, and (3) known dates for other instances of the same event. The output of our system …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:1Ye0OR6EYb4C,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2018,"This paper analyzes the varied performance of Matrix Factorization (MF) on the related tasks of relation extraction and knowledge-base completion, which have been unified recently into a single framework of knowledge-base inference (KBI) [Toutanova et al., 2015]. We first propose a new evaluation protocol that makes comparisons between MF and Tensor Factorization (TF) models fair. We find that this results in a steep drop in MF performance. Our analysis attributes this to the high out-of-vocabulary (OOV) rate of entity pairs in test folds of commonly-used datasets. To alleviate this issue, we propose three extensions to MF. Our best model is a TF-augmented MF model. This hybrid model is robust and obtains strong results across various KBI datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:6_hjMsCP8ZoC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2018,"One popular way for lifted inference in probabilistic graphical models is to first merge symmetric states into a single cluster (orbit) and then use these for downstream inference, via variations of orbital MCMC [Niepert, 2012]. These orbits are represented compactly using permutations over variables, and variable-value (VV) pairs, but they can miss several state symmetries in a domain. We define the notion of permutations over block-value (BV) pairs, where a block is a set of variables. BV strictly generalizes VV symmetries, and can compute many more symmetries for increasing block sizes. To operationalize use of BV permutations in lifted inference, we describe 1) an algorithm to compute BV permutations given a block partition of the variables, 2) BV-MCMC, an extension of orbital MCMC that can sample from BV orbits, and 3) a heuristic to suggest good block partitions. Our experiments show that BV-MCMC can mix much faster compared to vanilla MCMC and orbital MCMC.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:q-HalDI95KYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2018,"We observe that end-to-end memory networks (MN) trained for task-oriented dialogue, such as for recommending restaurants to a user, suffer from an out-ofvocabulary (OOV) problem–the entities returned by the Knowledge Base (KB) may not be seen by the network at training time, making it impossible for it to use them in dialogue. We propose a Hierarchical Pointer Memory Network (HyP-MN), in which the next word may be generated from the decode vocabulary or copied from a hierarchical memory maintaining KB results and previous utterances. Evaluating over the dialog bAbI tasks, we find that HyP-MN drastically outperforms MN obtaining 12% overall accuracy gains. Further analysis reveals that MN fails completely in recommending any relevant restaurant, whereas HyP-MN recommends the best next restaurant 80% of the time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:wKETBy42zhYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2018,"Domain-independent probabilistic planners input an MDP description in a factored representation language such as PPDDL or RDDL, and exploit the specifics of the representation for faster planning. Traditional algorithms operate on each problem instance independently, and good methods for transferring experience from policies of other instances of a domain to a new instance do not exist. Recently, researchers have begun exploring the use of deep reactive policies, trained via deep reinforcement learning (RL), for MDP planning domains. One advantage of deep reactive policies is that they are more amenable to transfer learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:OBSaB-F7qqsC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2018,"While crowdsourcing enables data collection at scale, ensuring high-quality data remains a challenge. In particular, effective task design underlies nearly every reported crowdsourcing success, yet remains difficult to accomplish. Task design is hard because it involves a costly iterative process: identifying the kind of work output one wants, conveying this information to workers, observing worker performance, understanding what remains ambiguous, revising the instructions, and repeating the process until the resulting output is satisfactory. To facilitate this process, we propose a novel meta-workflow that helps requesters optimize crowdsourcing task designs and Sprout, our open-source tool, which implements this workflow. Sprout improves task designs by (1) eliciting points of confusion from crowd workers, (2) enabling requesters to quickly understand these misconceptions and the overall space of questions, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:-7ulzOJl1JYC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2018,"State-of-the-art knowledge base completion (KBC) models predict a score for every known or unknown fact via a latent factorization over entity and relation embeddings. We observe that when they fail, they often make entity predictions that are incompatible with the type required by the relation. In response, we enhance each base factorization with two type-compatibility terms between entity-relation pairs, and combine the signals in a novel manner. Without explicit supervision from a type catalog, our proposed modification obtains up to 7% MRR gains over base models, and new state-of-the-art results on several datasets. Further analysis reveals that our models better represent the latent types of entities and their embeddings also predict supervised types better than the embeddings fitted by baseline models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:jFemdcug13IC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2018,"Machine learning in real-world high-skew domains is difficult, because traditional strategies for crowdsourcing labeled training examples are ineffective at locating the scarce minority-class examples. For example, both random sampling and traditional active learning (which reduces to random sampling when just starting) will most likely recover very few minority-class examples. To bootstrap the machine learning process, researchers have proposed tasking the crowd with finding or generating minority-class examples, but such strategies have their weaknesses as well. They are unnecessarily expensive in well-balanced domains, and they often yield samples from a biased distribution that is unrepresentative of the one being learned. This paper extends the traditional active learning framework by investigating the problem of intelligently switching between various crowdsourcing strategies for obtaining labeled training examples in order to optimally train a classifier. We start by analyzing several such strategies (eg, annotate an example, generate a minority-class example, etc.), and then develop a novel, skew-robust algorithm, called MB-CB, for the control problem. Experiments show that our method outperforms state-of-the-art GL-Hybrid by up to 14.3 points in F1 AUC, across various domains and class-frequency settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:CdxZDUztZiMC,http://www.cse.iitd.ac.in/~mausam
Mausam,"['Artificial Intelligence', 'Neuro-Symbolic AI', 'Planning under Uncertainty', 'Information Extraction', 'Knowledge Graph']",38,5538,2018,"We develop CALM, a coordination analyzer that improves upon the conjuncts identified from dependency parses. It uses a language model based scoring and several linguistic constraints to search over hierarchical conjunct boundaries (for nested coordination). By splitting a conjunctive sentence around these conjuncts, CALM outputs several simple sentences. We demonstrate the value of our coordination analyzer in the end task of Open Information Extraction (Open IE). State-of-the-art Open IE systems lose substantial yield due to ineffective processing of conjunctive sentences. Our Open IE system, CALMIE, performs extraction over the simple sentences identified by CALM to obtain up to 1.8 x yield with a moderate increase in precision compared to extractions from original sentences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5y4YmFcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=5y4YmFcAAAAJ:owLR8QvbtFgC,http://www.cse.iitd.ac.in/~mausam
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2023,"Change detection for aerial imagery involves locating and identifying changes associated with the areas of interest between co-registered bi-temporal or multi-temporal images of a geographical location. Farm ponds are man-made structures belonging to the category of minor irrigation structures used to collect surface run-off water for future irrigation purposes. Detection of farm ponds from aerial imagery and their evolution over time helps in land surveying to analyze the agricultural shifts, policy implementation, seasonal effects and climate changes. In this paper, we introduce a publicly available object detection and instance segmentation (OD/IS) dataset for localizing farm ponds from aerial imagery. We also collected and annotated the bi-temporal data over a time-span of 14 years across 17 villages, resulting in a binary change detection dataset called \textbf{F}arm \textbf{P}ond \textbf{C}hange \textbf{D}etection Dataset (\textbf{FPCD}). We have benchmarked and analyzed the performance of various object detection and instance segmentation methods on our OD/IS dataset and the change detection methods over the FPCD dataset. The datasets are publicly accessible at this page: \textit{\url{https://huggingface.co/datasets/ctundia/FPCD}}",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:70eg2SAEIzsC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2022,"Sustainable intensification (SI) of agriculture combines the dual goals of increasing productivity while staying within safe limits of resource use. In practice, how can thresholds which operate at resource scale guide intensification driven by social, economic and biophysical factors at the farm scale? In this paper, we present the case of agricultural intensification in the shallow hard-rock aquifer region of western India to illustrate how cross-scale feedback effects are crucial determinants of not only the resource sustainability and farm productivity but also of social dimensions of SI such as equity and justice. Supported by private investment in plastic-lined farm-ponds, the increasing shift to horticulture in the study area raises questions about the sustainability of the practice. We use a socio-hydrological lens and develop a system dynamics model to analyze how the growing technology-mediated intensification may lead …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:RGFaLdJalmkC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2021,"Deep learning has led to many recent advances in object detection and instance segmentation, among other computer vision tasks. These advancements have led to wide application of deep learning based methods and related methodologies in object detection tasks for satellite imagery. In this paper, we introduce MIS Check-Dam, a new dataset of check-dams from satellite imagery for building an automated system for the detection and mapping of check-dams, focusing on the importance of irrigation structures used for agriculture. We review some of the most recent object detection and instance segmentation methods and assess their performance on our new dataset. We evaluate several single stage, two-stage and attention based methods under various network configurations and backbone architectures. The dataset and the pre-trained models are available at https://www.cse.iitb.ac.in/gramdrishti/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:ns9cj8rnVeAC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2021,"Existing techniques for the cost optimization of water distribution networks either employ meta-heuristics, or try to develop problem-specific optimization techniques. Instead, we exploit recent advances in generic NLP solvers and explore a rich set of model refinement techniques. The networks that we study contain a single source and multiple demand nodes with residual pressure constraints. Indeterminism of flow values and flow direction in the network leads to non-linearity in these constraints making the optimization problem non-convex. While the physical network is cyclic, flow through the network is necessarily acyclic and thus enforces an acyclic orientation. We devise different strategies of finding acyclic orientations and explore the benefit of enforcing such orientations explicitly as a constraint. Finally, we propose a parallel link formulation that models flow in each link as two separate flows with opposing directions. This allows us to tackle numerical difficulties in optimization when flow in a link is near zero. We find that all our proposed formulations give results at par with least cost solutions obtained in the literature on benchmark networks. We also introduce a suite of large test networks since existing benchmark networks are small in size, and find that the parallel link approach outperforms all other approaches on these bigger networks, resulting in a more tractable technique of cost optimization.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:O3NaXMp0MMsC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2020,"We present a System Dynamics (SD) model of the Covid-19 pandemic spread in India. The detailed age-structured compartment-based model endogenously captures various disease transmission pathways, expanding significantly from the standard SEIR model. The model is customized for India by using the appropriate population pyramid, contact rate matrices, external arrivals (as per actual data), and a few other calibrated fractions based on the reported cases of Covid-19 in India. Also, we have explicitly modeled, using independent time-variant levers, the effects of testing, contact tracing, isolating Covid-positive patients, quarantining, use of mask/better hygiene practices, social distancing through contact rate reductions at distinct zones of home(H), work(W), school(S) and other(O) locations. Simulation results show that, even after an extended lock-down, some non-trivial number of infections (even asymptomatic) will be left and the pandemic will resurface. Only tools that work against the pandemic is high rate of testing of those who show Covid-19 like symptoms, isolating them if they are positive and contact tracing all contacts of positive patients and quarantining them, in combination with use of face masks and personal hygiene. A wide range of combination of effectiveness of contact tracing, isolation, quarantining and personal hygiene measures help minimize the pandemic impact and some imperfections in implementation of one measure can be compensated by better implementation of other measures.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:hMod-77fHWUC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2020,"Minor irrigation structures such as well and farm ponds play very important roles in agriculture growth in developing countries. Typically, a minor irrigation census is conducted every five years to take inventory of these structures. It is essential that an up to date database of these structures be maintained for planning and policy formulation purposes. In this work, we present the design and implementation of an online system for the automatic detection of irrigation structures from satellite images. Our system is built using three popular object detection architectures-YOLO, FasterRCNN and RetinaNet. Our system takes input at multiple resolutions and fragments and reassembles the input region to perform object detection. Since currently there exists no dataset for farm pond and the only publicly available well dataset covers a small geographical region, we have prepared object detection datasets for farm ponds and wells using Google Maps satellite images. We compare the performance of a number of state of the art object detection models and find that a clear trade-off exists between the detection accuracy and inference time with the RetinaNet providing a golden mean.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:GnPB-g6toBAC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2019,"The design of rural drinking water schemes consists of optimization of several network components like pipes, tanks, pumps and valves. The sizing and configuration of these network configurations need to be such that the water requirements are met while at the same time being cost efficient so as to be within government norms. We developed the JalTantra system to design such water distribution networks. The Integer Linear Program (ILP) model used in JalTantra and described in our previous work solved the problem optimally, but took a significant amount of time for larger networks—an hour for a network with 100 nodes. In this current work, we describe a series of three improvements of the model. We prove that these improvements result in tighter models, i.e. the set of points of linear relaxation is strictly smaller than the linear relaxation for the initial model. We test the series of three improved models along …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:bEWYMUwI8FkC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2019,"Government bodies responsible for drinking water distribution in India face the challenging task of designing schemes that provide a quality of service that is adequate to meet the needs of citizens at a cost below the strict government norms. Engineers at these government bodies must undertake the design process using tools that are not optimal and consider only pipe diameter selection, which is only one component of the entire scheme design. As such, much of the design process is undertaken in an ad hoc and heuristic manner, relying on the experience and intuition of the engineers. We developed JalTantra, a web system that aids these government engineers in sizing both pipe diameters and the various other water network components, such as tanks, pumps, and valves. We use an integer linear program model, which allows us to solve the problem optimally and quickly.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:M3NEmzRMIkIC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2019,"The Government of India conducts a well census every five years. It is time-consuming, costly, and usually incomplete. By using transfer learning-based object detection algorithms, we have built a system for the automatic detection of wells in satellite images. We analyze the performance of three object detection algorithms-Convolutional Neural Network, HaarCascade, and Histogram of Oriented Gradients on the task of well detection and find that the Convolutional Neural Network based YOLOv2 performs best and forms the core of our system. Our current system has a precision value of 0.95 and a recall value of 0.91 on our dataset. The main contribution of our work is to create a novel open-source system for well detection in satellite images and create an associated dataset which will be put in the public domain. A related contribution is the development of a general purpose satellite image annotation system to annotate and validate objects in satellite images. While our focus is on well detection, the system is general purpose and can be used for detection of other objects as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:YFjsv_pBGBYC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2019,"A holistic set of indicators using a stock and flow framework is used to assess farming practices across socio-economic and ecological dimensions. We design a methodology to estimate, normalize, and aggregate the indicators to form composite indices. The indicators under each dimension are aggregated using the progressive weighted average to give three-dimensional indices viz. economic, social, and ecological indices, which are aggregated to give a single holistic index called Farm Assessment Index (FAI). Unlike other approaches where the comparison of farming system is restricted within the sample under study, normalization of indicators using regional averages makes the FAI suitable for universal comparisons of farming systems across crops and regions. The methodology was applied to evaluate farming practices of 60 organic and 60 conventional farmers, from two Indian states over three years. The …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:NMxIlDl6LWMC,https://www.cse.iitb.ac.in/~damani/
Om P. Damani,"['System Dynamics', 'Technology for Development', 'Sustainable Development']",8,337,2018,"A national identity scheme has long-term and large-scale implications to the welfare of the people, efficiency of governance and law enforcement, individuals’ fundamental right to privacy and national security. Motivated by several issues surfaced by the implementation of Aadhaar, and several privacy and security concerns that have been pointed out, we develop a (non-exhaustive) list of technical guidelines for national identity schemes. We observe that the current Aadhaar design significantly deviates from these guidelines, strongly suggesting that to address the root causes of the issues that have manifested so far, many parts of the system require major redesign. We also put forth several policy guidelines, which we believe are crucial to the success of a national identity scheme in India.
Digital technology is a powerful tool, and India, like any other modern nation, can ill afford to keep away from exploiting the promises it offers. Yet, one needs to wield this technology with caution, like a scalpel rather than a sledge hammer, especially when it is applied at a national scale and affects millions of the poorest and most vulnerable. One should also bear in mind that any cyber infrastructure that is being developed today will become targets for cyber warfare in the future.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=oEuni4IAAAAJ&sortby=pubdate&citation_for_view=oEuni4IAAAAJ:blknAaTinKkC,https://www.cse.iitb.ac.in/~damani/
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2023,"Fracture produces new mesh fragments that introduce additional degrees of freedom in the system dynamics. Existing finite element method (FEM) based solutions suffer from increasing computational cost as the system matrix size increases. We solve this problem by presenting a graph‐based FEM model for fracture simulation that is remeshing‐free and easily scales to high‐resolution meshes. Our algorithm models fracture on the graph induced in a volumetric mesh with tetrahedral elements. We relabel the edges of the graph using a computed damage variable to initialize and propagate fracture. We prove that non‐linear, hyper‐elastic strain energy density is expressible entirely in terms of the edge lengths of the induced graph. This allows us to reformulate the system dynamics for the relabelled graph without changing the size of the system dynamics matrix and thus prevents the computational cost from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:ns9cj8rnVeAC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2022,Fracture simulation of real-world materials is an exceptionally challenging problem due to complex material properties like anisotropic elasticity and the presence of material impurities. We present a graph-based finite element method to simulate dynamic fracture in anisotropic materials. We further enhance this model by developing a novel probabilistic damage mechanics for modelling materials with impurities using a random graph-based formulation. We demonstrate how this formulation can be used by artists for directing and controlling fracture. We simulate and render fractures for a diverse set of materials to demonstrate the potency and robustness of our methods.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:O3NaXMp0MMsC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2022,"When an object breaks, simulating evolution of fracture as per artist control while maintaining physical realism and plausibility is a challenging problem due to different complex material properties of real world objects. In this work, we present impurity maps as a way to guide fracture paths for both brittle and ductile fracture. We develop a novel probabilistic damage mechanics to model fracture in materials with impurities, using a random graph-based formulation in conjunction with graph-based FEM. An artist created map allows us to selectively distribute the impurities in the material, to weaken the object in those specific regions where the imperfections are added. During simulation, the presence of impurities guide the cracks that develop such that the fracture pattern closely follows the impurity map. We simulate artist-controlled fractures on different materials to demonstrate the potency of our method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:BqipwSGYUEgC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2022,"The accuracy of hand pose and shape recovery algorithms depends on how closely the geometric hand model resembles the user’s hand. Most existing methods rely on learned shape space, e.g. MANO; but this shape model fails to generalize to unseen hand shapes with large deviations from the training set. We introduce a new hand shape model, aMANO, that augments MANO by introducing local scale adaptation that enables modeling substantially different hand sizes. We use both MANO and aMANO for calibrating the shape to new users from a stream of depth images and observe the improvement of aMANO over MANO. We believe that our new hand shape model is a significant step in improving the robustness and accuracy of existing hand tracking solutions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:YFjsv_pBGBYC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2022,"Sculpting is an art form that relies on both the visual and tactile senses. A faithful simulation of sculpting, therefore, requires interactive, physically accurate haptic and visual feedback. We present an interactive physics-based sculpting framework with faithful haptic feedback. We enable cutting of the material by designing a stable, remeshing-free cutting algorithm called Improved stable eXtended Finite Element Method. We present a simulation framework to enable stable visual and haptic feedback at interactive rates. We evaluate the performance of our framework quantitatively and quantitatively through an extensive user study.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:JV2RwH3_ST0C,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2022,Our first approach is based on linearization of the hyper-elastic strain energy first and then projecting out stresses along the fractured edges; and finally weakening just the fractured edges similar to [Khodabakhshi et al. 2016]. The residual stress continues working on the remaining intact edges. The fracture simulation results using this approach are presented in Figure 1.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:RYcK_YlVTxYC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2022,"The accuracy of hand tracking algorithms depends on how closely the geometry of the mesh model resembles the user’s hand shape. Most existing methods rely on a learned shape space model; however, this fails to generalize to unseen hand shapes with significant deviations from the training set. We introduce local scale adaptation to augment this data-driven shape model and thus enable modeling hands of substantially different sizes. We also present a framework to calibrate our proposed hand shape model by registering it to depth data and achieve accurate and robust tracking. We demonstrate the capability of our proposed adaptive shape model over the most widely used existing hand model by registering it to subjects from different demographics. We also validate the accuracy and robustness of our tracking framework on challenging public hand datasets where we improve over state-of-the-art methods. Our adaptive hand shape model and tracking framework offer a significant boost towards generalizing the accuracy of hand tracking.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:NaGl4SEjCO4C,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2022,"We present a deep neural framework that allows users to create surfaces from a stream of sparse 3D sketch strokes. Our network consists of a global surface estimation module followed by a local surface refinement. This facilitates in the incremental prediction of surfaces. Thus, our proposed method works with 3D sketch strokes and estimate a surface interactively in real time. We compare the proposed method with various state-of-the-art methods and show its efficacy for surface fitting. Further, we integrate our method into an existing Blender based 3D content creation pipeline to show its usefulness in 3D modeling.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:GnPB-g6toBAC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2021,"We present a physics-based framework to simulate porous, deformable materials and interactive tools with haptic feedback that can reshape it. In order to allow the material to be moulded non-homogeneously, we propose an algorithm to change the material properties of the object depending on its water content. We present a multi-resolution, multi-timescale simulation framework to enable stable visual and haptic feedback at interactive rates. We test our model for physical consistency, accuracy, interactivity and appeal through a user study and quantitative performance evaluation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:maZDTaKrznsC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2021,"We present a CATALIST model that ‘tames’ the attention (heads) of an attention-based scene text recognition model. We provide supervision to the attention masks at multiple levels, i.e., line, word, and character levels while training the multi-head attention model. We demonstrate that such supervision improves training performance and testing accuracy. To train CATALIST and its attention masks, we also present a synthetic data generator ALCHEMIST that enables the synthetic creation of large scene-text video datasets, along with mask information at character, word, and line levels. We release a real scene-text dataset of 2k videos,  with videos of real scenes that potentially contain scene-text in a combination of three different languages, namely, English, Hindi, and Marathi. We record these videos using 5 types of camera transformations - (i) translation, (ii) roll, (iii) tilt, (iv) pan, and (v) zoom to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:k_IJM867U9cC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2021,"Fracture of solid objects produces debris. Modelling the physics that produces the broken fragments from the original solid requires an increase in the number of degrees of freedom. This causes a huge increase in computational cost for FEM based methods used to model such phenomena. We present a graph-based FEM method that tackles this issue by relabeling the edges of the graph induced in a volumetric mesh, using a damage variable. We reformulate the system dynamics for this relabelled graph in order to simulate the fracture mechanics using FEM without an explosion in the computation cost. Our method therefore requires no remeshing of the volumetric mesh used for computation and this makes it very scalable to high-resolution meshes. We demonstrate that the method can simulate both brittle and ductile fracture.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:isC4tDSrTZIC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2021,"Fracture produces new mesh fragments that introduce additional degrees of freedom in the system dynamics. Existing finite element method (FEM) based solutions suffer from an explosion in computational cost as the system matrix size increases. We solve this problem by presenting a graph-based FEM model for fracture simulation that is remeshing-free and easily scales to high-resolution meshes. Our algorithm models fracture on the graph induced in a volumetric mesh with tetrahedral elements. We relabel the edges of the graph using a computed damage variable to initialize and propagate fracture. We prove that non-linear, hyper-elastic strain energy is expressible entirely in terms of the edge lengths of the induced graph. This allows us to reformulate the system dynamics for the relabeled graph without changing the size of system dynamics matrix and thus prevents the computational cost from blowing up. The fractured surface has to be reconstructed explicitly only for visualization purposes. We simulate standard laboratory experiments from structural mechanics and compare the results with corresponding real-world experiments. We fracture objects made of a variety of brittle and ductile materials, and show that our technique offers stability and speed that is unmatched in current literature.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:TFP_iSt0sucC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2021,"General relativity describes the curvature of spacetime. Rays of light follow geodesic paths in curved spacetime. Visualizing scenes containing spacetime regions with pronounced curvature requires tracing of these light ray paths. We present a monte carlo approach for non-linear raytracing to render scenes in curved spacetime. In contrast to earlier work, we can accurately resolve ray-object interactions. This allows us to create plausible visualizations of what happens when a black hole appears in a more known environment, like a room with regular specular and diffuse surfaces. We demonstrate that our solution is correct at cosmological scales by showing how spacetime warps around a stationary schwarzschild black hole and a non-stationary kerr black hole. We verify that the solution is consistent with the predictions of general relativity. In the absence of any curvature in spacetime, our renderer behaves like a normal linear ray tracer. Our method has the potential to create rich, physically plausible visualizations of complex phenomena that can be used for a range of purposes, from creating visual effects to making pedagogical aids to understand the behaviour of spacetime as predicted by general relativity. Copyright © 2021 by scitepress – science and technology publications, lda. All rights reserved",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:70eg2SAEIzsC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2020,"Sketching is one of the most natural ways for representing any object pictorially. It is however, challenging to convert sketches to 3D content that is suitable for various applications like movies, games and computer aided design. With the advent of more accessible Virtual Reality (VR) and Augmented Reality (AR) technologies, sketching can potentially become a more powerful yet easy‐to‐use modality for content creation. In this state‐of‐the‐art report, we aim to present a comprehensive overview of techniques related to sketch based content creation, both on the desktop and in VR/AR. We discuss various basic concepts related to static and dynamic content creation using sketches. We provide a structured review of various aspects of content creation including model generation, coloring and texturing, and finally animation. We try to motivate the advantages that VR/AR based sketching techniques and systems can …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:r0BpntZqJG4C,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2020,"Sanskrit OCR documents have a lot of errors. Correcting those errors using conventional spell-checking approaches breaks down due to the limited vocabulary. This is because of high inflections of Sanskrit, where words are dynamically formed by Sandhi rules, Samāsa rules, Taddhita affixes, etc. Therefore, correcting OCR documents require huge efforts. In this paper, we present different machine learning approaches and various ways to improve features for ameliorating the error corrections in Sanskrit OCR documents. We simulated Subanta Prakaraṇam of VaiyākaraṇaSiddhāntaKaumudī for synthesizing off-the-shelf dictionary. Most of the methods we propose can also work for general Sanskrit word corrections.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:TQgYirikUcIC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2019,"Obtaining a high-quality OCR output in smart cities, with human-in-the-loop, is an interesting problem for surveillance and other similar applications. Achieving high accuracy while reading license plates in the real world videos is cumbersome due to complexities like multiple vehicles, high-density traffic in spatial and temporal domains, varying camera angles and illumination, occlusions and multiple resolutions. We present a modular framework for OCR corrections in the chaotic Indian traffic videos that especially involve complex license plate patterns. Such patterns are obtained from a state-of-the-art deep learning model trained on video frames. Since such a model reads the text from videos (instead of images), we incorporate multi-frame consensus for generating suggestions in our framework. To ease the correction process, our human-interactive framework first breaks down the multi-vehicle videos into …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:RHpTSmoSYBkC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2019,"We work on the problem of recognizing license plates and street signs automatically in challenging conditions such as chaotic traffic. We leverage state-of-the-art text spotters to generate a large amount of noisy labeled training data. The data is filtered using a pattern derived from domain knowledge. We augment training and testing data with interpolated boxes and annotations that makes our training and testing robust. We further use synthetic data during training to increase the coverage of the training data. We train two different models for recognition. Our baseline is a conventional Convolution Neural Network (CNN) encoder followed by a Recurrent Neural Network (RNN) decoder. As our first contribution, we bypass the detection phase by augmenting the baseline with an Attention mechanism in the RNN decoder. Next, we build in the capability of training the model end-to-end on scenes containing license …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:4JMBOYKVnBMC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2019,"Texts in Indic Languages contain a large proportion of out-of-vocabulary (OOV) words due to frequent fusion using conjoining rules (of which there are around 4000 in Sanskrit). OCR errors further accentuate this complexity for the error correction systems. Variations of sub-word units such as n-grams, possibly encapsulating the context, can be extracted from the OCR text as well as the language text individually. Some of the sub-word units that are derived from the texts in such languages highly correlate to the word conjoining rules. Signals such as frequency values (on a corpus) associated with such sub-word units have been used previously with log-linear classifiers for detecting errors in Indic OCR texts. We explore two different encodings to capture such signals and augment the input to Long Short Term Memory (LSTM) based OCR correction models, that have proven useful in the past for jointly learning the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:e5wmG9Sq2KIC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2019,"We present an unsupervised incremental learning method for refining hand shape and pose estimation. We propose a refiner network (RefNet) that can augment a state-of-the-art hand tracking system (BaseNet) by refining its estimations on unlabeled data. At each input depth frame, the estimations from the BaseNet are iteratively refined by RefNet using a model-fitting strategy. During this process, the RefNet adapts to the input data characteristics by incremental learning. We show that our method provides more accurate hand shape and pose estimates on both a standard dataset and real data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:_Qo2XoVZTnwC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2018,"We present a reduced model based on position based dynamics for real-time simulation of human musculature. We demonstrate our methods on the muscles of the human arm. Co-simulation of all the muscles of the human arm allow us to accurately track the development of stresses and strains in the muscles, when the arm is moved. We evaluate our method for accuracy by comparing it with gold standard simulation models based on finite volume methods, and demonstrate the stability of the method under flexion, extension and torsion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:R3hNpaxXUhUC,http://www.cse.iitb.ac.in/~paragc
Parag Chaudhuri,"['Animation', 'Computer Graphics', 'Computer Vision', 'Virtual and Augmented Reality']",7,208,2018,"We present an intuitive method to create 2D hand-drawn character animation suitable for novice animators. Given the 2D model sheet of the character that shows how the character looks from the front and side, our method can generate sketched views of the character from any direction, using the sketch stroke style used in the model sheet. Subsequently, our system can generate an animation of the character using motion capture data, and render it using the same sketched strokes. Our method is not only able to reproduce the sketch stroke style, but also the colours and other character details that the animator adds to the model sheet. The method can resolve occlusion correctly, both due to moving body parts and change in orientation of the character with respect to the camera. The animator can interactively change the sketch style, colours or other details, at any frame, as required. The animation generated by our method has the fluid style of hand sketched animation, and provides a very good starting point for novice animators that can be then improved to create the final, desired animation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kOkSgaMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kOkSgaMAAAAJ:HDshCWvjkbEC,http://www.cse.iitb.ac.in/~paragc
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2022,"The propensity of task-based functional magnetic resonance imaging (T-fMRI) to large physiological fluctuations, measurement noise, and imaging artifacts entail longer scans and higher temporal resolution (trading off spatial resolution) to alleviate the effects of degradation. This paper focuses on methods towards reducing scan times and enabling higher spatial resolution in T-fMRI. We propose a novel mixed-dictionary model combining (i) the task-based design matrix,(ii) a learned dictionary from resting-state fMRI, and (iii) an analytically-defined wavelet frame. For model fitting, we propose a novel adaptation of the inference framework relying on variational Bayesian expectation maximization with nested minorization. We leverage the mixed-dictionary model coupled with variational inference to enable 2× shorter scan times in T-fMRI, improving activation-map estimates towards the same quality as those …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:kRWSkSYxWN8C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2022,"One-class classification (OCC) methods for abnormality detection learn either a generative model of the inlier class (e.g., using variants of kernel principal component analysis) or a decision boundary to encapsulate the inlier class (e.g., using one-class variants of the support vector machine). Recent methods use deep-neural-network models to learn (for the inlier class) either latent-space distributions or autoencoders, but not both. OCC learning typically relies solely on inlier-class data, but some recent semi-supervised versions also leverage some outlier-class training data. We propose a robust and uncertainty-aware variational framework for OCC, leveraging data-adaptive generalized-Gaussian (GG) models leading to distribution modeling in both latent space and image space. We propose a reparameterization for samples from the latent-space GG to enable backpropagation. Results on publicly available real …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:J-pR_7NvFogC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2022,"Reducing the dose of ionizing radiation underlying combined imaging with positron emission tomography (PET) and computed tomography (CT) typically leads to reduced image quality. We propose a novel variational deep-neural-network (DNN) framework for image quality enhancement of low-dose PET-CT images, relying on Monte-Carlo expectation maximization. Unlike existing DNN-based training that pairs low-dose PET-CT images with their corresponding high-dose versions, we propose a semi-supervised learning framework that enables learning using a small number of high-dose images. We propose a robust and uncertainty-aware loss motivated by a heavy-tailed generalized-Gaussian distribution on the residuals between the DNN output and the PET-CT data, aiding our semi-supervised learning scheme. Results on publicly available data show the benefits of our framework, quantitatively and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:1qzjygNMrQYC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2022,"Anomaly detection is a one-class classification (OCC) problem where the methods learn either a generative model of the inlier class (eg, in the variants of kernel principal component analysis) or a decision boundary to encapsulate the inlier class (eg, in the one-class variants of the support vector machine). Learning schemes for OCC typically rely on training data solely from the inlier class, but some recent approaches have proposed semi-supervised extensions, eg, variants of semi-supervised anomaly detection that also leverage a small amount of training data from outlier classes. Other recent methods extend existing principles to employ deep neural network (DNN) modeling that relies on learning (for the inlier class) either latent-space distributions or autoencoders, but not both. We propose a novel semi-supervised variational formulation, leveraging generalized-Gaussian models leading to data-adaptive, robust, and uncertainty-aware distribution modeling in both latent space and image space. For variational learning, we propose a novel reparameterization for sampling from the latent-space generalized-Gaussian to enable backpropagation-based optimization. Results on several public image sets show the benefits of our method over state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:BrmTIyaxlBUC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"Radiation exposure in positron emission tomography (PET) imaging limits its usage in the studies of radiation-sensitive populations, e.g., pregnant women, children, and adults that require longitudinal imaging. Reducing the PET radiotracer dose or acquisition time reduces photon counts, which can deteriorate image quality. Recent deep-neural-network (DNN) based methods for image-to-image translation enable the mapping of low-quality PET images (acquired using substantially reduced dose), coupled with the associated magnetic resonance imaging (MRI) images, to high-quality PET images. However, such DNN methods focus on applications involving test data that match the statistical characteristics of the training data very closely and give little attention to evaluating the performance of these DNNs on new out-of-distribution (OOD) acquisitions. We propose a novel DNN formulation that models the (i …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:eJXPG6dFmWUC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"Typical deep-neural-network (DNN) based generative image models often (i) show limited ability to learn a disentangled latent representation, (ii) show limited controllability leading to undesirable side effects when manipulating selected attributes during image generation, and (iii) require large attribute-annotated training sets. We propose a generative DNN model for face images by explicitly disentangling geometry and appearance modeling to achieve selective controllability of the desired attributes with less side effects. To learn geometric variability, we leverage grayscale sketch representations to learn (i) a deformable mean template representing the population-mean face geometry and (ii) a generative model of deformations to model individual face-geometry variations, using dense image registration. We learn the appearance variability in a (color-image) space that we explicitly design by factoring out the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:B3FOqHPlNUQC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"Resting-state functional magnetic resonance imaging (R-fMRI) applications can entail a higher temporal-sampling rate that trades off spatial resolution, thereby challenging effective scientific studies. To enable higher spatial resolution, current schemes speedup per-timeframe scanning by reconstruction from simultaneous multislice (SMS) magnetic resonance imaging (MRI) with k-space undersampling (sometimes temporal undersampling), while using prior models on the signal. We propose a novel algorithmic framework to reconstruct R-fMRI (SMS with controlled aliasing) that has, both, k-space undersampling and temporal undersampling. We propose a coupled spatiotemporal sparse model, incorporating (i) a robust spatially-regularized temporal-dictionary prior and (ii) a spatiotemporal wavelet prior, which we fit efficiently using variational Bayesian expectation maximization with nested minorization (VBEMNM …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:D_sINldO8mEC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"Functional positron emission tomography (fPET) imaging using continuous infusion of [18F]-fluorodeoxyglucose (FDG) is a novel neuroimaging technique to track dynamic glucose utilization in the brain. In comparison to conventional static or dynamic bolus PET, fPET maintains a sustained supply of glucose in the blood plasma which improves sensitivity to measure dynamic glucose changes in the brain, and enables mapping of dynamic brain activity in task-based and resting-state fPET studies. However, there is a trade-off between temporal resolution and spatial noise due to the low concentration of FDG and the limited sensitivity of multi-ring PET scanners. Images from fPET studies suffer from partial volume errors and residual scatter noise that may cause the cerebral metabolic functional maps to be biased. Gaussian smoothing filters used to denoise the fPET images are suboptimal, as they introduce additional …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:4fKUyHm3Qg0C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"We introduce a machine learning-based method for fully automated diagnosis of sickle cell disease of poor-quality unstained images of a mobile microscope. Our method is capable of distinguishing between diseased, trait (carrier), and normal samples unlike the previous methods that are limited to distinguishing the normal from the abnormal samples only. The novelty of this method comes from distinguishing the trait and the diseased samples from challenging images that have been captured directly in the field. The proposed approach contains two parts, the segmentation part followed by the classification part. We use a random forest algorithm to segment such challenging images acquitted through a mobile phone-based microscope. Then, we train two classifiers based on a random forest (RF) and a support vector machine (SVM) for classification. The results show superior performances of both of the classifiers not only for images which have been captured in the lab, but also for the ones which have been acquired in the field itself.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:LPZeul_q3PIC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"Current approaches for semantic image inpainting rely on deep neural networks (DNNs) that learn under full supervision, i.e., using a training set comprising pairs of (i) corrupted images with holes and (ii) corresponding uncorrupted images. However, for several real-world applications, obtaining large sets of uncorrupted images is challenging or infeasible. Current methods also rely on adversarial training involving min-max optimization that is prone to instability during learning. We propose a novel self-supervised image-inpainting DNN framework that can learn in both completely unsupervised and semi-supervised modes. Moreover, our DNN learning formulation bypasses adversarial training and, thereby, lends itself to more stable training. Results on the publicly available CelebA dataset show that our method, even when learning unsupervisedly, outperforms the state of the art that learns with full supervision.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:8AbLer7MMksC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"Deep neural networks (DNNs) for nonlinear generative mixture modeling typically rely on unsupervised learning that employs hard clustering schemes, or variational learning with loose / approximate bounds, or under-regularized modeling. We propose a novel statistical framework for a DNN mixture model using a single generative adversarial network. Our learning formulation proposes a novel data-likelihood term relying on a well-regularized / constrained Gaussian mixture model in the latent space along with a prior term on the DNN weights. Our min-max learning increases the data likelihood using a tight variational lower bound using expectation maximization (EM). We leverage our min-max EM learning scheme for semi-supervised learning. Results on three real-world image datasets demonstrate the benefits of our compact modeling and learning formulation over the state of the art for nonlinear generative …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:geHnlv5EZngC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"Undersampled reconstruction in resting functional magnetic resonance imaging (R-fMRI) holds the potential to enable higher spatial resolution in brain R-fMRI without increasing scan duration. We propose a novel approach to reconstruct kt undersampled R-fMRI relying on a deep convolutional neural network (CNN) framework. The architecture of our CNN framework comprises a novel scheme for R-fMRI reconstruction that jointly learns two multilayer CNN components for (i) explicitly filling in missing k-space data, using acquired data in frequency-temporal neighborhoods, and (ii) image quality enhancement in the spatiotemporal domain. The architecture sandwiches the Fourier transformation from the frequency domain to the spatial domain between the two aforementioned CNN components, during, both, CNN learning and inference. We propose four methods within our framework, including a Bayesian CNN …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:sSrBHYA8nusC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"Image-to-image translation is an ill-posed problem as unique one-to-one mapping may not exist between the source and target images. Learning-based methods proposed in this context often evaluate the performance on test data that is similar to the training data, which may be impractical. This demands robust methods that can quantify uncertainty in the prediction for making informed decisions, especially for critical areas such as medical imaging. Recent works that employ conditional generative adversarial networks (GANs) have shown improved performance in learning photo-realistic image-to-image mappings between the source and the target images. However, these methods do not focus on (i) robustness of the models to out-of-distribution (OOD)-noisy data and (ii) uncertainty quantification. This paper proposes a GAN-based framework that (i) models an adaptive loss function for robustness to OOD-noisy data that automatically tunes the spatially varying norm for penalizing the residuals and (ii) estimates the per-voxel uncertainty in the predictions. We demonstrate our method on two key applications in medical imaging:(i) undersampled magnetic resonance imaging (MRI) reconstruction (ii) MRI modality propagation. Our experiments with two different real-world datasets show that the proposed method (i) is robust to OOD-noisy test data and provides improved accuracy and (ii) quantifies voxel-level uncertainty in the predictions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:eflP2zaiRacC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2021,"Typical methods for semantic image segmentation rely on large training sets comprising pixel-level segmentations and pixel-level classifications. In medical applications, a large number of training images with per-pixel segmentations are difficult to obtain. In addition, many applications involve images or image tiles containing a single object/region of interest, where the image/tile-level information about object/region class is readily available. We propose a novel deep-neural-network (DNN) framework for joint segmentation and recognition of objects relying on weakly-supervised learning from training sets having very few expert segmentations, but with object-class labels available for all images/tiles. For weakly-supervised learning, we propose a variational-learning framework relying on Monte Carlo expectation maximization (MCEM), inferring a posterior distribution on the missing segmentations. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:VOx2b1Wkg3QC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2020,"Higher spatial resolution in resting-state functional magnetic resonance imaging (R-fMRI) can give reliable information about the functional networks in the cerebral cortex. Typical methods can achieve higher spatial or temporal resolution by speeding up scans using either (i) complex pulse-sequence designs or (ii) k-space undersampling coupled with priors on the signal. We propose to undersample the R-fMRI acquisition in k-space and time to speedup scans in order to improve spatial resolution. We propose a novel model-based R-fMRI reconstruction framework using a robust, subject-invariant, spatially regularized dictionary prior on the signal. Furthermore, we propose a novel inference framework based on variational Bayesian expectation maximization with nested minorization (VB-EM-NM). Our inference framework allows us to provide an estimate of uncertainty of the reconstruction, unlike typical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:K3LRdlH-MEoC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2020,"Functional positron emission tomography (fPET) imaging using continuous infusion of [18F]-fluorodeoxyglucose (FDG) is a novel neuroimaging technique to track dynamic glucose utilization in the brain. In comparison to conventional static PET, fPET maintains a sustained supply of glucose in the blood plasma which improves sensitivity to measure dynamic glucose changes in the brain, and enables mapping of dynamic brain activity in task-based and resting-state fPET studies. However, there is a trade-off between temporal resolution and spatial noise due to the low concentration of FDG and the limited sensitivity of multi-ring PET scanners. Images from fPET studies suffer from partial volume errors and residual scatter noise that may cause the cerebral metabolic functional maps to be biased. Gaussian smoothing filters used to denoise the fPET images are suboptimal, as they introduce additional partial volume errors. In this work, a post-processing framework based on a magnetic resonance (MR) Bowsher-like prior was used to improve the spatial and temporal signal to noise characteristics of the fPET images. The performance of the MR guided method was compared with conventional Gaussian filtering using both simulated and in vivo task fPET datasets. The results demonstrate that the MR guided fPET framework reduces the partial volume errors, enhances the sensitivity of identifying brain activation, and improves the anatomical accuracy for mapping changes of brain metabolism in response to a visual stimulation task. The framework extends the use of functional PET to investigate the dynamics of brain metabolic responses for faster …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2020,"For simultaneous positron-emission-tomography and magnetic-resonance-imaging (PET-MRI) systems, while early methods relied on independently reconstructing PET and MRI images, recent works have demonstrated improvement in image reconstructions of both PET and MRI using joint reconstruction methods. The current state-of-the-art joint reconstruction priors rely on fine-scale PET-MRI dependencies through the image gradients at corresponding spatial locations in the PET and MRI images. In the general context of image restoration, compared to gradient-based models, patch-based models (e.g., sparse dictionaries) have demonstrated better performance by modeling image texture better. Thus, we propose a novel joint PET-MRI patch-based dictionary prior that learns inter-modality higher-order dependencies together with intra-modality textural patterns in the images. We model the joint-dictionary prior …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:u9iWguZQMMsC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2020,"Accelerated resting-state functional magnetic resonance imaging (R-fMRI) can provide higher spatial resolution and improved brain connectivity maps. Current methods for fast R-fMRI rely on either fully-sampled parallel imaging or undersampled reconstruction using signal priors, but not both. We propose a novel Bayesian reconstruction framework that combines simultaneous multislice (SMS) imaging, controlled aliasing, and undersampling in k-space and time to reconstruct high-quality signals and connectivity maps. We use a generative dictionary model on R-fMRI time-series, which is robust to signal fluctuations and artifacts, adapts to inter-subject variations through optimized similarity transforms on its atoms, and uses spatially regularized sparsity. Results on simulated and clinical R-fMRI show that our method gives more accurate reconstructions and connectivity maps than the state of the art, and can enable …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:WbkHhVStYXYC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2020,"Statistical shape priors can be crucial in segmenting objects when the data differentiates poorly between the object and its surroundings. For reliable learning, while some methods need high-quality expert segmentations, other methods need large training sets, both of which can often be difficult to obtain in clinical deployment or scientific studies. We propose to couple deep neural networks with a pointset-based shape prior that can be learned effectively despite training sets having small size and imperfections in expert curation. The prior relies on sparse Riemannian modeling in Kendall shape space. Results on clinical brain magnetic resonance imaging data show that our framework improves over the state of the art in segmenting the thalamus and the caudate.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:Tiz5es2fbqcC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2020,"Abnormality detection in medical images is a one-class classification problem for which existing methods typically involve variants of kernel principal component analysis or one-class support vector machines. However, existing methods rely on highly-curated training sets with full supervision, often using heuristics for model fitting or ignore the variances of the data within principal subspaces. In contrast, we propose novel methods that can work with imperfectly curated datasets using robust statistical learning, by extending the multivariate generalized-Gaussian distribution to a reproducing kernel Hilbert space (RKHS) and employing it within a mixture model. We propose a novel semi-supervised extension of our learning scheme, showing that a small amount of expert feedback through high-quality labeled data of the outlier class can boost performance. We propose expectation maximization for our semi-supervised …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:XiSMed-E-HIC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2020,"Uncertainty quantification in medical imaging is critical for clinical translation of deep learningbased methods. Modality propagation within the context of medical imaging is a problem of interest, both across as well as within modalities. For magnetic resonance imaging (MRI), often, multicontrast MRI images are acquired for improved diagnosis and prognosis. In this work, we focus on the synthesis of T2w MRI images from T1w MRI images. Prior works used generative adversarial networks (GANs), but lack (i) uncertainty quantification,(ii) evaluating the robustness of the network to out-of-distribution data (common in medical imaging). We propose a robust GAN framework that incorporates uncertainty quantification using quasi-norm based penalties, and also show the efficacy of the method on unseen systemic and physiological perturbations on a large publicly available multimodal MRI dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:08ZZubdj9fEC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"Simultaneous positron emission tomography (PET) and magnetic resonance imaging (MRI) provide complementary information about brain function and structure. Joint reconstruction of MRI and PET images can improve image quality in both modalities, potentially enabling faster MRI and lower-dose PET scans. Current methods for joint MRI-PET reconstruction use priors that model inter-modality dependencies in image gradients. Many methods also ignore the potential in parallel MRI for acceleration. In contrast, we combine accelerated parallel MRI with a joint MRI-PET patch-based dictionary model to infer higher-order dependencies across MRI and PET image neighborhoods. We propose a novel Bayesian framework for joint MRI-PET reconstruction. The results show that our method reconstructs images more accurately, in simulated and in vivo MRI-PET (in parallel MRI) cases, than the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:nb7KW1ujOQ8C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"Deep neural networks for image quality enhancement typically need large quantities of highly-curated training data comprising pairs of low-quality images and their corresponding high-quality images. While high-quality image acquisition is typically expensive and time-consuming, medium-quality images are faster to acquire, at lower equipment costs, and available in larger quantities. Thus, we propose a novel generative adversarial network (GAN) that can leverage training data at multiple levels of quality (e.g., high and medium quality) to improve performance while limiting costs of data curation. We apply our mixed-supervision GAN to (i) super-resolve histopathology images and (ii) enhance laparoscopy images by combining super-resolution and surgical smoke removal. Results on large clinical and pre-clinical datasets show the benefits of our mixed-supervision GAN over the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:1sJd4Hv_s6UC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"In high-angular-resolution diffusion imaging (HARDI), simultaneous multislice (SMS) acquisition incorporated in multi-coil parallel imaging offers speedups in addition to the speedup obtained from undersampling gradient directions. We propose a novel learning-based method for reconstructing direction-undersampled SMS HARDI data. Our method relies on random-forest regression that also informs on the uncertainty in the reconstructions stemming from noise and artifacts. Results on a large clinical HARDI dataset show that our method significantly improves over the state of the art on SMS HARDI reconstruction qualitatively and quantitatively.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:CHSYGLWDkRkC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"High-angular-resolution diffusion imaging (HARDI) relies on multicoil acquisitions for clinical applications. HARDI scan time can be reduced by undersampling the set of gradient directions. Typical methods for undersampled HARDI reconstruction use two-stage schemes that first take scanner-reconstructed magnitude images for the acquired directions, and then fit a model to the reconstructed under-sampled diffusion signals, where they assume a Gaussian noise model that behaves poorly for high b values or high noise. In contrast, we propose a novel Bayesian framework for undersampled-HARDI reconstruction that directly fits to multicoil data. We use magnitude images per coil and a Rician noise model to bypass complicated phase-related artifacts and accurately reconstruct at large b values. We use a sparse dictionary prior on the diffusion signal across directions, and a multiscale wavelet regularity on each …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:xtRiw3GOFMkC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"Abnormality detection in medical images is a one-class classification problem for which typical methods use variants of kernel principal component analysis or one-class support vector machines. However, in practical deployment scenarios, many such methods are sensitive to the outliers present in the imperfectly-curated training sets. Current robust methods use heuristics for model fitting or lack formulations to leverage even a small amount of high-quality expert feedback. In contrast, we propose a novel method combining (i) robust statistical modeling, extending the multivariate generalized-Gaussian to a reproducing kernel Hilbert space, with (ii) semi-supervised learning to leverage a small expert-labeled outlier set. Results on simulated and real-world data, including endoscopy data, show that our method outperforms the state of the art in accurately detecting abnormalities.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:NhqRSupF_l8C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"Typical methods for image segmentation, or labeling, formulate and solve an optimization problem to produce a single optimal solution. For applications in clinical decision support relying on automated medical image segmentation, it is also desirable for methods to inform about (i) the uncertainty in label assignments or object boundaries or (ii) alternate close-to-optimal solutions. However, typical methods fail to do so. To estimate uncertainty, while some Bayesian methods rely on simplified prior models and approximate variational inference schemes, others rely on sampling segmentations from the associated posterior model using (i) traditional Markov chain Monte Carlo (MCMC) methods based on Gibbs sampling or (ii) approximate perturbation models. However, in such typical approaches, in practice, the resulting inference or generated sample set are approximations that deviate significantly from those …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:EUQCXRtRnyEC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:tOudhMTPpwUC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"Colocalization studies perform dual-color fluorescence microscopy imaging of two (or more) biological entities in the same specimen to elucidate common functional characteristics from their spatial co-distribution. Reliable estimation of colocalization is challenging due to the presence of both noise and blur artifacts, in addition to the fluorescence intensity variations and common background, from the digital imaging process. State-of-the-art methods that quantify colocalization either require the input images to be preprocessed or fall short of addressing one or more of these challenges in a holistic way, thereby producing incorrect estimates. In contrast, this paper proposes a unified statistical framework to estimate colocalization using (i) a Bayesian Markov random field (MRF) modeling of the observed dual-channel image that is corrupted by (known) blur and Poisson noise, and (ii) the expectation-maximization (EM …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:tS2w5q8j5-wC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"Super-resolution using deep neural networks typically relies on highly curated training sets that are often unavailable in clinical deployment scenarios. Using loss functions that assume Gaussian-distributed residuals makes the learning sensitive to corruptions in clinical training sets. We propose novel loss functions that are robust to corruptions in training sets by modeling heavy-tailed non-Gaussian distributions on the residuals. We propose a loss based on an autoencoder-based manifold-distance between the super-resolved and high-resolution images, to reproduce realistic textural content in super-resolved images. We propose to learn to super-resolve images to match human perceptions of structure, luminance, and contrast. Results on a large clinical dataset shows the advantages of each of our contributions, where our framework improves over the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:_xSYboBqXhAC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"Radiation exposure in positron emission tomography (PET) examination is a major issue for patient safety. PET image quality is severely degraded if low dose of radioactive tracer is administered. With a simultaneous magnetic resonance (MR)-PET scanner, MR anatomical priors can potentially improve PET image reconstruction. In this work, we introduce a framework to synthesize high quality standard dose PET images from the low dose PET and T1 MR images using an atlas guided convolutional neural network (CNN) approach. Compared with the conventional methods, the introduced method demonstrates improved PET image quality for datasets acquired with ten-fold PET dose reduction.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:vRqMK49ujn8C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2019,"We propose a novel Bayesian decision theoretic deep-neural-network (DNN) framework for image segmentation, enabling us to define a principled measure of uncertainty associated with label probabilities. Our framework estimates uncertainty analytically at test time, unlike the state of the art that relies on approximate and expensive algorithms using sampling or multiple passes. Moreover, our framework leads to a novel Bayesian interpretation of the softmax layer. We propose a novel method to improve DNN calibration. Results on three large datasets show that our framework improves segmentation quality and calibration, and provides more realistic uncertainty estimates, over existing methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:b0M2c_1WBrUC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"For medical image segmentation, most fully convolutional networks (FCNs) need strong supervision through a large sample of high-quality dense segmentations, which is taxing in terms of costs, time and logistics involved. This burden of annotation can be alleviated by exploiting weak inexpensive annotations such as bounding boxes and anatomical landmarks. However, it is very difficult to \textit{a priori} estimate the optimal balance between the number of annotations needed for each supervision type that leads to maximum performance with the least annotation cost. To optimize this cost-performance trade off, we present a budget-based cost-minimization framework in a mixed-supervision setting via dense segmentations, bounding boxes, and landmarks. We propose a linear programming (LP) formulation combined with uncertainty and similarity based ranking strategy to judiciously select samples to be annotated next for optimal performance. In the results section, we show that our proposed method achieves comparable performance to state-of-the-art approaches with significantly reduced cost of annotations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:bFI3QPDXJZMC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"In this paper, we propose a new method to perform Sparse Kernel Principal Component Analysis (SKPCA) and also mathematically analyze the validity of SKPCA. We formulate SKPCA as a constrained optimization problem with elastic net regularization in kernel feature space and solve it. We consider outlier detection (where KPCA is employed) as an application for SKPCA, using the RBF kernel. We test it on 5 real world datasets and show that by using just 4% (or even less) of the principal components (PCs), where each PC has on average less than 12% non-zero elements in the worst case among all 5 datasets, we are able to nearly match and in 3 datasets even outperform KPCA. We also compare the performance of our method with a recently proposed method for SKPCA and show that our method performs better in terms of both accuracy and sparsity. We also provide a novel probabilistic proof to justify the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:a0OBvERweLwC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"Simultaneous magnetic resonance imaging (MRI) and positron emission tomography (PET) has enabled the simultaneous acquisition of anatomical and metabolic information. The superior soft tissue contrast MRI images and high molecular sensitivity of PET images provide complementary information, which is useful in clinical diagnosis and therapy monitoring. However, PET images suffer from intrinsic resolution problems due to finite detector size and poor signal to noise ratio. PET image reconstruction methods using MRI images as anatomical priors have shown improved resolution and image quality [1]. However, PET images are fundamentally different from MRI images in terms of contrast, resolution and structure. Majority of the anatomical priors are based on image gradients. Such priors assume that image gradients in PET and MRI have similar magnitude and orientation. Patch based priors like dictionaries, on the other hand, can learn contextual and textural information in the images on top of local image gradients. Recently, interest in dictionary learning has increased for various image denoising tasks as well as MRI image reconstruction for severely undersampled k-space data [2]. However, patch based priors from MRI-alone still has the risk of cross-talk between the images. We have proposed a novel prior for PET image reconstruction, using a coupled MR-PET dictionary [3]. The dictionary is learnt from an already available set of MRI and PET training images, which are co-registered. Since the dictionary learns the basis functions which is tailored well to the image statistics rather than global basis functions such as Fourier and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:V3AGJWp-ZtQC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"Simultaneous magnetic resonance imaging (MRI) and positron emission tomography (PET) enable simultaneous acquisition of anatomical and functional imaging. Currently, separate reconstruction of MRI and PET images is performed. Recently, joint reconstruction of MRI-PET has been explored using gradient based priors, which have the risk of infusing cross-modality artefacts. We propose a coupled MR-PET patch based dictionary prior for the joint reconstruction of MRI and PET contrasts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:P5F9QuxV20EC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"Faster resting-state functional magnetic resonance imaging (R-fMRI) can improve spatiotemporal resolution and functional sensitivity. To speedup scans, current methods rely on complex pulse-sequence design or straightforward undersampling along with (weak) priors on the signal. We propose a Bayesian graphical R-fMRI reconstruction framework relying on learning data-adaptive prior models through dictionaries that we design to be robust to large physiological fluctuations typical in R-fMRI signals. Our dictionary adapts to multiple subjects through an optimal similarity transform. Our reconstructions on simulated and real-world R-fMRI give more accurate functional networks and better spatial resolution than the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:cFHS6HbyZ2cC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"In digital fluorescence microscopy, colocalization estimate between two biological entities within a specimen is often based on subjective visual inspection of images or ad hoc sequence of algorithms with several manually-tuned parameters, leading to irreproducible and unreliable estimates. We propose a novel Bayesian Markov random field (MRF) model for colocalization estimation from dual-channel images, encoding colocalization as a model parameter, to solve a unified data-driven optimization problem that, unlike existing methods, automatically deals with common-background removal, object labeling, parameter tuning, and noise. For model fitting, we propose Monte Carlo expectation maximization (EM) with perfect sampling extended from priors to posteriors, for our MRF model, to guarantee sampler convergence. We use consistent pseudo-likelihood estimators to deal with intractability in MRF parameter …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:dfsIfKJdRG4C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"Abnormality detection in biomedical images is a one-class classification problem, where methods learn a statistical model to characterize the inlier class using training data solely from the inlier class. Typical methods (i) need well-curated training data and (ii) have formulations that are unable to utilize expert feedback through (a small amount of) labeled outliers. In contrast, we propose a novel deep neural network framework that (i) is robust to corruption and outliers in the training data, which are inevitable in real-world deployment, and (ii) can leverage expert feedback through high-quality labeled data. We introduce an autoencoder formulation that (i) gives robustness through a non-convex loss and a heavy-tailed distribution model on the residuals and (ii) enables semi-supervised learning with labeled outliers. Results on three large medical datasets show that our method outperforms the state of the art in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:4OULZ7Gr8RgC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"For image segmentation, typical fully convolutional networks (FCNs) need strong supervision through a large sample of high-quality dense segmentations, entailing high costs in expert-raters’ time and effort. We propose MS-Net, a new FCN to significantly reduce supervision cost, and improve performance, by coupling strong supervision with weak supervision through low-cost input in the form of bounding boxes and landmarks. Our MS-Net enables instance-level segmentation at high spatial resolution, with feature extraction using dilated convolutions. We propose a new loss function using bootstrapped Dice overlap for precise segmentation. Results on large datasets show that MS-Net segments more accurately at reduced supervision costs, compared to the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:f2IySw72cVMC,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"Typical segmentation methods produce a single optimal solution and fail to inform about (i) the confidence/uncertainty in the object boundaries or (ii) alternate close-to-optimal solutions. To estimate uncertainty, some methods intend to sample segmentations from an associated posterior model using Markov chain Monte Carlo (MCMC) sampling or perturbation models. However, they cannot guarantee sampling from the true posterior, deviating significantly in practice. We propose a novel method that guarantees exact MCMC sampling, in finite time, of multi-label segmentations from generic Bayesian Markov random field (MRF) models. For exact sampling, we propose Fill’s strategy and extend it to generic MRF models via a novel bounding chain algorithm. Results on simulated data and clinical brain images from 4 classic problems show that our uncertainty estimates gain accuracy over the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:pyW8ca7W8N0C,http://www.cse.iitb.ac.in/~suyash
Suyash P. Awate,"['Image Analysis', 'Medical Image Computing', 'Machine Learning', 'Computer Vision']",19,981,2018,"Multimodal imaging combining positron emission tomography (PET) and magnetic resonance imaging (MRI) provides complementary information about metabolism and anatomy. While the appearances of MRI and PET images are distinctive, there are fundamental inter-image dependencies relating structure and function. In PET-MRI imaging, typical PET reconstruction methods use priors to enforce PET-MRI dependencies at the very fine scale of image gradients and, so, cannot capture larger-scale inter-image correlations and intra-image texture patterns. Some recent methods enforce statistical models of MRI-image patches on PET-image patches, risking infusing anatomical features into PET images. In contrast, we propose a novel patch-based joint dictionary model for PET and MRI, learning regularity in individual patches and correlations in spatially-corresponding patches, for Bayesian PET …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=xVs3dPgAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=xVs3dPgAAAAJ:D03iK_w7-QYC,http://www.cse.iitb.ac.in/~suyash
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2023,"In this paper, we describe a method for estimating the joint probability density from data samples by assuming that the underlying distribution can be decomposed as a mixture of product densities with few mixture components. Prior works have used such a decomposition to estimate the joint density from lower-dimensional marginals, which can be estimated more reliably with the same number of samples. We combine two key ideas: dictionaries to represent 1-D densities, and random projections to estimate the joint distribution from 1-D marginals, explored separately in prior work. Our algorithm benefits from improved sample complexity over the previous dictionary-based approach by using 1-D marginals for reconstruction. We evaluate the performance of our method on estimating synthetic probability densities and compare it with the previous dictionary-based approach and Gaussian Mixture Models (GMMs). Our algorithm outperforms these other approaches in all the experimental settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:08ZZubdj9fEC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2023,"It is well known that a band-limited signal can be reconstructed from its uniformly spaced samples if the sampling rate is sufficiently high. More recently, it has been proved that one can reconstruct a 1D band-limited signal even if the exact sample locations are unknown, but given just the distribution of the sample locations and their ordering in 1D. In this work, we extend the analytical bounds on the reconstruction error in such scenarios for quasi-bandlimited signals. We also prove that the method for such a reconstruction is resilient to a certain proportion of errors in the specification of the sample location ordering. We then express the problem of tomographic reconstruction of 2D images from 1D Radon projections under unknown angles with known angle distribution, as a special case for reconstruction of quasi-bandlimited signals from samples at unknown locations with known distribution. Building upon our theoretical background, we present asymptotic bounds for 2D quasi-bandlimited image reconstruction from 1D Radon projections in the unknown angles setting, which commonly occurs in cryo-electron microscopy (cryo-EM). To the best of our knowledge, this is the first piece of work to perform such an analysis for 2D cryo-EM, even though the associated reconstruction algorithms have been known for a long time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2023,"Videos shot by laymen using hand-held cameras contain undesirable shaky motion. Estimating the global motion between successive frames, in a manner not influenced by moving objects, is central to many video stabilization techniques, but poses significant challenges. A large body of work uses 2D affine transformations or homography for the global motion. However, in this work, we introduce a more general representation scheme, which adapts any existing optical flow network to ignore the moving objects and obtain a spatially smooth approximation of the global motion between video frames. We achieve this by a knowledge distillation approach, where we first introduce a low pass filter module into the optical flow network to constrain the predicted optical flow to be spatially smooth. This becomes our student network, named as GlobalFlowNet. Then, using the original optical flow network as the teacher …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:738O_yMBCRsC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2023,"Videos shot by laymen using hand-held cameras contain undesirable shaky motion. Estimating the global motion between successive frames, in a manner not influenced by moving objects, is central to many video stabilization techniques, but poses significant challenges. A large body of work uses 2D affine transformations or homography for the global motion. However, in this work, we introduce a more general representation scheme, which adapts any existing optical flow network to ignore the moving objects and obtain a spatially smooth approximation of the global motion between video frames. We achieve this by a knowledge distillation approach, where we first introduce a low pass filter module into the optical flow network to constrain the predicted optical flow to be spatially smooth. This becomes our student network, named as GLOBALFLOWNET. Then, using the original optical flow network as the teacher network, we train the student network using a robust loss function. Given a trained GLOBALFLOWNET, we stabilize videos using a two stage process. In the first stage, we correct the instability in affine parameters using a quadratic programming approach constrained by a user-specified cropping limit to control loss of field of view. In the second stage, we stabilize the video further by smoothing global motion parameters, expressed using small number of discrete cosine transform coefficients. In extensive experiments on a variety of different videos, our technique outperforms state of the art techniques in terms of subjective quality and different quantitative measures of video stability. Additionally, we present a new measure for evaluation of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:p2g8aNsByqUC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2022,"The COVID-19 pandemic has adversely affected millions all over the world. Efficient and effective testing of individuals for COVID-19, via modalities such as reverse transcription polymerase chain reaction (RT-PCR) is a crucial factor in combating this menace. Given the widespread scarcity of testing resources including testing kits, reagents, skilled manpower and available time, pooled testing has been advocated as a method of speed-up. Pooling involves mixing together small portions of ‘samples’ of different individuals, followed by testing the pools instead of the individual samples. It has been observed that a much smaller number of pools, as compared to the number of samples, is sufficient to allow for accurate prediction of the health status of the constituent samples, under the common and reasonable assumption that only a small number of the samples were infected. Artificial intelligence (AI) has emerged as …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:XiSMed-E-HIC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2022,"Group testing can help maintain a widespread testing program using fewer resources amid a pandemic. In a group testing setup, we are given n samples, one per individual. Each individual is either infected or uninfected. These samples are arranged into m < n pooled samples, where each pool is obtained by mixing a subset of the n individual samples. Infected individuals are then identified using a group testing algorithm. In this paper, we incorporate side information (SI) collected from contact tracing (CT) into nonadaptive/single-stage group testing algorithms. We generate different types of possible CT SI data by incorporating different possible characteristics of the spread of the disease. These data are fed into a group testing framework based on generalized approximate message passing (GAMP). Numerical results show that our GAMP-based algorithms provide improved accuracy. Compared to a loopy belief propagation algorithm, our proposed framework can increase the success probability by 0.25 for a group testing problem of n = 500 individuals with m = 100 pooled samples.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:u9iWguZQMMsC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2022,"Radial sampling pattern is an important signal acquisition strategy in magnetic resonance imaging (MRI) owing to better immunity to motion-induced artifacts and less pronounced aliasing due to undersampling compared to the Cartesian sampling. These advantages of radial sampling can be exploited in acquisition of multidimensional signals such as High Angular Resolution Diffusion Imaging (HARDI), with tremendous scope of acceleration. Despite such benefits, gradient delays lead to samples being acquired from unknown miscentered radial trajectories, severely degrading the image reconstruction quality. In the present work, we propose Csr-Pert that is a joint framework, wherein these perturbed radial trajectories are estimated and utilized for image reconstruction from the compressively sensed measurements of (i) MRI data and (ii) HARDI data. The proposed Csr-Pert method is tested on one real MRI …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:OU6Ihb5iCvQC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2022,"In this work, we study non-parametric estimation of joint probabilities of a given set of discrete and continuous ran-dom variables from their (empirically estimated) 2D marginals, under the assumption that the distribution could be approxi-mated by a mixture of product densities/mass functions. Estimation of joint probability density function using semi-parametric techniques such as Gaussian Mixture Models (GMMs) is widely studied. However, they yield poor results when the underlying densities are mixtures of various other families such as Laplacian, generalized Gaussian, uniform, etc. Further, GMMs are not the best choice to estimate distributions which are hybrid in nature, i.e., when it contains both discrete and continuous components. We present a novel approach for estimating the distribution using ideas from dictionary representations in signal processing coupled with low rank tensor decomposition. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:uWQEDVKXjbEC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2022,"Methods and systems for determining viruses in biological samples using a single round based pooling. Embodiments disclosed herein relate to quantitative testing of biological samples, and more particularly to a quantitative, non-adaptive and single round pooling method for testing of viruses (for example: Coronavirus disease of 2019 (COVID-19), Severe Acute Respiratory Syndrome (SARS), or the like) in biological samples of individuals.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:nb7KW1ujOQ8C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2022,"Tomographic reconstruction from undersampled measurements is a necessity when the measurement process is potentially harmful, needs to be rapid, or is resource-expensive. In such cases, information from previously existing longitudinal scans of the same object (‘object-prior’) helps in the reconstruction of the current object (‘test’) from its significantly fewer measurements. A common problem with these techniques is the influence of object-priors in the reconstruction of new changes in the test. In this work, we mitigate this problem by first estimating the location of changes (‘new regions’) and then imposing object-prior in only those regions which are similar to the prior (‘old regions’). Our work is based on longitudinal data acquisition scenarios where we wish to study new changes that evolve within an object over time, such as in repeated scanning for disease monitoring, or in tomography-guided surgical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:1sJd4Hv_s6UC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2022,"Diffusion magnetic resonance imaging (dMRI) is being extensively used to study the neural architecture of the brain. High angular resolution diffusion imaging (HARDI), a variant of diffusion MRI, measures the diffusion of water molecules along the angular gradient directions in the q-space. It provides better estimates of fiber orientations compared to the traditionally used diffusion tensor imaging (DTI). However, HARDI requires acquisition of relatively large number of samples leading to longer scanning times. Several approaches based on compressive sensing (CS) have been proposed to accelerate HARDI acquisition, leveraging on the sparse representation of the HARDI signal in a pre-specified sparsifying basis. In this paper, we propose to carry out reconstruction of compressively sensed HARDI data using an adaptively learned transform. The transform is learned (i) from the compressive measurements on-the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:abG-DnoFyZgC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2022,"In this work, we study non-parametric estimation of joint probabilities of a given set of discrete and continuous random variables from their (empirically estimated) 2D marginals, under the assumption that the joint probability could be decomposed and approximated by a mixture of product densities/mass functions. The problem of estimating the joint probability density function (PDF) using semi-parametric techniques such as Gaussian Mixture Models (GMMs) is widely studied. However such techniques yield poor results when the underlying densities are mixtures of various other families of distributions such as Laplacian or generalized Gaussian, uniform, Cauchy, etc. Further, GMMs are not the best choice to estimate joint distributions which are hybrid in nature, i.e., some random variables are discrete while others are continuous. We present a novel approach for estimating the PDF using ideas from dictionary representations in signal processing coupled with low rank tensor decompositions. To the best our knowledge, this is the first work on estimating joint PDFs employing dictionaries alongside tensor decompositions. We create a dictionary of various families of distributions by inspecting the data, and use it to approximate each decomposed factor of the product in the mixture. Our approach can naturally handle hybrid -dimensional distributions. We test our approach on a variety of synthetic and real datasets to demonstrate its effectiveness in terms of better classification rates and lower error rates, when compared to state of the art estimators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:CHSYGLWDkRkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"In this paper, we consider compressive inversion of a signal/image that is sparse in typical orthonormal bases used in image processing, given its measurements that have been corrupted by Poisson noise. The square-root operation is known to convert a Poisson random variable into one that is approximately Gaussian distributed with a constant variance. We present two different computationally tractable, penalized estimators with a data-fidelity term based on the aforementioned square-root based ‘variance stabilization transform’. The first estimator has been proposed earlier in the literature, but this is the first paper to analyze its theoretical performance in compressed sensing. Our second estimator is completely novel, and also has the interesting statistical property of being an approximately pivotal estimator. For both estimators, we specifically consider the case of a physically realistic sensing matrix in our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:cFHS6HbyZ2cC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"As compared to using randomly generated sensing matrices, optimizing the sensing matrix w.r.t. a carefully designed criterion is known to lead to better quality signal recovery given a set of compressive measurements. In this paper, we propose generalizations of the well-known mutual coherence criterion for optimizing sensing matrices starting from random initial conditions. We term these generalizations as bi-coherence or tri-coherence and they are based on a criterion that discourages any one column of the sensing matrix from being close to a sparse linear combination of other columns. We also incorporate training data to further improve the sensing matrices through weighted coherence, weighted bi-coherence, or weighted tri-coherence criteria, which assign weights to sensing matrix columns as per their importance. An algorithm is also presented to solve the optimization problems. Finally, the effectiveness of the proposed algorithm is demonstrated through empirical results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:EUQCXRtRnyEC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"Compressed sensing (CS) involves sampling signals at rates less than their Nyquist rates and attempting to reconstruct them after sample acquisition. Most such algorithms have parameters, for example the regularization parameter in LASSO, which need to be chosen carefully for optimal performance. These parameters can be chosen based on assumptions on the noise level or signal sparsity, but this knowledge may often be unavailable. In such cases, cross validation (CV) can be used to choose these parameters in a purely data-driven fashion. Previous work analyzing the use of CV in CS has been based on the cross-validation error with Gaussian measurement noise. But it is well known that the error is not robust to impulse noise and provides a poor estimate of the recovery error, failing to choose the best parameter. Here we propose using the error which provides substantial performance benefits given …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:zA6iFVUQeVQC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"Most compressed sensing algorithms do not account for the effect of saturation in noisy compressed measurements, though saturation is an important consequence of the limited dynamic range of existing sensors. The few algorithms that handle saturation effects either simply discard saturated measurements, or impose additional constraints to ensure consistency of the estimated signal with the saturated measurements (based on a known saturation threshold) given uniform-bounded noise. In this paper, we instead propose a new data fidelity function which is directly based on ensuring a certain form of consistency between the signal and the saturated measurements, and can be expressed as the negative logarithm of a certain carefully designed likelihood function. Our estimator works even in the case of Gaussian noise (which is potentially unbounded) in the measurements. We prove that our data fidelity function …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:3s1wT3WcHBgC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"Joint probability density or joint probability mass function (PDF/PMF) estimation is a fundamental machine learning problem. The number of free parameters scales exponentially with respect to the number of random variables. Hence, most work on nonparametric joint distribution estimation is based on some structural assumptions such as clique factorization adopted by probabilistic graphical models, imposition of low rank on the joint probability tensor and reconstruction from 3-way or 2-way marginals, etc. In the current work, we link random projections of data to the problem of PMF estimation using techniques from tomography. Using it alongside low-rank tensor decomposition, we present an approach to estimate joint distribution from just one-way marginals in a transformed space. We provide a novel algorithm for recovering factors of the tensor from one-way marginals, test it across synthetic and real-world …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:u_35RYKgDlwC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"Compressed Sensing assumes a linear model for acquiring signals however imperfections may arise in the specification of the ‘ideal’ measurement model. We present the first study which considers the case of two such common calibration issues: (a) unknown measurement scaling (sensor gains) due to hardware vagaries or due to unknown object motion in MRI scanning, in conjunction with (b) unknown offsets to measurement frequencies in case of a Fourier measurement matrix. We propose an alternating minimisation algorithm for on-the-fly signal recovery in the case when errors (a) and (b) occur jointly. We show simulation results over a variety of situations that outperform the baselines of signal recovery by ignoring either or both types of calibration errors. We also show theoretical results for signal recovery by introducing a perturbed version of the well-known Generalized Multiple Measurement Vectors …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:dfsIfKJdRG4C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"Group testing can save testing resources in the context of the ongoing COVID-19 pandemic. In group testing, we are given n samples, one per individual, and arrange them into m < n pooled samples, where each pool is obtained by mixing a subset of the n individual samples. Infected individuals are then identified using a group testing algorithm. In this paper, we use side information (SI) collected from contact tracing (CT) within nonadaptive/single-stage group testing algorithms. We generate data by incorporating CT SI and characteristics of disease spread between individuals. These data are fed into two signal and measurement models for group testing, where numerical results show that our algorithms provide improved sensitivity and specificity. While Nikolopoulos et al. utilized family structure to improve nonadaptive group testing, ours is the first work to explore and demonstrate how CT SI can further improve …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:SeFeTyx0c_EC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"Group testing can help maintain a widespread testing program using fewer resources amid a pandemic. In group testing, we are given samples, one per individual. These samples are arranged into pooled samples, where each pool is obtained by mixing a subset of the individual samples. Infected individuals are then identified using a group testing algorithm. In this paper, we use side information (SI) collected from contact tracing (CT) within nonadaptive/single-stage group testing algorithms. We generate CT SI data by incorporating characteristics of disease spread between individuals. These data are fed into two signal and measurement models for group testing, and numerical results show that our algorithms provide improved sensitivity and specificity. We also show how to incorporate CT SI into the design of the pooling matrix. That said, our numerical results suggest that the utilization of SI in the pooling matrix design based on the minimization of a weighted coherence measure does not yield significant performance gains beyond the incorporation of SI in the group testing algorithm.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:yD5IFk8b50cC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"Given a set of N random variables X1, X2,..., XN, estimating the joint density p (X1, X2,..., XN) is a fundamental problem in many fields such as statistics and machine learning. This probabilistic interpretation can help us make may inferences to help us aid take better decisions for the problem in hand. For a simple example, take X1 as the time taken to drive to a particular destination and Xi, 2≤ i≤ N denote a scalar number indicating the traffic on the N− 1 streets. We would want to make predictions such as the minimum time needed for reaching the destination given we somehow know the traffic profiles of all the streets, ie more formally, we would want to find the following: min p (X1| X2, X3,..., XN). Maximum a posteriori (MAP) estimation of the joint probability density is used in classification problems. Probabilistic models can also be used for anomaly detection in various fields like law, medicine. Capturing the joint density is helpful as we can infer a variety of queries of such form easily (?). Most the work done can be classified in a few categories namely:
1. If the realisations of these random variables are discrete, then standard histogramming would work but it requires a large number of samples (exponential in N) to make the estimate of the joint close to the actual density and is clearly not scalable for large N. In the big data era, it is very common for data to be high dimensional (an image of size 200× 200 is 40k dimensional), and hence such a naive approach for modelling densities without accounting for the inherent structure which data posseses fails in these scenarios.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:_xSYboBqXhAC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"In many compressive sensing reconstruction algorithms, a good choice of important parameters such as the optimal number of measurements (which is dependent upon the unknown signal sparsity) or the regularization parameter, is critical for successful signal recovery. Cross-validation provides a principled method of doing so, by dividing the measurements into a ‘reconstruction set’ to recover the signal given each candidate parameter value, and a ‘cross-validation set’ to determine in a purely data-driven manner as to which candidate parameter value is optimal. In previous work, such a technique has been theoretically analyzed for the case of noiseless compressive measurements or for the case of additive i.i.d. Gaussian noise in the measurements. This paper presents the first theoretical analysis of this technique for compressed sensing when the measurements are corrupted by Poisson noise, the dominant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:ZHo1McVdvXMC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"We propose ‘Tapestry’, a single-round pooled testing method with application to COVID-19 testing using quantitative Reverse Transcription Polymerase Chain Reaction (RT-PCR) that can result in shorter testing time and conservation of reagents and testing kits, at clinically acceptable false positive or false negative rates. Tapestry combines ideas from compressed sensing and combinatorial group testing to create a new kind of algorithm that is very effective in deconvoluting pooled tests. Unlike Boolean group testing algorithms, the input is a quantitative readout from each test and the output is a list of viral loads for each sample relative to the pool with the highest viral load. For guaranteed recovery of infected samples out of being tested, Tapestry needs only tests with high probability, using random binary pooling matrices. However, we propose deterministic binary pooling matrices based on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:RGFaLdJalmkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,"In this paper, an approach to optimize a device discovery process using highly directive antennas for Terahertz communications is introduced. An algorithm using compressed sensing and some first results based on simulation data are presented. The simulation environment and scenarios as well as the compressed sensing theory are explained and the concept is evaluated considering different propagation scenarios as well as different frequencies and angular resolutions. Finally, the results show that the number of directions of the considered device discovery process can be reduced by up to 61 % on average.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:4OULZ7Gr8RgC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2021,Method and electronic device for providing image-based CAPTCHA challenge Embodiments herein achieve an electronic device for providing an image-based CAPTCHA challenge. The electronic device is configured to cause to display the image-based CAPTCHA challenge for a user of the electronic device. The image-based CAPTCHA challenge includes a first image and a second image of an object displayed from different viewpoints. The first image includes a challenge point in at least one portion of the object. The electronic device is further configured to detect at least one input from the user indicating the at least one challenge point on at least one portion of the second image. The electronic device is further configured to automatically determine whether the at least one portion of the second image on which the at least one input performed by the user corresponds to the at least one portion of the first image …,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:KxtntwgDAa4C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2020,"Compressed sensing is a signal processing technique for efficiently acquiring and reconstructing a signal, by finding solutions to underdetermined linear systems. The signals are generally undersampled below Nyquist rate and then a lossy reconstruction is performed. For reconstruction, the sparsity of signals in certain bases is exploited. Generally for images, these bases could be DCT (Discrete Cosine Transform), Wavelet, Fourier or even dictionaries learned using training data. For reconstruction, algorithms such as OMP or LASSO are generally used.
Let x be the signal and be the sensing matrix. Then=· represent the measurements which we obtain. Since x is a sparse signal in some basis, let= where D is the basis and is the sparse vector. Then the compressed sensing problems tries to find using y and=·",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:pyW8ca7W8N0C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2020,"Brain neural connectivity patterns are increasingly analyzed with diffusion magnetic resonance imaging (dMRI) via the estimation of local fiber-tract orientations. High angular resolution diffusion imaging (HARDI), a variant of dMRI, is known to produce better representation of fiber orientations than the traditionally used diffusion tensor imaging (DTI). However, it requires a large number of samples leading to longer scan times. In this paper, we propose a new method, namely, MSR-HARDI, for the accelerated reconstruction of HARDI data using multiple sparsity regularizers in the k - q space. Combination of regularizers is observed to provide improved reconstructions as compared to individual regularizers. The proposed method is also observed to provide better reconstruction than the existing state-of-the-art methods in terms of the normalized mean squared error.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:g5m5HwL7SMYC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2020,"We have previously described Tapestry Pooling, a scheme to enhance the capacity of RT-qPCR testing, and provided experimental evidence with spiked synthetic RNA to show that it can help to scale testing and restart the economy. Here we report on validation studies with Covid19 patient samples for the Tapestry Pooling scheme with prevalence in the range of 1% to 2%. We pooled RNA extracted from patient samples that were previously tested for Covid19, sending each sample to three pools. Following three different pooling schemes, we pipetted 320 samples into 48 pools with pool size of 20 at prevalence rate of 1.6%, 500 samples into 60 pools with pool size of 25 at prevalence rate of 2%, and 961 samples into 93 pools with pool size of 31 at prevalence rate of 1%. Of the 191 RT-qPCR experiments that we performed, only one pool was incorrect (false negative). Our recovery algorithm correctly called results for the individual samples, with a 100% sensitivity and a 99.9% specificity, with only one false positive across all the 1,781 blinded results required to be called. We show up to 10X savings in number of tests required at a range of prevalence rates and pool sizes. These experiments establish that Tapestry Pooling is robust enough to handle the diversity of sample constitutions and viral loads seen in real-world samples.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:pqnbT2bcN3wC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2020,"Low-dose tomography is highly preferred in medical procedures for its reduced radiation risk when compared to standard-dose Computed Tomography (CT). However, the lower the intensity of X-rays, the higher the acquisition noise and hence the reconstructions suffer from artefacts. A large body of work has focussed on improving the algorithms to minimize these artefacts. In this work, we propose two new techniques, rescaled non-linear least squares and Poisson-Gaussian convolution, that reconstruct the underlying image making use of an accurate or near-accurate statistical model of the noise in the projections. We also propose a reconstruction method when prior knowledge of the underlying object is available in the form of templates. This is applicable to longitudinal studies wherein the same object is scanned multiple times to observe the changes that evolve in it over time. Our results on 3D data show that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:blknAaTinKkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2020,"We propose Tapestry, a novel approach to pooled testing with application to COVID-19 testing with quantitative Polymerase Chain Reaction (PCR) that can result in shorter testing time and conservation of reagents and testing kits. Tapestry combines ideas from compressed sensing and combinatorial group testing with a novel noise model for PCR. Unlike Boolean group testing algorithms, the input is a quantitative readout from each test, and the output is a list of viral loads for each sample. While other pooling techniques require a second confirmatory assay, Tapestry obtains individual sample-level results in a single round of testing. When testing n samples with t tests, as many as k= O (t/log n) infected samples can be identified at clinically-acceptable false positive and false negative rates. This makes Tapestry viable even at prevalence rates as high as 10%. Tapestry has been validated in simulations as well as in wet lab experiments with oligomers. Clinical trials with Covid-19 samples are underway. An accompanying Android application Byom Smart Testing which makes the Tapestry protocol straightforward to implement in testing centres is available for free download.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:WbkHhVStYXYC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2020,"The COVID-19 pandemic has strained testing capabilities worldwide. There is an urgent need to find economical and scalable ways to test more people. We present Tapestry, a novel quantitative nonadaptive pooling scheme to test many samples using only a few tests. The underlying molecular diagnostic test is any real-time RT-PCR diagnostic panel approved for the detection of the SARS-CoV-2 virus. In cases where most samples are negative for the virus, Tapestry accurately identifies the status of each individual sample with a single round of testing in fewer tests than simple two-round pooling. We also present a companion Android application BYOM Smart Testing which guides users through the pipetting steps required to perform the combinatorial pooling. The results of the pooled tests can be fed into the application to recover the status and estimated viral load for each individual sample.
NOTE: This protocol has been validated with in vitro experiments that used synthetic RNA and DNA fragments and additionally, its expected behavior has been confirmed using computer simulations. Validation with clinical samples is ongoing. We are looking for clinical collaborators with access to patient samples. Please contact the corresponding author if you wish to validate this protocol on clinical samples.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:YFjsv_pBGBYC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2020,"The COVID-19 pandemic has strained testing capabilities worldwide. There is an urgent need to find economical and scalable ways to test more people. We present Tapestry, a novel quantitative nonadaptive pooling scheme to test many samples using only a few tests. The underlying molecular diagnostic test is any real-time RT-PCR diagnostic panel approved for the detection of the SARS-CoV-2 virus. In cases where most samples are negative for the virus, Tapestry accurately identifies the status of each individual sample with a single round of testing in fewer tests than simple two-round pooling. We also present a companion Android application BYOM Smart Testing which guides users through the pipetting steps required to perform the combinatorial pooling. The results of the pooled tests can be fed into the application to recover the status and estimated viral load for each individual sample.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:tOudhMTPpwUC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2020,"Consider a scene submerged underneath a fluctuating water surface. Images of such a scene, when acquired from a camera in the air, exhibit significant spatial distortions. In this paper, we present a novel, computationally efficient pre-processing algorithm to correct a significant amount (~ 50%) of apparent distortion present in video sequences of such a scene. We demonstrate that when the partially restored video output from this stage is given as input to other methods, it significantly improves their performance. This algorithm involves (i) tracking a small number N of salient feature points across the T frames to yield point-trajectories\\boldsymbol q_i\triangleq\(x_ it, y_ it)\_ t= 1^ T\_ i= 1^ N, and (ii) using the point-trajectories to infer the deformations at other non-tracked points in every frame. A Fourier decomposition of the N trajectories, followed by a novel Fourier phase-interpolation step, is used to infer deformations at all other points. Our method exploits the inherent spatio-temporal characteristics of the fluctuating water surface to correct non-rigid deformations to a very large extent. The source code, datasets and supplemental material can be accessed at [1],[2].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:NMxIlDl6LWMC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"Low-dose tomography is highly preferred in medical procedures for its reduced radiation risk when compared to standard-dose Computed Tomography (CT). However, the lower the intensity of X-rays, the higher the acquisition noise and hence the reconstructions suffer from artefacts. A large body of work has focussed on improving the algorithms to minimize these artefacts. In this work, we propose two new techniques, rescaled non-linear least squares and Poisson-Gaussian convolution, that reconstruct the underlying image making use of an accurate or near-accurate statistical model of the noise in the projections. We also propose a reconstruction method when prior knowledge of the underlying object is available in the form of templates. This is applicable to longitudinal studies wherein the same object is scanned multiple times to observe the changes that evolve in it over time. Our results on 3D data show that prior information can be used to compensate for the low-dose artefacts, and we demonstrate that it is possible to simultaneously prevent the prior from adversely biasing the reconstructions of new changes in the test object, via a method called ``re-irradiation''. Additionally, we also present two techniques for automated tuning of the regularization parameters for tomographic inversion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:D03iK_w7-QYC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"In many applications in compressed sensing, the measurement matrix is a Fourier matrix, ie, it measures the Fourier transform of the underlying signal at some specified ‘base’frequencies {u i} i= 1 M, where M is the number of measurements. However due to system calibration errors, the system may measure the Fourier transform at frequencies {u i+ δ i} i= 1 M that are different from the base frequencies and where {δ i} i= 1 M are unknown frequency perturbations. Ignoring such perturbations can lead to major errors in signal recovery. In this paper, we present a simple but effective alternating minimization algorithm to recover the perturbations in the frequencies in situ with the signal, which we assume is sparse or compressible in some known basis. In many cases, the perturbations {δ i} i= 1 M can be expressed in terms of a small number of unique parameters P≪ M. We demonstrate that in such cases, the method …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:j3f4tGmQtD8C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"In this paper, we consider the problem of nonlinear blind compressed sensing, i.e. jointly estimating the sparse codes and sparsity-promoting basis, under signal-dependent noise. We focus our efforts on the Poisson noise model, though other signal-dependent noise models can be considered. By employing a well-known variance stabilizing transform such as the Anscombe transform, we formulate our task as a nonlinear least squares problem with the ℓ 1 penalty imposed for promoting sparsity. We solve this objective function under non-negativity constraints imposed on both the sparse codes and the basis. To this end, we propose a multiplicative update rule, similar to that used in non-negative matrix factorization (NMF), for our alternating minimization algorithm. To the best of our knowledge, this is the first attempt at a formulation for nonlinear blind compressed sensing, with and without the Poisson noise model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:k_IJM867U9cC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"We present a technique for compressive phase retrieval under Poisson noise using the theory of variance stabilization transforms (VSTs). We modify two existing algorithms using VSTs, and derive worst-case performance bounds for both the algorithms. Our proposed modification allows for easy and very principled parameter tuning. Our estimator is tractable and we also show numerical results on phase recovery of sparse signals for Poisson corrupted measurements, and demonstrate the relative advantage of our modification at low intensities. We also present a comparison of the performance and other theoretical aspects of both the algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:isC4tDSrTZIC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"This paper addresses the task of projection design for source separation in the compressive domain, where one observes a compressed linear mixture of two source signals with known priors. By positioning that both the sources follow a Gaussian mixture, we formulate an objective that tightly approximates the minimum mean squared error and solve the optimization problem using a gradient-based approach. In the blind setting, where the mixing ratio unknown, we propose a cross-validation approach to independently estimate the mixing ratio. We also provide a number of numerical results on synthetic and real image data that validate our findings. To the best of our knowledge, this is the first effort in projection design for prior-based source separation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:TFP_iSt0sucC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"Abnormality detection in medical images is a one-class classification problem for which typical methods use variants of kernel principal component analysis or one-class support vector machines. However, in practical deployment scenarios, many such methods are sensitive to the outliers present in the imperfectly-curated training sets. Current robust methods use heuristics for model fitting or lack formulations to leverage even a small amount of high-quality expert feedback. In contrast, we propose a novel method combining (i) robust statistical modeling, extending the multivariate generalized-Gaussian to a reproducing kernel Hilbert space, with (ii) semi-supervised learning to leverage a small expert-labeled outlier set. Results on simulated and real-world data, including endoscopy data, show that our method outperforms the state of the art in accurately detecting abnormalities.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:bEWYMUwI8FkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"In this paper, we present an algorithm to automatically construct all the conformations of a heterogeneous planar object from their tomographic projections at random unknown view angles. Our statistically motivated approach can reveal and analyze the heterogeneity in the projection dataset and segregate the projections belonging to different structures without requiring prior structural information or templates, expert human intervention or even the knowledge of the number of conformations present in the sample. Even in the presence of high noise variance (low SNR) and a large number of conformations, our algorithm can estimate the structures of each conformation to a high degree of accuracy. We demonstrate the broad applicability of our algorithm by evaluating its performance on synthetic 2D datasets of well-known protein complexes such as Lipase under varying levels of noise and different number of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:RHpTSmoSYBkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"The need for tomographic reconstruction from sparse measurements arises when the measurement process is potentially harmful, needs to be rapid, or is uneconomical. In such cases, information from previous longitudinal scans of the same object helps to reconstruct the current object while requiring significantly fewer updating measurements. Our work is based on longitudinal data acquisition scenarios where we wish to study new changes that evolve within an object over time, such as in repeated scanning for disease monitoring, or in tomography-guided surgical procedures. While this is easily feasible when measurements are acquired from a large number of projection views, it is challenging when the number of views is limited. If the goal is to track the changes while simultaneously reducing sub-sampling artefacts, we propose (1) acquiring measurements from a small number of views and using a global unweighted prior-based reconstruction. If the goal is to observe details of new changes, we propose (2) acquiring measurements from a moderate number of views and using a more involved reconstruction routine. We show that in the latter case, a weighted technique is necessary in order to prevent the prior from adversely affecting the reconstruction of new structures that are absent in any of the earlier scans. The reconstruction of new regions is safeguarded from the bias of the prior by computing regional weights that moderate the local influence of the priors. We are thus able to effectively reconstruct both the old and the new structures in the test. In addition to testing on simulated data, we have validated the efficacy of our method on real …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:maZDTaKrznsC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"Most existing bounds for signal reconstruction from compressive measurements make the assumption of additive signal-independent noise. However in many compressive imaging systems, the noise statistics are more accurately represented by Poisson or Poisson–Gaussian noise models. In this paper, we derive upper bounds for signal reconstruction error from compressive measurements which are corrupted by Poisson or Poisson–Gaussian noise. The features of our bounds are as follows:(1) the bounds are derived for a computationally tractable convex estimator with statistically motivated parameter selection. The estimator penalizes signal sparsity subject to a constraint that imposes a novel statistically motivated upper bound on a term based on variance stabilization transforms to approximate the Poisson or Poisson–Gaussian distributions by distributions with (nearly) constant variance.(2) The bounds are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:TQgYirikUcIC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"Recovery error bounds in compressed sensing under Gaussian or uniform bounded noise do not translate easily to the case of Poisson noise. Reasons for this include the signal dependent nature of Poisson noise, and also the fact that the negative log likelihood in case of a Poisson distribution (which is directly related to the generalized Kullback–Leibler divergence) is not a metric and does not obey the triangle inequality. There exist prior theoretical results in the form of provable error bounds for computationally tractable estimators for compressed sensing problems under Poisson noise. However, these results do not apply to realistic compressive systems, which must obey some crucial constraints such as non-negativity and flux preservation. On the other hand, there exist provable error bounds for such realistic systems in the published literature, but they are for estimators that are computationally intractable. In …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:4JMBOYKVnBMC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2019,"Images of static scenes submerged beneath a wavy water surface exhibit severe non-rigid distortions. The physics of water flow suggests that water surfaces possess spatio-temporal smoothness and temporal periodicity. Hence they possess a sparse representation in the 3D discrete Fourier (DFT) basis. Motivated by this, we pose the task of restoration of such video sequences as a compressed sensing (CS) problem. We begin by tracking a few salient feature points across the frames of a video sequence of the submerged scene. Using these point trajectories, we show that the motion fields at all other (non-tracked) points can be effectively estimated using a typical CS solver. This by itself is a novel contribution in the field of non-rigid motion estimation. We show that this method outperforms state of the art algorithms for underwater image restoration. We further consider a simple optical flow algorithm based on local polynomial expansion of the image frames (PEOF). Surprisingly, we demonstrate that PEOF is more efficient and often outperforms all the state of the art methods in terms of numerical measures. Finally, we demonstrate that a two-stage approach consisting of the CS step followed by PEOF much more accurately preserves the image structure and improves the (visual as well as numerical) video quality as compared to just the PEOF stage. The source code, datasets and supplemental material can be accessed at [??],[??].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:r0BpntZqJG4C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2018,"The need for tomographic reconstruction from sparse measurements arises when the measurement process is potentially harmful, needs to be rapid, or is uneconomical. In such cases, prior information from previous longitudinal scans of the same or similar objects helps to reconstruct the current object whilst requiring significantly fewer `updating' measurements. However, a significant limitation of all prior-based methods is the possible dominance of the prior over the reconstruction of new localised information that has evolved within the test object. In this paper, we improve the state of the art by (1) detecting potential regions where new changes may have occurred, and (2) effectively reconstructing both the old and new structures by computing regional weights that moderate the local influence of the priors. We have tested the efficacy of our method on synthetic as well as real volume data. The results demonstrate that using weighted priors significantly improves the overall quality of the reconstructed data whilst minimising their impact on regions that contain new information.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:-f6ydRqryjwC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2018,"In many applications in compressed sensing, the measurement matrix is a Fourier matrix, i.e., it measures the Fourier transform of the underlying signal at some specified `base' frequencies {u i } M i=1 , where M is the number of measurements. However due to system calibration errors, the system may measure the Fourier transform at frequencies {u i + δ i } M i=1 that are different from the base frequencies and where {δ i } M i=1 are unknown. Ignoring perturbations of this nature can lead to major errors in signal recovery. In this paper, we present a simple but effective alternating minimization algorithm to recover the perturbations in the frequencies in situ with the signal, which we assume is sparse or compressible in some known basis. In many practical cases, the perturbations {δ i } M i=1 can be expressed in terms of a small number of unique parameters P z M. We demonstrate that in such cases, the method …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:_Qo2XoVZTnwC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2018,"Traditionally, direction of arrival (DOA) estimation techniques have been based on spectral estimation methods utilizing signal and noise subspaces [1]. Such techniques perform well when sensor measurements are available at multiple snapshots. Recently, compressed sensing (CS) based DOA estimation techniques have been introduced, which improve source localization in the single snapshot case by modeling the angle search as a sparse recovery problem. In this domain, various on-grid and off-grid methods have been proposed in the existing literature [2] [3] [4]. The on-grid methods rely on a fixed basis and solve traditional CS based sparse recovery problems while the latter has modifications based on first-order Taylor approximation of the array manifold matrix. In this paper, we present an off-grid CS based formulation, where we employ an alternating minimization strategy for fine-grid search of source …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:R3hNpaxXUhUC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2018,We present an algorithm for image denoising under Poisson noise using the theory of variance stabilization transforms. We derive worst-case performance bounds for our algorithm. Our proposed estimator allows for easy and very principled parameter tuning unlike existing approaches which require specification of signal dependent parameters. Moreover our estimator is computationally tractable. We also demonstrate numerical results on image denoising under Poisson noise to support the theoretical results.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:HDshCWvjkbEC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2018,"We present an estimator, based on the Anscombe transform, for the problem of low-rank matrix recovery under Poisson noise. We derive an upper bound on the matrix reconstruction error for this estimator, considering a linear sensing operator which obeys realistic constraints like non-negativity and flux-preservation. Besides being computationally tractable (convex), our estimator also allows for principled parameter tuning. Moreover, our method is capable of handling Poisson-Gaussian noise and the case where the Poisson or Poisson-Gaussian corrupted measurements are uniformly quantized. In addition to our theoretical results, we present some numerical results for Poisson low-rank matrix recovery under varying intensity levels and number of measurements.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:mB3voiENLucC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2018,"Most existing work in designing sensing matrices for compressive recovery is based on optimizing some quality factor, such as mutual coherence, average coherence or the restricted isometry constant (RIC), of the sensing matrix. In this paper, we report anomalous results that show that such a design is not always guaranteed to improve reconstruction results. We also present a design method based on the minimum mean squared error (MMSE) criterion, imposing priors on signal and noise for natural images, and show that it yields results superior to results from coherence-based methods while taking into account physical constraints on the sensing matrix.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:hFOr9nPyWt4C,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2018,"In this paper, we present an algorithm for effectively reconstructing an object from a set of its tomographic projections without any knowledge of the viewing directions or any prior structural information, in the presence of pathological amounts of noise, unknown shifts in the projections, and outliers among the projections. The outliers are mainly in the form of a number of projections of a completely different object, as compared to the object of interest. We introduce a novel approach of first processing the projections, then obtaining an initial estimate for the orientations and the shifts, and then define a refinement procedure to obtain the final reconstruction. Even in the presence of high noise variance (up to of the average value of the (noiseless) projections) and presence of outliers, we are able to successfully reconstruct the object. We also provide interesting empirical comparisons of our method with the sparsity based optimization procedures that have been used earlier for image reconstruction tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:hC7cP41nSMkC,http://www.cse.iitb.ac.in/~ajitvr
Ajit Rajwade,"['Image Processing', 'Computer Vision', 'Compressed Sensing', 'Tomographic Reconstruction', 'Inverse Problems']",11,621,2018,"Let X∗ be the true rank 1 matrix that satisfies the constraints in Q1, andX be the solution to Q1 for an appropriate choice of parameters. We define∆= X− X⋆. For a matrix X∈ R d× d, XT denotes a matrix with all values zero except the indices in T, which are set to the corresponding values of X.∀ λ≥ 2d
1− ρ+ d k 1 2 and δ≤",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=CkTW7PwAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=CkTW7PwAAAAJ:JV2RwH3_ST0C,http://www.cse.iitb.ac.in/~ajitvr
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2022,"Benchmarking energy usage help identify operational and strategic best practices suitable for an establishment while creating awareness of energy consumption. Therefore in this work, we present XENIA, a data-driven energy benchmarking methodology for buildings in Singapore using a public dataset of building attributes. We develop an ensemble tree model to predict energy consumption using the building attributes as predictors. Symmetric mean absolute percentage error of these models for hotel and retail buildings is 5.15% and 5.02%, respectively. A benchmark grade is then assigned to each building using the actual and predicted energy consumption. To interpret the model, we provide a global explanation using the partial dependence function to show the effect of building attributes on energy consumption. For local explanation, i.e., for a specific building, we use the SHAP value to show the influence of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:oH8HCDhqVGsC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2022,"The article addresses the void in developing analytical methods concerning to design urban configurations that could reduce fire risks, and, thus, could help in achieving sustainable goals. A novel algorithm is developed to generate alternative Urban Built Form (UBF) models that could be less susceptible to fire compared to the existing built-form. Fire susceptibility of a generated UBF is predicted using a developed linear regression model. The algorithm considers existing regulations to derive rules and develop scenarios that might be effective in building fire-resilient cities. The outcomes of the simulations showed a significant decrease in the fire susceptibility of the southern region of Mumbai city. Moreover, for a certain simulated scenario the predicted UBF could accommodate twice the current population while being less susceptible than the existing UBF. The proposed techniques and methods can act as a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:Nufq_to8ts0C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2022,"The article aims to analyze the various causes and relationships of fire with the urban pattern. Various spatial analytics and geostatistical techniques are applied to reveal spatiotemporal variations in the datasets. The novel machine learning framework models important variables identified by random forest technique as predictors to develop GWR models. The framework is applied to establish the relationship between fire vulnerability and urban patterns for two periods (day and night) for the southern region of Mumbai city. We found that the urban pattern has a strong relationship with fire vulnerability, especially during the day time. High R-square values of 0.9086 and 0.7448 are achieved for the day and night periods, respectively. Further, significant differences in the influence of the predictors is observed during the periods. As cities are becoming more prone to fire, this study has the potential to help decision …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:wBLCggQE-ToC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2022,"Distributed control over wireless networks is essential for cyber-physical systems (CPS) in which multiple agents work on a common task. Examples include mobile robots jointly manufacturing a product [7, 56] and drones flying in formation in a rescue mission [20]. To support emerging multi-agent CPS, a tight integration and co-design of wireless communication and control is needed that does the following:
• Facilitates distributed control. To coordinate their activities, each agent must be capable of exchanging messages with every other agent. In this way, each agent can drive a local control loop based on local sensor readings (eg, a drone can stabilize its flight), while in addition communication with other agents allows to solve a distributed control task (eg, drone swarm keeping a desired formation). This is commonly referred to as multi-agent",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:cww_0JKUTDwC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"The focus of this book is smart energy management with the recurring theme being the use of computational and data-driven methods that use requirements/measurement/monitoring data to drive actuation/control, optimization, and resource management. The computational perspective is applied to manage energy, with an emphasis on smart buildings and the smart electric grids. The book also presents computational thinking and techniques such as inferencing and learning for energy management. To this end, this book is designed to help understand the recent research trends in energy management, focusing specifically on the efforts to increase energy efficiency of buildings, campuses, and cities.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:uPCvBZYD9qUC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"Artificial intelligence-based techniques applied to the electricity consumption data generated from the smart grid prove to be an effective solution in reducing Non Technical Loses (NTLs), thereby ensures safety, reliability, and security of the smart energy systems. However, imbalanced data, consecutive missing values, large training times, and complex architectures hinder the real time application of electricity theft detection models. In this paper, we present EnsembleNTLDetect, a robust and scalable electricity theft detection framework that employs a set of efficient data pre-processing techniques and machine learning models to accurately detect electricity theft by analysing consumers’ electricity consumption patterns. This framework utilises an enhanced Dynamic Time Warping Based Imputation (eDTWBI) algorithm to impute missing values in the time series data and leverages the Near-miss undersampling …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:tgTmbKTkO1IC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"Residential solar installations are becoming increasingly popular among homeowners. However, renters and homeowners living in shared buildings cannot go solar as they do not own the shared spaces. Community-owned solar arrays and energy storage have emerged as a solution, which enables ownership even when they do not own the property or roof. However, such community-owned systems do not allow individuals to control their share for optimizing a home’s electricity bill. To overcome this limitation, inspired by the concept of virtualization in operating systems, we propose virtual community-owned solar and storage—a logical abstraction to allow individuals to independently control their share of the system. We argue that such individual control can benefit all owners and reduce their reliance on grid power. We present mechanisms and algorithms to provide a virtual solar and battery …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:urP0JZOBBUsC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"Buildings, viewed as cyber-physical systems, become smart by deploying Building Management Systems (BMS). They should be aware about the state and environment of the building. This is achieved by developing a sensing system that senses different interesting factors of the building, called as “facets of sensing.” Depending on the application, different facets need to be sensed at various locations. Existing approaches for sensing these facets consist of deploying sensors at all the places so they can be sensed directly. But installing numerous sensors often aggravate the issues of user inconvenience, cost of installation and maintenance, and generation of e-waste. This article proposes how intelligently using the existing information can help to estimate the facets in cyber-physical systems like buildings, thereby reducing the sensors to be deployed. In this article, an optimization framework has been developed …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:GtqhT-R7ZnwC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"Since the thermal condition of living spaces affects the occupants' productivity and their quality of life, it is important to design effective heating, ventilation and air conditioning (HVAC) control strategies for better energy efficiency and thermal comfort. An essential step in HVAC control and energy optimization is thermal comfort modeling. Recently, data-driven thermal comfort models have been preferred over the Fanger's Predicted Mean Vote (PMV) model due to higher accuracy and ease of use. However, the unavailability of comprehensive labelled thermal comfort data from the occupants poses a significant modeling challenge. This paper addresses data inadequacy issues by adopting ‘transfer learning’ to leverage well learned knowledge from source domain (same climate zones) to target domain (different climate zone) where modeling data is sparse. Specifically, a Transfer Learning based Convolutional …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:xii_ZKWM4-0C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"Smart meters are the backbone of smart grids. They provide real time electricity consumption data and and are widely used for measuring, monitoring and analyzing energy consumption. Sometimes, they enable users to perform corrective actions. But, to facilitate proper data analysis, it is imperative that data be accurate or have minimum error. This paper presents an edge deployed smart meter error correction algorithm that utilises Clustering (using K-Means algorithm) and Feed-Forward Artificial Neural Networks (ANN). An edge device, a Raspberry Pi Module, connects smart meters to the internet. The algorithm maps (possibly erroneous) readings of our in-house developed meters to readings of calibrated standard off-the-shelf (Schneider) meters. Usage of Clustering with ANN has helped substantially improve the accuracy of the readings from a previously used linear regression designed for the same purpose …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:ybfzIt2tCtgC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"A sustainable city is capable of supplying its energy and food, minimizing the dependence on fossil fuels, and assisting the city residents in reducing the ecological footprint. The promotion of renewable energy and energy efficiency is related not only to the change in lifestyle but also to the innovation and adoption of advanced technologies. The consumer receives financial compensation for selling the energy resulting in considerable savings on electricity cost. For residential consumers, it provides economic incentives for localized power generation, and utilities benefit from the reduction in transmission and distribution losses. Apart from this conventional use, there are several other applications – to store renewable energy, reduce peak consumption, and enable the consumers to participate in Demand Response (DR) programs – that are not widely exercised. The utilization of a pooled battery offers residential …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:iKswqCX-FLkC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"Increasing global building energy demand, with the related economic and environmental impact, upsurges the need for the design of reliable energy demand forecast models. This work presents k CNN-LSTM, a deep learning framework that operates on the energy consumption data recorded at predefined intervals to provide accurate building energy consumption forecasts. k CNN-LSTM employs (i) k− means clustering–to perform cluster analysis to understand the energy consumption pattern/trend;(ii) Convolutional Neural Networks (CNN)–to extract complex features with non-linear interactions that affect energy consumption; and (iii) Long Short Term Memory (LSTM) neural networks–to handle long-term dependencies through modeling temporal information in the time series data. The efficiency and applicability of k CNN-LSTM were demonstrated using a real time building energy consumption data acquired …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:LWqeokA2EBkC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"Power shortage is a serious issue especially in developing nations. Such power deficits are traditionally handled through rolling blackouts - a service area is divided into subareas, each of which is denied power during a designated time in the day. Today, smart grids provide the opportunity of avoiding complete blackouts, converting them to brownouts which allow selective provisioning of power supply to support essential loads while curtailing supply to less critical loads. We formulate the brownout based power distribution problem as an integer linear programming (ilp) and show that solution strategies such as conventional dynamic programming (dp) impose substantial overheads. So, we propose the streamlined dp-based priority level allocator (sdpa) which utilizes the discrete nature of power demands of each subarea and generates the overall optimal solution far quicker by focusing on a lower number of non-dominating partial dp-solutions. Sdpa is found to be about 9 to 33 times faster than dp and applicable to real-time brown-out based power distribution in moderate sized grids. However, even sdpa may fail to meet the real-time requirements of dynamic power imbalance mitigation in very large grids. So, a fast yet effective power adjustment approach namely, proportionally balanced priority level allocator (pbpa), has been designed and implemented. Experimental results show that although solutions provided by pbpa could be less effective by upto 12 percent compared to optimal dynamic programming based schemes, being about 4 orders of magnitude faster, it can be deployed for real time allocations of power. © 2020 ieee.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:uEM9VtRl8xsC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,The assessment of people’s perception of surroundings has been given less regard in top-down urban planning approaches. The earlier body of research aimed toward understanding preferences has been quintessential in highlighting modes and methods to appraise urban environments. Related studies have been focused on small-scale experiments based on evaluation of mainly visual realm due to unavailability of technological means and workforce to conduct research. We explore and review the possibilities of using recent advancements in technology for the collection of different sensory datasets required to gauge people’s perception and preference toward urban spaces on a large scale. This paper provides fresh perspectives on the integration of traditional research practices with the latest approaches in sensory data collection and analysis.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:4oJvMfeQlr8C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"The increasing frequency and intensity of disasters pose a big challenge while building resilient cities. Unplanned urbanization has further complicated the matter. In the era of building technology-driven smart citiesSmart cities, there is a lack of effective Information and Communication Technology (ICT)Information and Communication Technology (ICT)-based disaster managementDisaster Management (DM) implementation and strategic planning. To address these concerns, an ICT-based system is developed and tested during the fire drills. Testing of the system was done in sync with the workflow of a proposed framework for the city of Mumbai. The framework consists of an upgraded local disaster body, namely Smart Disaster Management Body (SDMB). The body is built upon the idea of ICTInformation and Communication Technology (ICT). Framework components and gaps are identified by attending fire drills …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:_9Xh93LWpsYC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2021,"The Government of Nepal lacked a common digital platform for communication among agencies during the response of 2015, Gorkha earthquake. It exposed the weakness in the utilisation of information and communication technologies (ICTs) to build the platform, which affected effective information communication for coordination among agencies. Lack of coordination delayed relief support, reconstruction, and rehabilitation during the post-disaster phase. It may result in effort duplication, uneven resource distribution, improper volunteer mobilisation, and expenditure documentation. We propose a government to government (G2G) crisis communication system to establish a digital platform to improve communication among agencies. A proactive communication system is established by adopting a four-channel crisis communication method. A structured interview-based survey with the officials of GoN captures their …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:j8pvxH-kN2QC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Phasor Measurement Unit (PMU) sensors are commonly used nowadays for sensing different line parameters of the grid for making it more efficient and reliable. However, they are costly to procure and maintain. Also, they may fail and produce measurements with errors. Towards these issues, a novel optimization model and a polynomial time algorithm are developed that solve these issues with respect to minimal PMU deployment in the grid. These techniques are compared and tested on the standard IEEE 5, 14, 30, 57 and 118 bus systems. For achieving cross-validation and robustness ability in the grid, the developed optimization model and algorithm deploy about 70% and 141% less number of additional PMUs, respectively, as compared with the baseline approach. The results indicate that the developed techniques are very pragmatic and holistic since they take minimal time for allocating minimum …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:adHtZc2wMuEC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"This study investigates people's perception of visual and auditory landscapes in a mixed-use urban environment. A set of audio and visual data is collected at different intervals during the day in local streets with the help of an audio recorder and camera setup. The High and Low-level features from the collected audio and visual datasets are captured with the help of custom Deep Learning (DL) models and other standard algorithms. The collected data is used in the perception survey, which included human subjects (n = 73). The evaluation of the individual perception is done with the help of eight and six auditory and visual perceptual attributes, respectively. The results from the survey are then studied in relation to the features extracted from algorithms. Finally, a street of 10 km length is chosen within the study area where a spatiotemporal street-level visual and auditory data is collected. Statistical analysis and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:4QKQTXcH0q8C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Heterogeneous and mixed urban forms profoundly influence fire susceptibility. Planning interventions to achieve fire resilience in urban areas are often not prioritized, primarily due to lack of analytical evidences. This paper proposes a novel analytical framework to reduce the fire-susceptibility in urban areas through optimal and cost-effective redevelopment of the existing UBFs. The framework includes a linear regression model to estimate the relationship between the fire-susceptibility of an area and the built-up spaces at a granular scale. A linear optimization model is incorporated in the framework to minimize the financial expenses, incurred during the redevelopment, for the reduction in fire-susceptibility of a city. The applicability of the framework is demonstrated through four different redevelopment scenarios of the southern part of Mumbai city. Pareto optimal solutions for various desired conditions of fire …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:WIXB4To3Tx4C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Data-driven approaches to computationally manage electricity consumption is envisioned as a standard practice under the smart grid paradigm. The roll out of Advanced Metering Infrastructure provides the necessary push for installation of smart meters for electricity consumers. Since smart meters are capable of measuring at fine temporal resolutions they act as a source of data for research challenges ranging from smart energy management to consumer participation and adoption of renewable energy sources. However, geographical location, built environment, climate and lifestyle preferences affect the electricity consumption patterns of a consumer. Therefore it is imperative to derive solutions using data that can represent specific conditions of demography and geographical region. To this end, we present SEIL-R- a public dataset of electricity consumption by residences of a multi-storey building located in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:QKtdBID3u5MC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Estimating the state of electric grid is a critical activity since it makes the grid more efficient and reliable. This is commonly achieved by Phasor Measurement Unit (PMU) sensors, which synchronise measurements using GPS. But these are expensive and costly to maintain. Most of the existing techniques mainly focus on minimizing the number of PMUs. But these sensors may produce errors, and may also fail and stop working. Therefore, in this paper, a novel heuristic algorithm has been developed that minimizes the number of PMUs to be allocated while tackling five different aspects of PMU allocation problems related to cross validation of PMU data, robustness against PMU failures and limitation on the number of PMUs that can be deployed on a node. The algorithm is simple to implement and takes only a fraction of a second to compute the results. The effectiveness of this technique has been successfully tested …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:GiYFt9mpioMC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Energy management is one of the critical challenges of smart buildings. This is achieved by sensing the different factors of building. The existing approaches overlook the problems associated with the deployment of a large number of sensors. However, this paper presents a novel and holistic minimum sensor deployment method - an optimization framework to sense different factors for better energy management in buildings. It describes how intelligently using the existing information can lead to a reduction in sensors. The optimization framework is compared with the baseline approach, which deploys sensors at all the locations where they should be sensed, for an existing building. The results indicate that the newly developed optimization framework requires 72.92% less sensors as compared to the baseline approach. This feature makes it an impressive proposition and results in lesser e-waste generation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:CRzUtm-VnGAC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Under the broader aegis of smart grid, the use of Distributed Ledger Technology to promote privacy, trust and security in peer-to-peer (P2P) energy sharing is gaining attention globally. However, implementation is limited to microgrid or neighbourhood level due to the challenges of scalability and performance associated with increase in number of prosumers. Therefore, the inclusion of stakeholders- producers to prosumers-require a scalable solution for advancing the information and energy exchange objectives. To this end, we propose CEnTrA, an application of sharding in blockchain to develop a novel hierarchical model capable of processing P2P energy sharing transactions at city-scale. CEnTrA is based on ChainSpace and takes advantage of the structure of the electrical grid to create a scalable network. The hierarchical model allows the use of customized transaction policies at different levels and locations …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:oldoQiaHq2UC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Abstract
Fire disasters pose a severe threat to the functionality of the cities and their sustainable development. Lack of analytical approach in research literature hinders the development of a fire-resilient city. A novel analytical framework is proposed in this paper to reduce the overall fire susceptibility of a city through a cost-effective redevelopment of the existing urban built forms (UBF). The proposed framework involves a regression model to capture the linear relationship between the fire susceptibility of an area and the built-up variables at a granular scale. Additionally, extended pinch analysis is incorporated in the framework to minimize the financial expenses incurred during the redevelopment, for the reduction in fire susceptibility of a city. The applicability of the proposed framework is demonstrated through a case study involving the southern region of Mumbai, India. The results suggest medium-rise buildings …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:kO05sadLmrgC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"In Urban areas buildings, the potential to harvest solar energy through facade is larger compared to the roof. Effective faade area available to harvest solar energy is influenced determined by the building bye-laws and also the national building codes, especially fire safety norms. Its potential depends not only on the geographical location but also on surrounding entities. Since BIPV has to must be implemented in the design phase of the building, accessing its potential for deploying appropriate technology is important. In urban areas, the solar potential is greatly affected by the shadowing from the surrounding objects such as trees, buildings, and, urban furniture. Solar potential is also influenced by geographical parameters such as climate, longitude, and latitude. Rooftop potential data, policies, and case studies are readily available for most developing countries but not the facade potential. In this study, we will …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:GJVTs2krol4C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Facade based building integrated Photovoltaic (BIPV) will form an integral part of the development of buildings with the aim of zero net-energy. Recent advancements and incentives have made the facade based BIPV a viable option in most of the European Union, Japan, and China. To maximize the yield of the BIPV, the BIPV module's position on the facade becomes critical because it affects electricity generation as well as influences the indoor comfort i.e. day-lighting and thermal gain. Placement of the BIPV is influenced by the surrounding obstacles and the building aesthetics. In this study, the placement of the BIPV modules is optimized for a given facade potential by framing an optimization problem. The objective is to maximize the yield of the BIPV module within the available facade area. The optimization problem is framed for a given facade area, radiation profile, and for two different module sizes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:Nnq8S6OXqDYC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Facade based building integrated Photo-voltaic(BIPV) is expected to form an integral part of the development of future urban buildings built with the aim of zero net-energy. Facade based BIPV can not only generate power but also be used to manage human comfort. Since the decision to include facade based BIPV has to be taken in the design phase of a building, it is important to know the thermal impact of BIPV on the indoor environment. The thermal impact varies with the transparency and technology of the BIPV. Currently, the performance of the BIPV is studied from the electricity generation and/or heating point of view. As of now, only one study is available in the literature, which compares two technologies of single transparency, their electricity generation potential, and their impact on indoor thermal comfort. The study presented in this paper focuses on data from two solar PV structures consisting of BIPV …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:hKjooKYXoHIC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Purpose
This paper aims to examine the factors that might influence the acceptance of government-to-government (G2G) systems in the Government of Nepal (GoN), to enhance the communication for coordination among government agencies.
Design/methodology/approach
After reviewing the Unified Model for E-Government Acceptance (UMEGA), interviews, focus group discussions with government officials and interviews with the retired senior government officials, a conceptual model has been proposed. The model is empirically tested with 234 responses collected from the government officials working in the central ministries of GoN using the structural equation modeling technique.
Findings
The result showed that factors considered from UMEGA such as performance expectancy, effort expectancy, facilitating conditions and attitude have a significant influence on the behavioral intention to use the system in the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:eFf2swCANGcC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"With a rampant increase in the urban population, especially in megacities, the number of high rise buildings is increasing rapidly. Both high rise buildings and lifestyle changes have resulted in high energy consumption. Heating, Ventilation, and Air Conditioning (HVAC) contribute the most to energy consumption in high-rise buildings. As thermal comfort is the major driving factor for the functioning of HVAC systems in a space, it is essential to understand how indoor environmental conditions vary across buildings' dimensions. Traditional approaches rely on simulations to understand the spatial and temporal variations of indoor conditions. Visualization offers opportunities to find solutions for complex thermal variations in buildings because of variation in environmental conditions owing to orientation, height, etc.
In this paper, we adopt a data-driven approach that considers the difference in indoor temperature …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:8RAEygVn5_EC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Imbalances in electricity supply and demand are a significant problem in developing countries resulting in rolling blackouts/load shedding. Due to the inconvenience caused by blackouts, several brownout (partial blackout) strategies have been proposed. In this paper, we resort to keeping the electricity demand of a household within a specified threshold. Our approach combines two distinct methods of end-point load (appliance) control: priority-based techniques and combinatorial optimization-based techniques to create a hybrid approach that gives users flexibility in configuring their preferences on-the-fly. We have quantified the user preferences using the Analytical Hierarchy Process, which is useful for solving such Multi-Criteria Decision-Making problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:pUxgyZctzPYC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Although built-up areas exacerbate the urban heat island (UHI) effect, the thermal impact of heterogeneous urban areas remains unknown. In this study geographically weighted regression (GWR) is used to examine the locally variable relationship between land surface temperatures (LSTs) and urban built form (UBF) indices. Sky view factor, built coverage, vegetation, building height, distance to ecosystem services and surface elevation are shown to have a significant geographically varying impact on LST and urban heat stress. These UBF variables can serve as urban design instruments, help predict LST and enable the mitigation of UHI effects in heterogeneous urban areas, while GWR offers a local planning tool for the formulation of climate-responsive, local area level development regulations and policies.
Abbreviations
BCR, Built Coverage Ratio; BHt, Building Height; DEM, Digital Elevation Model; DistES …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:CMvovTBb2okC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Data driven building energy consumption forecasting models play a significant role in enhancing the energy efficiency of the buildings through building energy management, energy operations, and control strategies. The multi-source and heterogeneous energy consumption data necessitates the integration of evolutionary algorithms and data-driven models for better forecast accuracy and robustness. We present eDemand, an energy consumption forecasting model which employs long short term memory networks and improved sine cosine optimization algorithm for accurate and robust building energy consumption forecasting. A novel Haar wavelet based mutation operator was introduced to enhance the divergence nature of sine cosine optimization algorithm towards the global optimal solution. Further, the hyperparameters (learning rate, weight decay, momentum, and number of hidden layers) of the LSTM …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:17ZO-CJnx_8C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Rapid deployment of Internet of Things (IoT) has led to ubiquitous and pervasive sensing of objects in the physical world, such as artifacts in buildings, agriculture, cities, the electric grid, etc. Meaningful visualization of large amounts of sensor data demands user-friendly, convenient and flexible tools. In this paper, we discuss the design, implementation and performance of a novel distributed caching & aggregation mechanism to handle the visualization of sensor data, which is time series data. Its features include a) bitmap indexing for capturing the dynamics of the cached data b) exploiting recency of data usage when making cache insertion and replacement decisions and c) integrating existing databases and open-source visualization platforms to provide quick and effective distributed caching solutions to handle time-series data. We evaluate our system on real-world data generated by sensors deployed in an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:G36d5HCDkJYC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2020,"Emergency Response Services (ERS) in the developing countries often face the challenge of distributing the resources in a manner to provide optimal service. Moreover, the exclusion of heterogeneous urban fabric and considerable variations of travel time and coverage demand throughout the day often leads to inadequate solutions. Hence, we propose an approach to incorporate dynamic aspects like demand, travel time, and coverage area in developing an asset location model. We illustrate how the travel time distribution produces more reliable coverage results when compared to the model considering fixed travel times over the periods. We also incorporate the influence of urban settlement elements like built-up compactness etc. in the resource allocation. A machine learning based approach is proposed to estimate the varying demand. The prediction model predicts the firefighting vehicles demand with high …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:NU-BerS4NX4C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"Facade based building integrated Photovoltaic (BIPV) will form an integral part in the development of buildings with the aim of zero net-energy. Facade areas are significantly larger than the roof areas in multistory, mid-rise or high-rise buildings, however the amount of radiation falling is less than on roofs. Case studies and policies exist for roof PV installations, but not for facade installations in tropical urban areas. Since the decision to include BIPV has to be taken in the design phase of a building, it is important to know the thermal impact of BIPV on the indoor environment. The thermal impact varies with transparency and technology of the BIPV utilized. Currently, the performance of the BIPV is studied from the electricity generation or a heating point of views. As of today, only one study is available in the literature, which compares two technologies of single transparency, their electricity generation potential and their …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:d4tt_xEv1X8C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"Solar energy helps to reduce pollution in urban areas and minimizes the dependence of urban electricity consumers on the utility by generating power locally. Local generation also reduces losses and increases the power supply reliability. Apart from electricity generation, solar energy could also be utilized to cool or heat a building as well as for day lighting to increase human comfort levels. The potential of this technology depends not only on the geographical location but also on the surrounding entities (eg presence of other buildings and obstacles). The conventional way of assessing the facade based Building Integrated Photovoltaic (BIPV) potential of a building is to develop 3-D models which involve solar geometrical calculations. A lot of resources are needed to estimate the solar potential of the buildings in a neighborhood or at city scale. Nevertheless, this method cannot be applied anywhere since many …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:8uzoZH4hB9AC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"Motivated by recent advancements in Deep Reinforcement Learning (RL), we have developed an RL agent to manage the operation of storage devices in a household and is designed to maximize demand-side cost savings. The proposed technique is data-driven, and the RL agent learns from scratch how to efficiently use the energy storage device given variable tariff structures. In most of the studies, the RL agent is considered as a black box, and how the agent has learned is often ignored. We explain the learning progression of the RL agent, and the strategies it follows based on the capacity of the storage device.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:pRWBApOjXDcC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"While the previous studies have attempted to quantify the environmental characteristics which stimulate different emotions and perceptions, the temporal aspect of the transient urbanscapes and the multimodality in data collection and analysis has not been given enough attention. The characteristics of the urban environment fluctuate with the time, time-based sensory data collection is, therefore, critical for comprehensive assessment of the surroundings. This research note aims to propose a methodology for the temporal and multimodal data collection and demonstrates the use of smartphone-based camera and handheld recorder to manually collect visual and audio datasets simultaneously from urban streets. It utilizes state of the art computer algorithms to extract attributes from the visual and auditory datasets which can further help in establishing comparison and relationships between different urban spaces …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:DquSII9TDu4C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"A solar PV-battery installation allows grid-connected electricity `prosumers' to engage in peak shaving, load shifting, Demand Response programs, and other grid ancillary services through data-driven energy management. These value streams generate revenue for consumers while assisting utilities in managing the grid. Such cyber-physical systems provide impetus to create consumer-centric business models that can leverage ICT infrastructure and resulting data for deployment of energy storage devices. This can lead to the diverse use of a battery as energy storage in a community where consumers, utility, and an energy management platform or service provider act as stakeholders. However, operation, control, management, and protection of stakeholders' interest in such smart community deployment projects exhibit complex interlinkages that are both technical and administrative. Thus ensuring a sustainable …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:cRMvf6lLvU8C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"The shift towards capacity building and deteriorating governance, may lead to poor service delivery which is a prime challenge for governing agencies. Different countries follow their own sets of governance parameters and often assess the outcome of policies based on them. In order to compose a uniform good governance framework, we have conducted a comparative analysis among 22 existing governance frameworks across the globe and shortlisted 13 major criteria along with 74 sub-criteria. We explored the method to measure these governance components with the help of various indicators and took expert opinion to distribute weight among these indicators. Finally, the case of Mumbai city is discussed with the examples of direct indicators, which may be used to measure a sub-criteria of any specific criteria. The quantification process is also demonstrated with three specific representative indicators. For …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:qsWQJNntlusC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"The performance of Convolutional Neural Networks (CNN) in satellite image classification tasks has been found superior to that of traditional algorithms. However, comparatively fewer studies have experimented with CNN-based classifiers to classify intra-urban characteristics with open mid and low-resolution earth observation (EO) datasets. The current pace of urbanization necessitates understanding and mapping of inherent urban forms, which would further assist in devising policies pertaining to sustainable urban development. While several remote sensing methods have been utilized to understand the urban structure, the replicability and generalizability of such approaches have been some of the key limitations. This study creates the CNN model to identify the degrees of built arrangement in mid resolution Sentinel 2B imagery of ten largest Indian cities. Training and testing datasets for seven land cover …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:cdwqcPQS8ssC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"Building Integrated Photovoltaics (BIPV) is expected to be a viable option for Near Zero/Zero Energy Buildings (NZEB/ZEB) in urban areas. Facade based BIPV gives an option to the builders/designers to manage human comfort as well as improve aesthetics by including more than one BIPV technology or transparency. However, from the power generation point of view, these PV modules are subjected to non-uniform illumination and partial shading due to the surrounding buildings and structures in most urban scenario. The power output of the modules do not match with the inverter rating as they do not receive direct radiation for most of the day and implementation of vertical orientation minimizes the power generation. Connecting them in series and/or parallel is an option to increase power generation, but it is highly influenced by the shading patterns. In this paper, we propose a scheme of power converters for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:ShjGdcaqzI0C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"The thermal profile of the urban built-up area is essential for reducing the impact of built-up areas on urban heat stress. This study quantifies the variations in the outdoor thermal profile of built forms in a heterogeneous urban area. A two-step process was adopted to quantify built form induced heat stress. The build form typologies referred to as Urban Built Form (UBFX) were clustered based on parameterised build form indices (sky view factor, built height etc.) using statistical data reduction. The heat stress of the categorised UBFs was then examined through field measurements and radiation simulation model. Variations in thermal variables were assessed using three indices - Cooling Potential (CP), Humidex (Hx) and Mean Radiant Temperature (Tmrt) that collectively define the thermal profile of each UBF. A novel Heat Stress Risk Index (HSRI) was conceptualised and computed to represent the aggregate risk of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:qCpRzq7zkD8C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"Slums provide cheaper workforce and informal services which contribute substantially towards GDP. However, such areas, due to the high population density, sub-standard housing and lack of essential services are urban risks. The socio-physical development of such settlements has often been neglected due to poor laws and provisions in urban management and policies. One of the primary reasons for negligence has been the unavailability of slum maps to study the evolution of slums and to actively manage and contain them. Various remote sensing techniques have been utilized to answer the problem but have not produced universal solutions. In recent years, Deep Learning (DL) techniques with remote sensing have been found beneficial in comprehending the underlying structure of physical features present in the satellite imageries. This study deals with one of the Deep Learning techniques which use pre …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:rqnDXT1GswoC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"Rapid urbanization with haphazard growth pattern often leads to intensification of built-up areas. The built-up areas increase the ambient air temperature and results in heat stress conditions thereby causing adverse health impacts. Therefore, mitigation of urban warming has become a major concern for urban administrators. Accurate identification of heat stressed areas has been difficult due to the low spatial or temporal resolutions of data collected through conventional methods. Hence, in this paper, we have applied an ICT based solution by deploying low cost sensor modules at various building typologies to continuously monitor and capture the diurnal thermal variations in air temperatures. With diurnal temperature profile, we could assess 1) the thermal gradient of varied built typologies and, 2) using spatial analytics, we could analyse the spatial variability of hotspots in the study area. ICT based data-driven …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:MDX3w3dAD3YC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"Deep learning (DL) methods have provided several breakthroughs in conventional data analysis techniques, especially with image and audio datasets. Rapid assessment and large-scale quantification of environmental attributes have been possible through such models. This study focuses on the creation of Artificial Neural Networks (ANN) and Recurrent Neural Networks (RNN) based models to classify sound sources from manually collected sound clips in local streets. A subset of an openly available AudioSet data is used to train and evaluate the model against the common sound classes present in the urban streets. The collection of audio data is done at random locations in the selected study area of 0.2 sq. km. The audio clips are further classified according to the extent of anthropogenic (mainly traffic), natural and human-based sounds present in particular locations. Rather than the manual tuning of model …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:c1AJUTjuCtUC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"Traditional city planning and design tools require major restructuring. Even with the rapid growth in the availability of mobile communication devices, connectivity, data generation, and analysis tools, the idea of the creation of citizen-centric and smart cities has not been fully conceptualized. Individual perception and preferences toward urban spaces play an important role in mental satisfaction and wellbeing. However, the notion has not been studied and experimented along with various planning instruments. This study discusses the recent studies involving Artificial intelligence tools and sensory data collection. This paper further comment on the integrated methodology to collect sensory datasets that will further help in the evaluation of urban surroundings with individual perspectives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:4n0clTBhZ78C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2019,"The data generated by many applications is in semi structured format, such as XML. This data can be used for analytics only after shredding and storing it in structured format. This process is known as Extract-Transform-Load or ETL. However, ETL process is often time consuming due to which crucial time-sensitive insights can be lost or they may become un-actionable. Hence, this paper poses the following question: How do we expose analytical insights in the raw XML data? We address this novel problem by discovering additional information from the raw semi-structured data repository, called complementary information (CI), for a given user query. Experiments with real as well as synthetic data show that the discovered CI is relevant in the context of the given user query, nontrivial, and has high precision. The recall is also found to be high for most queries. Crowd-sourced feedback on the discovered CI …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:orDZ08hpP44C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"The studies in the classification of the urban spatial structure have been essential in deriving insights into the land cover and the built typology which helped in the estimation of energy consumption patterns, urban density, compactness, and hierarchy of settlements. However, the analysis and comparison of the physical forms of the cities have been attempted in a piecemeal fashion where the requirement of datasets and the computation power for analysis has been a major hindrance. With the advancement in machine learning based techniques, large datasets such as satellite imagery can be studied with advanced computer vision methods. These solutions may help in studying the intricate nature of human habitats in large extents of geographical areas including various urban areas. This study utilizes smaller patches of medium resolution Sentinel-2B Imagery of ten different cities in India to explore the urban forms present in these cities. This study uses Stacked Convolutional Autoencoder (CAE) to reduce the dimensionality of satellite imagery patches and unsupervised clustering techniques such as t-SNE and K-means to study the characteristics of similar patches. On analyzing the clusters through visual exploration, similar patches are delineated and provided with corresponding labels representing urban forms. Individual clusters are then studied with respect to each city. The motive of the study is to gain insights into the different types of morphological patterns present within and among cities.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:cNe27ouKFcQC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"In most process control systems nowadays, process measurements are periodically collected and archived in historians. Analytics applications process the data, and provide results offline or in a time period that is considerably slow in comparison to the performance of many manufacturing processes. Along with the proliferation of Internet-of-Things (IoT) and the introduction of ""pervasive sensors"" technology in process industries, increasing number of sensors and actuators are installed in process plants for pervasive sensing and control, and the volume of produced process data is growing exponentially. To digest these data and meet the ever-growing requirements to increase production efficiency and improve product quality, there needs a way to both improve the performance of the analytic system and scale the system to closely monitor a much larger set of plant resources. In this paper, we present a real-time …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:QaSi33NTfwYC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"Urbanization leads to the densification of built-up areas, and thereby increases surface heat island intensity which is one of the growing concerns in the rapidly urbanizing cities. Another notable aspect of cities like Mumbai is the uncontrolled growth of informal slum housing clusters, which have emerged as a significant urban built form in the landscape of cities. This study presents a case of Mumbai that aims to explore the linkages between slum housing—here referred as ‘slum urban form’ (SUF)—and surface urban heat island (SUHI) supported by spatial-statistical analysis. The magnitude of the impact of urban form on SUHI, measured by land surface temperature (LST), is examined using Cohen’s d index, which measures the effect size for two groups—SUF and ‘formal’ housing—on LST. The results confirm a ‘large’ effect indicating a significant difference in mean LST between the two groups. The spatial …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:hefNtdE4IMkC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"The assessments on human perception of urban spaces are essential for the management and upkeep of surroundings. A large part of the previous studies is dedicated towards the visual appreciation and judgement of various physical features present in the surroundings. Visual qualities of the environment stimulate feelings of safety, pleasure, and belongingness. Scaling such assessments to cover city boundaries necessitates the assistance of state-of-the-art computer vision techniques. We developed a mobile-based application to collect visual datasets in the form of street-level imagery with the help of volunteers. We further utilised the potential of deep learning-based image analysis techniques in gaining insights into such datasets. In addition, we explained our findings with the help of environment variables which are related to individual satisfaction and wellbeing.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:SpPTWFSNUtQC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:j5aT6aphRxQC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"Smart meters allow us to track a variety of electrical parameters including voltage. Even though mains voltage is assumed to remain constant, it does vary, albeit within a small range, so the variation is mostly ignored. But we show how the small variations in voltage sensed at different points in the electrical system and the relative variations in voltage values at a certain location can be exploited for better disaggregation of appliance loads, differentiating between appliances, even of the same type, increasing the scope of disaggregation for performing tasks like sub-metering and fault localization. We believe that our solution is a highly practical and simpler alternative to the more involved techniques that require sophisticated algorithms and/or hardware. To top it all, the proposed technique is also general-purpose and cost-effective.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:idthP5jqfYAC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"Since many residential locations are unsuitable for solar deployments due to space constraints, community-owned solar arrays with energy storage that are collectively shared by a group of homes have emerged as a solution. However, such a group-owned system does not allow individual control over how the electricity generation from the solar array and energy stored in the battery is used for optimizing a home's electricity bill. To overcome this limitation, we propose vSolar, a technique that virtualizes community solar and battery arrays such that each virtual system can be independently controlled, regardless of others. Further, we present mechanisms and algorithms that allow homes with surplus energy to lend to homes with deficit energy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:NtCmTCuxid4C,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"This paper presents a comparative study of the expected changes in load curves of two major cities in India, if their respective rooftop PV potentials are achieved. Rooftop PV potential assessments studies done for the city of Mumbai concluded that the city has around 1.72 GW potential. Based on similar studies, the city of Delhi is reported to have around 2.56 GW potential. Load pattern of the cities were obtained from the data from 'load dispatch centers' of the respective cities and PV generation patterns were simulated using PVSyst software. It was observed that, in Indian cities, the summer load curve has two peak demand points, one at midday and one in the late evening. In winter, the peak occurs in the morning. If we can have a fairly distributed rooftop PV system in the city (so that the local fluctuations in generation due to cloud movement, etc., can be neglected) the city's peak load demand during the midday …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:q0uBw5dMOAkC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"Thermal modeling is necessary if we want to control the thermal environment in a space within a building. Heating, Ventilation and Air-Conditioning (HVAC) equipment are usually installed in a building based on the empirical formula developed by the manufacturers considering the worst case scenarios of heat loss/gain through the walls, the windows and from other sources like body heat. In order to provide thermal comfort in building spaces and at the same time save energy, accurate modeling is required for adequate provisions and control of HVAC equipment. Better accuracy of a building's thermal model usually increases the complexity and thereby the demand for higher processing capability of the computer-based controller. This can increase the cost and the payback period and often become deterrent to implementation in large real-world buildings. This work is an attempt to study the existing modeling …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:as0KMg8qHbkC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"Power shortage is a serious issue in developing nations. During periods of high demand, utilities need to motivate the consumers to curtail their consumption for maintaining grid stability and avoiding blackouts or brownouts. Identification of suitable candidates is essential for such events, as the budget set aside by utilities for Demand Response (DR) events for providing incentives to the consumers should not exceed the added production cost due to peaks. Similarly, from the consumers' point of view, participation comes with the compromise to their convenience. Hence, the selection criteria should be such that it minimizes the peaking cost to the utility without affecting consumer comfort.
In this paper, we present SmarDeR, a smart DR consumer selection strategy which considers several factors and consolidates them into a single function which can work in different modes to strategically choose the candidates for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:v_tt_AnqfNMC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"Power shortage is a serious issue especially in third world countries, and is traditionally handled through rolling blackouts. Today, smart grids provide the opportunity of avoiding complete blackouts by converting them to brownouts, which allow selective provisioning of power supply to support essential loads while curtailing supply to less critical loads. In this work, we formulate brownout based power distribution scheduling as an optimization problem and propose a modified Dynamic Programming (DP) based optimal algorithm (suitable for moderate sized grids) that is 9 to 40 times faster than the conventional DP approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:M_lZXyI38BkC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"A national identity scheme has long-term and large-scale implications to the welfare of the people, efficiency of governance and law enforcement, individuals’ fundamental right to privacy and national security. Motivated by several issues surfaced by the implementation of Aadhaar, and several privacy and security concerns that have been pointed out, we develop a (non-exhaustive) list of technical guidelines for national identity schemes. We observe that the current Aadhaar design significantly deviates from these guidelines, strongly suggesting that to address the root causes of the issues that have manifested so far, many parts of the system require major redesign. We also put forth several policy guidelines, which we believe are crucial to the success of a national identity scheme in India.
Digital technology is a powerful tool, and India, like any other modern nation, can ill afford to keep away from exploiting the promises it offers. Yet, one needs to wield this technology with caution, like a scalpel rather than a sledge hammer, especially when it is applied at a national scale and affects millions of the poorest and most vulnerable. One should also bear in mind that any cyber infrastructure that is being developed today will become targets for cyber warfare in the future.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:Nw_I7GeUguwC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"Ubiquitous sensing enabled by Wireless Sensor Network(WSN) technologies offers the ability to measure, infer and understand environmental parameters and respond to changes. In this paper, we describe our Internet of Things(IoT)-based intelligent solution designed to reduce the energy consumption in existing buildings without affecting the thermal comfort of the users. We have designed IoT nodes which can be used for sensing necessary parameters in any environment. Based on the measured values they send appropriate control commands to the appliances such as lights, fans or ACs, making the infrastructure smart, which helps us achieve our goal of reducing the energy consumption. We have deployed our IoT nodes in four classrooms in our academic building to make them smart.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:h168fVGZblEC,http://www.cse.iitb.ac.in/~krithi
Krithi Ramamritham,"['databases', 'real-time systems', 'ICT based solutions for society']",25,2842,2018,"Presents a listing of the editorial board, board of governors, current staff, committee members, and/or society editors for this issue of the publication.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LFLG5pcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LFLG5pcAAAAJ:E7VqQtBCVmcC,http://www.cse.iitb.ac.in/~krithi
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2023,"With wide adaptation of open-source Android into mobile devices by different device vendors, sophisticated malware are developed to exploit security vulnerabilities. As comprehensive security analysis on physical devices are impractical and costly, emulator-driven security analysis has gained popularity in recent times. Existing dynamic analysis frameworks suffer from two major issues: (i) they do not provide foolproof anti-emulation-detection measures even for fingerprint-based attacks, and (ii) they lack efficient cross-layer profiling capabilities. In this work, we present InviSeal, a comprehensive and scalable dynamic analysis framework that includes low-overhead cross-layer profiling techniques and detailed anti-emulation-detection measures along with the basic emulation features. While providing an emulator-based comprehensive analysis platform, InviSeal strives to remain behind-the-scene to avoid …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:ldfaerwXgEUC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2022,"Data prefetching is a technique that plays a crucial role in modern high-performance processors by hiding long latency memory accesses. Several state-of-the-art hardware prefetchers exploit the concept of deltas, defined as the difference between the cache line addresses of two demand accesses. Existing delta prefetchers, such as best offset prefetching (BOP) and multi-lookahead prefetching (MLOP), train and predict future accesses based on global deltas. We observed that the use of global deltas results in missed opportunities to anticipate memory accesses.In this paper, we propose Berti, a first-level data cache prefetcher that selects the best local deltas, i.e., those that consider only demand accesses issued by the same instruction. Thanks to a high-confidence mechanism that precisely detects the timely local deltas with high coverage, Berti generates accurate prefetch requests. Then, it orchestrates the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:2P1L_qKh6hAC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2022,"On a multi-core system, the shared last-level cache(LLC) is vulnerable to various kinds of cross-core contention-based attacks. LLC randomization and LLC partitioning are two promising mitigation strategies that mitigate these attacks. LLC-randomization techniques make an attacker’s life difficult in mounting contention-based attacks but do not entirely mitigate them. Randomized caches are also ineffective in preventing occupancy-based attacks. In contrast, state-of-the-art LLC partitioning techniques mitigate all possible LLC contention-based attacks by allocating isolated LLC regions to different processes or security domains. However, restricting processes to isolated LLC region(s) affects overall LLC utilization and incurs performance overhead (as high as 72%) and memory subsystem energy overhead (as high as 89%); effectively providing security guarantee at the cost of performance and energy.One of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:70eg2SAEIzsC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2022,"Intel SGX preserves the confidentiality and integrity aspects of data and code through enclaves (that reside in the trusted part of the memory) and protects it from different layers of the malicious system software, including the OS. Micro-architecture research in the presence of SGX is an interesting theme to explore as SGX does not mitigate timing side-channel attacks at various levels of a memory hierarchy and causes significant performance slowdown. The research community extensively uses existing benchmark suites like SPEC CPU 2017 for evaluating new proposals on the various aspects of micro-architecture research. As there is no benchmark suite available for micro-architecture research with SGX, state-of-the-art micro-architecture research in the presence of SGX assumes an entire SPEC benchmark is running inside an enclave. In reality, Intel SGX assumes that a major portion of the application's code …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:ns9cj8rnVeAC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2022,"With the inception of the Spectre attack in 2018, microarchitecture mitigation strategies propose secure cache hi-erarchies that do not leak the speculative state. Among many mitigation strategies, MuonTrap, proposes an efficient, secure cache hierarchy that provides speculative attack resiliency with minimum performance slowdown. Hardware prefetchers play a significant role in improving application performance by fetching and bringing data and instructions into caches before time. To prevent hardware prefetchers from leaking information about the speculative blocks brought into the cache, MuonTrap trains and triggers hardware prefetchers on the committed instruction streams, eliminating speculative state leakage. We find that on-commit prefetching can lead to significant performance slowdown as high as 20.46 % (primarily because of prefetch timeliness issues), making hardware prefetchers less effective …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:YFjsv_pBGBYC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2022,"With the large-scale adaptation of Android OS and ever-increasing contributions in the Android application space, Android has become the number one target of malware writers. In recent years, a large number of automatic malware detection and classification systems have evolved to tackle the dynamic nature of malware growth using either static or dynamic analysis techniques. Performance of static malware detection methods degrade due to the obfuscation attacks. Although many benchmark datasets are available to measure the performance of malware detection and classification systems, only a single obfuscated malware dataset (PRAGuard) is available to showcase the efficacy of the existing malware detection systems against the obfuscation attacks. PRAGuard contains outdated samples till March 2013 and does not represent the latest application categories. Moreover, PRAGuard does not provide the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:lSLTfruPkqcC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2022,"Usage of the execution stack at run-time captures the dynamic state of programs and can be used to derive useful insights into the program behaviour. The stack usage information can be used to identify and debug performance and security aspects of applications. Binary run-time instrumentation techniques are well known to capture the memory access traces during program execution. Tracing the program in entirety and filtering out stack specific accesses is a commonly used technique for stack related analysis. However, applying vanilla tracing techniques (using tools like Intel Pin) for multi-threaded programs has challenges such as identifying the stack areas to perform efficient run-time tracing.
In this paper, we introduce SniP, an open-source stack tracing framework for multi-threaded programs built around Intel's binary instrumentation tool Pin. SniP provides a framework for efficient run-time tracing of stack …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:RYcK_YlVTxYC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2022,"Flush-based cache attacks like Flush+Reload and Flush+Flush are highly precise and effective. Most of the flush-based attacks provide high accuracy in controlled and isolated environments where attacker and victim share OS pages. However, we observe that these attacks are prone to low accuracy on a noisy multi-core system with co-running applications. Two root causes for the varying accuracy of flush-based attacks are: (i) the dynamic nature of core frequencies that fluctuate depending on the system load, and (ii) the relative placement of victim and attacker threads in the processor, like same or different physical cores. These dynamic factors critically affect the execution latency of key instructions like clflush and mov, rendering the pre-attack calibration step ineffective.We propose DABANGG, a set of novel refinements to make flush-based attacks resilient to system noise by making them aware of frequency …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:J_g5lzvAfSwC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2022,"Performance of Translation Lookaside Buffers (TLBs) and on-chip caches plays a crucial role in delivering high-performance for memory-intensive applications with irregular memory accesses. Our observations show that, on average, an L2 TLB (STLB) miss for address translation can stall the head of the reorder buffer (ROB) for a maximum of 50 cycles. The corresponding data request, also called as the replay load can stall the head of the ROB for more than 200 cycles. We show that current state-of-the-art mid-level (L2C) and last-level cache (LLC) replacement policies do not treat cache block with address translations and replay data access differently. As a result these policies fail to reduce ROB stalls because of translation and replay data access misses. To improve the performance further on top of high-performing cache replacement policies, we propose address translation and replay data access conscious …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:NaGl4SEjCO4C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2022,"High-performance branch target buffers (BTBs) and the L1I cache are key to high-performance front-end. Modern branch predictors are highly accurate, but with an increase in code footprint in modern-day server workloads, BTB and L1I misses are still frequent. Recent industry trend shows usage of large BTBs (100s of KB per core) that provide performance closer to the ideal BTB along with a decoupled front-end that provides efficient fetch-directed L1I instruction prefetching. On the other hand, techniques proposed by academia, like BTB prefetching and using retire order stream for learning, fail to provide significant performance with modern-day processor cores that are deeper and wider.
We solve the problem fundamentally by increasing the storage density of the last-level BTB. We observe that not all branch instructions require a full branch target address. Instead, we can store the branch target as a branch …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:RGFaLdJalmkC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2021,"Non-volatile memory (NVM) provides persistent memory semantics with access latencies comparable to volatile DRAM. The persistent nature of NVM requires the application developers to design data consistency mechanisms for failure recovery, without which application may end up with inconsistent memory state after a power failure or a system crash. Most commonly employed methods use architectural support for cache line flushing and memory fencing to enforce ordering of writes to NVM. In this paper, we study the performance overhead of different hardware primitives used to achieve NVM consistency on Intel x86-64 and Arm64 systems using micro-benchmarks. Further, we also empirically analyze the impact of working set size and memory access characteristics (read-to-write ratio) of applications on different data consistency techniques. Logging based mechanisms (e.g., redo and undo logging …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:BqipwSGYUEgC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2021,"Over the past few years, Android has become one of the most popular operating systems for smartphones as it is open-source and provides extensive support for wide variety of applications. This has led to an increase in the number of malware targeting Android devices. The lack of robust security enforcement in Play Store along with the rapid increase in the number of new Android malware presents a scope for a variety of diverse malicious applications to spread across devices. Further-more, Android allows installation of an application from unver-ified sources (e.g., third-party market and sideloading), which opens up other ways for mal ware to infect the smartphones. This paper presents DeepDetect that enables on-device malware detection by employing a machine learning based model on static features. With effective feature engineering, DeepDetect can be used on-device. To classify an Android application …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:GnPB-g6toBAC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2021,"Recent trends of the use of deep neural networks (DNNs) in mission-critical applications have increased the threats of microarchitectural attacks on DNN models. Recently, researchers have proposed techniques for inferring the DNN model based on microarchitecture-level clues. However, existing techniques require prior knowledge of victim models, lack generality, or provide incomplete information of the victim model architecture. This paper proposes an attack that leaks the layer-type of DNNs using hardware performance monitoring counters (PMCs).
Our attack works by profiling low-level hardware events and then analyzes this data using machine learning algorithms. We also apply techniques for removing the class imbalance in the PMC traces and for removing the noise. We present microarchitectural insights (hardware PMCs such as cache accesses/misses, branch instructions, and total instructions) that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:hMod-77fHWUC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2021,"Hardware data prefetching is a latency hiding technique that mitigates the memory wall problem by fetching data blocks into caches before the processor demands them. For high performing state-of-the-art data prefetchers, this increases dynamic and static energy in memory hierarchy, due to increase in number of requests. A trivial way to improve energy-efficiency of hardware prefetchers is to prefetch instructions on the critical path of execution. As criticality-based data prefetching does not degrade performance significantly; this is an ideal approach to solve the energy-efficiency problem. We discuss limitations of existing critical instruction detection techniques and propose a new technique that uses re-order buffer occupancy as a metric to detect critical instructions and performs prefetcher-specific threshold tuning. With our detector, we achieve maximum memory hierarchy energy savings of 12.3% with 1.4 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:NMxIlDl6LWMC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2021,"Cross-core conflict-based timing attacks like Prime+Probe at the shared last-level cache (LLC) are practical and can cause information leakage. Cache address randomization is one of the techniques that claim to mitigate these attacks. CEASER, CEASER-S, and ScatterCache are the three recent randomized caches that use encryption engines to randomize the memory address mapping. CEASER and CEASER-S, along with encryption engines, remap the cache blocks periodically to break the static mapping of memory blocks into the LLC blocks. Encryption engine and remapping provide security to the randomized caches. However, access to encryption engines and the remapping of cache blocks are on the critical path of LLC accesses. We target encryption engine and remapping of randomized cache to mount a denial of service (DoS) attack named DAMARU. In DAMARU, the attacker frequently sends memory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:JV2RwH3_ST0C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2021,"Keystone is a trusted execution environment, based on RISC-V architecture. It divides the memory into a secure Keystone private memory and an unsecure non-Keystone memory, and allows code that lies inside the Keystone private memory to execute securely. Simple demand paging in Keystone ends up leaking sensitive access patterns of Keystone application to the Operating System(OS), that is assumed to be malicious. This is because, to access the unsecure non-Keystone memory, Keystone needs support of the OS. To mitigate this, Keystone needs to implement oblivious demand paging while obfuscating its page access patterns by using Oblivious RAM(ORAM) techniques. This causes substantial slowdown in the application execution. In this paper, we bridge the performance gap between application execution time with unsecure and secure demand paging in Keystone by using Deterministic, stash free, Write only ORAM (DetWoORAM) for oblivious demand paging. We also show why DetWoORAM, that is a write-only ORAM, is sufficient for oblivious demand paging. DetWoORAM logically partitions the memory into a main area and a holding area. The actual pages are stored in main area. We propose two enhancements over DetWoORAM that improves the application execution slowdown. The first enhancement, which we call the Eager DetWoORAM, involves page preloading that exploits the deterministic access pattern of DetWoORAM, and tries to hide the ORAM latency. The second enhancement, which we call the Parallel DetWoORAM, involves spawning multiple threads and each thread performs a part of the DetWoORAM …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:M3NEmzRMIkIC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2021,"High-performance branch target buffers (BTBs) and the L1I cache are key to high-performance front-end. Modern branch predictors are highly accurate, but with an increase in code footprint in modern-day server workloads, BTB and L1I misses are still frequent. Recent industry trend shows usage of large BTBs (100s of KB per core) that provide performance closer to the ideal BTB along with a decoupled front-end that provides efficient fetch-directed L1I instruction prefetching. On the other hand, techniques proposed by academia, like BTB prefetching and using retire order stream for learning, fail to provide significant performance with modern-day processor cores that are deeper and wider. We solve the problem fundamentally by increasing the storage density of the last-level BTB. We observe that not all branch instructions require a full branch target address. Instead, we can store the branch target as a branch offset, relative to the branch instruction. Using branch offset enables the BTB to store multiple branches per entry. We reduce the BTB storage in half, but we observe that it increases skewness in the BTB. We propose a skewed indexed and compressed last-level BTB design called MicroBTB (MBTB) that stores multiple branches per BTB entry. We evaluate MBTB on 100 industry-provided server workloads. A 4K-entry MBTB provides 17.61% performance improvement compared to an 8K-entry baseline BTB design with a storage savings of 47.5KB per core.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:k_IJM867U9cC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2021,"Cross-core cache attacks glean sensitive data by exploiting the fundamental interference at the shared resources like the last-level cache (LLC) and coherence directories. Complete non-interference will make cross-core cache attacks unsuccessful. To this end, we propose a seclusive cache hierarchy with zero storage overhead and a marginal increase in on-chip traffic, that provides non-interference by employing cache-privatization on demand. Upon a cross-core eviction by an attacker core at the LLC, the block is back-filled into the private cache of the victim core. Our back-fill strategy mitigates cross-core conflict based LLC and coherence directory-based attacks. We show the efficacy of the seclusive cache hierarchy by comparing it with existing cache hierarchies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:TFP_iSt0sucC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:blknAaTinKkC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2020,"Micro-architectural attacks exploit timing channels at different micro-architecture units. Some of the micro-architecture units like cache automatically provide the timing difference (the difference between a hit and a miss). However, there are other units that are not documented, and their influence on the timing difference is not fully understood. One such micro-architecture unit is an L2 hardware prefetcher named Streamer. In this paper, we reverse-engineer the Stream prefetcher, which is commercially available in the Intel machines. We perform a set of experiments and provide our observations and insights. Further, we use these observations to construct a cross-thread covert channel using the Stream prefetcher, with an accuracy of 91.3% and a bandwidth of 54.44 KBps.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:iH-uZ7U-co4C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2020,"Hardware prefetching is one of the common off-chip DRAM latency hiding techniques. Though hardware prefetchers are ubiquitous in the commercial machines and prefetching techniques are well studied in the computer architecture community, the “memory wall” problem still exists after decades of microarchitecture research and is considered to be an essential problem to solve. In this paper, we make a case for breaking the memory wall through data prefetching at the L1 cache.We propose a bouquet of hardware prefetchers that can handle a variety of access patterns driven by the control flow of an application. We name our proposal Instruction Pointer Classifier based spatial Prefetching (IPCP). We propose IPCP in two flavors: (i) an L1 spatial data prefetcher that classifies instruction pointers at the L1 cache level, and issues prefetch requests based on the classification, and (ii) a multi-level IPCP where the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:4JMBOYKVnBMC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2020,"Sophisticated malware employs various emulation-detection techniques to bypass the dynamic analysis systems that are running on top of virtualized environments. Hence, a defense mechanism needs to be incorporated in emulation based analysis platforms to mitigate the emulation-detection strategies opted by malware. In this paper, first we design an emulation-detection library that has configurable capabilities ranging from basic to advanced detection techniques like distributed detection and GPS information. We use this library to arm several existing malware with different levels of emulation-detection capabilities and study the efficacy of anti-emulation-detection measures of well known emulator driven dynamic analysis frameworks. Furthermore, we propose STDNeut (Sensor, Telephony system, and Device state information Neutralizer) – a configurable anti-emulation-detection mechanism that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:bEWYMUwI8FkC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2020,"Flush based cache attacks like Flush+ Reload and Flush+ Flush are one of the highly effective cache attacks. In fact, the Flush+ Flush attack is stealthy too. Most of the flush based attacks provide high accuracy in controlled environments where attacker and victim are the only two processes that are running on a system by sharing OS pages. However, we observe that these attacks lose their effectiveness (prone to low accuracy) on a noisy multi-core system where co-running applications run along with the attacker and the victim. Two root causes for the varying accuracy of flush based attacks are:(i) the dynamic nature of core frequencies that fluctuate depending on the system load, and (ii) the relative placement of victim and attacker threads in the processor (same logical core, same physical core, different physical cores). The variation in the processor frequencies and placement of threads affect one of the critical attack steps (the cache latency calibration step as the latency threshold set to distinguish a cache hit from a miss becomes inaccurate). We propose a set of refinements (DABANGG refinements) to make existing flush attacks resilient to frequency changes and thread placement in the processor, and therefore system noise. We propose refinements to pre-attack and attack steps and make it conscious about the latency change. We evaluate DABANGG-enabled Flush+ Reload and Flush+ Flush attacks (DABANGG+ Flush+ Reload and DABANGG+ Flush+ Flush, respectively) against the standard Flush+ Reload and Flush+ Flush attacks across four scenarios for eight different combinations of system noise capturing different levels of compute …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:r0BpntZqJG4C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2020,"Large instruction working sets are common with modern client and server workloads. These working sets often fit in the large last-level cache (LLC). However, the L1 instruction cache (L1-I) suffers from a high miss rate blocking the instruction supply to the front-end of the processor. Instruction prefetching is a latency hiding technique that can bring instructions from the LLC into the L1-I. We propose a bouquet of instruction pointer (IP) jumpers, named JIP. JIP is a high-performance L1-I prefetcher that uses different prefetching techniques by classifying instructions into the following categories:(i) a nonbranch,(ii) a branch that jumps to a single target IP on all instances, and (iii) a branch that jumps to different target IPs on different instances. Compared to a baseline with no instruction prefetching, averaged across 50 traces, JIP provides a prefetch coverage of 91.33%(as high as 99.99%), which leads to a performance improvement of 27.75%(as high as 93%). JIP makes a strong case for instruction prefetching as the performance gap between the perfect L1-I and JIP is just 7.49%. JIP demands a hardware overhead of 127.8 KB.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:j3f4tGmQtD8C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2019,"Cross-core last-level cache (LLC) eviction based side-channel attacks are becoming practical because of the inclusive nature of shared resources (e.g., an inclusive LLC), that creates back-invalidation-hits at the private caches. Most of the cross-core eviction based side-channel attack strategies exploit the same for a successful attack. The fundamental principle behind all the cross-core eviction attack strategies is that the attacker can observe LLC access time differences (in terms of latency differences between events such as hits/misses) to infer about the data used by the victim. We fool the attacker (by providing LLC hits to the addresses of interest) through a back-invalidation-hits triggered hardware prefetching technique (BITP). BITP is an L2 cache level hardware prefetcher that prefetches the back-invalidated block addresses and refills the LLC (along with the L2) before the attacker's observation/access …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:_Qo2XoVZTnwC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2019,"Cross-core last-level cache based side-channel attacks are becoming practical, affecting all forms of computing devices like mobiles, desktops, servers, and cloud based systems. Mitigating last-level cache based side channel attacks has become an active area of research and many proposals target to mitigate cross-core based conflict attacks. Secure Cache Hierarchy Aware Replacement Policy (SHARP) is one of the recent proposals that mitigate the conflict attacks by changing the underlying last-level cache replacement policy. Though SHARP is an elegant proposal; there are many subtle points, which were not part of the original SHARP proposal that appeared in the ISCA’17. Through this paper, we discuss and debate the subtle issues that are left unanswered in the original SHARP paper.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:HDshCWvjkbEC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2019,"Memory deduplication in virtualized systems is shown to be a very useful memory optimization as it is simple to use and provides memory efficient cloud hosting. However, memory deduplication based side channel attacks---information disclosure attacks and covert channel construction across virtual machines---can be mounted using the timing information available because of Copy-on-Write (CoW) fault handling semantics. The CoW semantic has been a necessary-evil with regard to deduplication as it plays a vital role in supporting guest OS transparent deduplication but enables a timing channel for exploitation. Thus to decimate the huge access time difference between a normal write and a write to a shared page, we propose CoWLight, a combination of hardware and software techniques for handling the CoW page faults in an efficient manner. In this work, we propose to address the security issues at its …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:hC7cP41nSMkC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2019,"Through this paper, we propose an instruction pointer classifier based hardware prefetching technique for the DPC-3. We use multiple instruction pointer based prefetchers that suit different access patterns and overall cover a wide spectrum of access patterns. Our classifier classifies instruction pointers at the L1 cache level and communicate the same to the L2 prefetcher. Our prefetching framework named Instruction Pointer Classifier based Prefetching (IPCP) provides 43.75% improvement for single-core and 22% for 25 selectively chosen multi-core mixes, respectively. IPCP demands a hardware overhead of 16.7 KB per core.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:g5m5HwL7SMYC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:R3hNpaxXUhUC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2019,"Value prediction has immense potential in improving performance of the modern day processors. Based on the CVP leaderboard, the ideal value predictor provides 107% speedup whereas the state-of-the-art EVES predictor provides 35.8% with an unlimited storage. Through this manuscript, we attempt to push the limits of EVES. We propose a finite context method based value predictor named Sliding FCM. A sliding window FCM stores the history of values for a particular instruction pointer and while predicting in the future, it matches the recent history of values with a relatively older set of values. In case of a match, it predicts the next value from the history of values as the value to predict. Sliding FCM coupled with EVES (we call it STEVES) improves the average performance to 37% with a maximum speedup of 1000%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:hFOr9nPyWt4C,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2018,"Recent advances in research on compressed caches make them an attractive design point for effective hardware implementation for last-level caches. For instance, the yet another compressed cache (YACC) layout leverages both spatial and compression factor localities to pack compressed contiguous memory blocks from a 4-block super-block in a single cache block location. YACC requires less than 2% extra storage over a conventional uncompressed cache.
Performance of LLC is also highly dependent on its cache block replacement management. This includes allocation and bypass decision on a miss as well as replacement target selection which is guided by priority insertion policy on allocation and priority promotion policy on a hit. YACC uses the same cache layout as a conventional set-associative uncompressed cache Therefore the LLC cache management policies that were introduced during the past …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:ZeXyd9-uunAC,https://www.cse.iitb.ac.in/~biswa
Biswabandan Panda,"['micro-architecture for performance and security', 'OS-architecture interface']",7,205,2018,"Value prediction is one of the promising micro-architectural techniques to improve the processor performance. Through this paper, we provide a series of four enhancements that we apply on top of Differential Finite Context-Method (DFCM) value predictor and call it DFCM++. Our design achieves a geomean IPC of 4.11 whereas the baseline system, without any value predictor, provides a geomean IPC of 3.21 (an improvement of 28.1%). In comparison to the baseline DFCM, which provides a geomean IPC of 2.93, DFCM++ delivers an improvement of 40.2%. Additionally, we show the effectiveness of our enhancements on some of the state-of-the-art value predictors such as VTAGE and DVTAGE.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ZGZkHzcAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ZGZkHzcAAAAJ:mVmsd5A6BfQC,https://www.cse.iitb.ac.in/~biswa
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2022,"Policy Iteration (PI) is a widely used family of algorithms to compute optimal policies for Markov Decision Problems (MDPs). We derive upper bounds on the running time of PI on Deterministic MDPs (DMDPs): the class of MDPs in which every state-action pair has a unique next state. Our results include a non-trivial upper bound that applies to the entire family of PI algorithms, and affirmation that a conjecture regarding Howard's PI on MDPs is true for DMDPs. Our analysis is based on certain graph-theoretic results, which may be of independent interest.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:NaGl4SEjCO4C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2022,"In September 2016, Stanford's ""One Hundred Year Study on Artificial Intelligence"" project (AI100) issued the first report of its planned long-term periodic assessment of artificial intelligence (AI) and its impact on society. It was written by a panel of 17 study authors, each of whom is deeply rooted in AI research, chaired by Peter Stone of the University of Texas at Austin. The report, entitled ""Artificial Intelligence and Life in 2030,"" examines eight domains of typical urban settings on which AI is likely to have impact over the coming years: transportation, home and service robots, healthcare, education, public safety and security, low-resource communities, employment and workplace, and entertainment. It aims to provide the general public with a scientifically and technologically accurate portrayal of the current state of AI and its potential and to help guide decisions in industry and governments, as well as to inform research and development in the field. The charge for this report was given to the panel by the AI100 Standing Committee, chaired by Barbara Grosz of Harvard University.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:9ZlFYXVOiuMC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2022,"Reconnaissance Blind Chess is an imperfect-information variant of chess with significant private information that challenges state-of-the-art algorithms. The Johns Hopkins University Applied Physics Laboratory and several organizing partners held the second NeurIPS machine Reconnaissance Blind Chess competition in 2021. 18 bots competed in 9,180 games, revealing a dominant champion with 91% wins. The top four bots in the tournament matched or exceeded the performance of the inaugural tournament’s winner. However, none of the algorithms converge to an optimal, unexploitable strategy or appear to have addressed the core research challenges associated with Reconnaissance Blind Chess.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:ns9cj8rnVeAC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2022,"We consider the problem of correctly identifying the mode of a discrete distribution with sufficiently high probability by observing a sequence of iid samples drawn from . This problem reduces to the estimation of a single parameter when has a support set of size . After noting that this special case is handled very well by prior-posterior-ratio (PPR) martingale confidence sequences (Waudby-Smith and Ramdas, 2020), we propose a generalisation to mode estimation, in which may take values. To begin, we show that the"" one-versus-one"" principle to generalise from to classes is more efficient than the"" one-versus-rest"" alternative. We then prove that our resulting stopping rule, denoted PPR-1v1, is asymptotically optimal (as the mistake probability is taken to 0). PPR-1v1 is simple and computationally light, and incurs significantly fewer samples than competitors even in the non-asymptotic regime. We demonstrate its gains in two practical applications of sampling: election forecasting and verification of smart contracts in blockchains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:TFP_iSt0sucC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2021,"The Indian railway network carries the largest number of passengers in the world, with over 8.4 billion transported in 2018, in addition to 1.2 billion tonnes of freight [1]. Nonetheless, the network has only about a tenth the “track-length per passenger” of the U.S., and half that of China [2]. This severe limitation of infrastructure, coupled with variability and heterogeneity in operations, raises significant challenges in scheduling. In this paper, we describe a policy search approach to decide arrival/departure times and track allocations for trains such that the resource and operating constraints of the railway line are satisfied, while the priority-weighted departure delay (PWDD) is minimised. We evaluate our approach on three large railway lines from the Indian network. We observe significant reductions of PWDD over traditional heuristics and a solution based on reinforcement learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:M3NEmzRMIkIC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2021,"We consider the problem of correctly identifying the\textit {mode} of a discrete distribution with sufficiently high probability by observing a sequence of iid samples drawn from . This problem reduces to the estimation of a single parameter when has a support set of size . After noting that this special case is tackled very well by prior-posterior-ratio (PPR) martingale confidence sequences\citep {waudby-ramdas-ppr}, we propose a generalisation to mode estimation, in which may take values. To begin, we show that the"" one-versus-one"" principle to generalise from to classes is more efficient than the"" one-versus-rest"" alternative. We then prove that our resulting stopping rule, denoted PPR-1v1, is asymptotically optimal (as the mistake probability is taken to ). PPR-1v1 is parameter-free and computationally light, and incurs significantly fewer samples than competitors even in the non …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:bEWYMUwI8FkC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2021,"POMDPs are capable of modelling a large class of decision and planning problems. However, solving large POMDPs optimally is infeasible. The following text reports observations of various experiments related to solving large POMDPs using various strategies conducted as part of an R&D project at IIT Bombay. The section 2 and 3 in the text formally define MDPs and POMDPs and also mention how POMDP solutions (formally called policies) are represented. Important existing POMDP solving algorithms relevant to the experiments conducted are summarized in section 4. Section 5 describes the Subset Update algorithm introduced in [8]. Section 6 mentions a way to reduce the FSC sizes during each iteration by a logical pruning step. Section 7 specifies a few methods to combine two FSCs into a single FSC. Section 8 reports certain empirical results. Some observations and possibilities of future work have been highlighted in the last section.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:k_IJM867U9cC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2021,"In the practice of sequential decision making, agents are often designed to sense state at regular intervals of time steps, , ignoring state information in between sensing steps. While it is clear that this practice can reduce sensing and compute costs, recent results indicate a further benefit. On many Atari console games, reinforcement learning (RL) algorithms deliver substantially better policies when run with -- in fact with even as high as . In this paper, we investigate the role of the parameter in RL; is called the ""frame-skip"" parameter, since states in the Atari domain are images. For evaluating a fixed policy, we observe that under standard conditions, frame-skipping does not affect asymptotic consistency. Depending on other parameters, it can possibly even benefit learning. To use in the control setting, one must first specify which -step open-loop action sequences can be executed in between sensing steps. We focus on ""action-repetition"", the common restriction of this choice to -length sequences of the same action. We define a task-dependent quantity called the ""price of inertia"", in terms of which we upper-bound the loss incurred by action-repetition. We show that this loss may be offset by the gain brought to learning by a smaller task horizon. Our analysis is supported by experiments on different tasks and learning algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:r0BpntZqJG4C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2021,"My research is driven by my curiosity about the nature of intelligence. Of the several aspects that characterise the behaviour of intelligent agents, I primarily study sequential decision making, learning, and exploration. My interests also extend to broader questions on the effects of AI on life and society. In this paper, I present four distinct investigations drawn from my recent work, which range from theoretical to applied, and which involve both analysis and design. I also share my outlook as an early-career researcher.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:iH-uZ7U-co4C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2020,"Policy Iteration (PI) is a classical family of algorithms to compute an optimal policy for any given Markov Decision Problem (MDP). The basic idea in PI is to begin with some initial policy and to repeatedly update the policy to one from an improving set, until an optimal policy is reached. Different variants of PI result from the (switching) rule used for improvement. An important theoretical question is how many iterations a specified PI variant will take to terminate as a function of the number of states n and the number of actions k in the input MDP. While there has been considerable progress towards upper-bounding this number, there are fewer results on lower bounds. In particular, existing lower bounds primarily focus on the special case of k = 2 actions. We devise lower bounds for k ≥ 3. Our main result is that a particular variant of PI can take Ω(k n /2) iterations to terminate. We also generalise existing constructions on …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:j3f4tGmQtD8C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2020,"Policy Iteration (PI) is a popular family of algorithms to compute an optimal policy for a givenMarkov Decision Problem (MDP). Starting from an arbitrary initial policy, PI repeatedly performs locally-improving switches until an optimal policy is found. The exact form of the switching rule gives rise to different variants of PI. Two decades ago, Mansour and Singh [1999] provided the first non-trivial “strong” upper bound on the number of iterations taken by “Howard’s PI”(HPI), a widelyused variant of PI (strong bounds depend only on the number of states and actions in the MDP). They also proposed a randomised variant (RPI) and showed an even tighter strong upper bound. Their bounds for HPI and RPI have not been improved subsequently.\\{We} revisit the algorithms and analysis of Mansour and Singh [1999]. We prove a novel result on the structure of the policy space for k-action MDPs, , which generalises a result known for k= 2. Also proposing a new counting argument, we obtain a strong bound of (O iterations for an algorithm akin to RPI, improving significantly upon Mansour and Singh’s original bound of roughly O (). Similar analysis of a randomised variant of HPI also yields a strong upper bound of (O ( iterations, registering the first exponential improvement for HPI over the trivial bound of . Our other contributions include a lower bound of iterations for RPI and an upper bound of iterations for a randomised variant of “Batch-Switching PI”[Kalyanakrishnan et al., 2016a] on 2-action MDPs—the tightest strong upper bound shown yet for the PI family.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:e5wmG9Sq2KIC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2020,"Regret minimisation in stochastic multi-armed bandits is a well-studied problem, for which several optimal algorithms have been proposed. Such algorithms depend on (sufficient statistics of) the empirical reward distributions of the arms to decide which arm to pull next. In this paper, we consider the design of algorithms that are constrained to store statistics from only a bounded number of arms. For bandits with a finite set of arms, we derive a sub-linear upper bound on the regret that decreases with the “arm memory” size M. For instances with a large, possibly infinite, set of arms, we show a sub-linear bound on the quantile regret.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:-f6ydRqryjwC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2020,"This paper describes a policy search approach for railway scheduling using the covariance matrix adaptation evolution strategy (CMA-ES). The goal is to define arrival/departure times and track allocations for all trains such that the resource and operating constraints of the railway line are satisfied, and priority-weighted train departure delay is minimised. The proposed approach is scalable in the sense that (i) the optimised policy can be applied to an arbitrarily long railway line, independent of the number of trains, tracks, and stations, and (ii) the on-line implementation is computationally light enough to be applied in real-time. Our experiments show that policies computed with CMA-ES are able to produce solutions with lower priorityweighted delay than heuristics and reinforcement learning (RL) algorithms reported in literature, on synthetic examples as well as actual railway line data from portions of the Indian Railway network.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:RHpTSmoSYBkC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2019,"POMDPs are capable of modelling a large class of decision and planning problems. However, solving large POMDPs optimally is infeasible. The following text proposes a variant of Policy Iteration in POMDPs, which makes this solving more tractable. We specify a method which regulates the update of Finite-State Controllers (FSCs) in Hansen’s Policy Iteration algorithm [1]. We selectively add only a subset of improving FSC nodes (as opposed to adding all improvements), during Policy Improvement. Towards the end of the text, we also suggest a method to locally combine FSC nodes, in order to decrease controller size without impairing the policy.
The 2nd and 3rd section in the text formally define MDPs and POMDPs and also mention how POMDP solutions (formally called policies) are represented. Important existing POMDP solving algorithms are summarized in section 4. The initial insights gained during the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:4JMBOYKVnBMC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2019,"We consider the problem of identifying any k out of the best m arms in an n-armed stochastic multi-armed bandit; framed in the PAC setting, this particular problem generalises both the problem of “best subset selection”(Kalyanakrishnan & Stone, 2010) and that of selecting “one out of the best m” arms (Roy Chaudhuri & Kalyanakrishnan, 2017). We present a lower bound on the worst-case sample complexity for general k, and a fully sequential PAC algorithm, LUCB-km, which is more sample-efficient on easy instances. Also, extending our analysis to infinite-armed bandits, we present a PAC algorithm that is independent of n, which identifies an arm from the best fraction of arms using at most an additive poly-log number of samples than compared to the lower bound, thereby improving over Roy Chaudhuri & Kalyanakrishnan (2017) and Aziz et al.(2018). The problem of identifying k> 1 distinct arms from the best fraction is not always well-defined; for a special class of this problem, we present lower and upper bounds. Finally, through a reduction, we establish a relation between upper bounds for the “one out of the best ” problem for infinite instances and the “one out of the best m” problem for finite instances. We conjecture that it is more efficient to solve “small” finite instances using the latter formulation, rather than going through the former.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:hFOr9nPyWt4C,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2018,"In the future of India lies the future of a sixth of the world's population. As the Artificial Intelligence (AI) revolution sweeps through societies and enters daily life, its role in shaping India's development and growth is bound to be substantial. For India, AI holds promise as a catalyst to accelerate progress, while providing mechanisms to leapfrog traditional hurdles such as poor infrastructure and bureaucracy. At the same time, an investment in AI is accompanied by risk factors with long-term implications on society: it is imperative that risks be vetted at this early stage. In this paper, we describe opportunities and challenges for AI in India. We detail opportunities that are cross-cutting (bridging India's linguistic divisions, mining public data), and also specific to one particular sector (healthcare). We list challenges that originate from existing social conditions (such as equations of caste and gender). Thereafter we distill out …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:L8Ckcad2t8MC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:_Qo2XoVZTnwC,http://www.cse.iitb.ac.in/~shivaram
Shivaram Kalyanakrishnan,"['Artificial Intelligence', 'Machine Learning']",15,1586,2018,"The stochastic multi-armed bandit is a wellstudied abstraction of decision making in the face of uncertainty. We consider the setting in which the number of bandit arms is much larger than the possible number of pulls, and can even be infinite. With the aim of minimising regret with respect to an optimal arm, existing methods for this setting either assume some structure over the set of arms (Kleinberg et al., 2008, Ray Chowdhury and Gopalan, 2017), or some property of the reward distribution (Wang et al., 2008). Invariably, the validity of such assumptions—and therefore the performance of the corresponding methods—depends on instance-specific parameters, which might not be known beforehand.
We propose a conceptually simple, parameter-free, and practically effective alternative. Specifically we introduce a notion of regret with respect to the top quantile of a probability distribution over the expected reward of randomly drawn arms. Our main contribution is an algorithm that achieves sublinear “quantile-regret”, both (1) when it is specified a quantile, and (2) when the quantile can be any (unknown) positive value. The algorithm needs no side information about the arms or about the structure of their reward distributions: it relies on random sampling to reach arms in the top quantile. Experiments show that our algorithm outperforms several previous methods (in terms of conventional regret) when the latter are not tuned well, and often even when they are.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YZkeEqAAAAAJ&sortby=pubdate&citation_for_view=YZkeEqAAAAAJ:hC7cP41nSMkC,http://www.cse.iitb.ac.in/~shivaram
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2023,"We present a framework for efficient stateless model checking (SMC) of concurrent programs under three prominent models of causal consistency, \documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$${\texttt {CCv}}, {\texttt {CM}}, \texttt{CC}$$\end{document}. Our approach is based on exploring traces under the program order and the reads from relations. Our SMC algorithm is provably optimal in the sense that it explores each and relation exactly once. We have implemented our framework in a tool called Conschecker. Experiments show that Conschecker performs well in detecting anomalies in classical distributed databases benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:uLbwQdceFCQC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2023,We consider parameterized verification of systems executing according to the total store ordering (TSO) semantics. The processes manipulate abstract data types over potentially infinite domains. We present a framework that translates the reachability problem for such systems to the reachability problem for register machines enriched with the given abstract data type.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:JQOojiI6XY0C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2023,"Over the years, several memory models have been proposed to capture the subtle concurrency semantics of C/C++.One of the most fundamental problems associated with a memory model M is consistency checking: given an execution X, is X consistent with M? This problem lies at the heart of numerous applications, including specification testing and litmus tests, stateless model checking, and dynamic analyses. As such, it has been explored extensively and its complexity is well-understood for traditional models like SC and TSO. However, less is known for the numerous model variants of C/C++, for which the problem becomes challenging due to the intricacies of their concurrency primitives. In this work we study the problem of consistency checking for popular variants of the C11 memory model, in particular, the RC20 model, its release-acquire (RA) fragment, the strong and weak variants of RA (SRA and WRA), as well as the Relaxed fragment of RC20. Motivated by applications in testing and model checking, we focus on reads-from consistency checking. The input is an execution X specifying a set of events, their program order and their reads-from relation, and the task is to decide the existence of a modification order on the writes of X that makes X consistent in a memory model. We draw a rich complexity landscape for this problem; our results include (i)~nearly-linear-time algorithms for certain variants, which improve over prior results, (ii)~fine-grained optimality results, as well as (iii)~matching upper and lower bounds (NP-hardness) for other variants. To our knowledge, this is the first work to characterize the complexity of consistency …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:UHK10RUVsp4C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2023,"We consider parameterized verification of systems executing according to the total store ordering (TSO) semantics. The processes manipulate abstract data types over potentially infinite domains. We present a framework that translates the reachability problem for such systems to the reachability problem for register machines enriched with the given abstract data type. We use the translation to obtain tight complexity bounds for TSO-based parameterized verification over several abstract data types, such as push-down automata, ordered multi push-down automata, one-counter nets, one-counter automata, and Petri nets. We apply the framework to get complexity bounds for higher order stack and counter variants as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:1yQoGdGgb4wC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2022,"The verification of transactional concurrent programs running over causally consistent databases is a challenging problem. We present a framework for efficient stateless model checking (SMC) of concurrent programs with transactions under two well known models of causal consistency, CCv and CC. Our approach is based on exploring the program order po and the reads from rf relations, avoiding exploration of all possible coherence orders. Our SMC algorithm is provably optimal in the sense that it explores each po and rf relation exactly once. We have implemented our framework in a tool called \ourtool{}. Experiments show that \ourtool{} performs well in detecting anomalies in classical distributed databases benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:5awf1xo2G04C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2022,"The verification of transactional concurrent programs running over causally consistent databases is a challenging problem. We present a framework for efficient stateless model checking (SMC) of concurrent programs with transactions under two well known models of causal consistency, CCv and CC. Our approach is based on exploring the program order po and the reads from rf relations, avoiding exploration of all possible coherence orders. Our SMC algorithm is provably optimal in the sense that it explores each po and rf relation exactly once. We have implemented our framework in a tool called TRANCHECKER. Experiments show that TRANCHECKER performs well in detecting anomalies in classical distributed databases benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:LjlpjdlvIbIC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2022,"This paper presents an optimization based framework to automate system repair against omega-regular properties. In the proposed formalization of optimal repair, the systems are represented as Kripke structures, the properties as -regular languages, and the repair space as repair machines—weighted omega-regular transducers equipped with Büchi conditions—that rewrite strings and associate a cost sequence to these rewritings. To translate the resulting cost-sequences to easily interpretable payoffs, we consider several aggregator functions to map cost sequences to numbers—including limit superior, supremum, discounted-sum, and average-sum—to define quantitative cost semantics. The problem of optimal repair, then, is to determine whether traces from a given system can be rewritten to satisfy an -regular property when the allowed cost is bounded by a given threshold. We also consider the dual …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:eq2jaN3J8jMC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2022,"The class of regular transformations has several equivalent characterizations such as functional MSO transductions, deterministic two-way transducers, streaming string transducers, as well as regular transducer expressions (RTE).
For algorithmic applications, it is very common and useful to transform a specification, here, an RTE, to a machine, here, a transducer. In this paper, we give an efficient construction of a two-way reversible transducer (2RFT) equivalent to a given RTE. 2RFTs form a well behaved class of transducers which are deterministic and co-deterministic (hence allows evaluation in linear time w.r.t. the input word), and where composition has only polynomial complexity.
As a significant complexity improvement over existing techniques, we give the first elementary procedure for translating RTEs to machines. For full RTE, the constructed 2RFT has size doubly exponential in the size of the expression …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:PELIpwtuRlgC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2022,Release-acquire (RA) is a popular fragment of C++ 11 [12](in which reads are annotated by acquire and writes by release) that strikes a good balance between programmability and performance and has,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:SdhP9T11ey4C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2022,"Functional MSO transductions, deterministic two-way transducers, as well as streaming string transducers are all equivalent models for regular functions. In this paper, we show that every regular function, either on finite words or on infinite words, captured by a deterministic two-way transducer, can be described with a regular transducer expression (RTE ). For infinite words, the two-way transducer uses Muller acceptance and ω-regular look-ahead. RTEs are constructed from constant functions using the combinators if-then-else (deterministic choice), Hadamard product, and unambiguous versions of the Cauchy product, the 2-chained Kleene-iteration and the 2-chained omega-iteration. Our proof works for transformations of both finite and infinite words, extending the result on finite words of Alur et al. in LICS'14.
The construction of an RTE associated with a deterministic two-way transducer is guided by a regular …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:VL0QpB8kHFEC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2022,"Metric Temporal Logic (MTL) and Timed Propositional Temporal Logic (TPTL) are prominent real-time extensions of Linear Temporal Logic (LTL). In general, the satisfiability checking problem for these extensions is undecidable when both the future (Until, U) and the past (Since, S) modalities are used (denoted by MTL[U,S] and TPTL[U,S]). In a classical result, the satisfiability checking for Metric Interval Temporal Logic (MITL[U,S]), a non-punctual fragment of MTL[U,S], is shown to be decidable with EXPSPACE complete complexity. A straightforward adoption of non-punctuality does not recover decidability in the case of TPTL[U,S]. Hence we propose a more refined notion called non-adjacency for TPTL[U,S], and focus on its 1-variable fragment, 1-TPTL[U,S]. We show that non-adjacent 1-TPTL[U,S] is strictly more expressive than MITL. As one of our main results, we show that the satisfiability checking problem for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:ye4kPcJQO24C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"This paper addresses reliability of timed systems in the setting of resilience, that considers the behaviors of a system when unspecified timing errors such as missed deadlines occur. Given a fault model that allows transitions to fire later than allowed by their guard, a system is universally resilient (or self-resilient) if after a fault, it always returns to a timed behavior of the non-faulty system. It is existentially resilient if after a fault, there exists a way to return to a timed behavior of the non-faulty system, that is, if there exists a controller which can guide the system back to a normal behavior. We show that universal resilience of timed automata is undecidable, while existential resilience is decidable, in EXPSPACE. To obtain better complexity bounds and decidability of universal resilience, we consider untimed resilience, as well as subclasses of timed automata.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:bnK-pcrLprsC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"Reinforcement Learning (RL) is a sampling based approach to optimization, where learning agents rely on scalar reward signals to discover optimal solutions. The specification of learning objectives as scalar rewards is tedious and error prone, and more so for real-time systems with complex time-critical requirements. This paper advocates the use of Duration Calculus (DC)—a highly expressive real-time logic with duration and length modalities—in expressing the learning objectives in model-free RL for stochastic real-time systems. On the other hand, to model stochastic real-time environments, we consider probabilistic timed automata (PTA)—Markov decision processes extended with clock variables—that provide an expressive yet computationally decidable formalism to capture real-time constraints over nondeterministic and probabilistic behaviors. The key hurdle in developing a convergent RL algorithm for DC …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:tkaPQYYpVKoC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"In this paper, we present a novel method for learning LTL properties from a set of traces. The main novelty of our method, as compared to many existing ones, is that we learn formulae in a ""quantitative"" sense : given a sample consisting of positive traces and negative traces , we find the formula which ""best"" describes the sample such that all positive traces satisfy and all negative traces do not satisfy . To decide how good a formula is with respect to the sample, we have developed a scheme of assigning a value for a formula for a given trace under various schemes. We use the schemes to encode the optimal property synthesis problem, namely, finding the best property/LTL formula into an optimization problem. Then we use an SMT solver to find the best fit formula for a given set of traces. Finally, we present a hybrid approach combining classical LTL satisfaction and the ranking scheme that works on a fragment of LTL and greatly improves performance while maintaining reasonable expressiveness. We have developed a tool QuantLearn based on our method and applied on some benchmarks. We also compared different valuation schemes. Our experiments suggest that QuantLearn is successful in mining formulae which are reasonably good representations of the sample with high resilience to noise in the data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:Y5dfb0dijaUC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"Regular model checking is an exploration technique for infinite state systems where state spaces are represented as regular languages and transition relations are expressed using rational relations over infinite (or finite) strings. We extend the regular model checking paradigm to permit the use of more powerful transition relations: the class of regular relations, of which the rational relations are a strict subset. We use the language of monadic second-order logic (MSO) on infinite strings to specify such relations and adopt streaming string transducers (SSTs) as a suitable computational model. We introduce nondeterministic SSTs over infinite strings (-NSSTs) and show that they precisely capture the relations definable in MSO. We further explore theoretical properties of -NSSTs required to effectively carry out regular model checking. In particular, we establish that the regular type checking problem for  …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:Mojj43d5GZwC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"Multi-pushdown systems are a standard model for concurrent recursive programs, but they have an undecidable reachability problem. Therefore, there have been several proposals to underapproximate their sets of runs so that reachability in this underapproximation becomes decidable. One such underapproximation that covers a relatively high portion of runs is scope boundedness. In such a run, after each push to stack , the corresponding pop operation must come within a bounded number of visits to stack . In this work, we generalize this approach to a large class of infinite-state systems. For this, we consider the model of valence systems, which consist of a finite-state control and an infinite-state storage mechanism that is specified by a finite undirected graph. This framework captures pushdowns, vector addition systems, integer vector addition systems, and combinations thereof. For this framework, we propose a notion of scope boundedness that coincides with the classical notion when the storage mechanism happens to be a multi-pushdown. We show that with this notion, reachability can be decided in PSPACE for every storage mechanism in the framework. Moreover, we describe the full complexity landscape of this problem across all storage mechanisms, both in the case of (i) the scope bound being given as input and (ii) for fixed scope bounds. Finally, we provide an almost complete description of the complexity landscape if even a description of the storage mechanism is part of the input.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:WA5NYHcadZ8C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"In this paper, we study the extension of 1-clock Alternating Timed Automata (1-ATA) with the ability to read in both forward and backward direction, the 2-Way 1-clock Alternating Timed Automata (2-Way 1-ATA). We show that subclass of 2-Way 1-ATA with reset free loops (2-Way 1-ATA-rfl) is expressively equivalent to MSO[<] extended with Guarded Metric Quantifiers (GQMSO). Emptiness Checking problem for 2-Way 1-ATA-rfl (and hence GQMSO) is undecidable, in general. We propose a ""non-punctuality"" like restriction, called non-adjacency, for 2-Way 1-ATA-rfl, and also for GQMSO, for which the emptiness (respectively, satisfiability) checking becomes decidable. Non-Adjacent 2-Way 1-ATA is the first such class of Timed Automata with alternations and 2-wayness for which the emptiness checking is decidable (and that too with elementary complexity). We also show that 2-Way 1-ATA-rfl, even with the non-adjacent restrictions, can express properties is not recognizable using 1-ATA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:HE397vMXCloC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"In this paper, we study the extension of 1-clock Alternating Timed Automata (1-ATA) with the ability to scan the timed behaviour in both forward and backward directions: the 2-Way 1-clock Alternating Timed Automata (2-Way 1-ATA). We show that the subclass of 2-Way 1-ATA with reset free loops (2-Way 1-ATA-rfl) is expressively equivalent to MSO [<] extended with Guarded Metric Quantifiers (GQMSO). The emptiness checking problem for 2-Way 1-ATA-rfl (and hence GQMSO) is undecidable, in general. We propose a generalization of the classical nonpunctuality restriction, called non-adjacency, for 2-Way 1-ATA-rfl, and also for GQMSO, for which the emptiness (respectively, satisfiability) checking becomes decidable. Non-Adjacent 2-Way 1-ATA-rfl is the first class of timed automata with alternations and 2-wayness for which the emptiness checking is decidable with elementary complexity. We also show that 2-Way 1-ATA-rfl, even with the non-adjacent restrictions, can express properties that are not recognizable by 1-ATA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:WqliGbK-hY8C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"FO transductions, aperiodic deterministic two-way transducers, as well as aperiodic streaming string transducers are all equivalent models for first order definable functions. In this paper, we solve the problem of expressions capturing first order definable functions, thereby generalizing the seminal SF=AP (star-free expressions = aperiodic languages) result of Schützenberger. Our result also generalizes a lesser known characterization by Schutzenberger of aperiodic languages by SD-regular expressions (SD=AP). We show that every first order definable function over finite words captured by an aperiodic deterministic two-way transducer can be described with an SD-regular transducer expression (SDRTE). An SDRTE is a regular expression where Kleene stars are used in a restricted way: they can appear only on aperiodic languages which are prefix codes of bounded synchronization delay. SDRTEs are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:V3AGJWp-ZtQC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"The origin semantics for transducers was proposed in 2014, and it led to various characterizations and decidability results that are in contrast with the classical semantics. In this paper we add a further decidability result for characterizing transducers that are close to oneway transducers in the origin semantics. We show that it is decidable whether a non-deterministic two-way word transducer can be resynchronized by a bounded, regular resynchronizer into an origin-equivalent oneway transducer. The result is in contrast with the usual semantics, where it is undecidable to know if a non-deterministic two-way transducer is equivalent to some one-way transducer.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:1qzjygNMrQYC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"We study the safety verification problem for parameterized systems under the release-acquire (RA) semantics. It has been shown that the problem is intractable for systems with unlimited access to atomic compare-and-swap (CAS) instructions. We show that, from a verification perspective where approximate results help, this is overly pessimistic. We study parameterized systems consisting of an unbounded number of environment threads executing identical but CAS-free programs and a fixed number of distinguished threads that are unrestricted. Our first contribution is a new semantics that considerably simplifies RA but is still equivalent for the above systems as far as safety verification is concerned. We apply this (general) result to two subclasses of our model. We show that safety verification is only \pspace-complete for the bounded model checking problem where the distinguished threads are loop-free. Interestingly, we can still afford the unbounded environment. We show that the complexity jumps to \nexp-complete for thread-modular verification where an unrestricted distinguished `ego' thread interacts with an environment of CAS-free threads plus loop-free distinguished threads (as in the earlier setting). Besides the usefulness for verification, the results are strong in that they delineate the tractability border for an established semantics.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:J-pR_7NvFogC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"Metric Temporal Logic (MTL) and Timed Propositional Temporal Logic (TPTL) are prominent real-time extensions of Linear Temporal Logic (LTL). In general, the satisfiability checking problem for these extensions is undecidable when both the future U and the past S modalities are used. In a classical result, the satisfiability checking for MITL[U,S], a non-punctual fragment of MTL[U,S], is shown to be decidable with EXPSPACE complete complexity. Given that this notion of non-punctuality does not recover decidability in the case of TPTL[U,S], we propose a generalization of non-punctuality called non-adjacency for TPTL[U,S], and focus on its 1-variable fragment, 1-TPTL[U,S]. While non-adjacent 1-TPTL[U,S] appears to be a very small fragment, it is strictly more expressive than MITL. As our main result, we show that the satisfiability checking problem for non-adjacent 1-TPTL[U,S] is decidable with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:t6usbXjVLHcC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2021,"We consider the reachability problem for finite-state multi-threaded programs under the promising semantics (PS 2.0) of Lee et al., which captures most common program transformations. Since reachability is already known to be undecidable in the fragment of PS 2.0 with only release-acquire accesses (PS 2.0-ra), we consider the fragment with only relaxed accesses and promises (PS 2.0-rlx). We show that reachability under PS 2.0-rlx is undecidable in general and that it becomes decidable, albeit non-primitive recursive, if we bound the number of promises.
Given these results, we consider a bounded version of the reachability problem. To this end, we bound both the number of promises and of “view-switches”, i.e., the number of times the processes may switch their local views of the global memory. We provide a code-to-code translation from an input program under PS 2.0 (with relaxed and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:wbdj-CoPYUoC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2020,"In PLDI'20, Lee et al. introduced the \emph{promising } semantics PS 2.0 of the C++ concurrency that captures most of the common program transformations while satisfying the DRF guarantee. The reachability problem for finite-state programs under PS 2.0 with only release-acquire accesses is already known to be undecidable. Therefore, we address, in this paper, the reachability problem for programs running under PS 2.0 with relaxed accesses together with promises. We show that this problem is undecidable even in the case where the input program has finite state. Given this undecidability result, we consider the fragment of PS 2.0 with only relaxed accesses allowing bounded number of promises. We show that under this restriction, the reachability is decidable, albeit very expensive: it is non-primitive recursive. Given this high complexity with bounded number of promises and the undecidability result for the RA fragment of PS 2.0, we consider a bounded version of the reachability problem. To this end, we bound both the number of promises and the ""view-switches"", i.e, the number of times the processes may switch their local views of the global memory. We provide a code-to-code translation from an input program under PS 2.0, with relaxed and release-acquire memory accesses along with promises, to a program under SC. This leads to a reduction of the bounded reachability problem under PS 2.0 to the bounded context-switching problem under SC. We have implemented a prototype tool and tested it on a set of benchmarks, demonstrating that many bugs in programs can be found using a small bound.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:D_sINldO8mEC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2020,"In PLDI'20, Lee et al. introduced the\emph {promising} semantics PS 2.0 of the C++ concurrency that captures most of the common program transformations while satisfying the DRF guarantee. The reachability problem for finite-state programs under PS 2.0 with only release-acquire accesses is already known to be undecidable. Therefore, we address, in this paper, the reachability problem for programs running under PS 2.0 with relaxed accesses together with promises. We show that this problem is undecidable even in the case where the input program has finite state. Given this undecidability result, we consider the fragment of PS 2.0 with only relaxed accesses allowing bounded number of promises. We show that under this restriction, the reachability is decidable, albeit very expensive: it is non-primitive recursive. Given this high complexity with bounded number of promises and the undecidability result for the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:BrmTIyaxlBUC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2020,"We address the separability problem for straight-line string constraints. The separability problem for languages of a class C by a class S asks: given two languages A and B in C, does there exist a language I in S separating A and B (i.e., I is a superset of A and disjoint from B)? The separability of string constraints is the same as the fundamental problem of interpolation for string constraints. We first show that regular separability of straight line string constraints is undecidable. Our second result is the decidability of the separability problem for straight-line string constraints by piece-wise testable languages, though the precise complexity is open. In our third result, we consider the positive fragment of piece-wise testable languages as a separator, and obtain an EXPSPACE algorithm for the separability of a useful class of straight-line string constraints, and a PSPACE-hardness result.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:VOx2b1Wkg3QC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2020,"Testing containment of queries is a fundamental reasoning task in knowledge representation. We study here the containment problem for Conjunctive Regular Path Queries (CRPQs), a navigational query language extensively used in ontology and graph database querying. While it is known that containment of CRPQs is expspace-complete in general, we focus here on severely restricted fragments, which are known to be highly relevant in practice according to several recent studies. We obtain a detailed overview of the complexity of the containment problem, depending on the features used in the regular expressions of the queries, with completeness results for np, pitwo, pspace or expspace.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:eflP2zaiRacC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2020,"In automatic control synthesis, we may need to handle specifications with timing constraints and control such that the system meets the specification as much as possible, which is called robust control. In this paper, we present a method for open loop robust controller synthesis from duration calculus (DC) specifications. For robust synthesis, we propose an approach to evaluate the robustness of DC specifications on a given run of a system. We leverage a CEGIS like method for synthesizing robust control signals. In our method, the DC specifications and the system under control are encoded into mixed integer linear problems, and the optimization problem is solved to yield a control signal. We have implemented a tool (ControlDC) based on the method and applied it on a set of benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:mvPsJ3kp5DgC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2020,"Regular functions from infinite words to infinite words can be equivalently specified by MSO-transducers, streaming ω-string transducers as well as deterministic two-way transducers with look-ahead. In their one-way restriction, the latter transducers define the class of rational functions. Even though regular functions are robustly characterised by several finite-state devices, even the subclass of rational functions may contain functions which are not computable (by a Turing machine with infinite input). This paper proposes a decision procedure for the following synthesis problem: given a regular function f (equivalently specified by one of the aforementioned transducer model), is f computable and if it is, synthesize a Turing machine computing it.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:q3oQSFYPqjQC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2020,"Boolean programs with multiple recursive threads can be captured as pushdown automata with multiple stacks. This model is Turing complete, and hence, one is often interested in analyzing a restricted class which still captures useful behaviors. In this paper, we propose a new class of bounded underapproximations for multi-pushdown systems, which subsumes most existing classes. We develop an efficient algorithm for solving the under-approximate reachability problem, which is based on efficient fix-point computations. We implement it in our tool BHIM and illustrate its applicability by generating a set of relevant benchmarks and examining its performance. As an additional takeaway BHIM solves the binary reachability problem in pushdown automata. To show the versatility of our approach, we then extend our algorithm to the timed setting and provide the first implementation that can handle timed multi …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2019,"Given a Boolean formula F(X, Y), where X is a vector of outputs and Y is a vector of inputs, the Boolean functional synthesis problem requires us to compute a Skolem function vector Ψ(Y) such that F(Ψ(Y), Y) holds whenever ∃X F(X, Y) holds. In this paper, we investigate the relation between the representation of the specification F(X, Y) and the complexity of synthesis. We introduce a new normal form for Boolean formulas, called SynNNF, that guarantees polynomial-time synthesis and also polynomial-time existential quantification for some order of quantification of variables. We show that several normal forms studied in the knowledge compilation literature are subsumed by SynNNF, although SynNNF can be super-polynomially more succinct than them. Motivated by these results, we propose an algorithm to convert a specification in CNF to SynNNF, with the intent of solving the Boolean functional synthesis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:4fKUyHm3Qg0C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2019,"In this paper, we analyze timed systems with data structures. We start by describing behaviors of timed systems using graphs with timing constraints. Such a graph is called realizable if we can assign time-stamps to nodes or events so that they are consistent with the timing constraints. The logical definability of several graph properties [20], [10] has been a challenging problem, and we show, using a highly nontrivial argument, that the realizability property for collections of graphs with strict timing constraints is logically definable in a class of propositional dynamic logic (EQ-ICPDL), which is strictly contained in MSO. Using this result, we propose a novel, algorithmically efficient and uniform proof technique for the analysis of timed systems enriched with auxiliary data structures, like stacks and queues. Our technique unravels new results (for emptiness checking as well as model checking) for timed systems with richer …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:K3LRdlH-MEoC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2019,"We study two formalisms that allow to compare transducers over words under origin semantics: rational and regular resynchronizers, and show that the former are captured by the latter. We then consider some instances of the following synthesis problem: given transducers T1, T2, construct a rational (resp. regular) resynchronizer R, if it exists, such that T1 is contained in R(T2) under the origin semantics. We show that synthesis of rational resynchronizers is decidable for functional, and even finite-valued, one-way transducers, and undecidable for relational one-way transducers. In the two-way setting, synthesis of regular resynchronizers is shown to be decidable for unambiguous two-way transducers. For larger classes of two-way transducers, the decidability status is open.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:vRqMK49ujn8C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2019,"We address the verification of concurrent programs running under the release-acquire (RA) semantics. We show that the reachability problem is undecidable even in the case where the input program is finite-state. Given this undecidability, we follow the spirit of the work on context-bounded analysis for detecting bugs in programs under the classical SC model, and propose an under-approximate reachability analysis for the case of RA. To this end, we propose a novel notion, called view-switching, and provide a code-to-code translation from an input program under RA to a program under SC. This leads to a reduction, in polynomial time, of the bounded view-switching reachability problem under RA to the bounded context-switching problem under SC. We have implemented a prototype tool VBMC and tested it on a set of benchmarks, demonstrating that many bugs in programs can be found using a small number of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:tOudhMTPpwUC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2019,"Regular functions from infinite words to infinite words can be equivalently specified by MSO-transducers, streaming -string transducers as well as deterministic two-way transducers with look-ahead. In their one-way restriction, the latter transducers define the class of rational functions. Even though regular functions are robustly characterised by several finite-state devices, even the subclass of rational functions may contain functions which are not computable (by a Turing machine with infinite input). This paper proposes a decision procedure for the following synthesis problem: given a regular function (equivalently specified by one of the aforementioned transducer model), is computable and if it is, synthesize a Turing machine computing it. For regular functions, we show that computability is equivalent to continuity, and therefore the problem boils down to deciding continuity. We establish a generic characterisation of continuity for functions preserving regular languages under inverse image (such as regular functions). We exploit this characterisation to show the decidability of continuity (and hence computability) of rational and regular functions. For rational functions, we show that this can be done in \textsc{NLogSpace} (it was already known to be in \textsc{PTime} by Prieur). In a similar fashion, we also effectively characterise uniform continuity of regular functions, and relate it to the notion of uniform computability, which offers stronger efficiency guarantees.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:08ZZubdj9fEC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:eMMeJKvmdy0C,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2019,"Perfect languages, characterized by closure under Boolean operations and decidable emptiness problem, form the basis for decidable automata-theoretic model-checking for the corresponding class of models. Regular languages and visibly pushdown languages are paradigmatic examples of perfect languages. In a previous work authors have established a timed context-sensitive perfect language characterized by multistack pushdown automata (MPA) with an explicit bound on number of rounds where in each round at most one stack is used. This paper complements the results of on bounded-round timed MPA by characterizing an alternative restriction on timed context-sensitive perfect languages called the scope-bounded multi-stack timed push-down automata where every stack symbol must be popped within a bounded number of stack contexts. The proposed model uses visibly-pushdown alphabet …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2019,"This paper proposes a novel notion called variability verification applicable to Software Product Lines (SPL). Variability is central to SPL and we have observed that variability is expressed differently at different levels of abstraction in the development flow of SPL. A natural problem in this context is the conformance of variability information expressed at different levels. Design variability verification, in particular, checks whether the variability expressed at the design level conforms to that at the requirement level. Unlike many existing approaches to SPL modelling, our work does not assume a single global view of variation points, even within the same level of abstraction. In our view, an SPL is a concurrent composition of features, where each feature exhibits independent variability. This enables incremental addition of variability. The procedure is compositional in the sense that the verification of an entire SPL …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:p2g8aNsByqUC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2018,"In this paper, we look at an unambiguous version of Simon's forest factorization theorem, a very deep result which has wide connections in algebra, logic and automata. Given a morphism from to a finite semigroup , we construct a universal, unambiguous automaton A which is ""good"" for . The goodness of $\Aa$ gives a very easy proof for the forest factorization theorem, providing a Ramsey split for any word in such that the height of the Ramsey split is bounded by the number of states of A. An important application of synthesizing good automata from the morphim is in the construction of regular transducer expressions (RTE) corresponding to deterministic two way transducers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:SP6oXDckpogC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2018,"We introduce the model of communicating timed automata (CTA) that extends the classical models of finite-state processes communicating through FIFO perfect channels and timed automata, in the sense that the finite-state processes are replaced by timed automata, and messages inside the perfect channels are equipped with clocks representing their ages. In addition to the standard operations (resetting clocks, checking guards of clocks) each automaton can either (1) append a message to the tail of a channel with an initial age or (2) receive the message at the head of a channel if its age satisfies a set of given constraints. In this paper, we show that the reachability problem is undecidable even in the case of two timed automata connected by one unidirectional timed channel if one allows global clocks (that the two automata can check and manipulate). We prove that this undecidability still holds even for CTA consisting of three timed automata and two unidirectional timed channels (and without any global clock). However, the reachability problem becomes decidable (in EXPTIME) in the case of two automata linked with one unidirectional timed channel and with no global clock. Finally, we consider the bounded-context case, where in each context, only one timed automaton is allowed to receive messages from one channel while being able to send messages to all the other timed channels. In this case we show that the reachability problem is decidable.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:LPZeul_q3PIC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2018,"Functional MSO transductions, deterministic two-way transducers, as well as streaming string transducers are all equivalent models for regular functions. In this paper, we show that every regular function, either on finite words or on infinite words, captured by a deterministic two-way transducer, can be described with a regular transducer expression (RTE). For infinite words, the transducer uses Muller acceptance and ω-regular look-ahead. RTEs are constructed from constant functions using the combinators if-then-else (deterministic choice), Hadamard product, and unambiguous versions of the Cauchy product, the 2-chained Kleene-iteration and the 2-chained omega-iteration. Our proof works for transformations of both finite and infinite words, extending the result on finite words of Alur et al. in LICS'14. In order to construct an RTE associated with a deterministic two-way Muller transducer with look-ahead, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:738O_yMBCRsC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2018,"We define two classes of functions, called regular (respectively, first-order) list functions, which manipulate objects such as lists, lists of lists, pairs of lists, lists of pairs of lists, etc. The definition is in the style of regular expressions: the functions are constructed by starting with some basic functions (e.g. projections from pairs, or head and tail operations on lists) and putting them together using four combinators (most importantly, composition of functions). Our main results are that first-order list functions are exactly the same as first-order transductions, under a suitable encoding of the inputs; and the regular list functions are exactly the same as MSO-transductions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:u9iWguZQMMsC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2018,"Timed systems, such as timed automata, are usually analyzed using their operational semantics on timed words. The classical region abstraction for timed automata reduces them to (untimed) finite state automata with the same time-abstract properties, such as state reachability. We propose a new technique to analyze such timed systems using finite tree automata instead of finite word automata. The main idea is to consider timed behaviors as graphs with matching edges capturing timing constraints. When a family of graphs has bounded tree-width, they can be interpreted in trees and MSO-definable properties of such graphs can be checked using tree automata. The technique is quite general and applies to many timed systems. In this paper, as an example, we develop the technique on timed pushdown systems, which have recently received considerable attention. Further, we also demonstrate how we can use it on timed automata and timed multi-stack pushdown systems (with boundedness restrictions).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:P5F9QuxV20EC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2018,"This paper investigates Kamp-like and B\""uchi-like theorems for 1-clock Alternating Timed Automata (1-ATA) and its natural subclasses. A notion of 1-ATA with loop-free-resets is defined. This automaton class is shown to be expressively equivalent to the temporal logic $\regmtl$ which is extended with a regular expression guarded modality. Moreover, a subclass of future timed MSO with k-variable-connectivity property is introduced as logic $\qkmso$. In a Kamp-like result, it is shown that $\regmtl$ is expressively equivalent to $\qkmso$. As our second result, we define a notion of conjunctive-disjunctive 1-clock ATA ($\wf$ 1-ATA). We show that $\wf$ 1-ATA with loop-free-resets are expressively equivalent to the sublogic $\F\regmtl$ of $\regmtl$. Moreover $\F\regmtl$ is expressively equivalent to $\qtwomso$, the two-variable connected fragment of $\qkmso$. The full class of 1-ATA is shown to be expressively equivalent to $\regmtl$ extended with fixed point operators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:1sJd4Hv_s6UC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2018,"In this paper, we address the verification problem for timed asynchronous programs. We associate to each task, a deadline for its execution. We first show that the control state reachability problem for such class of systems is decidable while the configuration reachability problem is undecidable. Then, we consider the subclass of timed asynchronous programs where tasks are always being executed from the same state. For this subclass, we show that the control state reachability problem is PSPACE-complete. Furthermore, we show the decidability for the configuration reachability problem for the subclass.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:uWQEDVKXjbEC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2018,"This paper investigates a decidable and highly expressive real time logic QkMSO which is obtained by extending MSO [<] with guarded quantification using block of less than k metric quantifiers. The resulting logic is shown to be expressively equivalent to 1-clock ATA where loops are without clock resets, as well as, RatMTL, a powerful extension of MTL [U_I] with regular expressions. We also establish 4-variable property for QkMSO and characterize the expressive power of its 2-variable fragment. Thus, the paper presents progress towards expressively complete logics for 1-clock ATA.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:UxriW0iASnsC,http://www.cse.iitb.ac.in/~krishnas
Shankara Narayanan Krishna,"['Formal Methods', 'Automata', 'Logic']",12,487,2018,"We introduce the model of communicating timed automata (CTA) that extends the classical models of finite-state processes communicating through FIFO perfect channels and timed automata, in the sense that the finite-state processes are replaced by timed automata, and messages inside the perfect channels are equipped with clocks representing their ages. In addition to the standard operations (resetting clocks, checking guards of clocks) each automaton can either (1) append a message to the tail of a channel with an initial age or (2) receive the message at the head of a channel if its age satisfies a set of given constraints. In this paper, we show that the reachability problem is undecidable even in the case of two timed automata connected by one unidirectional timed channel if one allows global clocks (that the two automata can check and manipulate). We prove that this undecidability still holds even for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=14JlaZsAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=14JlaZsAAAAJ:KxtntwgDAa4C,http://www.cse.iitb.ac.in/~krishnas
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2023,"We present VeriAbsL, a reachability verifier that performs verification in three stages. First, it slices the input code using a combination of two slicers, then it verifies the slices using predicted strategies, and at last, it composes the result of verifying the individual slices. We introduce a novel shallow slicing technique that uses variable reference information of the program, and data and control dependencies of the entry function to generate slices. We also introduce a novel strategy prediction technique that uses machine learning to predict a strategy. It uses boolean features to describe a program to a neural network that predicts a strategy. We use the portfolio of VeriAbs, a reachabiltiy verifier with manually defined strategies. In sv-comp 2023, VeriAbsL verified 227 (Without witness validation.) more programs than VeriAbs, and 475 (Without witness validation.) programs that VeriAbs could not verify.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:lmc2jWPfTJgC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2023,"Boolean functional synthesis is the process of constructing a Boolean function from a Boolean specification that relates input and output variables. Despite recent developments in synthesis algorithms, Boolean functional synthesis remains a challenging problem even when state-of-the-art techniques are used for decomposing the specification. In this work, we present a new decomposition approach that decomposes the specification into separate input and output components. To begin with, we adapt the notion of “sequential decomposition” and present a framework that allows the input and output components to be independently synthesized and then re-composed to yield an implementation of the overall specification. Although theoretically appealing, this approach suffers from some practical drawbacks, as evidenced by our experiments. This motivates us to propose a relaxed approach to synthesis by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:VL0QpB8kHFEC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2023,"Boolean functional synthesis concerns the automatic generation of Boolean functions satisfying given logical specifications. This problem has numerous applications, and has attracted significant attention from researchers over the past decade. Complexity-theoretic arguments indicate that it is extremely unlikely that the problem has any polynomial-time algorithm. Yet, state-of-the-art tools for this problem routinely handle problems with several thousands of variables. What makes these algorithms tick? In this paper, we provide an overview of some of the techniques that underlie the practical efficiency of these solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:gsN89kCJA0AC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2023,"Results: A total of 800 patients met the inclusion criteria, of whom 75 (9.37%) had ISH. Blood Pressure increased with age. The most common echocardiographic change observed in ISH patients was increased Left Ventricular Mass Index (LVMI), while concentric Left Ventricular Hypertrophy (LVH) was more common in women than men with isolated Systolic Hypertension. The incidence of LVMI increased as the severity of ISH increased. Furthermore, patients with stage 3 ISH were nearly 4 times more likely to develop Proteinuria. Conclusion: The findings of this study are in line with previous studies evaluating the presence of ISH in the adult Indian population. There is need for effective population screening along with effective treatment for Blood Pressure to reduce morbidity and mortality. Primary prevention strategies may be the need of the hour in the Indian population which is at risk of cardiovascular Disease associated with Hypertension.[J Indian Med Assoc 2023; 121 (3): 43-7]",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:MLfJN-KU85MC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2022,"Skolem functions play a central role in logic, from helping eliminate quantifiers in first-order logic formulas to providing functional implementations of relational specifications. While their existence follows from classical results in logic, less is known about how to compute them effectively and efficiently (whenever such computation is possible). The problem of computing or synthesizing Skolem functions from relational specifications, however, continues to show up in many interesting applications. Recently, a rich line of work has considered theoretical and practical aspects of the problem in a restricted setting, namely synthesis of Boolean Skolem functions from Boolean relational specifications. In this chapter, we take an in-depth look into this fascinating problem and its various implications, from general theoretical and complexity results to practical algorithms, and also draw interesting connections to the knowledge …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:kuK5TVdYjLIC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2022,"Given a system of constraints over a set X of variables, projected model counting asks us to count satisfying assignments of the constraint system projected on a subset of X. A key idea used in modern projected counters is to first compute an independent support, say , that is often a small subset of , and to then count models projected on instead of on . While this has been effective in scaling performance of counters, the question of whether we can benefit by projecting on variables beyond has not been explored. In this paper, we study this question and show that contrary to intuition, it can be beneficial to project on variables even beyond . In several applications, a good upper bound of the projected model count often suffices. We show that in several such cases, we can identify a set of variables, called upper bound support (UBS), that is not necessarily a subset of , and yet counting models …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:URolC5Kub84C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2022,"Arrays are commonly used in a variety of software to store and process data in loops. Automatically proving safety properties of such programs that manipulate arrays is challenging. We present a novel verification technique, called full-program induction, for proving (a sub-class of) quantified as well as quantifier-free properties of programs manipulating arrays of parametric size N. Instead of inducting over individual loops, our technique inducts over the entire program (possibly containing multiple loops) directly via the program parameter N. The technique performs non-trivial transformations of the given program and pre-conditions during the inductive step. The transformations assist in effectively reducing the assertion checking problem by transforming a program with multiple loops to a program which has fewer and simpler loops or is loop free. Significantly, full-program induction does not require generation or use …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:ILKRHgRFtOwC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2022,"The long run behaviour of linear dynamical systems is often studied by looking at eventual properties of matrices and recurrences that underlie the system. A basic problem in this setting is as follows: given a set of pairs of rational weights and matrices , does there exist an integer N s.t for all , (resp. ). We study this problem, its applications and its connections to linear recurrence sequences. Our first result is that for , the problem is as hard as the ultimate positivity of linear recurrences, a long standing open question (known to be -hard). Our second result is that for any , the problem reduces to ultimate positivity of linear recurrences. This yields upper bounds for several subclasses of matrices by exploiting known results on linear recurrence sequences. Our third result is a general reduction technique for a large class of problems (including the above) from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:BwyfMAYsbu0C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2022,"Skolem functions play a central role in the study of first order logic, both from theoretical and practical perspectives. While every Skolemized formula in first-order logic makes use of Skolem constants and/or functions, not all such Skolem constants and/or functions admit effectively computable interpretations. Indeed, the question of whether there exists an effectively computable interpretation of a Skolem function, and if so, how to automatically synthesize it, is fundamental to their use in several applications, such as planning, strategy synthesis, program synthesis etc.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:EYYDruWGBe4C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2021,"We present a new multi-objective optimization approach for synthesizing interpretations that “explain” the behavior of black-box machine learning models. Constructing human-understandable interpretations for black-box models often requires balancing conflicting objectives. A simple interpretation may be easier to understand for humans while being less precise in its predictions vis-a-vis a complex interpretation. Existing methods for synthesizing interpretations use a single objective function and are often optimized for a single class of interpretations. In contrast, we provide a more general and multi-objective synthesis framework that allows users to choose (1) the class of syntactic templates from which an interpretation should be synthesized, and (2) quantitative measures on both the correctness and explainability of an interpretation. For a given black-box, our approach yields a set of Pareto-optimal interpretations with respect to the correctness and explainability measures. We show that the underlying multi-objective optimization problem can be solved via a reduction to quantitative constraint solving, such as weighted maximum satisfiability. To demonstrate the benefits of our approach, we have applied it to synthesize interpretations for black-box neural-network classifiers. Our experiments show that there often exists a rich and varied set of choices for interpretations that are missed by existing approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:uWiczbcajpAC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2021,"Given a relational specification between Boolean inputs and outputs, Boolean functional synthesis seeks to synthesize each output as a function of the inputs such that the specification is met. Despite significant algorithmic advances in Boolean functional synthesis over the past few years, there are relatively small specifications that have remained beyond the reach of all state-of-the-art tools. In trying to understand this behaviour, we show that unless some hard conjectures in complexity theory are falsified, Boolean functional synthesis must generate large Skolem functions in the worst-case. Given this inherent hardness, what does one do to solve the problem? We present a two-phase algorithm, where the first phase is efficient in practice both in terms of time and size of synthesized functions, and solves a large fraction of our benchmarks. This phase is also guaranteed to solve the problem when the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:hMsQuOkrut0C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:fEOibwPWpKIC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2021,"Boolean Skolem function synthesis concerns syn¬thesizing outputs as Boolean functions of inputs such that a relational specification between inputs and outputs is satisfied. This problem, also known as Boolean functional synthesis, has several applications, including design of safe controllers for autonomous systems, certified QBF solving, cryptanalysis etc. Recently, complexity theoretic hardness results have been shown for the problem, although several algorithms proposed in the literature are known to work well in practice. This dichotomy between theoretical hardness and practical efficacy has motivated research on normal forms of specification representation that guarantee efficient synthesis, thus partially explaining the efficacy of some of these algorithms.In this paper we go one step further and ask if there exists a normal form representation of the specification that precisely characterizes ""efficient"" synthesis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:uc_IGeMz5qoC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2021,"Skolem functions play a central role in the study of first order logic, both from theoretical and practical perspectives. While every Skolemized formula in first-order logic makes use of Skolem constants and/or functions, not all such Skolem constants and/or functions admit effectively computable interpretations. Indeed, the question of whether there exists an effectively computable interpretation of a Skolem function, and if so, how to automatically synthesize it, is fundamental to their use in several applications, such as planning, strategy synthesis, program synthesis etc. In this paper, we investigate the computability of Skolem functions and their automated synthesis in the full generality of first order logic. We first show a strong negative result, that even under mild assumptions on the vocabulary, it is impossible to obtain computable interpretations of Skolem functions. We then show a positive result, providing a precise characterization of first-order theories that admit effective interpretations of Skolem functions, and also present algorithms to automatically synthesize such interpretations. We discuss applications of our characterization as well as complexity bounds for Skolem functions (interpreted as Turing machines).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:9Nmd_mFXekcC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2021,"We present a novel verification technique to prove properties of a class of array programs with a symbolic parameter N denoting the size of arrays. The technique relies on constructing two slightly different versions of the same program. It infers difference relations between the corresponding variables at key control points of the joint control-flow graph of the two program versions. The desired post-condition is then proved by inducting on the program parameter N, wherein the difference invariants are crucially used in the inductive step. This contrasts with classical techniques that rely on finding potentially complex loop invaraints for each loop in the program. Our synergistic combination of inductive reasoning and finding simple difference invariants helps prove properties of programs that cannot be proved even by the winner of Arrays sub-category in SV-COMP 2021. We have implemented a prototype tool …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:ipzZ9siozwsC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2021,"Model counting, or counting solutions of a set of constraints, is a fundamental problem in Computer Science with diverse applications. Since exact counting is computationally hard (# P complete), approximate counting techniques have received much attention over the past few decades. In this chapter, we focus on counting models of propositional formulas, and discuss in detail universal-hashing based approximate counting, which has emerged as the predominant paradigm for state-of-the-art approximate model counters. These counters are randomized algorithms that exploit properties of universal hash functions to provide rigorous approximation guarantees, while piggybacking on impressive advances in propositional satisfiability solving to scale up to problem instances with a million variables. We elaborate on various choices in designing such approximate counters and the implications of these choices. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:nrtMV_XWKgEC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2020,"A key problem in constrained random verification (CRV) concerns generation of input stimuli that result in good coverage of the system's runs in targeted corners of its behavior space. Existing CRV solutions however provide no formal guarantees on the distribution of the system's runs. In this paper, we take a first step towards solving this problem. We present an algorithm based on Algebraic Decision Diagrams for sampling bounded traces (i.e. sequences of states) of a sequential circuit with provable uniformity (or bias) guarantees, while satisfying given constraints. We have implemented our algorithm in a tool called TraceSampler. Extensive experiments show that TraceSampler outperforms alternative approaches that provide similar uniformity guarantees.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:35r97b3x0nAC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2020,"Demand-driven methods for program analysis have primarily been viewed as efficient algorithms for computing the same information as the corresponding exhaustive methods, but for a given set of demands. We explore demand-driven flow-sensitive alias analysis (which we call ADFSA ) and propose its improved version called PDFSA that computes both aliases and pointers for the demands raised by changing the notion of relevance for indirect assignment statements. We formally show that while ADFSA is as precise as the corresponding exhaustive flow-sensitive alias analysis (EFSA ), PDFSA can be more precise than both ADFSA and EFSA. This surprising result is based on the following insight: A demand-driven method computes less information than the corresponding exhaustive method. PDFSA exploits this to reduce the uncertainty caused by aliasing which in turn, reduces the conflation of memory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:Fu2w8maKXqMC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2020,"VeriAbs is a strategy selection based reachability verifier for C code. It analyzes the structure of loops, and intervals of inputs to choose one of the four verification strategies implemented in VeriAbs. In this paper, we present VeriAbs version 1.4 with updates in three strategies. We add an array verification technique called full-program induction, and enhance the existing techniques of loop pruning, k-path interval analysis, and disjunctive loop summarization. These changes have improved the verification of programs with arrays, and unstructured loops and unstructured control flows.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:2KloaMYe4IUC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2020,"We present a full-program induction technique for proving (a sub-class of) quantified as well as quantifier-free properties of programs manipulating arrays of parametric size N. Instead of inducting over individual loops, our technique inducts over the entire program (possibly containing multiple loops) directly via the program parameter N. Significantly, this does not require generation or use of loop-specific invariants. We have developed a prototype tool Vajra to assess the efficacy of our technique. We demonstrate the performance of Vajra vis-a-vis several state-of-the-art tools on a set of array manipulating benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:NJ774b8OgUMC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2019,"T OCK. COM and IEEE TSE. In fact, ICSE 2014 was held in Hyderabad and POPL 2015 was held in Mumbai under the General Chairship of Pankaj Jalote and Sriram Rajamani, respectively. India also has its flagship annual conference called Innovations in Software Engineering (ISEC), which provides a platform for sharing experiences of various research groups.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:tzM49s52ZIMC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2019,"Given a Boolean formula F(X, Y), where X is a vector of outputs and Y is a vector of inputs, the Boolean functional synthesis problem requires us to compute a Skolem function vector Ψ(Y) such that F(Ψ(Y), Y) holds whenever ∃X F(X, Y) holds. In this paper, we investigate the relation between the representation of the specification F(X, Y) and the complexity of synthesis. We introduce a new normal form for Boolean formulas, called SynNNF, that guarantees polynomial-time synthesis and also polynomial-time existential quantification for some order of quantification of variables. We show that several normal forms studied in the knowledge compilation literature are subsumed by SynNNF, although SynNNF can be super-polynomially more succinct than them. Motivated by these results, we propose an algorithm to convert a specification in CNF to SynNNF, with the intent of solving the Boolean functional synthesis …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:hkOj_22Ku90C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2019,"A promising approach to probabilistic inference that has attracted recent attention exploits its reduction to a set of model counting queries. Since probabilistic inference and model counting are# P-hard, various relaxations are used in practice, with the hope that these relaxations allow efficient computation while also providing rigorous approximation guarantees.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:WqliGbK-hY8C,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2019,"Finding gene regulatory pathways that explain outcomes of wet-lab experiments is one of the holy grails of systems biology. SAT-solving techniques have been used in the past to find few small explanatory pathways assuming either zero or a few known perturbations in the experimental observations. Unfortunately, these approaches do not work when (i) there is noise in the experimental data or domain knowledge, as opposed to known perturbations, and (ii) the number of possible pathways generated by repeatedly invoking a SAT-solver is too large to be analyzed by enumeration. In such settings, determining if an actor plays a functionally significant role towards explaining experimental observations is very difficult using existing SAT-based techniques.
In this paper, we formalize the problem of functional significance checking in gene-regulatory pathways in the presence of a bounded amount of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:ZfRJV9d4-WMC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2019,"Counting the number of perfect matchings in bipartite graphs, or equivalently computing the permanent of 0-1 matrices, is an important combinatorial problem that has been extensively studied by theoreticians and practitioners alike. The permanent is #P-Complete; hence it is unlikely that a polynomial-time algorithm exists for the problem. Researchers have therefore focused on finding tractable subclasses of matrices for permanent computation. One such subclass that has received much attention is that of sparse matrices i.e. matrices with few entries set to 1, the rest being 0. For this subclass, improved theoretical upper bounds and practically efficient algorithms have been developed. In this paper, we ask whether it is possible to go beyond sparse matrices in our quest for developing scalable techniques for the permanent, and answer this question affirmatively. Our key insight is to represent permanent …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:dQ2og3OwTAUC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2018,"Given a relational specification between Boolean inputs and outputs, the goal of Boolean functional synthesis is to synthesize each output as a function of the inputs such that the specification is met. In this paper, we first show that unless some hard conjectures in complexity theory are falsified, Boolean functional synthesis must generate large Skolem functions in the worst-case. Given this inherent hardness, what does one do to solve the problem? We present a two-phase algorithm, where the first phase is efficient both in terms of time and size of synthesized functions, and solves a large fraction of benchmarks. To explain this surprisingly good performance, we provide a sufficient condition under which the first phase must produce correct answers. When this condition fails, the second phase builds upon the result of the first phase, possibly requiring exponential time and generating exponential-sized …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:g3aElNc5_aQC,http://www.cse.iitb.ac.in/~supratik
Supratik Chakraborty,"['Formal methods', 'constrained sampling and counting', 'automated synthesis', 'logic and automata theory']",16,1093,2018,"A demand-driven approach to program analysis have been viewed as efficient algorithms to compute only the information required to serve a target demand. In contrast, an exhaustive approach computes all information in anticipation of it being used later. However, for a given set of demands, demand-driven methods are believed to compute the same information that would be computed by the corresponding exhaustive methods. We investigate the precision and bidirectional nature of demand-driven methods and show that: (a) demand-driven methods can be formalized inherently as bidirectional data flow analysis because the demands are propagated against the control flow and the information to satisfy the demands is propagated along the control flow. We extend the formalization of the Meet Over Paths solution to bidirectional flows. This formalization helps us to prove the soundness and precision of our analysis, and (b) since a demand-driven method computes only the required information to meet a demand, it should be able to reduce the imprecision caused by data abstractions and hence should be more precise than an exhaustive method. We show that while this is indeed the case with Java, for C/C++, the precision critically hinges on how indirect assignments are handled. We use this insight and propose a demand-driven alias analysis that is more precise than an exhaustive analysis for C/C++ too. We have chosen devirtualization as an application. Our measurements show that our method is not only more efficient but more precise than the existing demand-driven method, as well as the corresponding exhaustive method.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LwG4hd8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LwG4hd8AAAAJ:1yQoGdGgb4wC,http://www.cse.iitb.ac.in/~supratik
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2023,"We introduce UDAAN, an open-source post-editing tool that can reduce manual editing efforts to quickly produce publishable-standard documents in several Indic languages. UDAAN has an end-to-end Machine Translation (MT) plus post-editing pipeline wherein users can upload a document to obtain raw MT output. Further, users can edit the raw translations using our tool. UDAAN offers several advantages: i. Domain-aware, vocabulary-based lexical constrained MT. ii. source-target and target-target lexicon suggestions for users. Replacements are based on the source and target texts’ lexicon alignment. iii. Translation suggestions are based on logs created during user interaction. iv. Source-target sentence alignment visualisation that reduces the cognitive load of users during editing. v. Translated outputs from our tool are available in multiple formats: docs, latex, and PDF. We also provide the facility to use …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:URolC5Kub84C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2023,"Humans are, arguably, one of the most important regions of interest in a visual analysis pipeline. Detecting how the human interacts with the surrounding environment, thus, becomes an important problem and has several potential use-cases. While this has been adequately addressed in the literature in the image setting, there exist very few methods addressing the case for in-the-wild videos. The problem is further exacerbated by the high degree of label skew. To this end, we propose SeRVo-HOI, a robust end-to-end framework for recognizing human-object interactions from a video, particularly in high label-skew settings. The network contextualizes multiple image representations and is trained to explicitly handle dataset skew. We propose and analyse methods to address the long-tail distribution of the labels and show improvements on the tail-labels. SeRVo-HOI outperforms the state-of-the-art by a significant margin 21.1% vs 17.6% mAP on the large-scale, in-the-wild VidHOI dataset while particularly demonstrating solid improvements in the tail-classes 19.9% vs 17.3% mAP.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:q3CdL3IzO_QC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2023,"In several supervised learning scenarios, auxiliary losses are used in order to introduce additional information or constraints into the supervised learning objective. For instance, knowledge distillation aims to mimic outputs of a powerful teacher model; similarly, in rule-based approaches, weak labeling information is provided by labeling functions which may be noisy rule-based approximations to true labels. We tackle the problem of learning to combine these losses in a principled manner. Our proposal, AMAL, uses a bi-level optimization criterion on validation data to learn optimal mixing weights, at an instance-level, over the training data. We describe a meta-learning approach towards solving this bi-level objective, and show how it can be applied to different scenarios in supervised learning. Experiments in a number of knowledge distillation and rule denoising domains show that AMAL provides noticeable gains …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:HbR8gkJAVGIC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Deep neural networks have seen great success in recent years; however, training a deep model is often challenging as its performance heavily depends on the hyper-parameters used. In addition, finding the optimal hyper-parameter configuration, even with state-of-the-art (SOTA) hyper-parameter optimization (HPO) algorithms, can be time-consuming, requiring multiple training runs over the entire datasetfor different possible sets of hyper-parameters. Our central insight is that using an informative subset of the dataset for model training runs involved in hyper-parameter optimization, allows us to find the optimal hyper-parameter configuration significantly faster. In this work, we propose AUTOMATA, a gradient-based subset selection framework for hyper-parameter tuning. We empirically evaluate the effectiveness of AUTOMATA in hyper-parameter tuning through several experiments on real-world datasets in the text, vision, and tabular domains. Our experiments show that using gradient-based data subsets for hyper-parameter tuning achieves significantly faster turnaround times and speedups of 3×-30× while achieving comparable performance to the hyper-parameters found using the entire dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:BUYA1_V_uYcC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Sanskrit is a classical language with about 30 million extant manuscripts fit for digitisation, available in written, printed or scannedimage forms. However, it is still considered to be a low-resource language when it comes to available digital resources. In this work, we release a post-OCR text correction dataset containing around 218,000 sentences, with 1.5 million words, from 30 different books. Texts in Sanskrit are known to be diverse in terms of their linguistic and stylistic usage since Sanskrit was the 'lingua franca' for discourse in the Indian subcontinent for about 3 millennia. Keeping this in mind, we release a multi-domain dataset, from areas as diverse as astronomy, medicine and mathematics, with some of them as old as 18 centuries. Further, we release multiple strong baselines as benchmarks for the task, based on pre-trained Seq2Seq language models. We find that our best-performing model, consisting of byte level tokenization in conjunction with phonetic encoding (Byt5+SLP1), yields a 23% point increase over the OCR output in terms of word and character error rates. Moreover, we perform extensive experiments in evaluating these models on their performance and analyse common causes of mispredictions both at the graphemic and lexical levels. Our code and dataset is publicly available at https://github.com/ayushbits/pe-ocr-sanskrit.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:xtoqd-5pKcoC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"A majority of recent developments in neural architecture search (NAS) have been aimed at decreasing the computational cost of various techniques without affecting their final performance. Towards this goal, several low-fidelity and performance prediction methods have been considered, including those that train only on subsets of the training data. In this work, we present an adaptive subset selection approach to NAS and present it as complementary to state-of-the-art NAS approaches. We uncover a natural connection between one-shot NAS algorithms and adaptive subset selection and devise an algorithm that makes use of state-of-the-art techniques from both areas. We use these techniques to substantially reduce the runtime of DARTS-PT (a leading one-shot NAS algorithm), as well as BOHB and DEHB (leading multifidelity optimization algorithms), without sacrificing accuracy. Our results are consistent across multiple datasets, and towards full reproducibility, we release our code at https: //anonymous.4open.science/r/SubsetSelection NAS-B132.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:Dip1O2bNi0gC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"The majority of recent developments in neural architecture search (NAS) have been aimed at decreasing the computational cost of various techniques without affecting their final performance. Towards this direction, many low-fidelity and performance prediction methods have been considered, including using subsets of the training data. In this work, we initiate the study of *adaptive* subset selection for NAS and present it as complementary to state-of-the-art NAS approaches. We uncover a natural connection between one-shot NAS algorithms and adaptive subset selection and devise an algorithm that makes use of state-of-the-art techniques from both areas. We use these techniques to substantially reduce the runtime of DARTS-PT, a leading one-shot NAS algorithm, without sacrificing accuracy. Our results are consistent across multiple datasets, and our code and all materials needed to reproduce our results are available at https://anonymous.4open.science/r/SubsetSelection_NAS-2BE4.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:p__nRnzSRKYC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Training state-of-the-art ASR systems such as RNN-T often has a high associated financial and environmental cost. Training with a subset of training data could mitigate this problem if the subset selected could achieve on-par performance with training with the entire dataset. Although there are many data subset selection(DSS) algorithms, direct application to the RNN-T is difficult, especially the DSS algorithms that are adaptive and use learning dynamics such as gradients, as RNN-T tend to have gradients with a significantly larger memory footprint. In this paper, we propose Partitioned Gradient Matching (PGM) a novel distributable DSS algorithm, suitable for massive datasets like those used to train RNN-T. Through extensive experiments on Librispeech 100H and Librispeech 960H, we show that PGM achieves between 3x to 6x speedup with only a very small accuracy degradation (under 1% absolute WER difference). In addition, we demonstrate similar results for PGM even in settings where the training data is corrupted with noise.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:PoWvk5oyLR8C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Domain-specific neural machine translation (NMT) systems (e.g., in educational applications) are socially significant with the potential to help make information accessible to a diverse set of users in multilingual societies. It is desirable that such NMT systems be lexically constrained and draw from domain-specific dictionaries. Dictionaries could present multiple candidate translations for a source words/phrases on account of the polysemous nature of words. The onus is then on the NMT model to choose the contextually most appropriate candidate. Prior work has largely ignored this problem and focused on the single candidate setting where the target word or phrase is replaced by a single constraint. In this work we present DICTDIS, a lexically constrained NMT system that disambiguates between multiple candidate translations derived from dictionaries. We achieve this by augmenting training data with multiple dictionary candidates to actively encourage disambiguation during training. We demonstrate the utility of DICTDIS via extensive experiments on English-Hindi sentences in a variety of domains including news, finance, medicine and engineering. We obtain superior disambiguation performance on all domains with improved fluency in some domains of up to 4 BLEU points, when compared with existing approaches for lexically constrained and unconstrained NMT.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:i2xiXl-TujoC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"The challenge that climate change poses to humanity has spurred a rapidly developing field of artificial intelligence research focused on climate change applications. The climate change AI (CCAI) community works on a diverse, challenging set of problems which often involve physics-constrained ML or heterogeneous spatiotemporal data. It would be desirable to use automated machine learning (AutoML) techniques to automatically find high-performing architectures and hyperparameters for a given dataset. In this work, we benchmark popular AutoML libraries on three high-leverage CCAI applications: climate modeling, wind power forecasting, and catalyst discovery. We find that out-of-the-box AutoML libraries currently fail to meaningfully surpass the performance of human-designed CCAI models. However, we also identify a few key weaknesses, which stem from the fact that most AutoML techniques are tailored to computer vision and NLP applications. For example, while dozens of search spaces have been designed for image and language data, none have been designed for spatiotemporal data. Addressing these key weaknesses can lead to the discovery of novel architectures that yield substantial performance gains across numerous CCAI applications. Therefore, we present a call to action to the AutoML community, since there are a number of concrete, promising directions for future work in the space of AutoML for CCAI. We release our code and a list of resources at https://github.com/climate-change-automl/climate-change-automl.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:SpbeaW3--B0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Solving math word problems (MWPs) is an important and challenging problem in natural language processing. Existing approaches to solving MWPs require full supervision in the form of intermediate equations. However, labeling every MWP with its corresponding equations is a time-consuming and expensive task. In order to address this challenge of equation annotation, we propose a weakly supervised model for solving MWPs by requiring only the final answer as supervision. We approach this problem by first learning to generate the equation using the problem description and the final answer, which we subsequently use to train a supervised MWP solver. We propose and compare various weakly supervised techniques to learn to generate equations directly from the problem description and answer. Through extensive experiments, we demonstrate that without using equations for supervision, our approach achieves accuracy gains of 4.5% and 32% over the current state-of-the-art weakly-supervised approach, on the standard Math23K and AllArith datasets respectively. Additionally, we curate and release new datasets of roughly 10k MWPs each in English and in Hindi (a low-resource language). These datasets are suitable for training weakly supervised models. We also present an extension of our model to semi-supervised learning and present further improvements on results, along with insights.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:S16KYo8Pm5AC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Training deep learning models on medical datasets that perform well for all classes is a challenging task. It is often the case that a suboptimal performance is obtained on some classes due to the natural class imbalance issue that comes with medical data. An effective way to tackle this problem is by using targeted active learning, where we iteratively add data points that belong to the rare classes, to the training data. However, existing active learning methods are ineffective in targeting rare classes in medical datasets. In this work, we propose Clinical (targeted aCtive Learning for ImbalaNced medICal imAge cLassification) a framework that uses submodular mutual information functions as acquisition functions to mine critical data points from rare classes. We apply our framework to a wide-array of medical imaging datasets on a variety of real-world class imbalance scenarios-namely, binary imbalance and long-tail imbalance. We show that Clinical outperforms the state-ofthe-art active learning methods by acquiring a diverse set of data points that belong to the rare classes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:e_rmSamDkqQC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Avoiding out-of-distribution (OOD) data is critical for training supervised machine learning models in the medical imaging domain. Furthermore, obtaining labeled medical data is difficult and expensive since it requires expert annotators like doctors, radiologists, etc. Active learning (AL) is a well-known method to mitigate labeling costs by selecting the most diverse or uncertain samples. However, current AL methods do not work well in the medical imaging domain with OOD data. We propose Diagnose (avoiDing out-of-dIstribution dAta usinG submodular iNfOrmation meaSurEs), an active learning framework that can jointly model similarity and dissimilarity, which is crucial in mining indistribution data and avoiding OOD data at the same time. Particularly, we use a small number of data points as exemplars that represent a query set of in-distribution data points and another set of exemplars that represent a private set of OOD data points. We illustrate the generalizability of our framework by evaluating it on a wide variety of real-world OOD scenarios. Our experiments verify the superiority of Diagnose over the state-of-the-art AL methods across multiple domains of medical imaging.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:WZBGuue-350C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Training deep learning models on medical datasets that perform well for all classes is a challenging task. It is often the case that a suboptimal performance is obtained on some classes due to the natural class imbalance issue that comes with medical data. An effective way to tackle this problem is by using targeted active learning, where we iteratively add data points that belong to the rare classes, to the training data. However, existing active learning methods are ineffective in targeting rare classes in medical datasets. In this work, we propose Clinical (targeted aCtive Learning for ImbalaNced medICal imAge cLassification) a framework that uses submodular mutual information functions as acquisition functions to mine critical data points from rare classes. We apply our framework to a wide-array of medical imaging datasets on a variety of real-world class imbalance scenarios - namely, binary imbalance and long-tail …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:-FonjvnnhkoC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Avoiding out-of-distribution (OOD) data is critical for training supervised machine learning models in the medical imaging domain. Furthermore, obtaining labeled medical data is difficult and expensive since it requires expert annotators like doctors, radiologists, etc. Active learning (AL) is a well-known method to mitigate labeling costs by selecting the most diverse or uncertain samples. However, current AL methods do not work well in the medical imaging domain with OOD data. We propose Diagnose (avoiDing out-of-dIstribution dAta usinG submodular iNfOrmation meaSurEs), an active learning framework that can jointly model similarity and dissimilarity, which is crucial in mining in-distribution data and avoiding OOD data at the same time. Particularly, we use a small number of data points as exemplars that represent a query set of in-distribution data points and another set of exemplars that represent a private set …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:oNZyr7d5Mn4C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Introduction
Limited treatment options exist for COVID-19 infections; thus, attempts from complementary and alternative systems (CAM) of medicine are being explored as possible therapeutic options. Ayurcov is a formulation made of ingredients mentioned in Ayurveda. These constituents have proven antiviral, detoxifying, immune-modulating, and bio-enhancing properties. The present study was carried out to evaluate the therapeutic effect and safety of Ayurcov in patients with various severity states of COVID-19 infections.
Methods
A randomized, single blinded, controlled trial was carried out in adults diagnosed with mild-to-moderate, and severe COVID-19 infections confirmed by real time reverse transcriptase polymerase chain reaction (rRTPCR) test. The interventional group received three doses of ‘Ayurcov’. It is constituted of Haridra Churna (Curcuma longa), Go ark (Bos Indicus Distilled Urine), Sphatika (Alum …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:Z5m8FVwuT1cC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"With ever-increasing dataset sizes, subset selection techniques are becoming increasingly important for a plethora of tasks. It is often necessary to guide the subset selection to achieve certain desiderata, which includes focusing or targeting certain data points, while avoiding others. Examples of such problems include: i) targeted learning, where the goal is to find subsets with rare classes or rare attributes on which the model is under performing, and ii) guided summarization, where data (eg, image collection, text, document or video) is summarized for quicker human consumption with specific additional user intent. Motivated by such applications, we present PRISM, a rich class of PaRameterIzed Submodular information Measures. Through novel functions and their parameterizations, PRISM offers a variety of modeling capabilities that enable a trade-off between desired qualities of a subset like diversity or representation and similarity/dissimilarity with a set of data points. We demonstrate how PRISM can be applied to the two real-world problems mentioned above, which require guided subset selection. In doing so, we show that PRISM interestingly generalizes some past work, therein reinforcing its broad utility. Through extensive experiments on diverse datasets, we demonstrate the superiority of PRISM over the state-of-the-art in targeted learning and in guided image-collection summarization. PRISM is available as a part of the SUBMODLIB (https://github. com/decile-team/submodlib) and TRUST (https://github. com/decile-team/trust) toolkits.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:g3aElNc5_aQC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Current autograders of programming assignments are typically program output based; they fall short in many ways: e.g. they do not carry out subjective evaluations such as code quality, or whether the code has followed any instructor specified constraints; this is still done manually by teaching assistants. In this paper, we tackle a specific aspect of such evaluation: to verify whether a program implements a specific algorithm that the instructor specified. An algorithm, e.g. bubble sort, can be coded in myriad different ways, but a human can always understand the code and spot, say a bubble sort, vs. a selection sort. We develop and compare four approaches to do precisely this: given the source code of a program known to implement a certain functionality, identify the algorithm used, among a known set of algorithms. The approaches are based on code similarity, Support Vector Machine (SVM) with tree or graph …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:L7CI7m0gUJcC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"The data distribution in popular crowd counting datasets is typically heavy tailed and discontinuous. This skew affects all stages within the pipelines of deep crowd counting approaches. Specifically, the approaches exhibit unacceptably large standard deviation wrt statistical measures (MSE, MAE). To address such concerns in a holistic manner, we make two fundamental contributions. Firstly, we modify the training pipeline to accommodate the knowledge of dataset skew. To enable principled and balanced minibatch sampling, we propose a novel smoothed Bayesian binning approach. More specifically, we propose a novel cost function which can be readily incorporated into existing crowd counting deep networks to encourage bin-aware optimization. As the second contribution, we introduce additional performance measures which are more inclusive and throw light on various comparative performance aspects of the deep networks. We also show that our binning-based modifications retain their superiority wrt the newly proposed performance measures. Overall, our contributions enable a practically useful and detail-oriented characterization of performance for crowd counting approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:BwyfMAYsbu0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"The data distribution in popular crowd counting datasets is typically heavy tailed and discontinuous. This skew affects all stages within the pipelines of deep crowd counting approaches. Specifically, the approaches exhibit unacceptably large standard deviation wrt statistical measures (MSE, MAE). To address such concerns in a holistic manner, we make two fundamental contributions. Firstly, we modify the training pipeline to accommodate the knowledge of dataset skew. To enable principled and balanced minibatch sampling, we propose a novel smoothed Bayesian binning approach. More specifically, we propose a novel cost function which can be readily incorporated into existing crowd counting deep networks to encourage bin-aware optimization. As the second contribution, we introduce additional performance measures which are more inclusive and throw light on various comparative performance aspects of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:hMsQuOkrut0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"We focus on the audio-visual video parsing (AVVP) problem that involves detecting audio and visual event labels with temporal boundaries. The task is especially challenging since it is weakly supervised with only event labels available as a bag of labels for each video. An existing state-of-the-art model for AVVP uses a hybrid attention network (HAN) to generate cross-modal features for both audio and visual modalities, and an attentive pooling module that aggregates predicted audio and visual segment-level event probabilities to yield video-level event probabilities. We provide a detailed analysis of modality bias in the existing HAN architecture, where a modality is completely ignored during prediction. We also propose a variant of feature aggregation in HAN that leads to an absolute gain in F-scores of about 2% and 1.6% for visual and audio-visual events at both segment-level and event-level, in comparison to the existing HAN model.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:ML0RJ9NH7IQC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Current semi-supervised learning (SSL) methods assume a balance between the number of data points available for each class in both the labeled and the unlabeled data sets. However, there naturally exists a class imbalance in most real-world datasets. It is known that training models on such imbalanced datasets leads to biased models, which in turn lead to biased predictions towards the more frequent classes. This issue is further pronounced in SSL methods, as they would use this biased model to obtain psuedo-labels (on the unlabeled data) during training. In this paper, we tackle this problem by attempting to select a balanced labeled dataset for SSL that would result in an unbiased model. Unfortunately, acquiring a balanced labeled dataset from a class imbalanced distribution in one shot is challenging. We propose BASIL (Balanced Active Semi-supervIsed Learning), a novel algorithm that optimizes the submodular mutual information (SMI) functions in a per-class fashion to gradually select a balanced dataset in an active learning loop. Importantly, our technique can be efficiently used to improve the performance of any SSL method. Our experiments on Path-MNIST and Organ-MNIST medical datasets for a wide array of SSL methods show the effectiveness of Basil. Furthermore, we observe that Basil outperforms the state-of-the-art diversity and uncertainty based active learning methods since the SMI functions select a more balanced dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:AvfA0Oy_GE0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"We focus on the audio-visual video parsing (AVVP) problem that involves detecting audio and visual event labels with temporal boundaries. The task is especially challenging since it is weakly supervised with only event labels available as a bag of labels for each video. An existing state-of-the-art model for AVVP uses a hybrid attention network (HAN) to generate cross-modal features for both audio and visual modalities, and an attentive pooling module that aggregates predicted audio and visual segment-level event probabilities to yield video-level event probabilities. We provide a detailed analysis of modality bias in the existing HAN architecture, where a modality is completely ignored during prediction. We also propose a variant of feature aggregation in HAN that leads to an absolute gain in F-scores of about 2% and 1.6% for visual and audio-visual events at both segment-level and event-level, in comparison to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:4MWp96NkSFoC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Submodular functions are a special class of set functions which naturally model the notion of representativeness, diversity, coverage etc. and have been shown to be computationally very efficient. A lot of past work has applied submodular optimization to find optimal subsets in various contexts. Some examples include data summarization for efficient human consumption, finding effective smaller subsets of training data to reduce the model development time (training, hyper parameter tuning), finding effective subsets of unlabeled data to reduce the labeling costs, etc. A recent work has also leveraged submodular functions to propose submodular information measures which have been found to be very useful in solving the problems of guided subset selection and guided summarization. In this work, we present Submodlib which is an open-source, easy-to-use, efficient and scalable Python library for submodular optimization with a C++ optimization engine. Submodlib finds its application in summarization, data subset selection, hyper parameter tuning, efficient training and more. Through a rich API, it offers a great deal of flexibility in the way it can be used.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:uWiczbcajpAC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Knowledge distillation is a technique where the outputs of a pretrained model, often known as the teacher model is used for training a student model in a supervised setting. The teacher model outputs being a richer distribution over labels should improve the student model's performance as opposed to training with the usual hard labels. However, the label distribution imposed by the logits of the teacher network may not be always informative and may lead to poor student performance. We tackle this problem via the use of an adaptive loss mixing scheme during KD. Specifically, our method learns an instance-specific convex combination of the teacher-matching and label supervision objectives, using meta learning on a validation metric signalling to the student `how much' of KD is to be used. Through a range of experiments on controlled synthetic data and real-world datasets, we demonstrate performance gains obtained using our approach in the standard KD setting as well as in multi-teacher and self-distillation settings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:vDijr-p_gm4C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Post-editing in Automatic Speech Recognition (ASR) entails automatically correcting common and systematic errors produced by the ASR system. The outputs of an ASR system are largely prone to phonetic and spelling errors. In this paper, we propose to use a powerful pre-trained sequence-to-sequence model, BART, further adaptively trained to serve as a denoising model, to correct errors of such types. The adaptive training is performed on an augmented dataset obtained by synthetically inducing errors as well as by incorporating actual errors from an existing ASR system. We also propose a simple approach to rescore the outputs using word level alignments. Experimental results on accented speech data demonstrate that our strategy effectively rectifies a significant number of ASR errors and produces improved WER results when compared against a competitive baseline.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:epqYDVWIO7EC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Vāgyojaka is an open-source post-editing and annotation tool for automatic speech recognition (asr) that aims to reduce the human effort required to correct the asr results. We adopt a dictionary-based lookup method to highlight the incorrect words in the asr transcript and give suggestions by generating the closest valid words. For curating the speech corpus, we provide a rich list of tagset that captures various spoken audio features. Further, we conducted a user study to evaluate the effectiveness of our tool and observed that post-editing requires 1/3 lesser time than editing without using our tool. The user study can be found on our website. Copyright © 2022 isca.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:M7yex6snE4oC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Sanskrit is a low-resource language in the regime of ASR. We propose an ASR system for Sanskrit that effectively combines subword tokenisation strategies and search space enrichment with linguistic information. More specifically, we first use a subword based language model and acoustic model to generate a search space, to address the challenges due to the high degree of out of vocabulary entries in morphologically rich language, Sanskrit. We then convert the search space into a wordbased search space, and further enrich with morphological and lexical information based on a shallow parser. Finally, we rescore the transitions in our search space, a word confusion network, using a supervised morphological parser proposed for Sanskrit. Our proposed approach currently reports the state of the art results in Sanskrit ASR, with a 7.18 absolute point reduction in WER than the previous state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:kz9GbA2Ns4gC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Humans are, arguably, one of the most important regions of interest in a visual analysis pipeline. Detecting how the human interacts with the surrounding environment, thus, becomes an important problem and has several potential use-cases. While this has been adequately addressed in the literature in the image setting, there exist very few methods addressing the case for in-the-wild videos. The problem is further exacerbated by the high degree of label skew. To this end, we propose SERVO-HOI, a robust end-to-end framework for recognizing human-object interactions from a video, particularly in high label-skew settings. The network contextualizes multiple image representations and is trained to explicitly handle dataset skew. We propose and analyse methods to address the long-tail distribution of the labels and show improvements on the tail-labels. SERVOHOI outperforms the state-of-the-art by a significant margin (21.2% vs 17.6% mAP) on the large-scale, in-the-wild VidHOI dataset while particularly demonstrating solid improvements in the tail-classes (20.9% vs 17.3% mAP).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:KUbvn5osdkgC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2022,"Machine learning, and specifically deep learning has transformed numerous application domains like computer vision and video analytics, speech recognition, natural language processing, and so on. As a result, significant focus of researchers in the last decade has been on obtaining the most accurate models, often matching and sometimes surpassing human level performance in these areas. However, deep learning is also unlike human learning in many ways. To achieve the human level performance, deep models require large amounts of labeled training data, several GPU instances to train, and massive size models (ranging from hundreds of millions to billions of parameters). In addition, they are often not robust to noise, imbalance, and out of distribution data, and can also easily inherit the biases in the training data. Motivated by these desiderata and many more, we will present a rich framework of subset selection and coreset based approaches. We will begin by studying the theoretical aspects of subset selection, such as the modeling paradigms of coresets and submodularity, and the resulting optimization algorithms and theoretical properties. We will then study the application of subset selection to a number of areas like: a) compute-efficient training of deep models, b) label efficient methods like active learning, c) feature selection and model compression, d) targeted subset selection for robust, fair, and personalized learning, and e) human assisted learning. An important component of this tutorial will be a hands-on session where we will present a number of toolkits developed as a part of DECILE (www. decile. org), which include …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:vbGhcppDl1QC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Video retrieval using natural language queries requires learning semantically meaningful joint embeddings between the text and the audio-visual input. Often, such joint embeddings are learnt using pairwise (or triplet) contrastive loss objectives which cannot give enough attention to ‘difficult-to-retrieve’ samples during training. This problem is especially pronounced in data-scarce settings where the data is relatively small (10% of the large scale MSR-VTT) to cover the rather complex audio-visual embedding space. In this context, we propose to compensate for data scarcity by using domain knowledge to augment supervision. Specifically, in addition to the conventional three samples of a triplet (anchor, positive, and negative), we introduce a fourth term - a partial - to define a margin based partial-order loss. The partials are heuristically sampled such that they semantically lie in the overlap zone between the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:EkHepimYqZsC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Datasets for training crowd counting deep networks are typically heavy-tailed in count distribution and exhibit discontinuities across the count range. As a result, the de facto statistical measures (MSE, MAE) exhibit large variance and tend to be unreliable indicators of performance across the count range. To address these concerns in a holistic manner, we revise processes at various stages of the standard crowd counting pipeline. To enable principled and balanced minibatch sampling, we propose a novel smoothed Bayesian sample stratification approach. We propose a novel cost function which can be readily incorporated into existing crowd counting deep networks to encourage strata-aware optimization. We analyze the performance of representative crowd counting approaches across standard datasets at per strata level and in aggregate. We analyze the performance of crowd counting approaches across …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:nrtMV_XWKgEC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"We study the task of adapting an existing ASR model to a non-native accent while being constrained by a transcription budget on the duration of utterances selected from a large unlabeled corpus. We propose a subset selection approach using the recently proposed submodular mutual information functions, in which we identify a diverse set of utterances that match the target accent. This is specified through a few target utterances and achieved by modelling the relationship between the target and the selected subsets using these functions. The model adapts to the accent through fine-tuning with utterances selected and transcribed from the unlabeled corpus. We also use an accent classifier to learn accent-aware feature representations. Our method is also able to exploit samples from other accents to perform out-of-domain selections for low-resource accents which are not available in these corpora. We show that the targeted subset selection approach improves significantly upon random sampling - by around 5% to 10% (absolute) in most cases, and is around 10x more label-efficient. We also compare with an oracle method where we specifically pick from the target accent and our method is comparable to the oracle in its selections and WER performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:ruyezt5ZtCIC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"A critical bottleneck in supervised machine learning is the need for large amounts of labeled data which is expensive and time consuming to obtain. However, it has been shown that a small amount of labeled data, while insufficient to re-train a model, can be effectively used to generate human-interpretable labeling functions (LFs). These LFs, in turn, have been used to generate a large amount of additional noisy labeled data, in a paradigm that is now commonly referred to as data programming. However, previous approaches to automatically generate LFs make no attempt to further use the given labeled data for model training, thus giving up opportunities for improved performance. Moreover, since the LFs are generated from a relatively small labeled dataset, they are prone to being noisy, and naively aggregating these LFs can lead to very poor performance in practice. In this work, we propose an LF based reweighting framework \ouralgo{} to solve these two critical limitations. Our algorithm learns a joint model on the (same) labeled dataset used for LF induction along with any unlabeled data in a semi-supervised manner, and more critically, reweighs each LF according to its goodness, influencing its contribution to the semi-supervised loss using a robust bi-level optimization algorithm. We show that our algorithm significantly outperforms prior approaches on several text classification datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:uc_IGeMz5qoC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"We present a CATALIST model that ‘tames’ the attention (heads) of an attention-based scene text recognition model. We provide supervision to the attention masks at multiple levels, i.e., line, word, and character levels while training the multi-head attention model. We demonstrate that such supervision improves training performance and testing accuracy. To train CATALIST and its attention masks, we also present a synthetic data generator ALCHEMIST that enables the synthetic creation of large scene-text video datasets, along with mask information at character, word, and line levels. We release a real scene-text dataset of 2k videos,  with videos of real scenes that potentially contain scene-text in a combination of three different languages, namely, English, Hindi, and Marathi. We record these videos using 5 types of camera transformations - (i) translation, (ii) roll, (iii) tilt, (iv) pan, and (v) zoom to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:yB1At4FlUx8C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Datasets for training crowd counting deep networks are typically heavy-tailed in count distribution and exhibit discontinuities across the count range. As a result, the de facto statistical measures (MSE, MAE) exhibit large variance and tend to be unreliable indicators of performance across the count range. To address these concerns in a holistic manner, we revise processes at various stages of the standard crowd counting pipeline. To enable principled and balanced minibatch sampling, we propose a novel smoothed Bayesian sample stratification approach. We propose a novel cost function which can be readily incorporated into existing crowd counting deep networks to encourage strata-aware optimization. We analyze the performance of representative crowd counting approaches across standard datasets at per strata level and in aggregate. We analyze the performance of crowd counting approaches across …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:ILKRHgRFtOwC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"We present\spear, an open-source python library for data programming with semi supervision. The package implements several recent data programming approaches including facility to programmatically label and build training data. SPEAR facilitates\textit {weak supervision} in the form of heuristics (or rules) and association of\textit {noisy} labels to the training dataset. These\textit {noisy} labels are aggregated to assign labels to the unlabeled data for downstream tasks. We have implemented several label aggregation approaches that aggregate the\textit {noisy} labels and then train using the\textit {noisily} labeled set in a cascaded manner. Our implementation also includes other approaches that\textit {jointly} aggregate and train the model for text classification tasks. Thus, in our python package, we integrate several cascade and joint data-programming approaches while also providing the facility of data …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:9Nmd_mFXekcC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"We present SPEAR, an open-source python library for data programming with semi supervision. The package implements several recent data programming approaches including facility to programmatically label and build training data. SPEAR facilitates weak supervision in the form of heuristics (or rules) and association of noisy labels to the training dataset. These noisy labels are aggregated to assign labels to the unlabeled data for downstream tasks. We have implemented several label aggregation approaches that aggregate the noisy labels and then train using the noisily labeled set in a cascaded manner. Our implementation also includes other approaches that jointly aggregate and train the model for text classification tasks. Thus, in our python package, we integrate several cascade and joint data-programming approaches while also providing the facility of data programming by letting the user define labeling functions or rules. The code and tutorial notebooks are available at https://github.com/decile-team/spear. Further, extensive documentation can be found at https://spear-decile.readthedocs.io/. Video tutorials demonstrating the usage of our package are available here. We also present some real-world use cases of SPEAR.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:XD-gHx7UXLsC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Recursive neural networks (RvNN) have been shown useful for learning sentence representations and helped achieve competitive performance on several natural language inference tasks. However, recent RvNN-based models fail to learn simple grammar and meaningful semantics in their intermediate tree representation. In this work, we propose an attention mechanism over Tree-LSTMs to learn more meaningful and explainable parse tree structures. We also demonstrate the superior performance of our proposed model on natural language inference, semantic relatedness, and sentiment analysis tasks and compare them with other state-of-the-art RvNN based methods. Further, we present a detailed qualitative and quantitative analysis of the learned parse trees and show that the discovered linguistic structures are more explainable, semantically meaningful, and grammatically correct than recent approaches …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:_Re3VWB3Y0AC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Multimodal IR, spanning text corpus, knowledge graph and images, called outside knowledge visual question answering (OKVQA), is of much recent interest. However, the popular data set has serious limitations. A surprisingly large fraction of queries do not assess the ability to integrate cross-modal information. Instead, some are independent of the image, some depend on speculation, some require OCR or are otherwise answerable from the image alone. To add to the above limitations, frequency-based guessing is very effective because of (unintended) widespread answer overlaps between the train and test folds. Overall, it is hard to determine when state-of-the-art systems exploit these weaknesses rather than really infer the answers, because they are opaque and their 'reasoning' process is uninterpretable. An equally important limitation is that the dataset is designed for the quantitative assessment only of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:tKAzc9rXhukC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Data subset selection from a large number of training instances has been a successful approach toward efficient and cost-effective machine learning. However, models trained on a smaller subset may show poor generalization ability. In this paper, our goal is to design an algorithm for selecting a subset of the training data, so that the model can be trained quickly, without significantly sacrificing on accuracy. More specifically, we focus on data subset selection for regularized regression problems and provide a novel problem formulation which seeks to minimize the training loss with respect to both the trainable parameters and the subset of training data, subject to error bounds on the validation set. We tackle this problem using several technical innovations. First, we represent this problem with simplified constraints using the dual of the original training problem and show that the objective of this new representation is a monotone and -submodular function, for a wide variety of modeling choices. Such properties lead us to develop SELCON, an efficient majorization-minimization algorithm for data subset selection, that admits an approximation guarantee even when the training provides an imperfect estimate of the trained model. Finally, our experiments on several datasets show that SELCON trades off accuracy and efficiency more effectively than the current state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:z_wVstp3MssC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"The great success of modern machine learning models on large datasets is contingent on extensive computational resources with high financial and environmental costs. One way to address this is by extracting subsets that generalize on par with the full data. In this work, we propose a general framework, GRAD-MATCH, which finds subsets that closely match the gradient of the\emph {training or validation} set. We find such subsets effectively using an orthogonal matching pursuit algorithm. We show rigorous theoretical and convergence guarantees of the proposed algorithm and, through our extensive experiments on real-world datasets, show the effectiveness of our proposed framework. We show that GRAD-MATCH significantly and consistently outperforms several recent data-selection algorithms and achieves the best accuracy-efficiency trade-off. GRAD-MATCH is available as a part of the CORDS toolkit:\url {https://github. com/decile-team/cords}.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:kzcrU_BdoSEC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Data subset selection from a large number of training instances has been a successful approach toward efficient and cost-effective machine learning. However, models trained on a smaller subset may show poor generalization ability. In this paper, our goal is to design an algorithm for selecting a subset of the training data, so that the model can be trained quickly, without significantly sacrificing on accuracy. More specifically, we focus on data subset selection for L2 regularized regression problems and provide a novel problem formulation which seeks to minimize the training loss with respect to both the trainable parameters and the subset of training data, subject to error bounds on the validation set. We tackle this problem using several technical innovations. First, we represent this problem with simplified constraints using the dual of the original training problem and show that the objective of this new representation is a monotone and alpha-submodular function, for a wide variety of modeling choices. Such properties lead us to develop SELCON, an efficient majorization-minimization algorithm for data subset selection, that admits an approximation guarantee even when the training provides an imperfect estimate of the trained model. Finally, our experiments on several datasets show that SELCON trades off accuracy and efficiency more effectively than the current state-of-the-art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:j8SEvjWlNXcC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"With the goal of making deep learning more label-efficient, a growing number of papers have been studying active learning (AL) for deep models. However, there are a number of issues in the prevalent experimental settings, mainly stemming from a lack of unified implementation and benchmarking. Issues in the current literature include sometimes contradictory observations on the performance of different AL algorithms, unintended exclusion of important generalization approaches such as data augmentation and SGD for optimization, a lack of study of evaluation facets like the labeling efficiency of AL, and little or no clarity on the scenarios in which AL outperforms random sampling (RS). In this work, we present a unified re-implementation of state-of-the-art AL algorithms in the context of image classification via our new open-source AL toolkit DISTIL, and we carefully study these issues as facets of effective evaluation. On the positive side, we show that AL techniques are to more label-efficient compared to RS with the use of data augmentation. Surprisingly, when data augmentation is included, there is no longer a consistent gain in using BADGE, a state-of-the-art approach, over simple uncertainty sampling. We then do a careful analysis of how existing approaches perform with varying amounts of redundancy and number of examples per class. Finally, we provide several insights for AL practitioners to consider in future work, such as the effect of the AL batch size, the effect of initialization, the importance of retraining the model at every round, and other insights.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:uJ-U7cs_P_0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the various linguistic peculiarities present in the language. The Sanskrit language is lexically productive, undergoes euphonic assimilation of phones at the word boundaries and exhibits variations in spelling conventions and in pronunciations. In this work, we propose the first large scale study of automatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact of unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR dataset for Sanskrit, which faithfully captures several of the linguistic characteristics expressed by the language. We investigate the role of different acoustic model and language model units in ASR systems for Sanskrit. We also propose a new modelling unit, inspired by the syllable level unit selection, that captures character sequences from one vowel in the word to the next vowel. We also highlight the importance of choosing graphemic representations for Sanskrit and show the impact of this choice on word error rates (WER). Finally, we extend these insights from Sanskrit ASR for building ASR systems in two other Indic languages, Gujarati and Telugu. For both these languages, our experimental results show that the use of phonetic based graphemic representations in ASR results in performance improvements as compared to ASR systems that use native scripts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:35r97b3x0nAC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Recently, unsupervised parsing of syntactic trees has gained considerable attention. A prototypical approach to such unsupervised parsing employs reinforcement learning and auto-encoders. However, no mechanism ensures that the learnt model leverages the well-understood language grammar. We propose an approach that utilizes very generic linguistic knowledge of the language present in the form of syntactic rules, thus inducing better syntactic structures. We introduce a novel formulation that takes advantage of the syntactic grammar rules and is independent of the base system. We achieve new state-of-the-art results on two benchmarks datasets, MNLI and WSJ. The source code of the paper is available at https://github.com/anshuln/Diora_with_rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:-_dYPAW6P2MC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Large scale machine learning and deep models are extremely data-hungry. Unfortunately, obtaining large amounts of labeled data is expensive, and training state-of-the-art models (with hyperparameter tuning) requires significant computing resources and time. Secondly, real-world data is noisy and imbalanced. As a result, several recent papers try to make the training process more efficient and robust. However, most existing work either focuses on robustness or efficiency, but not both. In this work, we introduce GLISTER, a GeneraLIzation based data Subset selecTion for Efficient and Robust learning framework. We formulate GLISTER as a mixed discrete-continuous bi-level optimization problem to select a subset of the training data, which maximizes the log-likelihood on a held-out validation set. We then analyze GLISTER for simple classifiers such as gaussian and multinomial naive-bayes, k-nearest neighbor classifier, and linear regression and show connections to submodularity. Next, we propose an iterative online algorithm GLISTER-ONLINE, which performs data selection iteratively along with the parameter updates, and can be applied to any loss-based learning algorithm. We then show that for a rich class of loss functions including cross-entropy, hinge-loss, squared-loss, and logistic-loss, the inner discrete data selection is an instance of (weakly) submodular optimization, and we analyze conditions for which GLISTER-ONLINE reduces the validation loss and converges. Finally, we propose GLISTER-ACTIVE, an extension to batch active learning, and we empirically demonstrate the performance of GLISTER on a wide range of tasks …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:1yQoGdGgb4wC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"With the rapid growth of data, it is becoming increasingly difficult to train or improve deep learning models with the right subset of data. We show that this problem can be effectively solved at an additional labeling cost by targeted data subset selection(TSS) where a subset of unlabeled data points similar to an auxiliary set are added to the training data. We do so by using a rich class of Submodular Mutual Information (SMI) functions and demonstrate its effectiveness for image classification on CIFAR-10 and MNIST datasets. Lastly, we compare the performance of SMI functions for TSS with other state-of-the-art methods for closely related problems like active learning. Using SMI functions, we observe ~20-30% gain over the model's performance before re-training with added targeted subset; ~12% more than other methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:evX43VCCuoAC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Solving math word problems (MWPs) is an important and challenging problem in natural language processing. Existing approaches to solve MWPs require full supervision in the form of intermediate equations. However, labeling every math word problem with its corresponding equations is a time-consuming and expensive task. In order to address this challenge of equation annotation, we propose a weakly supervised model for solving math word problems by requiring only the final answer as supervision. We approach this problem by first learning to generate the equation using the problem description and the final answer, which we then use to train a supervised MWP solver. We propose and compare various weakly supervised techniques to learn to generate equations directly from the problem description and answer. Through extensive experiment, we demonstrate that even without using equations for supervision, our approach achieves an accuracy of 56.0 on the standard Math23K dataset. We also curate and release a new dataset for MWPs in English consisting of 10227 instances suitable for training weakly supervised models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:2KloaMYe4IUC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"In this paper, we present a novel approach to the audio-visual video parsing (AVVP) task that demarcates events from a video separately for audio and visual modalities. The proposed parsing approach simultaneously detects the temporal boundaries in terms of start and end times of such events. We show how AVVP can benefit from the following techniques geared towards effective cross-modal learning: (i) adversarial training and skip connections (ii) global context aware attention and, (iii) self-supervised pretraining using an audio-video grounding objective to obtain cross-modal audio-video representations. We present extensive experimental evaluations on the Look, Listen, and Parse (LLP) dataset and show that we outperform the state-of-the-art Hybrid Attention Network (HAN) on all five metrics proposed for AVVP. We also present several ablations to validate the effect of pretraining, global attention and adversarial training.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:tzM49s52ZIMC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Video retrieval using natural language queries requires learning semantically meaningful joint embeddings between the text and the audio-visual input. Often, such joint embeddings are learnt using pairwise (or triplet) contrastive loss objectives which cannot give enough attention to 'difficult-to-retrieve' samples during training. This problem is especially pronounced in data-scarce settings where the data is relatively small (10% of the large scale MSR-VTT) to cover the rather complex audio-visual embedding space. In this context, we introduce Rudder - a multilingual video-text retrieval dataset that includes audio and textual captions in Marathi, Hindi, Tamil, Kannada, Malayalam and Telugu. Furthermore, we propose to compensate for data scarcity by using domain knowledge to augment supervision. To this end, in addition to the conventional three samples of a triplet (anchor, positive, and negative), we introduce a fourth term - a partial - to define a differential margin based partialorder loss. The partials are heuristically sampled such that they semantically lie in the overlap zone between the positives and the negatives, thereby resulting in broader embedding coverage. Our proposals consistently outperform the conventional max-margin and triplet losses and improve the state-of-the-art on MSR-VTT and DiDeMO datasets. We report benchmark results on Rudder while also observing significant gains using the proposed partial order loss, especially when the language specific retrieval models are jointly trained by availing the cross-lingual alignment across the language-specific datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:7T2F9Uy0os0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"With ever-increasing dataset sizes, subset selection techniques are becoming increasingly important for a plethora of tasks. It is often necessary to guide the subset selection to achieve certain desiderata, which includes focusing or targeting certain data points, while avoiding others. Examples of such problems include: i) targeted learning, where the goal is to find subsets with rare classes or rare attributes on which the model is underperforming, and ii) guided summarization, where data (eg, image collection, text, document or video) is summarized for quicker human consumption with specific additional user intent. Motivated by such applications, we present PRISM, a rich class of PaRameterIzed Submodular information Measures. Through novel functions and their parameterizations, PRISM offers a variety of modeling capabilities that enable a trade-off between desired qualities of a subset like diversity or representation and similarity/dissimilarity with a set of data points. We demonstrate how PRISM can be applied to the two real-world problems mentioned above, which require guided subset selection. In doing so, we show that PRISM interestingly generalizes some past work, therein reinforcing its broad utility. Through extensive experiments on diverse datasets, we demonstrate the superiority of PRISM over the state-of-the-art in targeted learning and in guided image-collection summarization.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:zLWjf1WUPmwC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Automatic video summarization is still an unsolved problem due to several challenges. The currently available datasets either have very short videos or have few long videos of only a particular type. We introduce a new benchmarking video dataset called VISIOCITY (VIdeo SummarIzatiOn based on Continuity, Intent and DiversiTY) which comprises of longer videos across six different categories with dense concept annotations capable of supporting different flavors of video summarization and other vision problems. For long videos, human reference summaries necessary for supervised video summarization techniques are difficult to obtain. We explore strategies to automatically generate multiple reference summaries from indirect ground truth present in VISIOCITY. We show that these summaries are at par with human summaries. We also present a study of different desired characteristics of a good summary and demonstrate how it is normal to have two good summaries with different characteristics. Thus we argue that evaluating a summary against one or more human summaries and using a single measure has its shortcomings. We propose an evaluation framework for better quantitative assessment of summary quality which is closer to human judgment. Lastly, we present insights into how a model can be enhanced to yield better summaries. Sepcifically, when multiple diverse ground truth summaries can exist, learning from them individually and using a combination of loss functions measuring different characteristics is better than learning from a single combined (oracle) ground truth summary using a single loss function. We demonstrate the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:_Ybze24A_UAC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Natural language processing (NLP) tasks (e.g. question-answering in English) benefit from knowledge of other tasks (e.g. named entity recognition in English) and knowledge of other languages (e.g. question-answering in Spanish). Such shared representations are typically learned in isolation, either across tasks or across languages. In this work, we propose a meta-learning approach to learn the interactions between both tasks and languages. We also investigate the role of different sampling strategies used during meta-learning. We present experiments on five different tasks and six different languages from the XTREME multilingual benchmark dataset. Our meta-learned model clearly improves in performance compared to competitive baseline models that also include multi-task baselines. We also present zero-shot evaluations on unseen target languages to demonstrate the utility of our proposed model.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:UHK10RUVsp4C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"We consider the problem of multi-label classification where the labels lie in a hierarchy. However, unlike most existing works in hierarchical multi-label classification, we do not assume that the label-hierarchy is known. Encouraged by the recent success of hyperbolic embeddings in capturing hierarchical relations, we propose to jointly learn the classifier parameters as well as the label embeddings. Such a joint learning is expected to provide a twofold advantage: i) the classifier generalizes better as it leverages the prior knowledge of existence of a hierarchy over the labels, and ii) in addition to the label co-occurrence information, the label-embedding may benefit from the manifold structure of the input datapoints, leading to embeddings that are more faithful to the label hierarchy. We propose a novel formulation for the joint learning and empirically evaluate its efficacy. The results show that the joint learning improves over the baseline that employs label co-occurrence based pre-trained hyperbolic embeddings. Moreover, the proposed classifiers achieve state-of-the-art generalization on standard benchmarks. We also present evaluation of the hyperbolic embeddings obtained by joint learning and show that they represent the hierarchy more accurately than the other alternatives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:uLbwQdceFCQC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:ipzZ9siozwsC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:Fu2w8maKXqMC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2021,"Human-Object Interaction detection from a video clip can be considered as a special case of video-based Visual-Relationship Detection wherein the subject must be a human. Specifically, it involves detecting the humans and objects in the clip as well as the interactions between them. Conventionally, the problem has been formulated as a space-time graph inference problem over the video clip features. In this work, we explore alternate spatial approaches for detecting Human-Object Interactions. We consider a hierarchical setup that decouples spatial and temporal aspects of the problem and analyse the impacts of a variety of design choices for the spatial networks. Particularly, to capture spatial relationships in the scene, we analyze the effectiveness of the traditionally used Graph Convolutional Networks against Convolutional Networks and Capsule Networks. Unlike current approaches, we avoid using ground truth data like depth maps or 3D human pose during inference, thus increasing generalization across non-RGBD datasets as well. We demonstrate a comprehensive analysis of the exploration, both quantitatively and qualitatively, while achieving state-of-the-art results in human-object interaction detection (88.9% and 92.6%) and anticipation tasks of CAD-120 and competitive results on image based HOI detection (47.2%) in V-COCO dataset, setting a new benchmark for visual features based approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:ZuybSZzF8UAC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"Analyzing the interactions between humans and objects from a video includes identification of the relationships between humans and the objects present in the video. It can be thought of as a specialized version of Visual Relationship Detection, wherein one of the objects must be a human. While traditional methods formulate the problem as inference on a sequence of video segments, we present a hierarchical approach, LIGHTEN, to learn visual features to effectively capture spatio-temporal cues at multiple granularities in a video. Unlike current approaches, LIGHTEN avoids using ground truth data like depth maps or 3D human pose, thus increasing generalization across non-RGBD datasets as well. Furthermore, we achieve the same using only the visual features, instead of the commonly used hand-crafted spatial features. We achieve state-of-the-art results in human-object interaction detection (88.9% and 92.6 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:hkOj_22Ku90C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"Question generation (QG) has recently attracted considerable attention. Most of the current neural models take as input only one or two sentences, and perform poorly when multiple sentences or complete paragraphs are given as input. However, in real-world scenarios it is very important to be able to generate high-quality questions from complete paragraphs. In this paper, we present a simple yet effective technique for answer-aware question generation from paragraphs. We augment a basic sequence-to-sequence QG model with dynamic, paragraph-specific dictionary and copy attention that is persistent across the corpus, without requiring features generated by sophisticated NLP pipelines or handcrafted rules. Our evaluation on SQuAD shows that our model significantly outperforms current state-of-the-art systems in question generation from paragraphs in both automatic and human evaluation. We achieve a 6-point improvement over the best system on BLEU-4, from 16.38 to 22.62.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:VL0QpB8kHFEC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"We study submodular information measures as a rich framework for generic, query-focused, privacy sensitive, and update summarization tasks. While past work generally treats these problems differently ({\em e.g.}, different models are often used for generic and query-focused summarization), the submodular information measures allow us to study each of these problems via a unified approach. We first show that several previous query-focused and update summarization techniques have, unknowingly, used various instantiations of the aforesaid submodular information measures, providing evidence for the benefit and naturalness of these models. We then carefully study and demonstrate the modelling capabilities of the proposed functions in different settings and empirically verify our findings on both a synthetic dataset and an existing real-world image collection dataset (that has been extended by adding concept annotations to each image making it suitable for this task) and will be publicly released. We employ a max-margin framework to learn a mixture model built using the proposed instantiations of submodular information measures and demonstrate the effectiveness of our approach. While our experiments are in the context of image summarization, our framework is generic and can be easily extended to other summarization settings (e.g., videos or documents).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:LjlpjdlvIbIC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"Analyzing the interactions between humans and objects from a video includes identification of the relationships between humans and the objects present in the video. It can be thought of as a specialized version of Visual Relationship Detection, wherein one of the objects must be a human. While traditional methods formulate the problem as inference on a sequence of video segments, we present a hierarchical approach, LIGHTEN, to learn visual features to effectively capture spatio-temporal cues at multiple granularities in a video. Unlike current approaches, LIGHTEN avoids using ground truth data like depth maps or 3D human pose, thus increasing generalization across non-RGBD datasets as well. Furthermore, we achieve the same using only the visual features, instead of the commonly used hand-crafted spatial features. We achieve state-of-the-art results in human-object interaction detection (88.9% and 92.6 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:eq2jaN3J8jMC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"Automatic video summarization is still an unsolved problem due to several challenges. We take steps towards making it more realistic by addressing the following challenges. Firstly, the currently available datasets either have very short videos or have few long videos of only a particular type. We introduce a new benchmarking dataset called VISIOCITY which comprises of longer videos across six different categories with dense concept annotations capable of supporting different flavors of video summarization and other vision problems. Secondly, for long videos, human reference summaries, necessary for supervised video summarization techniques, are difficult to obtain. We present a novel recipe based on pareto optimality to automatically generate multiple reference summaries from indirect ground truth present in VISIOCITY. We show that these summaries are at par with human summaries. Thirdly, we …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:9vf0nzSNQJEC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"The paradigm of data programming, which uses weak supervision in the form of rules/labelling functions, and semi-supervised learning, which augments small amounts of labelled data with a large unlabelled dataset, have shown great promise in several text classification scenarios. In this work, we argue that by not using any labelled data, data programming based approaches can yield sub-optimal performances, particularly when the labelling functions are noisy. The first contribution of this work is an introduction of a framework, \model which is a semi-supervised data programming paradigm that learns a \emph{joint model} that effectively uses the rules/labelling functions along with semi-supervised loss functions on the feature space. Next, we also study \modelss which additionally does subset selection on top of the joint semi-supervised data programming objective and \emph{selects} a set of examples that can be used as the labelled set by \model. The goal of \modelss is to ensure that the labelled data can \emph{complement} the labelling functions, thereby benefiting from both data-programming as well as appropriately selected data for human labelling. We demonstrate that by effectively combining semi-supervision, data-programming, and subset selection paradigms, we significantly outperform the current state-of-the-art on seven publicly available datasets. \footnote{The source code is available at \url{https://github.com/ayushbits/Semi-Supervised-LFs-Subset-Selection}}",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:5awf1xo2G04C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"Scarcity of labeled data is a bottleneck for supervised learning models. A paradigm that has evolved for dealing with this problem is data programming. An existing data programming paradigm allows human supervision to be provided as a set of discrete labeling functions (LF) that output possibly noisy labels to input instances and a generative model for consolidating the weak labels. We enhance and generalize this paradigm by supporting functions that output a continuous score (instead of a hard label) that noisily correlates with labels. We show across five applications that continuous LFs are more natural to program and lead to improved recall. We also show that accuracy of existing generative models is unstable with respect to initialization, training epochs, and learning rates. We give control to the data programmer to guide the training process by providing intuitive quality guides with each LF. We propose an elegant method of incorporating these guides into the generative model. Our overall method, called CAGE, makes the data programming paradigm more reliable than other tricks based on initialization, sign-penalties, or soft-accuracy constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:tkaPQYYpVKoC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"With the ever increasing growth of videos, automatic video summarization has become an important task which has attracted lot of interest in the research community. One of the challenges which makes it a hard problem to solve is presence of multiple ‘correct answers’. Because of the highly subjective nature of the task, there can be different “ideal” summaries of a video. Modelling user intent in the form of queries has been posed in literature as a way to alleviate this problem. The query-focused summary is expected to contain shots which are relevant to the query in conjunction with other important shots. For practical deployments in which very long videos need to be summarized, this need to capture user’s intent becomes all the more pronounced. In this work, we propose a simple two stage method which takes user query and video as input and generates a query-focused summary. Specifically, in the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:PR6Y55bgFSsC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"Understanding videos via captioning has gained a lot of traction recently. While captions are provided alongside videos, the information about where a caption aligns within a video is missing, which could be particularly useful for indexing and retrieval. Existing work on learning to infer alignments has mostly exploited visual features and ignored the audio signal. Video understanding applications often underestimate the importance of the audio modality. We focus on how to make effective use of the audio modality for temporal localization of captions within videos. We release a new audio-visual dataset that has captions time-aligned by (i) carefully listening to the audio and watching the video, and (ii) watching only the video. Our dataset is audio-rich and contains captions in two languages, English and Marathi (a low-resource language). We further propose an attention-driven multimodal model, for effective …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:SdhP9T11ey4C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2020,"Sanskrit OCR documents have a lot of errors. Correcting those errors using conventional spell-checking approaches breaks down due to the limited vocabulary. This is because of high inflections of Sanskrit, where words are dynamically formed by Sandhi rules, Samāsa rules, Taddhita affixes, etc. Therefore, correcting OCR documents require huge efforts. In this paper, we present different machine learning approaches and various ways to improve features for ameliorating the error corrections in Sanskrit OCR documents. We simulated Subanta Prakaraṇam of VaiyākaraṇaSiddhāntaKaumudī for synthesizing off-the-shelf dictionary. Most of the methods we propose can also work for general Sanskrit word corrections.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:sSrBHYA8nusC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Automatic question generation from paragraphs is an important and challenging problem, particularly due to the long context from paragraphs. In this paper, we propose and study two hierarchical models for the task of question generation from paragraphs. Specifically, we propose (a) a novel hierarchical BiLSTM model with selective attention and (b) a novel hierarchical Transformer architecture, both of which learn hierarchical representations of paragraphs. We model a paragraph in terms of its constituent sentences, and a sentence in terms of its constituent words. While the introduction of the attention mechanism benefits the hierarchical BiLSTM model, the hierarchical Transformer, with its inherent attention and positional encoding mechanisms also performs better than flat transformer model. We conducted empirical evaluation on the widely used SQuAD and MS MARCO datasets using standard metrics. The results demonstrate the overall effectiveness of the hierarchical models over their flat counterparts. Qualitatively, our hierarchical models are able to generate fluent and relevant questions",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:AXPGKjj_ei8C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Automatic question generation (QG) is a useful yet challenging task in NLP. Recent neural network-based approaches represent the state-of-the-art in this task. In this work, we attempt to strengthen them significantly by adopting a holistic and novel generator-evaluator framework that directly optimizes objectives that reward semantics and structure. The {\it generator} is a sequence-to-sequence model that incorporates the {\it structure} and {\it semantics} of the question being generated. The generator predicts an answer in the passage that the question can pivot on. Employing the copy and coverage mechanisms, it also acknowledges other contextually important (and possibly rare) keywords in the passage that the question needs to conform to, while not redundantly repeating words. The {\it evaluator} model evaluates and assigns a reward to each predicted question based on its conformity to the {\it structure} of ground-truth questions. We propose two novel QG-specific reward functions for text conformity and answer conformity of the generated question. The evaluator also employs structure-sensitive rewards based on evaluation measures such as BLEU, GLEU, and ROUGE-L, which are suitable for QG. In contrast, most of the previous works only optimize the cross-entropy loss, which can induce inconsistencies between training (objective) and testing (evaluation) measures. Our evaluation shows that our approach significantly outperforms state-of-the-art systems on the widely-used SQuAD benchmark as per both automatic and human evaluation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:HE397vMXCloC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Automatic question generation (QG) is a useful yet challenging task in NLP. Recent neural network-based approaches represent the state-of-the-art in this task. In this work, we attempt to strengthen them significantly by adopting a holistic and novel generator-evaluator framework that directly optimizes objectives that reward semantics and structure. The {\it generator} is a sequence-to-sequence model that incorporates the {\it structure} and {\it semantics} of the question being generated. The generator predicts an answer in the passage that the question can pivot on. Employing the copy and coverage mechanisms, it also acknowledges other contextually important (and possibly rare) keywords in the passage that the question needs to conform to, while not redundantly repeating words. The {\it evaluator} model evaluates and assigns a reward to each predicted question based on its conformity to the {\it structure} of ground-truth questions. We propose two novel QG-specific reward functions for text conformity and answer conformity of the generated question. The evaluator also employs structure-sensitive rewards based on evaluation measures such as BLEU, GLEU, and ROUGE-L, which are suitable for QG. In contrast, most of the previous works only optimize the cross-entropy loss, which can induce inconsistencies between training (objective) and testing (evaluation) measures. Our evaluation shows that our approach significantly outperforms state-of-the-art systems on the widely-used SQuAD benchmark as per both automatic and human evaluation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:tS2w5q8j5-wC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Recent advances in machine learning have led to significant accuracy improvements for the task of generating textual captions from videos based on audio and visual signals. In this work, we focus on the influence of modality (audio and visual input) on semantic coherence and well-formedness of the generated captions. We explore both architectural and algorithmic choices that potentially influence the utilization of these modalities. (Algorithmic choices include pretraining while architectural choices include modality-specific weighing schemes.) We study the influence of our choices on a popular video captioning dataset, MSRVTT, by providing quantitative and ex-tensive qualitative evaluations that measure the influence of audio-visual modalities, cohesiveness and ranked relevance of keywords. We are able to assert qualitative improvements on metrics characterizing the quality of the captions, along with …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:dTyEYWd-f8wC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Obtaining a high-quality OCR output in smart cities, with human-in-the-loop, is an interesting problem for surveillance and other similar applications. Achieving high accuracy while reading license plates in the real world videos is cumbersome due to complexities like multiple vehicles, high-density traffic in spatial and temporal domains, varying camera angles and illumination, occlusions and multiple resolutions. We present a modular framework for OCR corrections in the chaotic Indian traffic videos that especially involve complex license plate patterns. Such patterns are obtained from a state-of-the-art deep learning model trained on video frames. Since such a model reads the text from videos (instead of images), we incorporate multi-frame consensus for generating suggestions in our framework. To ease the correction process, our human-interactive framework first breaks down the multi-vehicle videos into …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:5ugPr518TE4C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"We work on the problem of recognizing license plates and street signs automatically in challenging conditions such as chaotic traffic. We leverage state-of-the-art text spotters to generate a large amount of noisy labeled training data. The data is filtered using a pattern derived from domain knowledge. We augment training and testing data with interpolated boxes and annotations that makes our training and testing robust. We further use synthetic data during training to increase the coverage of the training data. We train two different models for recognition. Our baseline is a conventional Convolution Neural Network (CNN) encoder followed by a Recurrent Neural Network (RNN) decoder. As our first contribution, we bypass the detection phase by augmenting the baseline with an Attention mechanism in the RNN decoder. Next, we build in the capability of training the model end-to-end on scenes containing license …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:Y5dfb0dijaUC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Texts in Indic Languages contain a large proportion of out-of-vocabulary (OOV) words due to frequent fusion using conjoining rules (of which there are around 4000 in Sanskrit). OCR errors further accentuate this complexity for the error correction systems. Variations of sub-word units such as n-grams, possibly encapsulating the context, can be extracted from the OCR text as well as the language text individually. Some of the sub-word units that are derived from the texts in such languages highly correlate to the word conjoining rules. Signals such as frequency values (on a corpus) associated with such sub-word units have been used previously with log-linear classifiers for detecting errors in Indic OCR texts. We explore two different encodings to capture such signals and augment the input to Long Short Term Memory (LSTM) based OCR correction models, that have proven useful in the past for jointly learning the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:J-pR_7NvFogC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Multi-person 3D human pose estimation from a single image is a challenging problem, especially for in-the-wild settings due to the lack of 3D annotated data. We propose HG-RCNN, a Mask-RCNN based network that also leverages the benefits of the Hourglass architecture for multi-person 3D Human Pose Estimation. A two-staged approach is presented that first estimates the 2D keypoints in every Region of Interest (RoI) and then lifts the estimated keypoints to 3D. Finally, the estimated 3D poses are placed in camera-coordinates using weak-perspective projection assumption and joint optimization of focal length and root translations. The result is a simple and modular network for multi-person 3D human pose estimation that does not require any multi-person 3D pose dataset. Despite its simple formulation, HG-RCNN achieves the state-of-the-art results on MuPoTS-3D while also approximating the 3D pose in the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:olpn-zPbct0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Generating syntactically and semantically valid and relevant questions from paragraphs is useful with many applications. Manual generation is a labour-intensive task, as it requires the reading, parsing and understanding of long passages of text. A number of question generation models based on sequence-to-sequence techniques have recently been proposed. Most of them generate questions from sentences only, and none of them is publicly available as an easy-to-use service. In this paper, we demonstrate ParaQG, a Web-based system for generating questions from sentences and paragraphs. ParaQG incorporates a number of novel functionalities to make the question generation process user-friendly. It provides an interactive interface for a user to select answers with visual insights on generation of questions. It also employs various faceted views to group similar questions as well as filtering techniques to eliminate unanswerable questions",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:bnK-pcrLprsC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"The problem of event extraction is a relatively difficult task for low resource languages due to the non-availability of sufficient annotated data. Moreover, the task becomes complex for tail (rarely occurring) labels wherein extremely less data is available. In this paper, we present a new dataset (InDEE-2019) in the disaster domain for multiple Indic languages, collected from news websites. Using this dataset, we evaluate several rule-based mechanisms to augment deep learning based models. We formulate our problem of event extraction as a sequence labeling task and perform extensive experiments to study and understand the effectiveness of different approaches. We further show that tail labels can be easily incorporated by creating new rules without the requirement of large annotated data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:wbdj-CoPYUoC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"In Web search, entity-seeking queries often trigger a special question answering (QA) system. It may use a parser to interpret the question to a structured query, execute that on a knowledge graph (KG), and return direct entity responses. QA systems based on precise parsing tend to be brittle: minor syntax variations may dramatically change the response. Moreover, KG coverage is patchy. At the other extreme, a large corpus may provide broader coverage, but in an unstructured, unreliable form. We present AQQUCN, a QA system that gracefully combines KG and corpus evidence. AQQUCN accepts a broad spectrum of query syntax, between well-formed questions to short “telegraphic” keyword sequences. In the face of inherent query ambiguities, AQQUCN aggregates signals from KGs and large corpora to directly rank KG entities, rather than commit to one semantic interpretation of the query. AQQUCN …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:eJXPG6dFmWUC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Automatic question generation (QG) is a challenging problem in natural language understanding. QG systems are typically built assuming access to a large number of training instances where each instance is a question and its corresponding answer. For a new language, such training instances are hard to obtain making the QG problem even more challenging. Using this as our motivation, we study the reuse of an available large QG dataset in a secondary language (e.g. English) to learn a QG model for a primary language (e.g. Hindi) of interest. For the primary language, we assume access to a large amount of monolingual text but only a small QG dataset. We propose a cross-lingual QG model which uses the following training regime: (i) Unsupervised pretraining of language models in both primary and secondary languages and (ii) joint supervised training for QG in both languages. We demonstrate the efficacy of our proposed approach using two different primary languages, Hindi and Chinese. We also create and release a new question answering dataset for Hindi consisting of 6555 sentences.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:1qzjygNMrQYC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"The problem of representation learning on graph can be difficult due to limited knowledge of training data and large presence of missing edges. Real-world social networks do not provide complete information about the network due to hidden information and privacy constraints. In such scenarios, typical representation learning methods are not able to capture network information effectively. In order to make them more useful, any available feature information can be used in addition to the network structure. In this paper, we aim to learn better representations by exploiting both content (or feature) information of nodes and structural information of the network. Our approach leverages generative adversarial networks to learn embedding for generator and discriminator in a minimax game. While the generator estimates the neighborhood of a node, the discriminator distinguishes between the presence or absence of a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:V3AGJWp-ZtQC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Supervised machine learning based state-of-the-art computer vision techniques are in general data hungry. Their data curation poses the challenges of expensive human labeling, inadequate computing resources and larger experiment turn around times. Training data subset selection and active learning techniques have been proposed as possible solutions to these challenges. A special class of subset selection functions naturally model notions of diversity, coverage and representation and can be used to eliminate redundancy thus lending themselves well for training data subset selection. They can also help improve the efficiency of active learning in further reducing human labeling efforts by selecting a subset of the examples obtained using the conventional uncertainty sampling based techniques. In this work, we empirically demonstrate the effectiveness of two diversity models, namely the Facility-Location …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:VOx2b1Wkg3QC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"This paper addresses automatic summarization of videos in a unified manner. In particular, we propose a framework for multi-faceted summarization for extractive, query base and entity summarization (summarization at the level of entities like objects, scenes, humans and faces in the video). We investigate several summarization models which capture notions of diversity, coverage, representation and importance, and argue the utility of these different models depending on the application. While most of the prior work on submodular summarization approaches has focused on combining several models and learning weighted mixtures, we focus on the explainability of different models and featurizations, and how they apply to different domains. We also provide implementation details on summarization systems and the different modalities involved. We hope that the study from this paper will give insights into …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:fQNAKQ3IYiAC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"In the light of exponentially increasing video content, video summarization has attracted a lot of attention recently due to its ability to optimize time and storage. Characteristics of a good summary of a video depend on the particular domain under question. We propose a novel framework for domain specific video summarization. Given a video of a particular domain, our system can produce a summary based on what is important for that domain in addition to possessing other desired characteristics like representation, coverage, diversity etc. as suitable to that domain. Past related work has focused either on using supervised approaches for ranking the snippets to produce summary or on using unsupervised approaches of generating the summary as a subset of snippets with the above characteristics. We look at the joint problem of learning domain specific importance of segments as well as the desired summary …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:5Ul4iDaHHb8C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Automated anomaly detection is a useful task that can aid investigations and detect crimes. To this end, we present a model that can be used as a tool for anomaly detection in surveillance videos. Following an unsupervised approach, we use an autoencoder model trained to minimize the reconstruction error between the input and the generated output. We also augment the training of the auto-encoder with supervision in the form of user ratings per frame; higher user ratings reflect normal behaviour that the model is expected to faithfully reconstruct. On the other hand, lower rated frames are suspected to be anomalous. We analyze the output of the autoencoder on a standard dataset as well as two of our datasets that we have made public. We study the behavior of reconstruction error with and without supervision as well as the temporal coherence of the reconstruction error. Additionally, we use Grad-CAM to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:D_sINldO8mEC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Embedding large graphs in a low-dimensional space has proven useful in various applications. However, there is a limited focus on real-world networks that are dynamic in nature and continuously evolving with time. In this paper, we propose a novel adversarial algorithm to learn representation of dynamic networks. We leverage generative adversarial networks and recurrent networks to capture temporal and structural information. We conduct extensive experiments on the task of graph reconstruction, link prediction and graph prediction. Experimental results demonstrate consistent, stable, and better results against state-of-the-art methods in many cases.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:_B80troHkn4C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2019,"Knowledge graphs have become ubiquitous data sources and their utility has been amplified by the research on ability to answer carefully crafted questions over knowledge graphs. We investigate the problem of question generation (QG) over knowledge graphs wherein, the level of difficulty of the question can be controlled. We present an end-to-end neural network-based method for automatic generation of complex multi-hop questions over knowledge graphs. Taking a subgraph and an answer as input, our transformer-based model generates a natural language question. Our model incorporates difficulty estimation based on named entity popularity, and makes use of this estimation to generate difficulty-controllable questions. We evaluate our model on two recent multi-hop QA datasets. Our evaluation shows that our model is able to generate high-quality, fluent and relevant questions. We have …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:XiVPGOgt02cC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2018,"In this paper, we present a state-of-the-art system for audio event detection. The labels on the training (and evaluation) data specify the set of events occurring in each audio clip, but neither the time spans nor the order in which they occur. Specifically, our task of weakly supervised learning is the “Detection and Classification of Acoustic Scenes and Events (DCASE) 2017” challenge [5]. We use the winning entry in this challenge given by Xu et al.[10] as our starting point and identify several important modifications that allow us to improve on their results significantly. Our techniques pertain to aggregation and consolidation over time and frequency signals over a (temporal) sequence before decoding the labels. In general, our work is also relevant to other tasks involving learning from weak labeling of sequential data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:4fKUyHm3Qg0C,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2018,"We present a system for resolving entities and disambiguating locations based on publicly available web data in the domain of ancient Hindu Temples. Scarce, unstructured information poses a challenge to Entity Resolution (ER) and snippet ranking. Additionally, because the same set of entities may be associated with multiple locations, Location Disambiguation (LD) is a problem. The mentions and descriptions of temples exist in the order of hundreds of thousands, with such data generated by various users in various forms such as text (Wikipedia pages), videos (YouTube videos), blogs, etc. We demonstrate an integrated approach using a combination of grammar rules for parsing and unsupervised (clustering) algorithms to resolve entity and locations with high confidence. A demo of our system is accessible at tinyurl. com/templedemos. Our system is open source and available on GitHub.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:K3LRdlH-MEoC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2018,"Supervised machine learning based state-of-the-art computer vision techniques are in general data hungry and pose the challenges of not having adequate computing resources and of high costs involved in human labeling efforts. Training data subset selection and active learning techniques have been proposed as possible solutions to these challenges respectively. A special class of subset selection functions naturally model notions of diversity, coverage and representation and they can be used to eliminate redundancy and thus lend themselves well for training data subset selection. They can also help improve the efficiency of active learning in further reducing human labeling efforts by selecting a subset of the examples obtained using the conventional uncertainty sampling based techniques. In this work we empirically demonstrate the effectiveness of two diversity models, namely the Facility-Location and Disparity-Min models for training-data subset selection and reducing labeling effort. We do this for a variety of computer vision tasks including Gender Recognition, Scene Recognition and Object Recognition. Our results show that subset selection done in the right way can add 2-3% in accuracy on existing baselines, particularly in the case of less training data. This allows the training of complex machine learning models (like Convolutional Neural Networks) with much less training data while incurring minimal performance loss.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:l7t_Zn2s7bgC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2018,"We describe MultiSynth, a framework for synthesizing domain-specific programs from a multimodal dataset of examples. Given a domain-specific language (DSL), a dataset is multimodal if there is no single program in the DSL that generalizes over all the examples. Further, even if the examples in the dataset were generalized in terms of a set of programs, the domains of these programs may not be disjoint, thereby leading to ambiguity in synthesis. MultiSynth is a framework that incorporates concepts of synthesizing programs with minimum generality, while addressing the need of accurate prediction. We show how these can be achieved through (i) transformation driven partitioning of the dataset,(ii) least general generalization, for a generalized specification of the input and the output, and (iii) learning to rank, for estimating feature weights in order to map an input to the most appropriate mode in case of ambiguity. We show the effectiveness of our framework in two domains: in the first case, we extend an existing approach for synthesizing programs for XML tree transformations to ambiguous multimodal datasets. In the second case, MultiSynth is used to preorder words for machine translation, by learning permutations of productions in the parse trees of the source side sentences. Our evaluations reflect the effectiveness of our approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:8AbLer7MMksC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2018,"Multi-label classification is crucial to several practical applications including document categorization, video tagging, targeted advertising etc. Training a multi-label classifier requires a large amount of labeled data which is often unavailable or scarce. Labeled data is then acquired by consulting multiple labelers---both human and machine. Inspired by ensemble methods, our premise is that labels inferred with high consensus among labelers, might be closer to the ground truth. We propose strategies based on interaction and active learning to obtain higher quality labels that potentially lead to greater consensus. We propose a novel formulation that aims to collectively optimize the cost of labeling, labeler reliability, label-label correlation and inter-labeler consensus. Evaluation on data labeled by multiple labelers (both human and machine) shows that our consensus output is closer to the ground truth when compared to the"" majority"" baseline. We present illustrative cases where it even improves over the existing ground truth. We also present active learning strategies to leverage our consensus model in interactive learning settings. Experiments on several real-world datasets (publicly available) demonstrate the efficacy of our approach in achieving promising classification results with fewer labeled data.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:tOudhMTPpwUC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2018,"In Web search, entity-seeking queries often trigger a special Question Answering (QA) system. It uses syntactic patterns to extract structure from the query, identify a semantic interpretation and then return direct entity responses from a knowledge graph (KG). Such QA systems tend to be brittle. Minor query variations may fail to trigger the QA system. Moreover, KG coverage is patchy at best. Rather than fall off the ""structure cliff"" in such cases, we propose a more robust approach that degrades gracefully on a ""structure ramp"". Our system, called AQQUCN, accepts a broad spectrum of queries, between well-formed questions to short ""telegraphic"" keyword sequences. In the face of inherent query ambiguities, AQQUCN aggregates signals from KGs and large corpora to directly rank KG entities, rather than commit to one semantic interpretation of the query. AQQUCN models the ideal interpretation as an unobservable or …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:Tiz5es2fbqcC,http://www.cse.iitb.ac.in/~ganesh
Ganesh Ramakrishnan,"['Machine Learning', 'Relational Learning', 'Information Extraction', 'Question Answering', 'Text Analytics']",17,1402,2018,"Neural network-based methods represent the state-of-the-art in question generation from text. Existing work focuses on generating only questions from text without concerning itself with answer generation. Moreover, our analysis shows that handling rare words and generating the most appropriate question given a candidate answer are still challenges facing existing approaches. We present a novel two-stage process to generate question-answer pairs from the text. For the first stage, we present alternatives for encoding the span of the pivotal answer in the sentence using Pointer Networks. In our second stage, we employ sequence to sequence models for question generation, enhanced with rich linguistic features. Finally, global attention and answer encoding are used for generating the question most relevant to the answer. We motivate and linguistically analyze the role of each component in our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=W1ZpREMAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=W1ZpREMAAAAJ:WbkHhVStYXYC,http://www.cse.iitb.ac.in/~ganesh
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2023,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:SkU8VjQp03IC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"The behavior of information cascades (such as retweets) has been modeled extensively. While point process-based generative models have long been in use for estimating cascade growths, deep learning has greatly enhanced the integration of diverse features and signals. We observe two significant temporal signals in cascade data that have not been reported or exploited to our knowledge. First, the popularity of the cascade root is known to influence cascade size strongly; but we find that the effect falls off rapidly with time. Second, we find a measurable positive correlation between the novelty of the root content (with respect to a streaming external corpus) and the relative size of the resulting cascade. Responding to these observations, we propose GammaCas, a new cascade growth model as a parametric function of time, which combines deep influence signals from content (e.g., tweet text), network features (e.g …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:NWFKKQzSIN4C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"Submodular functions and variants, through their ability to characterize diversity and coverage, have emerged as a key tool for data selection and summarization. Many recent approaches to learn submodular functions suffer from limited expressiveness. In this work, we propose FLEXSUBNET, a family of flexible neural models for both monotone and non-monotone submodular functions. To fit a latent submodular function from (set, value) observations, FLEXSUBNET applies a concave function on modular functions in a recursive manner. We do not draw the concave function from a restricted family, but rather learn from data using a highly expressive neural network that implements a differentiable quadrature procedure. Such an expressive neural model for concave functions may be of independent interest. Next, we extend this setup to provide a novel characterization of monotone \alpha-submodular functions, a recently introduced notion of approximate submodular functions. We then use this characterization to design a novel neural model for such functions. Finally, we consider learning submodular set functions under distant supervision in the form of (perimeter-set, high-value-subset) pairs. This yields a novel subset selection method based on an order-invariant, yet greedy sampler built around the above neural set functions. Our experiments on synthetic and real data show that FLEXSUBNET outperforms several baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:eK4aujBuqBIC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"The graph retrieval problem is to search in a large corpus of graphs for ones that are most similar to a query graph. A common consideration for scoring similarity is the maximum common subgraph (MCS) between the query and corpus graphs, usually counting the number of common edges (i.e., MCES). In some applications, it is also desirable that the common subgraph be connected, i.e., the maximum common connected subgraph (MCCS). Finding exact MCES and MCCS is intractable, but may be unnecessary if ranking corpus graphs by relevance is the goal. We design fast and trainable neural functions that approximate MCES and MCCS well. Late interaction methods compute dense representations for the query and corpus graph separately, and compare these representations using simple similarity functions at the last stage, leading to highly scalable systems. Early interaction methods combine information from both graphs right from the input stages, are usually considerably more accurate, but slower. We propose both late and early interaction neural MCES and MCCS formulations. They are both based on a continuous relaxation of a node alignment matrix between query and corpus nodes. For MCCS, we propose a novel differentiable network for estimating the size of the largest connected common subgraph. Extensive experiments with seven data sets show that our proposals are superior among late interaction models in terms of both accuracy and speed. Our early interaction models provide accuracy competitive with the state of the art, at substantially greater speeds.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:x9HjRiAMpasC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"Knowledge Graph Completion (KGC) predicts missing facts in an incomplete Knowledge Graph (KG). Multilingual KGs associate entities and relations with surface forms written in different languages. An entity or relation may be associated with distinct IDs in different KGs, necessitating entity alignment (EA) and relation alignment (RA). Many effective algorithms have been proposed for completion and alignment as separate tasks. Here we show that these tasks are synergistic and best solved together. Our multitask approach starts with a state-of-the-art KG embedding scheme, but adds a novel relation representation based on sets of embeddings of (subject, object) entity pairs. This representation leads to a new relation alignment loss term based on a maximal bipartite matching between two sets of embedding vectors. This loss is combined with traditional KGC loss and optionally, losses based on text embeddings of entity (and relation) names. In experiments over KGs in seven languages, we find that our system achieves large improvements in KGC compared to a strong completion model that combines known facts in all languages. It also outperforms strong EA and RA baselines, underscoring the value of joint alignment and completion.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:fXbrI0tPCuEC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"Detecting and labeling stance in social media text is strongly motivated by hate speech detection, poll prediction, engagement forecasting, and concerted propaganda detection. Today's best neural stance detectors need large volumes of training data, which is difficult to curate given the fast-changing landscape of social media text and issues on which users opine. Homophily properties over the social network provide strong signal of coarse-grained user-level stance. But semi-supervised approaches for tweet-level stance detection fail to properly leverage homophily. In light of this, We present SANDS, a new semi-supervised stance detector. SANDS starts from very few labeled tweets. It builds multiple deep feature views of tweets. It also uses a distant supervision signal from the social network to provide a surrogate loss signal to the component learners. We prepare two new tweet datasets comprising over 236,000 …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:OWslULmvb_UC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"Given a query graph and a database of corpus graphs, a graph retrieval system aims to deliver the most relevant corpus graphs. Graph retrieval based on subgraph matching has a wide variety of applications, eg, molecular fingerprint detection, circuit design, software analysis, and question answering. In such applications, a corpus graph is relevant to a query graph, if the query graph is (perfectly or approximately) a subgraph of the corpus graph. Existing neural graph retrieval models compare the node or graph embeddings of the query-corpus pairs, to compute the relevance scores between them. However, such models may not provide edge consistency between the query and corpus graphs. Moreover, they predominantly use symmetric relevance scores, which are not appropriate in the context of subgraph matching, since the underlying relevance score in subgraph search should be measured using the partial order induced by subgraph-supergraph relationship. Consequently, they show poor retrieval performance in the context of subgraph matching. In response, we propose ISONET, a novel interpretable neural edge alignment formulation, which is better able to learn the edge-consistent mapping necessary for subgraph matching. ISONET incorporates a new scoring mechanism which enforces an asymmetric relevance score, specifically tailored to subgraph matching. ISONET’s design enables it to directly identify the underlying subgraph in a corpus graph, which is relevant to the given query graph. Our experiments on diverse datasets show that ISONET outperforms recent graph retrieval formulations and systems. Additionally, ISONET …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:USX2HHcnDqcC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"Progress with supervised Open Information Extraction (OpenIE) has been primarily limited to English due to the scarcity of training data in other languages. In this paper, we explore techniques to automatically convert English text for training OpenIE systems in other languages. We introduce the Alignment-Augmented Constrained Translation (AACTrans) model to translate English sentences and their corresponding extractions consistently with each other—with no changes to vocabulary or semantic meaning which may result from independent translations. Using the data generated with AACTrans, we train a novel two-stage generative OpenIE model, which we call Gen2OIE, that outputs for each sentence: 1) relations in the first stage and 2) all extractions containing the relation in the second stage. Gen2OIE increases relation coverage using a training data transformation technique that is generalizable to multiple languages, in contrast to existing models that use an English-specific training loss. Evaluations on 5 languages—Spanish, Portuguese, Chinese, Hindi and Telugu—show that the Gen2OIE with AACTrans data outperforms prior systems by a margin of 6-25% in F1.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:q2HS4OCVtYIC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"Recent advances in transformers have enabled Table Question Answering (Table QA) systems to achieve high accuracy and SOTA results on open domain datasets like WikiTableQuestions and WikiSQL. Such transformers are frequently pre-trained on open-domain content such as Wikipedia, where they effectively encode questions and corresponding tables from Wikipedia as seen in Table QA dataset. However, web tables in Wikipedia are notably flat in their layout, with the first row as the sole column header. The layout lends to a relational view of tables where each row is a tuple. Whereas, tables in domain-specific business or scientific documents often have a much more complex layout, including hierarchical row and column headers, in addition to having specialized vocabulary terms from that domain. To address this problem, we introduce the domain-specific Table QA dataset AIT-QA (Airline Industry Table QA). The dataset consists of 515 questions authored by human annotators on 116 tables extracted from public U.S. SEC filings (publicly available at: https://www.sec.gov/edgar.shtml) of major airline companies for the fiscal years 2017-2019. We also provide annotations pertaining to the nature of questions, marking those that require hierarchical headers, domain-specific terminology, and paraphrased forms. Our zero-shot baseline evaluation of three transformer-based SOTA Table QA methods - TaPAS (end-to-end), TaBERT (semantic parsing-based), and RCI (row-column encoding-based) - clearly exposes the limitation of these methods in this practical setting, with the best accuracy at just 51.8\% (RCI). We also present pragmatic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:BO8BTsX0K1AC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"Scene graphs are powerful abstractions that capture relationships between objects in images by modeling objects as nodes and relationships as edges. Generation of realistic synthetic scene graphs has applications like scene synthesis and data augmentation for supervised learning. Existing graph generative models are predominantly targeted toward molecular graphs, leveraging the limited vocabulary of atoms and bonds and also the well-defined semantics of chemical compounds. In contrast, scene graphs have much larger object and relation vocabularies, and their semantics are latent. To address this challenge, we propose a variational autoencoder for scene graphs, which is optimized for the maximum mean discrepancy (MMD) between the ground truth scene graph distribution and distribution of the generated scene graphs. Our method views a scene graph as a collection of star graphs and encodes it into a latent representation of the underlying stars. The decoder generates scene graphs by learning to sample the component stars and edges between them. Our experiments show that our method is able to mimic the underlying scene graph generative process more accurately than several state-of-the-art baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:jYy9R3AkpWgC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2022,"Relation classification (sometimes called relation extraction) requires trustworthy datasets for fine-tuning large language models, as well as for evaluation. Data collection is challenging for Indian languages, because they are syntactically and morphologically diverse, as well as different from resource-rich languages like English. Despite recent interest in deep generative models for Indian languages, relation classification is still not well served by public datasets. In response, we present IndoRE, a dataset with 21K entity- and relation-tagged gold sentences in three Indian languages (Bengali, Hindi, and Telugu), plus English. We start with a multilingual BERT (mBERT)-based system that captures entity span positions and type information, and provides competitive performance on monolingual relation classification. Using this baseline system, we explore transfer mechanisms between languages and the scope to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:rQcm2j6_ZE8C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,"In recent years, inductive graph embedding models, viz., graph neural networks (GNNs) have become increasingly accurate at link prediction (LP) in online social networks. The performance of such networks depends strongly on the input node features, which vary across networks and applications. Selecting appropriate node features remains application-dependent and generally an open question. Moreover, owing to privacy and ethical issues, use of personalized node features is often restricted. In fact, many publicly available data from online social network do not contain any node features (e.g., demography). In this work, we provide a comprehensive experimental analysis which shows that harnessing a transductive technique (e.g., Node2Vec) for obtaining initial node representations, after which an inductive node embedding technique takes over, leads to substantial improvements in link prediction accuracy …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:Z98IfIjqAwMC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,"Multimodal IR, spanning text corpus, knowledge graph and images, called outside knowledge visual question answering (OKVQA), is of much recent interest. However, the popular data set has serious limitations. A surprisingly large fraction of queries do not assess the ability to integrate cross-modal information. Instead, some are independent of the image, some depend on speculation, some require OCR or are otherwise answerable from the image alone. To add to the above limitations, frequency-based guessing is very effective because of (unintended) widespread answer overlaps between the train and test folds. Overall, it is hard to determine when state-of-the-art systems exploit these weaknesses rather than really infer the answers, because they are opaque and their 'reasoning' process is uninterpretable. An equally important limitation is that the dataset is designed for the quantitative assessment only of the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:oFKsPyNwwpYC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,"Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by providing temporal scopes (start and end times) on each edge in the KG. While Question Answering over KG (KGQA) has received some attention from the research community, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored area. Lack of broad coverage datasets has been another factor limiting progress in this area. We address this challenge by presenting CRONQUESTIONS, the largest known Temporal KGQA dataset, clearly stratified into buckets of structural complexity. CRONQUESTIONS expands the only known previous dataset by a factor of 340x. We find that various state-of-the-art KGQA methods fall far short of the desired performance on this new dataset. In response, we also propose CRONKGQA, a transformer-based solution that exploits recent advances in Temporal KG embeddings, and achieves performance superior to all baselines, with an increase of 120% in accuracy over the next best performing method. Through extensive experiments, we give detailed insights into the workings of CRONKGQA, as well as situations where significant further improvements appear possible. In addition to the dataset, we have released our code as well.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:JjBZBFkNMTQC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,"Link prediction (LP) algorithms propose to each node a ranked list of nodes that are currently non-neighbors, as the most likely candidates for future linkage. Owing to increasing concerns about privacy, users (nodes) may prefer to keep some of their connections protected or private. Motivated by this observation, our goal is to design a differentially private LP algorithm, which trades off between privacy of the protected node-pairs and the link prediction accuracy. More specifically, we first propose a form of differential privacy on graphs, which models the privacy loss only of those node-pairs which are marked as protected. Next, we develop DPLP, a learning to rank algorithm, which applies a monotone transform to base scores from a non-private LP system, and then adds noise. DPLP is trained with a privacy induced ranking loss, which optimizes the ranking utility for a given maximum allowed level of privacy leakage of the protected node-pairs. Under a recently introduced latent node embedding model, we present a formal trade-off between privacy and LP utility. Extensive experiments with several real-life graphs and several LP heuristics show that DPLP can trade off between privacy and predictive performance more effectively than several alternatives.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:hbz17DqrwuEC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,"After observing a snapshot of a social network, a link prediction (LP) algorithm identifies node pairs between which new edges will likely materialize in future. Most LP algorithms estimate a score for currently non-neighboring node pairs, and rank them by this score. Recent LP systems compute this score by comparing dense, low dimensional vector representations of nodes. Graph neural networks (GNNs), in particular graph convolutional networks (GCNs), are popular examples. For two nodes to be meaningfully compared, their embeddings should be indifferent to reordering of their neighbors. GNNs typically use simple, symmetric set aggregators to ensure this property, but this design decision has been shown to produce representations with limited expressive power. Sequence encoders are more expressive, but are permutation sensitive by design. Recent efforts to overcome this dilemma turn out to be unsatisfactory for LP tasks. In response, we propose PermGNN, which aggregates neighbor features using a recurrent, order-sensitive aggregator and directly minimizes an LP loss while it isattacked'by adversarial generator of neighbor permutations. PermGNN has superior expressive power compared to earlier GNNs. Next, we devise an optimization framework to map PermGNN's node embeddings to a suitable locality-sensitive hash, which speeds up reporting the top-K most likely edges for the LP task. Our experiments on diverse datasets show that PermGNN outperforms several state-of-the-art link predictors by a significant margin, and can predict the most likely edges fast.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:Y20HiHuZk70C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:SFOYbPikdlgC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,"The Transformer and its variants have been proven to be efficient sequence learners in many different domains. Despite their staggering success, a critical issue has been the enormous number of parameters that must be trained (ranging from to ) along with the quadratic complexity of dot-product attention. In this work, we investigate the problem of approximating the two central components of the Transformer---multi-head self-attention and point-wise feed-forward transformation, with reduced parameter space and computational complexity. We build upon recent developments in analyzing deep neural networks as numerical solvers of ordinary differential equations. Taking advantage of an analogy between Transformer stages and the evolution of a dynamical system of multiple interacting particles, we formulate a temporal evolution scheme,\name, to bypass costly dot-product attention over multiple stacked layers. We perform exhaustive experiments with\name\on well-known encoder-decoder as well as encoder-only tasks. We observe that the degree of approximation (or inversely, the degree of parameter reduction) has different effects on the performance, depending on the task. While in the encoder-decoder regime,\name\delivers performances comparable to the original Transformer, in encoder-only tasks it consistently outperforms Transformer along with several subsequent variants.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:LHWLPdAD5FMC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,"Our goal is to evaluate the accuracy of a black-box classification model, not as a single aggregate on a given test data distribution, but as a surface over a large number of combinations of attributes characterizing multiple test data distributions. Such attributed accuracy measures become important as machine learning models get deployed as a service, where the training data distribution is hidden from clients, and different clients may be interested in diverse regions of the data distribution. We present Attributed Accuracy Assay (AAA)---a Gaussian Process (GP)-based probabilistic estimator for such an accuracy surface. Each attribute combination, called an'arm'is associated with a Beta density from which the service's accuracy is sampled. We expect the GP to smooth the parameters of the Beta density over related arms to mitigate sparsity. We show that obvious application of GPs cannot address the challenge of heteroscedastic uncertainty over a huge attribute space that is sparsely and unevenly populated. In response, we present two enhancements: pooling sparse observations, and regularizing the scale parameter of the Beta densities. After introducing these innovations, we establish the effectiveness of AAA both in terms of its estimation accuracy and exploration efficiency, through extensive experiments and analysis.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:04dtUmz_MT0C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,"Knowledge Graph Completion (KGC) predicts missing facts in an incomplete Knowledge Graph. Almost all of existing KGC research is applicable to only one KG at a time, and in one language only. However, different language speakers may maintain separate KGs in their language and no individual KG is expected to be complete. Moreover, common entities or relations in these KGs have different surface forms and IDs, leading to ID proliferation. Entity alignment (EA) and relation alignment (RA) tasks resolve this by recognizing pairs of entity (relation) IDs in different KGs that represent the same entity (relation). This can further help prediction of missing facts, since knowledge from one KG is likely to benefit completion of another. High confidence predictions may also add valuable information for the alignment tasks. In response, we study the novel task of jointly training multilingual KGC, relation alignment and entity alignment models. We present ALIGNKGC, which uses some seed alignments to jointly optimize all three of KGC, EA and RA losses. A key component of ALIGNKGC is an embedding based soft notion of asymmetric overlap defined on the (subject, object) set signatures of relations this aids in better predicting relations that are equivalent to or implied by other relations. Extensive experiments with DBPedia in five languages establish the benefits of joint training for all tasks, achieving 10-32 MRR improvements of ALIGNKGC over a strong state-of-the-art single-KGC system completion model over each monolingual KG . Further, ALIGNKGC achieves reasonable gains in EA and RA tasks over a vanilla completion model over a KG that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:HfY9tUF4VgMC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2021,"Social network research has focused on hyperlink graphs, bibliographic citations, friend/follow patterns, influence spread, etc. Large software repositories also form a highly valuable networked artifact, usually in the form of a collection of packages, their developers, dependencies among them, and bug reports. This “social network of code” is rarely studied by social network researchers. We introduce two new problems in this setting. These problems are well-motivated in the software engineering community but not closely studied by social network scientists. The first is to identify packages that are most likely to be troubled by bugs in the immediate future, thereby demanding the greatest attention. The second is to recommend developers to packages for the next development cycle. Simple autoregression can be applied to historical data for both problems, but we propose a novel method to integrate network …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:z2g7kDSNNyoC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"A recent state-of-the-art neural open information extraction (OpenIE) system generates extractions iteratively, requiring repeated encoding of partial outputs. This comes at a significant computational cost. On the other hand, sequence labeling approaches for OpenIE are much faster, but worse in extraction quality. In this paper, we bridge this trade-off by presenting an iterative labeling-based system that establishes a new state of the art for OpenIE, while extracting 10x faster. This is achieved through a novel Iterative Grid Labeling (IGL) architecture, which treats OpenIE as a 2-D grid labeling task. We improve its performance further by applying coverage (soft) constraints on the grid at training time. Moreover, on observing that the best OpenIE systems falter at handling coordination structures, our OpenIE system also incorporates a new coordination analyzer built with the same IGL architecture. This IGL based coordination analyzer helps our OpenIE system handle complicated coordination structures, while also establishing a new state of the art on the task of coordination analysis, with a 12.3 pts improvement in F1 over previous analyzers. Our OpenIE system, OpenIE6, beats the previous systems by as much as 4 pts in F1, while being much faster.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:i9B0nK2ie9AC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"State-of-the-art NLP inference uses enormous neural architectures and models trained for GPU-months, well beyond the reach of most consumers of NLP. This has led to one-size-fits-all public API-based NLP service models by major AI companies, serving large numbers of clients. Neither (hardware deficient) clients nor (heavily subscribed) servers can afford traditional fine tuning. Many clients own little or no labeled data. We initiate a study of adaptation of centralized NLP services to clients, and present one practical and lightweight approach. Each client uses an unsupervised, corpus-based sketch to register to the service. The server uses an auxiliary network to map the sketch to an abstract vector representation, which then informs the main labeling network. When a new client registers with its sketch, it gets immediate accuracy benefits. We demonstrate the success of the proposed architecture using sentiment labeling, NER, and predictive language modeling",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:rMiSbtrAJs8C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"Modeling user engagement dynamics on social media has compelling applications in market trend analysis, user-persona detection, and political discourse mining. Most existing approaches depend heavily on knowledge of the underlying user network. However, a large number of discussions happen on platforms that either lack any reliable social network (news portal, blogs, Buzzfeed) or reveal only partially the inter-user ties (Reddit, Stackoverflow). Many approaches require observing a discussion for some considerable period before they can make useful predictions. In real-time streaming scenarios, observations incur costs. Lastly, most models do not capture complex interactions between exogenous events (such as news articles published externally) and in-network effects (such as follow-up discussions on Reddit) to determine engagement levels. To address the three limitations noted above, we propose a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:ace9KxS0p5UC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"Graph retrieval from a large corpus of graphs has a wide variety of applications, e.g., sentence retrieval using words and dependency parse trees for question answering, image retrieval using scene graphs, and molecule discovery from a set of existing molecular graphs. In such graph search applications, nodes, edges and associated features bear distinctive physical significance. Therefore, a unified, trainable search model that efficiently returns corpus graphs that are highly relevant to a query graph has immense potential impact. In this paper, we present an effective, feature and structure-aware, end-to-end trainable neural match scoring system for graphs. We achieve this by constructing the product graph between the query and a candidate graph in the corpus, and then conduct a family of random walks on the product graph, which are then aggregated into the match score, using a network whose parameters …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:_bh1rdP-zDcC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"While traditional systems for Open Information Extraction were statistical and rule-based, recently neural models have been introduced for the task. Our work builds upon CopyAttention, a sequence generation OpenIE model (Cui et. al., 2018). Our analysis reveals that CopyAttention produces a constant number of extractions per sentence, and its extracted tuples often express redundant information. We present IMoJIE, an extension to CopyAttention, which produces the next extraction conditioned on all previously extracted tuples. This approach overcomes both shortcomings of CopyAttention, resulting in a variable number of diverse extractions per sentence. We train IMoJIE on training data bootstrapped from extractions of several non-neural systems, which have been automatically filtered to reduce redundancy and noise. IMoJIE outperforms CopyAttention by about 18 F1 pts, and a BERT-based strong baseline by 2 F1 pts, establishing a new state of the art for the task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:rr29yNp9FasC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"Temporal knowledge bases associate relational (s,r,o) triples with a set of times (or a single time instant) when the relation is valid. While time-agnostic KB completion (KBC) has witnessed significant research, temporal KB completion (TKBC) is in its early days. In this paper, we consider predicting missing entities (link prediction) and missing time intervals (time prediction) as joint TKBC tasks where entities, relations, and time are all embedded in a uniform, compatible space. We present TIMEPLEX, a novel time-aware KBC method, that also automatically exploits the recurrent nature of some relations and temporal interactions between pairs of relations. TIMEPLEX achieves state-of-the-art performance on both prediction tasks. We also find that existing TKBC models heavily overestimate link prediction performance due to imperfect evaluation mechanisms. In response, we propose improved TKBC evaluation protocols for both link and time prediction tasks, dealing with subtle issues that arise from the partial overlap of time intervals in gold instances and system predictions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:kGbpvR7Ecy8C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"Knowledge Base Completion (KBC) has been a very active area lately. Several recent KBCpapers propose architectural changes, new training methods, or even new formulations. KBC systems are usually evaluated on standard benchmark datasets: FB15k, FB15k-237, WN18, WN18RR, and Yago3-10. Most existing methods train with a small number of negative samples for each positive instance in these datasets to save computational costs. This paper discusses how recent developments allow us to use all available negative samples for training. We show that Complex, when trained using all available negative samples, gives near state-of-the-art performance on all the datasets. We call this approach COMPLEX-V2. We also highlight how various multiplicative KBC methods, recently proposed in the literature, benefit from this train-ing regime and become indistinguishable in terms of performance on most datasets. Our work calls for a reassessment of their individual value, in light of these findings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:RW1BPcyHXiwC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"We will review cross-community co-evolution of question answering (QA) with the advent of large-scale knowledge graphs (KGs), continuous representations of text and graphs, and deep sequence analysis. Early QA systems were information retrieval (IR) systems enhanced to extract named entity spans from high-scoring passages. Starting with WordNet, a series of structured curations of language and world knowledge, called KGs, enabled further improvements. Corpus is unstructured and messy to exploit for QA. If a question can be answered using the KG alone, it is attractive to ‘interpret’ the free-form question into a structured query, which is then executed on the structured KG. This process is called KGQA. Answers can be high-quality and explainable if the KG has an answer, but manual curation results in low coverage. KGs were soon found useful to harness corpus information. Named entity mention spans …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:BjLbhSWBl98C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"Extensive literature demonstrates how the copying of references (links) can lead to the emergence of various structural properties (e.g., power-law degree distribution and bipartite cores) in bibliographic and other similar directed networks. However, it is also well known that the copying process is incapable of mimicking the number of directed triangles in such networks; neither does it have the power to explain the obsolescence of older papers. In this paper, we propose RefOrCite, a new model that allows for copying of both the references from (i.e., out-neighbors of) as well as the citations to (i.e., in-neighbors of) an existing node. In contrast, the standard copying model (CP) only copies references. While retaining its spirit, RefOrCite differs from the Forest Fire (FF) model in ways that makes RefOrCite amenable to mean-field analysis for degree distribution, triangle count, and densification. Empirically, RefOrCite …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:G60ApcfeQaAC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"Fake news spread via social media is a major problem today. It is not easy with current-generation tools to check if a particular article is genuine or contains fake news. While there are many Web sites today that debunk viral fake news, checking if a particular article has been debunked or is true is not easy for an end-user. Search engines like Google do not make it easy to check a complete article since they limit the number of query keywords. In this paper, we outline the architecture of the Kauwa-Kaate system for fact-checking articles. Queried articles are searched against articles crawled from fact-checking sites, as well as against articles crawled from trusted news sites. Our system supports querying based on text as well as on images and video; the latter features are very important since many fake news articles are based on images and videos. We also describe the user interfaces which we will use to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:A5aiAONn640C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2020,"Many text mining tasks, such as clustering, classification, retrieval, and named entity linking, benefit from a measure of relatedness between entities in a knowledge graph. We present a thorough study of all entity relatedness measures in recent literature based on Wikipedia as the knowledge graph. To facilitate this study, we introduce a new dataset with human judgments of entity relatedness. No clear dominance is seen between measures based on textual similarity and graph proximity. Some of the better measures involve expensive global graph computations. We propose a new, space-efficient, computationally lightweight, two-stage framework for relatedness computation. In the first stage, a small weighted subgraph is dynamically grown around the two query entities; in the second stage, relatedness is derived based on computations on this subgraph. Our system shows better agreement with human judgment …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:KUazKHuGu6AC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"Social networks, forums, and social media have emerged as global platforms for forming and shaping opinions on a broad spectrum of topics like politics, sports, and entertainment. Users (also called actors) often update their evolving opinions, influenced through discussions with other users. Theoretical models and their analysis on understanding opinion dynamics in social networks abound in the literature. However, these models are often based on concepts from statistical physics. Their goal is to establish specific phenomena like steady state consensus or bifurcation. Analysis of transient effects is largely avoided. Moreover, many of these studies assume that actors’ opinions are observed globally and synchronously, which is rarely realistic. In this article, we initiate an investigation into a family of novel data-driven influence models that accurately learn and fit realistic observations. We estimate and do not …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:pXiCqeVOhFwC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"With the prolification of multimodal interaction in various domains, recently there has been much interest in text based image retrieval in the computer vision community. However most of the state of the art techniques model this problem in a purely neural way, which makes it difficult to incorporate pragmatic strategies in searching a large scale catalog especially when the search requirements are insufficient and the model needs to resort to an interactive retrieval process through multiple iterations of question-answering. Motivated by this, we propose a neural-symbolic approach for a one-shot retrieval of images from a large scale catalog, given the caption description. To facilitate this, we represent the catalog and caption as scene-graphs and model the retrieval task as a learnable graph matching problem, trained end-to-end with a REINFORCE algorithm. Further, we briefly describe an extension of this pipeline to an iterative retrieval framework, based on interactive questioning and answering.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:r5yabEp13iMC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"Neural Program Induction (NPI) is a paradigm for decomposing high-level tasks such as complex question-answering over knowledge bases (KBQA) into executable programs by employing neural models. Typically, this involves two key phases: i) inferring input program variables from the highlevel task description, and ii) generating the correct program sequence involving these variables. Here we focus on NPI for Complex KBQA with only the final answer as supervision, and not gold programs. This raises major challenges; namely i) noisy query annotation in the absence of any supervision can lead to catastrophic forgetting while learning, ii) reward becomes extremely sparse owing to the noise. To deal with these, we propose a noise-resilient NPI model, Stable Sparse Reward based Programmer (SSRP) that evades noise-induced instability through continual retrospection and its comparison with current learning behavior. On complex KBQA datasets, SSRP performs at par with hand-crafted rule-based models when provided with gold program input, and in the noisy settings outperforms state-of-the-art models by a significant margin even with a noisier query annotator.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:uHQrz-U2knEC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"Recent years have seen increasingly complex question-answering on knowledge bases (KBQA) involving logical, quantitative, and comparative reasoning over KB subgraphs. Neural Program Induction (NPI) is a pragmatic approach toward modularizing the reasoning process by translating a complex natural language query into a multi-step executable program. While NPI has been commonly trained with the ‘‘gold’’ program or its sketch, for realistic KBQA applications such gold programs are expensive to obtain. There, practically only natural language queries and the corresponding answers can be provided for training. The resulting combinatorial explosion in program space, along with extremely sparse rewards, makes NPI for KBQA ambitious and challenging. We present Complex Imperative Program Induction from Terminal Rewards (CIPITR), an advanced neural programmer that mitigates reward …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:4_yl7nwqy4oC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"In Web search, entity-seeking queries often trigger a special question answering (QA) system. It may use a parser to interpret the question to a structured query, execute that on a knowledge graph (KG), and return direct entity responses. QA systems based on precise parsing tend to be brittle: minor syntax variations may dramatically change the response. Moreover, KG coverage is patchy. At the other extreme, a large corpus may provide broader coverage, but in an unstructured, unreliable form. We present AQQUCN, a QA system that gracefully combines KG and corpus evidence. AQQUCN accepts a broad spectrum of query syntax, between well-formed questions to short “telegraphic” keyword sequences. In the face of inherent query ambiguities, AQQUCN aggregates signals from KGs and large corpora to directly rank KG entities, rather than commit to one semantic interpretation of the query. AQQUCN …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:IaRkJ05COeQC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"In several natural language tasks, labeled sequences are available in separate domains (say, languages), but the goal is to label sequences with mixed domain (such as code-switched text). Or, we may have available models for labeling whole passages (say, with sentiments), which we would like to exploit toward better position-specific label inference (say, target-dependent sentiment annotation). A key characteristic shared across such tasks is that different positions in a primary instance can benefit from different ‘experts’ trained from auxiliary data, but labeled primary instances are scarce, and labeling the best expert for each position entails unacceptable cognitive burden. We propose GIRNet, a unified position-sensitive multi-task recurrent neural network (RNN) architecture for such applications. Auxiliary and primary tasks need not share training instances. Auxiliary RNNs are trained over auxiliary instances. A primary instance is also submitted to each auxiliary RNN, but their state sequences are gated and merged into a novel composite state sequence tailored to the primary inference task. Our approach is in sharp contrast to recent multi-task networks like the crossstitch and sluice networks, which do not control state transfer at such fine granularity. We demonstrate the superiority of GIRNet using three applications: sentiment classification of code-switched passages, part-of-speech tagging of codeswitched text, and target position-sensitive annotation of sentiment in monolingual passages. In all cases, we establish new state-of-the-art performance beyond recent competitive baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:Nb0HLiwjfsIC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"Code-switching, the interleaving of two or more languages within a sentence or discourse is pervasive in multilingual societies. Accurate language models for code-switched text are critical for NLP tasks. State-of-the-art data-intensive neural language models are difficult to train well from scarce language-labeled code-switched text. A potential solution is to use deep generative models to synthesize large volumes of realistic code-switched text. Although generative adversarial networks and variational autoencoders can synthesize plausible monolingual text from continuous latent space, they cannot adequately address code-switched text, owing to their informal style and complex interplay between the constituent languages. We introduce VACS, a novel variational autoencoder architecture specifically tailored to code-switching phenomena. VACS encodes to and decodes from a two-level hierarchical representation, which models syntactic contextual signals in the lower level, and language switching signals in the upper layer. Sampling representations from the prior and decoding them produced well-formed, diverse code-switched sentences. Extensive experiments show that using synthetic code-switched text with natural monolingual data results in significant (33.06%) drop in perplexity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:ysWPWRY3VgcC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"Multilingual writers and speakers often alternate between two languages in a single discourse, a practice called ""code-switching"". Existing sentiment detection methods are usually trained on sentiment-labeled monolingual text. Manually labeled code-switched text, especially involving minority languages, is extremely rare. Consequently, the best monolingual methods perform relatively poorly on code-switched text. We present an effective technique for synthesizing labeled code-switched text from labeled monolingual text, which is more readily available. The idea is to replace carefully selected subtrees of constituency parses of sentences in the resource-rich language with suitable token spans selected from automatic translations to the resource-poor language. By augmenting scarce human-labeled code-switched text with plentiful synthetic code-switched text, we achieve significant improvements in sentiment labeling accuracy (1.5%, 5.11%, 7.20%) for three different language pairs (English-Hindi, English-Spanish and English-Bengali). We also get significant gains for hate speech detection: 4% improvement using only synthetic text and 6% if augmented with real text.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:BZGggv0hN9sC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"Given a small corpus pertaining to a limited set of focused topics, our goal is to train embeddings that accurately capture the sense of words in the topic in spite of the limited size of . These embeddings may be used in various tasks involving . A popular strategy in limited data settings is to adapt pre-trained embeddings trained on a large corpus. To correct for sense drift, fine-tuning, regularization, projection, and pivoting have been proposed recently. Among these, regularization informed by a word's corpus frequency performed well, but we improve upon it using a new regularizer based on the stability of its cooccurrence with other words. However, a thorough comparison across ten topics, spanning three tasks, with standardized settings of hyper-parameters, reveals that even the best embedding adaptation strategies provide small gains beyond well-tuned baselines, which many earlier comparisons ignored. In a bold departure from adapting pretrained embeddings, we propose using to probe, attend to, and borrow fragments from any large, topic-rich source corpus (such as Wikipedia), which need not be the corpus used to pretrain embeddings. This step is made scalable and practical by suitable indexing. We reach the surprising conclusion that even limited corpus augmentation is more useful than adapting embeddings, which suggests that non-dominant sense information may be irrevocably obliterated from pretrained embeddings and cannot be salvaged by adaptation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:F_tUKv7nyWgC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:Oi-j_DTgP3cC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"Detecting and aggregating sentiments toward people, organizations, and events expressed in unstructured social media have become critical text mining operations. Early systems detected sentiments over whole passages, whereas more recently, target-specific sentiments have been of greater interest. In this paper, we present MTTDSC, a multi-task target-dependent sentiment classification system that is informed by feature representation learnt for the related auxiliary task of passage-level sentiment classification. The auxiliary task uses a gated recurrent unit (GRU) and pools GRU states, followed by an auxiliary fully-connected layer that outputs passage-level predictions. In the main task, these GRUs contribute auxiliary per-token representations over and above word embeddings. The main task has its own, separate GRUs. The auxiliary and main GRUs send their states to a different fully connected layer, trained …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:lAj_JhtUatoC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2019,"A leaderboard is a tabular presentation of performance scores of the best competing techniques that address a specific scientific problem. Manually maintained leaderboards take time to emerge, which induces a latency in performance discovery and meaningful comparison. This can delay dissemination of best practices to non-experts and practitioners. Regarding papers as proxies for techniques, we present a new system to automatically discover and maintain leaderboards in the form of partial orders between papers, based on performance reported therein. In principle, a leaderboard depends on the task, data set, other experimental settings, and the choice of performance metrics. Often there are also tradeoffs between different metrics. Thus, leaderboard discovery is not just a matter of accurately extracting performance numbers and comparing them. In fact, the levels of noise and uncertainty around …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:J3KpcKIlIpsC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2018,"Beyond word embeddings, continuous representations of knowledge graph (KG) components, such as entities, types and relations, are widely used for entity mention disambiguation, relation inference and deep question answering. Great strides have been made in modeling general, asymmetric or antisymmetric KG relations using Gaussian, holographic, and complex embeddings. None of these directly enforce transitivity inherent in the is-instance-of and is-subtype-of relations. A recent proposal, called order embedding (OE), demands that the vector representing a subtype elementwise dominates the vector representing a supertype. However, the manner in which such constraints are asserted and evaluated have some limitations. In this short research note, we make three contributions specific to representing and inferring transitive relations. First, we propose and justify a significant improvement to the OE loss …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:dw5aoL0HVgwC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2018,"This paper analyzes the varied performance of Matrix Factorization (MF) on the related tasks of relation extraction and knowledge-base completion, which have been unified recently into a single framework of knowledge-base inference (KBI) [Toutanova et al., 2015]. We first propose a new evaluation protocol that makes comparisons between MF and Tensor Factorization (TF) models fair. We find that this results in a steep drop in MF performance. Our analysis attributes this to the high out-of-vocabulary (OOV) rate of entity pairs in test folds of commonly-used datasets. To alleviate this issue, we propose three extensions to MF. Our best model is a TF-augmented MF model. This hybrid model is robust and obtains strong results across various KBI datasets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:D4n_APcuzvwC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2018,"State-of-the-art knowledge base completion (KBC) models predict a score for every known or unknown fact via a latent factorization over entity and relation embeddings. We observe that when they fail, they often make entity predictions that are incompatible with the type required by the relation. In response, we enhance each base factorization with two type-compatibility terms between entity-relation pairs, and combine the signals in a novel manner. Without explicit supervision from a type catalog, our proposed modification obtains up to 7% MRR gains over base models, and new state-of-the-art results on several datasets. Further analysis reveals that our models better represent the latent types of entities and their embeddings also predict supervised types better than the embeddings fitted by baseline models.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:lYbyOjaXH8MC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2018,"Systems for structured knowledge extraction and inference have made giant strides in the last decade. Starting from shallow linguistic tagging and coarse-grained recognition of named entities at the resolution of people, places, organizations, and times, modern systems link billions of pages of unstructured text with knowledge graphs having hundreds of millions of entities belonging to tens of thousands of types, and related by tens of thousands of relations. Via deep learning, systems build continuous representations of words, entities, types, and relations, and use these to continually discover new facts to add to the knowledge graph, and support search systems that go far beyond page-level ""ten blue links''. We will present a comprehensive catalog of the best practices in traditional and deep knowledge extraction, inference and search. We will trace the development of diverse families of techniques, explore their …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:_WP0DvM6eX8C,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2018,"Systems, methods, and computer readable media related to determining whether a compound is a non-compositional noun compound (“NCC”). Some implementations are additionally or alternatively directed to using determined NCCs to adapt performance of one or more computer-based actions such as indexing or otherwise annotating electronic resources (eg, web pages or other Internet resources), processing search queries, identifying and/or ranking electronic resources in response to search queries, identifying and/or ranking search query suggestions for search queries, etc.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:5LOebrzo1TYC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2018,"A national identity scheme has long-term and large-scale implications to the welfare of the people, efficiency of governance and law enforcement, individuals’ fundamental right to privacy and national security. Motivated by several issues surfaced by the implementation of Aadhaar, and several privacy and security concerns that have been pointed out, we develop a (non-exhaustive) list of technical guidelines for national identity schemes. We observe that the current Aadhaar design significantly deviates from these guidelines, strongly suggesting that to address the root causes of the issues that have manifested so far, many parts of the system require major redesign. We also put forth several policy guidelines, which we believe are crucial to the success of a national identity scheme in India.
Digital technology is a powerful tool, and India, like any other modern nation, can ill afford to keep away from exploiting the promises it offers. Yet, one needs to wield this technology with caution, like a scalpel rather than a sledge hammer, especially when it is applied at a national scale and affects millions of the poorest and most vulnerable. One should also bear in mind that any cyber infrastructure that is being developed today will become targets for cyber warfare in the future.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:UO6ax3c-pNsC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2018,"We present CROSSGRAD, a method to use multi-domain training data to learn a classifier that generalizes to new domains. CROSSGRAD does not need an adaptation phase via labeled or unlabeled data, or domain features in the new domain. Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training. In contrast, CROSSGRAD is free to use domain signals for predicting labels, if it can prevent overfitting on training domains. We conceptualize the task in a Bayesian setting, in which a sampling step is implemented as data augmentation, based on domain-guided perturbations of input instances. CROSSGRAD parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other's objectives. This enables us to directly perturb inputs, without separating and re-mixing domain signals while making various distributional assumptions. Empirical evaluation on three different applications where this setting is natural establishes that (1) domain-guided perturbation provides consistently better generalization to unseen domains, compared to generic instance perturbation methods, and that (2) data augmentation is a more stable and accurate method than domain adversarial training.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:fhZv66dCuXAC,https://www.cse.iitb.ac.in/~soumen/
Soumen Chakrabarti,"['Web search', 'Web mining', 'social networks', 'machine learning']",33,3743,2018,"Named entity disambiguation (NED) is a central problem in information extraction. The goal is to link entities in a knowledge graph (KG) to their mention spans in unstructured text. Each distinct mention span (like John Smith, Jordan or Apache) represents a multi-class classification task. NED can therefore be modeled as a multitask problem with tens of millions of tasks for realistic KGs. We initiate an investigation into neural representations, network architectures, and training protocols for multitask NED. Specifically, we propose a task-sensitive representation learning framework that learns mention dependent representations, followed by a common classifier. Parameter learning in our framework can be decomposed into solving multiple smaller problems involving overlapping groups of tasks. We prove bounds for excess risk, which provide additional insight into the problem of multi-task representation learning. While remaining practical in terms of training memory and time requirements, our approach outperforms recent strong baselines, on four benchmark data sets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LfF2zfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=LfF2zfQAAAAJ:HOg0WoviCygC,https://www.cse.iitb.ac.in/~soumen/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2023,"DribbleBot (Dexterous Ball Manipulation with a Legged Robot) is a legged robotic system that can dribble a soccer ball under the same real-world conditions as humans (i.e., in-the-wild). We adopt the paradigm of training policies in simulation using reinforcement learning and transferring them into the real world. We overcome critical challenges of accounting for variable ball motion dynamics on different terrains and perceiving the ball using body-mounted cameras under the constraints of onboard computing. Our results provide evidence that current quadruped platforms are well-suited for studying dynamic whole-body control problems involving simultaneous locomotion and manipulation directly from sensory observations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:eJXPG6dFmWUC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2023,"Transformations based on domain expertise (expert transformations), such as random-resized-crop and color-jitter, have proven critical to the success of contrastive learning techniques such as SimCLR. Recently, several attempts have been made to replace such domain-specific, human-designed transformations with generated views that are learned. However for imagery data, so far none of these view-generation methods has been able to outperform expert transformations. In this work, we tackle a different question: instead of replacing expert transformations with generated views, can we constructively assimilate generated views with expert transformations? We answer this question in the affirmative and propose a view generation method and a simple, effective assimilation method that together improve the state-of-the-art by up to ~3.6% on three different datasets. Importantly, we conduct a detailed empirical study that systematically analyzes a range of view generation and assimilation methods and provides a holistic picture of the efficacy of learned views in contrastive representation learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:D_sINldO8mEC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2023,"We study the problem of object retrieval in scenarios where visual sensing is absent, object shapes are unknown beforehand and objects can move freely, like grabbing objects out of a drawer. Successful solutions require localizing free objects, identifying specific object instances, and then grasping the identified objects, only using touch feedback. Unlike vision, where cameras can observe the entire scene, touch sensors are local and only observe parts of the scene that are in contact with the manipulator. Moreover, information gathering via touch sensors necessitates applying forces on the touched surface which may disturb the scene itself. Reasoning with touch, therefore, requires careful exploration and integration of information over time -- a challenge we tackle. We present a system capable of using sparse tactile feedback from fingertip touch sensors on a dexterous hand to localize, identify and grasp novel objects without any visual feedback. Videos are available at https://taochenshh.github.io/projects/tactofind.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:fQNAKQ3IYiAC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2023,"Efficient simulation of tactile sensors can unlock new opportunities for learning tactile-based manipulation policies in simulation and then transferring the learned policy to real systems, but fast and reliable simulators for dense tactile normal and shear force fields are still under-explored. We present a novel approach for efficiently simulating both the normal and shear tactile force field covering the entire contact surface with an arbitrary tactile sensor spatial layout. Our simulator also provides analytical gradients of the tactile forces to accelerate policy learning. We conduct extensive simulation experiments to showcase our approach and demonstrate successful zero-shot sim-to-real transfer for a high-precision peg-insertion task with high-resolution vision-based GelSlim tactile sensors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:p2g8aNsByqUC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2023,"We present a framework for specifying tasks involving spatial relations between objects using only 5-10 demonstrations and then executing such tasks given point cloud observations of a novel pair of objects in arbitrary initial poses. Our approach structures these rearrangement tasks by assigning a consistent local coordinate frame to the task-relevant object parts, localizing the corresponding coordinate frame on unseen object instances, and executing an action that brings these frames into alignment. We propose an optimization method that uses multiple Neural Descriptor Fields (NDFs) and a single annotated 3D keypoint to assign a set of consistent coordinate frames to the task-relevant object parts. We also propose an energy-based learning scheme to model the joint configuration of the objects that satisfies a desired relational task. We validate our pipeline on three multi-object rearrangement tasks in simulation and on a real robot. Results show that our method can infer relative transformations that satisfy the desired relation between novel objects in unseen initial poses using just a few demonstrations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:OU6Ihb5iCvQC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2023,"Learned locomotion policies can rapidly adapt to diverse environments similar to those experienced during training but lack a mechanism for fast tuning when they fail in an out-of-distribution test environment. This necessitates a slow and iterative cycle of reward and environment redesign to achieve good performance on a new task. As an alternative, we propose learning a single policy that encodes a structured family of locomotion strategies that solve training tasks in different ways, resulting in Multiplicity of Behavior (MoB). Different strategies generalize differently and can be chosen in real-time for new tasks or environments, bypassing the need for time-consuming retraining. We release a fast, robust open-source MoB locomotion controller, Walk These Ways, that can execute diverse gaits with variable footswing, posture, and speed, unlocking diverse downstream tasks: crouching, hopping, high-speed running, stair traversal, bracing against shoves, rhythmic dance, and more. Video and code release: https://gmargo11. github. io/walk-these-ways",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:uWQEDVKXjbEC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2023,"This paper studies the prediction of a target from a pair of random variables , where the ground-truth predictor is additive . We study the performance of empirical risk minimization (ERM) over functions , and , fit on a given training distribution, but evaluated on a test distribution which exhibits covariate shift. We show that, when the class is ""simpler"" than (measured, e.g., in terms of its metric entropy), our predictor is more resilient to \emph{heterogenous covariate shifts} in which the shift in is much greater than that in . These results rely on a novel H\""older style inequality for the Dudley integral which may be of independent interest. Moreover, we corroborate our theoretical findings with experiments demonstrating improved resilience to shifts in ""simpler"" features across numerous domains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:5Ul4iDaHHb8C,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2023,"Contact planning is crucial in locomoting systems.Specifically, appropriate contact planning can enable versatile behaviors (e.g., sidewinding in limbless locomotors) and facilitate speed-dependent gait transitions (e.g., walk-trot-gallop in quadrupedal locomotors). The challenges of contact planning include determining not only the sequence by which contact is made and broken between the locomotor and the environments, but also the sequence of internal shape changes (e.g., body bending and limb shoulder joint oscillation). Most state-of-art contact planning algorithms focused on conventional robots (e.g.biped and quadruped) and conventional tasks (e.g. forward locomotion), and there is a lack of study on general contact planning in multi-legged robots. In this paper, we show that using geometric mechanics framework, we can obtain the global optimal contact sequence given the internal shape changes sequence. Therefore, we simplify the contact planning problem to a graph optimization problem to identify the internal shape changes. Taking advantages of the spatio-temporal symmetry in locomotion, we map the graph optimization problem to special cases of spin models, which allows us to obtain the global optima in polynomial time. We apply our approach to develop new forward and sidewinding behaviors in a hexapod and a 12-legged centipede. We verify our predictions using numerical and robophysical models, and obtain novel and effective locomotion behaviors.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:8AbLer7MMksC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2023,"To act in the world, robots rely on a representation of salient task aspects: for example, to carry a cup of coffee, a robot must consider movement efficiency and cup orientation in its behaviour. However, if we want robots to act for and with people, their representations must not be just functional but also reflective of what humans care about, i.e. their representations must be aligned with humans'. In this survey, we pose that current reward and imitation learning approaches suffer from representation misalignment, where the robot's learned representation does not capture the human's representation. We suggest that because humans will be the ultimate evaluator of robot performance in the world, it is critical that we explicitly focus our efforts on aligning learned task representations with humans, in addition to learning the downstream task. We advocate that current representation learning approaches in robotics should be studied from the perspective of how well they accomplish the objective of representation alignment. To do so, we mathematically define the problem, identify its key desiderata, and situate current robot learning methods within this formalism. We conclude the survey by suggesting future directions for exploring open challenges.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:geHnlv5EZngC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"Recent improvements in conditional generative modeling have made it possible to generate high-quality images from language descriptions alone. We investigate whether these methods can directly address the problem of sequential decision-making. We view decision-making not through the lens of reinforcement learning (RL), but rather through conditional generative modeling. To our surprise, we find that our formulation leads to policies that can outperform existing offline RL approaches across standard benchmarks. By modeling a policy as a return-conditional diffusion model, we illustrate how we may circumvent the need for dynamic programming and subsequently eliminate many of the complexities that come with traditional offline RL. We further demonstrate the advantages of modeling policies as conditional diffusion models by considering two other conditioning variables: constraints and skills. Conditioning on a single constraint or skill during training leads to behaviors at test-time that can satisfy several constraints together or demonstrate a composition of skills. Our results illustrate that conditional generative modeling is a powerful tool for decision-making.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:K3LRdlH-MEoC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"In-hand object reorientation is necessary for performing many dexterous manipulation tasks, such as tool use in unstructured environments that remain beyond the reach of current robots. Prior works built reorientation systems that assume one or many of the following specific circumstances: reorienting only specific objects with simple shapes, limited range of reorientation, slow or quasistatic manipulation, the need for specialized and costly sensor suites, simulation-only results, and other constraints which make the system infeasible for real-world deployment. We overcome these limitations and present a general object reorientation controller that is trained using reinforcement learning in simulation and evaluated in the real world. Our system uses readings from a single commodity depth camera to dynamically reorient complex objects by any amount in real time. The controller generalizes to novel objects not used during training. It is successful in the most challenging test: the ability to reorient objects in the air held by a downward-facing hand that must counteract gravity during reorientation. The results demonstrate that the policy transfer from simulation to the real world can be accomplished even for dynamic and contact-rich tasks. Lastly, our hardware only uses open-source components that cost less than five thousand dollars. Such construction makes it possible to replicate the work and democratize future research in dexterous manipulation. Videos are available at: https://taochenshh.github.io/projects/visual-dexterity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:738O_yMBCRsC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"State-of-the-art reinforcement learning (RL) algorithms typically use random sampling (e.g., -greedy) for exploration, but this method fails in hard exploration tasks like Montezuma's Revenge. To address the challenge of exploration, prior works incentivize the agent to visit novel states using an exploration bonus (also called an intrinsic reward or curiosity). Such methods can lead to excellent results on hard exploration tasks but can suffer from intrinsic reward bias and underperform when compared to an agent trained using only task rewards. This performance decrease occurs when an agent seeks out intrinsic rewards and performs unnecessary exploration even when sufficient task reward is available. This inconsistency in performance across tasks prevents the widespread use of intrinsic rewards with RL algorithms. We propose a principled constrained policy optimization procedure that automatically tunes the importance of the intrinsic reward: it suppresses the intrinsic reward when exploration is unnecessary and increases it when exploration is required. This results in superior exploration that does not require manual tuning to balance the intrinsic reward against the task reward. Consistent performance gains across sixty-one ATARI games validate our claim. The code is available at https://github.com/Improbable-AI/eipo.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:Tiz5es2fbqcC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"We present a strong baseline that surpasses the performance of previously published methods on the Habitat Challenge task of navigating to a target object in indoor environments. Our method is motivated from primary failure modes of prior state-of-the-art: poor exploration, inaccurate object identification, and agent getting trapped due to imprecise map construction. We make three contributions to mitigate these issues: (i) First, we show that existing map-based methods fail to effectively use semantic clues for exploration. We present a semantic-agnostic exploration strategy (called Stubborn) without any learning that surprisingly outperforms prior work. (ii) We propose a strategy for integrating temporal information to improve object identification. (iii) Lastly, due to inaccurate depth observation the agent often gets trapped in small regions. We develop a multi-scale collision map for obstacle identification that mitigates …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:NhqRSupF_l8C,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"Meta-reinforcement learning algorithms provide a data-driven way to acquire policies that quickly adapt to many tasks with varying rewards or dynamics functions. However, learned meta-policies are often effective only on the exact task distribution on which they were trained and struggle in the presence of distribution shift of test-time rewards or transition dynamics. In this work, we develop a framework for meta-RL algorithms that are able to behave appropriately under test-time distribution shifts in the space of tasks. Our framework centers on an adaptive approach to distributional robustness that trains a population of meta-policies to be robust to varying levels of distribution shift. When evaluated on a potentially shifted test-time distribution of tasks, this allows us to choose the meta-policy with the most appropriate level of robustness, and use it to perform fast adaptation. We formally show how our framework allows for improved regret under distribution shift, and empirically show its efficacy on simulated robotics problems under a wide range of distribution shifts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:dshw04ExmUIC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"Offline RL algorithms must account for the fact that the dataset they are provided may leave many facets of the environment unknown. The most common way to approach this challenge is to employ pessimistic or conservative methods, which avoid behaviors that are too dissimilar from those in the training dataset. However, relying exclusively on conservatism has drawbacks: performance is sensitive to the exact degree of conservatism, and conservative objectives can recover highly suboptimal policies. In this work, we propose that offline RL methods should instead be adaptive in the presence of uncertainty. We show that acting optimally in offline RL in a Bayesian sense involves solving an implicit POMDP. As a result, optimal policies for offline RL must be adaptive, depending not just on the current state but rather all the transitions seen so far during evaluation. We present a model-free algorithm for approximating this optimal adaptive policy, and demonstrate the efficacy of learning such adaptive policies in offline RL benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:SP6oXDckpogC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"In this work, we consider one-shot imitation learning for object rearrangement tasks, where an AI agent needs to watch a single expert demonstration and learn to perform the same task in different environments. To achieve a strong generalization, the AI agent must infer the spatial goal specification for the task. However, there can be multiple goal specifications that fit the given demonstration. To address this, we propose a reward learning approach, Graph-based Equivalence Mappings (GEM), that can discover spatial goal representations that are aligned with the intended goal specification, enabling successful generalization in unseen environments. Specifically, GEM represents a spatial goal specification by a reward function conditioned on i) a graph indicating important spatial relationships between objects and ii) state equivalence mappings for each edge in the graph indicating invariant properties of the corresponding relationship. GEM combines inverse reinforcement learning and active reward learning to efficiently improve the reward function by utilizing the graph structure and domain randomization enabled by the equivalence mappings. We conducted experiments with simulated oracles and with human subjects. The results show that GEM can drastically improve the generalizability of the learned goal representations over strong baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:xtRiw3GOFMkC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"Value approximation using deep neural networks is at the heart of off-policy deep reinforcement learning, and is often the primary module that provides learning signals to the rest of the algorithm. While multi-layer perceptron networks are universal function approximators, recent works in neural kernel regression suggest the presence of a spectral bias, where fitting high-frequency components of the value function requires exponentially more gradient update steps than the low-frequency ones. In this work, we re-examine off-policy reinforcement learning through the lens of kernel regression and propose to overcome such bias via a composite neural tangent kernel. With just a single line-change, our approach, the Fourier feature networks (FFN) produce state-of-the-art performance on challenging continuous control domains with only a fraction of the compute. Faster convergence and better off-policy stability also make it possible to remove the target network without suffering catastrophic divergences, which further reduces TD}(0)'s estimation bias on a few tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:bFI3QPDXJZMC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"We present a system for accurately predicting stable orientations for diverse rigid objects. We propose to overcome the critical issue of modelling multimodality in the space of rotations by using a conditional generative model to accurately classify contact surfaces. Our system is capable of operating from noisy and partially-observed pointcloud observations captured by real world depth cameras. Our method substantially outperforms the current state-of-the-art systems on a simulated stacking task requiring highly accurate rotations, and demonstrates strong sim2real zero-shot transfer results across a variety of unseen objects on a real world reorientation task.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:KxtntwgDAa4C,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"Traditional robotic manipulator design methods require extensive, time-consuming, and manual trial and error to produce a viable design. During this process, engineers often spend their time redesigning or reshaping components as they discover better topologies for the robotic manipula-tor. Tactile sensors, while useful, often complicate the design due to their bulky form factor. We propose an integrated design pipeline to streamline the design and manufacturing of robotic manipulators with knitted, glove-like tactile sensors. The proposed pipeline allows a designer to assemble a collection of modular, open-source components by applying predefined graph grammar rules. The end result is an intuitive design paradigm that allows the creation of new virtual designs of manipulators in a matter of minutes. Our framework allows the designer to fine-tune the manipulator's shape through cage-based geometry …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:CHSYGLWDkRkC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"We present Neural Descriptor Fields (NDFs), an object representation that encodes both points and relative poses between an object and a target (such as a robot gripper or a rack used for hanging) via category-level descriptors. We employ this representation for object manipulation, where given a task demonstration, we want to repeat the same task on a new object instance from the same category. We propose to achieve this objective by searching (via optimization) for the pose whose descriptor matches that observed in the demonstration. NDFs are conveniently trained in a self-supervised fashion via a 3D auto-encoding task that does not rely on expert-labeled keypoints. Further, NDFs are SE(3)-equivariant, guaranteeing performance that generalizes across all possible 3D object translations and rotations. We demonstrate learning of manipulation tasks from few (∼5-10) demonstrations both in simulation and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:pyW8ca7W8N0C,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"Agile maneuvers such as sprinting and high-speed turning in the wild are challenging for legged robots. We present an end-to-end learned controller that achieves record agility for the MIT Mini Cheetah, sustaining speeds up to 3.9 m/s. This system runs and turns fast on natural terrains like grass, ice, and gravel and responds robustly to disturbances. Our controller is a neural network trained in simulation via reinforcement learning and transferred to the real world. The two key components are (i) an adaptive curriculum on velocity commands and (ii) an online system identification strategy for sim-to-real transfer leveraged from prior work. Videos of the robot's behaviors are available at: https://agility.csail.mit.edu/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:nb7KW1ujOQ8C,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"In state-of-the-art self-supervised learning (SSL) pre-training produces semantically good representations by encouraging them to be invariant under meaningful transformations prescribed from human knowledge. In fact, the property of invariance is a trivial instance of a broader class called equivariance, which can be intuitively understood as the property that representations transform according to the way the inputs transform. Here, we show that rather than using only invariance, pre-training that encourages non-trivial equivariance to some transformations, while maintaining invariance to other transformations, can be used to improve the semantic quality of representations. Specifically, we extend popular SSL methods to a more general framework which we name Equivariant Self-Supervised Learning (E-SSL). In E-SSL, a simple additional pre-training objective encourages equivariance by predicting the transformations applied to the input. We demonstrate E-SSL’s effectiveness empirically on several popular computer vision benchmarks, e.g. improving SimCLR to 72.5% linear probe accuracy on ImageNet. Furthermore, we demonstrate usefulness of E-SSL for applications beyond computer vision; in particular, we show its utility on regression problems in photonics science. Our code, datasets and pre-trained models are available at https://github.com/rdangovs/essl to aid further research in E-SSL.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:abG-DnoFyZgC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"A system and method for detecting, recording and communicating events involved in the care and treatment of cognitively impaired persons through detection, video recording, storage and communication. The system includes video cameras that typically begin recording upon detecting motion, a local computing unit at the care location that detects alerts, and a cloud or other remote computing and transmission unit. The local computing unit aggregates, stores, processes, and transmits data including performing event detection through an artificial intelligence technique and generating appropriate alerts. The cloud computing aggregates data from many managed care communities, trains new convolutional neural networks from this data, distributes these networks to the local computing units to perform event detection, and provides a platform for various stakeholders to view the collected video data and generated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:1sJd4Hv_s6UC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"State-of-the-art deep Q-learning methods update Q-values using state transition tuples sampled from the experience replay buffer. This strategy often uniformly and randomly samples or prioritizes data sampling based on measures such as the temporal difference (TD) error. Such sampling strategies can be inefficient at learning Q-function because a state's Q-value depends on the Q-value of successor states. If the data sampling strategy ignores the precision of the Q-value estimate of the next state, it can lead to useless and often incorrect updates to the Q-values. To mitigate this issue, we organize the agent's experience into a graph that explicitly tracks the dependency between Q-values of states. Each edge in the graph represents a transition between two states by executing a single action. We perform value backups via a breadth-first search starting from that expands vertices in the graph starting from the set of terminal states and successively moving backward. We empirically show that our method is substantially more data-efficient than several baselines on a diverse range of goal-reaching tasks. Notably, the proposed method also outperforms baselines that consume more batches of training experience and operates from high-dimensional observational data such as images.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:_xSYboBqXhAC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"A system and method for detecting, recording and communicating events involved in the care and treatment of cognitively impaired persons through detection, video recording, storage and communication. The system includes video cameras that typically begin recording upon detecting motion, a local computing unit at the care location that detects alerts, and a cloud or other remote computing and transmission unit. The local computing unit aggregates, stores, processes, and transmits data including performing event detection through an artificial intelligence technique and generating appropriate alerts. The cloud computing aggregates data from many managed care communities, trains new convolutional neural networks from this data, distributes these networks to the local computing units to perform event detection, and provides a platform for various stakeholders to view the collected video data and generated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:TFP_iSt0sucC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,In-hand object reorientation has been a challenging problem in robotics due to high dimensional actuation space and the frequent change in contact state between the fingers and the objects. We present a simple model-free framework that can learn to reorient objects with both the hand facing upwards and downwards. We demonstrate the capability of reorienting over geometrically different objects in both cases. The learned policies show strong zero-shot transfer performance on new objects. We provide evidence that these policies are amenable to real-world operation by distilling them to use observations easily available in the real world. The videos of the learned policies are available at: https://taochenshh. github. io/projects/in-hand-reorientation.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:D03iK_w7-QYC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"Robots are commonly used for several industrial applications and some have made their mark even in households (eg, the roomba). Undoubtedly these systems are impressive! However, they are very narrow in their functionality and we are not even close to building a robot butler. A central challenge is the ability to work with sensory observations and generalization to novel situations. While we do not prescribe a solution to this problem, we do provide a perspective on a few dominant ideas in robot learning for multi-task learning and generalization. This perspective suggests a counter-intuitive conclusion: the primary challenge in building generalizable robotic systems (eg, a robot butler) is not in the learning algorithms or the hardware, but in how humans transfer their knowledge to robots.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:yD5IFk8b50cC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2022,"Humans have a strong intuitive understanding of the 3D environment around us. The mental model of the physics in our brain applies to objects of different materials and enables us to perform a wide range of manipulation tasks that are far beyond the reach of current robots. In this work, we desire to learn models for dynamic 3D scenes purely from 2D visual observations. Our model combines Neural Radiance Fields (NeRF) and time contrastive learning with an autoencoding framework, which learns viewpoint-invariant 3D-aware scene representations. We show that a dynamics model, constructed over the learned representation space, enables visuomotor control for challenging manipulation tasks involving both rigid bodies and fluids, where the target is specified in a viewpoint different from what the robot operates on. When coupled with an auto-decoding framework, it can even support goal specification from camera viewpoints that are outside the training distribution. We further demonstrate the richness of the learned 3D dynamics model by performing future prediction and novel view synthesis. Finally, we provide detailed ablation studies regarding different system designs and qualitative analysis of the learned representations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:pqnbT2bcN3wC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"Meteorological applications such as precipitation nowcasting, synthetic radar generation, statistical downscaling and others have benefited from deep learning (DL) approaches, however several challenges remain for widespread adaptation of these complex models in operational systems. One of these challenges is adequate generalizability; deep learning models trained from datasets collected in specific contexts should not be expected to perform as well when applied to different contexts required by large operational systems. One obvious mitigation for this is to collect massive amounts of training data that cover all expected meteorological contexts, however this is not only costly and difficult to manage, but is also not possible in many parts of the globe where certain sensing platforms are sparse. In this paper, we describe an application of transfer learning to perform domain transfer for deep learning models …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:f2IySw72cVMC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"Today's robotic quadruped systems can robustly walk over a diverse range of rough but continuous terrains, where the terrain elevation varies gradually. Locomotion on discontinuous terrains, such as those with gaps or obstacles, presents a complementary set of challenges. In discontinuous settings, it becomes necessary to plan ahead using visual inputs and to execute agile behaviors beyond robust walking, such as jumps. Such dynamic motion results in significant motion of onboard sensors, which introduces a new set of challenges for real-time visual processing. The requirement for agility and terrain awareness in this setting reinforces the need for robust control. We present Depth-based Impulse Control (DIC), a method for synthesizing highly agile visually-guided locomotion behaviors. DIC affords the flexibility of model-free learning but regularizes behavior through explicit model-based optimization of ground reaction forces. We evaluate the proposed method both in simulation and in the real world.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:dfsIfKJdRG4C,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"We present a framework for solving long-horizon planning problems involving manipulation of rigid objects that operates directly from a point-cloud observation. Our method plans in the space of object subgoals and frees the planner from reasoning about robot-object interaction dynamics. We show that for rigid-bodies, this abstraction can be realized using low-level manipulation skills that maintain sticking-contact with the object and represent subgoals as 3D transformations. To enable generalization to unseen objects and improve planning performance, we propose a novel way of representing subgoals for rigid-body manipulation and a graph-attention based neural network architecture for processing point-cloud inputs. We experimentally validate these choices using simulated and real-world experiments on the YuMi robot. Results demonstrate that our method can successfully manipulate new objects into target configurations requiring long-term planning. Overall, our framework realizes the best of the worlds of task-and-motion planning (TAMP) and learning-based approaches. Project website: https://anthonysimeonov. github. io/rpo-planning-framework/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:RGFaLdJalmkC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"Universal value functions are a core component of off-policy multi-goal reinforcement learning. The de-facto paradigm is to approximate Q(s, a, g) using monolithic neural networks which lack inductive biases to produce complex interactions between the state s and the goal g. In this work, we propose a bilinear decomposition that represents the Q-value via a low-rank approximation in the form of a dot product between two vector fields. The first vector field, f(s, a), captures the environment's local dynamics at the state s; whereas the second component, ϕ(s, g), captures the global relationship between the current state and the goal. We show that our bilinear decomposition scheme improves sample efficiency over the original monolithic value approximators, and transfer better to unseen goals. We demonstrate significant learning speed-up over a variety of tasks on a simulated robot arm, and the challenging task of dexterous manipulation with a Shadow hand.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:b0M2c_1WBrUC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"The current dominant paradigm for robotic manipulation involves two separate stages: manipulator design and control. Because the robot's morphology and how it can be controlled are intimately linked, joint optimization of design and control can significantly improve performance. Existing methods for co-optimization are limited and fail to explore a rich space of designs. The primary reason is the trade-off between the complexity of designs that is necessary for contact-rich tasks against the practical constraints of manufacturing, optimization, contact handling, etc. We overcome several of these challenges by building an end-to-end differentiable framework for contact-aware robot design. The two key components of this framework are: a novel deformation-based parameterization that allows for the design of articulated rigid robots with arbitrary, complex geometry, and a differentiable rigid body simulator that can handle contact-rich scenarios and computes analytical gradients for a full spectrum of kinematic and dynamic parameters. On multiple manipulation tasks, our framework outperforms existing methods that either only optimize for control or for design using alternate representations or co-optimize using gradient-free methods.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:HoB7MX3m0LUC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"Current model-based reinforcement learning methods struggle when operating from complex visual scenes due to their inability to prioritize task-relevant features. To mitigate this problem, we propose learning Task Informed Abstractions (TIA) that explicitly separates reward-correlated visual features from distractors. For learning TIA, we introduce the formalism of Task Informed MDP (TiMDP) that is realized by training two models that learn visual features via cooperative reconstruction, but one model is adversarially dissociated from the reward signal. Empirical evaluation shows that TIA leads to significant performance gains over state-of-the-art methods on many visual control tasks where natural and unconstrained visual distractions pose a formidable challenge. Project page: https://xiangfu. co/tia",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:70eg2SAEIzsC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"Background
Lying on the floor for a long period of time has been described as a critical determinant of prognosis following a fall. In addition to fall-related injuries due to the trauma itself, prolonged immobilization on the floor results in a wide range of comorbidities and may double the risk of death in elderly. Thus, reducing the length of Time On the Ground (TOG) in fallers seems crucial in vulnerable individuals with cognitive disorders who cannot get up independently.
Objective
This study aimed to examine the effect of a new technology called SafelyYou Guardian (SYG) on early post-fall care including reduction of Time Until staff Assistance (TUA) and TOG.
Methods
SYG uses continuous video monitoring, artificial intelligence, secure networks, and customized computer applications to detect and notify caregivers about falls in real time while providing immediate access to video footage of falls. The present observational study was conducted in 6 California memory care facilities where SYG was installed in bedrooms of consenting residents and families. Fall events were video recorded over 10 months. During the baseline installation period (November 2017 to December 2017), SYG video captures of falls were not provided on a regular basis to facility staff review. During a second period (January 2018 to April 2018), video captures were delivered to facility staff on a regular weekly basis. During the third period (May 2018 to August 2018), real-time notification (RTN) of any fall was provided to facility staff. Two digital markers (TUA, TOG) were automatically measured and compared between …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:M05iB0D1s5AC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"A majority of microrobots are constructed using compliant materials that are difficult to model analytically, limiting the utility of traditional model-based controllers. Challenges in data collection on microrobots and large errors between simulated models and real robots make current model-based learning and sim-to-real transfer methods difficult to apply. We propose a novel framework residual model learning (RML) that leverages approximate models to substantially reduce the sample complexity associated with learning an accurate robot model. We show that using RML, we can learn a model of the Harvard Ambulatory MicroRobot (HAMR) using just 12 seconds of passively collected interaction data. The learned model is accurate enough to be leveraged as ""proxy-simulator"" for learning walking and turning behaviors using model-free reinforcement learning algorithms. RML provides a general framework for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:vV6vV6tmYwMC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"Modern deep neural networks are highly over-parameterized compared to the data on which they are trained, yet they often generalize remarkably well. A flurry of recent work has asked: why do deep networks not overfit to their training data? In this work, we make a series of empirical observations that investigate and extend the hypothesis that deeper networks are inductively biased to find solutions with lower effective rank embeddings. We conjecture that this bias exists because the volume of functions that maps to low effective rank embedding increases with depth. We show empirically that our claim holds true on finite width linear and non-linear models on practical learning paradigms and show that on natural data, these are often the solutions that generalize well. We then show that the simplicity bias exists at both initialization and after training and is resilient to hyper-parameters and learning methods. We further demonstrate how linear over-parameterization of deep non-linear models can be used to induce low-rank bias, improving generalization performance on CIFAR and ImageNet without changing the modeling capacity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:lSLTfruPkqcC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2021,"State-of-the-art deep Q-learning methods update Q-values using state transition tuples sampled from the experience replay buffer. Often this strategy is to randomly sample or prioritize data sampling based on measures such as the temporal difference (TD) error. Such sampling strategies are agnostic to the structure of the Markov decision process (MDP) and can therefore be data inefficient at propagating reward signals from goal states to the initial state. To accelerate reward propagation, we make use of the MDP structure by organizing the agent’s experience into a graph. Each edge in the graph represents a transition between two connected states. We perform value backups via a breadth-first search that expands vertices in the graph starting from the set of terminal states successively moving backward. We empirically show that our method is substantially more data-efficient than several baselines on sparse reward tasks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:4OULZ7Gr8RgC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2020,"Reinforcement learning (RL) has achieved impressive performance in a variety of online settings in which an agent's ability to query the environment for transitions and rewards is effectively unlimited. However, in many practical applications, the situation is reversed: an agent may have access to large amounts of undirected offline experience data, while access to the online environment is severely limited. In this work, we focus on this offline setting. Our main insight is that, when presented with offline data composed of a variety of behaviors, an effective way to leverage this data is to extract a continuous space of recurring and temporally extended primitive behaviors before using these primitives for downstream task learning. Primitives extracted in this way serve two purposes: they delineate the behaviors that are supported by the data from those that are not, making them useful for avoiding distributional shift in offline RL; and they provide a degree of temporal abstraction, which reduces the effective horizon yielding better learning in theory, and improved offline RL in practice. In addition to benefiting offline policy optimization, we show that performing offline primitive learning in this way can also be leveraged for improving few-shot imitation learning as well as exploration and transfer in online RL on a variety of benchmark domains. Visualizations are available at https://sites.google.com/view/opal-iclr",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:ns9cj8rnVeAC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2020,"Learning robotic manipulation tasks using reinforcement learning with sparse rewards is currently impractical due to the outrageous data requirements. Many practical tasks require manipulation of multiple objects, and the complexity of such tasks increases with the number of objects. Learning from a curriculum of increasingly complex tasks appears to be a natural solution, but unfortunately, does not work for many scenarios. We hypothesize that the inability of the state- of-the-art algorithms to effectively utilize a task curriculum stems from the absence of inductive biases for transferring knowledge from simpler to complex tasks. We show that graph-based relational architectures overcome this limitation and enable learning of complex tasks when provided with a simple curriculum of tasks with increasing numbers of objects. We demonstrate the utility of our framework on a simulated block stacking task. Starting from …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:JV2RwH3_ST0C,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2020,"Research in developmental psychology consistently shows that children explore the world thoroughly and efficiently and that this exploration allows them to learn. In turn, this early learning supports more robust generalization and intelligent behavior later in life. While much work has gone into developing methods for exploration in machine learning, artificial agents have not yet reached the high standard set by their human counterparts. In this work we propose using DeepMind Lab (Beattie et al., 2016) as a platform to directly compare child and agent behaviors and to develop new exploration techniques. We outline two ongoing experiments to demonstrate the effectiveness of a direct comparison, and outline a number of open research questions that we believe can be tested using this methodology.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:2P1L_qKh6hAC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2019,"Background
Falls of individuals with dementia are frequent, dangerous and costly. Early detection and access to the history of a fall is crucial for efficient post-fall care. Real-time video detection and capture of falls thanks to artificial intelligence and secure transmission (SafelyYou technology; published in JMIR 2017, presented at AAIC 2018) offers high potential to support conventional care management in fallers. The objective of the study was to assess whether introduction of SafelyYou technology in memory care facilities would modify post-fall patterns of care provided to individuals with dementia.
Methods
An observational study (November 2017-August 2018) was carried out in six memory care facilities (California). Falls were video-captured (24/24, 7/7) thanks to wall-mounted cameras deployed in 66 out of 199 (33.2%) private bedrooms of consenting residents and families. Falls were video captured and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:isC4tDSrTZIC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2019,"METHODS
After institutional review board approval from the University of California, Berkeley, participants were enrolled in a pilot study to test the feasibility and acceptability of using SafelyYou Guardian in 6 residential care facilities from June 1 to August 31, 2018. Previous work had shown a reduction in falls at 1 care facility over a 3-month period through video incident review. 4 This specific pilot study was supported in part by a National Institutes of Health, National Institute of Aging Small Business Innovation Research Grant (1R43AG058354-01).
From a potential population of 193 residents in 6 communities, 55 participants enrolled in the study. However, fall data for both participants and nonparticipants were treated equally by the facilities. For participants, falls were detected and recorded by the AI-enabled camera system. Due to administrative and regulatory requirements, data about fall incidents and outcomes were routinely recorded for facility residents. Facility staff were able to review the falls in real time, immediately after each incident, for study participants. With the exception of video review for study participants, staff had to rely on routine protocol to manage each fall. The assigned shift manager would decide when to activate the EMT with support from the surrogate decision maker for the resident with dementia. Using",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:bEWYMUwI8FkC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2019,"We present a method for storing multiple models within a single set of parameters. Models can coexist in superposition and still be retrieved individually. In experiments with neural networks, we show that a surprisingly large number of models can be effectively stored within a single parameter instance. Furthermore, each of these models can undergo thousands of training steps without significantly interfering with other models within the superposition. This approach may be viewed as the online complement of compression: rather than reducing the size of a network after training, we make use of the unrealized capacity of a network during training.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:j3f4tGmQtD8C,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2019,"Children are naturally curious, and now even reinforcement learning models within machine learning are channeling this child-like curiosity. Pathak et-al (2017) created the ICM (Intrinsic Curiosity Model) in which curiosity serves as an intrinsic reward signal to enable the agent to explore its environment and learn skills, in this case a maze game called Doom. We study this inherent ability in children by having them explore mazes, with and without goals built using DeepMind software. In our pilot data we found that kids are adept at exploring the maze, readily and without prompt. We suggest a relationship between exploration and performance on a maze task, such that performance in the curiosity driven maze exploration task, is correlated with finding a goal in a second separate maze, even when the initial path to the goal is blocked. We also show side-by-side comparisons of the ICM vs. children exploring on our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:O3NaXMp0MMsC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2019,"Deep reinforcement learning (RL) algorithms have recently achieved impressive results on a range of video games, learning to play them at or beyond a human level just from raw pixel inputs. However, do they leverage visual information in the same manner as humans do? Our investigations suggest that they do not: given a static game, we find that a state-of-the-art deep RL algorithm solves that game faster without visual input (only the agent location was provided to the algorithm). We posit that this is because deep RL attacks each problem tabula rasa, ie without any prior knowledge, as also suggested by other recent work. We further propose that in certain settings, an agent is better off having no visual input compared to having no visual priors. To demonstrate this, we conduct an experiment with human participants and find that people solve a game that hid all visual input (except agent location) much faster …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:k_IJM867U9cC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2018,"Background:
Automated cardiac image interpretation has the potential to transform clinical practice in multiple ways, including enabling serial assessment of cardiac function by nonexperts in primary care and rural settings. We hypothesized that advances in computer vision could enable building a fully automated, scalable analysis pipeline for echocardiogram interpretation, including (1) view identification, (2) image segmentation, (3) quantification of structure and function, and (4) disease detection.
Methods:
Using 14 035 echocardiograms spanning a 10-year period, we trained and evaluated convolutional neural network models for multiple tasks, including automated identification of 23 viewpoints and segmentation of cardiac chambers across 5 common views. The segmentation output was used to quantify chamber volumes and left ventricular mass, determine ejection fraction, and facilitate automated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:e5wmG9Sq2KIC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2018,"What makes humans so good at solving seemingly complex video games? Unlike computers, humans bring in a great deal of prior knowledge about the world, enabling efficient decision making. This paper investigates the role of human priors for solving video games. Given a sample game, we conduct a series of ablation studies to quantify the importance of various priors on human performance. We do this by modifying the video game environment to systematically mask different types of visual information that could be used by humans as priors. We find that removal of some prior knowledge causes a drastic degradation in the speed with which human players solve the game, e.g. from 2 minutes to over 20 minutes. Furthermore, our results indicate that general priors, such as the importance of objects and visual consistency, are critical for efficient game-play. Videos and the game manipulations are available at https://rach0012.github.io/humanRL_website/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:hC7cP41nSMkC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2018,"Our fascination with human intelligence has historically influenced AI research to directly build autonomous agents that can solve intellectually challenging problems such as chess and GO. The same philosophy of direct optimization has percolated in the design of systems for image/speech recognition or language translation. But, the AI systems of today are brittle and very different from humans in the way they solve problems as evidenced by their severely limited ability to adapt or generalize. Evolution took a very long time to evolve the necessary sensorimotor skills of an ape (approx. 3.5 billion years) and relatively very short amount of time to develop apes into present-day humans (approx. 18 million years) that can reason and make use of language. There is probably a lesson to be learned here: by the time organisms with simple sensorimotor skills evolved, they possibly also developed the necessary …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:_Qo2XoVZTnwC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2018,We present an approach for building an active agent that learns to segment its visual observations into individual objects by interacting with its environment in a completely self-supervised manner. The agent uses its current segmentation model to infer pixels that constitute objects and refines the segmentation model by interacting with these pixels. The model learned from over 50K interactions generalizes to novel objects and backgrounds. Data collection by interaction is natural and a noisy source of information. We propose a robust set loss to deal with noisy training signal and provide a benchmark dataset comprising robot interactions with few human labeled examples for future research to build upon. We provide evidence that re-organization of visual observations into objects is a powerful representation for downstream vision-based control tasks. Our system is capable of rearranging multiple objects into target configurations from visual inputs alone. Full paper available at https://pathak22. github. io,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:TQgYirikUcIC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2018,"The current dominant paradigm for imitation learning relies on strong supervision of expert actions to learn both'what'and'how'to imitate. We pursue an alternative paradigm wherein an agent first explores the world without any expert supervision and then distills its experience into a goal-conditioned skill policy with a novel forward consistency loss. In our framework, the role of the expert is only to communicate the goals (ie, what to imitate) during inference. The learned policy is then employed to mimic the expert (ie, how to imitate) after seeing just a sequence of images demonstrating the desired task. Our method is' zero-shot'in the sense that the agent never has access to expert actions during training or for the task demonstration at inference. We evaluate our zero-shot imitator in two real-world settings: complex rope manipulation with a Baxter robot and navigation in previously unseen office environments with a TurtleBot. Through further experiments in VizDoom simulation, we provide evidence that better mechanisms for exploration lead to learning a more capable policy which in turn improves end task performance. Videos, models, and more details are available at https://pathak22. github. io/zeroshot-imitation/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:mB3voiENLucC,https://people.csail.mit.edu/pulkitag/
Pulkit Agrawal,"['Robotics', 'Computer Vision', 'Artificial Intelligence', 'Reinforcement Learning']",27,7096,2018,"Grasping objects with high dimensional controllers such as an anthropomorphic hand using reinforcement learning is a challenging problem. In this work we experiment with a 16-D simulated version of a prosthetic hand developed for SouthHampton Hand Assessment Procedure (SHAP). We demonstrate that it is possible to learn successful grasp policies for an anthropomorphic hand from scratch using deep reinforcement learning. We find that our grasping model is robust to sensor noise, variations in object shape, position of the object and physical parameters such as the density of the object. Under these variations, we also investigate the utility of touch sensing for grasping objects. We believe that our results and analysis provide useful insights and strong baselines for future research into the exciting direction of object manipulation with anthropomorphic hands using proprioceptive and other sensory feedback.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=UpZmJI0AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=UpZmJI0AAAAJ:qUcmZB5y_30C,https://people.csail.mit.edu/pulkitag/
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2023,"In goal-reaching reinforcement learning (RL), the optimal value function has a particular geometry, called quasimetric structure. This paper introduces Quasimetric Reinforcement Learning (QRL), a new RL method that utilizes quasimetric models to learn optimal value functions. Distinct from prior approaches, the QRL objective is specifically designed for quasimetrics, and provides strong theoretical recovery guarantees. Empirically, we conduct thorough analyses on a discretized MountainCar environment, identifying properties of QRL and its advantages over alternatives. On offline and online goal-reaching benchmarks, QRL also demonstrates improved sample efficiency and performance, across both state-based and image-based observations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:wvYxNZNCP7wC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2023,"Despite increasingly realistic image quality, recent 3D image generative models often operate on 3D volumes of fixed extent with limited camera motions. We investigate the task of unconditionally synthesizing unbounded nature scenes, enabling arbitrarily large camera motion while maintaining a persistent 3D world model. Our scene representation consists of an extendable, planar scene layout grid, which can be rendered from arbitrary camera poses via a 3D decoder and volume rendering, and a panoramic skydome. Based on this representation, we learn a generative world model solely from single-view internet photos. Our method enables simulating long flights through 3D landscapes, while maintaining global scene consistency--for instance, returning to the starting point yields the same view of the scene. Our approach enables scene extrapolation beyond the fixed bounds of current 3D generative models, while also supporting a persistent, camera-independent world representation that stands in contrast to auto-regressive 3D prediction models. Our project page: https://chail.github.io/persistent-nature/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:HJSXoJQnj-YC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2023,"Pre-trained deep image representations are useful for post-training tasks such as classification through transfer learning, image retrieval, and object detection. Data augmentations are a crucial aspect of pre-training robust representations in both supervised and self-supervised settings. Data augmentations explicitly or implicitly promote invariance in the embedding space to the input image transformations. This invariance reduces generalization to those downstream tasks which rely on sensitivity to these particular data augmentations. In this paper, we propose a method of learning representations that are instead equivariant to data augmentations. We achieve this equivariance through the use of steerable representations. Our representations can be manipulated directly in embedding space via learned linear maps. We demonstrate that our resulting steerable and equivariant representations lead to better performance on transfer learning and robustness: e.g. we improve linear probe top-1 accuracy by between 1% to 3% for transfer; and ImageNet-C accuracy by upto 3.4%. We further show that the steerability of our representations provides significant speedup (nearly 50x) for test-time augmentations; by applying a large number of augmentations for out-of-distribution detection, we significantly improve OOD AUC on the ImageNet-C dataset over an invariant representation.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:SnGPuo6Feq8C,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"Humans form mental images of 3D scenes to support counterfactual imagination, planning, and motor control. Our abilities to predict the appearance and affordance of the scene from previously unobserved viewpoints aid us in performing manipulation tasks (e.g., 6-DoF kitting) with a level of ease that is currently out of reach for existing robot learning frameworks. In this work, we aim to build artificial systems that can analogously plan actions on top of imagined images. To this end, we introduce Mental Imagery for Robotic Affordances (MIRA), an action reasoning framework that optimizes actions with novel-view synthesis and affordance prediction in the loop. Given a set of 2D RGB images, MIRA builds a consistent 3D scene representation, through which we synthesize novel orthographic views amenable to pixel-wise affordances prediction for action optimization. We illustrate how this optimization process enables us to generalize to unseen out-of-plane rotations for 6-DoF robotic manipulation tasks given a limited number of demonstrations, paving the way toward machines that autonomously learn to understand the world around them for planning actions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:kzcSZmkxUKAC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"Asymmetrical distance structures (quasimetrics) are ubiquitous in our lives and are gaining more attention in machine learning applications. Imposing such quasimetric structures in model representations has been shown to improve many tasks, including reinforcement learning (RL) and causal relation learning. In this work, we present four desirable properties in such quasimetric models, and show how prior works fail at them. We propose Interval Quasimetric Embedding (IQE), which is designed to satisfy all four criteria. On three quasimetric learning experiments, IQEs show strong approximation and generalization abilities, leading to better performance and improved efficiency over prior methods. Project Page: https://www.tongzhouwang.info/interval_quasimetric_embedding Quasimetric Learning Code Package: https://www.github.com/quasimetric-learning/torch-quasimetric",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:ziOE8S1-AIUC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"Learning image representations using synthetic data allows training neural networks without some of the concerns associated with real images, such as privacy and bias. Existing work focuses on a handful of curated generative processes which require expert knowledge to design, making it hard to scale up. To overcome this, we propose training with a large dataset of twenty-one thousand programs, each one generating a diverse set of synthetic images. These programs are short code snippets, which are easy to modify and fast to execute using OpenGL. The proposed dataset can be used for both supervised and unsupervised representation learning, and reduces the gap between pre-training with real and procedurally generated images by 38%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:mUJArPsKIAAC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"One of the grand challenges of reinforcement learning is the ability to generalize to new tasks. However, general agents require a set of rich, diverse tasks to train on. Designing a `foundation environment' for such tasks is tricky -- the ideal environment would support a range of emergent phenomena, an expressive task space, and fast runtime. To take a step towards addressing this research bottleneck, this work presents Powderworld, a lightweight yet expressive simulation environment running directly on the GPU. Within Powderworld, two motivating challenges distributions are presented, one for world-modelling and one for reinforcement learning. Each contains hand-designed test tasks to examine generalization. Experiments indicate that increasing the environment's complexity improves generalization for world models and certain reinforcement learning agents, yet may inhibit learning in high-variance environments. Powderworld aims to support the study of generalization by providing a source of diverse tasks arising from the same core rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:YsrPvlHIBpEC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"Humans integrate multiple sensory modalities (e.g., visual and audio) to build a causal understanding of the physical world. In this work, we propose a novel type of intrinsic motivation for Reinforcement Learning (RL) that encourages the agent to understand the causal effect of its actions through auditory event prediction. First, we allow the agent to collect a small amount of acoustic data and use K-means to discover underlying auditory event clusters. We then train a neural network to predict the auditory events and use the prediction errors as intrinsic rewards to guide RL exploration. We first conduct proof-of-concept experiments using a set of Atari games for an in-depth analysis of our module. We then apply our model to embodied audio-visual exploration using the Habitat simulator and active exploration with a rolling robot using the ThreeDWorld (TDW) simulator. Experimental results demonstrate the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:4X0JR2_MtJMC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"American leadership in AI. These broad strategy documents have influenced organizations such as the United States Department of the Air Force (DAF). The DAF-MIT AI Accelerator is an initiative between the DAF and MIT to bridge the gap between AI researchers and DAF mission requirements. Several projects supported by the DAF-MIT AI Accelerator are developing public challenge problems that address numerous Federal AI research priorities. These challenges target priorities by making large, AI-ready datasets publicly available, incentivizing open-source solutions, and creating a demand signal for dual use technologies that can stimulate further research. In this article, we describe these public challenges being developed and how their application contributes to scientific advances.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:1DsIQWDZLl8C,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"Meaningful uncertainty quantification in computer vision requires reasoning about semantic information—say, the hair color of the person in a photo or the location of a car on the street. To this end, recent breakthroughs in generative modeling allow us to represent semantic information in disentangled latent spaces, but providing uncertainties on the semantic latent variables has remained challenging. In this work, we provide principled uncertainty intervals that are guaranteed to contain the true semantic factors for any underlying generative model. The method does the following:(1) it uses quantile regression to output a heuristic uncertainty interval for each element in the latent space (2) calibrates these uncertainties such that they contain the true value of the latent for a new, unseen input. The endpoints of these calibrated intervals can then be propagated through the generator to produce interpretable uncertainty visualizations for each semantic factor. This technique reliably communicates semantically meaningful, principled, and instance-adaptive uncertainty in inverse problems like image super-resolution and image completion. Code and demos can be found on our project page.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:pAkWuXOU-OoC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"The ability to separate signal from noise, and reason with clean abstractions, is critical to intelligence. With this ability, humans can efficiently perform real world tasks without considering all possible nuisance factors.How can artificial agents do the same? What kind of information can agents safely discard as noises? In this work, we categorize information out in the wild into four types based on controllability and relation with reward, and formulate useful information as that which is both controllable and reward-relevant. This framework clarifies the kinds information removed by various prior work on representation learning in reinforcement learning (RL), and leads to our proposed approach of learning a Denoised MDP that explicitly factors out certain noise distractors. Extensive experiments on variants of DeepMind Control Suite and RoboDesk demonstrate superior performance of our denoised world model over using raw observations alone, and over prior works, across policy optimization control tasks as well as the non-control task of joint position regression.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:kWvqk_afx_IC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"The present disclosure provides an improved training methodology that enables supervised contrastive learning to be simultaneously performed across multiple positive and negative training examples. In particular, example aspects of the present disclosure are directed to an improved, supervised version of the batch contrastive loss, which has been shown to be very effective at learning powerful representations in the self-supervised setting. Thus, the proposed techniques adapt contrastive learning to the fully supervised setting and also enable learning to occur simultaneously across multiple positive examples.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:DBa1UEJaJKAC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"The Multimodal Learning for Earth and Environment Challenge (MultiEarth 2022) will be the first competition aimed at the monitoring and analysis of deforestation in the Amazon rainforest at any time and in any weather conditions. The goal of the Challenge is to provide a common benchmark for multimodal information processing and to bring together the earth and environmental science communities as well as multimodal representation learning communities to compare the relative merits of the various multimodal learning methods to deforestation estimation under well-defined and strictly comparable conditions. MultiEarth 2022 will have three sub-challenges: 1) matrix completion, 2) deforestation estimation, and 3) image-to-image translation. This paper presents the challenge guidelines, datasets, and evaluation metrics for the three sub-challenges. Our challenge website is available at https://sites.google.com/view/rainforest-challenge.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:PyEswDtIyv0C,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"Generative models operate at fixed resolution, even though natural images come in a variety of sizes. As high-resolution details are downsampled away and low-resolution images are discarded altogether, precious supervision is lost. We argue that every pixel matters and create datasets with variable-size images, collected at their native resolutions. To take advantage of varied-size data, we introduce continuous-scale training, a process that samples patches at random scales to train a new generator with variable output resolutions. First, conditioning the generator on a target scale allows us to generate higher resolution images than previously possible, without adding layers to the model. Second, by conditioning on continuous coordinates, we can sample patches that still obey a consistent global layout, which also allows for scalable training at higher resolutions. Controlled FFHQ experiments show that our …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:-jrNzM816MMC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"This paper presents an unpaired method for creating line drawings from photographs. Current methods often rely on high quality paired datasets to generate line drawings. However, these datasets often have limitations due to the subjects of the drawings belonging to a specific domain, or in the amount of data collected. Although recent work in unsupervised image-to-image translation has shown much progress, the latest methods still struggle to generate compelling line drawings. We observe that line drawings are encodings of scene information and seek to convey 3D shape and semantic meaning. We build these observations into a set of objectives and train an image translation to map photographs into line drawings. We introduce a geometry loss which predicts depth information from the image features of a line drawing, and a semantic loss which matches the CLIP features of a line drawing with its corresponding photograph. Our approach outperforms state-of-the-art unpaired image translation and line drawing generation methods on creating line drawings from arbitrary photographs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:OBSaB-F7qqsC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"Thin, reflective objects such as forks and whisks are common in our daily lives, but they are particularly chal-lenging for robot perception because it is hard to reconstruct them using commodity RGB-D cameras or multi-view stereo techniques. While traditional pipelines struggle with objects like these, Neural Radiance Fields (NeRFs) have recently been shown to be remarkably effective for performing view synthesis on objects with thin structures or reflective materials. In this paper we explore the use of NeRF as a new source of supervision for robust robot vision systems. In particular, we demonstrate that a NeRF representation of a scene can be used to train dense object descriptors. We use an optimized NeRF to extract dense correspondences between multiple views of an object, and then use these correspondences as training data for learning a view-invariant representation of the object. NeRF's usage of a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:Dem6FJhTUoYC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"We introduce an offline multi-agent reinforcement learning (offline MARL) framework that utilizes previously collected data without additional online data collection. Our method reformulates offline MARL as a sequence modeling problem and thus builds on top of the simplicity and scalability of the Transformer architecture. In the fashion of centralized training and decentralized execution, we propose to first train a teacher policy as if the MARL dataset is generated by a single agent. After the teacher policy has identified and recombined the"" good"" behavior in the dataset, we create separate student policies and distill not only the teacher policy's features but also its structural relations among different agents' features to student policies. Despite its simplicity, the proposed method outperforms state-of-the-art model-free offline MARL baselines while being more robust to demonstration's quality on several environments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:raTqNPD5sRQC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"We introduce a new approach to image forensics: placing physical refractive objects, which we call totems, into a scene so as to protect any photograph taken of that scene. Totems bend and redirect light rays, thus providing multiple, albeit distorted, views of the scene within a single image. A defender can use these distorted totem pixels to detect if an image has been manipulated. Our approach unscrambles the light rays passing through the totems by estimating their positions in the scene and using their known geometric and material properties. To verify a totem-protected image, we detect inconsistencies between the scene reconstructed from totem viewpoints and the scene’s appearance from the camera viewpoint. Such an approach makes the adversarial manipulation task more difficult, as the adversary must modify both the totem and image pixels in a geometrically consistent manner without knowing the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:F2UWTTQJPOcC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:HhcuHIWmDEUC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"Our world is full of asymmetries. Gravity and wind can make reaching a place easier than coming back. Social artifacts such as genealogy charts and citation graphs are inherently directed. In reinforcement learning and control, optimal goal-reaching strategies are rarely reversible (symmetrical). Distance functions supported on these asymmetrical structures are called quasimetrics. Despite their common appearance, little research has been done on the learning of quasimetrics. Our theoretical analysis reveals that a common class of learning algorithms, including unconstrained multilayer perceptrons (MLPs), provably fails to learn a quasimetric consistent with training data. In contrast, our proposed Poisson Quasimetric Embedding (PQE) is the first quasimetric learning formulation that both is learnable with gradient-based optimization and enjoys strong performance guarantees. Experiments on random graphs, social graphs, and offline Q-learning demonstrate its effectiveness over many common baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:HGTzPopzzJcC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2022,"Generative models are now capable of producing highly realistic images that look nearly indistinguishable from the data on which they are trained. This raises the question: if we have good enough generative models, do we still need datasets? We investigate this question in the setting of learning general-purpose visual representations from a black-box generative model rather than directly from data. Given an off-the-shelf image generator without any access to its training data, we train representations from the samples output by this generator. We compare several representation learning methods that can be applied to this setting, using the latent space of the generator to generate multiple ""views"" of the same semantic content. We show that for contrastive methods, this multiview data can naturally be used to identify positive pairs (nearby in latent space) and negative pairs (far apart in latent space). We find that the resulting representations rival or even outperform those learned directly from real data, but that good performance requires care in the sampling strategy applied and the training method. Generative models can be viewed as a compressed and organized copy of a dataset, and we envision a future where more and more ""model zoos"" proliferate while datasets become increasingly unwieldy, missing, or private. This paper suggests several techniques for dealing with visual representation learning in such a future. Code is available on our project page https://ali-design.github.io/GenRep/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:L1USKYWJimsC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"Communication requires having a common language, a lingua franca, between agents. This language could emerge via a consensus process, but it may require many generations of trial and error. Alternatively, the lingua franca can be given by the environment, where agents ground their language in representations of the observed world. We demonstrate a simple way to ground language in learned representations, which facilitates decentralized multi-agent communication and coordination. We find that a standard representation learning algorithm--autoencoding--is sufficient for arriving at a grounded common language. When agents broadcast these representations, they learn to understand and respond to each other's utterances and achieve surprisingly strong task performance across a variety of multi-agent communication environments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:rHJHxKgnXwkC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"In the natural world, life has found innumerable ways to survive and often thrive. Between and even within species, each individual is in some manner unique, and this diversity lends adaptability and robustness to life. In this work, we aim to learn a space of diverse and high-reward policies in a given environment. To this end, we introduce a generative model of policies for reinforcement learning, which maps a low-dimensional latent space to an agent policy space. Our method enables learning an entire population of agent policies, without requiring the use of separate policy parameters. Just as real world populations can adapt and evolve via natural selection, our method is able to adapt to changes in our environment solely by selecting for policies in latent space. We test our generative model’s capabilities in a variety of environments, including an open-ended grid-world and a two-player soccer environment. Code, visualizations, and additional experiments can be found at https://kennyderek. github. io/adap/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:3NQIlFlcGxIC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"Humans have mental models that allow them to plan, experiment, and reason in the physical world. How should an intelligent agent go about learning such models? In this paper, we will study if models of the world learned in an open-ended physics environment, without any specific tasks, can be reused for downstream physics reasoning tasks. To this end, we build a benchmark Open-ended Physics Environment (OPEn) and also design several tasks to test learning representations in this environment explicitly. This setting reflects the conditions in which real agents (i.e. rolling robots) find themselves, where they may be placed in a new kind of environment and must adapt without any teacher to tell them how this environment works. This setting is challenging because it requires solving an exploration problem in addition to a model building and representation learning problem. We test several existing RL-based …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:Ade32sEp0pkC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"Current vision systems are trained on huge datasets, and these datasets come with costs: curation is expensive, they inherit human biases, and there are concerns over privacy and usage rights. To counter these costs, interest has surged in learning from cheaper data sources, such as unlabeled images. In this paper we go a step further and ask if we can do away with real image datasets entirely, instead learning from noise processes. We investigate a suite of image generation models that produce images from simple random processes. These are then used as training data for a visual representation learner with a contrastive loss. We study two types of noise processes, statistical image models and deep generative models under different random initializations. Our findings show that it is important for the noise to capture certain structural properties of real data but that good performance can be achieved even with processes that are far from realistic. We also find that diversity is a key property to learn good representations. Datasets, models, and code are available at https://mbaradad.github.io/learning_with_noise.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:jU7OWUQzBzMC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"Neural MMO is a computationally accessible research platform that combines large agent populations, long time horizons, open-ended tasks, and modular game systems. Existing environments feature subsets of these properties, but Neural MMO is the first to combine them all. We present Neural MMO as free and open source software with active support, ongoing development, documentation, and additional training, logging, and visualization tools to help users adapt to this new setting. Initial baselines on the platform demonstrate that agents trained in large populations explore more and learn a progression of skills. We raise other more difficult problems such as many-team cooperation as open research questions which Neural MMO is well-suited to answer. Finally, we discuss current limitations of the platform, potential mitigations, and plans for continued development.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:CB2v5VPnA5kC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"Self-supervised visual representation learning has achieved remarkable success in recent years. By subverting the need for supervised labels, such approaches are able to utilize the numerous unlabeled images that exist on the Internet and in photographic datasets. Yet to build truly intelligent agents, we must construct representation learning algorithms that can learn not only from datasets but also learn in environments. An agent in a natural environment will not typically be fed curated data. Instead, it must explore its environment to acquire the data it will learn from. We propose a framework, curious representation learning (CRL), which jointly learns a reinforcement learning policy and a visual representation model. The policy is trained to maximize the error of the representation learner, and in doing so is incentivized to explore its environment. At the same time, the learned representation becomes stronger and stronger as the policy feeds it ever harder data to learn from. Our learned embodied representations enable promising transfer to downstream embodied semantic and language-guided navigation, performing better or comparable to ImageNet pretraining without using any supervision at all. In addition, despite being trained in simulation, our learned representations can obtain interpretable results on real images.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:PaBasH6fAo0C,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"Image classification models can depend on multiple different semantic attributes of the image. An explanation of the decision of the classifier needs to both discover and visualize these properties. Here we present StylEx, a method for doing this, by training a generative model to specifically explain multiple attributes that underlie classifier decisions. A natural source for such attributes is the StyleSpace of StyleGAN, which is known to generate semantically meaningful dimensions in the image. However, because standard GAN training is not dependent on the classifier, it may not represent those attributes which are important for the classifier decision, and the dimensions of StyleSpace may represent irrelevant attributes. To overcome this, we propose a training procedure for a StyleGAN, which incorporates the classifier model, in order to learn a classifier-specific StyleSpace. Explanatory attributes are then selected from this space. These can be used to visualize the effect of changing multiple attributes per image, thus providing image-specific explanations. We apply StylEx to multiple domains, including animals, leaves, faces and retinal images. For these, we show how an image can be modified in different ways to change its classifier output. Our results show that the method finds attributes that align well with semantic ones, generate meaningful image-specific explanations, and are human-interpretable as measured in user-studies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:7Hz3ACDFbsoC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"In recent years, Generative Adversarial Networks have become ubiquitous in both research and public perception, but how GANs convert an unstructured latent code to a high quality output is still an open question. In this work, we investigate regression into the latent space as a probe to understand the compositional properties of GANs. We find that combining the regressor and a pretrained generator provides a strong image prior, allowing us to create composite images from a collage of random image parts at inference time while maintaining global consistency. To compare compositional properties across different generators, we measure the trade-offs between reconstruction of the unrealistic input and image quality of the regenerated samples. We find that the regression approach enables more localized editing of individual image parts compared to direct editing in the latent space, and we conduct experiments to quantify this independence effect. Our method is agnostic to the semantics of edits, and does not require labels or predefined concepts during training. Beyond image composition, our method extends to a number of related applications, such as image inpainting or example-based image editing, which we demonstrate on several GANs and datasets, and because it uses only a single forward pass, it can operate in real-time. Code is available on our project page: https://chail.github.io/latent-composition/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:zCSUwVk65WsC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"Modern deep neural networks are highly over-parameterized compared to the data on which they are trained, yet they often generalize remarkably well. A flurry of recent work has asked: why do deep networks not overfit to their training data? In this work, we make a series of empirical observations that investigate and extend the hypothesis that deeper networks are inductively biased to find solutions with lower effective rank embeddings. We conjecture that this bias exists because the volume of functions that maps to low effective rank embedding increases with depth. We show empirically that our claim holds true on finite width linear and non-linear models on practical learning paradigms and show that on natural data, these are often the solutions that generalize well. We then show that the simplicity bias exists at both initialization and after training and is resilient to hyper-parameters and learning methods. We further demonstrate how linear over-parameterization of deep non-linear models can be used to induce low-rank bias, improving generalization performance on CIFAR and ImageNet without changing the modeling capacity.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:ubry08Y2EpUC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"Training supervised image synthesis models requires a critic to compare two images: the ground truth to the result. Yet, this basic functionality remains an open problem. A popular line of approaches uses the L1 (mean absolute error) loss, either in the pixel or the feature space of pretrained deep networks. However, we observe that these losses tend to produce overly blurry and grey images, and other techniques such as GANs need to be employed to fight these artifacts. In this work, we introduce an information theory based approach to measuring similarity between two images. We argue that a good reconstruction should have high mutual information with the ground truth. This view enables learning a lightweight critic to"" calibrate"" a feature space in a contrastive manner, such that reconstructions of corresponding spatial patches are brought together, while other patches are repulsed. We show that our formulation immediately boosts the perceptual realism of output images when used as a drop-in replacement for the L1 loss, with or without an additional GAN loss.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:6bLC7aUMtPcC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2021,"Recent generative models can synthesize"" views"" of artificial images that mimic real-world variations, such as changes in color or pose, simply by learning from unlabeled image collections. Here, we investigate whether such views can be applied to real images to benefit downstream analysis tasks such as image classification. Using a pretrained generator, we first find the latent code corresponding to a given real input image. Applying perturbations to the code creates natural variations of the image, which can then be ensembled together at test-time. We use StyleGAN2 as the source of generative augmentations and investigate this setup on classification tasks involving facial attributes, cat faces, and cars. Critically, we find that several design decisions are required towards making this process work; the perturbation procedure, weighting between the augmentations and original image, and training the classifier on synthesized images can all impact the result. Currently, we find that while test-time ensembling with GAN-based augmentations can offer some small improvements, the remaining bottlenecks are the efficiency and accuracy of the GAN reconstructions, coupled with classifier sensitivities to artifacts in GAN-generated images.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:MpfHP-DdYjUC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"We present iNeRF, a framework that performs mesh-free pose estimation by ""inverting"" a Neural Radiance Field (NeRF). NeRFs have been shown to be remarkably effective for the task of view synthesis — synthesizing photorealistic novel views of real-world scenes or objects. In this work, we investigate whether we can apply analysis-by-synthesis via NeRF for mesh-free, RGB-only 6DoF pose estimation – given an image, find the translation and rotation of a camera relative to a 3D object or scene. Our method assumes that no object mesh models are available during either training or test time. Starting from an initial pose estimate, we use gradient descent to minimize the residual between pixels rendered from a NeRF and pixels in an observed image. In our experiments, we first study 1) how to sample rays during pose refinement for iNeRF to collect informative gradients and 2) how different batch sizes of rays …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:CaZNVDsoPx4C,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"The quality of image generation and manipulation is reaching impressive levels, making it increasingly difficult for a human to distinguish between what is real and what is fake. However, deep networks can still pick up on the subtle artifacts in these doctored images. We seek to understand what properties of fake images make them detectable and identify what generalizes across different model architectures, datasets, and variations in training. We use a patch-based classifier with limited receptive fields to visualize which regions of fake images are more easily detectable. We further show a technique to exaggerate these detectable properties and demonstrate that, even when the image generator is adversarially finetuned against a fake image classifier, it is still imperfect and leaves detectable artifacts in certain image patches. Code is available at https://github.com/chail/patch-forensics …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:0CzhzZyukY4C,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"Contrastive learning between multiple views of the data has recently achieved state of the art performance in the field of self-supervised representation learning. Despite its success, the influence of different view choices has been less studied. In this paper, we use theoretical and empirical analysis to better understand the importance of view selection, and argue that we should reduce the mutual information (MI) between views while keeping task-relevant information intact. To verify this hypothesis, we devise unsupervised and semi-supervised frameworks that learn effective views by aiming to reduce their MI. We also consider data augmentation as a way to reduce MI, and show that increasing data augmentation indeed leads to decreasing MI and improves downstream classification accuracy. As a by-product, we achieve a new state-of-the-art accuracy on unsupervised pre-training for ImageNet classification (73% top-1 linear readout with a ResNet-50).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:artPoR2Yc-kC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"Contrastive learning applied to self-supervised representation learning has seen a resurgence in recent years, leading to state of the art performance in the unsupervised training of deep image models. Modern batch contrastive approaches subsume or significantly outperform traditional contrastive losses such as triplet, max-margin and the N-pairs loss. In this work, we extend the self-supervised batch contrastive approach to the fully-supervised setting, allowing us to effectively leverage label information. Clusters of points belonging to the same class are pulled together in embedding space, while simultaneously pushing apart clusters of samples from different classes. We analyze two possible versions of the supervised contrastive (SupCon) loss, identifying the best-performing formulation of the loss. On ResNet-200, we achieve top-1 accuracy of 81.4% on the ImageNet dataset, which is 0.8% above the best number reported for this architecture. We show consistent outperformance over cross-entropy on other datasets and two ResNet variants. The loss shows benefits for robustness to natural corruptions, and is more stable to hyperparameter settings such as optimizers and data augmentations. In reduced data settings, it outperforms cross-entropy significantly. Our loss function is simple to implement and reference TensorFlow code is released at https://t. ly/supcon.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:5icHVeHT4IsC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"Progress in multiagent intelligence research is fundamentally limited by the number and quality of environments available for study. In recent years, simulated games have become a dominant research platform within reinforcement learning, in part due to their accessibility and interpretability. Previous works have targeted and demonstrated success on arcade, first person shooter (FPS), real-time strategy (RTS), and massive online battle arena (MOBA) games. Our work considers massively multiplayer online role-playing games (MMORPGs or MMOs), which capture several complexities of real-world learning that are not well modeled by any other game genre. We present Neural MMO, a massively multiagent game environment inspired by MMOs and discuss our progress on two more general challenges in multiagent systems engineering for AI research: distributed infrastructure and game IO. We further demonstrate that standard policy gradient methods and simple baseline models can learn interesting emergent exploration and specialization behaviors in this setting.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:yMeIxYmEMEAC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"Contrastive representation learning has been outstandingly successful in practice. In this work, we identify two key properties related to the contrastive loss:(1) alignment (closeness) of features from positive pairs, and (2) uniformity of the induced distribution of the (normalized) features on the hypersphere. We prove that, asymptotically, the contrastive loss optimizes these properties, and analyze their positive effects on downstream tasks. Empirically, we introduce an optimizable metric to quantify each property. Extensive experiments on standard vision and language datasets confirm the strong agreement between both metrics and downstream task performance. Directly optimizing for these two metrics leads to representations with comparable or better performance at downstream tasks than contrastive learning.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:tH6gc1N1XXoC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"Does having visual priors (e.g. the ability to detect objects) facilitate learning to perform vision-based manipulation (e.g. picking up objects)? We study this problem under the framework of transfer learning, where the model is first trained on a passive vision task (i.e., the data distribution does not depend on the agent’s decisions), then adapted to perform an active manipulation task (i.e., the data distribution does depend on the agent’s decisions). We find that pre-training on vision tasks significantly improves generalization and sample efficiency for learning to manipulate objects. However, realizing these gains requires careful selection of which parts of the model to transfer. Our key insight is that outputs of standard vision models highly correlate with affordance maps commonly used in manipulation. Therefore, we explore directly transferring model parameters from vision networks to affordance prediction networks …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:gVv57TyPmFsC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"The focus of recent meta-learning research has been on the development of learning algorithms that can quickly adapt to test time tasks with limited data and low computational cost. Few-shot learning is widely used as one of the standard benchmarks in meta-learning. In this work, we show that a simple baseline: learning a supervised or self-supervised representation on the meta-training set, followed by training a linear classifier on top of this representation, outperforms state-of-the-art few-shot learning methods. An additional boost can be achieved through the use of self-distillation. This demonstrates that using a good learned embedding model can be more effective than sophisticated meta-learning algorithms. We believe that our findings motivate a rethinking of few-shot image classification benchmarks and the associated role of meta-learning algorithms. Code: http://github.com/WangYueFt …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:nVrZBo8bIpAC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"Often we wish to transfer representational knowledge from one neural network to another. Examples include distilling a large network into a smaller one, transferring knowledge from one sensory modality to a second, or ensembling a collection of models into a single estimator. Knowledge distillation, the standard approach to these problems, minimizes the KL divergence between the probabilistic outputs of a teacher and student network. We demonstrate that this objective ignores important structural knowledge of the teacher network. This motivates an alternative objective by which we train a student to capture significantly more information in the teacher's representation of the data. We formulate this objective as contrastive learning. Experiments demonstrate that our resulting new objective outperforms knowledge distillation and other cutting-edge distillers on a variety of knowledge transfer tasks, including single model compression, ensemble distillation, and cross-modal transfer. Our method sets a new state-of-the-art in many transfer tasks, and sometimes even outperforms the teacher network when combined with knowledge distillation. Code: http://github.com/HobbitLong/RepDistiller.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:OcBU2YAGkTUC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"An open secret in contemporary machine learning is that many models work beautifully on standard benchmarks but fail to generalize outside the lab. This has been attributed to biased training data, which provide poor coverage over real world events. Generative models are no exception, but recent advances in generative adversarial networks (GANs) suggest otherwise - these models can now synthesize strikingly realistic and diverse images. Is generative modeling of photos a solved problem? We show that although current GANs can fit standard datasets very well, they still fall short of being comprehensive models of the visual manifold. In particular, we study their ability to fit simple transformations such as camera movements and color changes. We find that the models reflect the biases of the datasets on which they are trained (e.g., centered objects), but that they also exhibit some capacity for generalization: by ""steering"" in latent space, we can shift the distribution while still creating realistic images. We hypothesize that the degree of distributional shift is related to the breadth of the training data distribution. Thus, we conduct experiments to quantify the limits of GAN transformations and introduce techniques to mitigate the problem. Code is released on our project page: https://ali-design.github.io/gan_steerability/",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:yFnVuubrUp4C,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2020,"Humans view the world through many sensory channels, e.g., the long-wavelength light channel, viewed by the left eye, or the high-frequency vibrations channel, heard by the right ear. Each view is noisy and incomplete, but important factors, such as physics, geometry, and semantics, tend to be shared between all views (e.g., a “dog” can be seen, heard, and felt). We investigate the classic hypothesis that a powerful representation is one that models view-invariant factors. We study this hypothesis under the framework of multiview contrastive learning, where we learn a representation that aims to maximize mutual information between different views of the same scene but is otherwise compact. Our approach scales to any number of views, and is view-agnostic. We analyze key properties of the approach that make it work, finding that the contrastive loss outperforms a popular alternative based on cross-view …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:4vMrXwiscB8C,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2019,"The emergence of complex life on Earth is often attributed to the arms race that ensued from a huge number of organisms all competing for finite resources. We present an artificial intelligence research environment, inspired by the human game genre of MMORPGs (Massively Multiplayer Online Role-Playing Games, a.k.a. MMOs), that aims to simulate this setting in microcosm. As with MMORPGs and the real world alike, our environment is persistent and supports a large and variable number of agents. Our environment is well suited to the study of large-scale multiagent interaction: it requires that agents learn robust combat and navigation policies in the presence of large populations attempting to do the same. Baseline experiments reveal that population size magnifies and incentivizes the development of skillful behaviors and results in agents that outcompete agents trained in smaller populations. We further show that the policies of agents with unshared weights naturally diverge to fill different niches in order to avoid competition.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:HIFyuExEbWQC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2019,"Visual foresight gives an agent a window into the future, which it can use to anticipate events before they happen and plan strategic behavior. Although impressive results have been achieved on video prediction in constrained settings, these models fail to generalize when confronted with unfamiliar real-world objects. In this paper, we tackle the generalization problem via fast adaptation, where we train a prediction model to quickly adapt to the observed visual dynamics of a novel object. Our method, Experience-embedded Visual Foresight (EVF), jointly learns a fast adaptation module, which encodes observed trajectories of the new object into a vector embedding, and a visual prediction model, which conditions on this embedding to generate physically plausible predictions. For evaluation, we compare our method against baselines on video prediction and benchmark its utility on two real world control tasks. We show that our method is able to quickly adapt to new visual dynamics and achieves lower error than the baselines when manipulating novel objects. Videos are available at: http://evf. csail. mit. edu/.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:3htObqc8RwsC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2019,"Pushing is a fundamental robotic skill. Existing work has shown how to exploit models of pushing to achieve a variety of tasks, including grasping under uncertainty, in-hand manipulation and clearing clutter. Such models, however, are approximate, which limits their applicability.Learning-based methods can reason directly from raw sensory data with accuracy, and have the potential to generalize to a wider diversity of scenarios. However, developing and testing such methods requires rich-enough datasets. In this paper we introduce Omnipush, a dataset with high variety of planar pushing behavior.In particular, we provide 250 pushes for each of 250 objects, all recorded with RGB-D and a high precision tracking system. The objects are constructed so as to systematically explore key factors that affect pushing-the shape of the object and its mass distribution-which have not been broadly explored in previous …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:bKqednn6t2AC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2019,"We introduce a framework that uses Generative Adversarial Networks (GANs) to study cognitive properties like memorability. These attributes are of interest because we do not have a concrete visual definition of what they entail. What does it look like for a dog to be more memorable? GANs allow us to generate a manifold of natural-looking images with fine-grained differences in their visual attributes. By navigating this manifold in directions that increase memorability, we can visualize what it looks like for a particular generated image to become more memorable. The resulting"" visual definitions"" surface image properties (like"" object size"") that may underlie memorability. Through behavioral experiments, we verify that our method indeed discovers image manipulations that causally affect human memory performance. We further demonstrate that the same framework can be used to analyze image aesthetics and emotional valence. ganalyze. csail. mit. edu.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:mNrWkgRL2YcC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2019,"Contemporary sensorimotor learning approaches typically start with an existing complex agent (eg, a robotic arm), which they learn to control. In contrast, this paper investigates a modular co-evolution strategy: a collection of primitive agents learns to dynamically self-assemble into composite bodies while also learning to coordinate their behavior to control these bodies. Each primitive agent consists of a limb with a motor attached at one end. Limbs may choose to link up to form collectives. When a limb initiates a link-up action and there is another limb nearby, the latter is magnetically connected to the'parent'limb's motor. This forms a new single agent, which may further link with other agents. In this way, complex morphologies can emerge, controlled by a policy whose architecture is in explicit correspondence with the morphology. We evaluate the performance of these dynamic and modular agents in simulated environments. We demonstrate better generalization to test-time changes both in the environment, as well as in the structure of the agent, compared to static and monolithic baselines. Project videos and source code are provided in the supplementary material.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:dBIO0h50nwkC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2019,"Generative Adversarial Networks (GANs) typically learn a distribution of images in a large image dataset, and are then able to generate new images from this distribution. However, each natural image has its own internal statistics, captured by its unique distribution of patches. In this paper we propose an ""Internal GAN"" (InGAN) - an image-specific GAN - which trains on a single input image and learns its internal distribution of patches. It is then able to synthesize a plethora of new natural images of significantly different sizes, shapes and aspect-ratios - all with the same internal patch-distribution (same ""DNA"") as the input image. In particular, despite large changes in global size/shape of the image, all elements inside the image maintain their local size/shape. InGAN is fully unsupervised, requiring no additional data other than the input image itself. Once trained on the input image, it can remap the input to any size or shape in a single feedforward pass, while preserving the same internal patch distribution. InGAN provides a unified framework for a variety of tasks, bridging the gap between textures and natural images.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:IRz6iEL74y4C,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2018,"Sketch-based modeling strives to bring the ease and immediacy of drawing to the 3D world. However, while drawings are easy for humans to create, they are very challenging for computers to interpret due to their sparsity and ambiguity. We propose a data-driven approach that tackles this challenge by learning to reconstruct 3D shapes from one or more drawings. At the core of our approach is a deep convolutional neural network (CNN) that predicts occupancy of a voxel grid from a line drawing. This CNN provides an initial 3D reconstruction as soon as the user completes a single drawing of the desired shape. We complement this single-view network with an updater CNN that refines an existing prediction given a new drawing of the shape created from a novel viewpoint. A key advantage of our approach is that we can apply the updater iteratively to fuse information from an arbitrary number of viewpoints, without …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:6ZxmRoH8BuwC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2018,"Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:HtS1dXgVpQUC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2018,"We propose a metalearning approach for learning gradient-based reinforcement learning (RL) algorithms. The idea is to evolve a differentiable loss function, such that an agent, which optimizes its policy to minimize this loss, will achieve high rewards. The loss is parametrized via temporal convolutions over the agent's experience. Because this loss is highly flexible in its ability to take into account the agent's history, it enables fast task learning. Empirical results show that our evolved policy gradient algorithm (EPG) achieves faster learning on several randomized environments compared to an off-the-shelf policy gradient method. We also demonstrate that EPG's learned loss can generalize to out-of-distribution test time tasks, and exhibits qualitatively different behavior from other popular metalearning algorithms.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:sNmaIFBj_lkC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2018,"What makes a word memorable? Prior research has identified numerous factors: word frequency, concreteness, imageability, and valence have all been shown to affect recognition performance. One important dimension that has not received much attention is the nature of the relationship between words and meanings. Under the hypothesis that words are encoded primarily by their meanings, and not by their surface forms, this relationship should be central to determining word memorability. In particular, rational analysis suggests that people will more easily remember words that convey a large amount of information about their intended meaning and that have few alternatives–that is, memorable words will be those with few possible meanings and synonyms. To test this hypothesis, we ran two large-scale recognition memory experiments (each with 2,222 words, 600+ participants). Memory performance was overall high, on par with memory for pictures in a similar paradigm. Critically, however, not all words were remembered equally well. Consistent with our proposal, the best recognized words had few meanings and few synonyms. Indeed, the most memorable words had a one-to-one relationship with their meanings. Estimates of memorability derived from this rational account explain a large amount of the variance in word memorability.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:umqufdRvDiIC,http://web.mit.edu/phillipi
Phillip Isola,"['Computer Vision', 'Machine Learning', 'AI', 'Cognitive Science']",40,57650,2018,"While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called``perceptual losses""? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=ROILf3EAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=ROILf3EAAAAJ:XvxMoLDsR5gC,http://web.mit.edu/phillipi
Sara Achour,"['programming languages', 'compilers', 'emerging hardware technologies']",5,512,2023,"Hyperdimensional (HD) computing is an highly error-resilient computational paradigm that can be used to efficiently perform language classification, data retrieval, and analogical reasoning tasks on error-prone emerging hardware technologies. HD computation is storage-inefficient and often requires computing over 10,000-dimensional bit vectors. Prior work either leaves hypervectors unoptimized or dynamically tunes HD computation parameters (e.g., hypervector dimension) to deliver the desired accuracy. These approaches are time-consuming, lack accuracy guarantees, and do not generalize well. We present Heim, a framework for statically optimizing HD computation parameters to minimize resource usage in the presence of hardware error. Heim guarantees the optimized computation satisfies a user-provided target accuracy. Heim deploys a novel analysis procedure that unifies theoretical results in HD computing to systematically optimize HD computation. We develop four analysis-amenable data structures that leverage Heim to perform aggressive space-saving optimizations, and optimize these data structures to attain 99% query accuracy on both binary memory and multiple-bit-per-cell resistive memory. Heim-optimized data structures deliver 1.31x-14.51x reductions in hypervector size and 2.191x-27.27x reductions in memory usage while attaining 98.96-99.75% accuracy. Heim-optimized data structures deliver up to 41.40% accuracy improvements over dynamically tuned parameters. Heim computes parameters significantly faster than dynamic approaches.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=J-5mJ7AAAAAJ&sortby=pubdate&citation_for_view=J-5mJ7AAAAAJ:aqlVkmm33-oC,https://www.sara-achour.me/
Sara Achour,"['programming languages', 'compilers', 'emerging hardware technologies']",5,512,2021,"Reconfigurable dynamical-system solving analog devices are a powerful new ultra-low-power computing substrate capable of executing dynamical systems in a performant and energy-efficient manner. This class of devices leverages the physical behavior of transistors to directly implement computation. Under this paradigm, voltages and currents within the device implement continuously evolving variables in the computation. These hardware platforms are challenging to use because they are subject to a variety of low-level physical behaviors that profoundly affect the computation. Relevant physical behaviors include operating range and frequency limitations, noise, process variation, and quantization error. In this thesis, I present compilation techniques for automatically configuring such devices to execute dynamical systems and present the first compiler that automatically targets a physical dynamical system-solving reconfigurable analog device of this class. The presented compiler frees the end user from reasoning about the low-level physical behaviors present in the hardware and automates the process of mapping the dynamical system to the analog hardware. This thesis also introduces specification languages for describing dynamical systems, and the capabilities and physical limitations of the reprogrammable analog hardware. The compiler targets these specifications when mapping the computation. To faithfully implement a computation, the compiler configures the device so that the original dynamical system dynamics can be recovered from the physics of the device at runtime. The mapped computation simultaneously leverages the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=J-5mJ7AAAAAJ&sortby=pubdate&citation_for_view=J-5mJ7AAAAAJ:qxL8FJ1GzNcC,https://www.sara-achour.me/
Sara Achour,"['programming languages', 'compilers', 'emerging hardware technologies']",5,512,2020,"Reconfigurable analog devices are a powerful new computing substrate especially appropriate for executing computationally intensive dynamical system computations in an energy efficient manner. We present Legno, a compilation toolchain for programmable analog devices. Legno targets the HCDCv2, a programmable analog device designed to execute general nonlinear dynamical systems. To the best of our knowledge, Legno is the first compiler to successfully target a physical (as opposed to simulated) programmable analog device for dynamical systems and this paper is the first to present experimental results for any compiled computation executing on any physical programmable analog device of this class. The Legno compiler synthesizes analog circuits from parametric and specialized blocks and account for analog noise, quantization error, and manufacturing variations within the device. We evaluate the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=J-5mJ7AAAAAJ&sortby=pubdate&citation_for_view=J-5mJ7AAAAAJ:hqOjcs7Dif8C,https://www.sara-achour.me/
Sara Achour,"['programming languages', 'compilers', 'emerging hardware technologies']",5,512,2018,"Programmable analog devices are a powerful new computing substrate that are especially appropriate for performing computationally intensive simulations of neuromorphic and cytomorphic models. Current state of the art techniques for configuring analog devices to simulate dynamical systems do not consider the current and voltage operating ranges of analog device components or the sampling limitations of the digital interface of the device. We present Jaunt, a new solver that scales the values that configure the analog device to ensure the resulting analog computation executes within the operating constraints of the device, preserves the recoverable dynamics of the original simulation, and executes slowly enough to observe these dynamics at the sampled digital outputs. Our results show that, on a set of benchmark biological simulations, 1) unscaled configurations produce incorrect simulations because they …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=J-5mJ7AAAAAJ&sortby=pubdate&citation_for_view=J-5mJ7AAAAAJ:WF5omc3nYNoC,https://www.sara-achour.me/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2023,"Presenters often collect audience feedback through practice talks to refine their presentations. In formative interviews, we find that although text feedback and verbal discussions allow presenters to receive feedback, organizing that feedback into actionable presentation revisions remains challenging. Feedback may lack context, be redundant, and be spread across various emails, notes, and conversations. To collate and contextualize both text and verbal feedback, we present SlideSpecs. SlideSpecs lets audience members provide text feedback (e.g., ‘font too small’) while attaching an automatically detected context, including relevant slides (e.g., ‘Slide 7’) or content tags (e.g., ‘slide design’). SlideSpecs also records and transcribes spoken group discussions that commonly occur after practice talks and facilitates linking text critiques to relevant discussion segments. Finally, presenters can use SlideSpecs to review …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:SCE0ypLQHGcC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2023,"We present a neural network structure, ControlNet, to control pretrained large diffusion models to support additional input conditions. The ControlNet learns task-specific conditions in an end-to-end way, and the learning is robust even when the training dataset is small (< 50k). Moreover, training a ControlNet is as fast as fine-tuning a diffusion model, and the model can be trained on a personal devices. Alternatively, if powerful computation clusters are available, the model can scale to large amounts (millions to billions) of data. We report that large diffusion models like Stable Diffusion can be augmented with ControlNets to enable conditional inputs like edge maps, segmentation maps, keypoints, etc. This may enrich the methods to control large diffusion models and further facilitate related applications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:xoCRtiy2jdkC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2022,"Foundation paper piecing is a widely used quilt-making technique in which fabric pieces are sewn onto a paper guide to facilitate construction. But, designing paper pieceable quilt patterns is challenging because the sewing process imposes constraints on both the geometry and sewing order of the fabric pieces. Based on a formative study with expert quilt designers, we develop a novel sketch-based tool for designing such quilt patterns. Our tool lets designers sketch a partial design as a set of edges, which may intersect but do not have to form closed polygons, and our tool automatically completes it into a fully paper pieceable pattern. We contribute a new sketch-completion algorithm that extends the input sketched edges into a planar mesh composed of closed polygonal faces representing fabric pieces, determines a paper pieceable sewing order for the faces, and breaks complicated sketches into …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:hQ3-0SoZo6AC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2022,"Statically analyzing information flow, or how data influences other data within a program, is a challenging task in imperative languages. Analyzing pointers and mutations requires access to a program's complete source. However, programs often use pre-compiled dependencies where only type signatures are available. We demonstrate that ownership types can be used to soundly and precisely analyze information flow through function calls given only their type signature. From this insight, we built Flowistry, a system for analyzing information flow in Rust, an ownership-based language. We prove the system's soundness as a form of noninterference using the Oxide formal model of Rust. Then we empirically evaluate the precision of Flowistry, showing that modular flows are identical to whole-program flows in 94% of cases drawn from large Rust codebases. We illustrate the applicability of Flowistry by using it to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:SenaEjHFqFYC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2022,"We present ZoomShop, a photographic composition editing tool for adjusting relative size, position, and foreshortening of scene elements. Given an image and corresponding depth map as input, ZoomShop combines a novel non‐linear camera model and a depth‐aware image warp to reproject and deform the image. Users can isolate objects by selecting depth ranges and adjust their scale and foreshortening, which controls the paths of the camera rays through the scene. Users can also select 2D image regions and translate them, which determines the objective function in the image warp optimization. We demonstrate that ZoomShop can be used to achieve useful compositional goals, such as making a distant object more prominent while preserving foreground scenery, or making objects both larger and closer together so they still fit in the frame.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:vkG2KsohqNgC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2022,"Modern CAD tools represent 3D designs not only as geometry, but also as a program composed of geometric operations, each of which depends on a set of parameters. Program representations enable meaningful and controlled shape variations via parameter changes. However, achieving desired modifications solely through parameter editing is challenging when CAD models have not been explicitly authored to expose select degrees of freedom in advance. We introduce a novel bidirectional editing system for 3D CAD programs. In addition to editing the CAD program, users can directly manipulate 3D geometry and our system infers parameter updates to keep both representations in sync. We formulate inverse edits as a set of constrained optimization objectives, returning plausible updates to program parameters that both match user intent and maintain program validity. Our approach implements an …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:sK9NQJKSZRcC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2022,"Prior benchmarks have analyzed models' answers to questions about videos in order to measure visual compositional reasoning. Action Genome Question Answering (AGQA) is one such benchmark. AGQA provides a training/test split with balanced answer distributions to reduce the effect of linguistic biases. However, some biases remain in several AGQA categories. We introduce AGQA 2.0, a version of this benchmark with several improvements, most namely a stricter balancing procedure. We then report results on the updated benchmark for all experiments.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:tKAXkfz_euYC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2022,"Despite this cacophony of available theories, however, it has recently been argued that theory is underutilized in contemporary HCI research. Oulasvirta and Hornbaek provide a formal account of how theories can be used to guide design by generating counterfactual speculations about how design decisions will affect interaction [27]. In a survey of 25 CHI best papers, they found that a relatively small number used explicitly used theory to drive design in this way. Theory can also be used more loosely, to inspire a general direction for research or to interpret",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:mN77zE6YZBUC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2022,"Recent video question answering benchmarks indicate that state-of-the-art models struggle to answer compositional questions. However, it remains unclear which types of compositional reasoning cause models to mispredict. Furthermore, it is difficult to discern whether models arrive at answers using compositional reasoning or by leveraging data biases. In this paper, we develop a question decomposition engine that programmatically deconstructs a compositional question into a directed acyclic graph of sub-questions. The graph is designed such that each parent question is a composition of its children. We present AGQA-Decomp, a benchmark containing 2.3 M question graphs, with an average of 11.49 sub-questions per graph, and 4.55 M total new sub-questions. Using question graphs, we evaluate three state-of-the-art models with a suite of novel compositional consistency metrics. We find that models either cannot reason correctly through most compositions or are reliant on incorrect reasoning to reach answers, frequently contradicting themselves or achieving high accuracies when failing at intermediate reasoning steps.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:ooaom_WTAwIC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2022,"Learning 3D generative models from a dataset of monocular images enables self-supervised 3D reasoning and controllable synthesis. State-of-the-art 3D generative models are GANs which use neural 3D volumetric representations for synthesis. Images are synthesized by rendering the volumes from a given camera. These models can disentangle the 3D scene from the camera viewpoint in any generated image. However, most models do not disentangle other factors of image formation, such as geometry and appearance. In this paper, we design a 3D GAN which can learn a disentangled model of objects, just from monocular observations. Our model can disentangle the geometry and appearance variations in the scene, ie, we can independently sample from the geometry and appearance spaces of the generative model. This is achieved using a novel non-rigid deformable scene formulation. A 3D volume which represents an object instance is computed as a non-rigidly deformed canonical 3D volume. Our method learns the canonical volume, as well as its deformations, jointly during training. This formulation also helps us improve the disentanglement between the 3D scene and the camera viewpoints using a novel pose regularization loss defined on the 3D deformation field. In addition, we further model the inverse deformations, enabling the computation of dense correspondences between images generated by our model. Finally, we design an approach to embed real images onto the latent space of our disentangled generative model, enabling editing of real images.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:HIhYGD-CTiAC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2022,"Here, we show how our b (z) camera parameterization can be understood geometrically in terms of non-linear camera models. We first show that a piecewise-linear, continuous choice of b (z) corresponds to a sequence of linear camera models, each applied to different depth ranges, equivalent to the Computational Zoom model proposed by Badki et al.[BGKS17]. We then describe generalizations to non-linear and non-continuous b (z), and what these correspond to geometrically. For each type of these b (z)(ie, piecewise linear, curved, and discontinuous), we show that Equation 1 holds: u= x b (z)(1)",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:_hb0F9yZ3cgC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"Mix-and-match character creation tools enable users to quickly produce 2D character illustrations by combining various predefined accessories, like clothes and hairstyles, which are represented as separate, interchangeable artwork layers. However, these accessory layers are often designed to fit only the default body artwork, so users cannot modify the body without manually updating all the accessory layers as well. To address this issue, we present a method that captures and preserves important relationships between artwork layers so that the predefined accessories adapt with the character’s body. We encode these relationships with four types of constraints that handle common interactions between layers: (1) occlusion, (2) attachment at a point, (3) coincident boundaries, and (4) overlapping regions. A rig is a set of constraints that allow a motion or deformation specified on the body to transfer to the accessory …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:DIP-VHrGjvwC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"Cable (TV) news reaches millions of US households each day. News stakeholders such as communications researchers, journalists, and media monitoring organizations are interested in the visual content of cable news, especially who is on-screen. Manual analysis, however, is labor intensive and limits the size of prior studies. We conduct a large-scale, quantitative analysis of the faces in a decade of cable news video from the top three US cable news networks (CNN, FOX, and MSNBC), totaling 244,038 hours between January 2010 and July 2019. Our work uses technologies such as automatic face and gender recognition to measure the “screen time” of faces and to enable visual analysis and exploration at scale. Our analysis method gives insight into a broad set of socially relevant topics. For instance, male-presenting faces receive much more screen time than female-presenting faces (2.4 x in 2010, 1.9 x in 2019). To make our dataset and annotations accessible, we release a public interface at https://tvnews. stanford. edu that allows the general public to write queries and to perform their own analyses.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:_b9rsmHxKOYC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"We present a text-based tool for editing talking-head video that enables an iterative editing workflow. On each iteration users can edit the wording of the speech, further refine mouth motions if necessary to reduce artifacts, and manipulate non-verbal aspects of the performance by inserting mouth gestures (e.g., a smile) or changing the overall performance style (e.g., energetic, mumble). Our tool requires only 2 to 3 minutes of the target actor video and it synthesizes the video for each iteration in about 40 seconds, allowing users to quickly explore many editing possibilities as they iterate. Our approach is based on two key ideas. (1) We develop a fast phoneme search algorithm that can quickly identify phoneme-level subsequences of the source repository video that best match a desired edit. This enables our fast iteration loop. (2) We leverage a large repository of video of a source actor and develop a new self …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:_Nt1UvVys9QC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"Quiltmaking has become a popular craft, with 7-10 million quilters in the US alone [The Quilting Company 2017]. Foundation paper piecing is a common method for sewing the top layer of a quilt using a pattern printed on paper as a physical guide. Quilters sew pieces of fabric corresponding to each polygon in the pattern’s geometric design along the printed seam lines, directly to the paper and one another. The fabric pieces are sewn one at a time in the sewing order specified by the numbering of the polygons (Figure 1). After sewing all interior seams in the pattern, quilters remove the paper, resulting in a precise fabric patchwork quilt top ready to be layered atop batting material and backing fabric, and then sewn together into a finished quilt.
The paper guide serves as a foundation for the construction process that provides stability and increases precision compared to traditional quilt piecing techniques that do not use paper [Alteneder 2020; Mahoney 2016; Sharp 2018]. Specifically, it provides a stable base for aligning the fabric pieces and holding them in place via pins during sewing. The printed seam lines serve as precise visual guides for sewing the seams accurately. Sewing a straight seam at a specific location is far more difficult when there is no printed line to follow along. These advantages of paper piecing have made it a widely used method for sewing quilt tops, especially among beginners, but also for many experienced quilters [Mahoney 2016].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:iINcni2fUZgC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"Simulation offers many advantages when designing analog circuits. Designers can explore alternatives quickly, without added cost or risk of hardware faults. However, it is challenging to use simulation as an aid during interactive debugging of physical circuits, due to difficulties in comparing simulated analyses with hardware measurements. Designers must continually configure simulations to match the state of the physical circuit (e.g. capturing sensor inputs), and must manually rework the hardware to replicate changes or analyses performed in simulation. We propose techniques leveraging instrumentation and programmable test hardware to create a tight coupling between a physical circuit and its simulated model. Bridging these representations helps designers to compare simulated and measured behaviors, and to quickly perform analytical techniques on hardware (e.g. parameter-response analysis) that are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:kuAnG0LXj_AC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"We present a multi-modal approach for automatically generating hierarchical tutorials from instructional makeup videos. Our approach is inspired by prior research in cognitive psychology, which suggests that people mentally segment procedural tasks into event hierarchies, where coarse-grained events focus on objects while fine-grained events focus on actions. In the instructional makeup domain, we find that objects correspond to facial parts while fine-grained steps correspond to actions on those facial parts. Given an input instructional makeup video, we apply a set of heuristics that combine computer vision techniques with transcript text analysis to automatically identify the fine-level action steps and group these steps by facial part to form the coarse-level events. We provide a voice-enabled, mixed-media UI to visualize the resulting hierarchy and allow users to efficiently navigate the tutorial (e.g., skip ahead …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:rR1SM4wcGAYC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"Charts often contain visually prominent features that draw attention to aspects of the data and include text captions that emphasize aspects of the data. Through a crowdsourced study, we explore how readers gather takeaways when considering charts and captions together. We first ask participants to mark visually prominent regions in a set of line charts. We then generate text captions based on the prominent features and ask participants to report their takeaways after observing chart-caption pairs. We find that when both the chart and caption describe a high-prominence feature, readers treat the doubly emphasized high-prominence feature as the takeaway; when the caption describes a low-prominence chart feature, readers rely on the chart and report a higher-prominence feature as the takeaway. We also find that external information that provides context, helps further convey the caption’s message to the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:8wCixH_E2vEC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"Program tracing, or mentally simulating a program on concrete inputs, is an important part of general program comprehension. Programs involve many kinds of virtual state that must be held in memory, such as variable/value pairs and a call stack. In this work, we examine the influence of short-term working memory (WM) on a person’s ability to remember program state during tracing. We first confirm that previous findings in cognitive psychology transfer to the programming domain: people can keep about 7 variable/value pairs in WM, and people will accidentally swap associations between variables due to WM load. We use a restricted focus viewing interface to further analyze the strategies people use to trace through programs, and the relationship of tracing strategy to WM. Given a straight-line program, we find half of our participants traced a program from the top-down line-by-line (linearly), and the other half …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:CUz-cjXBMXMC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"We present a system that converts annotated broadcast video of tennis matches into interactively controllable video sprites that behave and appear like professional tennis players. Our approach is based on controllable video textures and utilizes domain knowledge of the cyclic structure of tennis rallies to place clip transitions and accept control inputs at key decision-making moments of point play. Most importantly, we use points from the video collection to model a player’s court positioning and shot selection decisions during points. We use these behavioral models to select video clips that reflect actions the real-life player is likely to take in a given match-play situation, yielding sprites that behave realistically at the macro level of full points, not just individual tennis motions. Our system can generate novel points between professional tennis players that resemble Wimbledon broadcasts, enabling new experiences …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:W26WQ4UGDhEC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2021,"Visual events are a composition of temporal actions involving actors spatially interacting with objects. When developing computer vision models that can reason about compositional spatio-temporal events, we need benchmarks that can analyze progress and uncover shortcomings. Existing video question answering benchmarks are useful, but they often conflate multiple sources of error into one accuracy metric and have strong biases that models can exploit, making it difficult to pinpoint model weaknesses. We present Action Genome Question Answering (AGQA), a new benchmark for compositional spatio-temporal reasoning. AGQA contains 192M unbalanced question answer pairs for 9.6 K videos. We also provide a balanced subset of 3.9 M question answer pairs, 3 orders of magnitude larger than existing benchmarks, that minimizes bias by balancing the answer distributions and types of question structures. Although human evaluators marked 86.02% of our question-answer pairs as correct, the best model achieves only 47.74% accuracy. In addition, AGQA introduces multiple training/test splits to test for various reasoning abilities, including generalization to novel compositions, to indirect references, and to more compositional steps. Using AGQA, we evaluate modern visual reasoning systems, demonstrating that the best models barely perform better than non-visual baselines exploiting linguistic biases and that none of the existing models generalize to novel compositions unseen during training.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:ouq6-fJ2VSQC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,"Audio travel podcasts are a valuable source of information for travelers. Yet, travel is, in many ways, a visual experience and the lack of visuals in travel podcasts can make it difficult for listeners to fully understand the places being discussed. We present Crosscast: a system for automatically adding visuals to audio travel podcasts. Given an audio travel podcast as input, Crosscast uses natural language processing and text mining to identify geographic locations and descriptive keywords within the podcast transcript. Crosscast then uses these locations and keywords to automatically select relevant photos from online repositories and synchronizes their display to align with the audio narration. In a user evaluation, we find that 85.7% of the participants preferred Crosscast generated audio-visual travel podcasts compared to audio-only travel podcasts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:sFh2DmJudxsC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,"Cable TV news reaches millions of U.S. households each day, and decisions about who appears on the news, and what stories get talked about, can profoundly influence public opinion and discourse. In this paper, we use computational techniques to analyze a data set of nearly 24/7 video, audio, and text captions from three major U.S. cable TV networks (CNN, FOX News, and MSNBC) from the last decade. Using automated machine learning tools, we detect faces in 244,038 hours of video, label their presented gender, identify prominent public figures, and align text captions to audio. We use these labels to perform face screen time and caption word frequency analyses of the contents of cable TV news. For example, we find that the ratio of female-presenting to male-presenting individuals has increased from 0.41 to 0.54 over the last decade. Donald Trump and Barack Obama received the most screen time over the last decade, with Trump receiving twice the screen time of Obama. Hillary Clinton's face was on screen 11% of the time when ""email"" was said in 2015 and 2016. In addition to reporting the results of our own analyses, we describe the design of an interactive web-based tool that allows the general public to perform their own screen time analyses on the entire cable TV news data set.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:n35PH7pn8T4C,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,"The consequent refinements provide suggestions for good design, and the process of refinement provides suggestions for uncovering design principles. Like written language, visualizations are cognitive tools, designed to augment the capacity of the human mind. Creating effective visualizations, as found in instructions, textbooks, and other media, requires collaboration between graphic designers and domain experts, as well as testing the target audience. Visualizations of systems, too, are ancient; frescoes in Egyptian tombs show how crops are grown and harvested. To make visualizations that are congruent with the desired mental representations requires techniques that reveal those internal mental representations. Creating effective visualizations entails numerous design decisions, as illustrated by a few examples. Route maps and assembly instructions belong to a larger class of visualizations that are used in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:moWhu9_CcosC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:N3pez2oqSB0C,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,"Efficient rendering of photo‐realistic virtual worlds is a long standing effort of computer graphics. Modern graphics techniques have succeeded in synthesizing photo‐realistic images from hand‐crafted scene representations. However, the automatic generation of shape, materials, lighting, and other aspects of scenes remains a challenging problem that, if solved, would make photo‐realistic computer graphics more widely accessible. Concurrently, progress in computer vision and machine learning have given rise to a new approach to image synthesis and editing, namely deep generative models. Neural rendering is a new and rapidly emerging field that combines generative machine learning techniques with physical knowledge from computer graphics, e.g., by the integration of differentiable rendering into network training. With a plethora of applications in computer graphics and vision, neural rendering is poised …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:xEh6bupSuykC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,"We present a system that automatically transforms text articles into audio-visual slideshows by leveraging the notion of word concreteness, which measures how strongly a word or phrase is related to some perceptible concept. In a formative study we learn that people not only prefer such audio-visual slideshows but find that the content is easier to understand compared to text articles or text articles augmented with images. We use word concreteness to select search terms and find images relevant to the text. Then, based on the distribution of concrete words and the grammatical structure of an article, we time-align selected images with audio narration obtained through text-to-speech to produce audio-visual slideshows. In a user evaluation we find that our concreteness-based algorithm selects images that are highly relevant to the text. The quality of our slideshows is comparable to slideshows produced manually using standard video editing tools, and people strongly prefer our slideshows to those generated using a simple keyword-search based approach.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:UOgPUojWnykC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,"People often use charts to analyze data, answer questions and explain their answers to others. In a formative study, we find that such human-generated questions and explanations commonly refer to visual features of charts. Based on this study, we developed an automatic chart question answering pipeline that generates visual explanations describing how the answer was obtained. Our pipeline first extracts the data and visual encodings from an input Vega-Lite chart. Then, given a natural language question about the chart, it transforms references to visual attributes into references to the data. It next applies a state-of-the-art machine learning algorithm to answer the transformed question. Finally, it uses a template-based approach to explain in natural language how the answer is determined from the chart's visual features. A user study finds that our pipeline-generated visual explanations significantly outperform in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:PV2Y7XyTJDgC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,"Programming offers new opportunities for visual art creation, but understanding and manipulating the abstract representations that make programming powerful can pose challenges for artists who are accustomed to manual tools and concrete visual interaction. We hypothesize that we can reduce these barriers through programming environments that link state to visual artwork output. We created Demystified Dynamic Brushes (DDB), a tool that bidirectionally links code, numerical data, and artwork across the programming interface and the execution environment - i.e., the artist's in-progress artwork. DDB automatically records stylus input as artists draw, and stores a history of brush state and output in relation to the input. This structure enables artists to inspect current and past numerical input, state, and output and control program execution through the direct selection of visual geometric elements in the drawing …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:tVzLobxzA7YC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,Technologies for manipulating our digital appearance alter the way the world sees us as well as the way we see ourselves.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:MagRZZew-58C,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,"Facial recognition technology (FRT) raises profound questions about the role of technology in society. The complex ethical and normative concerns about FRT's impact on privacy, speech, racial equity, and the power of the state merit serious debate. Yet one requirement common to proposed legislation and regulation of FRT is the testing and assessment of operational performance: how well does FRT actually work? This poses deep challenges given the rapid uptake of FRT in many new domains, such as retail, finance, travel, and criminal justice. In this Article, we provide research-and science-grounded recommendations for how to concretely test the operational accuracy of FRT that will be central to regulation and oversight.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:FQnhRx9bfrkC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2020,"Recent advances in machine learning and computer graphics have made it easier to convincingly manipulate video and audio. These so-called deep-fake videos range from complete full-face synthesis and replacement (face-swap), to complete mouth and audio synthesis and replacement (lip-sync), and partial word-based audio and mouth synthesis and replacement. Detection of deep fakes with only a small spatial and temporal manipulation is particularly challenging. We describe a technique to detect such manipulated videos by exploiting the fact that the dynamics of the mouth shape--visemes--are occasionally inconsistent with a spoken phoneme. We focus on the visemes associated with words having the sound M (mama), B (baba), or P (papa) in which the mouth must completely close in order to pronounce these phonemes. We observe that this is not the case in many deep-fake videos. Such phoneme-viseme mismatches can, therefore, be used to detect even spatially small and temporally localized manipulations. We demonstrate the efficacy and robustness of this approach to detect different types of deep-fake videos, including in-the-wild deep fakes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:ShM3enpx8HwC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"A major concern for filmmakers creating 360° video is ensuring that the viewer does not miss important narrative elements because they are looking in the wrong direction. This paper introduces gated clips which do not play the video past a gate time until a filmmaker-defined viewer gaze condition is met, such as looking at a specific region of interest (ROI). Until the condition is met, we seamlessly loop video playback using view-dependent video textures, a new variant of standard video textures that adapt the looping behavior to the portion of the scene that is within the viewer's field of view. We use our desktop GUI to edit live action and computer animated 360° videos. In a user study with casual viewers, participants prefer our looping videos over the standard versions and are able to successfully see all of the looping videos' ROIs without fear of missing important narrative content.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:cwugQcE3IssC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"Many real-world video analysis applications require the ability to identify domain-specific events in video, such as interviews and commercials in TV news broadcasts, or action sequences in film. Unfortunately, pre-trained models to detect all the events of interest in video may not exist, and training new models from scratch can be costly and labor-intensive. In this paper, we explore the utility of specifying new events in video in a more traditional manner: by writing queries that compose outputs of existing, pre-trained models. To write these queries, we have developed Rekall, a library that exposes a data model and programming model for compositional video event specification. Rekall represents video annotations from different sources (object detectors, transcripts, etc.) as spatiotemporal labels associated with continuous volumes of spacetime in a video, and provides operators for composing labels into queries that model new video events. We demonstrate the use of Rekall in analyzing video from cable TV news broadcasts, films, static-camera vehicular video streams, and commercial autonomous vehicle logs. In these efforts, domain experts were able to quickly (in a few hours to a day) author queries that enabled the accurate detection of new events (on par with, and in some cases much more accurate than, learned approaches) and to rapidly retrieve video clips for human-in-the-loop tasks such as video content curation and training data curation. Finally, in a user study, novice users of Rekall were able to author queries to retrieve new events in video given just one hour of query development time.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:8k3R5ScbChQC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"We present a search engine for D3 visualizations that allows queries based on their visual style and underlying structure. To build the engine we crawl a collection of 7860 D3 visualizations from the Web and deconstruct each one to recover its data, its data-encoding marks and the encodings describing how the data is mapped to visual attributes of the marks. We also extract axes and other non-data-encoding attributes of marks (e.g., typeface, background color). Our search engine indexes this style and structure information as well as metadata about the webpage containing the chart. We show how visualization developers can search the collection to find visualizations that exhibit specific design characteristics and thereby explore the space of possible designs. We also demonstrate how researchers can use the search engine to identify commonly used visual design patterns and we perform such a demographic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:e6AMIDGT8rIC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"Editing talking-head video to change the speech content or to remove filler words is challenging. We propose a novel method to edit talking-head video based on its transcript to produce a realistic output video in which the dialogue of the speaker has been modified, while maintaining a seamless audio-visual flow (i.e. no jump cuts). Our method automatically annotates an input talking-head video with phonemes, visemes, 3D face pose and geometry, reflectance, expression and scene illumination per frame. To edit a video, the user has to only edit the transcript, and an optimization strategy then chooses segments of the input corpus as base material. The annotated parameters corresponding to the selected segments are seamlessly stitched together and used to produce an intermediate video representation in which the lower half of the face is rendered with a parametric face model. Finally, a recurrent video …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:T4xR6ACgc60C,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"We present ConvCut, an interactive tool for efficiently navigating and editing 360 video of social conversations into shareable video highlights of the memorable moments. ConvCut starts by obtaining a high-quality transcript of the conversation and uses it to segment the video into one 360 video clip per line of speech. It then applies audio, video and text analysis to label the clips with information including the spatial location of faces, the current speaker, the topics of conversation, instances of laughter and extreme changes in volume, facial expression, or gestural motion. The resulting structure lets users navigate the video using keyword search over the transcript and labels to quickly find memorable moments. Users can mark the lines corresponding to these moments and ConvCut edits together the corresponding video clips, automatically choosing a regular field of view (RFOV) framing that emphasizes the speaker of each line. If desired, users can modify the automatic edit to include alternative framings or reactions from others in the group. We demonstrate that with ConvCut, first-time users can easily edit long social conversations (25-60 min) into short highlight videos (0.27-2 min) and share them with others. The resulting highlights include jokes, reactions to pranks, funny stories and interactions with children.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:Mr27SXpvooAC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"When watching how-to videos related to physical tasks, users' hands are often occupied by the task, making voice input a natural fit. To better understand the design space of voice interactions for how-to video navigation, we conducted three think-aloud studies using: 1) a traditional video interface, 2) a research probe providing a voice controlled video interface, and 3) a wizard-of-oz interface. From the studies, we distill seven navigation objectives and their underlying intents: pace control pause, content alignment pause, video control pause, reference jump, replay jump, skip jump, and peek jump. Our analysis found that users' navigation objectives and intents affect the choice of referent type and referencing approach in command utterances. Based on our findings, we recommend to 1) support conversational strategies like sequence expansions and command queues, 2) allow users to identify and refine their …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:vtskfw0NoLIC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"Visual blends are an advanced graphic design technique to draw attention to a message. They combine two objects in a way that is novel and useful in conveying a message symbolically. This paper presents VisiBlends, a flexible workflow for creating visual blends that follows the iterative design process. We introduce a design pattern for blending symbols based on principles of human visual object recognition. Our workflow decomposes the process into both computational techniques and human microtasks. It allows users to collaboratively generate visual blends with steps involving brainstorming, synthesis, and iteration. An evaluation of the workflow shows that decentralized groups can generate blends in independent microtasks, co-located groups can collaboratively make visual blends for their own messages, and VisiBlends improves novices' ability to make visual blends.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:Fp1gVP7Oym8C,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"Difficulties in accessing, isolating, and iterating on the components and connections of a printed circuit board (PCB) create unique challenges in PCB debugging. Manual probing methods are slow and error prone, and even dedicated PCB testing equipment remains limited by its inability to modify the circuit during testing. We present Pinpoint, a tool that facilitates in-circuit PCB debugging through techniques such as programmatically probing signals, dynamically disconnecting components and subcircuits to test in isolation, and splicing in new elements to explore potential modifications. Pinpoint automatically instruments a PCB design and generates designs for a physical jig board that interfaces the user's PCB to our custom testing hardware and to software tools. We evaluate Pinpoint's ability to facilitate the debugging of various PCB issues by instrumenting and testing different classes of boards, as well as by …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:AyW1NBs4p6IC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"Spatial layout is a key component in graphic design. While people who are blind or visually impaired (BVI) can use screen readers or magnifiers to access digital content, these tools fail to fully communicate the content's graphic design information. Through semi-structured interviews and contextual inquiries, we identify the lack of this information and feedback as major challenges in understanding and editing layouts. Guided by these insights and a co-design process with a blind hobbyist web developer, we developed an interactive, multimodal authoring tool that lets blind people understand spatial relationships between elements and modify layout templates. Our tool automatically generates tactile print-outs of a web page's layout, which users overlay on top of a tablet that runs our self-voicing digital design tool. We conclude with design considerations grounded in user feedback for improving the accessibility of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:FGlqWXlxCNkC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"Dubbing puppet videos to make the characters (e.g. Kermit the Frog) convincingly speak a new speech track is a popular activity with many examples of well-known puppets speaking lines from films or singing rap songs. But manually aligning puppet mouth movements to match a new speech track is tedious as each syllable of the speech must match a closed-open-closed segment of mouth movement for the dub to be convincing. In this work, we present two methods to align a new speech track with puppet video, one semi-automatic appearance-based and the other fully-automatic audio-based. The methods offer complementary advantages and disadvantages. Our appearance-based approach directly identifies closed-open-closed segments in the puppet video and is robust to low-quality audio as well as misalignments between the mouth movements and speech in the original performance, but requires some manual annotation. Our audio-based approach assumes the original performance matches a closed-open-closed mouth segment to each syllable of the original speech. It is fully automatic, robust to visual occlusions and fast puppet movements, but does not handle misalignments in the original performance. We compare the methods and show that both improve the credibility of the resulting video over simple baseline techniques, via quantitative evaluation and user ratings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:yG35QFzCZWcC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:0GenKHZIuKYC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,"A user interface provides for multi-stroke marking menus and other uses, for use on multitouch devices. One variant of multi-stroke marking is where users draw strokes with either both hands simultaneously or alternating between the hands. Alternating strokes between hands doubles the number of accessible menu items for the same number of strokes. Other inputs can be used as well, such as timing, placement, and direction.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:8U9l5EwV_MEC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:2lgwpy1Hu6IC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2018,"Visual blends are an advanced graphic design technique to draw users' attention to a message. They blend together two objects in a way that is novel and useful in conveying a message symbolically. This demo presents an interactive pipeline for creating visual blends that follows the iterative design process. Our pipeline decomposes the process into both computational techniques and human microtasks. It allows users to collaboratively generate visual blends with steps involving brainstorming, synthesis, and iteration. Our demo allows individual users to see how existing visual blends were made, edit or improve existing visual blends, and create new visual blends.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:q2fMW1XeUkEC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2018,"Document authors commonly use tables to support arguments presented in the text. But, because tables are usually separate from the main body text, readers must split their attention between different parts of the document. We present an interactive document reader that automatically links document text with corresponding table cells. Readers can select a sentence (or tables cells) and our reader highlights the relevant table cells (or sentences). We provide an automatic pipeline for extracting such references between sentence text and table cells for existing PDF documents that combines structural analysis of tables with natural language processing and rule-based matching. On a test corpus of 330 (sentence, table) pairs, our pipeline correctly extracts 48.8% of the references. An additional 30.5% contain only false negatives (FN) errors -- the reference is missing table cells. The remaining 20.7% contain false …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:JNgBMBbBnUoC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2018,"Film historians and filmmakers study the visual style of past films to answer research questions or gain inspiration for new projects. To help such film professionals conduct large-scale analyses of visual style in films, we present Film Grok, a computational tool for labeling and analyzing narrative films. We automatically label a dataset of 620 films with key features of visual style (eg, character framing, shot sequences) derived from filmmaking texts. To study these features in the broader context of the film, we provide narrative features such as dialogue, emotional sentiment, genre, and director. For example, we use our tools to show that the rise of TV in the 1950’s correlates with character framings that are on average 5% closer to the center of the screen and nearly 200% closer to the actor than they were in the 1930’s and 40’s. We show in another example that Westerns tend to use Extreme Long Shots at moments with 70% stronger negative sentiment than the rest of the film. Akira Kurosawa, a self-proclaimed student of American Westerns, furthers this trend, using Extreme Long Shots for moments with 400% stronger negative sentiment. We train an SVM to classify films based on genre and from this SVM extract the most discriminative shot sequences for each genre. Additionally, we use Film Grok’s labels to automatically produce supercuts and supergrids highlighting visual features of interest based on user queries.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:mCmIWee0OMYC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2018,"We present a visual analogue for musical rhythm derived from an analysis of motion in video, and show that alignment of visual rhythm with its musical counterpart results in the appearance of dance. Central to our work is the concept of visual beats --- patterns of motion that can be shifted in time to control visual rhythm. By warping visual beats into alignment with musical beats, we can create or manipulate the appearance of dance in video. Using this approach we demonstrate a variety of retargeting applications that control musical synchronization of audio and video: we can change what song performers are dancing to, warp irregular motion into alignment with music so that it appears to be dancing, or search collections of video for moments of accidentally dance-like motion that can be used to synthesize musical performances.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:3u3nxgfnd-AC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2018,"An approach is provided for sending pre-defined workflows to a display device of a user device. In one example, the approach includes receiving a request for steps to complete a task associated with a software application. In response to receiving the request for steps, the system obtains at least a first workflow and a second workflow, each workflow including one or more steps that the user device can execute to complete the task. The system receives a request to format the first workflow and the second workflow into one or more view formats. The system generates a summary of the first workflow and a summary of the second workflow. Each summary includes one or more salient attributes of the each workflow. The system sends to the display device at least the first workflow and the second workflow in the one or more view formats.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:K0fIQ6b0NmsC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2018,"For cooking professionals and culinary students, understanding cooking instructions is an essential yet demanding task. Common tasks include categorizing different approaches to cooking a dish and identifying usage patterns of particular ingredients or cooking methods, all of which require extensive browsing and comparison of multiple recipes. However, no existing system provides support for such in-depth and at-scale analysis. We present RecipeScape, an interactive system for browsing and analyzing the hundreds of recipes of a single dish available online. We also introduce a computational pipeline that extracts cooking processes from recipe text and calculates a procedural similarity between them. To evaluate how RecipeScape supports culinary analysis at scale, we conducted a user study with cooking professionals and culinary students with 500 recipes for two different dishes. Results show that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:Y7HEs_YmcnEC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2018,"It can be difficult to understand physical measurements (e.g., 28 lb, 600 gallons) that appear in news stories, data reports, and other documents. We develop tools that automatically re-express unfamiliar measurements using the measurements of familiar objects. Our work makes three contributions: (1) we identify effectiveness criteria for objects used in concrete measurement re-expressions; (2) we operationalize these criteria in a scalable method for mining a large dataset of concrete familiar objects with their physical dimensions from Amazon and Wikipedia; and (3) we develop automated concrete re-expression tools that implement three common re-expression strategies (adding familiar context, reunitization and proportional analogy) as energy minimization algorithms. Crowdsourced evaluations of our tools indicate that people find news articles with re-expressions more helpful and re- expressions help them to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:V2uI0bKpj5cC,http://graphics.stanford.edu/~maneesh/
Maneesh Agrawala,"['Graphics', 'Computer Graphics', 'HCI', 'Visualization']",47,8232,2018,"Understanding how people explore immersive virtual environments is crucial for many applications, such as designing virtual reality (VR) content, developing new compression algorithms, or learning computational models of saliency or visual attention. Whereas a body of recent work has focused on modeling saliency in desktop viewing conditions, VR is very different from these conditions in that viewing behavior is governed by stereoscopic vision and by the complex interaction of head orientation, gaze, and other kinematic constraints. To further our understanding of viewing behavior and saliency in VR, we capture and analyze gaze and head orientation data of 169 users exploring stereoscopic, static omni-directional panoramas, for a total of 1980 head and gaze trajectories for three different viewing conditions. We provide a thorough analysis of our data, which leads to several important insights, such as the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=YPzKczYAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=YPzKczYAAAAJ:qqRC41JmxUcC,http://graphics.stanford.edu/~maneesh/
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2023,Implicitly parallel programming systems must solve the joint problems of dependence analysis and coherence to ensure apparently-sequential semantics for applications run on distributed memory machines. Solving these problems in the presence of data-dependent control flow and arbitrary aliasing is a challenge that most existing systems eschew by compromising the expressivity of their programming models and/or the performance of their implementations. We demonstrate a general class of solutions to these problems via a reduction to the visibility problem from computer graphics.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:Hck25ST_3aIC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2023,"When training deep neural networks, keeping all tensors in high precision (e.g., 32-bit or even 16-bit floats) is often wasteful. However, keeping all tensors in low precision (e.g., 8-bit floats) can lead to unacceptable accuracy loss. Hence, it is important to use a precision assignment -- a mapping from all tensors (arising in training) to precision levels (high or low) -- that keeps most of the tensors in low precision and leads to sufficiently accurate models. We provide a technique that explores this memory-accuracy tradeoff by generating precision assignments that (i) use less memory and (ii) lead to more accurate models at the same time, compared to the precision assignments considered by prior work in low-precision floating-point training. Our method typically provides > 2x memory reduction over a baseline precision assignment while preserving training accuracy, and gives further reductions by trading off accuracy. Compared to other baselines which sometimes cause training to diverge, our method provides similar or better memory reduction while avoiding divergence.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:silx2ntsSuwC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2023,"Recent work has shown that automatic differentiation over the reals is almost always correct in a mathematically precise sense. However, actual programs work with machine-representable numbers (e.g., floating-point numbers), not reals. In this paper, we study the correctness of automatic differentiation when the parameter space of a neural network consists solely of machine-representable numbers. For a neural network with bias parameters, we prove that automatic differentiation is correct at all parameters where the network is differentiable. In contrast, it is incorrect at all parameters where the network is non-differentiable, since it never informs non-differentiability. To better understand this non-differentiable set of parameters, we prove a tight bound on its size, which is linear in the number of non-differentiabilities in activation functions, and provide a simple necessary and sufficient condition for a parameter to be in this set. We further prove that automatic differentiation always computes a Clarke subderivative, even on the non-differentiable set. We also extend these results to neural networks possibly without bias parameters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:aIdbFUkbNIkC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"We present distributed task fusion, a run-time optimization for task-based runtimes operating on parallel and heterogeneous systems. Distributed task fusion dynamically performs an efficient buffering, analysis, and fusion of asynchronously-evaluated distributed operations, reducing the overheads inherent to scheduling distributed tasks in implicitly parallel frameworks and runtimes. We identify the constraints under which distributed task fusion is permissible and describe an implementation in Legate, a domain-agnostic library for constructing portable and scalable task-based libraries. We present performance results using cuNumeric, a Legate library that enables scalable execution of NumPy pipelines on parallel and heterogeneous systems. We realize speedups up to 1.5x with task fusion enabled on up to 32 P100 GPUs, thus demonstrating efficient execution of pipelines involving many successive fine-grained …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:PkcyUWeTMh0C,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"The computation of two-electron repulsion integrals (ERIs) is often the most expensive step of integral-direct self-consistent field methods. Formally it scales as O(N4), where N is the number of Gaussian basis functions used to represent the molecular wave function. In practice, this scaling can be reduced to O(N2) or less by neglecting small integrals with screening methods. The contributions of the ERIs to the Fock matrix are of Coulomb (J) and exchange (K) type and require separate algorithms to compute matrix elements efficiently. We previously implemented highly efficient GPU-accelerated J-matrix and K-matrix algorithms in the electronic structure code TeraChem. Although these implementations supported the use of multiple GPUs on a node, they did not support the use of multiple nodes. This presents a key bottleneck to cutting-edge ab initio simulations of large systems, e.g., excited state dynamics of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:TlpoogIpr_IC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"Anomalous behaviour in subsystems of complex machines often affect overall performance even without failures. We devise unsupervised methods to detect times with degraded performance, and localize correlated signals, evaluated on a system with over 4000 monitored signals. From incidents comprising both downtimes and degraded performance, our approach localizes relevant signals within 1.2% of the parameter space.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:wvYxNZNCP7wC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"The first paper describing the Legion programming model was published in 2012 [BTSA12]. Since then, there has been enormous progress and many people have contributed to the project. Throughout this period new application developers have learned Legion through a combination of examples, lore from other members of the project, research papers and reading the source code of the Legion implementation. The intention here is to put down in a systematic fashion what a programmer who wants to use Legion to develop high performance applications needs to know. This book is intended to be a combination tutorial, rationale and manual. The first part is the tutorial and rationale, laying out in some detail what Legion is and why it is that way. The second part is the manual, which describes each of the API calls for the Legion C++ runtime. The example programs and configuration files referred to in this book can be found in the directory Examples/included in the Legion distribution. This book is incomplete and will remain incomplete for some time to come. But on the theory that partial documentation is better than no documentation, the manual is being made available while it is still in progress in the hope that it will be useful to new Legion programmers. Please report any errors or other issues to aiken@ cs. stanford. edu.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:DrR-2ekChdkC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"We introduce SpDISTAL, a compiler for sparse tensor algebra that targets distributed systems. SpDISTAL combines separate descriptions of tensor algebra expressions, sparse data structures, data distribution, and computation distribution. Thus, it enables distributed execution of sparse tensor algebra expressions with a wide variety of sparse data structures and data distributions. SpDISTAL is implemented as a C++ library that targets a distributed task-based runtime system and can generate code for nodes with both multi-core CPUs and multiple GPUs. SpDISTAL generates distributed code that achieves performance competitive with hand-written distributed functions for specific sparse tensor algebra expressions and that outperforms general interpretation-based systems by one to two orders of magnitude.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:eO3_k5sD8BwC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"Existing quantum compilers optimize quantum circuits by applying circuit transformations designed by experts. This approach requires significant manual effort to design and implement circuit transformations for different quantum devices, which use different gate sets, and can miss optimizations that are hard to find manually. We propose Quartz, a quantum circuit superoptimizer that automatically generates and verifies circuit transformations for arbitrary quantum gate sets. For a given gate set, Quartz generates candidate circuit transformations by systematically exploring small circuits and verifies the discovered transformations using an automated theorem prover. To optimize a quantum circuit, Quartz uses a cost-based backtracking search that applies the verified transformations to the circuit. Our evaluation on three popular gate sets shows that Quartz can effectively generate and verify transformations for different …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:sszUF3NjhM4C,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"We introduce DISTAL, a compiler for dense tensor algebra that targets modern distributed and heterogeneous systems. DISTAL lets users independently describe how tensors and computation map onto target machines through separate format and scheduling languages. The combination of choices for data and computation distribution creates a large design space that includes many algorithms from both the past (e.g., Cannon’s algorithm) and the present (e.g., COSMA). DISTAL compiles a tensor algebra domain specific language to a distributed task-based runtime system and supports nodes with multi-core CPUs and multiple GPUs. Code generated by is competitive with optimized codes for matrix multiply on 256 nodes of the Lassen supercomputer and outperforms existing systems by between 1.8x to 3.7x (with a 45.7x outlier) on higher order tensor operations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:NDuN12AVoxsC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"The Mixture of Experts architecture allows for outrageously large neural networks by scaling model parameter size independently from computational demand (FLOPs). However, current DNN frameworks cannot effectively support the dynamic data flow in Mixture of Experts, and implementations on top of these frameworks need to use workarounds that introduce significant overheads. To address the limitation of these frameworks, we present DynaMoE, a DNN library that uses dynamic recompilations to optimize and adapt the use of computational resources to the dynamic needs of Mixture of Experts models. Our evaluation shows that DynaMoE achieves a 1.8x speedup and supports 2.3x larger model sizes when compared to existing MoE systems, even when not using recompilations. We then present further optimizations enabled by dynamic recompilations that yield an additional 1.7x speedup while simultaneously reducing memory pressure and improving model quality.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:RoXSNcbkSzsC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"We present a PDR/IC3 algorithm for finding inductive invariants with quantifier alternations. We tackle scalability issues that arise due to the large search space of quantified invariants by combining a breadth-first search strategy and a new syntactic form for quantifier-free bodies. The breadth-first strategy prevents inductive generalization from getting stuck in regions of the search space that are expensive to search and focuses instead on lemmas that are easy to discover. The new syntactic form is well-suited to lemmas with quantifier alternations by allowing both limited conjunction and disjunction in the quantifier-free body, while carefully controlling the size of the search space. Combining the breadth-first strategy with the new syntactic form results in useful inductive bias by prioritizing lemmas according to: (i) well-defined syntactic metrics for simple quantifier structures and quantifier-free bodies, and (ii) the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:jFemdcug13IC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"Fundamental trends in computer architecture predict that nearly all aspects of future high-performance computing (HPC) architectures will have many more diverse components than past systems, leading toward a period of extreme heterogeneity (EH). The HPC community has already seen evidence of this trend [1, 2, 7, 9, 12, 15, 70]. In 2009, the drive to deploy more energy-efficient computers led the Oak Ridge Leadership Computing Facility (OLCF) to propose a system upgrade, composed of CPUs (central processing units) coupled with GPUs (graphics processing units), that firmly established an era of heterogeneous HPC across the Department of Energy (DOE). Continuing this trend, both recently deployed CORAL systems, Summit and Sierra—selected by OLCF and Lawrence Livermore National Laboratory, respectively—are composed of CPUs coupled with multiple GPUs and three types of memory. This trend is also manifested in the most recent TOP500 list: heterogeneous accelerators are used in 110 TOP500 systems and the majority of the TOP10 systems. Furthermore, a recent analysis of vendors’ current architectural roadmaps is consistent with the extreme heterogeneity that the Advanced Scientific Computing Research (ASCR) program is seeing in its computing upgrades. It indicates that future computers will be more complex and will be composed of a variety of processing units and specialized accelerators supported by open interconnects and deep memory hierarchies. Looking forward, we expect even more diverse accelerators for paradigms like machine learning, neuromorphic computing, and quantum computing.
Several …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:6yz0xqPARnAC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"Many invariant inference techniques reason simultaneously about states and predicates, and it is well-known that these two kinds of reasoning are in some sense dual to each other. We present a new formal duality between states and predicates, and use it to derive a new primal-dual invariant inference algorithm. The new induction duality is based on a notion of provability by incremental induction that is formally dual to reachability, and the duality is surprisingly symmetric. The symmetry allows us to derive the dual of the well-known Houdini algorithm, and by combining Houdini with its dual image we obtain primal-dual Houdini, the first truly primal-dual invariant inference algorithm. An early prototype of primal-dual Houdini for the domain of distributed protocol verification can handle difficult benchmarks from the literature.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:q-HalDI95KYC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"This paper presents Unity, the first system that jointly optimizes algebraic transformations and parallelization in distributed DNN training. Unity represents both parallelization and algebraic transformations as substitutions on a unified parallel computation graph (PCG), which simultaneously expresses the computation, parallelization, and communication of a distributed DNN training procedure.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:2l5NCbZemmgC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2022,"We introduce Programmatic Motion Concepts, a hierarchical motion representation for human actions that captures both low level motion and high level description as motion concepts. This representation enables human motion description, interactive editing, and controlled synthesis of novel video sequences within a single framework. We present an architecture that learns this concept representation from paired video and action sequences in a semi-supervised manner. The compactness of our representation also allows us to present a low-resource training recipe for data-efficient learning. By outperforming established baselines, especially in small data regime, we demonstrate the efficiency and effectiveness of our framework for multiple applications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:mKu_rENv82IC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2021,"Existing quantum compilers focus on mapping a logical quantum circuit to a quantum device and its native quantum gates. Only simple circuit identities are used to optimize the quantum circuit during the compilation process. This approach misses more complex circuit identities, which could be used to optimize the quantum circuit further. We propose Quanto, the first quantum optimizer that automatically generates circuit identities. Quanto takes as input a gate set and generates provably correct circuit identities for the gate set. Quanto's automatic generation of circuit identities includes single-qubit and two-qubit gates, which leads to a new database of circuit identities, some of which are novel to the best of our knowledge. In addition to the generation of new circuit identities, Quanto's optimizer applies such circuit identities to quantum circuits and finds optimized quantum circuits that have not been discovered by other quantum compilers, including IBM Qiskit and Cambridge Quantum Computing Tket. Quanto's database of circuit identities could be applied to improve existing quantum compilers and Quanto can be used to generate identity databases for new gate sets.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:AXkvAH5U_nMC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2021,"It's common to see specialized language constructs in modern task-based programming systems for reasoning about groups of independent tasks intended for parallel execution. However, most systems use an ad-hoc representation that limits expressiveness and often overfits for a given application domain. We introduce index launches, a scalable and flexible representation of a group of tasks. Index launches use a flexible mechanism to indicate the data required for a given task, allowing them to be used for a much broader set of use cases while maintaining an efficient representation. We present a hybrid design for index launches, involving static and dynamic program analyses, along with a characterization of how they're used in Legion and Regent, and show how they generalize constructs found in other task-based systems. Finally, we present results of scaling experiments which demonstrate that index …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:SjuI4pbJlxcC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2021,"We consider the problem of program synthesis from input-output examples via stochastic search. We identify a robust feature of stochastic synthesis: The search often progresses through a series of discrete plateaus. We observe that the distribution of synthesis times is often heavy-tailed and analyze how these distributions arise. Based on these insights, we present an algorithm that speeds up synthesis by an order of magnitude over the naive algorithm currently used in practice. Our experimental results are obtained in part using a new program synthesis benchmark for superoptimization distilled from widely used production code.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:1yWc8FF-_SYC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2021,"The DARPA FastNICs program targets orders of magnitude improvement in applications such as deep learning training by making radical improvements to network performance: While raw bandwidth has grown dramatically, the fundamental roadblock to application performance has been in delivering that data to the application. FLEET provides a primarily off-the-shelf solution with high-end servers and shared computational and storage resources connected via PCIe over a reconfigurable MEMS optical switch; it uses custom Optical NICs to allow arbitrary topologies that can be configured before or even during execution to take advantage of shared resources and to flow data between components. FLEET 's software is derived from Stanford Legion, which we are modifying to use the FLEET hardware and to plan application execution for these dynamic network topologies.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:LPtt_HFRSbwC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2021,"We present dynamic control replication, a run-time program analysis that enables scalable execution of implicitly parallel programs on large machines through a distributed and efficient dynamic dependence analysis. Dynamic control replication distributes dependence analysis by executing multiple copies of an implicitly parallel program while ensuring that they still collectively behave as a single execution. By distributing and parallelizing the dependence analysis, dynamic control replication supports efficient, on-the-fly computation of dependences for programs with arbitrary control flow at scale. We describe an asymptotically scalable algorithm for implementing dynamic control replication that maintains the sequential semantics of implicitly parallel programs.
An implementation of dynamic control replication in the Legion runtime delivers the same programmer productivity as writing in other implicitly parallel …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:jU7OWUQzBzMC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2021,"Current approaches to video analysis of human motion focus on raw pixels or keypoints as the basic units of reasoning. We posit that adding higher-level motion primitives, which can capture natural coarser units of motion such as backswing or follow-through, can be used to improve downstream analysis tasks. This higher level of abstraction can also capture key features, such as loops of repeated primitives, that are currently inaccessible at lower levels of representation. We therefore introduce Motion Programs, a neuro-symbolic, program-like representation that expresses motions as a composition of high-level primitives. We also present a system for automatically inducing motion programs from videos of human motion and for leveraging motion programs in video synthesis. Experiments show that motion programs can accurately describe a diverse set of human motions and the inferred programs contain semantically meaningful motion primitives, such as arm swings and jumping jacks. Our representation also benefits downstream tasks such as video interpolation and video prediction and outperforms off-the-shelf models. We further demonstrate how these programs can detect diverse kinds of repetitive motion and facilitate interactive video editing.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:3NQIlFlcGxIC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2021,"View Video Presentation: https://doi.org/10.2514/6.2021-0140.vid
This work discusses the development, verification and performance assessment of a discontinuous Galerkin solver for the compressible Navier-Stokes equations using the Legion programming system. This is motivated by (i) the potential of this family of high-order numer- ical methods to accurately and efficiently realize scale-resolving simulations on unstructured grids and (ii) the desire to accommodate the utilization of emerging compute platforms that exhibit increased parallelism and heterogeneity. As a task-based programming model specifically designed for performance portability across distributed heterogeneous architectures, Legion represents an interesting lternative to the traditional approach of using Message Passing Interface for massively parallel computational physics solvers. Following detailed discussion of the implementation, the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:CB2v5VPnA5kC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2020,"We present Task Bench, a parameterized benchmark designed to explore the performance of distributed programming systems under a variety of application scenarios. Task Bench dramatically lowers the barrier to benchmarking and comparing multiple programming systems by making the implementation for a given system orthogonal to the benchmarks themselves: every benchmark constructed with Task Bench runs on every Task Bench implementation. Furthermore, Task Bench's parameterization enables a wide variety of benchmark scenarios that distill the key characteristics of larger applications. To assess the effectiveness and overheads of the tested systems, we introduce a novel metric, minimum effective task granularity (METG). We conduct a comprehensive study with 15 programming systems on up to 256 Haswell nodes of the Cori supercomputer. Running at scale, 100μs-long tasks are the finest …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:jgBuDB5drN8C,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2020,"Graph Neural Networks (GNNs) are based on repeated aggregations of information from nodes' neighbors in a graph. However, because nodes share many neighbors, a naive implementation leads to repeated and inefficient aggregations and represents significant computational overhead. Here we propose Hierarchically Aggregated computation Graphs(HAGs), a new GNN representation technique that explicitly avoids redundancy by managing intermediate aggregation results hierarchically and eliminates repeated computations and unnecessary data transfers in GNN training and inference. HAGs perform the same computations and give the same models/accuracy as traditional GNNs, but in a much shorter time dueto optimized computations. To identify redundant computations,we introduce an accurate cost function and use a novel search algorithm to find optimized HAGs. Experiments show that the HAG …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:WC23djZS0W4C,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2020,"Quantified first-order formulas, often with quantifier alternations, are increasingly used in the verification of complex systems. While automated theorem provers for first-order logic are becoming more robust, invariant inference tools that handle quantifiers are currently restricted to purely universal formulas. We define and analyze first-order quantified separators and their application to inferring quantified invariants with alternations. A separator for a given set of positively and negatively labeled structures is a formula that is true on positive structures and false on negative structures. We investigate the problem of finding a separator from the class of formulas in prenex normal form with a bounded number of quantifiers and show this problem is NP-complete by reduction to and from SAT. We also give a practical separation algorithm, which we use to demonstrate the first invariant inference procedure able to infer …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:kw52XkFRtyQC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2020,"Graph neural networks (GNNs) have been demonstrated to be an effective model for learning tasks related to graph structured data. Different from classical deep neural networks which handle relatively small individual samples, GNNs process very large graphs, which must be partitioned and processed in a distributed manner. We present Roc, a distributed multi-GPU framework for fast GNN training and inference on graphs. Roc is up to 4.6 x faster than existing GNN frameworks on a single machine, and can scale to multiple GPUs on multiple machines. This performance gain is mainly enabled by Roc's graph partitioning and memory management optimizations. Besides performance acceleration, the better scalability of Roc also enables the exploration of more sophisticated GNN architectures on large, real-world graphs. We demonstrate that a class of GNN architectures significantly deeper and larger than the typical two-layer models can achieve new state-of-the-art classification accuracy on the widely used Reddit dataset.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:1taIhTC69MYC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2020,"Hall′ s condition on a finite simple graph equipped with a vertex list assignment and a” color demand” function is a necessary condition for the existence of a proper vertex multicoloring satisfying certain requirements. Hall′ s t-condition is Hall’s condition particularized to the cases when the list assignment is constant. A graph is Hall tchromatic if, for every color demand function on it, the satisfying of Hall’s t-condition suffices for the existence of a proper multicoloring of the graph, satisfying the demand, from a fixed list of t colors. It is known that all (finite, simple) graphs are Hall tchromatic for each t∈{0, 1, 2}, and there is a class of graphs, including the odd wheels except for W3= K4, each of which is Hall t-chromatic only for t∈{0, 1, 2}. We show that the Petersen graph is Hall 3-chromatic. Also, by adding a requirement to Hall’s t-condition, we define weak Hall t-chromaticity and determine for each odd wheel the values of t for which the wheel is weakly Hall t-chromatic.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:hsZV8lGYWTMC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2020,"The study of thermal radiation interacting with particle-laden turbulence is of great importance in a wide range of scientific and engineering applications. The computational study of such systems is challenging as a result of the large number of thermo-fluid mechanisms governing the underlying physics. To build confidence and improve the prediction accuracy of such simulations, the impact of uncertainties on the quantities of interest must be measured. This, however, requires a computational budget that is typically a large multiple of the cost of a single calculation, and thus may become infeasible for expensive simulation models featuring a large number of uncertain inputs and highly nonlinear behavior. In this regard, multifidelity methods have become increasingly popular in recent years as acceleration strategies to reduce the computational cost. These methods are based on a hierarchy of generalized numerical …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:wKETBy42zhYC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"Dynamic languages provide the flexibility needed to implement expressive support for task-based parallel programming constructs. We present Pygion, a Python interface for the Legion task-based programming system, and show that it can provide features comparable to Regent, a statically typed programming language with dedicated support for the Legion programming model. Furthermore, we show that the dynamic nature of Python permits the implementation of several key optimizations (index launches, futures, mapping) currently implemented in the Regent compiler. Together these features enable Pygion code that is comparable in expressiveness but more flexible than Regent, and substantially more concise, less error prone, and easier to use than C++ Legion code. Pygion is designed to interoperate with Regent and can use Regent to generate high- performance CPU and GPU kernel implementations. We …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:kVjdVfd2voEC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"Although data partitioning is required to enable parallelism on distributed memory systems, data partitions are not first class objects in most distributed programming models. As a result, automatic parallelizers and application writers encode a particular partitioning strategy in the parallelized program, leading to a program not easily configured or composed with other parallel programs.
We present a constraint-based approach to automatic data partitioning. By introducing abstractions for first-class data partitions, we express a space of correct partitioning strategies. Candidate partitions are characterized by partitioning constraints, which can be automatically inferred from data accesses in parallelizable loops. Constraints can be satisfied by synthesized partitioning code or user-provided partitions. We demonstrate that programs auto-parallelized in our approach are easily composed with manually parallelized parts …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:43bX7VzcjpAC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"High-order discontinuous Galerkin (DG) methods have emerged as attractive techniques for simulating complex flows. In particular, these methods combine features of variational finite-element methods with finite-volume discretizations, thereby (i) allowing for arbitrarily high order of accuracy,(ii) enabling the discretization of complex geometries on irregular meshes,(iii) providing advanced refinement strategies, and (iv) the large degree of structured computations and data locality introduce a high level of parallelism, making these methods particularly suitable for high-performance computing on exascale machines. This presentation will discuss recent advancements on developing high-order DG-methods for complex flows that involve chemical reactions and multiphase flows. Following a theoretic consideration of performance gains of high-order schemes on exascale systems, we will discuss algorithmic …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:v1_lew4L6wgC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"The study of complex multiphysics turbulent flows is commonly based on intensive computational high-fidelity simulations. To build confidence and improve their prediction accuracy, very large computational budgets are typically required to characterize the impact of uncertainties on the quantities of interest. In this regard, multifidelity methods have become increasingly popular in the last years as acceleration strategies. Exascale computing resources promise to facilitate the use of these approaches on larger scale problems by providing 1-10k times augmented floating-point capacity, but at expenses of requiring more complex data management as memory is expected to become more heterogeneous and distributed. The objective of this work, therefore, is to explore the performance of multifidelity ensemble-based strategies in large-scale multiphysics applications using an Exascale-ready computational framework.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:U4n9YNQMCAIC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"Direct numerical simulations of multi-stage ignition in low-temperature surrogate diesel jets is used to studyturbulence-chemistry'interactions governing cool flame propagation and turbulent diffusion and their role in accelerating low-and high-temperature ignition. The effects of varying the ambient temperature and oxygen concentration on mixture formation and combustion processes is quantified. Conditional statistics are presented showing the significance of turbulent diffusion relative to laminar flame propagation. These simulations are enabled by an asynchronous task-based programming model and runtime, Legion, which is used to obtain scalable performance of the Legion-S3D DNS code on Summit at the Oakridge Leadership Computing Facility. The Legion runtime is able to hide the memory latency by overlapping communication and computation and to optimize data movement. Refactoring Legion-S3D in …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:BzfGm06jWhQC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"Existing deep neural network (DNN) frameworks optimize the computation graph of a DNN by applying graph transformations manually designed by human experts. This approach misses possible graph optimizations and is difficult to scale, as new DNN operators are introduced on a regular basis.
We propose TASO, the first DNN computation graph optimizer that automatically generates graph substitutions. TASO takes as input a list of operator specifications and generates candidate substitutions using the given operators as basic building blocks. All generated substitutions are formally verified against the operator specifications using an automated theorem prover. To optimize a given DNN computation graph, TASO performs a cost-based backtracking search, applying the substitutions to find an optimized graph, which can be directly used by existing DNN frameworks.
Our evaluation on five real-world DNN …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:zCSUwVk65WsC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"Graph Neural Networks (GNNs) are based on repeated aggregations of information across nodes' neighbors in a graph. However, because common neighbors are shared between different nodes, this leads to repeated and inefficient computations. We propose Hierarchically Aggregated computation Graphs (HAGs), a new GNN graph representation that explicitly avoids redundancy by managing intermediate aggregation results hierarchically, eliminating repeated computations and unnecessary data transfers in GNN training and inference. We introduce an accurate cost function to quantitatively evaluate the runtime performance of different HAGs and use a novel HAG search algorithm to find optimized HAGs. Experiments show that the HAG representation significantly outperforms the standard GNN graph representation by increasing the end-to-end training throughput by up to 2.8x and reducing the aggregations and data transfers in GNN training by up to 6.3x and 5.6x, while maintaining the original model accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:ALROH1vI_8AC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"We introduce a robust semantics-driven technique for program equivalence checking. Given two functions we find a trace alignment over a set of concrete executions of both programs and construct a product program particularly amenable to checking equivalence.
We demonstrate that our algorithm is applicable to challenging equivalence problems beyond the scope of existing techniques. For example, we verify the correctness of the hand-optimized vector implementation of strlen that ships as part of the GNU C Library, as well as the correctness of vectorization optimizations for 56 benchmarks derived from the Test Suite for Vectorizing Compilers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:lgwcVrK6X84C,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"Existing deep learning frameworks optimize the computation graph of a DNN model by performing greedy rule-based graph transformations, which generally only consider transformations that strictly improve runtime performance. We propose relaxed graph substitutions that enable the exploration of complex graph optimizations by relaxing the strict performance improvement constraint, which greatly increases the space of semantically equivalent computation graphs that can be discovered by repeated application of a suitable set of graph transformations. We introduce a backtracking search algorithm over a set of relaxed graph substitutions to find optimized networks and use a flow-based graph split algorithm to recursively split a computation graph into smaller subgraphs to allow efficient search. We implement relaxed graph substitutions in a system called MetaFlow and show that MetaFlow improves the inference and training performance by 1.1-1.6× and 1.1-1.2× respectively over existing deep learning frameworks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:48xauSegjOkC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"Existing deep learning systems commonly parallelize deep neural network (DNN) training using data or model parallelism, but these strategies often result in suboptimal parallelization performance. We introduce SOAP, a more comprehensive search space of parallelization strategies for DNNs that includes strategies to parallelize a DNN in the Sample, Operator, Attribute, and Parameter dimensions. We present FlexFlow, a deep learning engine that uses guided randomized search of the SOAP space to find a fast parallelization strategy for a specific parallel machine. To accelerate this search, FlexFlow introduces a novel execution simulator that can accurately predict a parallelization strategy’s performance and is three orders of magnitude faster than prior approaches that execute each strategy. We evaluate FlexFlow with six real-world DNN benchmarks on two GPU clusters and show that FlexFlow increases training throughput by up to 3.3× over state-of-the-art approaches, even when including its search time, and also improves scalability.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:F1b5ZUV5XREC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:FiytvqdAVhgC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"The Predictive Science Academic Alliance Program (PSAAP) II at Stanford University is developing an exascale-ready multi-physics solver to investigate particle-laden turbulent flows in a radiation environment for solar energy receiver applications. In order to simulate the proposed concentrated particle-based receiver design three distinct but coupled physical phenomena must be modeled: fluid flows, Lagrangian particle dynamics, and the transport of thermal radiation. Therefore, three different physics solvers (fluid, particles, and radiation) must run concurrently with significant cross-communication in an integrated multi-physics simulation. However, each solver uses substantially different algorithms and data access patterns. Coordinating the overall data communication, computational load balancing, and scaling these different physics solvers together on modern massively parallel, heterogeneous high performance computing systems presents several major challenges. We have adopted the Legion programming system, via the Regent programming language, and its task parallel programming model to address these challenges. Our multi-physics solver Soleil-X is written entirely in the high level Regent programming language and is one of the largest and most complex applications written in Regent to date. At this workshop we will give an overview of the software architecture of Soleil-X as well as discuss how our multi-physics solver was designed to use the task parallel programming model provided by Legion. We will also discuss the development experience, scaling, performance, portability, and multi-physics simulation results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:PaBasH6fAo0C,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"Static analyses make the increasingly tenuous assumption that all source code is available for analysis; for example, large libraries often call into native code that cannot be analyzed. We propose a points-to analysis that initially makes optimistic assumptions about missing code, and then inserts runtime checks that report counterexamples to these assumptions that occur during execution. Our approach guarantees eventual soundness, which combines two guarantees:(i) the runtime checks are guaranteed to catch the first counterexample that occurs during any execution, in which case execution can be terminated to prevent harm, and (ii) only finitely many counterexamples ever occur, implying that the static analysis eventually becomes statically sound with respect to all remaining executions. We implement Optix, an eventually sound points-to analysis for Android apps, where the Android framework is missing. We show that the runtime checks added by Optix incur low overhead on real programs, and demonstrate how Optix improves a client information flow analysis for detecting Android malware.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:ubry08Y2EpUC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2019,"We consider the task of mapping pseudocode to executable code, assuming a one-to-one correspondence between lines of pseudocode and lines of code. Given test cases as a mechanism to validate programs, we search over the space of possible translations of the pseudocode to find a program that compiles and passes the test cases. While performing a best-first search, compilation errors constitute 88.7% of program failures. To better guide this search, we learn to predict the line of the program responsible for the failure and focus search over alternative translations of the pseudocode for that line. For evaluation, we collected the SPoC dataset (Search-based Pseudocode to Code) containing 18,356 C++ programs with human-authored pseudocode and test cases. Under a budget of 100 program compilations, performing search improves the synthesis success rate over using the top-one translation of the pseudocode from 25.6% to 44.7%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:1lhNe0rCu4AC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2018,"In this paper, we rigorously verify the correctness of dynamic dependence analysis, a key algorithm for parallelizing programs in implicitly parallel tasking systems. A dynamic dependence analysis of a program results in a task graph, a DAG of tasks constraining the order of task execution. Because a program is automatically parallelized based on its task graph, the analysis algorithm must generate a graph with all the dependencies that are necessary to preserve the program's original semantics for any non-deterministic parallel execution of tasks. However, this correctness is not straightforward to verify as implicitly parallel tasking systems often use an optimized dependence analysis algorithm. To study the correctness of dynamic dependence analysis in a realistic setting, we design a model algorithm that captures the essence of realistic analysis algorithms. We prove that this algorithm constructs task graphs that …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:4X0JR2_MtJMC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2018,"Many recent programming systems for both supercomputing and data center workloads generate task graphs to express computations that run on parallel and distributed machines. Due to the overhead associated with constructing these graphs the dependence analysis that generates them is often statically computed and memoized, and the resulting graph executed repeatedly at runtime. However, many applications require a dynamic dependence analysis due to data dependent behavior, but there are new challenges in capturing and re- executing task graphs at runtime. In this work, we introduce dynamic tracing, a technique to capture a dynamic dependence analysis of a trace that generates a task graph, and replay it. We show that an implementation of dynamic tracing improves strong scaling by an average of 4.9× and up to 7.0× on a suite of already optimized benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:AHdEip9mkN0C,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2018,"The past few years have witnessed growth in the computational requirements for training deep convolutional neural networks. Current approaches parallelize training onto multiple devices by applying a single parallelization strategy (eg, data or model parallelism) to all layers in a network. Although easy to reason about, these approaches result in suboptimal runtime performance in largescale distributed training, since different layers in a network may prefer different parallelization strategies. In this paper, we propose layer-wise parallelism that allows each layer in a network to use an individual parallelization strategy. We jointly optimize how each layer is parallelized by solving a graph search problem. Our evaluation shows that layer-wise parallelism outperforms state-of-the-art approaches by increasing training throughput, reducing communication costs, achieving better scalability to multiple GPUs, while maintaining original network accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:Ehil0879vHcC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2018,"The past few years have witnessed growth in the computational requirements for training deep convolutional neural networks. Current approaches parallelize training onto multiple devices by applying a single parallelization strategy (eg, data or model parallelism) to all layers in a network. Although easy to reason about, these approaches result in suboptimal runtime performance in large-scale distributed training, since different layers in a network may prefer different parallelization strategies. In this paper, we propose layer-wise parallelism that allows each layer in a network to use an individual parallelization strategy. We jointly optimize how each layer is parallelized by solving a graph search problem. Our evaluation shows that layer-wise parallelism outperforms state-of-the-art approaches by increasing training throughput, reducing communication costs, achieving better scalability to multiple GPUs, while maintaining original network accuracy.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:BJbdYPG6LGMC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2018,"Data transfers in parallel systems have a significant impact on the performance of applications. Most existing systems generally support only data transfers between memories with a direct hardware connection and have limited facilities for handling transformations to the data's layout in memory. As a result, to move data between memories that are not directly connected, higher levels of the software stack must explicitly divide a multi-hop transfer into a sequence of single-hop transfers and decide how and where to perform data layout conversions if needed. This approach results in inefficiencies, as the higher levels lack enough information to plan transfers as a whole, while the lower level that does the transfer sees only the individual single-hop requests.
We present Isometry, a path-based distributed data transfer system. The Isometry path planner selects an efficient path for a transfer and submits it to the Isometry …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:5MTHONV0fEkC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2018,"When analyzing programs, large libraries pose significant challenges to static points-to analysis. A popular solution is to have a human analyst provide points-to specifications that summarize relevant behaviors of library code, which can substantially improve precision and handle missing code such as native code. We propose Atlas, a tool that automatically infers points-to specifications. Atlas synthesizes unit tests that exercise the library code, and then infers points-to specifications based on observations from these executions. Atlas automatically infers specifications for the Java standard library, and produces better results for a client static information flow analysis on a benchmark of 46 Android apps compared to using existing handwritten specifications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:HtS1dXgVpQUC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2018,"The placement and movement of data is becoming the key limiting factor on both performance and energy efficiency of high performance computations. As systems generate more data, it is becoming increasingly difficult to actually move that data elsewhere for post-processing, as the rate of improvements in supporting I/O infrastructure is not keeping pace. Together, these trends are creating a shift in how we think about exascale computations, from a viewpoint that focuses on FLOPS to one that focuses on data and data-centric operations as fundamental to the reasoning about, and optimization of, scientific workflows on extreme-scale architectures. The overarching goal of our effort was the study of a unified data-driven approach for programming applications and in situ analysis and visualization. Our work was to understand the interplay between data-centric programming model requirements at extreme-scale and the overall impact of those requirements on the design, capabilities, flexibility, and implementation details for both applications and the supporting in situ infrastructure. In this context, we made many improvements to the Legion programming system (one of the leading data-centric models today) and demonstrated in situ analyses on real application codes using these improvements.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:LgRImbQfgY4C,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:8xutWZnSdmoC,http://theory.stanford.edu/~aiken
Alex Aiken,"['programming languages', 'compilers', 'verification', 'parallelism']",42,7284,2018,"Providing a software environment that can overcome the complexities of changes in how future supercomputers will be designed plays a key role in improving the nation’s rate of scientific discovery and innovation. In the past three decades, advances in computer technology have allowed the performance and functionality of processors to double every 2 years. This trend, known as Moore’s Law, has enabled both computational and experimental science to leverage the so far unending growth of the broad computing industry with very little change to the supporting software environment. But as computer chip manufacturing techniques reach the limits of the atomic scale, this era of predictable improvements is ending. This shift will have a significant impact on the design of high-performance computers, as well as the established software infrastructure required to effectively utilize the nation’s Leadership Computing Facilities. Computer vendors are pursuing systems built from combinations of different types of processors to improve capabilities, boost performance, and meet energy efficiency goals. Some of the most current supercomputers do not rely on a single type of processor but instead have added computational accelerators to meet the growing demands of increasingly complex computational workloads. According to studies from the US Department of Energy (DOE) Office of Science Advanced Scientific Computing Research program, several types of special-purpose accelerated processing units are currently under development and will play a huge role in the future of computer architectures. It is also likely that these processors will be …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3vKjkoQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=3vKjkoQAAAAJ:WHdLCjDvYFkC,http://theory.stanford.edu/~aiken
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2022,"We design fast algorithms for repeatedly sampling from strongly Rayleigh distributions, which include as special cases random spanning tree distributions and determinantal point processes. For a graph , we show how to approximately sample uniformly random spanning trees from G in 1 time per sample after an initial time preprocessing. This is the first nearly-linear runtime in the output size, which is clearly optimal. For a determinantal point process on k-sized subsets of a ground set of n elements, defined via an kernel matrix, we show how to approximately sample in time after an initial time preprocessing, where is the matrix multiplication exponent. The time to compute just the weight of the output set is simply , a natural barrier that suggests our runtime might be optimal for determinantal point processes as well. As a corollary, we even improve the state of the art for obtaining a single sample from a determinantal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:bFI3QPDXJZMC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2022,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:70eg2SAEIzsC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2022,"We establish a connection between sampling and optimization on discrete domains. For a family of distributions defined on size subsets of a ground set of elements, that is closed under external fields, we show that rapid mixing of natural local random walks implies the existence of simple approximation algorithms to find . More precisely, we show that if -step down-up random walks have spectral gap at least inverse polynomially large, then -step local search finds within a factor of . As the main application of our result, we show that -step local search achieves a nearly-optimal -factor approximation for MAP inference on nonsymmetric -DPPs. This is the first nontrivial multiplicative approximation algorithm for this problem. In our main technical result, we show that an exchange inequality, a concept rooted in discrete convex analysis, can be derived from fast mixing of local random walks. We further advance the state of the art on the mixing of random walks for nonsymmetric DPPs and more generally sector-stable distributions, by obtaining the tightest possible bound on the step size needed for polynomial-time mixing of random walks. We bring the step size down by a factor of compared to prior works, and consequently get a quadratic improvement on the runtime of local search steps; this improvement is potentially of independent interest in sampling applications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:zA6iFVUQeVQC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2022,"We introduce a notion called entropic independence that is an entropic analog of spectral notions of high-dimensional expansion. Informally, entropic independence of a background distribution µ on k-sized subsets of a ground set of elements says that for any (possibly randomly chosen) set S, the relative entropy of a single element of S drawn uniformly at random carries at most O(1/k) fraction of the relative entropy of S. Entropic independence is the analog of the notion of spectral independence, if one replaces variance by entropy. We use entropic independence to derive tight mixing time bounds, overcoming the lossy nature of spectral analysis of Markov chains on exponential-sized state spaces.
In our main technical result, we show a general way of deriving entropy contraction, a.k.a. modified log-Sobolev inequalities, for down-up random walks from spectral notions. We show that spectral independence of a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:_xSYboBqXhAC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2022,"We study parallel sampling algorithms for classes of distributions defined via determinants: symmetric, nonsymmetric, and partition-constrained determinantal point processes. For these distributions, counting, a.k.a. computing the partition function, can be reduced to a simple determinant computation which is highly parallelizable; Csanky proved it is in NC. However, parallel counting does not automatically translate to parallel sampling, as the classic reductions between sampling and counting are inherently sequential. Despite this, we show that for all the aforementioned determinant-based distributions, a roughly quadratic parallel speedup over sequential sampling can be achieved. If the distribution is supported on subsets of size of a ground set, we show how to approximately produce a sample in time with polynomially many processors for any . In the special case of symmetric determinantal point processes, our bound improves to and we show how to sample exactly in this case. We obtain our results via a generic sampling-to-counting reduction that uses approximate rejection sampling. As our main technical contribution, we show that whenever a distribution satisfies a certain form of high-dimensional expansion called entropic independence, approximate rejection sampling can achieve a roughly quadratic speedup in sampling via counting. Various forms of high-dimensional expansion, including the notion of entropic independence we use in this work, have been the source of major breakthroughs in sampling algorithms in recent years; thus we expect our framework to prove useful in the future for distributions beyond …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:f2IySw72cVMC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2022,"Learning from human feedback has shown to be a useful approach in acquiring robot reward functions. However, expert feedback is often assumed to be drawn from an underlying unimodal reward function. This assumption does not always hold including in settings where multiple experts provide data or when a single expert provides data for different tasks—we thus go beyond learning a unimodal reward and focus on learning a multimodal reward function. We formulate the multimodal reward learning as a mixture learning problem and develop a novel ranking-based learning approach, where the experts are only required to rank a given set of trajectories. Furthermore, as access to interaction data is often expensive in robotics, we develop an active querying approach to accelerate the learning process. We conduct experiments and user studies using a multi-task variant of OpenAI’s LunarLander and a real Fetch robot, where we collect data from multiple users with different preferences. The results suggest that our approach can efficiently learn multimodal reward functions, and improve data-efficiency over benchmark methods that we adapt to our learning problem.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:fPk4N6BV_jEC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"We introduce a framework for obtaining tight mixing times for Markov chains based on what we call restricted modified log-Sobolev inequalities. Modified log-Sobolev inequalities (MLSI) quantify the rate of relative entropy contraction for the Markov operator, and are notoriously difficult to establish. However, infinitesimally close to stationarity, entropy contraction becomes equivalent to variance contraction, a.k.a. a Poincare inequality, which is significantly easier to establish through, e.g., spectral analysis. Motivated by this observation, we study restricted modified log-Sobolev inequalities that guarantee entropy contraction not for all starting distributions, but for those in a large neighborhood of the stationary distribution. We show how to sample from the hardcore and Ising models on -node graphs that have a constant relative gap to the tree-uniqueness threshold, in nearly-linear time . Notably, our bound does not depend on the maximum degree , and is therefore optimal even for high-degree graphs. This improves on prior mixing time bounds of and , established via (non-restricted) modified log-Sobolev and Poincare inequalities respectively. We further show that optimal concentration inequalities can still be achieved from the restricted form of modified log-Sobolev inequalities. To establish restricted entropy contraction, we extend the entropic independence framework of Anari, Jain, Koehler, Pham, and Vuong to the setting of distributions that are spectrally independent under a restricted set of external fields. We also develop an orthogonal trick that might be of independent interest: utilizing Bernoulli factories we show how to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:dfsIfKJdRG4C,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"Constrained submodular function maximization has been used in subset selection problems such as selection of most informative sensor locations. Although these models have been quite popular, the solutions obtained via this approach are unstable to perturbations in data defining the submodular functions. Robust submodular maximization has been proposed as a richer model that aims to overcome this discrepancy as well as increase the modeling scope of submodular optimization. In this work, we consider robust submodular maximization with structured combinatorial constraints and give efficient algorithms with provable guarantees. Our approach is applicable to constraints defined by single or multiple matroids and knapsack as well as distributionally robust criteria. We consider both the offline setting where the data defining the problem are known in advance and the online setting where the input data are …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:yD5IFk8b50cC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"We present a framework for speeding up the time it takes to sample from discrete distributions defined over subsets of size of a ground set of elements, in the regime . We show that having estimates of marginals , the task of sampling from can be reduced to sampling from distributions supported on size subsets of a ground set of only elements. Here, is the parameter of entropic independence for . Further, the sparsified distributions are obtained by applying a sparse (mostly ) external field to , an operation that often retains algorithmic tractability of sampling from . This phenomenon, which we dub domain sparsification, allows us to pay a one-time cost of estimating the marginals of , and in return reduce the amortized cost needed to produce many samples from the distribution , as is often needed in upstream tasks such as counting and inference. For a wide range of distributions where , our result reduces the domain size, and as a corollary, the cost-per-sample, by a factor. Examples include monomers in a monomer-dimer system, non-symmetric determinantal point processes, and partition-constrained Strongly Rayleigh measures. Our work significantly extends the reach of prior work of Anari and Derezi\'nski who obtained domain sparsification for distributions with a log-concave generating polynomial (corresponding to ). As a corollary of our new analysis techniques, we also obtain a less stringent requirement on the accuracy of marginal estimates even for the case of log-concave polynomials; roughly speaking, we show that constant-factor approximation is enough for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:u_35RYKgDlwC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"In this paper we consider the problem of computing the likelihood of the profile of a discrete distribution, ie, the probability of observing the multiset of element frequencies, and computing a profile maximum likelihood (PML) distribution, ie, a distribution with the maximum profile likelihood. For each problem we provide polynomial time algorithms that given iid samples from a discrete distribution, achieve an approximation factor of , improving upon the previous best-known bound achievable in polynomial time of (Charikar, Shiragur and Sidford, 2019). Through the work of Acharya, Das, Orlitsky and Suresh (2016), this implies a polynomial time universal estimator for symmetric properties of discrete distributions in a broader range of error parameter. To obtain our results on PML we establish new connections between PML and the well-studied Bethe and Sinkhorn approximations to the permanent (Vontobel, 2012 and 2014). It is known that the PML objective is proportional to the permanent of a certain Vandermonde matrix (Vontobel, 2012) with distinct columns, ie with non-negative rank at most . This allows us to show that the convex approximation to computing PML distributions studied in (Charikar, Shiragur and Sidford, 2019) is governed, in part, by the quality of Sinkhorn approximations to the permanent. We show that both Bethe and Sinkhorn permanents are approximations to the permanent of matrices with non-negative rank at most . This improves upon the previous known bounds of and combining these insights with careful rounding of the convex relaxation yields …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:j3f4tGmQtD8C,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"We prove tight mixing time bounds for natural random walks on bases of matroids, determinantal distributions, and more generally distributions associated with log-concave polynomials. For a matroid of rank k on a ground set of n elements, or more generally distributions associated with log-concave polynomials of homogeneous degree k on n variables, we show that the down-up random walk, started from an arbitrary point in the support, mixes in time O(klogk). Our bound has no dependence on n or the starting point, unlike the previous analyses of Anari et al. (STOC 2019), Cryan et al. (FOCS 2019), and is tight up to constant factors. The main new ingredient is a property we call approximate exchange, a generalization of well-studied exchange properties for matroids and valuated matroids, which may be of independent interest. In particular, given a distribution µ over size-k subsets of [n], our approximate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:rO6llkc54NcC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"Log-concave polynomials give rise to discrete probability distributions with several nice properties. In particular, log-concavity of the generating polynomial guarantees the existence of efficient algorithms for approximately sampling from a distribution and finding the size of its support. This class of distributions contains several important examples, including uniform measures over bases or independent sets of matroids, determinantal point processes and strongly Rayleigh measures, measures defined by mixed volumes in Mikowski sums, the random cluster model in certain regimes, and more.  In this tutorial, we will introduce the theory and applications of log-concave polynomials and survey some of the recent developments in this area.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:3s1wT3WcHBgC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"We show fully polynomial time randomized approximation schemes (FPRAS) for counting matchings of a given size, or more generally sampling/counting monomer-dimer systems in planar, not-necessarily-bipartite, graphs. While perfect matchings on planar graphs can be counted exactly in polynomial time, counting non-perfect matchings was shown by Jerrum (J Stat Phys 1987) to be #P-hard, who also raised the question of whether efficient approximate counting is possible. We answer this affirmatively by showing that the multi-site Glauber dynamics on the set of monomers in a monomer-dimer system always mixes rapidly, and that this dynamics can be implemented efficiently on downward-closed families of graphs where counting perfect matchings is tractable. As further applications of our results, we show how to sample efficiently using multi-site Glauber dynamics from partition-constrained strongly Rayleigh …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:YFjsv_pBGBYC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"We introduce a notion called entropic independence that is an entropic analog of spectral notions of high-dimensional expansion. Informally, entropic independence of a background distribution on -sized subsets of a ground set of elements says that for any (possibly randomly chosen) set , the relative entropy of a single element of drawn uniformly at random carries at most fraction of the relative entropy of . Entropic independence is the analog of the notion of spectral independence, if one replaces variance by entropy. We use entropic independence to derive tight mixing time bounds, overcoming the lossy nature of spectral analysis of Markov chains on exponential-sized state spaces. In our main technical result, we show a general way of deriving entropy contraction, a.k.a. modified log-Sobolev inequalities, for down-up random walks from spectral notions. We show that spectral independence of a distribution under arbitrary external fields automatically implies entropic independence. To derive our results, we relate entropic independence to properties of polynomials: is entropically independent exactly when a transformed version of the generating polynomial of is upper bounded by its linear tangent; this property is implied by concavity of the said transformation, which was shown by prior work to be locally equivalent to spectral independence. We apply our results to obtain tight modified log-Sobolev inequalities and mixing times for multi-step down-up walks on fractionally log-concave distributions. As our flagship application, we establish the tight mixing time of for Glauber dynamics on Ising models whose interaction matrix …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:b0M2c_1WBrUC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"A polynomial p∈ R [z 1,…, z n] is real stable if it has no roots in the upper-half complex plane. Gurvits's permanent inequality gives a lower bound on the coefficient of the z 1 z 2… z n monomial of a real stable polynomial p with nonnegative coefficients. This fundamental inequality has been used to attack several counting and optimization problems. Here, we study a more general question: Given a stable multilinear polynomial p with nonnegative coefficients and a set of monomials S, we show that if the polynomial obtained by summing up all monomials in S is real stable, then we can lowerbound the sum of coefficients of monomials of p that are in S. We also prove generalizations of this theorem to (real stable) polynomials that are not multilinear. We use our theorem to give a new proof of Schrijver's inequality on the number of perfect matchings of a regular bipartite graph, generalize a recent result of Nikolov and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:35N4QoGY0k4C,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"We say a probability distribution is spectrally independent if an associated pairwise influence matrix has a bounded largest eigenvalue for the distribution and all of its conditional distributions. We prove that if is spectrally independent, then the corresponding high-dimensional simplicial complex is a local spectral expander. Using a line of recent works on mixing time of high-dimensional walks on simplicial complexes [T. Kaufman and D. Mass, Proceedings of ITCS, 2017, pp. 4:1--4:27; I. Dinur and T. Kaufman, Proceedings of the IEEE 58th Annual Symposium on Foundations of Computer Science, 2017, pp. 974--985; T. Kaufman and I. Oppenheim, Proceedings of APPROX/RANDOM, 2018, pp. 47:1--47:17; V. L. Alev and L. C. Lau, Proceedings of the 52nd Annual ACM Symposium on Theory of Computing, 2020], this implies that the corresponding Glauber dynamics mixes rapidly and generates (approximate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:e5wmG9Sq2KIC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2021,"We prove that the permanent of nonnegative matrices can be deterministically approximated within a factor of in polynomial time, improving upon previous deterministic approximations. We show this by proving that the Bethe approximation of the permanent, a quantity computable in polynomial time, is at least as large as the permanent divided by . This resolves a conjecture of [L. Gurvits, Unleashing the Power of Schrijver's Permanental Inequality with the Help of the Bethe Approximation, preprint, arxiv 1106.2844, 2011]. Our bound is tight and, when combined with previously known inequalities lower bounding the permanent, fully resolves the quality of Bethe approximation for the permanent. As an additional corollary of our methods, we resolve a conjecture of [M. Chertkov and A. B. Yedidia, J. Mach. Learn. Res., 14 (2013), pp. 2029--2066], proving that fractional belief propagation with fractional parameter …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:Wp0gIr-vW9MC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2020,"We study the problem of sampling a uniformly random directed rooted spanning tree, also known as an arborescence, from a possibly weighted directed graph. Classically, this problem has long been known to be polynomial-time solvable; the exact number of arborescences can be computed by a determinant [Tut48], and sampling can be reduced to counting [JVV86, JS96]. However, the classic reduction from sampling to counting seems to be inherently sequential. This raises the question of designing efficient parallel algorithms for sampling. We show that sampling arborescences can be done in RNC. For several well-studied combinatorial structures, counting can be reduced to the computation of a determinant, which is known to be in NC [Csa75]. These include arborescences, planar graph perfect matchings, Eulerian tours in digraphs, and determinantal point processes. However, not much is known about efficient parallel sampling of these structures. Our work is a step towards resolving this mystery.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:NMxIlDl6LWMC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2020,"We define a notion of isotropy for discrete set distributions. If μ is a distribution over subsets S of a ground set [ n], we say that μ is in isotropic position if \mathbbPS ~ μ[e ∈ S] is the same for all e ∈ [n]. We design a new approximate sampling algorithm that leverages isotropy for the class of distributions μ that have a log-concave generating polynomial; this class includes determinantal point processes, strongly Rayleigh distributions, and uniform distributions over matroid bases. We show that when μ is in approximately isotropic position, the running time of our algorithm depends polynomially on the size of the set S, and only logarithmically on n. When n is much larger than the size of S, this is significantly faster than prior algorithms, and can even be sublinear in n. We then show how to transform a non-isotropic μ into an equivalent approximately isotropic form with a polynomial-time pre-processing step, accelerating …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:k_IJM867U9cC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2020,"Is perfect matching in NC? That is, is there a deterministic fast parallel algorithm for it? This has been an outstanding open question in theoretical computer science for over three decades, ever since the discovery of RNC perfect matching algorithms. Within this question, the case of planar graphs has remained an enigma: On the one hand, counting the number of perfect matchings is far harder than finding one (the former is #P-complete and the latter is in P), and on the other, for planar graphs, counting has long been known to be in NC whereas finding one has resisted a solution.
In this article, we give an NC algorithm for finding a perfect matching in a planar graph. Our algorithm uses the above-stated fact about counting perfect matchings in a crucial way. Our main new idea is an NC algorithm for finding a face of the perfect matching polytope at which a set (which could be polynomially large) of conditions …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:M3NEmzRMIkIC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2020,"Given a matrix and , we study the problem of finding the submatrix of with the maximum determinant in absolute value. This problem is motivated by the question of computing the determinant-based lower bound of [LSV86] on hereditary discrepancy, which was later shown to be an approximate upper bound as well [Mat13]. The special case where coincides with one of the dimensions of has been extensively studied. [Nik15] gave a -approximation algorithm for this special case, matching known lower bounds; he also raised as an open problem the question of designing approximation algorithms for the general case. We make progress towards answering this question by giving the first efficient approximation algorithm for general subdeterminant maximization with an approximation ratio that depends only on . Our algorithm finds a -approximate solution by performing a simple local search. Our main technical contribution, enabling the analysis of the approximation ratio, is an extension of Pl\""ucker relations for the Grassmannian, which may be of independent interest; Pl\""ucker relations are quadratic polynomial equations involving the set of subdeterminants of a matrix. We find an extension of these relations to subdeterminants of general matrices.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:maZDTaKrznsC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2020,"In this paper we provide a new efficient algorithm for approximately computing the profile maximum likelihood (PML) distribution, a prominent quantity in symmetric property estimation. We provide an algorithm which matches the previous best known efficient algorithms for computing approximate PML distributions and improves when the number of distinct observed frequencies in the given instance is small. We achieve this result by exploiting new sparsity structure in approximate PML distributions and providing a new matrix rounding algorithm, of independent interest. Leveraging this result, we obtain the first provable computationally efficient implementation of PseudoPML, a general framework for estimating a broad class of symmetric properties. Additionally, we obtain efficient PML-based estimators for distributions with small profile entropy, a natural instance-based complexity measure. Further, we provide a simpler and more practical PseudoPML implementation that matches the best-known theoretical guarantees of such an estimator and evaluate this method empirically.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:hMod-77fHWUC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2019,"We design an FPRAS to count the number of bases of any matroid given by an independent set oracle, and to estimate the partition function of the random cluster model of any matroid in the regime where 0<q<1. Consequently, we can sample random spanning forests in a graph and estimate the reliability polynomial of any matroid. We also prove the thirty year old conjecture of Mihail and Vazirani that the bases exchange graph of any matroid has edge expansion at least 1.
Our algorithm and proof build on the recent results of Dinur, Kaufman, Mass and Oppenheim who show that a high dimensional walk on a weighted simplicial complex mixes rapidly if for every link of the complex, the corresponding localized random walk on the 1-skeleton is a strong spectral expander. One of our key observations is that a weighted simplicial complex X is a 0-local spectral expander if and only if a naturally associated …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:aqlVkmm33-oC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2019,"Data collection and labeling is one of the main challenges in employing machine learning algorithms in a variety of real-world applications with limited data. While active learning methods attempt to tackle this issue by labeling only the data samples that give high information, they generally suffer from large computational costs and are impractical in settings where data can be collected in parallel. Batch active learning methods attempt to overcome this computational burden by querying batches of samples at a time. To avoid redundancy between samples, previous works rely on some ad hoc combination of sample quality and diversity. In this paper, we present a new principled batch active learning method using Determinantal Point Processes, a repulsive point process that enables generating diverse batches of samples. We develop tractable algorithms to approximate the mode of a DPP distribution, and provide theoretical guarantees on the degree of approximation. We further demonstrate that an iterative greedy method for DPP maximization, which has lower computational costs but worse theoretical guarantees, still gives competitive results for batch active learning. Our experiments show the value of our methods on several datasets against state-of-the-art baselines.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:hC7cP41nSMkC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2019,"In the Bayesian online selection problem, the goal is to find a pricing algorithm for serving a sequence of arriving buyers that maximizes the expected social-welfare (or revenue) subject to different types of structural constraints. The focus of this paper is on the case where the allowable subsets of served customers are characterized by a laminar matroid with constant depth. This problem is a special case of the well-known matroid Bayesian online selection problem studied in [Kleinberg & Weinberg, 2012], when the underlying matroid is laminar. We give the first Polynomial-Time Approximation Scheme (PTAS) for the above problem. Our approach is based on rounding the solution of a hierarchy of linear programming relaxations that can approximate the optimum online solution with any degree of accuracy as well as a concentration argument that shows our rounding does not have a considerable loss in the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:Zph67rFs4hoC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2019,"Constrained submodular function maximization has been used in subset selection problems such as selection of most informative sensor locations. While these models have been quite popular, the solutions obtained via this approach are unstable to perturbations in data defining the submodular functions. Robust submodular maximization has been proposed as a richer model that aims to overcome this discrepancy as well as increase the modeling scope of submodular optimization. In this work, we consider robust submodular maximization with structured combinatorial constraints and give efficient algorithms with provable guarantees. Our approach is applicable to constraints defined by single or multiple matroids, knapsack as well as distributionally robust criteria. We consider both the offline setting where the data defining the problem is known in advance as well as the online setting where the input data is revealed over time. For the offline setting, we give a nearly optimal bi-criteria approximation algorithm that relies on new extensions of the classical greedy algorithm. For the online version of the problem, we give an algorithm that returns a bi-criteria solution with sub-linear regret.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:RHpTSmoSYBkC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2019,"Is matching in NC, i.e., is there a deterministic fast parallel algorithm for it? This has been an outstanding open question in TCS for over three decades, ever since the discovery of randomized NC matching algorithms [KUW85, MVV87]. Over the last five years, the theoretical computer science community has launched a relentless attack on this question, leading to the discovery of several powerful ideas. We give what appears to be the culmination of this line of work: An NC algorithm for finding a minimum-weight perfect matching in a general graph with polynomially bounded edge weights, provided it is given an oracle for the decision problem. Consequently, for settling the main open problem, it suffices to obtain an NC algorithm for the decision problem. We believe this new fact has qualitatively changed the nature of this open problem. All known efficient matching algorithms for general graphs follow one of two approaches: given by Edmonds [Edm65] and Lov\'asz [Lov79]. Our oracle-based algorithm follows a new approach and uses many of the ideas discovered in the last five years. The difficulty of obtaining an NC perfect matching algorithm led researchers to study matching vis-a-vis clever relaxations of the class NC. In this vein, recently Goldwasser and Grossman [GG15] gave a pseudo-deterministic RNC algorithm for finding a perfect matching in a bipartite graph, i.e., an RNC algorithm with the additional requirement that on the same graph, it should return the same (i.e., unique) perfect matching for almost all choices of random bits. A corollary of our reduction is an analogous algorithm for general graphs.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:IWHjjKOFINEC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2018,"We give a self-contained proof of the strongest version of Mason's conjecture, namely that for any matroid the sequence of the number of independent sets of given sizes is ultra log-concave. To do this, we introduce a class of polynomials, called completely log-concave polynomials, whose bivariate restrictions have ultra log-concave coefficients. At the heart of our proof we show that for any matroid, the homogenization of the generating polynomial of its independent sets is completely log-concave.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:4DMP91E08xMC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2018,"We consider a simple and well-studied model for procurement problems and solve it to optimality. A buyer with a fixed budget wants to procure, from a set of available workers, a budget feasible subset that maximizes her utility: Any worker has a private reservation price and provides a publicly known utility to the buyer in case of being procured. The buyer’s utility function is additive over items. The goal is designing a direct revelation mechanism that solicits workers’ reservation prices and decides which workers to recruit and how much to pay them. Moreover, the mechanism has to maximize the buyer’s utility without violating her budget constraint. We study this problem in the prior-free setting; our main contribution is finding the optimal mechanism in this setting, under the “small bidders” assumption. This assumption, also known as the “small bid to budget ratio assumption,” states that the bid of each seller is small …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:kNdYIx-mwKoC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2018,"We give a deterministic polynomial time 2^O(r)-approximation algorithm for the number of bases of a given matroid of rank r and the number of common bases of any two matroids of rank r. To the best of our knowledge, this is the first nontrivial deterministic approximation algorithm that works for arbitrary matroids. Based on a lower bound of Azar, Broder, and Frieze this is almost the best possible assuming oracle access to independent sets of the matroid. There are two main ingredients in our result: For the first, we build upon recent results of Adiprasito, Huh, and Katz and Huh and Wang on combinatorial hodge theory to derive a connection between matroids and log-concave polynomials. We expect that several new applications in approximation algorithms will be derived from this connection in future. Formally, we prove that the multivariate generating polynomial of the bases of any matroid is log-concave as a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:mB3voiENLucC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2018,"We analyze linear independence of rank one tensors produced by tensor powers of randomly perturbed vectors. This enables efficient decomposition of sums of high-order tensors. Our analysis builds upon [BCMV14] but allows for a wider range of perturbation models, including discrete ones. We give an application to recovering assemblies of neurons.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:qxL8FJ1GzNcC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2018,"Recently Cole and Gkatzelis [10] gave the first constant factor approximation algorithm for the problem of allocating indivisible items to agents, under additive valuations, so as to maximize the Nash social welfare (NSW). We give constant factor algorithms for a substantial generalization of their problem – to the case of separable, piecewise-linear concave utility functions. We give two such algorithms, the first using market equilibria and the second using the theory of real stable polynomials. Both approaches require new algorithmic ideas.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:_FxGoFyzp5QC,https://nimaanari.com/
Nima Anari,"['Algorithms', 'Theoretical Computer Science']",19,1124,2018,"We study the problem of approximating the largest root of a real-rooted polynomial of degree n using its top k coefficients and give nearly matching upper and lower bounds. We present algorithms with running time polynomial in k that use the top k coefficients to approximate the maximum root within a factor of n1/k and when k ≤ log n and k > log n respectively. We also prove corresponding information-theoretic lower bounds of nΩ(1/k) and , and show strong lower bounds for noisy version of the problem in which one is given access to approximate coefficients.
This problem has applications in the context of the method of interlacing families of polynomials, which was used for proving the existence of Ramanujan graphs of all degrees, the solution of the Kadison-Singer problem, and bounding the integrality gap of the asymmetric traveling salesman problem. All of these involve computing the maximum root of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=kmeUhO8AAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=kmeUhO8AAAAJ:Tyk-4Ss8FVUC,https://nimaanari.com/
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"The softmax function is a ubiquitous component at the output of neural networks and increasingly in intermediate layers as well. This paper provides convex lower bounds and concave upper bounds on the softmax function, which are compatible with convex optimization formulations for characterizing neural networks and other ML models. We derive bounds using both a natural exponential-reciprocal decomposition of the softmax as well as an alternative decomposition in terms of the log-sum-exp function. The new bounds are provably and/or numerically tighter than linear bounds obtained in previous work on robustness verification of transformers. As illustrations of the utility of the bounds, we apply them to verification of transformers as well as of the robustness of predictive uncertainty estimates of deep ensembles.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:8xutWZnSdmoC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"The architecture of a coarse-grained reconfigurable array (CGRA) processing element (PE) has a significant effect on the performance and energy-efficiency of an application running on the CGRA. This paper presents APEX, an automated approach for generating specialized PE architectures for an application or an application domain. APEX first analyzes application domain benchmarks using frequent subgraph mining to extract commonly occurring computational subgraphs. APEX then generates specialized PEs by merging subgraphs using a datapath graph merging algorithm. The merged datapath graphs are translated into a PE specification from which we automatically generate the PE hardware description in Verilog along with a compiler that maps applications to the PE. The PE hardware and compiler are inserted into a flexible CGRA generation and compilation toolchain that allows for agile evaluation of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ZzlSgRqYykMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"Piecewise-affine (PWA) systems are widely used for modeling and control of robotics problems including modeling contact dynamics. A common approach is to encode the control problem of the PWA system as a Mixed-Integer Convex Program (MICP), which can be solved by general-purpose off-the-shelf MICP solvers. To mitigate the scalability challenge of solving these MICP problems, existing work focuses on devising efficient and strong formulations of the problems, while less effort has been spent on exploiting their specific structure to develop specialized solvers. The latter is the theme of our work. We focus on efficiently handling one-hot constraints, which are particularly relevant when encoding PWA dynamics. We have implemented our techniques in a tool, Soy, which organically integrates logical reasoning, arithmetic reasoning, and stochastic local search. For a set of PWA control benchmarks, Soy solves more problems, faster, than two state-of-the-art MICP solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Aul-kAQHnToC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"The high computational and memory requirements of large language model (LLM) inference traditionally make it feasible only with multiple high-end accelerators. Motivated by the emerging demand for latency-insensitive tasks with batched processing, this paper initiates the study of high-throughput LLM inference using limited resources, such as a single commodity GPU. We present FlexGen, a high-throughput generation engine for running LLMs with limited GPU memory. FlexGen can be flexibly configured under various hardware resource constraints by aggregating memory and computation from the GPU, CPU, and disk. Through a linear programming optimizer, it searches for efficient patterns to store and access tensors. FlexGen further compresses these weights and the attention cache to 4 bits with negligible accuracy loss. These techniques enable FlexGen to have a larger space of batch size choices and thus significantly increase maximum throughput. As a result, when running OPT-175B on a single 16GB GPU, FlexGen achieves significantly higher throughput compared to state-of-the-art offloading systems, reaching a generation throughput of 1 token/s for the first time with an effective batch size of 144. On the HELM benchmark, FlexGen can benchmark a 30B model with a 16GB GPU on 7 representative sub-scenarios in 21 hours. The code is available at https://github.com/FMInference/FlexGen",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:_OXeSy2IsFwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"With the slowing of Moore’s law, computer architects have turned to domain-specific hardware specialization to continue improving the performance and efficiency of computing systems. However, specialization typically entails significant modifications to the software stack to properly leverage the updated hardware. The lack of a structured approach for updating the compiler and the accelerator in tandem has impeded many attempts to systematize this procedure. We propose a new approach to enable flexible and evolvable domain-specific hardware specialization based on coarse-grained reconfigurable arrays (CGRAs). Our agile methodology employs a combination of new programming languages and formal methods to automatically generate the accelerator hardware and its compiler from a single source of truth. This enables the creation of design-space exploration frameworks that automatically generate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:WJVC3Jt7v1AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"We study satisfiability modulo the theory of finite fields and give a decision procedure for this theory. We implement our procedure for prime fields inside the cvc5 SMT solver. Using this theory, we construct SMT queries that verify the correctness of various zero knowledge proof compilers on various input programs. Our experiments show that our implementation is vastly superior to previous approaches (which encode field arithmetic using integers or bit-vectors).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:F9fV5C73w3QC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"We present VeriX, a first step towards verified explainability of machine learning models in safety-critical applications. Specifically, our sound and optimal explanations can guarantee prediction invariance against bounded perturbations. We utilise constraint solving techniques together with feature sensitivity ranking to efficiently compute these explanations. We evaluate our approach on image recognition benchmarks and a real-world scenario of autonomous aircraft taxiing.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HeT0ZceujKMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Recently, Graph Neural Networks (GNNs) have been applied for scheduling jobs over clusters, achieving better performance than hand-crafted heuristics. Despite their impressive performance, concerns remain over whether these GNN-based job schedulers meet users’ expectations about other important properties, such as strategy-proofness, sharing incentive, and stability. In this work, we consider formal verification of GNN-based job schedulers. We address several domain-specific challenges such as networks that are deeper and specifications that are richer than those encountered when verifying image and NLP classifiers. We develop vegas, the first general framework for verifying both single-step and multi-step properties of these schedulers based on carefully designed algorithms that combine abstractions, refinements, solvers, and proof transfer. Our experimental results show that vegas achieves …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:anf4URPfarAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Neural networks have become critical components of reactive systems in various domains within computer science. Despite their excellent performance, using neural networks entails numerous risks that stem from our lack of ability to understand and reason about their behavior. Due to these risks, various formal methods have been proposed for verifying neural networks; but unfortunately, these typically struggle with scalability barriers. Recent attempts have demonstrated that abstraction-refinement approaches could play a significant role in mitigating these limitations; but these approaches can often produce networks that are so abstract, that they become unsuitable for verification. To deal with this issue, we present CEGARETTE, a novel verification mechanism where both the system and the property are abstracted and refined simultaneously. We observe that this approach allows us to produce abstract networks which are both small and sufficiently accurate, allowing for quick verification times while avoiding a large number of refinement steps. For evaluation purposes, we implemented CEGARETTE as an extension to the recently proposed CEGAR-NN framework. Our results are very promising, and demonstrate a significant improvement in performance over multiple benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:KbBQZpvPDL4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Convolutional neural networks (CNNs) have achieved immense popularity in areas like computer vision, image processing, speech proccessing, and many others. Unfortunately, despite their excellent performance, they are prone to producing erroneous results — for example, minor perturbations to their inputs can result in severe classification errors. In this paper, we present the Cnn-Abs framework, which implements an abstraction-refinement based scheme for CNN verification. Specifically, Cnn-Abs simplifies the verification problem through the removal of convolutional connections in a way that soundly creates an over-approximation of the original problem; it then iteratively restores these connections if the resulting problem becomes too abstract. Cnn-Abs is designed to use existing verification engines as a backend, and our evaluation demonstrates that it can significantly boost the performance of a state-of-the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:bz8QjSJIRt4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Creating a compiler for an instruction set architecture (ISA) requires a set of rewrite rules describing how to translate from the compiler’s intermediate representation (IR) to the ISA. We address this challenge by synthesizing rewrite rules from a register-transfer level (RTL) description of the target architecture (with minimal annotations about its state and the ISA format), together with formal IR semantics, by constructing SMT queries where solutions represent valid rewrite rules. We evaluate our approach on multiple architectures, supporting both integer and floating-point operations. We synthesize both integer and floating-point rewrite rules from an intermediate representation to various reconfigurable array architectures in under 1.2 seconds per rule. We also synthesize integer rewrite rules from WebAssembly to RISC-V with both standard and custom extensions in under 4 seconds per rule, and we synthesize floating-point rewrite rules in under 8 seconds per rule.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:fFSKOagxvKUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Satisfiability modulo theories (SMT) solvers are widely used to prove security and safety properties of computer systems. For these applications, it is crucial that the result reported by an SMT solver be correct. Recently, there has been a renewed focus on producing independently checkable proofs in SMT solvers, partly with the aim of addressing this risk. These proofs record the reasoning done by an SMT solver and are ideally detailed enough to be easy to check. At the same time, modern SMT solvers typically implement hundreds of different term-rewriting rules in order to achieve state-of-the-art performance. Generating detailed proofs for applications of these rules is a challenge, because code implementing rewrite rules can be large and complex. Instrumenting this code to additionally produce proofs makes it even more complex and makes it harder to add new rewrite rules. We propose an alternative approach to the direct instrumentation of the rewriting module of an SMT solver. The approach uses a domain-specific language (DSL) to describe a set of rewrite rules declaratively and then reconstructs detailed proofs for specific rewrite steps on demand based on those declarative descriptions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:3htObqc8RwsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"With the increasing application of deep learning in mission-critical systems, there is a growing need to obtain formal guarantees about the behaviors of neural networks. Indeed, many approaches for verifying neural networks have been recently proposed, but these generally struggle with limited scalability or insufficient accuracy. A key component in many state-of-the-art verification schemes is computing lower and upper bounds on the values that neurons in the network can obtain for a specific input domain—and the tighter these bounds, the more likely the verification is to succeed. Many common algorithms for computing these bounds are variations of the symbolic-bound propagation method; and among these, approaches that utilize a process called back-substitution are particularly successful. In this paper, we present an approach for making back-substitution produce tighter bounds. To achieve this, we formulate and then minimize the imprecision errors incurred during back-substitution. Our technique is general, in the sense that it can be integrated into numerous existing symbolic-bound propagation techniques, with only minor modifications. We implement our approach as a proofof-concept tool, and present favorable results compared to stateof-the-art verifiers that perform back-substitution.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ODE9OILHJdcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Deep neural networks (DNNs) are increasingly being employed in safety-critical systems, and there is an urgent need to guarantee their correctness. Consequently, the verification community has devised multiple techniques and tools for verifying DNNs. When DNN verifiers discover an input that triggers an error, that is easy to confirm; but when they report that no error exists, there is no way to ensure that the verification tool itself is not flawed. As multiple errors have already been observed in DNN verification tools, this calls the applicability of DNN verification into question. In this work, we present a novel mechanism for enhancing Simplex-based DNN verifiers with proof production capabilities: the generation of an easy-tocheck witness of unsatisfiability, which attests to the absence of errors. Our proof production is based on an efficient adaptation of the well-known Farkas’ lemma, combined with mechanisms for handling piecewise-linear functions and numerical precision errors. As a proof of concept, we implemented our technique on top of the Marabou DNN verifier. Our evaluation on a safetycritical system for airborne collision avoidance shows that proof production succeeds in almost all cases and requires only minimal overhead.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:umqufdRvDiIC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"We develop a framework for model checking infinite-state systems by automatically augmenting them with auxiliary variables, enabling quantifier-free induction proofs for systems that would otherwise require quantified invariants. We combine this mechanism with a counterexample-guided abstraction refinement scheme for the theory of arrays. Our framework can thus, in many cases, reduce inductive reasoning with quantifiers and arrays to quantifier-free and array-free reasoning. We evaluate the approach on a wide set of benchmarks from the literature. The results show that our implementation often outperforms state-of-the-art tools, demonstrating its practical potential.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:OcBU2YAGkTUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"SMT solvers are highly complex pieces of software with performance, robustness, and correctness as key requirements. Complementing traditional testing techniques for these solvers with randomized stress testing has been shown to be quite effective. Recent work has showcased the value of input fuzzing for finding issues, but this approach typically does not comprehensively test a solver’s API. Previous work on model-based API fuzzing was tailored to a single solver and a small subset of SMT-LIB. We present Murxla, a comprehensive, modular, and highly extensible model-based API fuzzer for SMT solvers. Murxla randomly generates valid sequences of solver API calls based on a customizable API model, with full support for the semantics and features of SMT-LIB. It is solver-agnostic but extensible to allow for solver-specific testing and supports option fuzzing, cross-checking with other solvers, translation to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:yFnVuubrUp4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"In the past decade, satisfiability modulo theories (SMT) solvers have been extended to support the theory of strings and regular expressions. This theory has proven to be useful in a wide range of applications in academia and industry. To accommodate the expressive nature of string constraints used in those applications, string solvers use a multi-layered architecture where extended operators are reduced to a set of core operators. These reductions, however, are often costly to reason about. In this work, we propose new techniques for eagerly discovering conflicts based on equality reasoning and lazily avoiding reductions for certain extended functions based on lightweight reasoning. We present a strategy for integrating and scheduling these techniques in a CDCL-based theory solver for strings and regular expressions. We implement the techniques and the strategy in cvc5, a state-of-the-art SMT solver, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:_5tno0g5mFcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"The cvc5 SMT solver solves quantifier-free nonlinear real arithmetic problems by combining the cylindrical algebraic coverings method with incremental linearization in an abstraction-refinement loop. The result is a complete algebraic decision procedure that leverages efficient heuristics for refining candidate models. Furthermore, it can be used with quantifiers, integer variables, and in combination with other theories. We describe the overall framework, individual solving techniques, and a number of implementation details. We demonstrate its effectiveness with an evaluation on the SMT-LIB benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:2VqYfGB8ITEC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Dynamic arrays, also referred to as vectors, are fundamental data structures used in many programs. Modeling their semantics efficiently is crucial when reasoning about such programs. The theory of arrays is widely supported but is not ideal, because the number of elements is fixed (determined by its index sort) and cannot be adjusted, which is a problem, given that the length of vectors often plays an important role when reasoning about vector programs. In this paper, we propose reasoning about vectors using a theory of sequences. We introduce the theory, propose a basic calculus adapted from one for the theory of strings, and extend it to efficiently handle common vector operations. We prove that our calculus is sound and show how to construct a model when it terminates with a saturated configuration. Finally, we describe an implementation of the calculus in cvc5 and demonstrate its efficacy by evaluating it …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:4hFrxpcac9AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Algebraic datatypes, and among them lists and trees, have attracted a lot of interest in automated reasoning and Satisfiability Modulo Theories (SMT). Since its latest stable version, the SMT-LIB standard defines a theory of algebraic datatypes, which is currently supported by several mainstream SMT solvers. In this paper, we study this particular theory of datatypes and prove that it is strongly polite, showing how it can be combined with other arbitrary disjoint theories using polite combination. The combination method uses a new, simple, and natural notion of additivity that enables deducing strong politeness from (weak) politeness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:a9-T7VOCCH8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Proof production for SMT solvers is paramount to ensure their correctness independently from implementations, which are often prohibitively difficult to verify. Historically, however, SMT proof production has struggled with performance and coverage issues, resulting in the disabling of many crucial solving techniques and in coarse-grained (and thus hard to check) proofs. We present a flexible proof-production architecture designed to handle the complexity of versatile, industrialstrength SMT solvers and show how we leverage it to produce detailed proofs, including for components previously unsupported by any solver. The architecture allows proofs to be produced modularly, lazily, and with numerous safeguards for correctness. This architecture has been implemented in the state-of-the-art SMT solver cvc5. We evaluate its proofs for SMT-LIB benchmarks and show that the new architecture produces better coverage than previous approaches, has acceptable performance overhead, and supports detailed proofs for most solving components.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:0izLItjtcgwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"We consider the problem of certifying the robustness of deep neural networks against real-world distribution shifts. To do so, we bridge the gap between hand-crafted specifications and realistic deployment settings by proposing a novel neural-symbolic verification framework, in which we train a generative model to learn perturbations from data and define specifications with respect to the output of the learned model. A unique challenge arising from this setting is that existing verifiers cannot tightly approximate sigmoid activations, which are fundamental to many state-of-the-art generative models. To address this challenge, we propose a general meta-algorithm for handling sigmoid activations which leverages classical notions of counter-example-guided abstraction refinement. The key idea is to ""lazily"" refine the abstraction of sigmoid functions to exclude spurious counter-examples found in the previous abstraction, thus guaranteeing progress in the verification process while keeping the state-space small. Experiments on the MNIST and CIFAR-10 datasets show that our framework significantly outperforms existing methods on a range of challenging distribution shifts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:sNmaIFBj_lkC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Первоначально доминирующим решением для обработки текста были модели, основанные на сложных рекуррентных или сверточных нейронных сетях, далее им на смену пришла более простая и эффективная архитектура-Transformer [7]. Модели данной архитектуры показывают отличное качество на подавляющем большинстве существующих задач [1 2 3], относительно быстро обучаются, и хорошо поддаются параллелизации. Как показывают современные работы, эффективность данных моделей увеличивается с увеличением числа параметров [1]. За счет этого значительно возрастает сложность, цена и время необходимые для обучения каждой отдельной модели. В силу вышеупомянутых свойств появилась тенденция к созданию моделей, которые или нуждаются лишь в относительно дешевом дообучении на конкретной подзадаче [4], или же способны понимать и обобщать задачу по нескольким примерам, поданным с входными данными [1], и в силу чего вообще не нуждающиеся в дообучении. Для реализации моделей требующих дообучения в большинстве современных работ выбирается подход основанный на эмбеддингах-заранее обучается",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HtEfBTGE9r8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Inspired by sum-of-infeasibilities methods in convex optimization, we propose a novel procedure for analyzing verification queries on neural networks with piecewise-linear activation functions. Given a convex relaxation which over-approximates the non-convex activation functions, we encode the violations of activation functions as a cost function and optimize it with respect to the convex relaxation. The cost function, referred to as the Sum-of-Infeasibilities (SoI), is designed so that its minimum is zero and achieved only if all the activation functions are satisfied. We propose a stochastic procedure, DeepSoI, to efficiently minimize the SoI. An extension to a canonical case-analysis-based complete search procedure can be achieved by replacing the convex procedure executed at each search state with DeepSoI. Extending the complete search with DeepSoI achieves multiple simultaneous goals: 1) it guides the search …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:NXb4pA-qfm4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,cvc5 is the latest SMT solver in the cooperating validity checker series and builds on the successful code base of CVC4. This paper serves as a comprehensive system description of cvc5 ’s architectural design and highlights the major features and components introduced since CVC4  1.8. We evaluate cvc5 ’s performance on all benchmarks in SMT-LIB and provide a comparison against CVC4 and Z3.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:LO7wyVUgiFcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:0N-VGjzr574C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"The state of the art for bit-precise reasoning in the context of Satisfiability Modulo Theories (SMT) is a SAT-based technique called bit-blasting where the input formula is first simplified and then translated to an equisatisfiable propositional formula. The main limitation of this technique is scalability, especially in the presence of large bit-widths and arithmetic operators. We introduce an alternative technique, which we call int-blasting, based on a translation to an extension of integer arithmetic rather than propositional logic. We present several translations, discuss their differences, and evaluate them on benchmarks that arise from the verification of rewrite rule candidates for bit-vector solving, as well as benchmarks from SMT-LIB. We also provide preliminary results on 35 benchmarks that arise from smart contract verification. The evaluation shows that this technique is particularly useful for benchmarks with large bit …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:q3CdL3IzO_QC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"This paper is a description of the CVC5 SMT solver as entered into the 2022 SMT Competition. Here, we briefly summarize the main techniques implemented by CVC5 that are relevant. For more comprehensive information please refer to the tool paper about CVC5 [15], our website [7], and the source code on GitHub [6].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:yMeIxYmEMEAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"With the increasing availability of parallel computing power, there is a growing focus on parallelizing algorithms for important automated reasoning problems such as Boolean satisfiability (SAT). Divide-and-Conquer (D&C) is a popular parallel SAT solving paradigm that partitions SAT instances into independent sub-problems which are then solved in parallel. For unsatisfiable instances, state-of-the-art D&C solvers generate DRAT refutations for each sub-problem. However, they do not generate a single refutation for the original instance. To close this gap, we present Proof-Stitch, a procedure for combining refutations of different sub-problems into a single refutation for the original instance. We prove the correctness of the procedure and propose optimizations to reduce the size and checking time of the combined refutations by invoking existing trimming tools in the proof-combination process. We also provide an extensible implementation of the proposed technique. Experiments on instances from last year’s SAT competition show that the optimized refutations are checkable up to seven times faster than unoptimized refutations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:OR75R8vi5nAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Dynamic arrays, also referred to as vectors, are fundamental data structures used in many programs. Modeling their semantics efficiently is crucial when reasoning about such programs. The theory of arrays is widely supported but is not ideal, because the number of elements is fixed (determined by its index sort) and cannot be adjusted, which is a problem, given that the length of vectors often plays an important role when reasoning about vector programs. In this paper, we propose reasoning about vectors using a theory of sequences. We introduce the theory, propose a basic calculus adapted from one for the theory of strings, and extend it to efficiently handle common vector operations. We prove that our calculus is sound and show how to construct a model when it terminates with a saturated configuration. Finally, we describe an implementation of the calculus in cvc5 and demonstrate its efficacy by evaluating it on verification conditions for smart contracts and benchmarks derived from existing array benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:bKqednn6t2AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Neural networks can learn complex, non-convex functions, and it is challenging to guarantee their correct behavior in safety-critical contexts. Many approaches exist to find failures in networks (e.g., adversarial examples), but these cannot guarantee the absence of failures. Verification algorithms address this need and provide formal guarantees about a neural network by answering “yes or no” questions. For example, they can answer whether a violation exists within certain bounds. However, individual “yes or no"" questions cannot answer qualitative questions such as “what is the largest error within these bounds”; the answers to these lie in the domain of optimization. Therefore, we propose strategies to extend existing verifiers to perform optimization and find: (i) the most extreme failure in a given input region and (ii) the minimum input perturbation required to cause a failure. A naive approach using a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:k8Z6L05lTy4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"In recent years, cloud service providers have sold computation in increasingly granular units. Most recently,“serverless” executors run a single executable with restricted network access and for a limited time. The benefit of these restrictions is scale: thousand-way parallelism can be allocated in seconds, and CPU time is billed with sub-second granularity. To exploit these executors, we introduce gg-SAT: an implementation of divide-and-conquer SAT solving. Infrastructurally, gg-SAT departs substantially from previous implementations: rather than handling process or server management itself, gg-SAT builds on the gg framework, allowing computations to be executed on a configurable backend, including serverless offerings such as AWS Lambda. Our experiments suggest that when run on the same hardware, gg-SAT performs competitively with other D&C solvers, and that the 1000-way parallelism it offers (through AWS Lambda) is useful for some challenging SAT instances.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Ri6SYOTghG4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Hardware accelerators (HAs) are essential building blocks for fast and energy-efficient computing systems. Accelerator Quick Error Detection (A-QED) is a recent formal technique which uses Bounded Model Checking for pre-silicon verification of HAs. A-QED checks an HA for self-consistency, ie, whether identical inputs within a sequence of operations always produce the same output. Under modest assumptions, A-QED is both sound and complete. However, as is well-known, large design sizes significantly limit the scalability of formal verification, including A-QED. We overcome this scalability challenge through a new decomposition technique for A-QED, called A-QED with Decomposition (A-QED2). A-QED2 systematically decomposes an HA into smaller, functional sub-modules, called sub-accelerators, which are then verified independently using A-QED. We prove completeness of A-QED2; in particular, if the full HA under verification contains a bug, then A-QED2 ensures detection of that bug during A-QED verification of the corresponding subaccelerators. Results on over 100 (buggy) versions of a wide variety of HAs with millions of logic gates demonstrate the effectiveness and practicality of A-QED2.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:86PQX7AUzd4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"The increasing complexity of modern configurable systems makes it critical to improve the level of automation in the process of system configuration. Such automation can also improve the agility of the development cycle, allowing for rapid and automated integration of decoupled workflows. In this paper, we present a new framework for automated configuration of systems representable as state machines. The framework leverages model checking and satisfiability modulo theories (SMT) and can be applied to any application domain representable using SMT formulas. Our approach can also be applied modularly, improving its scalability. Furthermore, we show how optimization can be used to produce configurations that are best according to some metric and also more likely to be understandable to humans. We showcase this framework and its flexibility by using it to configure a CGRA memory tile for various image processing applications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:_axFR9aDTf0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Many SMT solvers implement efficient SAT-based procedures for solving fixed-size bit-vector formulas. These techniques, however, cannot be used directly to reason about bit-vectors of symbolic bit-width. To address this shortcoming, we propose a translation from bit-vector formulas with parametric bit-width to formulas in a logic supported by SMT solvers that includes non-linear integer arithmetic, uninterpreted functions, and universal quantification. While this logic is undecidable, our approach can still solve many formulas that arise in practice by capitalizing on advances in SMT solving for non-linear arithmetic and universally quantified formulas. We provide several case studies in which we have applied this approach with promising results, including the bit-width independent verification of invertibility conditions, compiler optimizations, and bit-vector rewrite rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:kz9GbA2Ns4gC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"This paper presents Smt-Switch, an open-source, solveragnostic API for SMT solving. Smt-Switch provides simple, uniform, and high-performance access to SMT solving for applications in areas such as automated reasoning, planning, and formal verification. It defines an abstract interface, which can be implemented by different SMT solvers. The interface allows the user to create, traverse, and manipulate terms, as well as dynamically dispatch queries to various underlying SMT solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:FPJr55Dyh1AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,We present a novel approach for solving quantified bit-vector constraints in Satisfiability Modulo Theories (SMT) based on computing symbolic inverses of bit-vector operators. We derive conditions that precisely characterize when bit-vector constraints are invertible for a representative set of bit-vector operators commonly supported by SMT solvers. We utilize syntax-guided synthesis techniques to aid in establishing these conditions and verify them independently by using several SMT solvers. We show that invertibility conditions can be embedded into quantifier instantiations using Hilbert choice expressions and give experimental evidence that a counterexample-guided approach for quantifier instantiation utilizing these techniques leads to performance improvements with respect to state-of-the-art solvers for quantified bit-vector constraints.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:i2xiXl-TujoC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"We present a novel approach to pre-silicon verification of processor designs. The purpose of pre-silicon verification is to find logic bugs in a design at an early stage and thus avoid time- and cost-intensive post-silicon debugging. Our approach relies on symbolic quick error detection (Symbolic QED, or SQED). SQED is targeted at finding logic bugs in a symbolic representation of a design by combining bounded model checking (BMC) with QED tests. QED tests are powerful in generating short sequences of instructions (traces) that trigger bugs. We extend an existing SQED approach with symbolic starting states. This way, we enable the BMC tool to select starting states arbitrarily when generating a trace. To avoid false positives, (e.g., traces starting in unreachable states that may not be-have in accordance with the processor instruction-set architecture), we define constraints to restrict the set of possible starting states. We demonstrate that these constraints, togeth-er with reasonable assumptions about the system behavior, allow us to avoid false positives. Using our approach, we discovered previously unknown bugs in open-source RISC-V processor cores that existing methods cannot detect. Moreover, our novel approach out-performs existing ones in the detection of bugs having long traces and in the detection of hardware Trojans, i.e., unauthorized modifications of a design.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Ug5p-4gJ2f0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Two awards were made in 2021 to honour outstanding papers from the IEEE Symposium On Logic In Computer Science 2001 held in Boston, MA, USA. The awards went to ""A Decision Procedure for an Extensional Theory of Arrays"", by Aaron Stump, Clark W. Barrett, David L. Dill, and Jeremy R. Levitt and to ""Dependent Types for Program Termination Verification"", by Hongwei Xi.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ClCfbGk0d_YC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"lazybvtoint is a new prototype SMT-solver, that will participate in the incremental and non-incremental tracks of the \qfbv logic.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ruyezt5ZtCIC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"The architecture of a coarse-grained reconfigurable array (CGRA) processing element (PE) has a significant effect on the performance and energy efficiency of an application running on the CGRA. This paper presents an automated approach for generating specialized PE architectures for an application or an application domain. Frequent subgraphs mined from a set of applications are merged to form a PE architecture specialized to that application domain. For the image processing and machine learning domains, we generate specialized PEs that are up to 10.5x more energy efficient and consume 9.1x less area than a baseline PE.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:foquWX3nUaYC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"This paper presents a novel approach for quantifier instantiation in Satisfiability Modulo Theories (SMT) that leverages syntax-guided synthesis (SyGuS) to choose instantiation terms. It targets quantified constraints over background theories such as (non)linear integer, reals and floating-point arithmetic, bit-vectors, and their combinations. Unlike previous approaches for quantifier instantiation in these domains which rely on theory-specific strategies, the new approach can be applied to any (combined) theory, when provided with a grammar for instantiation terms for all sorts in the theory. We implement syntax-guided instantiation in the SMT solver CVC4, leveraging its support for enumerative SyGuS. Our experiments demonstrate the versatility of the approach, showing that it is competitive with or exceeds the performance of state-of-the-art solvers on a range of background theories.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:PoWvk5oyLR8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Deep neural networks are widely used for nonlinear function approximation, with applications ranging from computer vision to control. Although these networks involve the composition of simple arithmetic operations, it can be very challenging to verify whether a particular network satisfies certain input-output properties. This article surveys methods that have emerged recently for soundly verifying such properties. These methods borrow insights from reachability analysis, optimization, and search. We discuss fundamental differences and connections between existing algorithms. In addition, we provide pedagogical implementations of existing methods and compare them on a set of benchmark problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:dQ2og3OwTAUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Symbolic model checking is an important tool for finding bugs (or proving the absence of bugs) in modern system designs. Because of this, improving the ease of use, scalability, and performance of model checking tools and algorithms continues to be an important research direction. In service of this goal, we present Pono, an open-source SMT-based model checker. Pono is designed to be both a research platform for developing and improving model checking algorithms, as well as a performance-competitive tool that can be used for academic and industry verification applications. In addition to performance, Pono prioritizes transparency (developed as an open-source project on GitHub), flexibility (Pono can be adapted to a variety of tasks by exploiting its general SMT-based interface), and extensibility (it is easy to add new algorithms and new back-end solvers). In this paper, we describe the design of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:5qfkUJPXOUwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"We make two contributions to the study of polite combination in satisfiability modulo theories. The first is a separation between politeness and strong politeness, by presenting a polite theory that is not strongly polite. This result shows that proving strong politeness (which is often harder than proving politeness) is sometimes needed in order to use polite combination. The second contribution is an optimization to the polite combination method, obtained by borrowing from the Nelson-Oppen method. The Nelson-Oppen method is based on guessing arrangements over shared variables. In contrast, polite combination requires an arrangement over all variables of the shared sorts. We show that when using polite combination, if the other theory is stably infinite with respect to a shared sort, only the shared variables of that sort need be considered in arrangements, as in the Nelson-Oppen method. The time required to reason about arrangements is exponential in the worst case, so reducing the number of variables considered has the potential to improve performance significantly. We show preliminary evidence for this by demonstrating a speed-up on a smart contract verification benchmark.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HbR8gkJAVGIC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"We introduce DeepCert, a tool-supported method for verifying the robustness of deep neural network (DNN) image classifiers to contextually relevant perturbations such as blur, haze, and changes in image contrast. While the robustness of DNN classifiers has been the subject of intense research in recent years, the solutions delivered by this research focus on verifying DNN robustness to small perturbations in the images being classified, with perturbation magnitude measured using established norms. This is useful for identifying potential adversarial attacks on DNN image classifiers, but cannot verify DNN robustness to contextually relevant image perturbations, which are typically not small when expressed with norms. DeepCert addresses this underexplored verification problem by supporting: (1) the encoding of real-world image perturbations; (2) the systematic evaluation of contextually relevant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:SpbeaW3--B0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"We develop a framework for model checking infinite-state systems by automatically augmenting them with auxiliary variables, enabling quantifier-free induction proofs for systems that would otherwise require quantified invariants. We combine this mechanism with a counterexample-guided abstraction refinement scheme for the theory of arrays. Our framework can thus, in many cases, reduce inductive reasoning with quantifiers and arrays to quantifier-free and array-free reasoning. We evaluate the approach on a wide set of benchmarks from the literature. The results show that our implementation often outperforms state-of-the-art tools, demonstrating its practical potential.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:S16KYo8Pm5AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Deep learning has emerged as an effective approach for creating modern software systems, with neural networks often surpassing hand-crafted systems. Unfortunately, neural networks are known to suffer from various safety and security issues. Formal verification is a promising avenue for tackling this difficulty, by formally certifying that networks are correct. We propose an SMT-based technique for verifying binarized neural networks — a popular kind of neural network, where some weights have been binarized in order to render the neural network more memory and energy efficient, and quicker to evaluate. One novelty of our technique is that it allows the verification of neural networks that include both binarized and non-binarized components. Neural network verification is computationally very difficult, and so we propose here various optimizations, integrated into our SMT procedure as deduction steps …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:WZBGuue-350C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"This paper presents Smt-Switch, an open-source, solver-agnostic API for SMT solving. Smt-Switch provides simple, uniform, and high-performance access to SMT solving for applications in areas such as automated reasoning, planning, and formal verification. It defines an abstract interface, which can be implemented by different SMT solvers. The interface allows the user to create, traverse, and manipulate terms, as well as dynamically dispatch queries to various underlying SMT solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:gsN89kCJA0AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"The ACAS X family of aircraft collision avoidance systems uses large numeric lookup tables to make decisions. Recent work used a deep neural network to approximate and compress a collision avoidance table, and simulations showed that the neural network performance was comparable to the original table. Consequently, neural network representations are being explored for use on small aircraft with limited storage capacity. However, the black-box nature of deep neural networks raises safety concerns because simulation results are not exhaustive. This work takes steps towards addressing these concerns by applying formal methods to analyze the behavior of collision avoidance neural networks both in isolation and in a closed-loop system. We evaluate our approach on a specific set of collision avoidance networks and show that even though the networks are not always locally robust, their closed-loop …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:oNZyr7d5Mn4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"The theory of strings supported by solvers in formal methods contains a large number of operators. Instead of implementing a semi-decision procedure that reasons about all the operators directly, string solvers often reduce operators to a core fragment and implement a semi-decision procedure over that fragment. These reductions considerably increase the number of constraints and thus have to be done carefully to achieve good performance. We propose novel reductions from regular expressions to string constraints and a framework for minimizing the introduction of new variables in current reductions of string constraints. The reductions of regular expression constraints enable string solvers to handle a significant fragment of such constraints without using dedicated reasoning over regular expressions. Minimizing the number of variables in the reduced constraints makes those constraints significantly cheaper to solve by the core solver. An experimental evaluation of our implementation of both techniques in CVC4, a state-of-the-art SMT solver with extensive support for the theory of strings, shows that they significantly improve the solver’s performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:LI9QrySNdTsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Although an agile approach is standard for software design, how to properly adapt this method to hardware is still an open question. This work addresses this question while building a system on chip (SoC) with specialized accelerators. Rather than using a traditional waterfall design flow, which starts by studying the application to be accelerated, we begin by constructing a complete flow from an application expressed in a high-level domain-specific language (DSL), in our case Halide, to a generic coarse-grained reconfigurable array (CGRA). As our under-standing of the application grows, the CGRA design evolves, and we have developed a suite of tools that tune application code, the compiler, and the CGRA to increase the efficiency of the resulting implementation. To meet our continued need to update parts of the system while maintaining the end-to-end flow, we have created DSL-based hardware generators …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:MLfJN-KU85MC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"We present A-QED (Accelerator-Quick Error Detection), a new approach for pre-silicon formal verification of stand-alone hardware accelerators. A-QED relies on bounded model checking -- however, it does not require extensive design-specific properties or a full formal design specification. While A- QED is effective for both RTL and high-level synthesis (HLS) design flows, it integrates seamlessly with HLS flows. Our A-QED results on several hardware accelerator designs demonstrate its practicality and effectiveness: 1. A-QED detected all bugs detected by conventional verification flow. 2. A-QED detected bugs that escaped conventional verification flow. 3. A-QED improved verification productivity dramatically, by 30X, in one of our case studies (1 person-day using A-QED vs. 30 person-days using conventional verification flow). 4. A-QED produced short counterexamples for easy debug (37X shorter on average vs …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:tuHXwOkdijsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Algebraic datatypes, and among them lists and trees, have attracted a lot of interest in automated reasoning and Satisfiability Modulo Theories (SMT). Since its latest stable version, the SMT-LIB standard defines a theory of algebraic datatypes, which is currently supported by several mainstream SMT solvers. In this paper, we study this particular theory of datatypes and prove that it is strongly polite, showing also how it can be combined with other arbitrary disjoint theories using polite combination. Our results cover both inductive and finite datatypes, as well as their union. The combination method uses a new, simple, and natural notion of additivity, that enables deducing strong politeness from (weak) politeness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:4MWp96NkSFoC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Symbolic model checking has become an important part of the verification flow in industrial hardware design. However, its use is still limited due to scaling issues. One way to address this is to exploit the large amounts of symmetry present in many real world designs. In this paper, we adapt partial order reduction for bounded model checking of synchronous hardware and introduce a novel technique that makes partial order reduction practical in this new domain. These approaches are largely automatic, requiring only minimal manual effort. We evaluate our technique on open-source and commercial packet mover circuits – designs containing FIFOs and arbiters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:p__nRnzSRKYC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Smart contracts are programs that implement potentially sophisticated transactions on modern blockchain platforms. In the rapidly evolving blockchain environment, smart contract programming languages must allow users to write expressive programs that manage and transfer assets, yet provide strong protection against sophisticated attacks. Addressing this need, we present flexible and reliable abstractions for programming with digital currency in the Move language [Blackshear et al. 2019]. Move uses novel linear [Girard 1987] resource types with semantics drawing on C++11 [Stroustrup 2013] and Rust [Matsakis and Klock 2014]: when a resource value is assigned to a new memory location, the location previously holding it must be invalidated. In addition, a resource type can only be created or destroyed by procedures inside its declaring module. We present an executable bytecode language with resources and prove that it enjoys resource safety, a conservation property for program values that is analogous to conservation of mass in the physical world.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ML0RJ9NH7IQC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"The required manual effort and verification expertise are among the main hurdles for adopting formal verification in processor design flows. Developing a set of properties that fully covers all instruction behaviors is a laborious and challenging task. This paper proposes a highly automated and ""complete"" processor verification approach which requires considerably less manual effort and expertise compared to the state of the art.The proposed approach extends the S 2 QED approach to cover both single and multiple instruction bugs and ensures that a design is completely verified according to a well-defined criterion. This makes the approach robust against human errors. The properties are simple and can be automatically generated from an ISA model with small manual effort. Furthermore, unlike in conventional property checking, the verification engineer does not need to explicitly specify the processor's behavior …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:g3aElNc5_aQC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Disclosed are improved methods and structures for verifying integrated circuits and in particular systems-on-a-chip constructed therefrom. We call methods and structures according to the present disclosure Symbolic Quick Error Detection or Symbolic QED, Illustrative characteristics of Symbolic QED include: 1) It is applicable to any System-on-Chip (SoC) design as long as it contains at least one programmable processor; 2) It is broadly applicable for logic bugs inside processor cores, accelerators, and uncore components; 3) It does not require failure reproduction; 4) It does not require human intervention during bug localization; 5) It does not require trace buffers, 6) It does not require assertions; and 7) It uses hardware structures called “change detectors” which introduce only a small area overhead. Symbolic QED exhibits: 1) A systematic (and automated) approach to inserting “change detectors” during a design …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:bnK-pcrLprsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Conclusion. This is a prototype experimental tool that is aimed to serve as a playground for arithmetic-based techniques for bit-vector solving. Incorporating such techniques in a fullfledged solver is left for future work, and is planned for when these techniques are better understood and evaluated using this tool.
Acknowledgments. We would like to thank the CVC4 and MathSAT5 teams for allowing us to use their tools. In particular, we thank Alberto Griggio for clarifying the relevant aspects of the MathSAT5 license, and to Aina Niemetz and Mathias Preiner for helpful tips regarding benchmarking and evaluating bit-vector formulas. We also thank the competition organizers, Haniel Barbosa, Jochen Hoenicke, and Antti Hyvarinen for clarifying the status of this tool for the competition and willingly accepting it as a new participant.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:YohjEiUPhakC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Deep neural network (DNN) verification is an emerging field, with diverse verification engines quickly becoming available. Demonstrating the effectiveness of these engines on real-world DNNs is an important step towards their wider adoption. We present a tool that can leverage existing verification engines in performing a novel application: neural network simplification, through the reduction of the size of a DNN without harming its accuracy. We report on the work-flow of the simplification process, and demonstrate its potential significance and applicability on a family of real-world DNNs for aircraft collision avoidance, whose sizes we were able to reduce by as much as 10%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:b1wdh0AR-JQC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"The Libra blockchain is designed to store billions of dollars in assets, so the security of code that executes transactions is important. The Libra blockchain has a new language for implementing transactions, called “Move.” This paper describes the Move Prover, an automatic formal verification system for Move. We overview the unique features of the Move language and then describe the architecture of the Prover, including the language for formal specification and the translation to the Boogie intermediate verification language .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:kuK5TVdYjLIC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"In text encoding standards such as Unicode, text strings are sequences of code points, each of which can be represented as a natural number. We present a decision procedure for a concatenation-free theory of strings that includes length and a conversion function from strings to integer code points. Furthermore, we show how many common string operations, such as conversions between lowercase and uppercase, can be naturally encoded using this conversion function. We describe our implementation of this approach in the SMT solver CVC4, which contains a high-performance string subsolver, and show that the use of a native procedure for code points significantly improves its performance with respect to other state-of-the-art string solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:TIZ-Mc8IlK0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"While hardware generators have drastically improved design productivity, they have introduced new challenges for the task of verification. To effectively cover the functionality of a sophisticated generator, verification engineers require tools that provide the flexibility of metaprogramming. However, flexibility alone is not enough; components must also be portable in order to encourage the proliferation of verification libraries as well as enable new methodologies. This paper introduces fault, a Python embedded hardware verification language that aims to empower design teams to realize the full potential of generators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:tYavs44e6CUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Symbolic quick error detection (SQED) is a formal pre-silicon verification technique targeted at processor designs. It leverages bounded model checking (BMC) to check a design for counterexamples to a self-consistency property: given the instruction set architecture (ISA) of the design, executing an instruction sequence twice on the same inputs must always produce the same outputs. Self-consistency is a universal, implementation-independent property. Consequently, in contrast to traditional verification approaches that use implementationspecific assertions (often generated manually), SQED does not require a full formal design specification or manually-written properties. Case studies have shown that SQED is effective for commercial designs and that SQED substantially improves design productivity. However, until now there has been no formal characterization of its bug-finding capabilities. We aim to close this gap by laying a formal foundation for SQED. We use a transition-system processor model and define the notion of a bug using an abstract specification relation. We prove the soundness of SQED, ie, that any bug reported by SQED is in fact a real bug in the processor. Importantly, this result holds regardless of what the actual specification relation is. We next describe conditions under which SQED is complete, that is, what kinds of bugs it is guaranteed to find. We show that for a large class of bugs, SQED can always find a trace exhibiting the bug. Ultimately, we prove full completeness of a variant of SQED that uses specialized state reset instructions. Our results enable a rigorous understanding of SQED and its bug-finding capabilities …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ILKRHgRFtOwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Inspired by recent successes of parallel techniques for solving Boolean satisfiability, we investigate a set of strategies and heuristics to leverage parallelism and improve the scalability of neural network verification. We present a general description of the Split-and-Conquer partitioning algorithm, implemented within the Marabou framework, and discuss its parameters and heuristic choices. In particular, we explore two novel partitioning strategies, that partition the input space or the phases of the neuron activations, respectively. We introduce a branching heuristic and a direction heuristic that are based on the notion of polarity. We also introduce a highly parallelizable pre-processing algorithm for simplifying neural network verification problems. An extensive experimental evaluation shows the benefit of these techniques on both existing and new benchmarks. A preliminary experiment ultra-scaling our algorithm using a large distributed cloud-based platform also shows promising results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:BwyfMAYsbu0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Deep neural networks are revolutionizing the way complex systems are developed. However, these automatically-generated networks are opaque to humans, making it difficult to reason about them and guarantee their correctness. Here, we propose a novel approach for verifying properties of a widespread variant of neural networks, called recurrent neural networks. Recurrent neural networks play a key role in, e.g., speech recognition, and their verification is crucial for guaranteeing the reliability of many critical systems. Our approach is based on the inference of invariants, which allow us to reduce the complex problem of verifying recurrent networks into simpler, non-recurrent problems. Experiments with a proof-of-concept implementation of our approach demonstrate that it performs orders-of-magnitude better than the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Z5m8FVwuT1cC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Coarse-grained reconfigurable architectures (CGRAs) are becoming popular accelerators for computationally intensive tasks. CGRAs offer the reconfigurability of an FPGA, but with larger configurable blocks which provide performance closer to ASICs. CGRAs can achieve very high compute density if the routing networks are restricted; however, mapping using traditional annealing-based approaches does not perform well for such architectures. This paper uses Satisfiability Modulo Theories (SMT) solvers to rapidly map designs onto arbitrary CGRA fabrics. This approach is sound, complete, and in many cases an order of magnitude faster than state-of-the-art constraint-based mapping techniques using integer linear programming (ILP). Additionally, we propose a functional duplication strategy that decreases pressure on the routing network from high-fanout operations, leading to significant performance …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:BUYA1_V_uYcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"This special issue consists of extended versions of papers selected from the 9th NASA Formal Methods Symposium (NFM 2017). The symposium was held at the NASA Ames Research Center, Moffett Field, CA, on May 16–18, 2017. NFM is a forum to foster collaboration between theoreticians and practitioners from NASA, academia, and industry, with the goal of identifying challenges and providing solutions to achieving assurance in mission-and safety-critical systems. Examples of such systems include advanced separation assurance algorithms for aircraft, next-generation air transportation, autonomous rendezvous and docking for spacecraft, autonomous on-board software for unmanned aerial systems (UAS), UAS traffic management, autonomous robots, and systems for fault detection, diagnosis, and prognostics. The topics covered by the NASA Formal Methods Symposium include: model checking, theorem …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ye4kPcJQO24C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"As designs grow in size and complexity, design verification becomes one of the most difficult and costly tasks facing design teams. Formal verification techniques offer great promise because of their ability to exhaustively explore design behaviors. However, formal techniques also have a reputation for being labor-intensive and limited to small blocks. Is there any hope for successful application of formal techniques at design scale? We answer this question affirmatively by digging deeper to understand what the real technological issues and opportunities are. First, we look at satisfiability solvers, the engines underlying formal techniques such as model checking. Given the recent innovations in satisfiability solving, we argue that there are many reasons to be optimistic that formal techniques will scale to designs of practical interest. We use our CoSA model checker as a demonstration platform to illustrate how …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ipzZ9siozwsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"The AAAI 2019 Spring Series was held Monday through Wednesday, March 25–27, 2019 on the campus of Stanford University, adjacent to Palo Alto, California. The titles of the nine symposia were Artificial Intelligence, Autonomous Machines, and Human Awareness: User Interventions, Intuition and Mutually Constructed Context; Beyond Curve Fitting—Causation, Counterfactuals and Imagination-Based AI; Combining Machine Learning with Knowledge Engineering; Interpretable AI for Well-Being: Understanding Cognitive Bias and Social Embeddedness; Privacy-Enhancing Artificial Intelligence and Language Technologies; Story-Enabled Intelligence; Towards Artificial Intelligence for Collaborative Open Science; Towards Conscious AI Systems; and Verification of Neural Networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:XD-gHx7UXLsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Detect and avoid (DAA) all other aircraft is a critical component to enable small unmanned aircraft system (sUAS) beyond visual line of sight (BVLOS) operations. Derived from the version of Airborne Collision Avoidance System X (ACAS X) for large UAS (ACAS Xu), a new member of the ACAS X family for sUAS (ACAS sXu) is being developed by the Federal Aviation Administration's (FAA's) Traffic-Alert and Collision Avoidance System (TCAS) Program Office. ACAS sXu is intended to provide both collision avoidance (CA) and remain well clear (RWC) capabilities with both vertical and horizontal advisories for the remote pilot in command (RPIC) and/or automated response system onboard the aircraft. ACAS sXu is envisioned to utilize a standard logic to serve sUASs with different equipages and operating in different airspace domains. The standard ACAS sXu logic may be hosted either in the embedded …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:t7zJ5fGR-2UC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"This work is a part of an ongoing effort to prove the correctness of invertibility conditions for the theory of fixed-width bit-vectors, which are used to solve quantified bit-vector formulas in the Satisfiability Modulo Theories (SMT) solver CVC4. While many of these were proved in a completely automatic fashion for any bit-width, some were only proved for bit-widths up to 65, even though they are being used to solve formulas over arbitrary bit-widths. In this paper we describe our initial efforts in proving a subset of these invertibility conditions in the Coq proof assistant. We describe the Coq library that we use, as well as the extensions that we introduced to it.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:uJ-U7cs_P_0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Deep reinforcement learning (RL) has recently been successfully applied to networking contexts including routing, flow scheduling, congestion control, packet classification, cloud resource management, and video streaming. Deep-RL-driven systems automate decision making, and have been shown to outperform state-of-the-art handcrafted systems in important domains. However, the (typical) non-explainability of decisions induced by the deep learning machinery employed by these systems renders reasoning about crucial system properties, including correctness and security, extremely difficult. We show that despite the obscurity of decision making in these contexts, verifying that deep-RL-driven systems adhere to desired, designer-specified behavior, is achievable. To this end, we initiate the study of formal verification of deep RL and present Verily, a system for verifying deep-RL-based systems that leverages …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:35r97b3x0nAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"CVC4Sy is a syntax-guided synthesis (SyGuS) solver based on bounded term enumeration and, for restricted fragments, quantifier elimination. The enumerative strategies are based on encoding term enumeration as an extension of the quantifier-free theory of algebraic datatypes and on a highly optimized brute-force algorithm. The quantifier elimination strategy extracts solutions from unsatisfiability proofs of the negated form of synthesis conjectures. It uses recent counterexample-guided techniques for quantifier instantiation that make finding such proofs practically feasible. CVC4Sy implements these strategies by extending the satisfiability modulo theories (SMT) solver CVC4. The strategy to be applied on a given problem is chosen heuristically based on the problem's structure. This document gives an overview of these techniques and their implementation in the SyGuS Solver CVC4Sy, an entry for SyGuS-Comp 2019.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:EkHepimYqZsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"We present an industrial case study that demonstrates the practicality and effectiveness of Symbolic Quick Error Detection (Symbolic QED) in detecting logic design flaws (logic bugs) during pre-silicon verification. Our study focuses on several microcontroller core designs (~1,800 flip-flops, ~70,000 logic gates) that have been extensively verified using an industrial verification flow and used for various commercial automotive products. The results of our study are as follows: 1. Symbolic QED detected all logic bugs in the designs that were detected by the industrial verification flow (which includes various flavors of simulation-based verification and formal verification). 2. Symbolic QED detected additional logic bugs that were not recorded as detected by the industrial verification flow. (These additional bugs were also perhaps detected by the industrial verification flow.)3.Symbolic QED enables significant design …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:5awf1xo2G04C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Recent discovery of security attacks in advanced processors, known as Spectre and Meltdown, has resulted in high public alertness about security of hardware. The root cause of these attacks is information leakage across covert channels that reveal secret data without any explicit information flow between the secret and the attacker. Many sources believe that such covert channels are intrinsic to highly advanced processor architectures based on speculation and out-of-order execution, suggesting that such security risks can be avoided by staying away from high-end processors. This paper, however, shows that the problem is of wider scope: we present new classes of covert channel attacks which are possible in average-complexity processors with in-order pipelining, as they are mainstream in applications ranging from Internet-of-Things to Autonomous Systems. We present a new approach as a foundation for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:eq2jaN3J8jMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"The International Conference on Formal Methods in Computer Aided Design (FMCAD), held in San Jose, California, from October 22-25 in 2019, is the nineteenth in a series of meetings on the theory and applications of rigorous formal techniques for the automated design of systems. The FMCAD conference covers formal aspects of specification, verification, synthesis, testing, and security, and is a leading forum for researchers and practitioners in academia and industry alike. The program of FMCAD 2019 comprises a tutorial day with three tutorials on program synthesis, verification of analog and mixed-signal circuits, and post-silicon validation; two keynotes on safe autonomy and formal methods for hardware security; and a forum for doctoral students. Finally, the main program contains the presentations of the accepted papers. The tutorial day features three presentations:",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:AvfA0Oy_GE0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:yB1At4FlUx8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"The Boolean Satisfiability (SAT) problem is the canonical NP-complete problem and is fundamental to computer science, with a wide array of applications in planning, verification, and theorem proving. Developing and evaluating practical SAT solvers relies on extensive empirical testing on a set of real-world benchmark formulas. However, the availability of such real-world SAT formulas is limited. While these benchmark formulas can be augmented with synthetically generated ones, existing approaches for doing so are heavily hand-crafted and fail to simultaneously capture a wide range of characteristics exhibited by real-world SAT instances. In this work, we present G2SAT, the first deep generative framework that learns to generate SAT formulas from a given set of input formulas. Our key insight is that SAT formulas can be transformed into latent bipartite graph representations which we model using a specialized deep generative neural network. We show that G2SAT can generate SAT formulas that closely resemble given real-world SAT instances, as measured by both graph metrics and SAT solver behavior. Further, we show that our synthetic SAT formulas could be used to improve SAT solver performance on real-world benchmarks, which opens up new opportunities for the continued development of SAT solvers and a deeper understanding of their performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:nrtMV_XWKgEC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Deep neural networks are revolutionizing the way complex systems are designed. Consequently, there is a pressing need for tools and techniques for network analysis and certification. To help in addressing that need, we present Marabou, a framework for verifying deep neural networks. Marabou is an SMT-based tool that can answer queries about a network’s properties by transforming these queries into constraint satisfaction problems. It can accommodate networks with different activation functions and topologies, and it performs high-level reasoning on the network that can curtail the search space and improve performance. It also supports parallel execution to further enhance scalability. Marabou accepts multiple input formats, including protocol buffer files generated by the popular TensorFlow framework for neural networks. We describe the system architecture and main components, evaluate the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:-_dYPAW6P2MC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Automated reasoning procedures are essential for a number of applications that involve bit-exact floating-point computations. This paper presents conditions that characterize when a variable in a floating-point constraint has a solution, which we call invertibility conditions. We describe a novel workflow that combines human interaction and a syntax-guided synthesis (SyGuS) solver that was used for discovering these conditions. We verify our conditions for several floating-point formats. One implication of this result is that a fragment of floating-point arithmetic admits compact quantifier elimination. We implement our invertibility conditions in a prototype extension of our solver CVC4, showing their usefulness for solving quantified constraints over floating-points.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:evX43VCCuoAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"The performance of modern Satisfiability Modulo Theories (SMT) solvers relies crucially on efficient decision procedures as well as static simplification techniques, which include large sets of rewrite rules. Manually discovering and implementing rewrite rules is challenging. In this work, we propose a framework that uses enumerative syntax-guided synthesis (SyGuS) to propose rewrite rules that are not implemented in a given SMT solver. We implement this framework in cvc4, a state-of-the-art SMT and SyGuS solver, and evaluate several use cases. We show that some SMT solvers miss rewriting opportunities, or worse, have bugs in their rewriters. We also show that a variation of our approach can be used to test the correctness of a rewriter. Finally, we show that rewrites discovered with this technique lead to significant improvements in cvc4 on both SMT and SyGuS problems over bit-vectors and strings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:_Re3VWB3Y0AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Satisfiability Modulo Theories (SMT) solvers with support for the theory of strings have recently emerged as powerful tools for reasoning about string-manipulating programs. However, due to the complex semantics of extended string functions, it is challenging to develop scalable solvers for the string constraints produced by program analysis tools. We identify several classes of simplification techniques that are critical for the efficient processing of string constraints in SMT solvers. These techniques can reduce the size and complexity of input constraints by reasoning about arithmetic entailment, multisets, and string containment relationships over input terms. We provide experimental evidence that implementing them results in significant improvements over the performance of state-of-the-art SMT solvers for extended string constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ZfRJV9d4-WMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Many state-of-the-art Satisfiability Modulo Theories (SMT) solvers for the theory of fixed-size bit-vectors employ an approach called bit-blasting, where a given formula is translated into a Boolean satisfiability (SAT) problem and delegated to a SAT solver. Consequently, producing bit-vector proofs in an SMT solver requires incorporating SAT proofs into its proof infrastructure. In this paper, we describe three approaches for integrating DRAT proofs generated by an off-the-shelf SAT solver into the proof infrastructure of the SMT solver CVC4 and explore their strengths and weaknesses. We implemented all three approaches using CryptoMiniSat as the SAT back-end for its bit-blasting engine and evaluated performance in terms of proof-production and proof-checking.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:tKAzc9rXhukC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Many SMT solvers implement efficient SAT-based procedures for solving fixed-size bit-vector formulas. These approaches, however, cannot be used directly to reason about bit-vectors of symbolic bit-width. To address this shortcoming, we propose a translation from bit-vector formulas with parametric bit-width to formulas in a logic supported by SMT solvers that includes non-linear integer arithmetic, uninterpreted functions, and universal quantification. While this logic is undecidable, this approach can still solve many formulas by capitalizing on advances in SMT solving for non-linear arithmetic and universally quantified formulas. We provide several case studies in which we have applied this approach with promising results, including the bit-width independent verification of invertibility conditions, compiler optimizations, and bit-vector rewrites.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:NJ774b8OgUMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"We present cvc4sy, a syntax-guided synthesis (SyGuS) solver based on three bounded term enumeration strategies. The first encodes term enumeration as an extension of the quantifier-free theory of algebraic datatypes. The second is based on a highly optimized brute-force algorithm. The third combines elements of the others. Our implementation of the strategies within the satisfiability modulo theories (SMT) solver cvc4 and a heuristic to choose between them leads to significant improvements over state-of-the-art SyGuS solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Fu2w8maKXqMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"SMT solvers have throughout the years been able to cope with increasingly expressive formulas, from ground logics to full first-order logic (FOL). In contrast, the extension of SMT solvers to higher-order logic (HOL) is mostly unexplored. We propose a pragmatic extension for SMT solvers to support HOL reasoning natively without compromising performance on FOL reasoning, thus leveraging the extensive research and implementation efforts dedicated to efficient SMT solving. We show how to generalize data structures and the ground decision procedure to support partial applications and extensionality, as well as how to reconcile quantifier instantiation techniques with higher-order variables. We also discuss a separate approach for redesigning an HOL SMT solver from the ground up via new data structures and algorithms. We apply our pragmatic extension to the CVC4 SMT solver and discuss a redesign …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:JQOojiI6XY0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Recent discovery of security attacks in advanced processors, known as Spectre and Meltdown, has resulted in high public alertness about security of hardware. The root cause of these attacks is information leakage across"" covert channels"" that reveal secret data without any explicit information flow between the secret and the attacker. Many sources believe that such covert channels are intrinsic to highly advanced processor architectures based on speculation and out-of-order execution, suggesting that such security risks can be avoided by staying away from high-end processors. This paper, however, shows that the problem is of wider scope: we present new classes of covert channel attacks which are possible in average-complexity processors with in-order pipelining, as they are mainstream in applications ranging from Internet-of-Things to Autonomous Systems. We present a new approach as a foundation for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:zLWjf1WUPmwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Symbolic model-checking is a well-established technique used in hardware design to assess, and formally verify, functional correctness. However, most modern model-checkers encode the problem into propositional satisfiability (SAT) and do not leverage any additional information beyond the input design, which is typically provided in a hardware description language such as Verilog.In this paper, we present CoSA (CoreIR Symbolic Analyzer), a model-checking tool for CoreIR designs. CoreIR is a new intermediate representation for hardware. CoSA encodes model-checking queries into first-order formulas that can be solved by Satisfiability Modulo Theories (SMT) solvers. In particular, it natively supports encodings using the theories of bitvectors and arrays. CoSA is closely integrated with CoreIR and can thus leverage CoreIR-generated metadata in addition to user-provided lemmas to assist with formal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:AXPGKjj_ei8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"We present a novel approach for solving quantified bit-vector formulas in Satisfiability Modulo Theories (SMT) based on computing symbolic inverses of bit-vector operators. We derive conditions that precisely characterize when bit-vector constraints are invertible for a representative set of bit-vector operators commonly supported by SMT solvers. We utilize syntax-guided synthesis techniques to aid in establishing these conditions and verify them independently by using several SMT solvers. We show that invertibility conditions can be embedded into quantifier instantiations using Hilbert choice expressions, and give experimental evidence that a counterexample-guided approach for quantifier instantiation utilizing these techniques leads to performance improvements with respect to state-of-the-art solvers for quantified bit-vector constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:wbdj-CoPYUoC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"This paper is a description of the CVC4 SMT solver as entered into the 2018 SMT Competition. We only list important differences from the 2017 SMT Competition version of CVC4. For further and more detailed information about CVC4, please refer to the original paper, the CVC4 website, or the source code on GitHub.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HE397vMXCloC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"We present Symbolic Quick Error Detection (Symbolic QED), a structured approach for logic bug detection and localization which can be used both during pre-silicon design verification as well as post-silicon validation and debug. This new methodology leverages prior work on Quick Error Detection (QED) which has been demonstrated to drastically reduce the latency, in terms of the number of clock cycles, of error detection following the activation of a logic (or electrical) bug. QED works through software transformations, including redundant execution and control flow checking, of the applied tests. Symbolic QED combines these error-detecting QED transformations with bounded model checking-based formal analysis to generate minimal-length bug activation traces that detect and localize any logic bugs in the design. We demonstrate the practicality and effectiveness of Symbolic QED using the OpenSPARC T2, a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:BrmTIyaxlBUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"With the rise of programmable network switches, network infrastructure is becoming more flexible and more capable than ever before. Programming languages such as P4 lower the barrier for changing the inner workings of network switches and offer a uniform experience across different devices. However, this programmability also brings the risk of introducing hard-to-catch bugs at a level that was previously covered by well-tested devices with a fixed set of capabilities. Subtle discrepancies between different implementations pose a risk of introducing bugs at a layer that is opaque to the user.
To reap the benefit of programmable hardware and keep---or improve upon---the reliability of traditional approaches, new tools are needed. In this work, we present p4pktgen, a tool for automatically generating test cases for P4 programs using symbolic execution. These test cases can be used to validate that P4 programs act …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:J-pR_7NvFogC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Driven by the demand for highly customizable processor cores for IoT and related applications, there is a renewed interest in effective but low-cost techniques for verifying systems-on-chip (SoCs). This paper revisits the problem of processor verification and presents a radically different approach when compared to the state of the art. The proposed approach is highly automated and leverages recent progress in the field of post-silicon validation by the method of Quick Error Detection (QED) and Symbolic Quick Error Detection (SQED). In this paper, we modify SQED by incorporating a symbolic initial state in its BMC-based analysis and generalize the approach into the S 2 QED method. As a first advantage, S 2 QED can separate logic bugs from electrical bugs in QED-based postsilicon validation. Secondly, it also makes a strong contribution to pre-silicon verification by proving that the execution of each instruction is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:5ugPr518TE4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"The increasing use of deep neural networks for safety-critical applications, such as autonomous driving and flight control, raises concerns about their safety and reliability. Formal verification can address these concerns by guaranteeing that a deep learning system operates as intended, but the state of the art is limited to small systems. In this work-in-progress report we give an overview of our work on mitigating this difficulty, by pursuing two complementary directions: devising scalable verification techniques, and identifying design choices that result in deep learning systems that are more amenable to verification.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:q3oQSFYPqjQC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Satisfiability Modulo Theories (SMT) refers to the problem of determining whether a first-order formula is satisfiable with respect to some logical theory. Solvers based on SMT are used as back-end engines in model-checking applications such as bounded, interpolation-based, and predicate-abstraction-based model checking. After a brief illustration of these uses, we survey the predominant techniques for solving SMT problems with an emphasis on the lazy approach, in which a propositional satisfiability (SAT) solver is combined with one or more theory solvers. We discuss the architecture of a lazy SMT solver, give examples of theory solvers, show how to combine such solvers modularly, and mention several extensions of the lazy approach. We also briefly describe the eager approach in which the SMT problem is reduced to a SAT problem. Finally, we discuss how the basic framework for determining …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HtS1dXgVpQUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:j8SEvjWlNXcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Deep neural networks have achieved impressive results in many complex applications, including classification tasks for image and speech recognition, pattern analysis or perception in self-driving vehicles. However, it has been observed that even highly trained networks are very vulnerable to adversarial perturbations. Adding minimal changes to inputs that are correctly classified can lead to wrong predictions, raising serious security and safety concerns. Existing techniques for checking robustness against such perturbations only consider searching locally around a few individual inputs, providing limited guarantees. We propose DeepSafe, a novel approach for automatically assessing the overall robustness of a neural network. DeepSafe applies clustering over known labeled data and leverages off-the-shelf constraint solvers to automatically identify and check safe regions in which the network is robust …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Mojj43d5GZwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"We introduce a new theory of algebraic datatypes where selector symbols can be shared between multiple constructors, thereby reducing the number of terms considered by current SMT-based solving approaches. We show that the satisfiability problem for the traditional theory of algebraic datatypes can be reduced to problems where selectors are mapped to shared symbols based on a transformation provided in this paper. The use of shared selectors addresses a key bottleneck for an SMT-based enumerative approach to the Syntax-Guided Synthesis (SyGuS) problem. Our experimental evaluation of an implementation of the new theory in the SMT solver cvc4 on syntax-guided synthesis and other domains provides evidence that the use of shared selectors improves state-of-the-art SMT-based approaches for constraints over algebraic datatypes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:1qzjygNMrQYC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Nearly all web-based interfaces are written in JavaScript. Given its prevalence, the support for high performance JavaScript code is crucial. The ECMA Technical Committee 39 (TC39) has recently extended the ECMAScript language (i.e., JavaScript) to support shared memory accesses between different threads. The extension is given in terms of a natural language memory model specification. In this paper we describe a formal approach for validating both the memory model and its implementations in various JavaScript engines. We first introduce a formal version of the memory model and report results on checking the model for consistency and other properties. We then introduce our tool, EMME, built on top of the Alloy analyzer, which leverages the model to generate all possible valid executions of a given JavaScript program. Finally, we report results using EMME together with small test programs to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:kRWSkSYxWN8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:u5HHmVD_uO8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"The softmax function is a ubiquitous component at the output of neural networks and increasingly in intermediate layers as well. This paper provides convex lower bounds and concave upper bounds on the softmax function, which are compatible with convex optimization formulations for characterizing neural networks and other ML models. We derive bounds using both a natural exponential-reciprocal decomposition of the softmax as well as an alternative decomposition in terms of the log-sum-exp function. The new bounds are provably and/or numerically tighter than linear bounds obtained in previous work on robustness verification of transformers. As illustrations of the utility of the bounds, we apply them to verification of transformers as well as of the robustness of predictive uncertainty estimates of deep ensembles.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:8xutWZnSdmoC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"The architecture of a coarse-grained reconfigurable array (CGRA) processing element (PE) has a significant effect on the performance and energy-efficiency of an application running on the CGRA. This paper presents APEX, an automated approach for generating specialized PE architectures for an application or an application domain. APEX first analyzes application domain benchmarks using frequent subgraph mining to extract commonly occurring computational subgraphs. APEX then generates specialized PEs by merging subgraphs using a datapath graph merging algorithm. The merged datapath graphs are translated into a PE specification from which we automatically generate the PE hardware description in Verilog along with a compiler that maps applications to the PE. The PE hardware and compiler are inserted into a flexible CGRA generation and compilation toolchain that allows for agile evaluation of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ZzlSgRqYykMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"Piecewise-affine (PWA) systems are widely used for modeling and control of robotics problems including modeling contact dynamics. A common approach is to encode the control problem of the PWA system as a Mixed-Integer Convex Program (MICP), which can be solved by general-purpose off-the-shelf MICP solvers. To mitigate the scalability challenge of solving these MICP problems, existing work focuses on devising efficient and strong formulations of the problems, while less effort has been spent on exploiting their specific structure to develop specialized solvers. The latter is the theme of our work. We focus on efficiently handling one-hot constraints, which are particularly relevant when encoding PWA dynamics. We have implemented our techniques in a tool, Soy, which organically integrates logical reasoning, arithmetic reasoning, and stochastic local search. For a set of PWA control benchmarks, Soy solves more problems, faster, than two state-of-the-art MICP solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Aul-kAQHnToC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"The high computational and memory requirements of large language model (LLM) inference traditionally make it feasible only with multiple high-end accelerators. Motivated by the emerging demand for latency-insensitive tasks with batched processing, this paper initiates the study of high-throughput LLM inference using limited resources, such as a single commodity GPU. We present FlexGen, a high-throughput generation engine for running LLMs with limited GPU memory. FlexGen can be flexibly configured under various hardware resource constraints by aggregating memory and computation from the GPU, CPU, and disk. Through a linear programming optimizer, it searches for efficient patterns to store and access tensors. FlexGen further compresses these weights and the attention cache to 4 bits with negligible accuracy loss. These techniques enable FlexGen to have a larger space of batch size choices and thus significantly increase maximum throughput. As a result, when running OPT-175B on a single 16GB GPU, FlexGen achieves significantly higher throughput compared to state-of-the-art offloading systems, reaching a generation throughput of 1 token/s for the first time with an effective batch size of 144. On the HELM benchmark, FlexGen can benchmark a 30B model with a 16GB GPU on 7 representative sub-scenarios in 21 hours. The code is available at https://github.com/FMInference/FlexGen",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:_OXeSy2IsFwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"With the slowing of Moore’s law, computer architects have turned to domain-specific hardware specialization to continue improving the performance and efficiency of computing systems. However, specialization typically entails significant modifications to the software stack to properly leverage the updated hardware. The lack of a structured approach for updating the compiler and the accelerator in tandem has impeded many attempts to systematize this procedure. We propose a new approach to enable flexible and evolvable domain-specific hardware specialization based on coarse-grained reconfigurable arrays (CGRAs). Our agile methodology employs a combination of new programming languages and formal methods to automatically generate the accelerator hardware and its compiler from a single source of truth. This enables the creation of design-space exploration frameworks that automatically generate …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:WJVC3Jt7v1AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2023,"We study satisfiability modulo the theory of finite fields and give a decision procedure for this theory. We implement our procedure for prime fields inside the cvc5 SMT solver. Using this theory, we construct SMT queries that verify the correctness of various zero knowledge proof compilers on various input programs. Our experiments show that our implementation is vastly superior to previous approaches (which encode field arithmetic using integers or bit-vectors).",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:F9fV5C73w3QC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"We present VeriX, a first step towards verified explainability of machine learning models in safety-critical applications. Specifically, our sound and optimal explanations can guarantee prediction invariance against bounded perturbations. We utilise constraint solving techniques together with feature sensitivity ranking to efficiently compute these explanations. We evaluate our approach on image recognition benchmarks and a real-world scenario of autonomous aircraft taxiing.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HeT0ZceujKMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Recently, Graph Neural Networks (GNNs) have been applied for scheduling jobs over clusters, achieving better performance than hand-crafted heuristics. Despite their impressive performance, concerns remain over whether these GNN-based job schedulers meet users’ expectations about other important properties, such as strategy-proofness, sharing incentive, and stability. In this work, we consider formal verification of GNN-based job schedulers. We address several domain-specific challenges such as networks that are deeper and specifications that are richer than those encountered when verifying image and NLP classifiers. We develop vegas, the first general framework for verifying both single-step and multi-step properties of these schedulers based on carefully designed algorithms that combine abstractions, refinements, solvers, and proof transfer. Our experimental results show that vegas achieves …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:anf4URPfarAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Neural networks have become critical components of reactive systems in various domains within computer science. Despite their excellent performance, using neural networks entails numerous risks that stem from our lack of ability to understand and reason about their behavior. Due to these risks, various formal methods have been proposed for verifying neural networks; but unfortunately, these typically struggle with scalability barriers. Recent attempts have demonstrated that abstraction-refinement approaches could play a significant role in mitigating these limitations; but these approaches can often produce networks that are so abstract, that they become unsuitable for verification. To deal with this issue, we present CEGARETTE, a novel verification mechanism where both the system and the property are abstracted and refined simultaneously. We observe that this approach allows us to produce abstract networks which are both small and sufficiently accurate, allowing for quick verification times while avoiding a large number of refinement steps. For evaluation purposes, we implemented CEGARETTE as an extension to the recently proposed CEGAR-NN framework. Our results are very promising, and demonstrate a significant improvement in performance over multiple benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:KbBQZpvPDL4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Convolutional neural networks (CNNs) have achieved immense popularity in areas like computer vision, image processing, speech proccessing, and many others. Unfortunately, despite their excellent performance, they are prone to producing erroneous results — for example, minor perturbations to their inputs can result in severe classification errors. In this paper, we present the Cnn-Abs framework, which implements an abstraction-refinement based scheme for CNN verification. Specifically, Cnn-Abs simplifies the verification problem through the removal of convolutional connections in a way that soundly creates an over-approximation of the original problem; it then iteratively restores these connections if the resulting problem becomes too abstract. Cnn-Abs is designed to use existing verification engines as a backend, and our evaluation demonstrates that it can significantly boost the performance of a state-of-the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:bz8QjSJIRt4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Creating a compiler for an instruction set architecture (ISA) requires a set of rewrite rules describing how to translate from the compiler’s intermediate representation (IR) to the ISA. We address this challenge by synthesizing rewrite rules from a register-transfer level (RTL) description of the target architecture (with minimal annotations about its state and the ISA format), together with formal IR semantics, by constructing SMT queries where solutions represent valid rewrite rules. We evaluate our approach on multiple architectures, supporting both integer and floating-point operations. We synthesize both integer and floating-point rewrite rules from an intermediate representation to various reconfigurable array architectures in under 1.2 seconds per rule. We also synthesize integer rewrite rules from WebAssembly to RISC-V with both standard and custom extensions in under 4 seconds per rule, and we synthesize floating-point rewrite rules in under 8 seconds per rule.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:fFSKOagxvKUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Satisfiability modulo theories (SMT) solvers are widely used to prove security and safety properties of computer systems. For these applications, it is crucial that the result reported by an SMT solver be correct. Recently, there has been a renewed focus on producing independently checkable proofs in SMT solvers, partly with the aim of addressing this risk. These proofs record the reasoning done by an SMT solver and are ideally detailed enough to be easy to check. At the same time, modern SMT solvers typically implement hundreds of different term-rewriting rules in order to achieve state-of-the-art performance. Generating detailed proofs for applications of these rules is a challenge, because code implementing rewrite rules can be large and complex. Instrumenting this code to additionally produce proofs makes it even more complex and makes it harder to add new rewrite rules. We propose an alternative approach to the direct instrumentation of the rewriting module of an SMT solver. The approach uses a domain-specific language (DSL) to describe a set of rewrite rules declaratively and then reconstructs detailed proofs for specific rewrite steps on demand based on those declarative descriptions.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:3htObqc8RwsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"With the increasing application of deep learning in mission-critical systems, there is a growing need to obtain formal guarantees about the behaviors of neural networks. Indeed, many approaches for verifying neural networks have been recently proposed, but these generally struggle with limited scalability or insufficient accuracy. A key component in many state-of-the-art verification schemes is computing lower and upper bounds on the values that neurons in the network can obtain for a specific input domain—and the tighter these bounds, the more likely the verification is to succeed. Many common algorithms for computing these bounds are variations of the symbolic-bound propagation method; and among these, approaches that utilize a process called back-substitution are particularly successful. In this paper, we present an approach for making back-substitution produce tighter bounds. To achieve this, we formulate and then minimize the imprecision errors incurred during back-substitution. Our technique is general, in the sense that it can be integrated into numerous existing symbolic-bound propagation techniques, with only minor modifications. We implement our approach as a proofof-concept tool, and present favorable results compared to stateof-the-art verifiers that perform back-substitution.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ODE9OILHJdcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Deep neural networks (DNNs) are increasingly being employed in safety-critical systems, and there is an urgent need to guarantee their correctness. Consequently, the verification community has devised multiple techniques and tools for verifying DNNs. When DNN verifiers discover an input that triggers an error, that is easy to confirm; but when they report that no error exists, there is no way to ensure that the verification tool itself is not flawed. As multiple errors have already been observed in DNN verification tools, this calls the applicability of DNN verification into question. In this work, we present a novel mechanism for enhancing Simplex-based DNN verifiers with proof production capabilities: the generation of an easy-tocheck witness of unsatisfiability, which attests to the absence of errors. Our proof production is based on an efficient adaptation of the well-known Farkas’ lemma, combined with mechanisms for handling piecewise-linear functions and numerical precision errors. As a proof of concept, we implemented our technique on top of the Marabou DNN verifier. Our evaluation on a safetycritical system for airborne collision avoidance shows that proof production succeeds in almost all cases and requires only minimal overhead.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:umqufdRvDiIC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"We develop a framework for model checking infinite-state systems by automatically augmenting them with auxiliary variables, enabling quantifier-free induction proofs for systems that would otherwise require quantified invariants. We combine this mechanism with a counterexample-guided abstraction refinement scheme for the theory of arrays. Our framework can thus, in many cases, reduce inductive reasoning with quantifiers and arrays to quantifier-free and array-free reasoning. We evaluate the approach on a wide set of benchmarks from the literature. The results show that our implementation often outperforms state-of-the-art tools, demonstrating its practical potential.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:OcBU2YAGkTUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"SMT solvers are highly complex pieces of software with performance, robustness, and correctness as key requirements. Complementing traditional testing techniques for these solvers with randomized stress testing has been shown to be quite effective. Recent work has showcased the value of input fuzzing for finding issues, but this approach typically does not comprehensively test a solver’s API. Previous work on model-based API fuzzing was tailored to a single solver and a small subset of SMT-LIB. We present Murxla, a comprehensive, modular, and highly extensible model-based API fuzzer for SMT solvers. Murxla randomly generates valid sequences of solver API calls based on a customizable API model, with full support for the semantics and features of SMT-LIB. It is solver-agnostic but extensible to allow for solver-specific testing and supports option fuzzing, cross-checking with other solvers, translation to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:yFnVuubrUp4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"In the past decade, satisfiability modulo theories (SMT) solvers have been extended to support the theory of strings and regular expressions. This theory has proven to be useful in a wide range of applications in academia and industry. To accommodate the expressive nature of string constraints used in those applications, string solvers use a multi-layered architecture where extended operators are reduced to a set of core operators. These reductions, however, are often costly to reason about. In this work, we propose new techniques for eagerly discovering conflicts based on equality reasoning and lazily avoiding reductions for certain extended functions based on lightweight reasoning. We present a strategy for integrating and scheduling these techniques in a CDCL-based theory solver for strings and regular expressions. We implement the techniques and the strategy in cvc5, a state-of-the-art SMT solver, and …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:_5tno0g5mFcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"The cvc5 SMT solver solves quantifier-free nonlinear real arithmetic problems by combining the cylindrical algebraic coverings method with incremental linearization in an abstraction-refinement loop. The result is a complete algebraic decision procedure that leverages efficient heuristics for refining candidate models. Furthermore, it can be used with quantifiers, integer variables, and in combination with other theories. We describe the overall framework, individual solving techniques, and a number of implementation details. We demonstrate its effectiveness with an evaluation on the SMT-LIB benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:2VqYfGB8ITEC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Dynamic arrays, also referred to as vectors, are fundamental data structures used in many programs. Modeling their semantics efficiently is crucial when reasoning about such programs. The theory of arrays is widely supported but is not ideal, because the number of elements is fixed (determined by its index sort) and cannot be adjusted, which is a problem, given that the length of vectors often plays an important role when reasoning about vector programs. In this paper, we propose reasoning about vectors using a theory of sequences. We introduce the theory, propose a basic calculus adapted from one for the theory of strings, and extend it to efficiently handle common vector operations. We prove that our calculus is sound and show how to construct a model when it terminates with a saturated configuration. Finally, we describe an implementation of the calculus in cvc5 and demonstrate its efficacy by evaluating it …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:4hFrxpcac9AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Algebraic datatypes, and among them lists and trees, have attracted a lot of interest in automated reasoning and Satisfiability Modulo Theories (SMT). Since its latest stable version, the SMT-LIB standard defines a theory of algebraic datatypes, which is currently supported by several mainstream SMT solvers. In this paper, we study this particular theory of datatypes and prove that it is strongly polite, showing how it can be combined with other arbitrary disjoint theories using polite combination. The combination method uses a new, simple, and natural notion of additivity that enables deducing strong politeness from (weak) politeness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:a9-T7VOCCH8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Proof production for SMT solvers is paramount to ensure their correctness independently from implementations, which are often prohibitively difficult to verify. Historically, however, SMT proof production has struggled with performance and coverage issues, resulting in the disabling of many crucial solving techniques and in coarse-grained (and thus hard to check) proofs. We present a flexible proof-production architecture designed to handle the complexity of versatile, industrialstrength SMT solvers and show how we leverage it to produce detailed proofs, including for components previously unsupported by any solver. The architecture allows proofs to be produced modularly, lazily, and with numerous safeguards for correctness. This architecture has been implemented in the state-of-the-art SMT solver cvc5. We evaluate its proofs for SMT-LIB benchmarks and show that the new architecture produces better coverage than previous approaches, has acceptable performance overhead, and supports detailed proofs for most solving components.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:0izLItjtcgwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"We consider the problem of certifying the robustness of deep neural networks against real-world distribution shifts. To do so, we bridge the gap between hand-crafted specifications and realistic deployment settings by proposing a novel neural-symbolic verification framework, in which we train a generative model to learn perturbations from data and define specifications with respect to the output of the learned model. A unique challenge arising from this setting is that existing verifiers cannot tightly approximate sigmoid activations, which are fundamental to many state-of-the-art generative models. To address this challenge, we propose a general meta-algorithm for handling sigmoid activations which leverages classical notions of counter-example-guided abstraction refinement. The key idea is to ""lazily"" refine the abstraction of sigmoid functions to exclude spurious counter-examples found in the previous abstraction, thus guaranteeing progress in the verification process while keeping the state-space small. Experiments on the MNIST and CIFAR-10 datasets show that our framework significantly outperforms existing methods on a range of challenging distribution shifts.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:sNmaIFBj_lkC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Первоначально доминирующим решением для обработки текста были модели, основанные на сложных рекуррентных или сверточных нейронных сетях, далее им на смену пришла более простая и эффективная архитектура-Transformer [7]. Модели данной архитектуры показывают отличное качество на подавляющем большинстве существующих задач [1 2 3], относительно быстро обучаются, и хорошо поддаются параллелизации. Как показывают современные работы, эффективность данных моделей увеличивается с увеличением числа параметров [1]. За счет этого значительно возрастает сложность, цена и время необходимые для обучения каждой отдельной модели. В силу вышеупомянутых свойств появилась тенденция к созданию моделей, которые или нуждаются лишь в относительно дешевом дообучении на конкретной подзадаче [4], или же способны понимать и обобщать задачу по нескольким примерам, поданным с входными данными [1], и в силу чего вообще не нуждающиеся в дообучении. Для реализации моделей требующих дообучения в большинстве современных работ выбирается подход основанный на эмбеддингах-заранее обучается",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HtEfBTGE9r8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Inspired by sum-of-infeasibilities methods in convex optimization, we propose a novel procedure for analyzing verification queries on neural networks with piecewise-linear activation functions. Given a convex relaxation which over-approximates the non-convex activation functions, we encode the violations of activation functions as a cost function and optimize it with respect to the convex relaxation. The cost function, referred to as the Sum-of-Infeasibilities (SoI), is designed so that its minimum is zero and achieved only if all the activation functions are satisfied. We propose a stochastic procedure, DeepSoI, to efficiently minimize the SoI. An extension to a canonical case-analysis-based complete search procedure can be achieved by replacing the convex procedure executed at each search state with DeepSoI. Extending the complete search with DeepSoI achieves multiple simultaneous goals: 1) it guides the search …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:NXb4pA-qfm4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,cvc5 is the latest SMT solver in the cooperating validity checker series and builds on the successful code base of CVC4. This paper serves as a comprehensive system description of cvc5 ’s architectural design and highlights the major features and components introduced since CVC4  1.8. We evaluate cvc5 ’s performance on all benchmarks in SMT-LIB and provide a comparison against CVC4 and Z3.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:LO7wyVUgiFcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:0N-VGjzr574C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"The state of the art for bit-precise reasoning in the context of Satisfiability Modulo Theories (SMT) is a SAT-based technique called bit-blasting where the input formula is first simplified and then translated to an equisatisfiable propositional formula. The main limitation of this technique is scalability, especially in the presence of large bit-widths and arithmetic operators. We introduce an alternative technique, which we call int-blasting, based on a translation to an extension of integer arithmetic rather than propositional logic. We present several translations, discuss their differences, and evaluate them on benchmarks that arise from the verification of rewrite rule candidates for bit-vector solving, as well as benchmarks from SMT-LIB. We also provide preliminary results on 35 benchmarks that arise from smart contract verification. The evaluation shows that this technique is particularly useful for benchmarks with large bit …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:q3CdL3IzO_QC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"This paper is a description of the CVC5 SMT solver as entered into the 2022 SMT Competition. Here, we briefly summarize the main techniques implemented by CVC5 that are relevant. For more comprehensive information please refer to the tool paper about CVC5 [15], our website [7], and the source code on GitHub [6].",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:yMeIxYmEMEAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"With the increasing availability of parallel computing power, there is a growing focus on parallelizing algorithms for important automated reasoning problems such as Boolean satisfiability (SAT). Divide-and-Conquer (D&C) is a popular parallel SAT solving paradigm that partitions SAT instances into independent sub-problems which are then solved in parallel. For unsatisfiable instances, state-of-the-art D&C solvers generate DRAT refutations for each sub-problem. However, they do not generate a single refutation for the original instance. To close this gap, we present Proof-Stitch, a procedure for combining refutations of different sub-problems into a single refutation for the original instance. We prove the correctness of the procedure and propose optimizations to reduce the size and checking time of the combined refutations by invoking existing trimming tools in the proof-combination process. We also provide an extensible implementation of the proposed technique. Experiments on instances from last year’s SAT competition show that the optimized refutations are checkable up to seven times faster than unoptimized refutations.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:OR75R8vi5nAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2022,"Dynamic arrays, also referred to as vectors, are fundamental data structures used in many programs. Modeling their semantics efficiently is crucial when reasoning about such programs. The theory of arrays is widely supported but is not ideal, because the number of elements is fixed (determined by its index sort) and cannot be adjusted, which is a problem, given that the length of vectors often plays an important role when reasoning about vector programs. In this paper, we propose reasoning about vectors using a theory of sequences. We introduce the theory, propose a basic calculus adapted from one for the theory of strings, and extend it to efficiently handle common vector operations. We prove that our calculus is sound and show how to construct a model when it terminates with a saturated configuration. Finally, we describe an implementation of the calculus in cvc5 and demonstrate its efficacy by evaluating it on verification conditions for smart contracts and benchmarks derived from existing array benchmarks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:bKqednn6t2AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Neural networks can learn complex, non-convex functions, and it is challenging to guarantee their correct behavior in safety-critical contexts. Many approaches exist to find failures in networks (e.g., adversarial examples), but these cannot guarantee the absence of failures. Verification algorithms address this need and provide formal guarantees about a neural network by answering “yes or no” questions. For example, they can answer whether a violation exists within certain bounds. However, individual “yes or no"" questions cannot answer qualitative questions such as “what is the largest error within these bounds”; the answers to these lie in the domain of optimization. Therefore, we propose strategies to extend existing verifiers to perform optimization and find: (i) the most extreme failure in a given input region and (ii) the minimum input perturbation required to cause a failure. A naive approach using a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:k8Z6L05lTy4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"In recent years, cloud service providers have sold computation in increasingly granular units. Most recently,“serverless” executors run a single executable with restricted network access and for a limited time. The benefit of these restrictions is scale: thousand-way parallelism can be allocated in seconds, and CPU time is billed with sub-second granularity. To exploit these executors, we introduce gg-SAT: an implementation of divide-and-conquer SAT solving. Infrastructurally, gg-SAT departs substantially from previous implementations: rather than handling process or server management itself, gg-SAT builds on the gg framework, allowing computations to be executed on a configurable backend, including serverless offerings such as AWS Lambda. Our experiments suggest that when run on the same hardware, gg-SAT performs competitively with other D&C solvers, and that the 1000-way parallelism it offers (through AWS Lambda) is useful for some challenging SAT instances.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Ri6SYOTghG4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Hardware accelerators (HAs) are essential building blocks for fast and energy-efficient computing systems. Accelerator Quick Error Detection (A-QED) is a recent formal technique which uses Bounded Model Checking for pre-silicon verification of HAs. A-QED checks an HA for self-consistency, ie, whether identical inputs within a sequence of operations always produce the same output. Under modest assumptions, A-QED is both sound and complete. However, as is well-known, large design sizes significantly limit the scalability of formal verification, including A-QED. We overcome this scalability challenge through a new decomposition technique for A-QED, called A-QED with Decomposition (A-QED2). A-QED2 systematically decomposes an HA into smaller, functional sub-modules, called sub-accelerators, which are then verified independently using A-QED. We prove completeness of A-QED2; in particular, if the full HA under verification contains a bug, then A-QED2 ensures detection of that bug during A-QED verification of the corresponding subaccelerators. Results on over 100 (buggy) versions of a wide variety of HAs with millions of logic gates demonstrate the effectiveness and practicality of A-QED2.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:86PQX7AUzd4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"The increasing complexity of modern configurable systems makes it critical to improve the level of automation in the process of system configuration. Such automation can also improve the agility of the development cycle, allowing for rapid and automated integration of decoupled workflows. In this paper, we present a new framework for automated configuration of systems representable as state machines. The framework leverages model checking and satisfiability modulo theories (SMT) and can be applied to any application domain representable using SMT formulas. Our approach can also be applied modularly, improving its scalability. Furthermore, we show how optimization can be used to produce configurations that are best according to some metric and also more likely to be understandable to humans. We showcase this framework and its flexibility by using it to configure a CGRA memory tile for various image processing applications.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:_axFR9aDTf0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Many SMT solvers implement efficient SAT-based procedures for solving fixed-size bit-vector formulas. These techniques, however, cannot be used directly to reason about bit-vectors of symbolic bit-width. To address this shortcoming, we propose a translation from bit-vector formulas with parametric bit-width to formulas in a logic supported by SMT solvers that includes non-linear integer arithmetic, uninterpreted functions, and universal quantification. While this logic is undecidable, our approach can still solve many formulas that arise in practice by capitalizing on advances in SMT solving for non-linear arithmetic and universally quantified formulas. We provide several case studies in which we have applied this approach with promising results, including the bit-width independent verification of invertibility conditions, compiler optimizations, and bit-vector rewrite rules.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:kz9GbA2Ns4gC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"This paper presents Smt-Switch, an open-source, solveragnostic API for SMT solving. Smt-Switch provides simple, uniform, and high-performance access to SMT solving for applications in areas such as automated reasoning, planning, and formal verification. It defines an abstract interface, which can be implemented by different SMT solvers. The interface allows the user to create, traverse, and manipulate terms, as well as dynamically dispatch queries to various underlying SMT solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:FPJr55Dyh1AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,We present a novel approach for solving quantified bit-vector constraints in Satisfiability Modulo Theories (SMT) based on computing symbolic inverses of bit-vector operators. We derive conditions that precisely characterize when bit-vector constraints are invertible for a representative set of bit-vector operators commonly supported by SMT solvers. We utilize syntax-guided synthesis techniques to aid in establishing these conditions and verify them independently by using several SMT solvers. We show that invertibility conditions can be embedded into quantifier instantiations using Hilbert choice expressions and give experimental evidence that a counterexample-guided approach for quantifier instantiation utilizing these techniques leads to performance improvements with respect to state-of-the-art solvers for quantified bit-vector constraints.,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:i2xiXl-TujoC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"We present a novel approach to pre-silicon verification of processor designs. The purpose of pre-silicon verification is to find logic bugs in a design at an early stage and thus avoid time- and cost-intensive post-silicon debugging. Our approach relies on symbolic quick error detection (Symbolic QED, or SQED). SQED is targeted at finding logic bugs in a symbolic representation of a design by combining bounded model checking (BMC) with QED tests. QED tests are powerful in generating short sequences of instructions (traces) that trigger bugs. We extend an existing SQED approach with symbolic starting states. This way, we enable the BMC tool to select starting states arbitrarily when generating a trace. To avoid false positives, (e.g., traces starting in unreachable states that may not be-have in accordance with the processor instruction-set architecture), we define constraints to restrict the set of possible starting states. We demonstrate that these constraints, togeth-er with reasonable assumptions about the system behavior, allow us to avoid false positives. Using our approach, we discovered previously unknown bugs in open-source RISC-V processor cores that existing methods cannot detect. Moreover, our novel approach out-performs existing ones in the detection of bugs having long traces and in the detection of hardware Trojans, i.e., unauthorized modifications of a design.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Ug5p-4gJ2f0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Two awards were made in 2021 to honour outstanding papers from the IEEE Symposium On Logic In Computer Science 2001 held in Boston, MA, USA. The awards went to ""A Decision Procedure for an Extensional Theory of Arrays"", by Aaron Stump, Clark W. Barrett, David L. Dill, and Jeremy R. Levitt and to ""Dependent Types for Program Termination Verification"", by Hongwei Xi.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ClCfbGk0d_YC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"lazybvtoint is a new prototype SMT-solver, that will participate in the incremental and non-incremental tracks of the \qfbv logic.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ruyezt5ZtCIC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"The architecture of a coarse-grained reconfigurable array (CGRA) processing element (PE) has a significant effect on the performance and energy efficiency of an application running on the CGRA. This paper presents an automated approach for generating specialized PE architectures for an application or an application domain. Frequent subgraphs mined from a set of applications are merged to form a PE architecture specialized to that application domain. For the image processing and machine learning domains, we generate specialized PEs that are up to 10.5x more energy efficient and consume 9.1x less area than a baseline PE.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:foquWX3nUaYC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"This paper presents a novel approach for quantifier instantiation in Satisfiability Modulo Theories (SMT) that leverages syntax-guided synthesis (SyGuS) to choose instantiation terms. It targets quantified constraints over background theories such as (non)linear integer, reals and floating-point arithmetic, bit-vectors, and their combinations. Unlike previous approaches for quantifier instantiation in these domains which rely on theory-specific strategies, the new approach can be applied to any (combined) theory, when provided with a grammar for instantiation terms for all sorts in the theory. We implement syntax-guided instantiation in the SMT solver CVC4, leveraging its support for enumerative SyGuS. Our experiments demonstrate the versatility of the approach, showing that it is competitive with or exceeds the performance of state-of-the-art solvers on a range of background theories.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:PoWvk5oyLR8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Deep neural networks are widely used for nonlinear function approximation, with applications ranging from computer vision to control. Although these networks involve the composition of simple arithmetic operations, it can be very challenging to verify whether a particular network satisfies certain input-output properties. This article surveys methods that have emerged recently for soundly verifying such properties. These methods borrow insights from reachability analysis, optimization, and search. We discuss fundamental differences and connections between existing algorithms. In addition, we provide pedagogical implementations of existing methods and compare them on a set of benchmark problems.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:dQ2og3OwTAUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Symbolic model checking is an important tool for finding bugs (or proving the absence of bugs) in modern system designs. Because of this, improving the ease of use, scalability, and performance of model checking tools and algorithms continues to be an important research direction. In service of this goal, we present Pono, an open-source SMT-based model checker. Pono is designed to be both a research platform for developing and improving model checking algorithms, as well as a performance-competitive tool that can be used for academic and industry verification applications. In addition to performance, Pono prioritizes transparency (developed as an open-source project on GitHub), flexibility (Pono can be adapted to a variety of tasks by exploiting its general SMT-based interface), and extensibility (it is easy to add new algorithms and new back-end solvers). In this paper, we describe the design of …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:5qfkUJPXOUwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"We make two contributions to the study of polite combination in satisfiability modulo theories. The first is a separation between politeness and strong politeness, by presenting a polite theory that is not strongly polite. This result shows that proving strong politeness (which is often harder than proving politeness) is sometimes needed in order to use polite combination. The second contribution is an optimization to the polite combination method, obtained by borrowing from the Nelson-Oppen method. The Nelson-Oppen method is based on guessing arrangements over shared variables. In contrast, polite combination requires an arrangement over all variables of the shared sorts. We show that when using polite combination, if the other theory is stably infinite with respect to a shared sort, only the shared variables of that sort need be considered in arrangements, as in the Nelson-Oppen method. The time required to reason about arrangements is exponential in the worst case, so reducing the number of variables considered has the potential to improve performance significantly. We show preliminary evidence for this by demonstrating a speed-up on a smart contract verification benchmark.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HbR8gkJAVGIC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"We introduce DeepCert, a tool-supported method for verifying the robustness of deep neural network (DNN) image classifiers to contextually relevant perturbations such as blur, haze, and changes in image contrast. While the robustness of DNN classifiers has been the subject of intense research in recent years, the solutions delivered by this research focus on verifying DNN robustness to small perturbations in the images being classified, with perturbation magnitude measured using established norms. This is useful for identifying potential adversarial attacks on DNN image classifiers, but cannot verify DNN robustness to contextually relevant image perturbations, which are typically not small when expressed with norms. DeepCert addresses this underexplored verification problem by supporting: (1) the encoding of real-world image perturbations; (2) the systematic evaluation of contextually relevant …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:SpbeaW3--B0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"We develop a framework for model checking infinite-state systems by automatically augmenting them with auxiliary variables, enabling quantifier-free induction proofs for systems that would otherwise require quantified invariants. We combine this mechanism with a counterexample-guided abstraction refinement scheme for the theory of arrays. Our framework can thus, in many cases, reduce inductive reasoning with quantifiers and arrays to quantifier-free and array-free reasoning. We evaluate the approach on a wide set of benchmarks from the literature. The results show that our implementation often outperforms state-of-the-art tools, demonstrating its practical potential.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:S16KYo8Pm5AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"Deep learning has emerged as an effective approach for creating modern software systems, with neural networks often surpassing hand-crafted systems. Unfortunately, neural networks are known to suffer from various safety and security issues. Formal verification is a promising avenue for tackling this difficulty, by formally certifying that networks are correct. We propose an SMT-based technique for verifying binarized neural networks — a popular kind of neural network, where some weights have been binarized in order to render the neural network more memory and energy efficient, and quicker to evaluate. One novelty of our technique is that it allows the verification of neural networks that include both binarized and non-binarized components. Neural network verification is computationally very difficult, and so we propose here various optimizations, integrated into our SMT procedure as deduction steps …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:WZBGuue-350C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2021,"This paper presents Smt-Switch, an open-source, solver-agnostic API for SMT solving. Smt-Switch provides simple, uniform, and high-performance access to SMT solving for applications in areas such as automated reasoning, planning, and formal verification. It defines an abstract interface, which can be implemented by different SMT solvers. The interface allows the user to create, traverse, and manipulate terms, as well as dynamically dispatch queries to various underlying SMT solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:gsN89kCJA0AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"The ACAS X family of aircraft collision avoidance systems uses large numeric lookup tables to make decisions. Recent work used a deep neural network to approximate and compress a collision avoidance table, and simulations showed that the neural network performance was comparable to the original table. Consequently, neural network representations are being explored for use on small aircraft with limited storage capacity. However, the black-box nature of deep neural networks raises safety concerns because simulation results are not exhaustive. This work takes steps towards addressing these concerns by applying formal methods to analyze the behavior of collision avoidance neural networks both in isolation and in a closed-loop system. We evaluate our approach on a specific set of collision avoidance networks and show that even though the networks are not always locally robust, their closed-loop …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:oNZyr7d5Mn4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"The theory of strings supported by solvers in formal methods contains a large number of operators. Instead of implementing a semi-decision procedure that reasons about all the operators directly, string solvers often reduce operators to a core fragment and implement a semi-decision procedure over that fragment. These reductions considerably increase the number of constraints and thus have to be done carefully to achieve good performance. We propose novel reductions from regular expressions to string constraints and a framework for minimizing the introduction of new variables in current reductions of string constraints. The reductions of regular expression constraints enable string solvers to handle a significant fragment of such constraints without using dedicated reasoning over regular expressions. Minimizing the number of variables in the reduced constraints makes those constraints significantly cheaper to solve by the core solver. An experimental evaluation of our implementation of both techniques in CVC4, a state-of-the-art SMT solver with extensive support for the theory of strings, shows that they significantly improve the solver’s performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:LI9QrySNdTsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Although an agile approach is standard for software design, how to properly adapt this method to hardware is still an open question. This work addresses this question while building a system on chip (SoC) with specialized accelerators. Rather than using a traditional waterfall design flow, which starts by studying the application to be accelerated, we begin by constructing a complete flow from an application expressed in a high-level domain-specific language (DSL), in our case Halide, to a generic coarse-grained reconfigurable array (CGRA). As our under-standing of the application grows, the CGRA design evolves, and we have developed a suite of tools that tune application code, the compiler, and the CGRA to increase the efficiency of the resulting implementation. To meet our continued need to update parts of the system while maintaining the end-to-end flow, we have created DSL-based hardware generators …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:MLfJN-KU85MC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"We present A-QED (Accelerator-Quick Error Detection), a new approach for pre-silicon formal verification of stand-alone hardware accelerators. A-QED relies on bounded model checking -- however, it does not require extensive design-specific properties or a full formal design specification. While A- QED is effective for both RTL and high-level synthesis (HLS) design flows, it integrates seamlessly with HLS flows. Our A-QED results on several hardware accelerator designs demonstrate its practicality and effectiveness: 1. A-QED detected all bugs detected by conventional verification flow. 2. A-QED detected bugs that escaped conventional verification flow. 3. A-QED improved verification productivity dramatically, by 30X, in one of our case studies (1 person-day using A-QED vs. 30 person-days using conventional verification flow). 4. A-QED produced short counterexamples for easy debug (37X shorter on average vs …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:tuHXwOkdijsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Algebraic datatypes, and among them lists and trees, have attracted a lot of interest in automated reasoning and Satisfiability Modulo Theories (SMT). Since its latest stable version, the SMT-LIB standard defines a theory of algebraic datatypes, which is currently supported by several mainstream SMT solvers. In this paper, we study this particular theory of datatypes and prove that it is strongly polite, showing also how it can be combined with other arbitrary disjoint theories using polite combination. Our results cover both inductive and finite datatypes, as well as their union. The combination method uses a new, simple, and natural notion of additivity, that enables deducing strong politeness from (weak) politeness.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:4MWp96NkSFoC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Symbolic model checking has become an important part of the verification flow in industrial hardware design. However, its use is still limited due to scaling issues. One way to address this is to exploit the large amounts of symmetry present in many real world designs. In this paper, we adapt partial order reduction for bounded model checking of synchronous hardware and introduce a novel technique that makes partial order reduction practical in this new domain. These approaches are largely automatic, requiring only minimal manual effort. We evaluate our technique on open-source and commercial packet mover circuits – designs containing FIFOs and arbiters.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:p__nRnzSRKYC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Smart contracts are programs that implement potentially sophisticated transactions on modern blockchain platforms. In the rapidly evolving blockchain environment, smart contract programming languages must allow users to write expressive programs that manage and transfer assets, yet provide strong protection against sophisticated attacks. Addressing this need, we present flexible and reliable abstractions for programming with digital currency in the Move language [Blackshear et al. 2019]. Move uses novel linear [Girard 1987] resource types with semantics drawing on C++11 [Stroustrup 2013] and Rust [Matsakis and Klock 2014]: when a resource value is assigned to a new memory location, the location previously holding it must be invalidated. In addition, a resource type can only be created or destroyed by procedures inside its declaring module. We present an executable bytecode language with resources and prove that it enjoys resource safety, a conservation property for program values that is analogous to conservation of mass in the physical world.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ML0RJ9NH7IQC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"The required manual effort and verification expertise are among the main hurdles for adopting formal verification in processor design flows. Developing a set of properties that fully covers all instruction behaviors is a laborious and challenging task. This paper proposes a highly automated and ""complete"" processor verification approach which requires considerably less manual effort and expertise compared to the state of the art.The proposed approach extends the S 2 QED approach to cover both single and multiple instruction bugs and ensures that a design is completely verified according to a well-defined criterion. This makes the approach robust against human errors. The properties are simple and can be automatically generated from an ISA model with small manual effort. Furthermore, unlike in conventional property checking, the verification engineer does not need to explicitly specify the processor's behavior …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:g3aElNc5_aQC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Disclosed are improved methods and structures for verifying integrated circuits and in particular systems-on-a-chip constructed therefrom. We call methods and structures according to the present disclosure Symbolic Quick Error Detection or Symbolic QED, Illustrative characteristics of Symbolic QED include: 1) It is applicable to any System-on-Chip (SoC) design as long as it contains at least one programmable processor; 2) It is broadly applicable for logic bugs inside processor cores, accelerators, and uncore components; 3) It does not require failure reproduction; 4) It does not require human intervention during bug localization; 5) It does not require trace buffers, 6) It does not require assertions; and 7) It uses hardware structures called “change detectors” which introduce only a small area overhead. Symbolic QED exhibits: 1) A systematic (and automated) approach to inserting “change detectors” during a design …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:bnK-pcrLprsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Conclusion. This is a prototype experimental tool that is aimed to serve as a playground for arithmetic-based techniques for bit-vector solving. Incorporating such techniques in a fullfledged solver is left for future work, and is planned for when these techniques are better understood and evaluated using this tool.
Acknowledgments. We would like to thank the CVC4 and MathSAT5 teams for allowing us to use their tools. In particular, we thank Alberto Griggio for clarifying the relevant aspects of the MathSAT5 license, and to Aina Niemetz and Mathias Preiner for helpful tips regarding benchmarking and evaluating bit-vector formulas. We also thank the competition organizers, Haniel Barbosa, Jochen Hoenicke, and Antti Hyvarinen for clarifying the status of this tool for the competition and willingly accepting it as a new participant.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:YohjEiUPhakC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Deep neural network (DNN) verification is an emerging field, with diverse verification engines quickly becoming available. Demonstrating the effectiveness of these engines on real-world DNNs is an important step towards their wider adoption. We present a tool that can leverage existing verification engines in performing a novel application: neural network simplification, through the reduction of the size of a DNN without harming its accuracy. We report on the work-flow of the simplification process, and demonstrate its potential significance and applicability on a family of real-world DNNs for aircraft collision avoidance, whose sizes we were able to reduce by as much as 10%.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:b1wdh0AR-JQC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"The Libra blockchain is designed to store billions of dollars in assets, so the security of code that executes transactions is important. The Libra blockchain has a new language for implementing transactions, called “Move.” This paper describes the Move Prover, an automatic formal verification system for Move. We overview the unique features of the Move language and then describe the architecture of the Prover, including the language for formal specification and the translation to the Boogie intermediate verification language .",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:kuK5TVdYjLIC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"In text encoding standards such as Unicode, text strings are sequences of code points, each of which can be represented as a natural number. We present a decision procedure for a concatenation-free theory of strings that includes length and a conversion function from strings to integer code points. Furthermore, we show how many common string operations, such as conversions between lowercase and uppercase, can be naturally encoded using this conversion function. We describe our implementation of this approach in the SMT solver CVC4, which contains a high-performance string subsolver, and show that the use of a native procedure for code points significantly improves its performance with respect to other state-of-the-art string solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:TIZ-Mc8IlK0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"While hardware generators have drastically improved design productivity, they have introduced new challenges for the task of verification. To effectively cover the functionality of a sophisticated generator, verification engineers require tools that provide the flexibility of metaprogramming. However, flexibility alone is not enough; components must also be portable in order to encourage the proliferation of verification libraries as well as enable new methodologies. This paper introduces fault, a Python embedded hardware verification language that aims to empower design teams to realize the full potential of generators.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:tYavs44e6CUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Symbolic quick error detection (SQED) is a formal pre-silicon verification technique targeted at processor designs. It leverages bounded model checking (BMC) to check a design for counterexamples to a self-consistency property: given the instruction set architecture (ISA) of the design, executing an instruction sequence twice on the same inputs must always produce the same outputs. Self-consistency is a universal, implementation-independent property. Consequently, in contrast to traditional verification approaches that use implementationspecific assertions (often generated manually), SQED does not require a full formal design specification or manually-written properties. Case studies have shown that SQED is effective for commercial designs and that SQED substantially improves design productivity. However, until now there has been no formal characterization of its bug-finding capabilities. We aim to close this gap by laying a formal foundation for SQED. We use a transition-system processor model and define the notion of a bug using an abstract specification relation. We prove the soundness of SQED, ie, that any bug reported by SQED is in fact a real bug in the processor. Importantly, this result holds regardless of what the actual specification relation is. We next describe conditions under which SQED is complete, that is, what kinds of bugs it is guaranteed to find. We show that for a large class of bugs, SQED can always find a trace exhibiting the bug. Ultimately, we prove full completeness of a variant of SQED that uses specialized state reset instructions. Our results enable a rigorous understanding of SQED and its bug-finding capabilities …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ILKRHgRFtOwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Inspired by recent successes of parallel techniques for solving Boolean satisfiability, we investigate a set of strategies and heuristics to leverage parallelism and improve the scalability of neural network verification. We present a general description of the Split-and-Conquer partitioning algorithm, implemented within the Marabou framework, and discuss its parameters and heuristic choices. In particular, we explore two novel partitioning strategies, that partition the input space or the phases of the neuron activations, respectively. We introduce a branching heuristic and a direction heuristic that are based on the notion of polarity. We also introduce a highly parallelizable pre-processing algorithm for simplifying neural network verification problems. An extensive experimental evaluation shows the benefit of these techniques on both existing and new benchmarks. A preliminary experiment ultra-scaling our algorithm using a large distributed cloud-based platform also shows promising results.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:BwyfMAYsbu0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2020,"Deep neural networks are revolutionizing the way complex systems are developed. However, these automatically-generated networks are opaque to humans, making it difficult to reason about them and guarantee their correctness. Here, we propose a novel approach for verifying properties of a widespread variant of neural networks, called recurrent neural networks. Recurrent neural networks play a key role in, e.g., speech recognition, and their verification is crucial for guaranteeing the reliability of many critical systems. Our approach is based on the inference of invariants, which allow us to reduce the complex problem of verifying recurrent networks into simpler, non-recurrent problems. Experiments with a proof-of-concept implementation of our approach demonstrate that it performs orders-of-magnitude better than the state of the art.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Z5m8FVwuT1cC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Coarse-grained reconfigurable architectures (CGRAs) are becoming popular accelerators for computationally intensive tasks. CGRAs offer the reconfigurability of an FPGA, but with larger configurable blocks which provide performance closer to ASICs. CGRAs can achieve very high compute density if the routing networks are restricted; however, mapping using traditional annealing-based approaches does not perform well for such architectures. This paper uses Satisfiability Modulo Theories (SMT) solvers to rapidly map designs onto arbitrary CGRA fabrics. This approach is sound, complete, and in many cases an order of magnitude faster than state-of-the-art constraint-based mapping techniques using integer linear programming (ILP). Additionally, we propose a functional duplication strategy that decreases pressure on the routing network from high-fanout operations, leading to significant performance …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:BUYA1_V_uYcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"This special issue consists of extended versions of papers selected from the 9th NASA Formal Methods Symposium (NFM 2017). The symposium was held at the NASA Ames Research Center, Moffett Field, CA, on May 16–18, 2017. NFM is a forum to foster collaboration between theoreticians and practitioners from NASA, academia, and industry, with the goal of identifying challenges and providing solutions to achieving assurance in mission-and safety-critical systems. Examples of such systems include advanced separation assurance algorithms for aircraft, next-generation air transportation, autonomous rendezvous and docking for spacecraft, autonomous on-board software for unmanned aerial systems (UAS), UAS traffic management, autonomous robots, and systems for fault detection, diagnosis, and prognostics. The topics covered by the NASA Formal Methods Symposium include: model checking, theorem …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ye4kPcJQO24C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"As designs grow in size and complexity, design verification becomes one of the most difficult and costly tasks facing design teams. Formal verification techniques offer great promise because of their ability to exhaustively explore design behaviors. However, formal techniques also have a reputation for being labor-intensive and limited to small blocks. Is there any hope for successful application of formal techniques at design scale? We answer this question affirmatively by digging deeper to understand what the real technological issues and opportunities are. First, we look at satisfiability solvers, the engines underlying formal techniques such as model checking. Given the recent innovations in satisfiability solving, we argue that there are many reasons to be optimistic that formal techniques will scale to designs of practical interest. We use our CoSA model checker as a demonstration platform to illustrate how …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ipzZ9siozwsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"The AAAI 2019 Spring Series was held Monday through Wednesday, March 25–27, 2019 on the campus of Stanford University, adjacent to Palo Alto, California. The titles of the nine symposia were Artificial Intelligence, Autonomous Machines, and Human Awareness: User Interventions, Intuition and Mutually Constructed Context; Beyond Curve Fitting—Causation, Counterfactuals and Imagination-Based AI; Combining Machine Learning with Knowledge Engineering; Interpretable AI for Well-Being: Understanding Cognitive Bias and Social Embeddedness; Privacy-Enhancing Artificial Intelligence and Language Technologies; Story-Enabled Intelligence; Towards Artificial Intelligence for Collaborative Open Science; Towards Conscious AI Systems; and Verification of Neural Networks.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:XD-gHx7UXLsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Detect and avoid (DAA) all other aircraft is a critical component to enable small unmanned aircraft system (sUAS) beyond visual line of sight (BVLOS) operations. Derived from the version of Airborne Collision Avoidance System X (ACAS X) for large UAS (ACAS Xu), a new member of the ACAS X family for sUAS (ACAS sXu) is being developed by the Federal Aviation Administration's (FAA's) Traffic-Alert and Collision Avoidance System (TCAS) Program Office. ACAS sXu is intended to provide both collision avoidance (CA) and remain well clear (RWC) capabilities with both vertical and horizontal advisories for the remote pilot in command (RPIC) and/or automated response system onboard the aircraft. ACAS sXu is envisioned to utilize a standard logic to serve sUASs with different equipages and operating in different airspace domains. The standard ACAS sXu logic may be hosted either in the embedded …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:t7zJ5fGR-2UC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"This work is a part of an ongoing effort to prove the correctness of invertibility conditions for the theory of fixed-width bit-vectors, which are used to solve quantified bit-vector formulas in the Satisfiability Modulo Theories (SMT) solver CVC4. While many of these were proved in a completely automatic fashion for any bit-width, some were only proved for bit-widths up to 65, even though they are being used to solve formulas over arbitrary bit-widths. In this paper we describe our initial efforts in proving a subset of these invertibility conditions in the Coq proof assistant. We describe the Coq library that we use, as well as the extensions that we introduced to it.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:uJ-U7cs_P_0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Deep reinforcement learning (RL) has recently been successfully applied to networking contexts including routing, flow scheduling, congestion control, packet classification, cloud resource management, and video streaming. Deep-RL-driven systems automate decision making, and have been shown to outperform state-of-the-art handcrafted systems in important domains. However, the (typical) non-explainability of decisions induced by the deep learning machinery employed by these systems renders reasoning about crucial system properties, including correctness and security, extremely difficult. We show that despite the obscurity of decision making in these contexts, verifying that deep-RL-driven systems adhere to desired, designer-specified behavior, is achievable. To this end, we initiate the study of formal verification of deep RL and present Verily, a system for verifying deep-RL-based systems that leverages …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:35r97b3x0nAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"CVC4Sy is a syntax-guided synthesis (SyGuS) solver based on bounded term enumeration and, for restricted fragments, quantifier elimination. The enumerative strategies are based on encoding term enumeration as an extension of the quantifier-free theory of algebraic datatypes and on a highly optimized brute-force algorithm. The quantifier elimination strategy extracts solutions from unsatisfiability proofs of the negated form of synthesis conjectures. It uses recent counterexample-guided techniques for quantifier instantiation that make finding such proofs practically feasible. CVC4Sy implements these strategies by extending the satisfiability modulo theories (SMT) solver CVC4. The strategy to be applied on a given problem is chosen heuristically based on the problem's structure. This document gives an overview of these techniques and their implementation in the SyGuS Solver CVC4Sy, an entry for SyGuS-Comp 2019.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:EkHepimYqZsC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"We present an industrial case study that demonstrates the practicality and effectiveness of Symbolic Quick Error Detection (Symbolic QED) in detecting logic design flaws (logic bugs) during pre-silicon verification. Our study focuses on several microcontroller core designs (~1,800 flip-flops, ~70,000 logic gates) that have been extensively verified using an industrial verification flow and used for various commercial automotive products. The results of our study are as follows: 1. Symbolic QED detected all logic bugs in the designs that were detected by the industrial verification flow (which includes various flavors of simulation-based verification and formal verification). 2. Symbolic QED detected additional logic bugs that were not recorded as detected by the industrial verification flow. (These additional bugs were also perhaps detected by the industrial verification flow.)3.Symbolic QED enables significant design …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:5awf1xo2G04C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Recent discovery of security attacks in advanced processors, known as Spectre and Meltdown, has resulted in high public alertness about security of hardware. The root cause of these attacks is information leakage across covert channels that reveal secret data without any explicit information flow between the secret and the attacker. Many sources believe that such covert channels are intrinsic to highly advanced processor architectures based on speculation and out-of-order execution, suggesting that such security risks can be avoided by staying away from high-end processors. This paper, however, shows that the problem is of wider scope: we present new classes of covert channel attacks which are possible in average-complexity processors with in-order pipelining, as they are mainstream in applications ranging from Internet-of-Things to Autonomous Systems. We present a new approach as a foundation for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:eq2jaN3J8jMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"The International Conference on Formal Methods in Computer Aided Design (FMCAD), held in San Jose, California, from October 22-25 in 2019, is the nineteenth in a series of meetings on the theory and applications of rigorous formal techniques for the automated design of systems. The FMCAD conference covers formal aspects of specification, verification, synthesis, testing, and security, and is a leading forum for researchers and practitioners in academia and industry alike. The program of FMCAD 2019 comprises a tutorial day with three tutorials on program synthesis, verification of analog and mixed-signal circuits, and post-silicon validation; two keynotes on safe autonomy and formal methods for hardware security; and a forum for doctoral students. Finally, the main program contains the presentations of the accepted papers. The tutorial day features three presentations:",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:AvfA0Oy_GE0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:yB1At4FlUx8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"The Boolean Satisfiability (SAT) problem is the canonical NP-complete problem and is fundamental to computer science, with a wide array of applications in planning, verification, and theorem proving. Developing and evaluating practical SAT solvers relies on extensive empirical testing on a set of real-world benchmark formulas. However, the availability of such real-world SAT formulas is limited. While these benchmark formulas can be augmented with synthetically generated ones, existing approaches for doing so are heavily hand-crafted and fail to simultaneously capture a wide range of characteristics exhibited by real-world SAT instances. In this work, we present G2SAT, the first deep generative framework that learns to generate SAT formulas from a given set of input formulas. Our key insight is that SAT formulas can be transformed into latent bipartite graph representations which we model using a specialized deep generative neural network. We show that G2SAT can generate SAT formulas that closely resemble given real-world SAT instances, as measured by both graph metrics and SAT solver behavior. Further, we show that our synthetic SAT formulas could be used to improve SAT solver performance on real-world benchmarks, which opens up new opportunities for the continued development of SAT solvers and a deeper understanding of their performance.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:nrtMV_XWKgEC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Deep neural networks are revolutionizing the way complex systems are designed. Consequently, there is a pressing need for tools and techniques for network analysis and certification. To help in addressing that need, we present Marabou, a framework for verifying deep neural networks. Marabou is an SMT-based tool that can answer queries about a network’s properties by transforming these queries into constraint satisfaction problems. It can accommodate networks with different activation functions and topologies, and it performs high-level reasoning on the network that can curtail the search space and improve performance. It also supports parallel execution to further enhance scalability. Marabou accepts multiple input formats, including protocol buffer files generated by the popular TensorFlow framework for neural networks. We describe the system architecture and main components, evaluate the …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:-_dYPAW6P2MC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Automated reasoning procedures are essential for a number of applications that involve bit-exact floating-point computations. This paper presents conditions that characterize when a variable in a floating-point constraint has a solution, which we call invertibility conditions. We describe a novel workflow that combines human interaction and a syntax-guided synthesis (SyGuS) solver that was used for discovering these conditions. We verify our conditions for several floating-point formats. One implication of this result is that a fragment of floating-point arithmetic admits compact quantifier elimination. We implement our invertibility conditions in a prototype extension of our solver CVC4, showing their usefulness for solving quantified constraints over floating-points.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:evX43VCCuoAC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"The performance of modern Satisfiability Modulo Theories (SMT) solvers relies crucially on efficient decision procedures as well as static simplification techniques, which include large sets of rewrite rules. Manually discovering and implementing rewrite rules is challenging. In this work, we propose a framework that uses enumerative syntax-guided synthesis (SyGuS) to propose rewrite rules that are not implemented in a given SMT solver. We implement this framework in cvc4, a state-of-the-art SMT and SyGuS solver, and evaluate several use cases. We show that some SMT solvers miss rewriting opportunities, or worse, have bugs in their rewriters. We also show that a variation of our approach can be used to test the correctness of a rewriter. Finally, we show that rewrites discovered with this technique lead to significant improvements in cvc4 on both SMT and SyGuS problems over bit-vectors and strings.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:_Re3VWB3Y0AC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Satisfiability Modulo Theories (SMT) solvers with support for the theory of strings have recently emerged as powerful tools for reasoning about string-manipulating programs. However, due to the complex semantics of extended string functions, it is challenging to develop scalable solvers for the string constraints produced by program analysis tools. We identify several classes of simplification techniques that are critical for the efficient processing of string constraints in SMT solvers. These techniques can reduce the size and complexity of input constraints by reasoning about arithmetic entailment, multisets, and string containment relationships over input terms. We provide experimental evidence that implementing them results in significant improvements over the performance of state-of-the-art SMT solvers for extended string constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:ZfRJV9d4-WMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Many state-of-the-art Satisfiability Modulo Theories (SMT) solvers for the theory of fixed-size bit-vectors employ an approach called bit-blasting, where a given formula is translated into a Boolean satisfiability (SAT) problem and delegated to a SAT solver. Consequently, producing bit-vector proofs in an SMT solver requires incorporating SAT proofs into its proof infrastructure. In this paper, we describe three approaches for integrating DRAT proofs generated by an off-the-shelf SAT solver into the proof infrastructure of the SMT solver CVC4 and explore their strengths and weaknesses. We implemented all three approaches using CryptoMiniSat as the SAT back-end for its bit-blasting engine and evaluated performance in terms of proof-production and proof-checking.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:tKAzc9rXhukC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"Many SMT solvers implement efficient SAT-based procedures for solving fixed-size bit-vector formulas. These approaches, however, cannot be used directly to reason about bit-vectors of symbolic bit-width. To address this shortcoming, we propose a translation from bit-vector formulas with parametric bit-width to formulas in a logic supported by SMT solvers that includes non-linear integer arithmetic, uninterpreted functions, and universal quantification. While this logic is undecidable, this approach can still solve many formulas by capitalizing on advances in SMT solving for non-linear arithmetic and universally quantified formulas. We provide several case studies in which we have applied this approach with promising results, including the bit-width independent verification of invertibility conditions, compiler optimizations, and bit-vector rewrites.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:NJ774b8OgUMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"We present cvc4sy, a syntax-guided synthesis (SyGuS) solver based on three bounded term enumeration strategies. The first encodes term enumeration as an extension of the quantifier-free theory of algebraic datatypes. The second is based on a highly optimized brute-force algorithm. The third combines elements of the others. Our implementation of the strategies within the satisfiability modulo theories (SMT) solver cvc4 and a heuristic to choose between them leads to significant improvements over state-of-the-art SyGuS solvers.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Fu2w8maKXqMC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2019,"SMT solvers have throughout the years been able to cope with increasingly expressive formulas, from ground logics to full first-order logic (FOL). In contrast, the extension of SMT solvers to higher-order logic (HOL) is mostly unexplored. We propose a pragmatic extension for SMT solvers to support HOL reasoning natively without compromising performance on FOL reasoning, thus leveraging the extensive research and implementation efforts dedicated to efficient SMT solving. We show how to generalize data structures and the ground decision procedure to support partial applications and extensionality, as well as how to reconcile quantifier instantiation techniques with higher-order variables. We also discuss a separate approach for redesigning an HOL SMT solver from the ground up via new data structures and algorithms. We apply our pragmatic extension to the CVC4 SMT solver and discuss a redesign …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:JQOojiI6XY0C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Recent discovery of security attacks in advanced processors, known as Spectre and Meltdown, has resulted in high public alertness about security of hardware. The root cause of these attacks is information leakage across"" covert channels"" that reveal secret data without any explicit information flow between the secret and the attacker. Many sources believe that such covert channels are intrinsic to highly advanced processor architectures based on speculation and out-of-order execution, suggesting that such security risks can be avoided by staying away from high-end processors. This paper, however, shows that the problem is of wider scope: we present new classes of covert channel attacks which are possible in average-complexity processors with in-order pipelining, as they are mainstream in applications ranging from Internet-of-Things to Autonomous Systems. We present a new approach as a foundation for …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:zLWjf1WUPmwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Symbolic model-checking is a well-established technique used in hardware design to assess, and formally verify, functional correctness. However, most modern model-checkers encode the problem into propositional satisfiability (SAT) and do not leverage any additional information beyond the input design, which is typically provided in a hardware description language such as Verilog.In this paper, we present CoSA (CoreIR Symbolic Analyzer), a model-checking tool for CoreIR designs. CoreIR is a new intermediate representation for hardware. CoSA encodes model-checking queries into first-order formulas that can be solved by Satisfiability Modulo Theories (SMT) solvers. In particular, it natively supports encodings using the theories of bitvectors and arrays. CoSA is closely integrated with CoreIR and can thus leverage CoreIR-generated metadata in addition to user-provided lemmas to assist with formal …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:AXPGKjj_ei8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"We present a novel approach for solving quantified bit-vector formulas in Satisfiability Modulo Theories (SMT) based on computing symbolic inverses of bit-vector operators. We derive conditions that precisely characterize when bit-vector constraints are invertible for a representative set of bit-vector operators commonly supported by SMT solvers. We utilize syntax-guided synthesis techniques to aid in establishing these conditions and verify them independently by using several SMT solvers. We show that invertibility conditions can be embedded into quantifier instantiations using Hilbert choice expressions, and give experimental evidence that a counterexample-guided approach for quantifier instantiation utilizing these techniques leads to performance improvements with respect to state-of-the-art solvers for quantified bit-vector constraints.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:wbdj-CoPYUoC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"This paper is a description of the CVC4 SMT solver as entered into the 2018 SMT Competition. We only list important differences from the 2017 SMT Competition version of CVC4. For further and more detailed information about CVC4, please refer to the original paper, the CVC4 website, or the source code on GitHub.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HE397vMXCloC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"We present Symbolic Quick Error Detection (Symbolic QED), a structured approach for logic bug detection and localization which can be used both during pre-silicon design verification as well as post-silicon validation and debug. This new methodology leverages prior work on Quick Error Detection (QED) which has been demonstrated to drastically reduce the latency, in terms of the number of clock cycles, of error detection following the activation of a logic (or electrical) bug. QED works through software transformations, including redundant execution and control flow checking, of the applied tests. Symbolic QED combines these error-detecting QED transformations with bounded model checking-based formal analysis to generate minimal-length bug activation traces that detect and localize any logic bugs in the design. We demonstrate the practicality and effectiveness of Symbolic QED using the OpenSPARC T2, a …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:BrmTIyaxlBUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"With the rise of programmable network switches, network infrastructure is becoming more flexible and more capable than ever before. Programming languages such as P4 lower the barrier for changing the inner workings of network switches and offer a uniform experience across different devices. However, this programmability also brings the risk of introducing hard-to-catch bugs at a level that was previously covered by well-tested devices with a fixed set of capabilities. Subtle discrepancies between different implementations pose a risk of introducing bugs at a layer that is opaque to the user.
To reap the benefit of programmable hardware and keep---or improve upon---the reliability of traditional approaches, new tools are needed. In this work, we present p4pktgen, a tool for automatically generating test cases for P4 programs using symbolic execution. These test cases can be used to validate that P4 programs act …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:J-pR_7NvFogC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Driven by the demand for highly customizable processor cores for IoT and related applications, there is a renewed interest in effective but low-cost techniques for verifying systems-on-chip (SoCs). This paper revisits the problem of processor verification and presents a radically different approach when compared to the state of the art. The proposed approach is highly automated and leverages recent progress in the field of post-silicon validation by the method of Quick Error Detection (QED) and Symbolic Quick Error Detection (SQED). In this paper, we modify SQED by incorporating a symbolic initial state in its BMC-based analysis and generalize the approach into the S 2 QED method. As a first advantage, S 2 QED can separate logic bugs from electrical bugs in QED-based postsilicon validation. Secondly, it also makes a strong contribution to pre-silicon verification by proving that the execution of each instruction is …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:5ugPr518TE4C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"The increasing use of deep neural networks for safety-critical applications, such as autonomous driving and flight control, raises concerns about their safety and reliability. Formal verification can address these concerns by guaranteeing that a deep learning system operates as intended, but the state of the art is limited to small systems. In this work-in-progress report we give an overview of our work on mitigating this difficulty, by pursuing two complementary directions: devising scalable verification techniques, and identifying design choices that result in deep learning systems that are more amenable to verification.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:q3oQSFYPqjQC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Satisfiability Modulo Theories (SMT) refers to the problem of determining whether a first-order formula is satisfiable with respect to some logical theory. Solvers based on SMT are used as back-end engines in model-checking applications such as bounded, interpolation-based, and predicate-abstraction-based model checking. After a brief illustration of these uses, we survey the predominant techniques for solving SMT problems with an emphasis on the lazy approach, in which a propositional satisfiability (SAT) solver is combined with one or more theory solvers. We discuss the architecture of a lazy SMT solver, give examples of theory solvers, show how to combine such solvers modularly, and mention several extensions of the lazy approach. We also briefly describe the eager approach in which the SMT problem is reduced to a SAT problem. Finally, we discuss how the basic framework for determining …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:HtS1dXgVpQUC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:j8SEvjWlNXcC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Deep neural networks have achieved impressive results in many complex applications, including classification tasks for image and speech recognition, pattern analysis or perception in self-driving vehicles. However, it has been observed that even highly trained networks are very vulnerable to adversarial perturbations. Adding minimal changes to inputs that are correctly classified can lead to wrong predictions, raising serious security and safety concerns. Existing techniques for checking robustness against such perturbations only consider searching locally around a few individual inputs, providing limited guarantees. We propose DeepSafe, a novel approach for automatically assessing the overall robustness of a neural network. DeepSafe applies clustering over known labeled data and leverages off-the-shelf constraint solvers to automatically identify and check safe regions in which the network is robust …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:Mojj43d5GZwC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"We introduce a new theory of algebraic datatypes where selector symbols can be shared between multiple constructors, thereby reducing the number of terms considered by current SMT-based solving approaches. We show that the satisfiability problem for the traditional theory of algebraic datatypes can be reduced to problems where selectors are mapped to shared symbols based on a transformation provided in this paper. The use of shared selectors addresses a key bottleneck for an SMT-based enumerative approach to the Syntax-Guided Synthesis (SyGuS) problem. Our experimental evaluation of an implementation of the new theory in the SMT solver cvc4 on syntax-guided synthesis and other domains provides evidence that the use of shared selectors improves state-of-the-art SMT-based approaches for constraints over algebraic datatypes.",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:1qzjygNMrQYC,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,"Nearly all web-based interfaces are written in JavaScript. Given its prevalence, the support for high performance JavaScript code is crucial. The ECMA Technical Committee 39 (TC39) has recently extended the ECMAScript language (i.e., JavaScript) to support shared memory accesses between different threads. The extension is given in terms of a natural language memory model specification. In this paper we describe a formal approach for validating both the memory model and its implementations in various JavaScript engines. We first introduce a formal version of the memory model and report results on checking the model for consistency and other properties. We then introduce our tool, EMME, built on top of the Alloy analyzer, which leverages the model to generate all possible valid executions of a given JavaScript program. Finally, we report results using EMME together with small test programs to …",https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=20&pagesize=80&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:kRWSkSYxWN8C,http://www.cs.stanford.edu/~barrett
Clark Barrett,"['Formal Methods', 'Satisfiability Modulo Theories', 'Automated Reasoning', 'Verification', 'Security']",32,8270,2018,,https://scholar.google.com/citations?view_op=view_citation&hl=en&user=BtwmZfQAAAAJ&cstart=100&pagesize=100&sortby=pubdate&citation_for_view=BtwmZfQAAAAJ:u5HHmVD_uO8C,http://www.cs.stanford.edu/~barrett
